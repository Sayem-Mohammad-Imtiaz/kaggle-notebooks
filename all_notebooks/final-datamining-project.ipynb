{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Term project Data Mining -CSE 5334\n# Name : Jugal Pareshbhai Patel\n# UTA ID : 1001769143","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Main goal of the project \n\n***The main goal of the project is to build a classifier which can predict the rating (1-10) from the given reviews or comments.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Abstract of the Project \n\nHere for prediction of rating from given reviews and comment we would compare  Naive Bayes classifier and Support Vector Machine (SVM) .Then after the comparision between these two classifiers , SVM gives better accuracy than Naive Bayes hands down .So now we will use linear SVM classifier for the prediction of ratings. The prediction rating would be in range of 1 - 10 . For Naive Bayes we have used Multinomial Naive Bayes algorithm among three naive bayes algorithm and for SVM we have used linear SVM classifier.\n\nHere are the steps done for achieving the goal of the project which is to predict the rating from given reviews and comments :\n1. Load the data from csv file using built in library which is pandas.\n2. Pre-Processing of data .\n3. Dividing dataset into three parts : Train data , Development data, Test data .\n4. Seperate the divided data into two parts : Comments and Ratings\n5. Vectorize comment for each divided data and convert the ratings to integer by using our custom function.\n6. Now we will use train data to train our SVM model and then we will predict the development and test accuracy.\n7. Now we will predict our rating for a single comment using trained SVM model.\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import re\nimport bz2\nimport pickle\nimport _pickle as cPickle\n\nimport pickle\nfrom sys import path\nfrom os.path import join\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadAndProcessData(filePath):\n    data = pd.read_csv(filePath, usecols=['comment', 'rating'])\n    data = data.fillna('')\n    data = data.sample(frac=1).reset_index(drop=True)\n\n    tempList = list()\n    for d in data['comment']:\n        d = d.strip().lower()\n        #d = re.sub('[\\W_]+', '', d, flags = re.UNICODE)\n        tempList.append(d)\n    data['comment'] = tempList.copy()\n\n    tempList = list()\n    for d in data['comment']:\n        if d.islower():\n            tempList.append(d)\n        else:\n            tempList.append('')\n    data['comment'] = tempList.copy()\n\n    tempList = list()\n    for r in data['rating']:\n        r = float(r)\n        tempList.append(r)\n    data['rating'] = tempList.copy()\n\n    data = data[data['comment'].apply(lambda xyz: len(xyz) > 0)]\n    data = data[data['rating'].apply(lambda rate: float(rate) >= 1)]\n    data = data.sample(frac=1).reset_index(drop=True)\n\n    return data\n\ndef getTrainData(data, n):\n    data = data.sample(frac=1).reset_index(drop=True)\n    lenOfData = data.shape[0]\n\n    endIndex = int(lenOfData * n)\n\n    trainSet = data[: endIndex]\n    otherSet = data[endIndex:]\n\n    trainSet = trainSet.sample(frac=1).reset_index(drop=True)\n    otherSet = otherSet.sample(frac=1).reset_index(drop=True)\n\n    return [trainSet, otherSet]\n\ndef getDevAndTestData(data):\n    devSet, testSet = getTrainData(data, 0.5).copy()\n    \n    if devSet.shape[0] >= testSet.shape[0]:\n        return [devSet, testSet]\n    else:\n        return [testSet, devSet]\n    \ndef generateFile(name, data):\n    with bz2.BZ2File(name + '.pbz2', 'w') as f:\n        cPickle.dump(data, f)\n    f.close()\n    \ndef readFile(name):\n    with bz2.BZ2File(name, 'rb') as f:\n        data = cPickle.load(f)\n    f.close()\n    return data\n\ndef getVectorizer(data):\n    vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n    vectorizer.fit(data)\n    generateFile('vectorizer', vectorizer)\n    # vectorizerFile = open('vectorizer', 'ab')\n    # pickle.dump(vectorizer, vectorizerFile)\n    # vectorizerFile.close()\n\n    return vectorizer\n\ndef vectorizeData(data, vectorizer):\n    data = vectorizer.transform(data)\n\n    return data\n\ndef workOnRatings(ratings):\n    tempList = list()\n    for r in ratings:\n        if r%int(r) <= 0.5:\n            tempList.append(int(r))\n        else:\n            tempList.append(int(r + 1))\n\n    return np.asarray(tempList)\n\n\ndef calAccuracy(actual, pred):\n    return accuracy_score(actual, pred)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pathToFolder = join(path[0], '/kaggle/input/boardgamegeek-reviews')\n#/content/drive/My Drive/Colab Notebooks/boardgamegeek-reviews\npathToFile = join(pathToFolder, 'bgg-13m-reviews.csv')\n\ndata = loadAndProcessData(pathToFile)\nprint(data)\n\ntrainDataset, tempDataset = getTrainData(data, 0.95).copy()\ndevDataset, testDataset = getDevAndTestData(tempDataset)\n\nprint('\\n\\n TRAIN DATASET:::\\n')\nprint(trainDataset)\nprint('\\n\\n DEVELOPEMENT DATASET:::\\n')\nprint(devDataset)\nprint('\\n\\n TEST DATASET:::')\nprint(testDataset)\n\n\ntrainComments, trainRatings = [trainDataset['comment'], trainDataset['rating']].copy()\ndevComments, devRatings = [devDataset['comment'], devDataset['rating']].copy()\ntestComments, testRatings = [testDataset['comment'], testDataset['rating']].copy()\n\ntry:\n  vectorizer = readFile('vectorizer.pbz2')\n  # vectorizeFile = open('vectorizer', 'rb')\n  # vectorizer = pickle.load(vectorizeFile)\n  print(\"Vectorizer read from file\")\nexcept (FileNotFoundError):\n  vectorizer = getVectorizer(trainComments)\n  print(\"Vectorizer file was not found... calling function\")\n\n\ntrainComments, trainRatings = [vectorizeData(trainComments, vectorizer), workOnRatings(trainRatings)]\ndevComments, devRatings = [vectorizeData(devComments, vectorizer), workOnRatings(devRatings)]\ntestComments, testRatings = [vectorizeData(testComments, vectorizer), workOnRatings(testRatings)]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What is Naive Bayes?\n\nNaive Bayes classifier is based on Bayes’ theorem, which is: P(H | x) = P(H) P(x | H) / P(x) P(H|x) is the posterior probability of hypothesis (H or target) given predictor (x or attribute). P(H) is the prior probability of hypothesis P(x|H) is the likelihood which is the probability of predictor given hypothesis. P(x) is the prior probability of predictor. Naive Bayes extends Bayes’ theorem to handle multiple evidences by assuming that each evidence is independent.\n\nApplications of Naive Bayes Algorithm :\n\n* Real time prediction\n* Multi class prediction\n* Text Classification / Spam Filtering / Sentiment Analysis\n* Recommendation Systems\n\nThere are 3 main types of Naive Bayes algorithms:\n\n* Gaussian Naive Bayes\n* Multinomial Naive Bayes\n* Bernoulli Naive Bayes\n\nFor our prjoect we have used Multinomial Naive Bayes algorithm for comparision with SVM model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nbModel = MultinomialNB(alpha = 1)\nnbModel.fit(trainComments, trainRatings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nbTrainRatingsResults = nbModel.predict(trainComments)\nnbDevRatingsResults = nbModel.predict(devComments)\nnbTestRatingsResults = nbModel.predict(testComments)\nnbTrainAccuracy = calAccuracy(trainRatings, nbTrainRatingsResults)\nnbDevAccuracy = calAccuracy(devRatings, nbDevRatingsResults)\nnbTestAccuracy = calAccuracy(testRatings, nbTestRatingsResults)\nprint(\"\\n\\nNB accuracy for train dataset: {:0.5f}\".format(nbTrainAccuracy))\nprint(\"NB accuracy for development dataset: {:0.5f}\".format(nbDevAccuracy))\nprint(\"NB accuracy for test dataset(FINAL): {:0.5f}\".format(nbTestAccuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What is Support Vector Machine?\n\nThe objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points. To separate the two classes of data points, there are many possible hyperplanes that could be chosen. Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence. Linear SVM is the newest extremely fast machine learning algorithm for solving multiclass classification problems from ultra large data sets.\n\nAdvantages:\n\n* SVM works relatively well when there is clear margin of separation between classes.\n* SVM is more effective in high dimensional spaces.\n* SVM is effective in cases where number of dimensions is greater than the number of samples.\n* SVM is relatively memory efficient.\n\n**The consensus for ML researchers and practitioners in almost all cases ,the SVM is better than Naive Bayes.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Tuning:\n\n* Hyperparameter tuning is used to improve the accuracy of SVM classifier.\n* Here we have different regularization parameter (c) and we will use that to show relation between accuracy of SVM classifier and whichever c value gives better accuracy , we will select that for improvement in accuracy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#hyper....\nsvmModel1 = LinearSVC(C = 0.1)\nsvmModel1.fit(trainComments, trainRatings)\nsvmModel3 = LinearSVC(C = 0.3)\nsvmModel3.fit(trainComments, trainRatings)\nsvmModel5 = LinearSVC(C = 0.5)\nsvmModel5.fit(trainComments, trainRatings)\nsvmModel7 = LinearSVC(C = 0.7)\nsvmModel7.fit(trainComments, trainRatings)\nsvmModel = LinearSVC()\nsvmModel.fit(trainComments, trainRatings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FOR C=0.1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmTrainRatingsResults = svmModel1.predict(trainComments)\nsvmDevRatingsResults = svmModel1.predict(devComments)\nsvmTestRatingsResults = svmModel1.predict(testComments)\nsvmTrainAccuracy = calAccuracy(trainRatings, svmTrainRatingsResults)\nsvmDevAccuracy = calAccuracy(devRatings, svmDevRatingsResults)\nsvmTestAccuracy = calAccuracy(testRatings, svmTestRatingsResults)\nprint(\"\\n\\nSVM accuracy for train dataset: {:0.5f}\".format(svmTrainAccuracy))\nprint(\"SVM accuracy for development dataset: {:0.5f}\".format(svmDevAccuracy))\nprint(\"SVM accuracy for test dataset(FINAL): {:0.5f}\".format(svmTestAccuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FOR C = 0.3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmTrainRatingsResults = svmModel3.predict(trainComments)\nsvmDevRatingsResults = svmModel3.predict(devComments)\nsvmTestRatingsResults = svmModel3.predict(testComments)\nsvmTrainAccuracy = calAccuracy(trainRatings, svmTrainRatingsResults)\nsvmDevAccuracy = calAccuracy(devRatings, svmDevRatingsResults)\nsvmTestAccuracy = calAccuracy(testRatings, svmTestRatingsResults)\nprint(\"\\n\\nSVM accuracy for train dataset: {:0.5f}\".format(svmTrainAccuracy))\nprint(\"SVM accuracy for development dataset: {:0.5f}\".format(svmDevAccuracy))\nprint(\"SVM accuracy for test dataset(FINAL): {:0.5f}\".format(svmTestAccuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FOR C= 0.5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmTrainRatingsResults = svmModel5.predict(trainComments)\nsvmDevRatingsResults = svmModel5.predict(devComments)\nsvmTestRatingsResults = svmModel5.predict(testComments)\nsvmTrainAccuracy = calAccuracy(trainRatings, svmTrainRatingsResults)\nsvmDevAccuracy = calAccuracy(devRatings, svmDevRatingsResults)\nsvmTestAccuracy = calAccuracy(testRatings, svmTestRatingsResults)\nprint(\"\\n\\nSVM accuracy for train dataset: {:0.5f}\".format(svmTrainAccuracy))\nprint(\"SVM accuracy for development dataset: {:0.5f}\".format(svmDevAccuracy))\nprint(\"SVM accuracy for test dataset(FINAL): {:0.5f}\".format(svmTestAccuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FOR C = 0.7","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmTrainRatingsResults = svmModel7.predict(trainComments)\nsvmDevRatingsResults = svmModel7.predict(devComments)\nsvmTestRatingsResults = svmModel7.predict(testComments)\nsvmTrainAccuracy = calAccuracy(trainRatings, svmTrainRatingsResults)\nsvmDevAccuracy = calAccuracy(devRatings, svmDevRatingsResults)\nsvmTestAccuracy = calAccuracy(testRatings, svmTestRatingsResults)\nprint(\"\\n\\nSVM accuracy for train dataset: {:0.5f}\".format(svmTrainAccuracy))\nprint(\"SVM accuracy for development dataset: {:0.5f}\".format(svmDevAccuracy))\nprint(\"SVM accuracy for test dataset(FINAL): {:0.5f}\".format(svmTestAccuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FOR C = 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmTrainRatingsResults = svmModel.predict(trainComments)\nsvmDevRatingsResults = svmModel.predict(devComments)\nsvmTestRatingsResults = svmModel.predict(testComments)\nsvmTrainAccuracy = calAccuracy(trainRatings, svmTrainRatingsResults)\nsvmDevAccuracy = calAccuracy(devRatings, svmDevRatingsResults)\nsvmTestAccuracy = calAccuracy(testRatings, svmTestRatingsResults)\nprint(\"\\n\\nSVM accuracy for train dataset: {:0.5f}\".format(svmTrainAccuracy))\nprint(\"SVM accuracy for development dataset: {:0.5f}\".format(svmDevAccuracy))\nprint(\"SVM accuracy for test dataset(FINAL): {:0.5f}\".format(svmTestAccuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# So from above steps of hyper-parameter tuning we can see that SVM classifier model's final accuracy is better when c = 0.1 which is 35.08585 .\n\n# So we had got high perfomance in final accuracy which is better than Naive Bayes's accuracy and what that of if SVM would be on itself.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# CHALLENGES :\n\n* ****Dataset is much large which contains more than 13 million of data.\n* ****There were many empty reviews, white spaces , non-english words\n* ****The review data contains many data in float values which was effecting the final accuracy\n* ****Which classifier to select for the best accuracy and predict the rating**\n\n\n# Actions taken to overcome challenges :\n\n* ****Because of the large dataset we have divided the dataset into different parts.\n* ****Conversion of review data which contains float value into integer value.\n* ****From viewing the final accuracy of Multinomial Naive Bayes and SVM , I selected SVM classifier for prediction of ratings.  \n* ****We have used hyper-parameter tuning to improve the accuracy of SVM classifier.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION :\n\n# The results shows that from Naive Bayes classifier and SVM classifier, the final accuracy of SVM classifier is way better than Naive Bayes classifier . So now will be using linear SVM classifier for achieving our goal for prediction of rating from given reviews. So from this we can say that for large text dataset after testing multiple times SVM model classifier is way better than other classifier model.\n\n# From default SVM's accuracy which was around 32 % we improved it to around 35 % , which is better than default SVM accuracy and Naive Bayes accuracy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n  finalSVM = readFile('svmModel.pbz2')\n  # vectorizeFile = open('vectorizer', 'rb')\n  # vectorizer = pickle.load(vectorizeFile)\n  print(\"Model read from file\")\nexcept (FileNotFoundError):\n  print(\"Model file was not found... calling function to create it\")\n  generateFile('svmModel', svmModel1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while True:\n  comment = input(\"Enter comment here...\\n\")\n  if comment == 'q':\n    break\n  comment = vectorizer.transform([comment])\n  rating = svmModel.predict(comment)[0]\n  print(rating)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# REFERENCES\n\n* https://towardsdatascience.com/svm-implementation-from-scratch-python-2db2fc52e5c2\n* https://towardsdatascience.com/vectorization-implementation-in-machine-learning-ca652920c55d\n* https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n* https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n* https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n* https://www.dataquest.io/blog/machine-learning-python/\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}