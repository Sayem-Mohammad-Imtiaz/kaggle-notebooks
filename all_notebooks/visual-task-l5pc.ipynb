{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nimport keras.layers as layers\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import array_to_img\nimport numpy as np\nfrom math import floor, ceil\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow import math, random, shape\nimport os\nfrom keras.losses import MeanSquaredError, BinaryCrossentropy\nfrom keras.optimizers import Nadam, SGD, Adam, Adamax\nfrom keras.activations import sigmoid\nfrom tensorflow import convert_to_tensor as tens\nfrom keras import backend as K\nfrom cv2 import getGaborKernel as Gabor\nfrom functools import reduce\nfrom matplotlib import pyplot as plt\nfrom math import sqrt\nimport itertools\nimport re\nfrom random import shuffle, seed\nfrom tensorflow.keras.utils import Sequence\nfrom keras.constraints import NonNeg\nfrom keras.regularizers import l1,l2,l1_l2\nfrom keras.initializers import RandomNormal\nimport tensorflow_addons as tfa","metadata":{"id":"imv7hlmyTW7X","executionInfo":{"status":"ok","timestamp":1608812549446,"user_tz":-120,"elapsed":2997,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:08.972203Z","iopub.execute_input":"2021-06-20T14:16:08.972553Z","iopub.status.idle":"2021-06-20T14:16:14.264533Z","shell.execute_reply.started":"2021-06-20T14:16:08.972521Z","shell.execute_reply":"2021-06-20T14:16:14.263674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EXC = 639\nBATCH_SIZE = 32\nRESOLUTION = 8\nEXCITATORY_SYNAPSES_WANTED = 8\nINHIBITORY_SYNAPSES_WANTED = 6","metadata":{"id":"cEiFIsPuIAzE","executionInfo":{"status":"ok","timestamp":1608822940208,"user_tz":-120,"elapsed":671,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:14.266234Z","iopub.execute_input":"2021-06-20T14:16:14.266575Z","iopub.status.idle":"2021-06-20T14:16:14.270559Z","shell.execute_reply.started":"2021-06-20T14:16:14.266542Z","shell.execute_reply":"2021-06-20T14:16:14.269668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform data to dataset","metadata":{"id":"nUlxq41-TW7e"}},{"cell_type":"code","source":"directory = '/kaggle/input/cat-and-dog/'\nLABELS = ['Cat', 'Dog']\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory+'training_set/training_set',\n    labels='inferred',\n    color_mode='grayscale',\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    batch_size=BATCH_SIZE,\n)\nvalid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory+'training_set/training_set',\n    labels='inferred',\n    color_mode='grayscale',\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    batch_size=BATCH_SIZE,\n)\n\ntest_ds = keras.preprocessing.image_dataset_from_directory(directory+'test_set/test_set', labels='inferred', color_mode='grayscale', batch_size=BATCH_SIZE)","metadata":{"id":"Gqx-EqsgTW7f","executionInfo":{"status":"ok","timestamp":1608812559067,"user_tz":-120,"elapsed":2787,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"e5d531b2-a67d-4fd0-c0d8-fa91c2e6c49f","execution":{"iopub.status.busy":"2021-06-20T14:16:14.271889Z","iopub.execute_input":"2021-06-20T14:16:14.272448Z","iopub.status.idle":"2021-06-20T14:16:23.809482Z","shell.execute_reply.started":"2021-06-20T14:16:14.272394Z","shell.execute_reply":"2021-06-20T14:16:23.808424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"show some photos","metadata":{"id":"tlokuuJITW7f"}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i, (images, labels) in enumerate(train_ds.take(9)):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[0].numpy()[:,:,0], cmap='gray')\n    plt.title(LABELS[int(labels[0])])\n    plt.axis(\"off\")","metadata":{"id":"2nXgbWl4TW7g","executionInfo":{"status":"ok","timestamp":1608812560391,"user_tz":-120,"elapsed":4101,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"b6dc864b-e48c-4b61-a4e8-0b3326f00187","execution":{"iopub.status.busy":"2021-06-20T14:16:23.814265Z","iopub.execute_input":"2021-06-20T14:16:23.816956Z","iopub.status.idle":"2021-06-20T14:16:27.379095Z","shell.execute_reply.started":"2021-06-20T14:16:23.816911Z","shell.execute_reply":"2021-06-20T14:16:27.378163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use David Beniaguev's (selfishgene) trained L5PC model","metadata":{"id":"P-VtQx1GTW7g"}},{"cell_type":"code","source":"class Module:\n    def __init__(self, path, module_name, name):\n        self.name = name\n        self.module = self.create_module(path, module_name)\n        self.input = self.module.input\n    \n    def __call__(self, inp):\n        return self.module(inp)\n    \n    def create_module(self, path, module_name):\n        models_folder  = os.path.join(path, 'Models')\n        model_filename  = os.path.join(models_folder, module_name)\n        old_model = keras.models.load_model(model_filename)\n        inp = keras.Input(shape=old_model.layers[0].input.shape[1:])\n        x = old_model.layers[1](inp)\n        for layer in old_model.layers[2:-2-1]:\n            x = layer(x)\n        output = old_model.layers[-3](x)\n        module = keras.Model(inp, output)\n#         L5PC_model.compile(optimizer=Nadam(lr=0.0001), loss='binary_crossentropy', loss_weights=[1.])\n\n        for layer in module.layers:\n            layer.trainable = False\n\n        module.summary()\n        return module       ","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:27.382176Z","iopub.execute_input":"2021-06-20T14:16:27.382566Z","iopub.status.idle":"2021-06-20T14:16:27.396394Z","shell.execute_reply.started":"2021-06-20T14:16:27.382524Z","shell.execute_reply":"2021-06-20T14:16:27.395622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Modules:\n    def __init__(self, neurons):\n        self.multiple = isinstance(neurons, list)\n        self.neurons = neurons\n        self.input = neurons[0].input if self.multiple else neurons.input\n        if not self.multiple:\n            print(\"Neuron module is\", self.neurons.name)\n        else:\n            message = f\"Averaging between {len(self.neurons)} neurons:\\n\"\n            for neuron in self.neurons:\n                message += f\"\\t- {neuron.name}\\n\"\n            print(message)\n                \n    def __call__(self, inputs):\n        if self.multiple:\n            outputs = math_ops.reduce_mean(tf.stack([module(inputs) for module in self.neurons], axis=-1), axis=-1)\n        else:\n            outputs = self.neurons(inputs)\n        return outputs  ","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:27.399821Z","iopub.execute_input":"2021-06-20T14:16:27.400197Z","iopub.status.idle":"2021-06-20T14:16:27.412327Z","shell.execute_reply.started":"2021-06-20T14:16:27.400163Z","shell.execute_reply":"2021-06-20T14:16:27.411406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multiple_neurons = True\ndataset_folder = '/kaggle/input/single-neurons-as-deep-nets-nmda-test-data'","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:27.413707Z","iopub.execute_input":"2021-06-20T14:16:27.41417Z","iopub.status.idle":"2021-06-20T14:16:27.421997Z","shell.execute_reply.started":"2021-06-20T14:16:27.414123Z","shell.execute_reply":"2021-06-20T14:16:27.42104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if multiple_neurons:\n    neurons = Modules([Module(dataset_folder, \"NMDA_TCN__DWT_8_224_217__model.h5\", \"Module_8_layers\"), \n                       Module(dataset_folder, \"NMDA_TCN__DWT_7_292_169__model.h5\", \"Module_7_layers\"), \n                       Module(dataset_folder, \"NMDA_TCN__DWT_9_256_241__model.h5\", \"Module_9_layers\")])\nelse:\n    neurons = Module(dataset_folder, \"NMDA_TCN__DWT_7_128_153__model.h5\", \"module_7_layers\")","metadata":{"id":"caILSWZMTW7g","executionInfo":{"status":"ok","timestamp":1608812566398,"user_tz":-120,"elapsed":1937,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"297d433e-8ba2-449b-cc16-6a2d3425b8a9","execution":{"iopub.status.busy":"2021-06-20T14:16:27.42347Z","iopub.execute_input":"2021-06-20T14:16:27.424013Z","iopub.status.idle":"2021-06-20T14:16:33.306099Z","shell.execute_reply.started":"2021-06-20T14:16:27.423974Z","shell.execute_reply":"2021-06-20T14:16:33.305365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some custom layers and funcs to use","metadata":{"id":"fv097qMmTW7g"}},{"cell_type":"code","source":"class ToBoolLayer(keras.layers.Layer):\n  def __init__(self, threshold=0.5, mult=15, use_sigmoid=True, use_special_sigmoid=None, name=\"ToBoolLayer\"):\n      super().__init__(name=name)\n      self.use_sigmoid = use_sigmoid\n      self.special_sigmoid = use_special_sigmoid\n      self.threshold = threshold\n      self.mult = mult\n\n  def build(self, shape):\n    if self.special_sigmoid is not None:\n      if not len(self.special_sigmoid) == 2:\n        raise Exception(\"Special sigmoid should be in format (pos_mult, neg_mult).\")\n      else:\n        self.sigmoid = SigmoidThreshold(*self.special_sigmoid, self.threshold)\n    elif self.use_sigmoid:\n      self.sigmoid = SigmoidThresholdEasier(threshold=self.threshold, mult=self.mult)\n    \n  def call(self, inputs, training=None):\n    if training is False:\n        inputs = inputs - self.threshold\n        inputs = math_ops.ceil(inputs)\n    elif self.use_sigmoid:\n        inputs = self.sigmoid(inputs)\n    return inputs","metadata":{"id":"DDTEqC7ZTW7h","executionInfo":{"status":"ok","timestamp":1608812566737,"user_tz":-120,"elapsed":540,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.308675Z","iopub.execute_input":"2021-06-20T14:16:33.30901Z","iopub.status.idle":"2021-06-20T14:16:33.319203Z","shell.execute_reply.started":"2021-06-20T14:16:33.30898Z","shell.execute_reply":"2021-06-20T14:16:33.31814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SpikeProcessor(keras.layers.Layer):\n    def __init__(self, nSynapses, start=None, end=None, name=\"SpikeProcessor\"):\n        super().__init__(name=name)\n        self.nSynapses = nSynapses\n        self.start = start\n        self.end = end\n\n    def build(self, shape):\n        self.dims = len(shape)\n        pass\n    \n    def call(self, inputs):\n        if self.start is not None:\n            if self.end is not None:\n                inputs = inputs[:,:,:,self.start:self.end] if self.dims==4 else inputs[:,:,self.start:self.end]\n            else:\n                inputs = inputs[:,:,:,self.start:] if self.dims==4 else inputs[:,:,self.start:]\n        elif self.end is not None:\n            inputs = inputs[:,:,:,:self.end] if self.dims==4 else inputs[:,:,:self.end]\n        preds_sum = math.reduce_sum(inputs, axis=-1, keepdims=True)\n        return_value = preds_sum/self.nSynapses\n        return layers.Flatten()(return_value)","metadata":{"id":"BZT3ZQ5ATW7h","executionInfo":{"status":"ok","timestamp":1608812567060,"user_tz":-120,"elapsed":854,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.32093Z","iopub.execute_input":"2021-06-20T14:16:33.321294Z","iopub.status.idle":"2021-06-20T14:16:33.335Z","shell.execute_reply.started":"2021-06-20T14:16:33.321256Z","shell.execute_reply":"2021-06-20T14:16:33.333952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Previous funcs and layers I don't use anymore","metadata":{"id":"TS9nw2I3TW7h"}},{"cell_type":"code","source":"class OneTimeStamp2Many(keras.layers.Layer):\n    def __init__(self, units):\n        super().__init__()\n        self.units = units\n    \n    def build(self, input_shape):\n        self.w = self.add_weight(shape=(self.units, input_shape[1]),\n                               initializer='random_normal',\n                               trainable=True)\n        self.b = self.add_weight(shape=(1,input_shape[1]),\n                               initializer='zeros',\n                               trainable=True)\n    def call(self, inputs):\n        inputs = K.expand_dims(inputs, axis=1)\n        return tf.multiply(inputs, self.w) + self.b","metadata":{"id":"iekR3vicTW7h","executionInfo":{"status":"ok","timestamp":1608794458807,"user_tz":-120,"elapsed":158358,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.336949Z","iopub.execute_input":"2021-06-20T14:16:33.33743Z","iopub.status.idle":"2021-06-20T14:16:33.349536Z","shell.execute_reply.started":"2021-06-20T14:16:33.33739Z","shell.execute_reply":"2021-06-20T14:16:33.34867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def noise_init(shape, dtype=None):\n    return tf.cast(\n        tf.concat(\n        [tf.random.categorical(tf.math.log([[0.92, 0.08]]), shape[-1]) \n         for _ in range(shape[-2])], axis=0), \n        dtype)","metadata":{"id":"BmdH72Q8TW7i","executionInfo":{"status":"ok","timestamp":1608794458808,"user_tz":-120,"elapsed":158352,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.351019Z","iopub.execute_input":"2021-06-20T14:16:33.351395Z","iopub.status.idle":"2021-06-20T14:16:33.360222Z","shell.execute_reply.started":"2021-06-20T14:16:33.351357Z","shell.execute_reply":"2021-06-20T14:16:33.359026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AddNoise(keras.layers.Layer):\n    def __init__(self, dtype=None):\n        super().__init__()\n        self.datatype=dtype\n\n    def build(self, shape):\n        self.noise = noise_init(shape, self.datatype)\n    \n    def call(self, inputs):\n        return math.multiply(inputs, self.noise)","metadata":{"id":"nUXN4Bm1TW7i","executionInfo":{"status":"ok","timestamp":1608794458808,"user_tz":-120,"elapsed":158350,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.361539Z","iopub.execute_input":"2021-06-20T14:16:33.36203Z","iopub.status.idle":"2021-06-20T14:16:33.371136Z","shell.execute_reply.started":"2021-06-20T14:16:33.361991Z","shell.execute_reply":"2021-06-20T14:16:33.370309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Funcs","metadata":{"id":"HqryLTaUTW7i"}},{"cell_type":"code","source":"def loss_for_me(y_true, y_preds):\n    return MeanSquaredError()(1, y_preds)","metadata":{"id":"pZ2H3wGyrbUd","executionInfo":{"status":"ok","timestamp":1608812568706,"user_tz":-120,"elapsed":639,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.372563Z","iopub.execute_input":"2021-06-20T14:16:33.373209Z","iopub.status.idle":"2021-06-20T14:16:33.383802Z","shell.execute_reply.started":"2021-06-20T14:16:33.373044Z","shell.execute_reply":"2021-06-20T14:16:33.382668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spikes_preds_processing(preds, n_spikes=50):\n    preds_sum = math.reduce_sum(preds, axis=-1, keepdims=True)\n    return preds_sum/(n_spikes)","metadata":{"id":"5f3B1SWXTW7i","executionInfo":{"status":"ok","timestamp":1608812569049,"user_tz":-120,"elapsed":971,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.385292Z","iopub.execute_input":"2021-06-20T14:16:33.385657Z","iopub.status.idle":"2021-06-20T14:16:33.39348Z","shell.execute_reply.started":"2021-06-20T14:16:33.385619Z","shell.execute_reply":"2021-06-20T14:16:33.39254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SigmoidThreshold(pos_mult=1, neg_mult=1, threshold=0):\n    \"\"\"returns a sigmoid function [0,1]->[0,1] with the center at threshold given, and slope multified\"\"\"\n    def sigmoid_threshold(x):\n        new_x = -x+threshold\n        multiplier = (pos_mult + neg_mult + (-pos_mult + neg_mult)*K.sign(new_x)) / 2 \n        return 1/(1+math.exp(multiplier*(new_x)))\n    return sigmoid_threshold","metadata":{"id":"Wl7uhvKsTW7i","executionInfo":{"status":"ok","timestamp":1608812569050,"user_tz":-120,"elapsed":964,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.394928Z","iopub.execute_input":"2021-06-20T14:16:33.395384Z","iopub.status.idle":"2021-06-20T14:16:33.403615Z","shell.execute_reply.started":"2021-06-20T14:16:33.395343Z","shell.execute_reply":"2021-06-20T14:16:33.402565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(0,1,0.01)\nthreshold = 1/16\npos_mult = 10\nneg_mult = 50\nplt.plot(x, SigmoidThreshold(pos_mult, neg_mult, threshold)(x))\nplt.ylim(0,1)\nplt.axhline(0.5, color='r', linestyle='--')\nplt.axvline(threshold, color='g', linestyle='--')\nplt.show()","metadata":{"id":"AgCnGTiqDqLR","executionInfo":{"status":"ok","timestamp":1608812569371,"user_tz":-120,"elapsed":1278,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"79b44f37-3a2c-4e87-d1a3-9b8231a9eaa1","execution":{"iopub.status.busy":"2021-06-20T14:16:33.405421Z","iopub.execute_input":"2021-06-20T14:16:33.40582Z","iopub.status.idle":"2021-06-20T14:16:33.568322Z","shell.execute_reply.started":"2021-06-20T14:16:33.405765Z","shell.execute_reply":"2021-06-20T14:16:33.56733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SigmoidThresholdEasier(mult=1, threshold=0.5):\n  \"\"\"returns a sigmoid function [0,1]->[0,1] with the center at threshold given, and slope multified\"\"\"\n  def sigmoid_threshold(x):\n      return 1/(1+math.exp(mult*(threshold-x)))\n  return sigmoid_threshold","metadata":{"id":"jYlYdJfVTW7j","executionInfo":{"status":"ok","timestamp":1608812569372,"user_tz":-120,"elapsed":1269,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.570971Z","iopub.execute_input":"2021-06-20T14:16:33.571916Z","iopub.status.idle":"2021-06-20T14:16:33.587141Z","shell.execute_reply.started":"2021-06-20T14:16:33.571836Z","shell.execute_reply":"2021-06-20T14:16:33.585052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"how the new sigmoid looks like","metadata":{"id":"awHJyR8-TW7j"}},{"cell_type":"code","source":"x = np.arange(0,1,0.01)\nthreshold = 0.9\nmult = 50\nplt.plot(x, SigmoidThresholdEasier(mult, threshold)(x))\nplt.ylim(0,1)\nplt.xlim(0,1)\nplt.axhline(0.5, color='r', linestyle='--')\nplt.axvline(threshold, color='g', linestyle='--')\nplt.show()","metadata":{"id":"ClSb-6fHTW7j","executionInfo":{"status":"ok","timestamp":1608812569373,"user_tz":-120,"elapsed":1263,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"5b4d512b-45b3-4eb6-c1d1-d9576e029bd5","execution":{"iopub.status.busy":"2021-06-20T14:16:33.589699Z","iopub.execute_input":"2021-06-20T14:16:33.590347Z","iopub.status.idle":"2021-06-20T14:16:33.73466Z","shell.execute_reply.started":"2021-06-20T14:16:33.590301Z","shell.execute_reply":"2021-06-20T14:16:33.733407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"will be in use later","metadata":{"id":"hBjjPRoETW7k"}},{"cell_type":"code","source":"def set_num_syn_loss(syns_wanted_per_ms=50):\n    def num_syn_loss(y_true, y_preds):\n        return MeanSquaredError()(1,y_preds/syns_wanted_per_ms)\n    return num_syn_loss","metadata":{"id":"LymD9MkFTW7k","executionInfo":{"status":"ok","timestamp":1608812569374,"user_tz":-120,"elapsed":1255,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.736679Z","iopub.execute_input":"2021-06-20T14:16:33.737061Z","iopub.status.idle":"2021-06-20T14:16:33.743Z","shell.execute_reply.started":"2021-06-20T14:16:33.73702Z","shell.execute_reply":"2021-06-20T14:16:33.741963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GetRandomInt():\n    def __init__(self, maximum):\n        self.maximum = maximum\n    def call(self):\n        return np.random.randint(0, self.maximum, 1)[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:33.744857Z","iopub.execute_input":"2021-06-20T14:16:33.745354Z","iopub.status.idle":"2021-06-20T14:16:33.754895Z","shell.execute_reply.started":"2021-06-20T14:16:33.74531Z","shell.execute_reply":"2021-06-20T14:16:33.753679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ToNeuronInput(keras.layers.Layer):\n    \"\"\"flattens the temporal dimensions, order by new_order and pads with 0's to fill\"\"\"\n    def __init__(self, full, padding=0, new_order=None, name=\"NeuronInput\", part=200, batch_size=BATCH_SIZE):\n        super().__init__(name=name)\n        self.full = full\n        self.new_order = None\n        self.zero_padding = isinstance(padding, int) and padding == 0\n        self.padding = padding\n        self.part = part\n        self.batch_size = batch_size\n    \n    def build(self, shape):\n        self.ms = shape[1]*shape[2]\n        self.times = self.part // self.ms\n        self.padding_amount = self.full-self.ms*self.times\n    \n    def call(self, inputs, padding):\n                \n        new_inp = layers.Reshape((self.ms, inputs.shape[-1]))(inputs)\n        if self.new_order is not None:\n            new_inp = self.gather(new_inp, self.new_order, axis=-2)\n        if self.times > 1:\n            new_inp = layers.Concatenate(axis=1)([new_inp for _ in range(self.times)])\n        if self.zero_padding and False:\n            new_inp = layers.ZeroPadding1D(padding=(self.full - self.ms*self.times, 0))(new_inp)\n        else:\n            padding = tf.reshape(padding, (padding.shape[0]*padding.shape[1]*padding.shape[2], padding.shape[-1]))\n            starting_time = layers.Lambda(lambda x: self.ranInt(x))(padding)\n            padding = padding[np.newaxis, starting_time:starting_time+self.padding_amount]\n            new_inp = layers.Concatenate(axis=-2)([tf.tile(padding, [tf.shape(new_inp)[0], 1, 1]), new_inp])\n        return new_inp\n\n    def ranInt(self, x):\n        return K.random_uniform((1,), 0, 1024-self.padding_amount, dtype=tf.int32)[0]#.numpy()\n    \n    @tf.function\n    def gather(x, ind):\n        return tf.gather(x+0, ind)","metadata":{"id":"gFrBZHkyTW7q","executionInfo":{"status":"ok","timestamp":1608812569375,"user_tz":-120,"elapsed":1247,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.757147Z","iopub.execute_input":"2021-06-20T14:16:33.757754Z","iopub.status.idle":"2021-06-20T14:16:33.780782Z","shell.execute_reply.started":"2021-06-20T14:16:33.757711Z","shell.execute_reply":"2021-06-20T14:16:33.779431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PredictNeuron(keras.layers.Layer):\n    \"\"\"flattens the temporal dimensions, order by new_order and pads with 0's to fill\"\"\"\n    def __init__(self, neuron_module, name=\"NeuronPrediction\"):\n        super().__init__(name=name)\n        self.neurons = neuron_module\n        self.single = not isinstance(self.neurons, list)\n        if self.single:\n            print(\"Neuron module is\", self.neurons.name)\n        else:\n            message = f\"Averaging between {len(self.neurons)} neurons:\\n\"\n            for neuron in self.neurons:\n                message += f\"\\t- {neuron.name}\\n\"\n            print(message)\n                \n    def call(self, inputs):\n        if not self.single:\n            outputs = math_ops.reduce_mean(tf.stack([module.module(inputs) for module in self.neurons], axis=-1), axis=-1)\n        else:\n            outputs = self.neurons.module(inputs)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:33.782259Z","iopub.execute_input":"2021-06-20T14:16:33.782895Z","iopub.status.idle":"2021-06-20T14:16:33.795551Z","shell.execute_reply.started":"2021-06-20T14:16:33.782844Z","shell.execute_reply":"2021-06-20T14:16:33.794716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Synapse Loss","metadata":{}},{"cell_type":"code","source":"def MeanSquaredErrorSynapsesPerMS(batch_size=32):\n  def mean_squared_error_synapses_per_ms(y_true, y_preds):\n    squared_difference = tf.square(1.-y_preds)\n    mean = tf.reduce_mean(squared_difference, axis=-1)\n    return mean\n  return mean_squared_error_synapses_per_ms","metadata":{"id":"Mq8hSWFxTW7r","executionInfo":{"status":"ok","timestamp":1608812569375,"user_tz":-120,"elapsed":1241,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:33.798433Z","iopub.execute_input":"2021-06-20T14:16:33.79895Z","iopub.status.idle":"2021-06-20T14:16:33.808865Z","shell.execute_reply.started":"2021-06-20T14:16:33.798904Z","shell.execute_reply":"2021-06-20T14:16:33.807895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MSE_RMS_SynapsesPerMS(wanted, size=N_EXC, batch_size=32, eps=1e-3):\n    def mse_rms(X, mu):\n        return tf.math.reduce_mean(tf.math.reduce_sum(tf.square(tf.math.sqrt(tf.math.reduce_mean(tf.square(X+eps), axis=-1)) - mu), axis=-1))\n    real_wanted = np.sqrt(wanted / size)\n    zeros_wanted = np.sqrt(1. - wanted / size)\n    def mse_rms_synapses_per_ms(y_true, y_preds):\n        result = tf.math.sqrt((mse_rms(y_preds, real_wanted)**2 + mse_rms(1. - y_preds, zeros_wanted)**2) / 2)\n        return result\n    return mse_rms_synapses_per_ms","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:33.810508Z","iopub.execute_input":"2021-06-20T14:16:33.810945Z","iopub.status.idle":"2021-06-20T14:16:33.822673Z","shell.execute_reply.started":"2021-06-20T14:16:33.8109Z","shell.execute_reply":"2021-06-20T14:16:33.821411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MeanSynapsesPerMsMetric:\n    def __init__(self, name=\"nSynapses\"):\n        self.name=name\n    def __call__(self, y_true, y_pred):\n        booleans = tf.cast(tf.math.greater(y_pred, 0.5), tf.float32)\n        summed = tf.math.reduce_sum(booleans, axis=-1)\n        mean_by_ms = tf.math.reduce_mean(summed, axis=-1)\n        meaned_batches = tf.math.reduce_mean(mean_by_ms, axis=-1)\n        return meaned_batches\n# def MeanSynapsesPerMsMetric(y_true, y_pred):\n#     booleans = tf.cast(tf.math.greater(y_pred, 0.5), tf.float32)\n#     summed = tf.math.reduce_sum(booleans, axis=-1)\n#     mean_by_ms = tf.math.reduce_mean(summed, axis=-1)\n#     meaned_batches = tf.math.reduce_mean(mean_by_ms, axis=-1)\n#     return meaned_batches","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:33.82445Z","iopub.execute_input":"2021-06-20T14:16:33.824925Z","iopub.status.idle":"2021-06-20T14:16:33.83565Z","shell.execute_reply.started":"2021-06-20T14:16:33.824883Z","shell.execute_reply":"2021-06-20T14:16:33.834606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class MeanSynapsesPerMsMetric(tf.keras.metrics.Metric):\n#     def __init__(self, name=\"SynapsesPerMs\", dtype=tf.float32):\n#         super().__init__(name=name, dtype=dtype)\n#         self.curr_result = self.add_weight(name='nSyns', initializer='zeros')\n#         self.dtype=dtype\n        \n#     def update_state(self, y_true, y_pred, sample_weight=None):\n#         booleans = tf.cast(tf.math.greater(y_pred, 0.5), self.dtype)\n#         summed = tf.math.reduce_sum(booleans, axis=-1)\n#         mean_by_ms = tf.math.reduce_mean(summed, axis=-1)\n#         meaned_batches = tf.math.reduce_mean(mean_by_ms, axis=-1)\n#         if sample_weight is not None:\n#             sample_weight = tf.cast(sample_weight, self.dtype)\n#             meaned_batches = tf.multiply(meaned_batches, sample_weight)\n#         self.curr_result.assign_add(meaned_batches)\n        \n#     def result(self):\n#         return tf.cast(self.curr_result)\n#     def reset_states(self):\n#         self.curr_result.assign(0.)\n#         self.n.assign(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:33.837377Z","iopub.execute_input":"2021-06-20T14:16:33.837884Z","iopub.status.idle":"2021-06-20T14:16:33.847766Z","shell.execute_reply.started":"2021-06-20T14:16:33.837762Z","shell.execute_reply":"2021-06-20T14:16:33.8466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = 8\nsamples = 10\nsynapses = 100\nmu = mean / synapses\n\nf = lambda x, y: MSE_RMS_SynapsesPerMS(mean, size=synapses)(x, np.tile(y[np.newaxis], (BATCH_SIZE,1,1)))\nmetric = lambda x: MeanSynapsesPerMsMetric()(None, np.tile(x[np.newaxis], (BATCH_SIZE,1,1)))#()\nupdate = lambda x: metric.update_state(None, np.tile(x[np.newaxis], (BATCH_SIZE,1,1)))\n\nroun = lambda x: str(round(x.numpy(), 3))\n\ngood = np.array([[1.]*mean + [0]*(synapses - mean)]*samples)\nfor i in range(samples): np.random.shuffle(good[i])\n\n# update(good)\nplt.figure(figsize=(10,5))    \nplt.suptitle(f\"Loss with wanted mean {mean}, {samples} samples and {synapses} synapses\")\nplt.subplot(3,2,1)\nplt.title(f\"perfect: {roun(f(None, good))}; nSyns {metric(good)}\")\nplt.imshow(good, cmap=\"gray\", vmin=0, vmax=1)\n# metric.reset_states()\n\nplt.subplot(3,2,2)\npretty_good = np.clip(good + np.random.normal(0, .3, good.shape), 0 ,1)\n# update(pretty_good)\nplt.title(f\"good: {roun(f(None, pretty_good))}; nSyns {metric(pretty_good)}\")\nplt.imshow(pretty_good, cmap=\"gray\", vmin=0, vmax=1)\n# metric.reset_states()\n\nplt.subplot(3,2,3)\nopposite = np.array([[not i for i in row] for row in good.astype(np.int8)], dtype=np.float32) #np.clip(good + np.random.normal(0, .6, good.shape), 0, 1)\n# update(opposite)\nplt.title(f\"opposite: {roun(f(None, opposite))}; nSyns {metric(opposite)}\")\nplt.imshow(opposite, cmap=\"gray\", vmin=0, vmax=1)\n# metric.reset_states()\n\nplt.subplot(3,2,4)\nbad = np.clip(np.random.normal(.5, .25, samples*synapses).reshape((samples, synapses)), 0, 1)\n# update(bad)\nplt.title(f\"random: {roun(f(None, bad))}; nSyns {metric(bad)}\")\nplt.imshow(bad, cmap=\"gray\", vmin=0, vmax=1)\n# metric.reset_states()\n\n\nplt.subplot(3,2,5)\nzeros = np.zeros((samples, synapses))\n# update(zeros)\nplt.title(f\"zeros: {roun(f(None, zeros))}; nSyns {metric(zeros)}\")\nplt.imshow(zeros, cmap=\"gray\", vmin=0, vmax=1)\n# metric.reset_states()\n\n\nplt.subplot(3,2,6)\nones = np.ones((samples, synapses))\n# update(ones)\nplt.title(f\"ones: {roun(f(None, ones))}; nSyns {metric(ones)}\")\nplt.imshow(ones, cmap=\"gray\", vmin=0, vmax=1)  \n# metric.reset_states()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:33.849447Z","iopub.execute_input":"2021-06-20T14:16:33.849783Z","iopub.status.idle":"2021-06-20T14:16:34.716245Z","shell.execute_reply.started":"2021-06-20T14:16:33.849756Z","shell.execute_reply":"2021-06-20T14:16:34.715312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MaxErrorSynapsesPerMS(batch_size=32, y_true_for_real=False):\n    def max_error_synapses_per_ms(y_true, y_preds):\n        maxes = tf.reduce_max(y_preds, axis=-1)\n        squared_difference = tf.square(1-y_preds)\n        mean = tf.reduce_mean(squared_difference, axis=-1)\n        return mean\n    return max_error_synapses_per_ms","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:34.718122Z","iopub.execute_input":"2021-06-20T14:16:34.71851Z","iopub.status.idle":"2021-06-20T14:16:34.725981Z","shell.execute_reply.started":"2021-06-20T14:16:34.718467Z","shell.execute_reply":"2021-06-20T14:16:34.72471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def EntropySynapseLoss(batch_size=32):\n    def entropy_synapse_loss(y_true, y_preds):\n        flattened = layers.Flatten()(y_preds)\n        return -math_ops.reduce_sum(flattened * math_ops.log(flattened), -1)\n    return entropy_synapse_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:34.727763Z","iopub.execute_input":"2021-06-20T14:16:34.728453Z","iopub.status.idle":"2021-06-20T14:16:34.748769Z","shell.execute_reply.started":"2021-06-20T14:16:34.728406Z","shell.execute_reply":"2021-06-20T14:16:34.741938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def VarianceSynapseLoss(k=1, batch_size=32):\n    def variance_synapse_loss(y_true, y_preds):\n        flattened = layers.Flatten()(y_preds)\n        mean = layers.Flatten()(layers.RepeatVector(flattened.shape[-1])(K.expand_dims(math_ops.reduce_mean(flattened, axis=-1), axis=-1)))\n        variance = math_ops.reduce_sum((flattened - mean)**2, -1) / (flattened.shape[-1] - 1)\n        return math_ops.exp(-k * variance)\n    return variance_synapse_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:34.752248Z","iopub.execute_input":"2021-06-20T14:16:34.753637Z","iopub.status.idle":"2021-06-20T14:16:34.767345Z","shell.execute_reply.started":"2021-06-20T14:16:34.7535Z","shell.execute_reply":"2021-06-20T14:16:34.766207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_acceptable_spikes_per_ms = 3.0\nmax_acceptable_spikes_deviation = 20.0\nactivity_reg_constant = 0.2 * 0.0028\n\n\ndef pre_synaptic_spike_regularization(activation_map):\n    # sum over all dendritic locations\n    x = K.sum(activation_map, axis=2)\n\n    # ask if it's above 'max_acceptable_spikes_per_ms'\n    x = K.relu(x - max_acceptable_spikes_per_ms)\n\n    # if above threshold, apply quadratic penelty\n    x = K.square(x / max_acceptable_spikes_deviation)\n\n    # average everything\n    x = activity_reg_constant * K.mean(x)\n\n    return x","metadata":{"id":"a6NtHpNJTW7t","executionInfo":{"status":"ok","timestamp":1608812605586,"user_tz":-120,"elapsed":1334,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:34.785264Z","iopub.execute_input":"2021-06-20T14:16:34.786141Z","iopub.status.idle":"2021-06-20T14:16:34.794256Z","shell.execute_reply.started":"2021-06-20T14:16:34.786092Z","shell.execute_reply":"2021-06-20T14:16:34.79294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Preprocessing**","metadata":{"id":"z0jZ0uIuTW7k"}},{"cell_type":"markdown","source":"Parameters for gabor filters and max pooling kernel sizes are from \"Robust Object Recognition with Cortex-Like Mechanisms\" (Serre et al.)","metadata":{"id":"AqbtgXauTW7k"}},{"cell_type":"markdown","source":"> # Gabor filters - Simple Cells","metadata":{"id":"kSLh2ZOQTW7k"}},{"cell_type":"code","source":"n_filters = 64\nn_orientations = 4\n\nksizes = [(i, i) for i in range(7,38, 2)]\nthetas = [0 , (45 / 180) * np.pi, (90 / 180) * np.pi, (135 / 180) * np.pi]\ngammas = [0.3] * 16\nsigmas = [2.8, 3.6, 4.5, 5.4, 6.3, 7.3, 8.2, 9.2, 10.2, 11.3, 12.3, 13.4, 14.6, 15.8, 17., 18.2]\nlambdas = [3.5, 4.6, 5.6, 6.8, 7.9, 9.1, 10.3, 11.5, 12.7, 14.1, 15.4, 16.8, 18.2, 19.7, 21.2, 22.8]\n\nall_filters = [[(size, sigma, theta, lambd, gamma) for theta in thetas] \n               for size, gamma, sigma, lambd in zip(ksizes, gammas, sigmas, lambdas)]\nall_filters = reduce(lambda x,y: x+y, all_filters, [])\nreoredering_inds = [ 0,0+4,   1, 1+4,  2, 2+4,  3, 3+4,\n                     8,8+4,   9, 9+4, 10,10+4, 11,11+4,\n                    16,16+4, 17,17+4, 18,18+4, 19,19+4,\n                    24,24+4, 25,25+4, 26,26+4, 27,27+4,\n                    32,32+4, 33,33+4, 34,34+4, 35,35+4,\n                    40,40+4, 41,41+4, 42,42+4, 43,43+4,\n                    48,48+4, 49,49+4, 50,50+4, 51,51+4,\n                    56,56+4, 57,57+4, 58,58+4, 59,59+4]\n\nall_filters_reordered = [all_filters[k] for k in reoredering_inds]","metadata":{"id":"ln1LFszmTW7l","executionInfo":{"status":"ok","timestamp":1608812576019,"user_tz":-120,"elapsed":669,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:34.799166Z","iopub.execute_input":"2021-06-20T14:16:34.800253Z","iopub.status.idle":"2021-06-20T14:16:34.827209Z","shell.execute_reply.started":"2021-06-20T14:16:34.800172Z","shell.execute_reply":"2021-06-20T14:16:34.825679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gabor initializer","metadata":{"id":"lN0DN6wFTW7l"}},{"cell_type":"code","source":"class GaborInitializer(tf.keras.initializers.Initializer):\n    def __init__(self, size, sigma, theta, lambd, gamma):\n        self.ksize = size\n        self.sigma = sigma\n        self.theta = theta\n        self.lambd = lambd\n        self.gamma = gamma\n\n    def __call__(self, dtype=None):\n        return tens(Gabor(self.ksize, self.sigma, self.theta, self.lambd, self.gamma))\n\n    def get_config(self):  # To support serialization\n        return {'ksize': self.ksize, 'sigma': self.sigma, 'theta': self.theta, 'lambda': self.lambd, 'gamma': self.gamma}","metadata":{"id":"gzLXQXYlTW7l","executionInfo":{"status":"ok","timestamp":1608812576313,"user_tz":-120,"elapsed":944,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:34.829377Z","iopub.execute_input":"2021-06-20T14:16:34.829971Z","iopub.status.idle":"2021-06-20T14:16:34.844942Z","shell.execute_reply.started":"2021-06-20T14:16:34.829924Z","shell.execute_reply":"2021-06-20T14:16:34.843515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_filter_shape = all_filters_reordered[-1][0]\ncenter_pixel_ind = int((max_filter_shape[0] - 1 ) / 2)\n\n# place to store all filter activations\nfilters_matrix = np.zeros((max_filter_shape[0], max_filter_shape[1], len(all_filters)))\n\nplt.figure(figsize=(18,22))\nplt.subplots_adjust(left=0.04, right=0.96, bottom=0.04, top=0.96, hspace=0.25, wspace=0.1)\nfor i, filt in enumerate(all_filters_reordered):\n    filter_size  = filt[0][0]\n    oritentation = (filt[2] / np.pi ) * 180\n    curr_sigma   = filt[1]\n    curr_lambda  = filt[3]\n    \n    half_filter_size = int((filter_size -1 ) / 2)\n    upper_left_start = center_pixel_ind - half_filter_size\n    \n    curr_small_filter = GaborInitializer(*filt)().numpy()\n    curr_full_filter = np.zeros((max_filter_shape))\n    curr_full_filter[upper_left_start:upper_left_start + filter_size, upper_left_start:upper_left_start + filter_size] = curr_small_filter\n    \n    # store the filter and the activations for later\n    filters_matrix[:,:,i] = curr_full_filter\n    \n    plt.subplot(8,8,i+1);\n    plt.title('%dx%d, $\\Theta=%d$, \\n$\\sigma=%.1f$, $\\lambda=%.1f$' %(filter_size, filter_size, oritentation, curr_sigma, curr_lambda))\n    plt.imshow(curr_full_filter, cmap='gray')\n    plt.axis(\"off\")","metadata":{"id":"RDQOu5WsTW7l","executionInfo":{"status":"ok","timestamp":1608812581326,"user_tz":-120,"elapsed":5951,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"b9a5b4e7-09f6-401d-a76c-b57d51a872ff","execution":{"iopub.status.busy":"2021-06-20T14:16:34.847421Z","iopub.execute_input":"2021-06-20T14:16:34.847917Z","iopub.status.idle":"2021-06-20T14:16:40.236453Z","shell.execute_reply.started":"2021-06-20T14:16:34.847874Z","shell.execute_reply":"2021-06-20T14:16:40.23576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to create Conv2D layer waith gabor filter","metadata":{"id":"H0Y1yzSJTW7m"}},{"cell_type":"code","source":"def simple_cells_module(filters_matrix, strides=(1,1), input_shape=(256,256)):\n    # input is a single channel gray scale image\n    input_tensor = keras.Input(shape=(input_shape[0],input_shape[1],1))\n    \n    # initializer with predefined weights\n    def gabor_filters_init(shape, dtype=None):\n        return -filters_matrix[:,:,np.newaxis,:]\n\n    num_filters = filters_matrix.shape[2]\n    kernel_size = (filters_matrix.shape[0], filters_matrix.shape[1])\n\n    # single conv2d layer with all weights\n    conv_2d_layer = layers.Conv2D(num_filters, kernel_size, strides=strides, kernel_initializer=gabor_filters_init, padding='same')\n    conv_2d_layer.trainable=False\n    simple_cell_activations = conv_2d_layer(input_tensor)\n    simple_cell_module = keras.Model(input_tensor, simple_cell_activations)\n    \n    return simple_cell_module","metadata":{"id":"lippTHZuTW7m","executionInfo":{"status":"ok","timestamp":1608812581327,"user_tz":-120,"elapsed":5943,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:40.238052Z","iopub.execute_input":"2021-06-20T14:16:40.238406Z","iopub.status.idle":"2021-06-20T14:16:40.249066Z","shell.execute_reply.started":"2021-06-20T14:16:40.238368Z","shell.execute_reply":"2021-06-20T14:16:40.248323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_pooling_size = list(range(8,23,2))\npooling_size_list = [[(s,s,2)] for s in max_pooling_size]\nnum_orientations = 4","metadata":{"id":"7Jzym63XTW7m","executionInfo":{"status":"ok","timestamp":1608812581327,"user_tz":-120,"elapsed":5937,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:40.252296Z","iopub.execute_input":"2021-06-20T14:16:40.252792Z","iopub.status.idle":"2021-06-20T14:16:40.26106Z","shell.execute_reply.started":"2021-06-20T14:16:40.252757Z","shell.execute_reply":"2021-06-20T14:16:40.26014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_process_module(filter_matrix, pooling_size_list, strides=(1,1), num_orientations=4, input_shape=(256,256)):\n    \n    print('num gabor filters must be %d' %(sum([x[0][-1] for x in pooling_size_list]) * num_orientations))\n\n    # input is a single channel gray scale image\n    input_tensor = keras.Input(shape=(input_shape[0],input_shape[1],1))\n    \n    # calc simple cell activations\n    simple_cells_activations = K.expand_dims(simple_cells_module(filters_matrix, strides=(1,1), input_shape=(256,256))(input_tensor), axis=-1)\n    \n    # add support for subsampling\n    strides_to_use = (strides[0], strides[1], 2)\n\n    # apply max pooling\n    maxpool_3d_layers = []\n    for k, pool_size in enumerate(pooling_size_list):\n        start_ind = num_orientations * pool_size[0][-1] * k\n        end_ind   = num_orientations * pool_size[0][-1] * (k + 1)\n        curr_pool_input_slice  = simple_cells_activations[:,:,:,start_ind:end_ind]\n        curr_pool_output_slice = layers.MaxPooling3D(pool_size=pool_size[0], strides=strides_to_use, padding='same')(curr_pool_input_slice)\n        maxpool_3d_layers.append(curr_pool_output_slice)\n    \n    # squeeze the last dimention\n    concatenated_pooled_layers = K.squeeze(layers.Concatenate(axis=-2)(maxpool_3d_layers), axis=-1)\n    \n    # wrap as module and return\n    complex_cell_module = keras.Model(input_tensor, concatenated_pooled_layers)\n    \n    return complex_cell_module","metadata":{"id":"QUS4OALUTW7m","executionInfo":{"status":"ok","timestamp":1608812581328,"user_tz":-120,"elapsed":5932,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:40.262569Z","iopub.execute_input":"2021-06-20T14:16:40.26329Z","iopub.status.idle":"2021-06-20T14:16:40.276812Z","shell.execute_reply.started":"2021-06-20T14:16:40.26323Z","shell.execute_reply":"2021-06-20T14:16:40.275988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessor(filters_matrix, pooling_sizes, n_orientations=4, conv_strides=(1,1), max_pooling_strides=(1,1), input_shape=(256,256)):\n    return pre_process_module(filters_matrix, pooling_sizes, strides=max_pooling_strides, num_orientations=n_orientations, input_shape=input_shape)\n","metadata":{"id":"eJZlf1x5TW7n","executionInfo":{"status":"ok","timestamp":1608812581328,"user_tz":-120,"elapsed":5925,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:40.278525Z","iopub.execute_input":"2021-06-20T14:16:40.278947Z","iopub.status.idle":"2021-06-20T14:16:40.29089Z","shell.execute_reply.started":"2021-06-20T14:16:40.27891Z","shell.execute_reply":"2021-06-20T14:16:40.290063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processor = preprocessor(filters_matrix, pooling_size_list, max_pooling_strides=(RESOLUTION,RESOLUTION))","metadata":{"id":"BeT3BaaLTW7n","executionInfo":{"status":"ok","timestamp":1608812581329,"user_tz":-120,"elapsed":5921,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"78b88a70-248c-4ba7-d9e0-3e8974ec902e","execution":{"iopub.status.busy":"2021-06-20T14:16:40.294301Z","iopub.execute_input":"2021-06-20T14:16:40.294691Z","iopub.status.idle":"2021-06-20T14:16:40.440265Z","shell.execute_reply.started":"2021-06-20T14:16:40.294558Z","shell.execute_reply":"2021-06-20T14:16:40.439378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2d_with_gabor(filters, trainable=False):\n    layer = layers.Conv2D(len(filters), filters[0][0], kernel_initializer='zeros', padding='same')\n    initalize = layer(np.zeros((1,256,256,1)))\n    new_weights = np.stack([GaborInitializer(*filt)() for filt in filters]).transpose((1,2,0))[:,:,np.newaxis,:]\n    layer.set_weights([new_weights, layer.get_weights()[-1]])\n    layer.trainable = trainable\n    return layer","metadata":{"id":"zxKG9vqMTW7o","executionInfo":{"status":"ok","timestamp":1608812581329,"user_tz":-120,"elapsed":5915,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:40.441547Z","iopub.execute_input":"2021-06-20T14:16:40.442044Z","iopub.status.idle":"2021-06-20T14:16:40.450234Z","shell.execute_reply.started":"2021-06-20T14:16:40.442007Z","shell.execute_reply":"2021-06-20T14:16:40.449508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(inp):\n    normalized = inp / 255\n    pre_process_s1 = [layers.Concatenate(axis=-2)\n                  ([K.expand_dims(conv2d_with_gabor(all_filters[n_orientations*j:n_orientations*(j+1)], \n                                                    trainable=False)(inp),\n                                  axis=-2) for j in (i, i+1)]) \n                  for i in range(0,n_filters//n_orientations,2)]\n    pre_process_c1 = layers.Concatenate(axis=-2)([(layers.MaxPooling3D(pool_size=(ksize, ksize, 2), strides=(1,1,2), padding=\"same\")(i)) \n                  for i, ksize in zip(pre_process_s1, max_pooling_size)])\n    return pre_process_c1","metadata":{"id":"JEK95Kw8TW7o","executionInfo":{"status":"ok","timestamp":1608812581330,"user_tz":-120,"elapsed":5910,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:40.451346Z","iopub.execute_input":"2021-06-20T14:16:40.451578Z","iopub.status.idle":"2021-06-20T14:16:40.465865Z","shell.execute_reply.started":"2021-06-20T14:16:40.451555Z","shell.execute_reply":"2021-06-20T14:16:40.46508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show preprocessing on one image from dataset","metadata":{"id":"N4PwG-TBTW7o"}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor _, (image, label) in enumerate(train_ds.take(1)):\n    image = image[0].numpy()[:,:,0]\n    label = int(label[0])\n    processed = processor(image[np.newaxis,:,:,np.newaxis]).numpy()[0]\n    for i in range(32):\n        ax = plt.subplot(8, 4, i+1)\n        plt.imshow(processed[:,:,i], cmap='gray')\n        plt.title(LABELS[label])\n        plt.axis(\"off\")","metadata":{"id":"pMHzCQ1zTW7p","executionInfo":{"status":"ok","timestamp":1608812586778,"user_tz":-120,"elapsed":11352,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"03606932-8624-4dce-89e1-a2fd2cf9ea77","execution":{"iopub.status.busy":"2021-06-20T14:16:40.467435Z","iopub.execute_input":"2021-06-20T14:16:40.468035Z","iopub.status.idle":"2021-06-20T14:16:44.680736Z","shell.execute_reply.started":"2021-06-20T14:16:40.467994Z","shell.execute_reply":"2021-06-20T14:16:44.678697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Noisy Optimizer (not used)\nhttps://arxiv.org/abs/1511.06807\n\nhttps://github.com/cpury/keras_gradient_noise","metadata":{"id":"DCaWcWciTW7p"}},{"cell_type":"code","source":"import inspect\nimport importlib\n\ndef add_gradient_noise(BaseOptimizer, keras=None):\n    \"\"\"\n    Given a Keras-compatible optimizer class, returns a modified class that\n    supports adding gradient noise as introduced in this paper:\n    https://arxiv.org/abs/1511.06807\n    The relevant parameters from equation 1 in the paper can be set via\n    noise_eta and noise_gamma, set by default to 0.3 and 0.55 respectively.\n    By default, tries to guess whether to use default Keras or tf.keras based\n    on where the optimizer was imported from. You can also specify which Keras\n    to use by passing the imported module.\n    \"\"\"\n    if keras is None:\n        # Import it automatically. Try to guess from the optimizer's module\n        if hasattr(BaseOptimizer, '__module__') and BaseOptimizer.__module__.startswith('keras'):\n            keras = importlib.import_module('keras')\n        else:\n            keras = importlib.import_module('tensorflow.keras')\n\n    K = keras.backend\n\n    if not (\n        inspect.isclass(BaseOptimizer) and\n        issubclass(BaseOptimizer, keras.optimizers.Optimizer)\n    ):\n        raise ValueError(\n            'add_gradient_noise() expects a valid Keras optimizer'\n        )\n\n    def _get_shape(x):\n        if hasattr(x, 'dense_shape'):\n            return x.dense_shape\n\n        return K.shape(x)\n\n    class NoisyOptimizer(BaseOptimizer):\n        def __init__(self, noise_eta=0.3, noise_gamma=0.55, **kwargs):\n            super(NoisyOptimizer, self).__init__(**kwargs)\n            with K.name_scope(self.__class__.__name__):\n                self.noise_eta = K.variable(noise_eta, name='noise_eta')\n                self.noise_gamma = K.variable(noise_gamma, name='noise_gamma')\n\n        def get_gradients(self, loss, params):\n            grads = super(NoisyOptimizer, self).get_gradients(loss, params)\n\n            # Add decayed gaussian noise\n            t = K.cast(self.iterations, K.dtype(grads[0]))\n            variance = self.noise_eta / ((1 + t) ** self.noise_gamma)\n\n            grads = [\n                grad + K.random_normal(\n                    _get_shape(grad),\n                    mean=0.0,\n                    stddev=K.sqrt(variance),\n                    dtype=K.dtype(grads[0])\n                )\n                for grad in grads\n            ]\n\n            return grads\n\n        def get_config(self):\n            config = {'noise_eta': float(K.get_value(self.noise_eta)),\n                      'noise_gamma': float(K.get_value(self.noise_gamma))}\n            base_config = super(NoisyOptimizer, self).get_config()\n            return dict(list(base_config.items()) + list(config.items()))\n\n    NoisyOptimizer.__name__ = 'Noisy{}'.format(BaseOptimizer.__name__)\n\n    return NoisyOptimizer","metadata":{"id":"Z58q6uw_TW7p","executionInfo":{"status":"ok","timestamp":1608812586779,"user_tz":-120,"elapsed":9237,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:44.682351Z","iopub.execute_input":"2021-06-20T14:16:44.68274Z","iopub.status.idle":"2021-06-20T14:16:44.70254Z","shell.execute_reply.started":"2021-06-20T14:16:44.6827Z","shell.execute_reply":"2021-06-20T14:16:44.701532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NoisySGD = add_gradient_noise(SGD)\nNoisyNadam = add_gradient_noise(Nadam)\nNoisyAdamax = add_gradient_noise(Adamax)","metadata":{"id":"HVVeWEnsTW7p","executionInfo":{"status":"ok","timestamp":1608812586780,"user_tz":-120,"elapsed":9226,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:44.704172Z","iopub.execute_input":"2021-06-20T14:16:44.704585Z","iopub.status.idle":"2021-06-20T14:16:44.718147Z","shell.execute_reply.started":"2021-06-20T14:16:44.704543Z","shell.execute_reply":"2021-06-20T14:16:44.717459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eta = 0.03\ngamma = 0.55\n\nn = 150\n\nvar = []\nfor t in range(n):\n    var.append(eta/(1+t)**gamma)\nplt.plot(np.arange(n), var)\nplt.title(r'Noise $\\sigma^{2} $ through epochs')\nplt.xlabel('ephocs')\nplt.ylabel(r'noise $\\sigma^{2}$')\nplt.show()","metadata":{"id":"HzrjIvE0TW7p","executionInfo":{"status":"ok","timestamp":1608812586781,"user_tz":-120,"elapsed":9219,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"247350a7-ced5-4613-df00-3c911f6de4e0","execution":{"iopub.status.busy":"2021-06-20T14:16:44.71986Z","iopub.execute_input":"2021-06-20T14:16:44.720175Z","iopub.status.idle":"2021-06-20T14:16:44.896394Z","shell.execute_reply.started":"2021-06-20T14:16:44.720147Z","shell.execute_reply":"2021-06-20T14:16:44.895481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start noise","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5,20))\ndct = {\"Dog\": [], \"Cat\": []}\nfor _, (image, label) in enumerate(train_ds.take(5)):\n    for img, lbl in zip(image, label):\n        dct[LABELS[lbl]].append(img[np.newaxis,])\n#     boolean = False\n#     if len(dogs) < 400//64:\n#         boolean = True\n#         dogs += [img[np.newaxis,] for img,lbl in zip(images,label) if LABELS[lbl]==\"Dog\"]\n#     if len(cats) < 400//64:\n#         boolean = True   \n#         cats += [img[np.newaxis,] for img,lbl in zip(images,label) if LABELS[lbl]==\"Cat\"]\n#     if not boolean: break\nall_images = np.concatenate(dct[\"Dog\"] + dct[\"Cat\"], axis=0)\nplt.subplot(5,1,1)\nplt.title(\"Original Image\")\nplt.imshow(all_images[0,:,:,0], cmap=\"gray\")\n\n# Import data\nblocksize = 64\n\n# Create blocks\nshuffled_images = all_images.copy()\nfor j in range(0, all_images.shape[2], blocksize):\n    for i in range(0, all_images.shape[1], blocksize):\n        indxs = np.random.permutation(all_images.shape[0]).tolist()\n        for orig,new in zip(indxs, range(all_images.shape[0])):\n            shuffled_images[orig,i:i+blocksize, j:j+blocksize] = all_images[new, i:i+blocksize, j:j+blocksize]\nplt.subplot(5,1,2)\nplt.title(\"Hybrid Image\")\nplt.imshow(shuffled_images[0,:,:,0], cmap=\"gray\")\n\n# plt.subplot(5,1,3)\n# plt.title(\"Smoothed Hybrid\")\n# smoothed = smoothing_layer(shuffled_images)\n# plt.imshow(smoothed[0,:,:,0], cmap=\"gray\")\n\n\n# image_list = [smoothed[i] for i in range(smoothed.shape[0])]\n# PADDING_HYBRID = np.concatenate(image_list, axis=-2)[np.newaxis]\n\n# processed_images = processor(smoothed)\n\n# plt.subplot(5,1,4)\n# plt.title(\"Processed Smoothened Hybrid Image (Channel 0)\")\n# plt.imshow(processed_images[0,:,:,0], cmap=\"gray\")\n\n# image_list = [processed_images[i] for i in range(processed_images.shape[0])]\n# PADDING = np.concatenate(image_list, axis=-2)[np.newaxis]\n# print(PADDING.shape)\n\nprocessed_images = processor(shuffled_images)\n\nplt.subplot(5,1,4)\nplt.title(\"Processed Hybrid Image (Channel 0)\")\nplt.imshow(processed_images[0,:,:,0], cmap=\"gray\")\n\nimage_list = [processed_images[i] for i in range(processed_images.shape[0])]\nPADDING = np.concatenate(image_list, axis=-2)[np.newaxis]\nprint(PADDING.shape)\n\nplt.subplot(5,1,5)\nplt.title(\"Concatenated Processed Hybrid Image (Channel 0)\")\nplt.imshow(PADDING[0,:,:,0], cmap=\"gray\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:44.898209Z","iopub.execute_input":"2021-06-20T14:16:44.898604Z","iopub.status.idle":"2021-06-20T14:16:47.974731Z","shell.execute_reply.started":"2021-06-20T14:16:44.898548Z","shell.execute_reply":"2021-06-20T14:16:47.973625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert V1-like images to Dataset (not used)","metadata":{"id":"BfxpuSZaTW7q"}},{"cell_type":"code","source":"class NumpyDirectoryGeneratorSequence(Sequence):\n    def __init__(self, dct_label, dtype='.npy', randomize=True, random_seed=1331, validation_split=None, is_validation=False, batch_size=32):\n        self.directories = dct_label\n        self.dtype = dtype\n        self.randomize = randomize\n        self.seed = random_seed\n        self.validation_split = validation_split\n        self.is_validation = is_validation\n        self.batch_size = batch_size\n        self.x = self.y = None\n        self._create_files()\n        \n    def _create_files(self):\n        files = []\n        for directory,label in self.directories.items():\n            files += [(directory+ ('' if directory[-1] == '/' else '/') +i, label) \n                           for i in os.listdir(directory) \n                           if re.findall(self.dtype, i)]\n        if self.randomize:\n            seed(self.seed)\n            shuffle(files)\n        if self.validation_split:\n            if self.is_validation:\n                files = files[floor(len(files) - len(files)*self.validation_split):]\n            else:\n                files = files[:floor(len(files) - len(files)*self.validation_split)]\n                \n        self.x, self.y = zip(*files)\n        self.y = np.array(self.y)\n    \n    def __len__(self):\n        return ceil(self.y.shape[0] / self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch_x_pre, batch_y = self.x[idx * self.batch_size:(idx + 1) * self.batch_size], self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_x = [np.load(file) for file in batch_x_pre]\n        return np.array(batch_x), batch_y","metadata":{"id":"9DltOM6MTW7q","execution":{"iopub.status.busy":"2021-06-20T14:16:47.976658Z","iopub.execute_input":"2021-06-20T14:16:47.977063Z","iopub.status.idle":"2021-06-20T14:16:47.994963Z","shell.execute_reply.started":"2021-06-20T14:16:47.977022Z","shell.execute_reply":"2021-06-20T14:16:47.993399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NumpyDirectoryGenerator:\n    def __init__(self, dct_label, dtype='.npy', randomize=True, random_seed=1331, validation_split=None, is_validation=False):\n        self.directories = dct_label\n        self.dtype = dtype\n        self.files = []\n        self.randomize = randomize\n        self.seed = random_seed\n        self.validation_split = validation_split\n        self.is_validation = is_validation\n        self._create_files()\n        \n    def _create_files(self):\n        for directory,label in self.directories.items():\n            self.files += [(directory+ ('' if directory[-1] == '/' else '/') +i, label) \n                           for i in os.listdir(directory) \n                           if re.findall(self.dtype, i)]\n        if self.randomize:\n            seed(self.seed)\n            shuffle(self.files)\n        if self.validation_split:\n            if self.is_validation:\n                self.files = self.files[floor(len(self.files) - len(self.files)*self.validation_split):]\n            else:\n                self.files = self.files[:floor(len(self.files) - len(self.files)*self.validation_split)]\n    \n    def __call__(self):\n        return iter(self)\n    \n    def __iter__(self):\n        for file, label in self.files:\n            with open(file, 'rb') as data:\n                yield (np.load(data), label)","metadata":{"id":"aUiYsLfUTW7q","execution":{"iopub.status.busy":"2021-06-20T14:16:47.99705Z","iopub.execute_input":"2021-06-20T14:16:47.997728Z","iopub.status.idle":"2021-06-20T14:16:48.016003Z","shell.execute_reply.started":"2021-06-20T14:16:47.997683Z","shell.execute_reply":"2021-06-20T14:16:48.014872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Microsaccades (not used)\nAfter preprocessing, the model will use a 3d convolutional layer with 1278 filters (that will be the input vector for a synapse) that slices the image to 256 blocks. Each one of these blocks will represent one ms, but in order to keep the \"eyesight\" none-linear, the vectors are reorganized in an order that represents microsaccades.\nThe following functions define the blocks order.","metadata":{"id":"a8SjOfLjTW7q"}},{"cell_type":"code","source":"def saccades_per1ms(shape, noise_mult=0, radius=0, radial_q=0, return_values_and_grades=False):\n    \"\"\"creates a new order, supposed to be simulating microsaccades but i didn't really check how they work\"\"\"\n    m, n = shape\n    size = m * n\n    center = np.array([m / 2, n / 2])-0.5 + np.mod(shape,2)*0.5\n    keys = np.arange(size)\n    if radius and radial_q:\n        keys = {(k, (i, j)): np.minimum((1-radial_q)*np.abs(np.sqrt(((np.array([i,j]) - center)**2).sum())-radius), \n                                        radial_q*np.sqrt(((np.array([i,j]) - center)**2).sum()))+np.random.rand(1)*noise_mult \n                for k, i, j in zip(keys, keys//m, np.mod(keys, m))}\n    else: \n        keys = {(k, (i, j)): np.abs(np.sqrt(((np.array([i,j]) - center)**2).sum())-radius)+np.random.rand(1)*noise_mult for k, i, j in zip(keys, keys//m, np.mod(keys, m))}\n\n    sort = sorted(keys.keys(), key=lambda x: keys[x])\n    sorted_lst = [i[0] for i in sort]\n    if not return_values_and_grades: return sorted_lst\n    as_array = np.zeros((m,n))\n    for k in range(len(sort)):\n        curr_i, curr_j = sort[k][1]\n        as_array[curr_i, curr_j] = k\n    return keys, as_array, sorted_lst","metadata":{"id":"ggFzX5NqTW7r","executionInfo":{"status":"ok","timestamp":1608818551233,"user_tz":-120,"elapsed":787,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:48.017197Z","iopub.execute_input":"2021-06-20T14:16:48.018722Z","iopub.status.idle":"2021-06-20T14:16:48.038446Z","shell.execute_reply.started":"2021-06-20T14:16:48.018669Z","shell.execute_reply":"2021-06-20T14:16:48.037745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = n = 8\nnoise_mult = 0.2\n\nvalue, grading, SACCADES_ORDER = saccades_per1ms((m,n), noise_mult, 6, radial_q=.1, return_values_and_grades=True)\nplt.figure(figsize=(8, 8))\ngrades = np.zeros((m,n))\nfor key, grade in value.items():\n    grades[key[1][0], key[1][1]] = grade\nplt.imshow(grades, cmap='gray')\nfor i in range(m):\n    for j in range(n):\n        text = plt.text(j, i, int(grading[i, j]), ha=\"center\", va=\"center\", color=\"w\")","metadata":{"id":"70osoZH3TW7r","executionInfo":{"status":"ok","timestamp":1608818579285,"user_tz":-120,"elapsed":1022,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"eb0e716d-9b5f-427b-e1ed-e381aee292be","execution":{"iopub.status.busy":"2021-06-20T14:16:48.040939Z","iopub.execute_input":"2021-06-20T14:16:48.041245Z","iopub.status.idle":"2021-06-20T14:16:48.381978Z","shell.execute_reply.started":"2021-06-20T14:16:48.04121Z","shell.execute_reply":"2021-06-20T14:16:48.381028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def saccades_blocks(shape, noise_mult=0, small_mult=0, rows=2, cols=2, radius=0, radial_q=0, return_values_and_grades=False):\n    arr = saccades_per1ms((m//rows, n//cols), noise_mult, radius, radial_q, True)[1]\n    small_arr = saccades_per1ms((rows, cols), small_mult, radius, radial_q, return_values_and_grades=True)[1]\n    size = m * n\n    keys = np.arange(size).reshape(shape)\n    sorted_dct = {}\n    for row in range(arr.shape[0]):\n        for col in range(arr.shape[1]):\n            value = arr[row, col]\n            k = 0\n            for subrow in range(rows):\n                for subcol in range(cols):\n                    sorted_dct[keys[rows*row+subrow, cols*col+subcol]] = rows*cols*value + small_arr[subrow, subcol]\n                    k += 1\n            keys[rows*row: rows*row +rows, cols*col: cols*col +cols] = rows*cols*value + small_arr\n    if not len(sorted_dct) == size: print(\"PROBLEM!\")\n    sorted_by_value = sorted(sorted_dct.keys(), key=lambda x: sorted_dct[x])\n    if not return_values_and_grades: return sorted_by_value\n    else:\n        return keys, sorted_by_value, arr, small_arr","metadata":{"id":"xuNHTYBrTW7r","executionInfo":{"status":"ok","timestamp":1608818552499,"user_tz":-120,"elapsed":2038,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:48.38397Z","iopub.execute_input":"2021-06-20T14:16:48.384404Z","iopub.status.idle":"2021-06-20T14:16:48.400456Z","shell.execute_reply.started":"2021-06-20T14:16:48.384356Z","shell.execute_reply":"2021-06-20T14:16:48.399307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show how the microsaccades look. The ints are the order, and the paint is the grade the order is decided by. the noise_mult can control how much the order is centered (the higher it is, the noisier it gets).","metadata":{"id":"W2rqj653TW7r"}},{"cell_type":"code","source":"m = n = 16\nnoise_mult = 0.6\nsmall_noise_mult = 1\n\nto_plot, SACCADES_ORDER, bigarr, smallarr = saccades_blocks((m,n), noise_mult, small_noise_mult, rows=2, cols=2, radius=3, radial_q=0.4, return_values_and_grades=True)\n_, (ax0, ax1, ax2) = plt.subplots(3,1, figsize=(20, 20), gridspec_kw={'height_ratios': [4,2,20]})\nax0.imshow(bigarr, cmap='gray')\nax1.imshow(smallarr, cmap='gray')\nax2.imshow(to_plot, cmap='gray')\nfor i in range(m):\n    for j in range(n):\n        text = ax2.text(j, i, int(to_plot[i, j]), ha=\"center\", va=\"center\", color=\"w\")\nplt.show()","metadata":{"id":"xigOtCo4TW7r","executionInfo":{"status":"ok","timestamp":1608818553606,"user_tz":-120,"elapsed":3137,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"5d26f077-c370-4d7e-9b92-d4aab943529d","execution":{"iopub.status.busy":"2021-06-20T14:16:48.402607Z","iopub.execute_input":"2021-06-20T14:16:48.403005Z","iopub.status.idle":"2021-06-20T14:16:49.493859Z","shell.execute_reply.started":"2021-06-20T14:16:48.402963Z","shell.execute_reply":"2021-06-20T14:16:49.492581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"ruv8yAnaTW7r"}},{"cell_type":"code","source":"def data_augmentation(rotate=0.1):\n    return tf.keras.Sequential([layers.experimental.preprocessing.RandomFlip(\"horizontal\"), \n                                layers.experimental.preprocessing.RandomRotation(0.075)])","metadata":{"id":"mMZLEv0WTW7t","executionInfo":{"status":"ok","timestamp":1608812589207,"user_tz":-120,"elapsed":627,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:49.495808Z","iopub.execute_input":"2021-06-20T14:16:49.496352Z","iopub.status.idle":"2021-06-20T14:16:49.502809Z","shell.execute_reply.started":"2021-06-20T14:16:49.496311Z","shell.execute_reply":"2021-06-20T14:16:49.501635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 10))\nfor _, (images, labels) in enumerate(train_ds.take(1)):\n    augmented = data_augmentation()(images)\n    for i in range(9):\n        plt.subplot(2, 9, i + 1)\n        plt.imshow(images[i,:,:,0], cmap='gray')\n        plt.title(LABELS[int(labels[i])])\n        plt.axis(\"off\")\n        \n        plt.subplot(2, 9, 9 + i + 1)\n        plt.imshow(augmented[i,:,:,0], cmap='gray')\n        plt.title(\"Augmented \" + LABELS[int(labels[i])])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:49.504656Z","iopub.execute_input":"2021-06-20T14:16:49.505132Z","iopub.status.idle":"2021-06-20T14:16:51.122394Z","shell.execute_reply.started":"2021-06-20T14:16:49.505092Z","shell.execute_reply":"2021-06-20T14:16:51.121488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BenchMark","metadata":{"id":"9h8n0iKWXifH"}},{"cell_type":"code","source":"def benchmark(depth=1, width=32, augment=True, optimizer=Nadam(5e-3), l2_reg=1e-3):\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    # x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)\n    for d in range(depth):\n      x = layers.Dense(units=width, activation='linear', kernel_regularizer=keras.regularizers.l2(l2_reg), name='FC_layer_%d' %(d + 1))(x)\n      x = layers.LeakyReLU(alpha=0.3, name='LReLU_%d' %(d + 1))(x)\n      x = layers.BatchNormalization(name='BN_layer_%d' %(d + 1))(x)\n    output = layers.Dense(1, activation='sigmoid', name='logits')(x)\n    model = keras.Model(inp, output)\n    model.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=keras.metrics.BinaryAccuracy())\n    return model","metadata":{"id":"jeF933XjXq4w","executionInfo":{"status":"ok","timestamp":1608794472627,"user_tz":-120,"elapsed":1086,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:51.124143Z","iopub.execute_input":"2021-06-20T14:16:51.124516Z","iopub.status.idle":"2021-06-20T14:16:51.138744Z","shell.execute_reply.started":"2021-06-20T14:16:51.124476Z","shell.execute_reply":"2021-06-20T14:16:51.137501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bench = benchmark(width=2, depth=1, optimizer=Nadam(1e-3), augment=False)\n# bench.summary()","metadata":{"id":"acpEK0ZRY6Ib","executionInfo":{"status":"ok","timestamp":1608795038229,"user_tz":-120,"elapsed":626,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"f10076de-be8a-4b98-e69f-a28b8e1ee2d6","execution":{"iopub.status.busy":"2021-06-20T14:16:51.140529Z","iopub.execute_input":"2021-06-20T14:16:51.140948Z","iopub.status.idle":"2021-06-20T14:16:51.148751Z","shell.execute_reply.started":"2021-06-20T14:16:51.140909Z","shell.execute_reply":"2021-06-20T14:16:51.14807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bench.fit(train_ds, epochs=3, validation_data=valid_ds)","metadata":{"id":"HbC_-hMkoQDN","executionInfo":{"status":"ok","timestamp":1608795702852,"user_tz":-120,"elapsed":662564,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"84709d95-511e-45b6-ed99-fc79345621c0","execution":{"iopub.status.busy":"2021-06-20T14:16:51.150283Z","iopub.execute_input":"2021-06-20T14:16:51.150739Z","iopub.status.idle":"2021-06-20T14:16:51.159026Z","shell.execute_reply.started":"2021-06-20T14:16:51.150702Z","shell.execute_reply":"2021-06-20T14:16:51.158115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archives = {}\n# for depth in (1,2,3):\n#   archives[depth] = {}\n#   for width in [1,2,4,8,16]:\n#     archives[depth][width] = set()\n#     for _ in range(3):\n#       bench = benchmark(depth=depth, width=width, optimizer=Nadam(1e-3), augment=True)\n#       archives[depth][width].add(bench.fit(train_ds, epochs=12, validation_data=valid_ds))","metadata":{"id":"l87OHyMlYsxC","outputId":"e4a9fee2-a3f9-4d72-b5c2-f42ded470b7e","execution":{"iopub.status.busy":"2021-06-20T14:16:51.160579Z","iopub.execute_input":"2021-06-20T14:16:51.161048Z","iopub.status.idle":"2021-06-20T14:16:51.168437Z","shell.execute_reply.started":"2021-06-20T14:16:51.161008Z","shell.execute_reply":"2021-06-20T14:16:51.167609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pickle.dump(archives, open('benchmark_archives.pickle', \"wb\"))","metadata":{"id":"h48qiqkEgSAz","execution":{"iopub.status.busy":"2021-06-20T14:16:51.170054Z","iopub.execute_input":"2021-06-20T14:16:51.170469Z","iopub.status.idle":"2021-06-20T14:16:51.178668Z","shell.execute_reply.started":"2021-06-20T14:16:51.170431Z","shell.execute_reply":"2021-06-20T14:16:51.177878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_dct = {nLayer: {nDepth: np.mean([np.mean(i[-3]) for i in nDepthValue]) for nDepth, nDepthValue in depths.items()} for nLayer, depths in archives.items()}","metadata":{"id":"qv2w5_JAeKl5","execution":{"iopub.status.busy":"2021-06-20T14:16:51.179897Z","iopub.execute_input":"2021-06-20T14:16:51.180448Z","iopub.status.idle":"2021-06-20T14:16:51.188755Z","shell.execute_reply.started":"2021-06-20T14:16:51.180418Z","shell.execute_reply":"2021-06-20T14:16:51.187825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_archives_df = pandas.DataFrame.from_dict(archives[1])\n# for i in (2,3):\n#   mean_archives_df.append(pandas.DataFrame.from_dict(archives[i]))\n# mean_archives_df","metadata":{"id":"AyKOIvqgd_Fa","execution":{"iopub.status.busy":"2021-06-20T14:16:51.192043Z","iopub.execute_input":"2021-06-20T14:16:51.19238Z","iopub.status.idle":"2021-06-20T14:16:51.201956Z","shell.execute_reply.started":"2021-06-20T14:16:51.192352Z","shell.execute_reply":"2021-06-20T14:16:51.200925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_dct = {nLayer: {nDepth: np.max([i[-1] for i in nDepthValue]) for nDepth, nDepthValue in depths.items()} for nLayer, depths in archives.items()}","metadata":{"id":"mjxb7s72hfwh","execution":{"iopub.status.busy":"2021-06-20T14:16:51.203949Z","iopub.execute_input":"2021-06-20T14:16:51.204262Z","iopub.status.idle":"2021-06-20T14:16:51.211422Z","shell.execute_reply.started":"2021-06-20T14:16:51.204235Z","shell.execute_reply":"2021-06-20T14:16:51.210499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_archives_df = pandas.DataFrame.from_dict(archives[1])\n# for i in (2,3):\n#   best_archives_df.append(pandas.DataFrame.from_dict(archives[i]))\n# best_archives_df","metadata":{"id":"MFD56qcUhl97","execution":{"iopub.status.busy":"2021-06-20T14:16:51.212568Z","iopub.execute_input":"2021-06-20T14:16:51.213086Z","iopub.status.idle":"2021-06-20T14:16:51.221319Z","shell.execute_reply.started":"2021-06-20T14:16:51.213054Z","shell.execute_reply":"2021-06-20T14:16:51.220637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for depth in (1,2,3):\n#   curDepth = archives[depth]\n#   for width in [1,2,4,8,16]:\n#     archives[depth][width] = set()","metadata":{"id":"mh6AvL6jdM2Y","execution":{"iopub.status.busy":"2021-06-20T14:16:51.222992Z","iopub.execute_input":"2021-06-20T14:16:51.223854Z","iopub.status.idle":"2021-06-20T14:16:51.231899Z","shell.execute_reply.started":"2021-06-20T14:16:51.223811Z","shell.execute_reply":"2021-06-20T14:16:51.231189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i, col in zip(range(3), ('b', 'r', 'g')):\n#   for history, boolean in zip(archives[i+1], (True, False, False)):\n#     if boolean:\n#       plt.plot(np.arange(50), history.history['val_binary_accuracy'], color=col, label=f\"nLayers={i+1}\")\n#     else:\n#       plt.plot(np.arange(50), history.history['val_binary_accuracy'], color=col)\n# plt.ylim(0,1)\n# plt.legend()\n# plt.show()","metadata":{"id":"3JiL3f9h-jiy","executionInfo":{"elapsed":650,"status":"ok","timestamp":1608316755301,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"},"user_tz":-120},"outputId":"d581d4e0-5a77-4387-db0e-9498dd3f1432","execution":{"iopub.status.busy":"2021-06-20T14:16:51.232781Z","iopub.execute_input":"2021-06-20T14:16:51.233834Z","iopub.status.idle":"2021-06-20T14:16:51.24213Z","shell.execute_reply.started":"2021-06-20T14:16:51.233Z","shell.execute_reply":"2021-06-20T14:16:51.241253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess + Conv3D + Nx(Conv2D + MaxPooling2D) + Dense","metadata":{"id":"0IlHFu7XTW7s"}},{"cell_type":"markdown","source":"using SGD - learn","metadata":{"id":"XiK7SiI-TW7s"}},{"cell_type":"code","source":"def pre_conv3d_conv2d_max_dense(lr, n_conv):\n    inp = keras.Input(shape=(256,256,1))\n    x = processor(inp)\n    x = layers.Conv2D(32, 3, activation='relu', strides=(3,3))(x)\n    x = layers.BatchNormalization()(x)\n    for _ in range(n_conv):\n        x = layers.Conv2D(32, 3, activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.MaxPooling2D((2,2))(x)\n    x = layers.Flatten()(x)\n#     x = layers.Conv3D(1278, (16,16,8), activation='sigmoid', strides=(16,16,8))(x)\n#     x = conv_to_neuron_input(x, 400, saccades)\n#     x = layers.Flatten()(x)\n    output = layers.Dense(1, activation='sigmoid')(x)\n    model = keras.Model(inp, output)\n    model.compile(optimizer=SGD(lr=lr), loss=MeanSquaredError(), metrics=keras.metrics.BinaryAccuracy())\n    # model_gabor = keras.Model(inp, [output, spikes_per_ml])\n    return model","metadata":{"id":"LdQHMvnhTW7s","execution":{"iopub.status.busy":"2021-06-20T14:16:51.243795Z","iopub.execute_input":"2021-06-20T14:16:51.24442Z","iopub.status.idle":"2021-06-20T14:16:51.256144Z","shell.execute_reply.started":"2021-06-20T14:16:51.244378Z","shell.execute_reply":"2021-06-20T14:16:51.255413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One Conv2D - learns","metadata":{"id":"Bzc_wz7DTW7s"}},{"cell_type":"code","source":"def preprocess_linear(lr, loss_func=SGD):\n    inp = keras.Input(shape=(256,256,1))\n    x = processor(inp)\n    x = layers.Flatten()(x)\n#     x = layers.Conv3D(1278, (16,16,8), activation='sigmoid', strides=(16,16,8))(x)\n#     x = conv_to_neuron_input(x, 400, saccades)\n#     x = layers.Flatten()(x)\n    output = layers.Dense(1, activation='sigmoid')(x)\n    model = keras.Model(inp, output)\n    model.compile(optimizer=loss_func(lr=lr), loss=MeanSquaredError(), metrics=keras.metrics.BinaryAccuracy())\n    # model_gabor = keras.Model(inp, [output, spikes_per_ml])\n    return model","metadata":{"id":"gugnFXItTW7s","execution":{"iopub.status.busy":"2021-06-20T14:16:51.25767Z","iopub.execute_input":"2021-06-20T14:16:51.258303Z","iopub.status.idle":"2021-06-20T14:16:51.267055Z","shell.execute_reply.started":"2021-06-20T14:16:51.25826Z","shell.execute_reply":"2021-06-20T14:16:51.266174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dense Initializer","metadata":{"id":"8mTYjTrMPnJV"}},{"cell_type":"code","source":"FULL = 400\ndef block_initializer(*windows):\n    rate = sum([j-i for i,j in windows])\n    def block(shape, dtype=None):\n        weights = np.zeros(FULL)\n        for i,j in windows:\n            weights[i:j] = 1 / (rate)\n        plt.plot(weights, label=\"spikes wanted\")\n        return weights[:,np.newaxis]\n    return block","metadata":{"id":"OPLDjL8WffeZ","executionInfo":{"status":"ok","timestamp":1608812593571,"user_tz":-120,"elapsed":609,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:51.268718Z","iopub.execute_input":"2021-06-20T14:16:51.269129Z","iopub.status.idle":"2021-06-20T14:16:51.278511Z","shell.execute_reply.started":"2021-06-20T14:16:51.269079Z","shell.execute_reply":"2021-06-20T14:16:51.277504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FULL = 400\ndef block_initializer(*windows):\n    rate = sum([j-i for i,j in windows])\n    def block(shape, dtype=None):\n        weights = np.zeros(FULL)\n        for i,j in windows:\n            weights[i:j] = 1/np.sqrt(2*np.pi)*np.exp(-0.5*(np.arange(i-(i+j)//2,j-(i+j)//2) / (j-i)*1.5)**2) / len(windows)\n        weights = weights / sum(weights)\n        plt.plot(weights, label=\"spikes wanted\")\n        return weights[:,np.newaxis]\n    return block","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.280082Z","iopub.execute_input":"2021-06-20T14:16:51.280563Z","iopub.status.idle":"2021-06-20T14:16:51.290743Z","shell.execute_reply.started":"2021-06-20T14:16:51.280524Z","shell.execute_reply":"2021-06-20T14:16:51.2898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bloop = block_initializer((250,280), (200, 230))(1)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.292033Z","iopub.execute_input":"2021-06-20T14:16:51.292569Z","iopub.status.idle":"2021-06-20T14:16:51.443216Z","shell.execute_reply.started":"2021-06-20T14:16:51.292527Z","shell.execute_reply":"2021-06-20T14:16:51.442318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dense_initializer_AP(cycle_time, full=400, sin_intializer=False, calc_init=False, norm_calc=False):\n    times = full // cycle_time\n    starting_time = full % cycle_time\n    def sinus_initializer(shape, dtype=None):\n        actual = (np.sin(np.arange(0,cycle_time*(times))*2*np.pi/cycle_time + np.pi) + 1) / times\n        padding = np.zeros(starting_time)\n        weights = np.concatenate([padding, actual])\n        return weights[:,np.newaxis]\n    def calcium_initializer(shape, dtype=None):\n        weights = np.zeros(full)\n        weights[starting_time:starting_time+3*cycle_time] = (np.sin(np.arange(0,3*cycle_time)*2/3*np.pi/cycle_time-np.pi/2)+1) / np.pi#cycle_time * 10\n        return weights[:, np.newaxis]\n    def normal_calcium(shape, dtype=None):\n        sigma = cycle_time\n        weights =  1/np.sqrt(2*np.pi)*np.exp(-((np.arange(full) - (starting_time + cycle_time)) / sigma)**2 * 0.5)\n        return weights[:, np.newaxis]\n    return sinus_initializer if sin_intializer else calcium_initializer if calc_init else normal_calcium","metadata":{"id":"F-xW-psVr02i","executionInfo":{"status":"ok","timestamp":1608812594989,"user_tz":-120,"elapsed":705,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:51.444885Z","iopub.execute_input":"2021-06-20T14:16:51.445447Z","iopub.status.idle":"2021-06-20T14:16:51.459781Z","shell.execute_reply.started":"2021-06-20T14:16:51.445405Z","shell.execute_reply":"2021-06-20T14:16:51.45887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.arange(400), dense_initializer_AP(32, calc_init=True)(1), color='b', label=\"calcium spike initializer\")\nplt.plot(np.arange(400), dense_initializer_AP(32, sin_intializer=True)(1),  color='r', label=\"pulses initializer\")\nplt.plot(np.arange(400), dense_initializer_AP(32)(1), color='g', label=\"normal calcium initializater\")\nplt.plot(np.arange(400), block_initializer((250,280), (200, 230))(1), color='k', label=\"block\")\nplt.ylim(0,1)\nplt.legend()\nplt.show()","metadata":{"id":"K1AJHukIuOtQ","executionInfo":{"status":"ok","timestamp":1608812595344,"user_tz":-120,"elapsed":706,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"d3889853-c47d-4dba-8b4e-f1ea11a295b2","execution":{"iopub.status.busy":"2021-06-20T14:16:51.462213Z","iopub.execute_input":"2021-06-20T14:16:51.462901Z","iopub.status.idle":"2021-06-20T14:16:51.643259Z","shell.execute_reply.started":"2021-06-20T14:16:51.462858Z","shell.execute_reply":"2021-06-20T14:16:51.64223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Previous Modules and Funcs","metadata":{"id":"p2KcGLNGTW7s"}},{"cell_type":"code","source":"def identity_init_1d_conv_layer(shape, dtype=None):\n    if shape[0] != 1:\n        raise ValueError('Can only be used with keranel size of 1')\n    if shape[1] != shape[2]:\n        raise ValueError('Can only be used with same number of filters for input and output')\n\n    return np.identity(shape[1])[np.newaxis]","metadata":{"id":"GkHtEF0bFJk1","executionInfo":{"status":"ok","timestamp":1608812606376,"user_tz":-120,"elapsed":512,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:51.644908Z","iopub.execute_input":"2021-06-20T14:16:51.645326Z","iopub.status.idle":"2021-06-20T14:16:51.651397Z","shell.execute_reply.started":"2021-06-20T14:16:51.645288Z","shell.execute_reply":"2021-06-20T14:16:51.650186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def playable(saccades=None, xaxis=False, use_sigmoid=True, sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n             useSynapse=False, qSynapse=0.2, augment=False, nSynapse=50, optimizer=SGD, conv_shape=(16,16)):\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    conv_shape = (1,x.shape[2]) if xaxis else conv_shape\n    x = layers.Conv2D(1278, conv_shape, strides=conv_shape, activity_regularizer=pre_synaptic_spike_regularization)(x)\n    x = layers.BatchNormalization()(x)\n    x = sigmoid(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, use_sigmoid=use_sigmoid, mult=sigmoid_mult, name='Neuron_Input_Bool')(x)  # only in validation and test\n    if useSynapse:\n        nSynapsesPerMS = SpikeProcessor(nSynapse, name='nSynapses')(x)\n#     x= layers.UpSampling()\n    x = ToNeuronInput(400, saccades, name=\"NeuronInput\")(x)\n    x = L5PC_model(x)   # run through david's model\n    \n    x = layers.Flatten()(x)\n    if to_bool:\n        x = ToBoolLayer(threshold=0.1, use_sigmoid=False, name='postNeuronBool')(x)  # only in validation and test\n    output = layers.Dense(1, activation='sigmoid', name='postNeuron')(x)\n    if useSynapse:\n        model = keras.Model(inp, [output, nSynapsesPerMS])\n        model.compile(optimizer=optimizer, loss={'postNeuron': MeanSquaredError(), 'nSynapses': loss_for_me}, \n                      metrics={'postNeuron': keras.metrics.BinaryAccuracy()}, loss_weights=[1-qSynapse, qSynapse])\n    else:\n        model = keras.Model(inp, output)#, output_after_sigmoid, output_train])\n        model.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=keras.metrics.BinaryAccuracy())\n    return model","metadata":{"id":"MLK0umP4TW7t","executionInfo":{"status":"ok","timestamp":1608812607318,"user_tz":-120,"elapsed":731,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:51.653027Z","iopub.execute_input":"2021-06-20T14:16:51.653436Z","iopub.status.idle":"2021-06-20T14:16:51.670561Z","shell.execute_reply.started":"2021-06-20T14:16:51.653375Z","shell.execute_reply":"2021-06-20T14:16:51.669469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1_reg = 1e-7\nl2_reg = 1e-6","metadata":{"id":"7hMzwK-CEuto","executionInfo":{"status":"ok","timestamp":1608812610800,"user_tz":-120,"elapsed":615,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:51.672208Z","iopub.execute_input":"2021-06-20T14:16:51.672724Z","iopub.status.idle":"2021-06-20T14:16:51.682683Z","shell.execute_reply.started":"2021-06-20T14:16:51.672683Z","shell.execute_reply":"2021-06-20T14:16:51.68178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def playable_initialized_dense(saccades=None, xaxis=False, use_sigmoid=True, \n                       sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n                       useSynapse=False, qSynapse=0.2, augment=False, \n                       nSynapse=50, optimizer=SGD(5e-3), conv_shape=(16,16),\n                       dense_init=block_initializer):\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    # x = layers.BatchNormalization()(x)\n    conv_shape = (1,x.shape[2]) if xaxis else conv_shape\n    x = layers.Conv2D(1278, conv_shape, strides=conv_shape,\n                      activity_regularizer=pre_synaptic_spike_regularization, name=\"WiringLayer\")(x)\n    x = layers.BatchNormalization()(x)\n    x = sigmoid(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(x)\n    if useSynapse:\n        nSynapsesPerMS = SpikeProcessor(nSynapse, name='nSynapses')(x)\n    one_cycle = 200//x.shape[1]\n    full_time = one_cycle*x.shape[1]\n\n    x = ToNeuronInput(400, new_order=saccades, name=\"NeuronInput\", padding=NOISE)(x)\n    x = L5PC_model(x)   # run through david's model\n    \n    x = layers.Flatten()(x)\n    if to_bool:\n        x = ToBoolLayer(threshold=0.2, use_sigmoid=False, mult=25, name='postNeuronBool')(x)  # only in validation and test\n    \n    output = layers.Dense(1, \n                          kernel_initializer=dense_init(start=400-full_time, end=400), \n                          bias_initializer=lambda shape, dtype: np.array([0.]), \n                          trainable=False,\n                          name=\"nSpikes\")(x)\n\n    if useSynapse:\n        model = keras.Model(inp, [output, nSynapsesPerMS])\n        model.compile(optimizer=optimizer, \n                      loss={'nSpikes': MeanSquaredError(), 'nSynapses': MeanSquaredErrorSynapsesPerMS()}, \n                      metrics={'nSpikes': keras.metrics.BinaryAccuracy()}, \n                      loss_weights=[1-qSynapse, qSynapse])\n    else:\n        model = keras.Model(inp, output)#, output_after_sigmoid, output_train])\n        model.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=keras.metrics.BinaryAccuracy())\n    return model","metadata":{"id":"NDEDHImAumbA","executionInfo":{"status":"ok","timestamp":1608812611084,"user_tz":-120,"elapsed":501,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T14:16:51.686128Z","iopub.execute_input":"2021-06-20T14:16:51.686433Z","iopub.status.idle":"2021-06-20T14:16:51.706486Z","shell.execute_reply.started":"2021-06-20T14:16:51.686405Z","shell.execute_reply":"2021-06-20T14:16:51.705536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def playable_dense(saccades=None, xaxis=False, use_sigmoid=True, \n                       sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n                       useSynapse=False, qSynapse=0.2, augment=False, \n                       nSynapse=50, optimizer=SGD(5e-3), conv_shape=(16,16),\n                       dense_init=block_initializer):\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    # x = layers.BatchNormalization()(x)\n    conv_shape = (1,x.shape[2]) if xaxis else conv_shape\n    x = layers.Conv2D(1278, conv_shape, strides=conv_shape,\n                      activity_regularizer=pre_synaptic_spike_regularization, name=\"WiringLayer\")(x)\n    x = layers.BatchNormalization()(x)\n    x = sigmoid(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(x)\n    if useSynapse:\n        nSynapsesPerMS = SpikeProcessor(nSynapse, name='nSynapses')(x)\n    one_cycle = 400//x.shape[1]\n    full_time = once_cycle*x.shape[1]\n\n    x = ToNeuronInput(400, new_order=saccades, name=\"NeuronInput\", padding=NOISE)(x)\n    x = L5PC_model(x)   # run through david's model\n    \n    x = layers.Flatten()(x)\n    if to_bool:\n        x = ToBoolLayer(threshold=0.2, use_sigmoid=False, mult=25, name='postNeuronBool')(x)  # only in validation and test\n    \n    output = layers.Dense(1, name=\"nSpikes\")(x[:, -full_time:])\n\n    if useSynapse:\n        model = keras.Model(inp, [output, nSynapsesPerMS])\n        model.compile(optimizer=optimizer, \n                      loss={'nSpikes': MeanSquaredError(), 'nSynapses': MeanSquaredErrorSynapsesPerMS()}, \n                      metrics={'nSpikes': keras.metrics.BinaryAccuracy()}, \n                      loss_weights=[1-qSynapse, qSynapse])\n    else:\n        model = keras.Model(inp, output)#, output_after_sigmoid, output_train])\n        model.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=keras.metrics.BinaryAccuracy())\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.707933Z","iopub.execute_input":"2021-06-20T14:16:51.708375Z","iopub.status.idle":"2021-06-20T14:16:51.727784Z","shell.execute_reply.started":"2021-06-20T14:16:51.708336Z","shell.execute_reply":"2021-06-20T14:16:51.726739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def around_spikes_loss(windows, r, full=400):\n    weights = np.zeros(full)\n    for start,end in windows:\n        weights[start-r:start] = 1\n        weights[end:end+r] = 1\n    for start,end in windows:\n        weights[start:end] = 0\n    weights = tens(weights[:,np.newaxis], dtype=tf.float32)\n    def loss(y_true, y_preds):\n        return mean_squared_error_synapses_per_ms(tf.matmul(y_preds, weights))\n    \n    def mean_squared_error_synapses_per_ms(y_preds):\n        squared_difference = tf.square(y_preds)\n        mean = tf.reduce_mean(squared_difference, axis=-1)\n        return mean\n    plt.plot(weights[:,0], label=\"silence wanted\")\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.729037Z","iopub.execute_input":"2021-06-20T14:16:51.72945Z","iopub.status.idle":"2021-06-20T14:16:51.741605Z","shell.execute_reply.started":"2021-06-20T14:16:51.729413Z","shell.execute_reply":"2021-06-20T14:16:51.740901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def different_nSynapses_initialized_dense(saccades=None, xaxis=False, use_sigmoid=True, \n                        sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, dropout=.2,\n                        excitatory_wanted=EXCITATORY_SYNAPSES_WANTED, inhibitory_wanted=INHIBITORY_SYNAPSES_WANTED,\n                        qSynapse=(0.1, 0.1), augment=False, \n                        optimizer=SGD(5e-3), conv_shape=(16,16),\n                        dense_init=block_initializer, spike_wanted = [(260,280)], loss_radius=20,\n                                          padding=PADDING):\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    # x = layers.BatchNormalization()(x)\n    conv_shape = (1,x.shape[2]) if xaxis else conv_shape\n    wiringLayer = layers.Conv2D(1278, conv_shape, strides=conv_shape,#kernel_constraint=keras.constraints.non_neg(),\n                      activity_regularizer=pre_synaptic_spike_regularization, name=\"WiringLayer\")\n    x = wiringLayer(x)\n    x = layers.BatchNormalization()(x)\n    x = sigmoid(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(x)\n    nExcitatorySynapsesPerMS = SpikeProcessor(excitatory_wanted, name='nExcitatory', end=639)(x)\n    nInhibitorySynapsesPerMS = SpikeProcessor(inhibitory_wanted, name='nInhibitory', start=639)(x)\n    cycle_time = x.shape[1]\n    cycles = 200//x.shape[1]\n    full_time = cycles*cycle_time\n    convertedPadding = wiringLayer(padding)\n    convertedPadding = layers.BatchNormalization()(convertedPadding)\n    convertedPadding = sigmoid(convertedPadding)\n    convertedPadding = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(convertedPadding)\n\n    x = ToNeuronInput(400, new_order=saccades, name=\"NeuronInput\", padding=convertedPadding)(x)\n    if dropout: layers.Dropout(dropout)(x)\n    x = L5PC_model(x)   # run through david's model\n    \n    x = layers.Flatten()(x)\n    if to_bool:\n        spike_train = ToBoolLayer(threshold=0.2, use_sigmoid=False, mult=25, name='SpikeTrain')(x)  # only in validation and test\n    \n    output = layers.Dense(1, \n                          kernel_initializer=dense_init(*spike_wanted), \n                          bias_initializer=lambda shape, dtype: np.array([0.]), \n                          trainable=False,\n                          name=\"nSpikes\")(x)\n    \n    model = keras.Model(inp, [output, spike_train, nExcitatorySynapsesPerMS, nInhibitorySynapsesPerMS])\n    model.compile(optimizer=optimizer, \n                  loss={'nSpikes': MeanSquaredError(), 'SpikeTrain': around_spikes_loss(spike_wanted, loss_radius), 'nExcitatory': MeanSquaredErrorSynapsesPerMS(), 'nInhibitory': MeanSquaredErrorSynapsesPerMS()}, \n                  metrics={'nSpikes': keras.metrics.BinaryAccuracy()}, \n                  loss_weights=[0.95-sum(qSynapse),0.05, *qSynapse])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.743393Z","iopub.execute_input":"2021-06-20T14:16:51.744033Z","iopub.status.idle":"2021-06-20T14:16:51.765275Z","shell.execute_reply.started":"2021-06-20T14:16:51.743976Z","shell.execute_reply":"2021-06-20T14:16:51.764448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def different_nSynapses(saccades=None, xaxis=False, use_sigmoid=True, \n                        sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n                        excitatory_wanted=EXCITATORY_SYNAPSES_WANTED, inhibitory_wanted=INHIBITORY_SYNAPSES_WANTED,\n                        qSynapse=(0.1, 0.1), augment=False, \n                        optimizer=SGD(5e-3), conv_shape=(16,16),\n                        dense_init=block_initializer, padding=PADDING):\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    # x = layers.BatchNormalization()(x)\n    conv_shape = (1,x.shape[2]) if xaxis else conv_shape\n    wiringLayer = layers.Conv2D(1278, conv_shape, strides=conv_shape,\n                      activity_regularizer=pre_synaptic_spike_regularization, name=\"WiringLayer\")\n    x = wiringLayer(x)\n    x = layers.BatchNormalization()(x)\n    x = sigmoid(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(x)\n    nExcitatorySynapsesPerMS = SpikeProcessor(excitatory_wanted, name='nExcitatory', end=639)(x)\n    nInhibitorySynapsesPerMS = SpikeProcessor(inhibitory_wanted, name='nInhibitory', start=639)(x)\n    one_cycle = 200//x.shape[1]\n    full_time = one_cycle*x.shape[1]\n    convertedPadding = wiringLayer(padding)\n    convertedPadding = layers.BatchNormalization()(convertedPadding)\n    convertedPadding = sigmoid(convertedPadding)\n    convertedPadding = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(convertedPadding)\n\n    x = ToNeuronInput(400, new_order=saccades, name=\"NeuronInput\", padding=convertedPadding)(x)\n    x = L5PC_model(x)   # run through david's model\n    \n    x = layers.Flatten()(x)\n    if to_bool:\n        x = ToBoolLayer(threshold=0.2, use_sigmoid=False, mult=25, name='postNeuronBool')(x)  # only in validation and test\n    \n    output = layers.Dense(1, name=\"nSpikes\")(x[:, -full_time:])\n\n    model = keras.Model(inp, [output, nExcitatorySynapsesPerMS, nInhibitorySynapsesPerMS])\n    model.compile(optimizer=optimizer, \n                  loss={'nSpikes': MeanSquaredError(), 'nExcitatory': MeanSquaredErrorSynapsesPerMS(), 'nInhibitory': MeanSquaredErrorSynapsesPerMS()}, \n                  metrics={'nSpikes': keras.metrics.BinaryAccuracy()}, \n                  loss_weights=[1-sum(qSynapse), *qSynapse])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.766782Z","iopub.execute_input":"2021-06-20T14:16:51.767218Z","iopub.status.idle":"2021-06-20T14:16:51.786798Z","shell.execute_reply.started":"2021-06-20T14:16:51.767102Z","shell.execute_reply":"2021-06-20T14:16:51.786061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def different_nSynapses_max_loss(window, saccades=None, xaxis=False, use_sigmoid=True, \n                        sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n                        excitatory_wanted=EXCITATORY_SYNAPSES_WANTED, inhibitory_wanted=INHIBITORY_SYNAPSES_WANTED,\n                        qSynapse=(0.1, 0.1), augment=False, \n                        optimizer=SGD(5e-3), conv_shape=(16,16),\n                        dense_init=block_initializer, padding=PADDING):\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    # x = layers.BatchNormalization()(x)\n    conv_shape = (1,x.shape[2]) if xaxis else conv_shape\n    wiringLayer = layers.Conv2D(1278, conv_shape, strides=conv_shape,\n                      activity_regularizer=pre_synaptic_spike_regularization, name=\"WiringLayer\")\n    x = wiringLayer(x)\n    x = layers.BatchNormalization()(x)\n    x = sigmoid(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(x)\n    nExcitatorySynapsesPerMS = SpikeProcessor(excitatory_wanted, name='nExcitatory', end=639)(x)\n    nInhibitorySynapsesPerMS = SpikeProcessor(inhibitory_wanted, name='nInhibitory', start=639)(x)\n    one_cycle = 200//x.shape[1]\n    full_time = one_cycle*x.shape[1]\n    convertedPadding = wiringLayer(padding)\n    convertedPadding = layers.BatchNormalization()(convertedPadding)\n    convertedPadding = sigmoid(convertedPadding)\n    convertedPadding = ToBoolLayer(threshold=sigmoid_threshold, \n                    use_sigmoid=use_sigmoid, \n                    mult=sigmoid_mult, \n                    name='preNeuronBool')(convertedPadding)\n\n    x = ToNeuronInput(400, new_order=saccades, name=\"NeuronInput\", padding=convertedPadding)(x)\n    x = L5PC_model(x)   # run through david's model\n    \n    output = layers.Flatten(name=\"SpikeTrain1\")(x)\n    if to_bool:\n        output = ToBoolLayer(threshold=0.2, use_sigmoid=True, mult=25, name='SpikeTrain')(output)  # only in validation and test\n    \n    model = keras.Model(inp, [output, nExcitatorySynapsesPerMS, nInhibitorySynapsesPerMS])\n    model.compile(optimizer=optimizer, \n                  loss={'SpikeTrain': max_loss(window), 'nExcitatory': MeanSquaredErrorSynapsesPerMS(), 'nInhibitory': MeanSquaredErrorSynapsesPerMS()}, \n                  metrics={'SpikeTrain': keras.metrics.BinaryAccuracy()}, \n                  loss_weights=[1-sum(qSynapse), *qSynapse])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.788225Z","iopub.execute_input":"2021-06-20T14:16:51.788665Z","iopub.status.idle":"2021-06-20T14:16:51.809199Z","shell.execute_reply.started":"2021-06-20T14:16:51.788624Z","shell.execute_reply":"2021-06-20T14:16:51.808222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def max_loss(windows, full=400):\n    \"\"\"not in use\"\"\"\n    weights = np.zeros(full)\n    for start,end in windows:\n        weights[start:end] = 1\n    weights = tens(weights, dtype=tf.float32)\n    def loss(y_true, y_preds):\n        loss_value =  (tf.cast(y_true, y_preds.dtype) - K.max(y_preds*weights, axis=-1))**2\n        return loss_value\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.810947Z","iopub.execute_input":"2021-06-20T14:16:51.812826Z","iopub.status.idle":"2021-06-20T14:16:51.821803Z","shell.execute_reply.started":"2021-06-20T14:16:51.812791Z","shell.execute_reply":"2021-06-20T14:16:51.820811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lowering Synapse loss Callback","metadata":{}},{"cell_type":"markdown","source":"# Pruning (not in use)","metadata":{}},{"cell_type":"code","source":"class SynapseLossDecay(keras.callbacks.Callback):\n    def __init__(self, alpha, beta, decay_alpha=.9, decay_beta=.9, low=.03):\n        super().__init__()\n        self.alpha = alpha\n        self.beta = beta\n        self.decay_alpha = decay_alpha\n        self.decay_beta = decay_beta\n        self.low = low\n\n#     @tf.autograph.experimental.do_not_convert\n    def on_epoch_end(self, batch, logs=None):\n        if self.alpha > 0:\n            if self.alpha < self.low: self.alpha = self.alpha * 0\n            else: self.alpha = self.alpha * self.decay_alpha\n        if self.beta > 0:\n            if self.beta < self.low: self.beta = self.beta * 0\n            else: self.beta = self.beta * self.decay_beta","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.823221Z","iopub.execute_input":"2021-06-20T14:16:51.823688Z","iopub.status.idle":"2021-06-20T14:16:51.834255Z","shell.execute_reply.started":"2021-06-20T14:16:51.823649Z","shell.execute_reply":"2021-06-20T14:16:51.833281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SynapsePruner(keras.callbacks.Callback):\n    def __init__(self, kmax1=5, kmax2=15, iterations=8, axis=-1, splitPoint = N_EXC, prune_layer=\"WiringLayer\"):\n        super().__init__()\n        self.kmax1 = kmax1\n        self.kmax2 = kmax2\n        self.iterations = iterations\n        self.curIterations = iterations\n        self.split = splitPoint\n        self.layer_to_prune = prune_layer\n        print(self)\n    \n    def __str__(self):\n        string = f\"\\nSynapsePruner callback:\\nkmax1 = {self.kmax1}\\n\"\n        string += f\"kmax2 = {self.kmax2}\\n\"\n        string += f\"every {self.iterations} iterations\"\n        return string\n        \n    def build(self, shape):\n        pass\n        \n#     @tf.autograph.experimental.do_not_convert\n    def on_train_batch_end(self, batch, logs=None):\n        if self.iterations:\n            if self.curIterations: self.curIterations -= 1\n            else:\n                self.prune()\n                self.curIterations = self.iterations\n\n    def prune(self):\n        layer = self.model.get_layer(self.layer_to_prune)\n        weights = layer.get_weights()\n        is_bias = len(weights) == 2\n        if is_bias: kernels, bias = layer.get_weights()\n        else: kernels = layer.get_weights()[0]\n        kernels = kernels[:, 0]\n        p1_x = kernels[:, :, :self.split]\n        p2_x = kernels[:, :, self.split:]\n        kmax1 = np.partition(p1_x, -self.kmax1, axis=-1)[:,:,-self.kmax1][:,:,np.newaxis]\n        kmax2 = np.partition(p2_x, -self.kmax2, axis=-1)[:,:,-self.kmax2][:,:,np.newaxis]\n\n\n        arr1 = (p1_x * (p1_x >= kmax1))\n        arr2 = (p2_x * (p2_x >= kmax2))\n        arr = np.concatenate([arr1, arr2], axis=-1)\n        arr = np.concatenate([arr1, arr2], axis=-1)\n        assert arr.shape == kernels.shape, tf.print(\"Oh no. something went wrong\")\n\n        layer.set_weights([arr[:, np.newaxis], bias] if is_bias else [arr[:, np.newaxis]])","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.835952Z","iopub.execute_input":"2021-06-20T14:16:51.836438Z","iopub.status.idle":"2021-06-20T14:16:51.856173Z","shell.execute_reply.started":"2021-06-20T14:16:51.836398Z","shell.execute_reply":"2021-06-20T14:16:51.855456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nFilters = 32\nnSyn = 10\nnPixels = 32  # coloumn\na_kmax1 = 1   # how many excitatory synapses per filter per pixel\na_kmax2 = 1   # how many inhibitory synapses per filter per pixel\n\n\nkernels = np.random.rand(nPixels*nFilters*nSyn).reshape((nPixels,nFilters,nSyn))\nsplat = nSyn //2\n\n# Split\np1_x = kernels[:, :, :splat]\np2_x = kernels[:, :, splat:]\n\n# find k-highest\nkmax1 = np.partition(p1_x, -a_kmax1,axis=-1)[:,:,-a_kmax1][:,:,np.newaxis]\nkmax2 = np.partition(p2_x, -a_kmax2,axis=-1)[:,:,-a_kmax2][:,:,np.newaxis]\n\n# Prune all lower\narr1 = (p1_x * (p1_x >= kmax1))\narr2 = (p2_x * (p2_x >= kmax2))\narr = np.concatenate([arr1, arr2], axis=-1)\n\n# Plot\nplt.figure(figsize=(50,10))\nfor i in range(nFilters):\n    plt.subplot(2,nFilters,i+1)\n    plt.title(f\"Filter {i}\")\n    plt.imshow(kernels[:,i,:], cmap=\"gray\")\n    plt.xlabel(\"Synapse\")\n    plt.ylabel(\"Pixel\")\n    plt.axvline(splat, color=\"r\", linestyle=\"--\")\n    \n    plt.subplot(2,nFilters,nFilters +i+1)\n    plt.title(f\"Pruned {i}\")\n    plt.imshow(arr[:,i,:], cmap=\"gray\")\n    plt.xlabel(\"Synapse\")\n    plt.ylabel(\"Pixel\")\n    plt.axvline(splat, color=\"r\", linestyle=\"--\")\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:51.85847Z","iopub.execute_input":"2021-06-20T14:16:51.859233Z","iopub.status.idle":"2021-06-20T14:16:59.228633Z","shell.execute_reply.started":"2021-06-20T14:16:51.859192Z","shell.execute_reply":"2021-06-20T14:16:59.227744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def printModule(dropout1, dropout2, sigmoid_threshold, sigmoid_mult, exWanted, inWanted, qSynapse, augment, synLoss):\n    print(\"~*~ Visual Module ~*~\")\n    if augment: print(f\"Images are augmented (rotated by {augment})\")\n    print(f\"Image Dropout Rate: {dropout1}\")\n    print(f\"Synapse Threshold: {sigmoid_threshold}\")\n    print(f\"Synapse Training Sigmoid Multiplication: {sigmoid_mult}\")\n    print(f\"Synapses Wanted: Exc-{exWanted}; Inh-{inWanted}; Sum-{exWanted+inWanted}\")\n    print(f\"Synapses Loss Rate: Exc-{qSynapse[0]}; Inh-{qSynapse[1]}\")\n    print(f\"Synapses Dropout Rate: {dropout2}\")\n    print(f\"Synapse Loss Function: {synLoss.__name__}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:59.230052Z","iopub.execute_input":"2021-06-20T14:16:59.230419Z","iopub.status.idle":"2021-06-20T14:16:59.237405Z","shell.execute_reply.started":"2021-06-20T14:16:59.230378Z","shell.execute_reply":"2021-06-20T14:16:59.236387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def different_nSynapses(saccades=None, xaxis=True, use_sigmoid=True, pruning=True, dropout1=.2, dropout2=False,\n                        sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n                        excitatory_wanted=EXCITATORY_SYNAPSES_WANTED, inhibitory_wanted=INHIBITORY_SYNAPSES_WANTED,\n                        qSynapse=(0.1, 0.1), augment=False, \n                        optimizer=SGD(5e-3), conv_shape=(16,16),\n                        padding=PADDING, synLoss=MeanSquaredErrorSynapsesPerMS):\n    printModule(dropout1, dropout2, sigmoid_threshold, sigmoid_mult, excitatory_wanted, inhibitory_wanted, qSynapse, augment, synLoss)\n    padding = tf.Variable(lambda: padding, trainable=False)\n    inp = keras.Input(shape=(256,256,1))\n    if augment:\n        x = data_augmentation(inp)\n    x = processor(x if augment else inp)\n    # x = layers.BatchNormalization()(x)\n    if dropout1:\n        x = layers.Dropout(dropout1)(x)\n    conv_shape = (x.shape[2], 1) if xaxis else conv_shape\n    f = tf.keras.Sequential([layers.Conv2D(1278, conv_shape, strides=conv_shape, #kernel_constraint=keras.constraints.NonNeg(), \n                                activity_regularizer=pre_synaptic_spike_regularization, name=\"WiringLayer\"),\n                             layers.BatchNormalization(name=\"BatchNorm\"),\n                             layers.Activation(sigmoid),\n                             ToBoolLayer(threshold=sigmoid_threshold, use_sigmoid=use_sigmoid, mult=sigmoid_mult, name='preNeuronBool')])\n    x = f(x)\n    pad = f(padding)\n        \n    cycles = 200//x.shape[-2]\n    full_time = cycles*x.shape[-2]\n    print(\"how many cycles:\", cycles)\n\n    x = ToNeuronInput(400, new_order=saccades, name=\"NeuronInput\")(x, padding=pad if padding is not 0 else padding)\n    \n    nExcitatorySynapsesPerMS = SpikeProcessor(excitatory_wanted, name='nExcitatory', end=639)(x)\n    nInhibitorySynapsesPerMS = SpikeProcessor(inhibitory_wanted, name='nInhibitory', start=639)(x)\n\n    if dropout2:\n        x = layers.Dropout(dropout2)(x)\n    x = L5PC_model(x)[:,-full_time:,:]   # run through david's model\n    x = layers.MaxPooling1D(x.shape[-2], strides=x.shape[-2], name=\"MaxPooling\")(x)\n    output = layers.Flatten(name=\"nSpikes\")(x)\n#     if to_bool:\n#         x = ToBoolLayer(threshold=0.2, use_sigmoid=False, mult=25, name='postNeuronBool')(x)  # only in validation and test\n    \n#     output = layers.Dense(1, name=\"nSpikes\")(x[:, -full_time:])\n#     model = keras.Model(inp, output)\n#     model.compile(optimizer=optimizer, loss={'nSpikes': MeanSquaredError()}, metrics={'nSpikes': keras.metrics.BinaryAccuracy()})\n    model = keras.Model(inp, [output, nExcitatorySynapsesPerMS, nInhibitorySynapsesPerMS])\n    model.compile(optimizer=optimizer, \n                  loss={'nSpikes': MeanSquaredError(), 'nExcitatory': synLoss(), 'nInhibitory': synLoss()}, \n                  metrics={'nSpikes': keras.metrics.BinaryAccuracy()}, \n                  loss_weights=[1-sum(qSynapse), *qSynapse])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:59.239467Z","iopub.execute_input":"2021-06-20T14:16:59.239956Z","iopub.status.idle":"2021-06-20T14:16:59.262673Z","shell.execute_reply.started":"2021-06-20T14:16:59.239873Z","shell.execute_reply":"2021-06-20T14:16:59.261804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Pad(keras.layers.Layer):\n    \"\"\"flattens the temporal dimensions, order by new_order and pads with 0's to fill\"\"\"\n    def __init__(self, padding, full=400, times=6, reverse=True, new_order=None, name=\"PadLayer\"):\n        super().__init__(name=name)\n        self.full = full\n        self.padding = padding\n        self.times = times\n        self.reverse = reverse\n        self.new_order = new_order\n        self.shape = None\n        self.pad_to_add = None\n    \n    def build(self, shape):\n        self.shape = shape\n        self.pad_to_add = self.full - self.shape[-2]*self.times\n    \n    def call(self, inputs):\n        if self.new_order is not None:\n            inputs = self.gather(inputs, self.new_order, axis=-2)\n        if self.times > 1:\n            if self.reverse: new_inp = layers.Concatenate(axis=-2)([inputs, K.reverse(inputs,axes=-2)] * (self.times // 2) + [inputs] * (self.times % 2))\n            else: new_inp = layers.Concatenate(axis=-2)([inputs] * self.times)\n        else: new_inp = inputs\n        starting_time = layers.Lambda(lambda x: self.ranInt(x))(self.padding)\n        padding = self.padding[:,:, starting_time:starting_time+self.pad_to_add]\n        new_inp = layers.Concatenate(axis=-2)([tf.tile(padding, [tf.shape(new_inp)[0], 1, 1, 1]), new_inp])\n        new_inp = K.reshape(new_inp, (tf.shape(new_inp)[0], self.shape[-3], self.shape[-2]*self.times + self.pad_to_add, self.shape[-1]))\n        return new_inp\n\n    def ranInt(self, x):\n        return K.random_uniform((1,), 0, self.padding.shape[-2]-self.pad_to_add, dtype=tf.dtypes.int32)[0]#.numpy()\n    \n    @tf.function\n    def gather(self, x, ind, axis):\n        return tf.gather(x+0, ind, axis)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:59.264256Z","iopub.execute_input":"2021-06-20T14:16:59.264794Z","iopub.status.idle":"2021-06-20T14:16:59.285268Z","shell.execute_reply.started":"2021-06-20T14:16:59.264751Z","shell.execute_reply":"2021-06-20T14:16:59.284071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SliceLayer(tf.keras.layers.Layer):\n    def __init__(self, start=None, end=None, name=\"SliceLayer\"):\n        super().__init__(name=name)\n        self.start = start\n        self.end = end\n\n    def build(self, shape):\n        self.dims = len(shape)\n        pass\n    \n    def call(self, inputs):\n        if self.start is not None:\n            if self.end is not None:\n                return inputs[:,:,:,self.start:self.end] if self.dims==4 else inputs[:,:,self.start:self.end]\n            else:\n                return inputs[:,:,:,self.start:] if self.dims==4 else inputs[:,:,self.start:]\n        elif self.end is not None:\n            return inputs[:,:,:,:self.end] if self.dims==4 else inputs[:,:,:self.end]","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:16:59.286845Z","iopub.execute_input":"2021-06-20T14:16:59.287291Z","iopub.status.idle":"2021-06-20T14:16:59.300322Z","shell.execute_reply.started":"2021-06-20T14:16:59.287251Z","shell.execute_reply":"2021-06-20T14:16:59.299213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def different_nSynapses(saccades=None, xaxis=True, use_sigmoid=True, pruning=True, dropout1=False, dropout2=False,\n                        sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n                        excitatory_wanted=EXCITATORY_SYNAPSES_WANTED, inhibitory_wanted=INHIBITORY_SYNAPSES_WANTED,\n                        qSynapse=(tf.Variable(0.1, trainable=False), tf.Variable(0.1, trainable=False)), augment=False, \n                        optimizer=SGD(momentum=.9), conv_shape=(16,16), threshold=.2, times=6,\n                        padding=PADDING, synLoss=MeanSquaredErrorSynapsesPerMS, nSynapse=True, neurons=neurons, regular_sigmoid=True, non_neg=False):\n    printModule(dropout1, dropout2, sigmoid_threshold, sigmoid_mult, excitatory_wanted, inhibitory_wanted, qSynapse, augment, synLoss)\n    module_name = \"module_syn_\"\n    for i in [dropout1, dropout2, sigmoid_threshold, sigmoid_mult, threshold, excitatory_wanted, inhibitory_wanted, qSynapse, augment, synLoss.__name__]:\n        module_name += str(i)\n           \n    inp = keras.Input(shape=(256,256,1))\n    \n    padding = tf.Variable(lambda: padding, trainable=False)\n    x = inp\n    if augment: x = data_augmentation(augment)(x)\n    x = processor(x)\n    if dropout1: x = layers.Dropout(dropout1)(x)\n    conv_shape = (x.shape[-3], 1) if xaxis else conv_shape\n    real_input_time = x.shape[-2]*times\n    x = Pad(padding, full=neurons.input.shape[-2], times=times)(x)\n    if non_neg: x = layers.Conv2D(2*N_EXC, conv_shape, strides=conv_shape, use_bias=True, kernel_constraint=keras.constraints.NonNeg(), name=\"WiringLayer\")(x)#, activity_regularizer=pre_synaptic_spike_regularization)(x)\n    else: x = layers.Conv2D(2*N_EXC, conv_shape, strides=conv_shape, use_bias=True, name=\"WiringLayer\")(x)#, activity_regularizer=pre_synaptic_spike_regularization)(x)\n    x = layers.BatchNormalization(name=\"BatchNorm\")(x)\n    if regular_sigmoid: x = layers.Activation(sigmoid)(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, use_sigmoid=use_sigmoid, mult=sigmoid_mult, name='preNeuronBool')(x)\n    \n    x = K.squeeze(x, axis=-3)\n        \n    ExcitatorySynapses = SliceLayer(end=N_EXC, name=\"ExcSyns\")(x)#[:, :, :N_EXC]  #SpikeProcessor(excitatory_wanted, name='nExcitatory', end=639)(x)\n    InhibitorySynapses = SliceLayer(start=N_EXC, name=\"InhSyns\")(x)#[:, :, N_EXC:]  #SpikeProcessor(inhibitory_wanted, name='nInhibitory', start=639)(x)\n\n    if dropout2: x = layers.Dropout(dropout2)(x)\n    x = neurons(x)[:,-real_input_time:,:]   # run through david's model, take only the post-noise time (32 ms X 6 times)\n    x = layers.MaxPooling1D(x.shape[-2], strides=x.shape[-2], name=\"MaxPooling\")(x)\n    x = ToBoolLayer(threshold=threshold, use_sigmoid=True, mult=1, name='postNeuronBool')(x)\n    output = layers.Flatten(name=\"nSpikes\")(x)\n    \n    model = keras.Model(inp, [output, ExcitatorySynapses, InhibitorySynapses])\n    if not nSynapse:\n        model.compile(optimizer=optimizer, loss={'nSpikes': MeanSquaredError()}, \n                      metrics={\"nSpikes\": keras.metrics.BinaryAccuracy(), \"ExcSyns\": MeanSynapsesPerMsMetric(), \"InhSyns\": MeanSynapsesPerMsMetric()})\n    else:\n        model.compile(optimizer=optimizer, \n                  loss=[MeanSquaredError(), synLoss(excitatory_wanted), synLoss(inhibitory_wanted)], \n                  metrics={\"nSpikes\": keras.metrics.BinaryAccuracy(), \"ExcSyns\": MeanSynapsesPerMsMetric(), \"InhSyns\": MeanSynapsesPerMsMetric()},\n                  loss_weights=[1.0 -qSynapse[0] - qSynapse[1], qSynapse[0], qSynapse[1]])\n    return model, module_name","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:32:16.603207Z","iopub.execute_input":"2021-06-20T16:32:16.603523Z","iopub.status.idle":"2021-06-20T16:32:16.631408Z","shell.execute_reply.started":"2021-06-20T16:32:16.603491Z","shell.execute_reply":"2021-06-20T16:32:16.630286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ex_synapse_weight = tf.Variable(0.05, trainable=False)\n# inh_synapse_weight = tf.Variable(0.05, trainable=False)\n\nmodel_synapses, module_name = different_nSynapses(threshold=.2, non_neg=False, nSynapse=False, dropout1=.3, dropout2=.3, use_sigmoid=True, regular_sigmoid=True, sigmoid_mult=50, sigmoid_threshold=.9, augment=1., optimizer=Nadam(), qSynapse=(.1, .1), synLoss=MeanSquaredErrorSynapsesPerMS)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:31:26.796979Z","iopub.execute_input":"2021-06-20T16:31:26.797291Z","iopub.status.idle":"2021-06-20T16:31:27.335602Z","shell.execute_reply.started":"2021-06-20T16:31:26.79726Z","shell.execute_reply":"2021-06-20T16:31:27.334878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=5e-3, decay_steps=10000, decay_rate=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:33:33.892276Z","iopub.execute_input":"2021-06-20T16:33:33.892624Z","iopub.status.idle":"2021-06-20T16:33:33.898574Z","shell.execute_reply.started":"2021-06-20T16:33:33.892579Z","shell.execute_reply":"2021-06-20T16:33:33.897263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_synapses, module_name = different_nSynapses(threshold=.2, non_neg=True, nSynapse=True, dropout1=0.2, dropout2=0.1, use_sigmoid=True, regular_sigmoid=True, sigmoid_mult=50, sigmoid_threshold=.95, augment=True, optimizer=Nadam(lr=5e-3), qSynapse=(.05, .05), synLoss=MSE_RMS_SynapsesPerMS)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:48:25.339821Z","iopub.execute_input":"2021-06-20T16:48:25.340231Z","iopub.status.idle":"2021-06-20T16:48:25.879158Z","shell.execute_reply.started":"2021-06-20T16:48:25.340188Z","shell.execute_reply":"2021-06-20T16:48:25.878423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_synapses.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:48:26.106253Z","iopub.execute_input":"2021-06-20T16:48:26.106554Z","iopub.status.idle":"2021-06-20T16:48:26.130811Z","shell.execute_reply.started":"2021-06-20T16:48:26.106524Z","shell.execute_reply":"2021-06-20T16:48:26.129691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_syn = model_synapses.fit(train_ds, epochs=200, validation_data=valid_ds, callbacks=[SynapsePruner(5, 3, iterations=1), tf.keras.callbacks.LearningRateScheduler(lr_schedule)])#, SynapseLossDecay(ex_synapse_weight, inh_synapse_weight)])#, tf.keras.callbacks.LearningRateScheduler(tfa.optimizers.CyclicalLearningRate(1e-3, 5.1e-2, 1e-2, lambda x: 1))])","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:48:26.467967Z","iopub.execute_input":"2021-06-20T16:48:26.468296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model_synapses\nhistory = history_syn","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.191746Z","iopub.status.idle":"2021-06-20T16:30:15.192201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Best Module so Far","metadata":{}},{"cell_type":"code","source":"def printModule(dropout1, dropout2, sigmoid_threshold, sigmoid_mult, augment):\n    print(\"~*~ Visual Module ~*~\")\n    if augment: print(\"Images are augmented\")\n    print(f\"Image Dropout Rate: {dropout1}\")\n    print(f\"Synapse Threshold: {sigmoid_threshold}\")\n    print(f\"Synapse Training Sigmoid Multiplication: {sigmoid_mult}\")\n    print(f\"Synapses Dropout Rate: {dropout2}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.193411Z","iopub.status.idle":"2021-06-20T16:30:15.194213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_module(saccades=None, xaxis=True, use_sigmoid=True, pruning=True, dropout1=.2, dropout2=False,\n                        sigmoid_threshold=0.9, sigmoid_mult=15, to_bool=True, \n                        augment=False, optimizer=SGD(5e-3), conv_shape=(16,16),\n                        padding=PADDING, neurons=neurons, model_name=\"L5PC\", non_neg=False):\n    \n    printModule(dropout1, dropout2, sigmoid_threshold, sigmoid_mult, augment)\n    module_name = f\"module_{model_name}_{dropout1}_{dropout2}_{sigmoid_threshold}_{sigmoid_mult}_{augment}\"\n    \n    inp = keras.Input(shape=(256,256,1))\n    \n    padding = tf.Variable(lambda: padding, trainable=False)\n    x = inp\n    if augment: x = data_augmentation(augment)(x)\n    x = processor(x)\n    if dropout1: x = layers.Dropout(dropout1)(x)\n    conv_shape = (x.shape[-3], 1) if xaxis else conv_shape\n    x = Pad(padding)(x)\n    if non_neg: x = layers.Conv2D(1278, conv_shape, strides=conv_shape, activity_regularizer=pre_synaptic_spike_regularization, kernel_constraint=keras.constraints.non_neg(),use_bias=True, name=\"WiringLayer\")(x)\n    else: x = layers.Conv2D(1278, conv_shape, strides=conv_shape, activity_regularizer=pre_synaptic_spike_regularization, use_bias=True, name=\"WiringLayer\")(x)\n\n    x = layers.BatchNormalization(name=\"BatchNorm\")(x)\n    x = layers.Activation(sigmoid)(x)\n    x = ToBoolLayer(threshold=sigmoid_threshold, use_sigmoid=use_sigmoid, mult=sigmoid_mult, name='preNeuronBool')(x)\n    \n    x = K.squeeze(x, axis=-3)\n\n    if dropout2: x = layers.Dropout(dropout2)(x)\n    x = PredictNeuron(neurons)(x)[:,-198:,:]   # run through david's model, take only the post-noise time (32 ms X 6 times)\n    x = layers.MaxPooling1D(x.shape[-2], strides=x.shape[-2], name=\"MaxPooling\")(x)\n    output = layers.Flatten(name=\"nSpikes\")(x)\n\n    model = keras.Model(inp, output)\n    model.compile(optimizer=optimizer, loss={'nSpikes': MeanSquaredError()}, metrics={'nSpikes': keras.metrics.BinaryAccuracy()})\n    return model, module_name","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.195671Z","iopub.status.idle":"2021-06-20T16:30:15.196419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_syn_2 = model_synapses.fit(train_ds, epochs=100, validation_data=valid_ds)#, callbacks=[SynapsePruner(100, 100, iterations=1)])#, SynapseLossDecay(ex_synapse_weight, inh_synapse_weight)])#, tf.keras.callbacks.LearningRateScheduler(tfa.optimizers.CyclicalLearningRate(1e-3, 5.1e-2, 1e-2, lambda x: 1))])","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.197865Z","iopub.status.idle":"2021-06-20T16:30:15.198559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model, module_name = create_module(use_sigmoid=True, dropout1=False, dropout2=False, sigmoid_mult=75, sigmoid_threshold=0.9, augment=.8, optimizer=Nadam())","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.199773Z","iopub.status.idle":"2021-06-20T16:30:15.200596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"drfpCrD-_qv9","executionInfo":{"status":"ok","timestamp":1608822960125,"user_tz":-120,"elapsed":490,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"840fe0af-447c-4a84-a41e-75468591c19d","execution":{"iopub.status.busy":"2021-06-20T16:30:15.201938Z","iopub.status.idle":"2021-06-20T16:30:15.202773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(train_ds, epochs=100, validation_data=valid_ds, callbacks=[SynapsePruner(100, 100, iterations=0)])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-20T16:30:15.204053Z","iopub.status.idle":"2021-06-20T16:30:15.204849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = history.history\n\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nplt.title(\"Loss\")\nplt.plot(hist[\"loss\"], color=\"k\", label=\"train\")\nplt.plot(hist[\"val_loss\"], color=\"r\", label=\"validation\")\nplt.axhline(0, color=\"b\", linestyle=\"--\")\nplt.xlabel(\"epochs\")\nplt.legend()\n\naccuracy = \"nSpikes_binary_accuracy\"\n# accuracy = \"binary_accuracy\"\n\nplt.subplot(1,2,2)\nplt.title(\"Accuracy\")\nplt.plot(hist[accuracy], color=\"k\", label=f\"train (last: {str(round(hist[accuracy][-1], 2))})\")\nplt.plot(hist[\"val_\"+accuracy], color=\"r\", label=f\"validation (last: {str(round(hist['val_'+accuracy][-1], 2))})\")\nplt.axhline(.5, color=\"b\", linestyle=\"--\", label=\"chance\")\nplt.ylim((0,1))\nplt.xlabel(\"epochs\")\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.206316Z","iopub.status.idle":"2021-06-20T16:30:15.207099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_ds)","metadata":{"id":"RsBSKE4iTW7u","executionInfo":{"status":"ok","timestamp":1608815946345,"user_tz":-120,"elapsed":16806,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"8f500b8a-61b9-4c09-b68f-e24e2c8b4452","execution":{"iopub.status.busy":"2021-06-20T16:30:15.208814Z","iopub.status.idle":"2021-06-20T16:30:15.20949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot","metadata":{"id":"7dGfCp8zTW7u"}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def plot_examples(model, startFrom=200, plot_cycle=False, plot_spikes=True, plot_start=None, write_last=False, weights_start=None, preNeuron=\"NeuronInput\", spikeTrain=\"SpikeTrain\", postNeuron=\"nSpikes\"):\n    plt.figure(figsize=(200, 250))\n    how_many = 10\n    for img, label in train_ds.take(1):\n#         inputs = K.function(model.input, model.get_layer(bool_layers[0]).output)([img])\n        inputs = K.function(model.input, model.get_layer(preNeuron).output)([img])\n        outputs = K.function(model.input, model.get_layer(spikeTrain).output)([img])\n        if write_last: nAP = K.function(model.input, model.get_layer(postNeuron).output)([img])\n        for i in range(how_many):\n            plt.subplot(how_many, 3, 3*i+1)\n            plt.imshow(img[i,:,:,0]/255, cmap='gray')\n            plt.title(LABELS[label[i]], fontdict={'fontsize':200})\n            plt.axis(\"off\")\n            plt.subplot(how_many, 3, 3*i+2)\n            if len(inputs[i].shape)==3:\n                curr_input = np.squeeze(inputs[i], axis=-3)[startFrom:]\n            else:\n                curr_input = inputs[i][startFrom:]\n            num_of_synapses = np.sum(curr_input, axis=-1)\n            mean_synapses = round(num_of_synapses.mean(), 2)\n            std_synapses = round(num_of_synapses.std(), 2)\n            plt.title(f\"\\u03BC: {str(mean_synapses)},  \\u03C3: {str(std_synapses)}\", fontdict={'fontsize':200})\n            plt.imshow(curr_input[-32:,:] if plot_cycle else curr_input, cmap='binary', vmin=0, vmax=1)\n            plt.axis(\"off\")\n            plt.subplot(how_many, 3, 3*i+3)\n            curr_output = outputs[i]            \n            spikes = []\n            curr_index = startFrom\n            while True:\n                start = np.where(curr_output[curr_index:] > 0.25)[0]\n                if not start.shape[0]: break\n                start = curr_index+start[0]\n                end = np.where(curr_output[start:] < 0.1)[0]\n                if not end.shape[0]: break\n                end = end[0] + start\n                spikes.append((start,end))\n                curr_index = end + 1\n            plt.title((f\"Score: {str(round(nAP[i][0],2))},\" if write_last else \"\") +f\"\\u03A3: {str(round(curr_output.sum(),2))}\" + (f\", spikes:{spikes}\" if plot_spikes else \"\"), fontdict={'fontsize':150})\n            plt.plot(curr_output, linewidth=5)\n            if weights_start is not None:\n                plt.plot(np.arange(weights_start, 400), model.get_layer(\"nSpikes\").get_weights()[0][:,0], color='r')\n            plt.ylim(0,1)\n            if plot_start: plt.axvline(plot_start, color='g', linestyle=':', linewidth=10.)\n            plt.axis('on')\n        break","metadata":{"id":"uciiuFqPTW7v","executionInfo":{"status":"ok","timestamp":1608815880827,"user_tz":-120,"elapsed":795,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T16:30:15.210809Z","iopub.status.idle":"2021-06-20T16:30:15.211611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_statistics(model, starting_time=0, cycle_time=32, preNeuron=\"NeuronInput\", spikeTrain=\"SpikeTrain\"):\n    \n    all_inputs = []\n    n_synapses = []\n    synapses_mu = []\n    synapses_std = []\n    synapses_max = []\n    synapses_min = []\n#     sum_output = []\n    all_outputs = []\n#     excitatory_synapses = []\n#     inhibitory_synapses = []\n    label_dct = {}\n    synapses_mean_per_label = {}\n    \n    for img, label in train_ds.take(25):\n        inputs = K.function(model.input, model.get_layer(preNeuron).output)([img])\n        outputs = K.function(model.input, model.get_layer(spikeTrain).output)([img])\n        all_inputs.append(inputs)\n        labels = [LABELS[lbl] for lbl in label]\n        for j in range(len(inputs)):\n            if len(inputs[j].shape)==3:\n                curr_input = np.squeeze(inputs[j], axis=-3)\n            else:\n                curr_input = inputs[j]\n            \n            num_of_synapses = np.sum(curr_input[starting_time:starting_time+cycle_time, :N_EXC], axis=-1)\n#             excitatory_synapses.append(np.sum(curr_input[:, :N_EXC], axis=-1).mean())\n#             inhibitory_synapses.append(np.sum(curr_input[:, N_EXC:], axis=-1).mean())\n            n_synapses.append(num_of_synapses)\n            synapses_mu.append(num_of_synapses.mean())\n            synapses_std.append(num_of_synapses.std())\n            synapses_max.append(num_of_synapses.max())\n            synapses_min.append(num_of_synapses.min())\n            curr_output = outputs[j]\n#             sum_output.append(curr_output.sum())\n            all_outputs.append(curr_output)\n            if labels[j] not in label_dct:\n                label_dct[labels[j]] = []\n                synapses_mean_per_label[labels[j]] = {\"Sum\": [], \"Ex\":[], \"Inh\":[]}\n            label_dct[labels[j]].append(curr_output)\n            synapses_mean_per_label[labels[j]][\"Sum\"].append(np.sum(curr_input[starting_time:starting_time+cycle_time], axis=-1).mean())\n            synapses_mean_per_label[labels[j]][\"Ex\"].append(np.sum(curr_input[starting_time:starting_time+cycle_time, :N_EXC], axis=-1).mean())\n            synapses_mean_per_label[labels[j]][\"Inh\"].append(np.sum(curr_input[starting_time:starting_time+cycle_time, N_EXC:], axis=-1).mean())\n\n    mean_dct = {}\n    for lbl in label_dct.keys():\n        mean_dct[lbl] = np.stack(label_dct[lbl]).mean(axis=0)\n\n    plt.figure(figsize=(15,10))\n\n    plt.subplot(3,3,1)\n    plt.title('input values')\n    plt.hist(np.array(all_inputs).ravel())\n\n    plt.subplot(3,3,2)\n    plt.title('mean of sum synapses')\n    plt.hist(synapses_mu)\n\n    plt.subplot(3,3,3)\n    plt.title('std of sum synapses')\n    plt.hist(synapses_std)\n\n    plt.subplot(3,3,4)\n    plt.title('max sum synapses')\n    plt.hist(synapses_max)\n\n    plt.subplot(3,3,5)\n    plt.title('min sum synapses')\n    plt.hist(synapses_min)\n\n    plt.subplot(3,3,6)\n    plt.title(f'mean output of neuron (AP)')\n    for lbl, value in mean_dct.items():\n        plt.plot(value, label=lbl, linewidth=2.)\n    plt.ylim(0,1)\n    plt.legend()\n\n    plt.subplot(3,3,7)\n    plt.title('Excitatory Synapses Mean per Label')\n    plt.hist([synapses_mean_per_label[lbl][\"Ex\"] for lbl in synapses_mean_per_label.keys()], label=list(synapses_mean_per_label.keys()))\n    plt.legend()\n    plt.xlim()\n\n\n    plt.subplot(3,3,8)\n    plt.title('Inhibitory Synapses Mean per Label')\n    plt.hist([synapses_mean_per_label[lbl][\"Inh\"] for lbl in synapses_mean_per_label.keys()], label=list(synapses_mean_per_label.keys()))\n    plt.legend()\n    plt.xlim()\n\n    \n    plt.subplot(3,3,9)\n    plt.title('All Synapses Mean per Label')\n    plt.hist([synapses_mean_per_label[lbl][\"Sum\"] for lbl in synapses_mean_per_label.keys()], label=list(synapses_mean_per_label.keys()))\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.212956Z","iopub.status.idle":"2021-06-20T16:30:15.21372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nmoduleLayer = r\"tf_op_layer_strided_slice_\\d+\"\nselectedLayer = None\nfor layer in model.layers:\n    if bool(re.search(moduleLayer, layer.name)):\n        selectedLayer = layer.name\n        break\n    else: print(layer.name)\nprint(selectedLayer)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.215015Z","iopub.status.idle":"2021-06-20T16:30:15.215863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_examples(model, startFrom=0, plot_cycle=False, plot_spikes=False, plot_start=None, write_last=True, preNeuron=\"preNeuronBool\", spikeTrain=selectedLayer)","metadata":{"id":"bAVpYijxTW7v","executionInfo":{"status":"ok","timestamp":1608822141298,"user_tz":-120,"elapsed":3513816,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"0bec28ac-dd67-49fc-f016-ed76f3c1da65","execution":{"iopub.status.busy":"2021-06-20T16:30:15.217203Z","iopub.status.idle":"2021-06-20T16:30:15.21784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_statistics(model, 200 + 200%32, preNeuron=\"preNeuronBool\", spikeTrain=selectedLayer)","metadata":{"id":"weTSTPMeTW7v","executionInfo":{"status":"ok","timestamp":1608822145474,"user_tz":-120,"elapsed":3517478,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"5ed8097b-25c9-4d0b-da11-c041fb2b64bf","execution":{"iopub.status.busy":"2021-06-20T16:30:15.21905Z","iopub.status.idle":"2021-06-20T16:30:15.219709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,15))\nweights = model.get_layer(\"WiringLayer\").get_weights()[0][0]\nplt.suptitle(f\"Weights Examples (8 synapses out of {2*N_EXC})\")\nfor i in range(8):\n    for j in range(4):\n        plt.subplot(8, 4, 4*i+j+1)\n        x = np.zeros((32,8))\n        for l in range(32//4):\n            x[:,l] = weights[:,l*4+j,i]\n        plt.imshow(x, vmin=tf.reduce_min(weights), vmax=tf.reduce_max(weights))\n        if not i:\n            plt.title(r\"$\\Theta={}\\pi$\".format(thetas[j]/np.pi))\n        if not j:\n            plt.ylabel(f\"Syn {i}\\nyaxis pixels\")\n        if i == 7:\n            plt.xlabel(f\"filter\")\n        plt.xticks([])\n        plt.yticks([])","metadata":{"id":"m6tSi907qDRa","executionInfo":{"status":"ok","timestamp":1608822151511,"user_tz":-120,"elapsed":4948,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"outputId":"80358f7c-3142-4dfb-a268-dc854a4f17b1","execution":{"iopub.status.busy":"2021-06-20T16:30:15.220971Z","iopub.status.idle":"2021-06-20T16:30:15.221667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(weights.mean(axis=(0,2)), label=\"mean\")\nplt.plot(np.abs(weights).mean(axis=(0,2)), label=\"abs mean\")\nplt.title(\"Mean and Abs Mean of Synapse Weights by Channel (after processing)\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.222921Z","iopub.status.idle":"2021-06-20T16:30:15.223725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\n\nplt.subplot(2,2,1)\nplt.title(r\"Exc Synapses Weights (std by Synapse)\")\nplt.hist(weights[:,:,:N_EXC].std(axis=(0,1)))\n\nplt.subplot(2,2,3)\nplt.title(r\"Exc Synapses Weights (sum by Synapse)\")\nplt.hist(weights[:,:,:N_EXC].sum(axis=(0,1)))\n\nplt.subplot(2,2,2)\nplt.title(r\"Inh Synapses Weights (std by Synapse)\")\nplt.hist(weights[:,:,N_EXC:].std(axis=(0,1)))\n\nplt.subplot(2,2,4)\nplt.title(r\"Inh Synapses Weights (sum by Synapse)\")\nplt.hist(weights[:,:,N_EXC:].sum(axis=(0,1)))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.225267Z","iopub.status.idle":"2021-06-20T16:30:15.226102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(10,20))\nweights = model.get_layer(\"WiringLayer\").get_weights()[0][0]\nprint(f\"min: {weights.min()}, max: {weights.max()}\\nmean: {weights.mean()}, sd: {weights.std()}\\n\")\nexc = weights[:,:,:N_EXC]\ninh = weights[:,:,N_EXC:]\n# xExc = K.flatten(tf.transpose(exc) / tf.reduce_max(exc, axis=-1))\n# xInh = K.flatten(tf.transpose(inh) / tf.reduce_max(exc, axis=-1))\n# print(f\"Exc: mean per pre-synaptic: {xExc.mean()}, mean binary: {(xExc>PRESYNAPTIC_THRESHOLD).sum(axis=-1).mean()}\")\n# print(f\"Inh: mean per pre-synaptic: {weights[:,N_EXC:].mean()}, mean binary: {(weights[:,N_EXC:]>PRESYNAPTIC_THRESHOLD).sum(axis=-1).mean()}\")\namountExc = [(exc>0.01).sum(axis=(0,1))]\namountInh = [(inh>0.01).sum(axis=(0,1))]\n\nplt.subplot(1,2,1)\nplt.hist(amountExc)\nplt.title(\"Exc Synapses per Pixel\")\nplt.ylabel(\"Synapses per Pixel\")\n\nplt.subplot(1,2,2)\nplt.hist(amountInh)\nplt.title(\"Inh Synapses per Pixel\")\n# plt.ylabel(\"Synapses per Neuron\")\n\n\n\n# plt.subplot(3,1,1)\n# plt.title(\"Histogram Synapses per Presynaptic Neuron (Exc synapse)\")\n# plt.hist((weights[:,:N_EXC]>PRESYNAPTIC_THRESHOLD).sum(axis=-1))\n# plt.ylabel(\"nSynapses\")\n\n# plt.subplot(3,1,2)\n# plt.title(\"Histogram Synapses per Presynaptic Neuron (Inh synapse)\")\n# plt.hist((weights[:,N_EXC:]>PRESYNAPTIC_THRESHOLD).sum(axis=-1))\n# plt.ylabel(\"nSynapses\")\n\n# plt.subplot(3,1,3)\n# plt.title(\"Weights\")\n# plt.imshow(weights, cmap='binary', vmin=0, vmax=weights.max())\n# plt.axvline(N_EXC, color='r')\n# plt.xlabel(\"synapse\")\n# plt.ylabel(\"neuron\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.227571Z","iopub.status.idle":"2021-06-20T16:30:15.228268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Images to 400X1278 matrices","metadata":{}},{"cell_type":"markdown","source":"# Save Weights","metadata":{}},{"cell_type":"code","source":"serial = 0","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.229444Z","iopub.status.idle":"2021-06-20T16:30:15.23027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(f\"{module_name}_weights.npy\", 'wb') as f:\n    np.save(f, model.get_layer(\"WiringLayer\").get_weights()[0])\nwith open(f\"{module_name}_bias.npy\", 'wb') as f:\n    np.save(f, model.get_layer(\"WiringLayer\").get_weights()[1])\nwith open(f\"{module_name}_batchnorm.npy\", 'wb') as f:\n    np.save(f, model.get_layer(\"BatchNorm\").get_weights())","metadata":{"id":"IER4lsMqtnYB","executionInfo":{"status":"ok","timestamp":1608822147219,"user_tz":-120,"elapsed":672,"user":{"displayName":"Roy Urbach","photoUrl":"","userId":"03979889048736445362"}},"execution":{"iopub.status.busy":"2021-06-20T16:30:15.231648Z","iopub.status.idle":"2021-06-20T16:30:15.232341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(f\"./{module_name}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:30:15.233629Z","iopub.status.idle":"2021-06-20T16:30:15.234378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evolution (not used)","metadata":{"id":"-Wv6yELpTW7v"}},{"cell_type":"code","source":"class EvolutionModule:\n    generations = {}\n    results = {}\n    alive = set()\n    \n    def __init__(self, ID, generation, create_func, noise=.1, parent=None):\n        self.module = None\n        \n        self.generation = generation\n        self.cur_generation = generation\n        self.ID = ID\n        self.parent = parent\n        self.name = \"Module\" + (f\"({parent.__str__()[6:]})-\" if parent else \"\") + f\"[{generation}.{ID}]\"\n        \n        if generation not in EvolutionModule.generations: EvolutionModule.generations[generation] = [self]\n        else: EvolutionModule.generations[generation].append(self)\n        EvolutionModule.alive.add(self)\n                   \n        self.history = None\n        \n        self.children = set()\n        self.status = True\n        \n        self.create_func = create_func\n        self.original_weights = None\n        self.noise = noise\n        \n        self._create_model()\n        \n    \n    def _create_model(self):\n        self.module = self.create_func()\n        if self.parent:\n            self.original_weights = [weight for weight in self.parent.get_weights()]\n            self.original_weights[2] = self.original_weights[2] + np.random.rand(*self.original_weights[2].shape) * self.original_weights[2].std() * self.noise\n            self.module.set_weights(self.original_weights)\n    \n    def give_birth(self, n):\n        self.cur_generation += 1\n        for i in range(n):\n            self.children.add(EvolutionModule(i, self.cur_generation, self.create_func, self.noise, self))\n    \n    def is_alive(self):\n        return self.status\n    \n    def fit(self, training_ds, epochs, validation_data):\n        self.to_print()\n        history = self.module.fit(train_ds, epochs=epochs, validation_data=validation_data).history\n        if not self.history: self.history = history\n        else: \n            for key, value in history.items(): \n                self.history[key].extend(value)\n    \n    def die(self):\n        self.status = False\n        EvolutionModule.alive.remove(self)\n    \n    def value(self, n):\n        if not self.history: return None\n        return np.mean(self.history['loss'][-n:])\n    \n    def accuracy(self):\n        return self.history['val_logits_binary_accuracy'][-1]\n    \n    def value_to_print(self, n):\n        return self.history['loss'][-1], np.mean(self.history['loss'][-n:]), self.history['val_loss'][-1], np.mean(self.history['val_loss'][-n:]), self.history['val_logits_binary_accuracy'][-1], np.mean(self.history['val_logits_binary_accuracy'][-n:])\n    \n    def to_print(self):\n        print(f\"\\n Beginning fitting for {self.name}...\\n\")\n    \n    def __str__(self):\n        return self.name\n    \n    def get_weights(self):\n        return self.module.get_weights()","metadata":{"id":"XaveiKPHTW7v","execution":{"iopub.status.busy":"2021-06-20T16:30:15.235878Z","iopub.status.idle":"2021-06-20T16:30:15.236667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    return playable(saccades=None, xaxis=True, use_sigmoid=True, sigmoid_mult=50, to_bool=True, useSynapse=True, qSynapse=0.1, sigmoid_threshold=0.8, augment=False, optimizer=SGD(5e-3))","metadata":{"id":"XxnIaN8jTW7w","execution":{"iopub.status.busy":"2021-06-20T16:30:15.238001Z","iopub.status.idle":"2021-06-20T16:30:15.238726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_evolution(nStart=10, nEpochs=10, nMax=2, nPerMax=3, nGenerations=5, rand=0.1, measure_by=2):\n    EvolutionModule.generations.clear()\n    EvolutionModule.results.clear()\n    EvolutionModule.alive.clear()\n    \n    print(\"\\nGeneration 0:\\n\")\n    for i in range(nStart):\n        module = EvolutionModule(i, 0, create_model, rand)\n        module.fit(train_ds, epochs=nEpochs, validation_data=valid_ds)\n    EvolutionModule.results[0] = sorted(EvolutionModule.alive, key=lambda x: x.value(measure_by))\n    print(\"\\n\" + \"* \"*10)\n    print(f'Generation: 0:\\n Best accuracy (by loss): {EvolutionModule.results[0][0].accuracy()} by {EvolutionModule.results[0][0]}\\n')\n    for module in EvolutionModule.alive:\n        print(module, end=': ')\n        print(\"Last loss: {0}, Mean loss: {1}, Last val_loss: {2}, Mean val_loss: {3}, Last val accuracy: {4}, Mean val acc: {5}\".format(*module.value_to_print(measure_by)))\n    print(\"\\n\" + \"* \"*10+'\\n')\n    \n    \n    for generation in range(1, nGenerations):    \n        print(f\"\\nGeneration {generation}:\\n\")\n        for module, indicator in zip(EvolutionModule.results[generation-1], [True]*nMax+[False]*len(EvolutionModule.alive)):\n            if indicator: module.give_birth(nPerMax)\n            else: module.die()\n        for module in EvolutionModule.alive:\n            module.fit(train_ds, epochs=nEpochs, validation_data=valid_ds)\n        \n        EvolutionModule.results[generation] = sorted(EvolutionModule.alive, key=lambda x: x.value(measure_by))\n        print(\"\\n\" + \"* \"*10)\n        print(f'Generation: {generation}:\\n Best accuracy (by loss): {EvolutionModule.results[generation][0].accuracy()}\\n')\n        for module in EvolutionModule.alive:\n            print(module, end=': ')\n            print(\"Last loss: {0}, Mean loss: {1}, Last val_loss: {2}, Mean val_loss: {3}, Last val accuracy: {4}, Mean val acc: {5}\".format(*module.value_to_print(measure_by)))\n        print(\"\\n\" + \"* \"*10+'\\n')\n        \n    print(\"\\n~ ~ ~ ~ ~ ~ Done! ~ ~ ~ ~ ~ ~\\n\")\n    return EvolutionModule.results[-1][0], EvolutionModule.generations, EvolutionModule.results, EvolutionModule.alive","metadata":{"id":"HpQE59lnTW7w","execution":{"iopub.status.busy":"2021-06-20T16:30:15.240166Z","iopub.status.idle":"2021-06-20T16:30:15.240868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evolution(result_dct={}, nStart=10, nEpochs=10, nMax=2, nPerMax=3, nGenerations=5, rand=0.1, measure_by=3):\n    result_dct[0] = []\n    for i in range(nStart):\n        print(\"\\nStarting first generation module number\", i, \"...\\n\")\n        model = create_model()\n        history = model.fit(train_ds, epochs=nEpochs, validation_data=valid_ds)\n        result_dct[0].append((model, history.history['loss'], history.history['val_loss'], history.history['val_logits_binary_accuracy']))\n    for generation in range(1,nGenerations):\n        result_dct[generation] = []\n        max_chosen = sorted(result_dct[generation-1], key=lambda x: sum(x[1][-measure_by:]))[:nMax]\n        \n        print(\"\\n\" + \"* \"*10)\n        print(f'Generation: {generation}:\\n Best accuracy (by loss): {max_chosen[0][-1][-1]}\\n')\n        for result in result_dct[generation-1]:\n            print(\"last loss:\", result[1][-1], \" loss mean:\", np.mean(result[1][-measure_by:]),\"   last accuracy:\", result[-1][-1], \"  accuracy mean:\", np.mean(result[-1][-measure_by:]))\n        print(\"\\n\" + \"* \"*10+'\\n')\n        \n        print(\"Starting generation \", generation+1,\"...\\n\")\n        i = 1\n        for max_model, _, _ in max_chosen:\n            old_weights = max_model.get_weights()\n            for _ in range(nPerMax):\n                print(\"Starting module number \", i, \" out of\", nMax*(nPerMax+1), \"\\n\")\n                new_weights = [weight for weight in old_weights]\n                old_conv_weights = new_weights[2]\n                new_weights[2] = old_conv_weights + np.random.rand(*old_conv_weights.shape) * old_conv_weights.std() * rand\n                model = create_model()\n                model.set_weights(new_weights)\n                history = model.fit(train_ds, epochs=nEpochs, validation_data=valid_ds)\n                result_dct[generation].append((model, history.history['loss'], history.history['val_loss'], history.history['val_logits_binary_accuracy']))\n                i+=1\n            print(\"\\nStarting father...\\n\")\n            history = max_model.fit(train_ds, epochs=nEpochs, validation_data=valid_ds)\n            result_dct[generation].append((model, history.history['loss'], history.history['val_loss'], history.history['val_logits_binary_accuracy']))\n    max_chosen = sorted(result_dct[generation-1], key=lambda x: sum(x[1][-measure_by:]))[:nMax]\n        \n    print(\"\\n\" + \"* \"*10)\n    print(f'Generation: {nGenerations}:\\n Best accuracy (by loss): {max_chosen[0][-1][-1]}\\n')\n    for result in result_dct[nGenerations-1]:\n        print(\"last loss:\", result[2][-1], \" loss mean:\", np.mean(result[2][-measure_by:]),\"   last accuracy:\", result[-1][-1], \"  accuracy mean:\", np.mean(result[-1][-measure_by:]))\n    print(\"\\n\" + \"* \"*10+'\\n')\n    return result_dct","metadata":{"id":"R9SDvX_PTW7w","execution":{"iopub.status.busy":"2021-06-20T16:30:15.242231Z","iopub.status.idle":"2021-06-20T16:30:15.242926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_module, generations, results, alive = run_evolution(nStart=10, nEpochs=10, nMax=3, nPerMax=2, nGenerations=6)\n# print(best_module.value_to_print(1))","metadata":{"id":"jxFh6AtQTW7w","execution":{"iopub.status.busy":"2021-06-20T16:30:15.244251Z","iopub.status.idle":"2021-06-20T16:30:15.245054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_examples(best_module)","metadata":{"id":"1NDh5i2eTW7x","outputId":"87545486-88dc-4cce-8c22-5d011461d2ec","execution":{"iopub.status.busy":"2021-06-20T16:30:15.246446Z","iopub.status.idle":"2021-06-20T16:30:15.247187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_statistics(best_module)","metadata":{"id":"zUo2VSI5TW7y","execution":{"iopub.status.busy":"2021-06-20T16:30:15.248511Z","iopub.status.idle":"2021-06-20T16:30:15.249207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cur_model = best_module\n# while cur_model:\n#     print(\" * * * * * * *\"*2)\n#     print(\"Current module:\", cur_model)\n#     print(\"current weights:\", best_module.get_weights()[2].std())\n#     print(\"Original weights:\", best_module.original_weights[2].std())\n#     cur_model = cur_model.parent","metadata":{"id":"165eAukhTW7y","execution":{"iopub.status.busy":"2021-06-20T16:30:15.250319Z","iopub.status.idle":"2021-06-20T16:30:15.251085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}