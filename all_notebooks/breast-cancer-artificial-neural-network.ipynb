{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a cancer data set. I have used 10 features which are selected through various feature selection techniques like ELI5. Several explainability techniques like LIME, SHAP, PDP (Partial dependency plots) have been employed as well. Hyperparameter optimization has been performed with the use of Grid-searchCV, Random-searchCV and Bayesian Optimization.\n\nReaders are recommended to take a look here - https://github.com/kaii55 for better understanding.\n\nhttps://kaii55.github.io - My website"},{"metadata":{"trusted":true},"cell_type":"code","source":"##Importing basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n \n#Importing Keras and Tensorflow for Deep Learning\nfrom keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport tensorflow as tf\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\n\n#Importing other libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n\n#Importing libraries for model evaluation \nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#Reading the dataset\ndf = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping unncessary columns\nlist = ['Unnamed: 32','id']\ndf.drop(list,axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the occurrences of malignant and non-malignant cells and print them\nocc = df['diagnosis'].value_counts()\nprint(occ)\n\n# Print the ratio of malignant and non-malignant cells\nprint(occ / len(df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the variance \nprint(df.var())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding categorical data values\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndf['diagnosis'] = labelencoder.fit_transform(df['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation checking in the dataset with the target value (Diagnosis)\ndf.corrwith(df.diagnosis).plot.bar(\n        figsize = (30, 10), title = \"Correlation with Target - Diagnosis\", fontsize = 20,\n        rot = 45, grid = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data selection - Here Only the important features are considered as they affect the models the most\n\ndf_1 = pd.DataFrame(df['diagnosis'])\ndf.drop(['diagnosis'], axis =1, inplace = True)\ndf_2 = pd.DataFrame(df[['radius_mean', 'texture_mean', 'perimeter_mean', \n                        'smoothness_mean', 'area_mean', 'concavity_mean', 'compactness_mean', \n                        'texture_se', 'area_se', 'fractal_dimension_mean']])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nss = StandardScaler()\n\nX = df_2\nY = df_1.values\n\n#Train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, \n                                                    stratify = Y)\n\n\n\n#Scaling and transforming the training data\nss.fit(X_train[['radius_mean', 'texture_mean', 'perimeter_mean', \n                        'smoothness_mean', 'area_mean', 'concavity_mean', 'compactness_mean', \n                        'texture_se', 'area_se', 'fractal_dimension_mean']])\n\nX_train = ss.transform(X_train[['radius_mean', 'texture_mean', 'perimeter_mean', \n                        'smoothness_mean', 'area_mean', 'concavity_mean', 'compactness_mean', \n                        'texture_se', 'area_se', 'fractal_dimension_mean']])\n\n\n#Transforming the data\nX_test = ss.transform(X_test[['radius_mean', 'texture_mean', 'perimeter_mean', \n                        'smoothness_mean', 'area_mean', 'concavity_mean', 'compactness_mean', \n                        'texture_se', 'area_se', 'fractal_dimension_mean']])\n\n\n\n\n#Sampling the data\n\n\nX_train_train, X_test_test, Y_train_train, Y_test_test = train_test_split(X_train, Y_train, test_size = 0.20)\n\nsm = SMOTE(random_state=42)\n\nX_resampled, Y_resampled = sm.fit_resample(X_train_train, Y_train_train)\n\n\n\n#If needed can be performed\n\n\"\"\"\nfrom sklearn.decomposition import PCA\npca = PCA()\nX_train = pca.fit_transform(X_train)\n\n\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of X: {}\".format(X.shape))\nprint(\"Shape of Y: {}\".format(Y.shape))\nprint(\"Shape of X_train: {}\".format(X_train.shape))\nprint(\"Shape of X_test: {}\".format(X_test.shape))\nprint(\"Shape of Y_train: {}\".format(Y_train.shape))\nprint(\"Shape of Y_test: {}\".format(Y_test.shape))\nprint(\"Shape of X_resampled: {}\".format(X_resampled.shape))\nprint(\"Shape of Y_resampled: {}\".format(Y_resampled.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\ncallbacks = [EarlyStopping(monitor='val_loss',mode='min',patience=2, restore_best_weights = True)]\nresults_control_accuracy = []\nfor i in range(0,30):\n    model = Sequential()\n    model.add(Dense(64, input_dim=len(X.columns),kernel_initializer = 'he_normal', activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, input_dim=len(X.columns),kernel_initializer = 'he_normal', activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.compile(keras.optimizers.Adam(lr=0.001),'binary_crossentropy',metrics=['accuracy'])\n\n    history = model.fit(X_resampled, Y_resampled, callbacks = callbacks,\n          epochs=30,validation_data = (X_test_test, Y_test_test),\n          batch_size=256, verbose = 0)\n\n    y_test_pred= model.predict(X_test) > 0.5\n    \n    f1 = f1_score(Y_test, y_test_pred)\n    \n    results_control_accuracy.append(f1)\n    \nprint(results_control_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_control_accuracy = pd.DataFrame(results_control_accuracy)\nmean_control_accuracy = results_control_accuracy.mean()\nprint(\"Mean Control Accuracy: {}\".format(mean_control_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std_control_accuracy = results_control_accuracy.std()\nprint(\"Standard Deviation of Control Accuracy Results: {}\".format(std_control_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test, y_test_pred)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Accuracy: {}\\nTest Accuracy:{}'.format(history.history['accuracy'][-1], history.history['val_accuracy'][-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Roc curve generation\nfrom sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(Y_test, y_test_pred)\nplt.plot ([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label = 'Deep Learning')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Deep Learning')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\ncallbacks = [EarlyStopping(monitor='val_loss',mode='min',patience=2, restore_best_weights = True)]\nresults_experimental_accuracy = []\nfor i in range(0,30):\n    model = Sequential()\n    model.add(Dense(64, input_dim=len(X.columns),kernel_initializer = 'he_normal',activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, kernel_initializer = 'he_normal', activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, input_dim=len(X.columns),kernel_initializer = 'he_normal',activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.compile(keras.optimizers.Adam(lr=0.001),'binary_crossentropy',metrics=['accuracy'])\n\n    history = model.fit(X_resampled, Y_resampled,callbacks = callbacks,\n          epochs=30,validation_data = (X_test_test, Y_test_test),\n          batch_size=256, verbose = 0)\n\n    y_test_pred= model.predict(X_test) > 0.5\n    \n    f1 = f1_score(Y_test, y_test_pred)\n    \n    results_experimental_accuracy.append(f1)\n    \nprint(results_experimental_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_experimental_accuracy = pd.DataFrame(results_experimental_accuracy)\nmean_experimental_accuracy = results_experimental_accuracy.mean()\nprint(\"Mean Experimental Accuracy: {}\".format(mean_experimental_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std_experimental_accuracy = results_experimental_accuracy.std()\nprint(\"Standard Deviation of Experimental Accuracy Results: {}\".format(std_experimental_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix generation\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test, y_test_pred)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification Report\nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Accuracy: {}\\nTest Accuracy:{}'.format(history.history['accuracy'][-1], history.history['val_accuracy'][-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Roc Curve generation\nfrom sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(Y_test, y_test_pred)\nplt.plot ([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label = 'Deep Learning')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Deep Learning')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_accuracy= pd.concat([results_control_accuracy, results_experimental_accuracy], axis=1)\nresults_accuracy.columns = ['Control', 'Experimental']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_accuracy.boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_accuracy.boxplot(showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = results_accuracy.boxplot()\nax.set_ylim([0.9,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_accuracy.hist(density=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normality Testing\nfrom scipy import stats\n\nalpha = 0.05;\n\ns, p = stats.normaltest(results_control_accuracy)\nif p < alpha:\n  print('Control data is not normal')\nelse:\n  print('Control data is normal')\n\ns, p = stats.normaltest(results_experimental_accuracy)\nif p < alpha:\n  print('Experimental data is not normal')\nelse:\n  print('Experimental data is normal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Significance Testing\ns, p = stats.wilcoxon(results_control_accuracy[0], results_experimental_accuracy[0])\n\nif p < 0.05:\n  print('null hypothesis rejected, significant difference between the data-sets')\nelse:\n  print('null hypothesis accepted, no significant difference between the data-sets')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}