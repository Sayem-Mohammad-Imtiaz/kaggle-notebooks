{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall opencv-python -y\n!pip uninstall opencv-contrib-python -y\n!pip uninstall opencv-python-headless -y\n!pip uninstall opencv-contrib-python-headless -y\n!pip uninstall opencv-contrib-python opencv-python\n!pip install opencv-contrib-python\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\nimport os,cv2,keras\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n#from tqdm.notebook import tqdm\nfrom tqdm import tqdm\nimport time\nimport random\n\nfrom keras.layers import Dense\nfrom keras import Model\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_iou(bb1, bb2):\n    assert bb1['x1'] < bb1['x2']\n    assert bb1['y1'] < bb1['y2']\n    assert bb2['x1'] < bb2['x2']\n    assert bb2['y1'] < bb2['y2']\n    \n    x_left = max(bb1['x1'], bb2['x1'])\n    y_top = max(bb1['y1'], bb2['y1'])\n    x_right = min(bb1['x2'], bb2['x2'])\n    y_bottom = min(bb1['y2'], bb2['y2'])\n    \n    if x_right < x_left or y_bottom < y_top:\n        return 0.0\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n    assert iou >= 0.0\n    assert iou <= 1.0\n    return iou","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rectangle(csv_annot):\n    df = pd.read_csv(csv_annot)\n    boxes=[]\n    for row in df.iterrows():\n        x1 = int(row[1][0].split(\" \")[0])\n        y1 = int(row[1][0].split(\" \")[1])\n        x2 = int(row[1][0].split(\" \")[2])\n        y2 = int(row[1][0].split(\" \")[3])\n        box={\"x1\":x1,\"x2\":x2,\"y1\":y1,\"y2\":y2}\n        boxes.append(box)\n    return boxes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rectang_from_image(image,x,y,w,h):\n    timage = image[y:y+h,x:x+w]\n    resized = cv2.resize(timage,\n                     (224,224),\n                     interpolation = cv2.INTER_AREA)\n    return resized","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_proposal = 2000\nmax_samples = 30\nIOU_treshold_plane = 0.7\nIOU_treshold_background = 0.3\n\ndataset_path = \"../input/airplanes-dataset-for-rcnn/Images/Images\"\nannot=\"../input/airplanes-dataset-for-rcnn/Airplanes_Annotations/Airplanes_Annotations\"\n\nss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n\ntrain_images=[]\ntrain_labels=[]\nimages=os.listdir(dataset_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_name=random.choice(images)\nimg = cv2.imread(os.path.join(dataset_path,img_name))\nplt.imshow(img)\ncsv_file = os.path.join(annot,str(img_name).split(\".\")[0]+\".csv\")\nboxes=get_rectangle(csv_file)\nfor box in boxes:\n    cv2.rectangle(img,(box['x1'],box['y1']),(box['x2'],box['y2']),(255,0,0), 2)\nplt.figure()\nplt.imshow(img)\n  \ncv2.setUseOptimized(True);\nss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\nss.setBaseImage(img)\nss.switchToSelectiveSearchFast()\nrects = ss.process()\nimOut = img.copy()\nfor i, rect in (enumerate(rects)):\n    x, y, w, h = rect\n    cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n# plt.figure()\nplt.imshow(imOut)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file in tqdm(images, desc=\"creating dataset\"):\n    try:\n        image=cv2.imread(os.path.join(dataset_path,file))\n        csv_path = os.path.join(annot,file.split(\".\")[0]+\".csv\")\n        box_values=get_rectangle(csv_path)\n        ss.setBaseImage(image)\n        ss.switchToSelectiveSearchFast()\n        ssresults = ss.process()\n        imout = image.copy()\n        counter=flag=falsecounter=fflag=bflag = 0\n        for e, result in  enumerate(ssresults):\n            if e< max_proposal and flag==0:\n                for a_box in box_values:\n                    x,y,w,h = result\n                    iou = get_iou(a_box,{\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n                    if counter < max_samples:\n                        if iou > IOU_treshold_plane:\n                            train_images.append(rectang_from_image(image,x,y,w,h))\n                            train_labels.append(1)\n                            counter +=1\n                    else:\n                        fflag = 1\n                    if falsecounter < max_samples:\n                        if iou < IOU_treshold_background:\n                            train_images.append(rectang_from_image(image,x,y,w,h))\n                            train_labels.append(0)\n                            falsecounter += 1\n                    else:\n                        bflag = 1\n                if fflag == 1 and bflag==1:\n                    flag=1\n    except Exception as e:\n        print(e)\n        continue","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vggmodel = VGG16(weights='imagenet', include_top=True)\n\nfor layers in (vggmodel.layers)[:15]:\n    print(layers)\n    layers.trainable = False\n    \nX= vggmodel.layers[-2].output\npredictions = Dense(1, activation=\"sigmoid\")(X)\nmodel_final = Model(vggmodel.input,predictions)\nopt = Adam(lr=0.0001)\nmodel_final.compile(loss = keras.losses.binary_crossentropy, optimizer = opt, metrics=[\"accuracy\"])\nmodel_final.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_new = np.array(train_images)\ny_new = np.array(train_labels)\n\nX_train, X_test , y_train, y_test = train_test_split(X_new,y_new,test_size=0.10)\n\ntrdata    = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=0)\ntraindata = trdata.flow(x=X_train, y=y_train)\ntsdata    = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=0)\ntestdata  = tsdata.flow(x=X_test, y=y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"ieeercnn_vgg16_1.h5\",\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True,\n                             save_weights_only=False,\n                             mode='auto', period=1)\n\nearly = EarlyStopping(monitor='val_loss', \n                      min_delta=0,\n                      patience=100,\n                      verbose=1,\n                      mode='auto')\n\nhist = model_final.fit_generator(generator= traindata,\n                                 steps_per_epoch= 10,\n                                 epochs= 1000, \n                                 validation_data= testdata,\n                                 validation_steps=2,\n                                 callbacks=[checkpoint,early])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\ndef create_download_link(title = \"Download model file\", filename = './RNN_model.h5'):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n\nmodel_final.save('./RNN_model.h5')\n# create a link to download the model \ncreate_download_link(filename='./RNN_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=random.choice(images)\nimg = cv2.imread(os.path.join(dataset_path,img))\nss.setBaseImage(img)\nss.switchToSelectiveSearchFast()\nssresults = ss.process()\nimout = img.copy()\nfor e,result in enumerate(ssresults):\n    if e < 2000:\n        x,y,w,h = result\n        timage = imout[y:y+h,x:x+w]\n        resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n        img = np.expand_dims(resized, axis=0)\n        out= model_final.predict(img)\n        if out[0][0] > 0.7:\n            cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\nplt.figure()\nplt.imshow(imout)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}