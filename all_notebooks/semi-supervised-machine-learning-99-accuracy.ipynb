{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"### Malicious Webpage Identification Using Semi Supervised Learning\n\nAlex Liddle"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport string\nimport re\nimport sklearn\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom scipy import stats\n#nltk.download('stopwords') #<---uncomment if you haven't downloaded the stopwords library\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the dataset¶"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataset into a pandas dataframe\ndf_reviews_raw = pd.read_csv('/kaggle/input/dataset-of-malicious-and-benign-webpages/Webpages_Classification_train_data.csv/Webpages_Classification_train_data.csv').drop(['Unnamed: 0'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect for missing values\ndf_reviews_raw.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check data types\ndf_reviews_raw.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect a small sample\ndf_reviews_raw.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean the data¶"},{"metadata":{},"cell_type":"markdown","source":"\nThe data must be cleaned and transformed into a format that the machine learning algorithms further down in this notebook expect. Furthermore, there should be a uniform distribution of labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the label distribution\ndf_reviews_raw.label.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get an equally distributed sample\ndf_reviews_untrimmed_sample = df_reviews_raw.groupby('label').apply(lambda x: x.sample(25000, random_state=42)).reset_index(drop=True)\n# Remove if content has less than 60 words\ndf_reviews_trimmed = df_reviews_untrimmed_sample[df_reviews_untrimmed_sample.content.str.split().str.len().ge(60)]\ndf_reviews_trimmed.label.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resample trimmed dataframe to make it uniformly distributed\ndf_reviews_sampled = df_reviews_trimmed.groupby('label').apply(lambda x: x.sample(2000, random_state=42)).reset_index(drop=True)\n# Randomly shuffle rows for aesthetics\ndf_reviews = df_reviews_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\ndf_reviews.label.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Examine the data¶"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews[['geo_loc', 'tld','who_is','https', 'label']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Text Preprocessing¶"},{"metadata":{},"cell_type":"markdown","source":"\nTo use our decision tree and random forest models, the data will need to be in a numerical format. As the value of one row with respect to another doesn't have an affect on either algorithm's decision when splitting a node (they are considered categorical variables), I will use ordinal encoding to transform the geo_loc, tld, who_is, https, and label columns. Meanwhile, natural language processing will be performed on the url and content columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews['geo_loc'] = OrdinalEncoder().fit_transform(df_reviews.geo_loc.values.reshape(-1,1))\ndf_reviews['tld'] = OrdinalEncoder().fit_transform(df_reviews.tld.values.reshape(-1,1))\ndf_reviews['who_is'] = OrdinalEncoder().fit_transform(df_reviews.who_is.values.reshape(-1,1))\ndf_reviews['https'] = OrdinalEncoder().fit_transform(df_reviews.https.values.reshape(-1,1))\ndf_reviews['label'] = OrdinalEncoder().fit_transform(df_reviews.label.values.reshape(-1,1))\n\n# convert url into human readable string that can be tokenized\ndf_reviews['url'] = df_reviews.url.apply(lambda x: ' '.join(x.split('://')[1].strip('www.').replace('.','/').split('/')))\ndf_reviews.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The textual data in the url and content columns will be tokenized, converted to lower case, and stopwords and punctuation will be removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before Preprocessing:\")\nprint(df_reviews.content.head())\n\ntqdm.pandas()\nstop = stopwords.words()\n\ndf_reviews.content = df_reviews.content.str.replace(\"[^\\w\\s]\", \"\").str.lower()\ndf_reviews.content = df_reviews.content.progress_apply(lambda x: ' '.join([item for item in x.split() \n                                                               if item not in stop]))\ndf_reviews.url = df_reviews.url.str.replace(\"[^\\w\\s]\", \"\").str.lower()\ndf_reviews.url = df_reviews.url.progress_apply(lambda x: ' '.join([item for item in x.split() \n                                                               if item not in stop]))\n\nprint(\"After Preprocessing:\")\nprint(df_reviews.content.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label urls and content using tfidf vectorization and clustering¶"},{"metadata":{},"cell_type":"markdown","source":"\nTo convert the widely varying content of the url and content columns into something more manageable for the decision tree and random forest models, I will label them using mini batch kmeans clustering. First, however, I will convert them into numeric vectors."},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(\n    min_df = 5,\n    max_df = 0.95,\n    max_features = 8000,\n    stop_words = 'english'\n)\n\ntfidf.fit(df_reviews.url)\nurl_tfidf = tfidf.transform(df_reviews.url)\n\ntfidf.fit(df_reviews.content)\ncontent_tfidf = tfidf.transform(df_reviews.content)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will use the elbow method to find the optimal number of clusters for each feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_optimal_clusters(data, max_k):\n    k_list = range(2, max_k+1)\n    \n    sse = []\n    for k in k_list:\n        sse.append(MiniBatchKMeans(n_clusters=k, init_size=1024, batch_size=2048, random_state=20).fit(data).inertia_)\n       \n    plt.style.use(\"dark_background\")\n    f, ax = plt.subplots(1, 1)\n    ax.plot(k_list, sse, marker='o')\n    ax.set_xlabel('Cluster Centers')\n    ax.set_xticks(k_list)\n    ax.set_xticklabels(k_list)\n    ax.set_ylabel('SSE')\n    ax.set_title('SSE by Cluster Center Plot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_optimal_clusters(url_tfidf, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An elbow can be seen where n_clusters equals nine. A new column, full of the clusters each row is assigned to, will be made."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews['url_cluster'] = MiniBatchKMeans(n_clusters=8, init_size=1024, batch_size=2048, \n                                            random_state=20).fit_predict(url_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_optimal_clusters(content_tfidf, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An elbow can be seen where n_clusters equals four. A new column, full of the clusters each row is assigned to, will be made."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews['content_cluster'] = MiniBatchKMeans(n_clusters=4, init_size=1024, batch_size=2048, \n                                            random_state=20).fit_predict(content_tfidf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate a training and test dataset¶"},{"metadata":{},"cell_type":"markdown","source":"The cleaned, transformed dataset will be split into a training and test set using a 70%/30% split."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_reviews[['url_cluster', 'url_len', 'geo_loc', 'tld', 'who_is', 'https', 'content_cluster',\n                'js_len', 'js_obf_len']]\ny = df_reviews.label\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model selection¶"},{"metadata":{},"cell_type":"markdown","source":"For the decision tree, the \"criterion\" and \"splitter\" hyperparameters will be tuned and cross-validation will be performed using the GridSearchCV sklearn module."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\nparam_grid=[{\"criterion\":[\"gini\", \"entropy\"],\n             \"splitter\":[\"best\", \"random\"]}]\ngrid=GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),param_grid=param_grid,cv=5)\ngrid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimal hyperparameters\ngrid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and test accuracies are examined to determine if overfitting or underfitting has occurred."},{"metadata":{"trusted":true},"cell_type":"code","source":"# training accuracy\ngrid.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test accuracy\ngrid.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the random forest, the \"n_estimators\" and \"criterion\" hyperparameters will be tuned and cross-validation will be performed using the GridSearchCV sklearn module."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nparam_grid=[{\"n_estimators\":[x for x in range(10, 120, 10)],\n             \"criterion\":[\"gini\", \"entropy\"]}]\ngrid=GridSearchCV(estimator=RandomForestClassifier(random_state=42),param_grid=param_grid,cv=5)\ngrid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimal hyperparameters\ngrid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and test accuracies are examined to determine if overfitting or underfitting has occurred."},{"metadata":{"trusted":true},"cell_type":"code","source":"# training accuracy\ngrid.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test accuracy\ngrid.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion"},{"metadata":{},"cell_type":"markdown","source":"Both algorithms performed exceptionally well and there is no evidence of overfitting or underfitting. This project serves as validation for using unsupervised learning for labeling textual data and the decision tree and/or random forest algorithms for identifying malicious webpages."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}