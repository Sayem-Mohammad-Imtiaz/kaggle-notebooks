{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sklearn as skl\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport seaborn as sns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('E:/NASA STAR CLASSIFICATION DATASET.csv')\ndf['Type'] = df['Type'].astype(str)\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Color'] = df['Color'].replace(['Blue White','Blue white','Blue-white'],'Blue-White')\ndf['Color'] = df['Color'].replace(['yellow-white','White-Yellow'],'Yellowish White')\ndf['Color'] = df['Color'].replace(['yellowish'],'Yellowish')\ndf['Color'] = df['Color'].replace(['Whitish','white'],'White')\n\nsns.catplot(x='Temperature',y='Color',data= df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_type = {'0':'Red Dwarf','1': 'Brown Dwarf','2': 'White Dwarf','3': 'Main Sequence','4': 'Supergiants','5': 'Hypergiants'}\ndf['Type'] = df['Type'].replace(dict_type.keys(),dict_type.values())\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_enc = pd.get_dummies(data=df.drop('Type',axis=1), columns=['Color','Spectral_Class'],drop_first= True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_enc.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_enc\ny = pd.DataFrame(df['Type'],columns=['Type'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test =train_test_split(X,y,test_size = 0.1,random_state = 20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nmm = MinMaxScaler()\nX_train_mm = pd.DataFrame(mm.fit_transform(X_train),columns=['Temperature', 'L', 'R', 'A_M', 'Color_Blue-White', 'Color_Orange',\n       'Color_Orange-Red', 'Color_Pale yellow orange', 'Color_Red',\n       'Color_White', 'Color_Yellowish', 'Color_Yellowish White',\n       'Spectral_Class_B', 'Spectral_Class_F', 'Spectral_Class_G',\n       'Spectral_Class_K', 'Spectral_Class_M', 'Spectral_Class_O'])\nX_test_mm = pd.DataFrame(mm.transform(X_test),columns=['Temperature', 'L', 'R', 'A_M', 'Color_Blue-White', 'Color_Orange',\n       'Color_Orange-Red', 'Color_Pale yellow orange', 'Color_Red',\n       'Color_White', 'Color_Yellowish', 'Color_Yellowish White',\n       'Spectral_Class_B', 'Spectral_Class_F', 'Spectral_Class_G',\n       'Spectral_Class_K', 'Spectral_Class_M', 'Spectral_Class_O'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_mm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nlr = LogisticRegression()\nmodel = lr.fit(X_train_mm,y_train)\npredictions = model.predict(X_test_mm)\nmodel_score = model.score(X_test_mm,y_test)\nprint(\"THE ACCURACY OF LOGISTIC REGRESSION CLASSIFIER IS\",model_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nmodel_rf = rf.fit(X_train_mm,y_train)\npredictions = model_rf.predict(X_test_mm)\nmodel_score_rf = model_rf.score(X_test_mm,y_test)\nprint(\"THE ACCURACY OF RANDOM FOREST CLASSIFIER IS\",model_score_rf)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1,metric='euclidean',weights='uniform')\nmodel_knn = knn.fit(X_train_mm,y_train)\nmodel_knn_score = knn.score(X_test_mm,y_test)\nmodel_knn_score\nmodel_knn_predictions = knn.predict(X_test_mm)\nprint(\"THE TEST ACCURACY OF KNN CLASSIFIER IS\",model_knn_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\ny_train = pd.get_dummies(data=y_train,columns =['Type'])\ny_test = pd.get_dummies(data=y_test,columns =['Type'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_nn = keras.Sequential([keras.layers.Dense(500,kernel_initializer = 'he_uniform',input_shape=(18,),activation = 'relu'),\n                            keras.layers.Dense(720,kernel_initializer = 'he_uniform',activation = 'relu'),\n                            keras.layers.Dense(800,kernel_initializer = 'he_uniform',activation = 'relu'),\n                            keras.layers.Dense(6,kernel_initializer = 'glorot_uniform',activation = 'softmax'),\n                            ])\nfrom tensorflow.keras.callbacks import  EarlyStopping\nes = EarlyStopping(patience=3,restore_best_weights= True)\nmodel_nn.compile(loss = \"categorical_crossentropy\",metrics = ['accuracy'],optimizer = 'sgd')\nhistory = model_nn.fit(X_train_mm,y_train,validation_data = (X_test_mm,y_test),epochs = 30,callbacks = es)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss,test_acc= model_nn.evaluate(X_test_mm,y_test)\nprint(\"test_accuracy:\",test_acc)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Performance')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['training_loss', 'validation_loss'], loc='upper right')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the model performs really well. There is no overfitting.","metadata":{}},{"cell_type":"markdown","source":"THE TEST ACCURACY OF LOGISTIC REGRESSION IS 95.83%","metadata":{}},{"cell_type":"markdown","source":"THE TEST ACCURACY OF RANDOM FOREST CLASSIFIER IS 100%","metadata":{}},{"cell_type":"markdown","source":"THE TEST ACCURACY OF KNN CLASSIFIER IS 100%","metadata":{}},{"cell_type":"markdown","source":"THE TEST ACCURACY OF ARTIFICIAL NEURAL NETWORK IS 95.8%","metadata":{}}]}