{"nbformat_minor":1,"cells":[{"outputs":[],"source":"import csv\nimport math\nimport random\n\n# Load CSV file, remove headers if any are dfound, \n# convert values to floats, and remove rows that \n# don't have x and y values\ndef load_csv(filename):\n    dataset = list()\n    with open(filename) as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            for i in range(len(row) - 1):\n                row[i] = float(row[i].strip())\n            row[-1] = 1.0 if row[-1] == 'R' else 0.0\n            dataset.append(row)\n    return dataset\n\ndef train_test_split(dataset, split):\n    train = list()\n    test = list(dataset)\n    train_len = len(dataset) * split\n    \n    while len(train) < train_len:\n        index = random.randrange(len(test))\n        item = test.pop(index)\n        train.append(item)\n    return train, test\n\ntrain, test = train_test_split(load_csv('../input/sonar.all-data.csv'), 0.6)\n\nprint('train %s . test . %s' % (len(train), len(test)))\n","cell_type":"code","execution_count":null,"metadata":{"_uuid":"0d6bf2d6964059bf0a630daa87d90b4f32f7dd60","_cell_guid":"e74d3417-8f70-4d96-907e-505318ccd8e8"}},{"outputs":[],"source":"def predict(row, weights):\n    activation = weights[0]\n    for i in range(len(row) - 1):\n        activation += weights[i + 1] * row[i]\n    return 1.0 if activation >= 0.0 else 0.0\n\ndef train_weights(train, l_rate, n_epoch):\n    weights = [0.0] * len(train[0])\n    for epoch in range(n_epoch):\n        sum_error = 0.0\n        for row in train:\n            prediction = predict(row, weights)\n            error = row[-1] - prediction\n            sum_error = sum_error + error ** 2\n            weights[0] = weights[0] + l_rate * error\n            for i in range(len(row) - 1):\n                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n    return weights\n\ndef perceptron(train, test, l_rate, n_epoch):\n    predictions = list()\n    weights = train_weights(train, l_rate, n_epoch)\n    for row in test:\n        prediction = predict(row, weights)\n        predictions.append(prediction)\n    return predictions\n\ndef stripped_test_set_and_actual(dataset):\n    test = list()\n    actual = list()\n    for row in dataset:\n        c = list(row)\n        actual.append(c[-1])\n        c[-1] = None\n        test.append(c)\n    return test, actual\n\ndef accuracy_metric(actual, predicted):\n    correct = 0\n    for i in range(len(actual)):\n        if actual[i] == predicted[i]:\n            correct = correct + 1\n    return correct / len(actual) * 100\n\ndef evaluate(train, test, algorithm, *args):\n    test_set, actual = stripped_test_set_and_actual(test)\n    predicted = algorithm(train, test, *args)\n    accuracy = accuracy_metric(actual, predicted)\n    return accuracy\n\n\naccuracy = evaluate(train, test, perceptron, 0.01, 50)\nprint('accuracy: ', accuracy)","cell_type":"code","execution_count":null,"metadata":{}}],"nbformat":4,"metadata":{"language_info":{"version":"3.6.3","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","name":"python","nbconvert_exporter":"python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}