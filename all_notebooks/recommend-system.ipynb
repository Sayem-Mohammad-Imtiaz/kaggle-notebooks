{"cells":[{"metadata":{},"cell_type":"markdown","source":"refer to [https://www.kaggle.com/morrisb/how-to-recommend-anything-deep-recommender]()"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data for all movies\nmovie_titles = pd.read_csv('../input/netflix-prize-data/movie_titles.csv', \n                           encoding = 'ISO-8859-1', \n                           header = None, \n                           names = ['Id', 'Year', 'Name']).set_index('Id')\n\nprint('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\nmovie_titles.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load a movie metadata dataset\nmovie_metadata = pd.read_csv('../input/the-movies-dataset/movies_metadata.csv', low_memory=False)[['original_title', 'overview', 'vote_count']].set_index('original_title').dropna()\n# Remove the long tail of rarly rated moves\nmovie_metadata = movie_metadata[movie_metadata['vote_count']>10].drop('vote_count', axis=1)\n\nprint('Shape Movie-Metadata:\\t{}'.format(movie_metadata.shape))\nmovie_metadata.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import deque","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load single data-file\ndf_raw = pd.read_csv('../input/netflix-prize-data/combined_data_1.txt', \n                     header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n\n\n# Find empty rows to slice dataframe for each movie\ntmp_movies = df_raw[df_raw['Rating'].isna()]['User'].reset_index()\nmovie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n\n# Shift the movie_indices by one to get start and endpoints of all movies\nshifted_movie_indices = deque(movie_indices)\nshifted_movie_indices.rotate(-1)\n\n\n# Gather all dataframes\nuser_data = []\n\n# Iterate over all movies\nfor [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n    \n    # Check if it is the last movie in the file\n    if df_id_1<df_id_2:\n        tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n    else:\n        tmp_df = df_raw.loc[df_id_1+1:].copy()\n        \n    # Create movie_id column\n    tmp_df['Movie'] = movie_id\n    \n    # Append dataframe to list\n    user_data.append(tmp_df)\n\n# Combine all dataframes\ndf = pd.concat(user_data)\ndel user_data, df_raw, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\nprint('Shape User-Ratings:\\t{}'.format(df.shape))\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get data\ndata_year = movie_titles['Year'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.plot(data_year)\nplt.xlabel('Release Year')\nplt.ylabel('Moives')\nplt.title('{} Movies Grouped By Year Of Release'.format(movie_titles.shape[0]))\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_rating = df['Rating'].value_counts().sort_index(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = [5,4,3,2,1]\ns=['{:.1f} %'.format(val) for val in (data_rating.values / df.shape[0] * 100)]\nplt.figure(figsize=(8,6))\nplt.bar(data_rating.index,data_rating.values)\nfor i in range(5):\n    plt.text(x[i],data_rating.values[i],s=s[i])\nplt.title('Distribution Of {} Netflix-Ratings'.format(df.shape[0]))\nplt.xlabel('Rating')\nplt.ylabel('Count')\nplt.grid(which='minor', axis='y')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Ratings Per Movie #####\n# Get data\ndata_movie = df.groupby('Movie')['Rating'].count().clip(upper=9999)\n\nplt.figure(figsize=(8,6))\nplt.hist(x = data_movie.values,bins = 100)\nplt.title('Distribution Of Ratings Per Movie (Clipped at 9999)')\nplt.xlabel('Ratings Per Movie')\nplt.ylabel('Count')\nplt.grid(axis='y')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n##### Ratings Per User #####\n# Get data\ndata_user = df.groupby('User')['Rating'].count().clip(upper=199)\n\nplt.figure(figsize=(8,6))\nplt.hist(x = data_user.values,bins = 100)\nplt.title('Distribution Of Ratings Per User (Clipped at 199)')\nplt.xlabel('Ratings Per User')\nplt.ylabel('Count')\nplt.grid(axis='y')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter sparse movies\nmin_movie_ratings = 10000\nfilter_movies = (df['Movie'].value_counts()>min_movie_ratings)\nfilter_movies = filter_movies[filter_movies].index.tolist()\n\n# Filter sparse users\nmin_user_ratings = 200\nfilter_users = (df['User'].value_counts()>min_user_ratings)\nfilter_users = filter_users[filter_users].index.tolist()\n\n# Actual filtering\ndf_filterd = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\ndel filter_movies, filter_users, min_movie_ratings, min_user_ratings\nprint('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\nprint('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle DataFrame\ndf_filterd = df_filterd.drop('Date', axis=1).sample(frac=1).reset_index(drop=True)\n\n# Testingsize\nn = 100000\n\n# Split train- & testset\ndf_train = df_filterd[:-n]\ndf_test = df_filterd[-n:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a user-movie matrix with empty values\ndf_p = df_train.pivot_table(index='User', columns='Movie', values='Rating')\nprint('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\ndf_p.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Mean Rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top n movies\nn = 10\n\n# Compute mean rating for all movies\nratings_mean = df_p.mean(axis=0).sort_values(ascending=False).rename('Rating-Mean').to_frame()\n\n# Count ratings for all movies\nratings_count = df_p.count(axis=0).rename('Rating-Count').to_frame()\n\n# Combine ratings_mean, ratings_count and movie_titles\nranking_mean_rating = ratings_mean.head(n).join(ratings_count).join(movie_titles.drop('Year', axis=1))\n\n\n# Join labels and predictions\ndf_prediction = df_test.set_index('Movie').join(ratings_mean)[['Rating', 'Rating-Mean']]\ny_true = df_prediction['Rating']\ny_pred = df_prediction['Rating-Mean']\n\n# Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n\nplt.figure(figsize=(10,6))\nplt.barh(list(range(1, n+1)),ranking_mean_rating['Rating-Mean'])\nplt.title('Ranking Of Top {} Mean-Movie-Ratings: {:.4f} RMSE'.format(n, rmse))\nplt.xlabel('Mean-Rating')\nplt.xlim(4.3,4.6)\nplt.ylabel('Movie')\nfor i in range(0,n):\n    plt.text(ranking_mean_rating['Rating-Mean'].values[i],i+1,\n             ranking_mean_rating['Name'].values[i]+':'+\n             ranking_mean_rating['Rating-Mean'].values.round(3)[i].astype(str),\n            color='red')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weighted Mean Rating\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of minimum votes to be considered\nm = 1000\n\n# Mean rating for all movies\nC = df_p.stack().mean()\n\n# Mean rating for all movies separatly\nR = df_p.mean(axis=0).values\n\n# Rating count for all movies separatly\nv = df_p.count().values\n\n\n# Weighted formula to compute the weighted rating\nweighted_score = (v/ (v+m) *R) + (m/ (v+m) *C)\n# Sort ids to ranking\nweighted_ranking = np.argsort(weighted_score)[::-1]\n# Sort scores to ranking\nweighted_score = np.sort(weighted_score)[::-1]\n# Get movie ids\nweighted_movie_ids = df_p.columns[weighted_ranking]\n\n\n# Join labels and predictions\ndf_prediction = df_test.set_index('Movie').join(pd.DataFrame(weighted_score, index=weighted_movie_ids, columns=['Prediction']))[['Rating', 'Prediction']]\ny_true = df_prediction['Rating']\ny_pred = df_prediction['Prediction']\n\n# Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n\n\n# Create DataFrame for plotting\ndf_plot = pd.DataFrame(weighted_score[:n], columns=['Rating'])\ndf_plot.index = weighted_movie_ids[:10]\nranking_weighted_rating = df_plot.join(ratings_count).join(movie_titles)\ndel df_plot\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.barh(list(range(1, n+1)),ranking_weighted_rating['Rating'])\nplt.title('Ranking Of Top {} Weighted-Movie-Ratings: {:.4f} RMSE'.format(n, rmse))\nplt.xlabel('Weighted Rating')\nplt.xlim(4.15,4.6)\nplt.ylabel('Movie')\nfor i in range(0,n):\n    plt.text(ranking_weighted_rating['Rating'].values[i],i+1,\n              ranking_weighted_rating['Name'].values[i]+':'+\n              ranking_weighted_rating['Rating'].values.round(3)[i].astype(str),\n              color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To create deep learning models\nfrom keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Matrix Factorisation With Keras And Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create user- & movie-id mapping\nuser_id_mapping = {id:i for i, id in enumerate(df_filterd['User'].unique())}\nmovie_id_mapping = {id:i for i, id in enumerate(df_filterd['Movie'].unique())}\n\n\n# Create correctly mapped train- & testset\ntrain_user_data = df_train['User'].map(user_id_mapping)\ntrain_movie_data = df_train['Movie'].map(movie_id_mapping)\n\ntest_user_data = df_test['User'].map(user_id_mapping)\ntest_movie_data = df_test['Movie'].map(movie_id_mapping)\n\n\n# Get input variable-sizes\nusers = len(user_id_mapping)\nmovies = len(movie_id_mapping)\nembedding_size = 10\n\n\n##### Create model\n# Set input layers\nuser_id_input = Input(shape=[1], name='user')\nmovie_id_input = Input(shape=[1], name='movie')\n\n# Create embedding layers for users and movies\nuser_embedding = Embedding(output_dim=embedding_size, \n                           input_dim=users,\n                           input_length=1, \n                           name='user_embedding')(user_id_input)\nmovie_embedding = Embedding(output_dim=embedding_size, \n                            input_dim=movies,\n                            input_length=1, \n                            name='item_embedding')(movie_id_input)\n\n# Reshape the embedding layers\nuser_vector = Reshape([embedding_size])(user_embedding)\nmovie_vector = Reshape([embedding_size])(movie_embedding)\n\n# Compute dot-product of reshaped embedding layers as prediction\ny = Dot(1, normalize=False)([user_vector, movie_vector])\n\n# Setup model\nmodel = Model(inputs=[user_id_input, movie_id_input], outputs=y)\nmodel.compile(loss='mse', optimizer='adam')\n\n\n# Fit model\nmodel.fit([train_user_data, train_movie_data],\n          df_train['Rating'],\n          batch_size=256, \n          epochs=4,\n          validation_split=0.1,\n          shuffle=True)\n\n# Test model\ny_pred = model.predict([test_user_data, test_movie_data])\ny_true = df_test['Rating'].values\n\n#  Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\nprint('\\n\\nTesting Result With Keras Matrix-Factorization: {:.4f} RMSE'.format(rmse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deep Learning With Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup variables\nuser_embedding_size = 20\nmovie_embedding_size = 10\n\n\n##### Create model\n# Set input layers\nuser_id_input = Input(shape=[1], name='user')\nmovie_id_input = Input(shape=[1], name='movie')\n\n# Create embedding layers for users and movies\nuser_embedding = Embedding(output_dim=user_embedding_size, \n                           input_dim=users,\n                           input_length=1, \n                           name='user_embedding')(user_id_input)\nmovie_embedding = Embedding(output_dim=movie_embedding_size, \n                            input_dim=movies,\n                            input_length=1, \n                            name='item_embedding')(movie_id_input)\n\n# Reshape the embedding layers\nuser_vector = Reshape([user_embedding_size])(user_embedding)\nmovie_vector = Reshape([movie_embedding_size])(movie_embedding)\n\n# Concatenate the reshaped embedding layers\nconcat = Concatenate()([user_vector, movie_vector])\n\n# Combine with dense layers\ndense = Dense(256)(concat)\ny = Dense(1)(dense)\n\n# Setup model\nmodel = Model(inputs=[user_id_input, movie_id_input], outputs=y)\nmodel.compile(loss='mse', optimizer='adam')\n\n\n# Fit model\nmodel.fit([train_user_data, train_movie_data],\n          df_train['Rating'],\n          batch_size=256, \n          epochs=4,\n          validation_split=0.1,\n          shuffle=True)\n\n# Test model\ny_pred = model.predict([test_user_data, test_movie_data])\ny_true = df_test['Rating'].values\n\n#  Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\nprint('\\n\\nTesting Result With Keras Deep Learning: {:.4f} RMSE'.format(rmse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deep Hybrid System With Metadata And Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import vstack","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create user- & movie-id mapping\nuser_id_mapping = {id:i for i, id in enumerate(df['User'].unique())}\nmovie_id_mapping = {id:i for i, id in enumerate(df['Movie'].unique())}\n\n# Use mapping to get better ids\ndf['User'] = df['User'].map(user_id_mapping)\ndf['Movie'] = df['Movie'].map(movie_id_mapping)\n\n\n##### Combine both datasets to get movies with metadata\n# Preprocess metadata\ntmp_metadata = movie_metadata.copy()\ntmp_metadata.index = tmp_metadata.index.str.lower()\n\n# Preprocess titles\ntmp_titles = movie_titles.drop('Year', axis=1).copy()\ntmp_titles = tmp_titles.reset_index().set_index('Name')\ntmp_titles.index = tmp_titles.index.str.lower()\n\n# Combine titles and metadata\ndf_id_descriptions = tmp_titles.join(tmp_metadata).dropna().set_index('Id')\ndf_id_descriptions['overview'] = df_id_descriptions['overview'].str.lower()\ndel tmp_metadata,tmp_titles\n\n\n# Filter all ratings with metadata\ndf_hybrid = df.drop('Date', axis=1).set_index('Movie').join(df_id_descriptions).dropna().drop('overview', axis=1).reset_index().rename({'index':'Movie'}, axis=1)\n\n\n# Split train- & testset\nn = 100000\ndf_hybrid = df_hybrid.sample(frac=1).reset_index(drop=True)\ndf_hybrid_train = df_hybrid[:1500000]\ndf_hybrid_test = df_hybrid[-n:]\n\n\n# Create tf-idf matrix for text comparison\ntfidf = TfidfVectorizer(stop_words='english')\ntfidf_hybrid = tfidf.fit_transform(df_id_descriptions['overview'])\n\n\n# Get mapping from movie-ids to indices in tfidf-matrix\nmapping = {id:i for i, id in enumerate(df_id_descriptions.index)}\n\ntrain_tfidf = []\n# Iterate over all movie-ids and save the tfidf-vector\nfor id in df_hybrid_train['Movie'].values:\n    index = mapping[id]\n    train_tfidf.append(tfidf_hybrid[index])\n    \ntest_tfidf = []\n# Iterate over all movie-ids and save the tfidf-vector\nfor id in df_hybrid_test['Movie'].values:\n    index = mapping[id]\n    test_tfidf.append(tfidf_hybrid[index])\n\n\n# Stack the sparse matrices\ntrain_tfidf = vstack(train_tfidf)\ntest_tfidf = vstack(test_tfidf)\n\n\n##### Setup the network\n# Network variables\nuser_embed = 10\nmovie_embed = 10\n\n\n# Create two input layers\nuser_id_input = Input(shape=[1], name='user')\nmovie_id_input = Input(shape=[1], name='movie')\ntfidf_input = Input(shape=[24144], name='tfidf', sparse=True)\n\n# Create separate embeddings for users and movies\nuser_embedding = Embedding(output_dim=user_embed,\n                           input_dim=len(user_id_mapping),\n                           input_length=1,\n                           name='user_embedding')(user_id_input)\nmovie_embedding = Embedding(output_dim=movie_embed,\n                            input_dim=len(movie_id_mapping),\n                            input_length=1,\n                            name='movie_embedding')(movie_id_input)\n\n# Dimensionality reduction with Dense layers\ntfidf_vectors = Dense(128, activation='relu')(tfidf_input)\ntfidf_vectors = Dense(32, activation='relu')(tfidf_vectors)\n\n# Reshape both embedding layers\nuser_vectors = Reshape([user_embed])(user_embedding)\nmovie_vectors = Reshape([movie_embed])(movie_embedding)\n\n# Concatenate all layers into one vector\nboth = Concatenate()([user_vectors, movie_vectors, tfidf_vectors])\n\n# Add dense layers for combinations and scalar output\ndense = Dense(512, activation='relu')(both)\ndense = Dropout(0.2)(dense)\noutput = Dense(1)(dense)\n\n\n# Create and compile model\nmodel = Model(inputs=[user_id_input, movie_id_input, tfidf_input], outputs=output)\nmodel.compile(loss='mse', optimizer='adam')\n\n\n# Train and test the network\nmodel.fit([df_hybrid_train['User'], df_hybrid_train['Movie'], train_tfidf],\n          df_hybrid_train['Rating'],\n          batch_size=1024, \n          epochs=4,\n          validation_split=0.1,\n          shuffle=True)\n\ny_pred = model.predict([df_hybrid_test['User'], df_hybrid_test['Movie'], test_tfidf])\ny_true = df_hybrid_test['Rating'].values\n\nrmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\nprint('\\n\\nTesting Result With Keras Hybrid Deep Learning: {:.4f} RMSE'.format(rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}