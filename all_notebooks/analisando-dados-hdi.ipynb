{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1) Import all Library that will be used\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nimport statsmodels.formula.api as smf\n\nfrom scipy import stats\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import scale\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import linear_model, svm, gaussian_process\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score\n\nprint('Bibliotecas OK')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arquivo extraído do site oficial :\n# http://hdr.undp.org/en/data\n\nHDI_Anual_df = pd.read_csv('../input/hdisempontosnulos/Human Development Index (HDI).csv', delimiter = ';')\n\nHDI_Anual_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HDI_Anual_df =HDI_Anual_df[HDI_Anual_df.Country == 'World']\n#HDI_Anual_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsvm = HDI_Anual_df.plot(y=[\"1990\", \"1991\", \"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"], figsize=(10,5), title=('EVOLUÇÃO HDI'), ylabel=('VARIAÇÃO ANUAL'), xlabel=('Países') )\n\nfigure = svm.get_figure()    \nfigure.savefig('HDI-Evolução.png')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HDI_Anual_df = pd.to_numeric(HDI_Anual_df)\n\nTemp = HDI_Anual_df\nTemp = Temp.drop(['Country'], axis=1)\n\nTemp = Temp.apply(pd.to_numeric)\nTemp.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Temp['Country'] = HDI_Anual_df['Country']\nTemp = Temp.set_index('Country')\n\nTemp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Temp = Temp.transpose()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Temp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = Temp.plot(y=[\"World\", \" Brazil\"], figsize=(10,5), title=('EVOLUÇÃO HDI'), ylabel=('VARIAÇÃO ANUAL'), xlabel=('Países') )\n\nfigure = svm.get_figure()    \nfigure.savefig('HDI-Evolução.png')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Temp.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}