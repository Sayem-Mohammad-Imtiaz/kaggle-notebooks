{"cells":[{"metadata":{"id":"E2llnqf54ZWT"},"cell_type":"markdown","source":"Dataset from: https://www.kaggle.com/shivamb/netflix-shows/ \n\nPerforming basic EDA, and planned tasks-\n* Type of content distribution in different countries\n* Clustering movies based on linguistic features","execution_count":null},{"metadata":{"id":"luahNp1u5-4v","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport subprocess as sp\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport wordcloud","execution_count":null,"outputs":[]},{"metadata":{"id":"SzdlwjzZ6PaH","trusted":true,"collapsed":true},"cell_type":"code","source":"# loading data\ndf = pd.read_csv('../input/netflix-shows/netflix_titles.csv')\nn_samples,n_feats = df.shape\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"T9a_dnLE6cGt"},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{"id":"CQ402jWz6xkE","trusted":true},"cell_type":"code","source":"df.columns\n\nprint(df.shape[0])\ndf.groupby(['type']).count()['show_id']\n\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"Dg9JCE4G6zJc","trusted":true},"cell_type":"code","source":"# movie and series distribution\ndist = df.groupby(df['type']).count()['show_id'].reset_index()\nfig, ax = plt.subplots(facecolor='white',figsize=(10,10))\nax.bar(dist['type'],dist['show_id'])","execution_count":null,"outputs":[]},{"metadata":{"id":"tI11sJr261Fs","trusted":true},"cell_type":"code","source":"# dist of movie or series running in countries\ncountries = []\nfor i in df['country']:\n    if isinstance(i,str):\n        l = i.split(',')\n        for i in range(len(l)):\n            l[i] = l[i].strip()\n        countries = countries + l\ndist = dict(Counter(countries))\ndist20 = {k:v for k,v in sorted(dist.items(),key=lambda x: x[1],reverse=True)[:20]}\nfig, ax = plt.subplots(facecolor='white',figsize=(10,20))\nax.barh(list(dist20.keys()),dist20.values())\nax.grid(True,axis='x')\nax.set_xlabel(\"Number of shows running\")\nplt.title(\"Top 20 Country by Show Available\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"LyTCa6dV62ds","trusted":true},"cell_type":"code","source":"# release year distribution, grouped by 10 years\nyears= df['release_year'].values\nmaxyrs = np.max(years)\nminyrs = np.min(years)\ndist = {k:0 for k in np.arange(1920,2021,10)}\nfor i in years:\n    dist[int(str(int(i / 10))+'0')] += 1\nxticklabels = [str(i)+'s' for i in dist.keys()]\nfig, ax = plt.subplots(facecolor='white', figsize= (20,10))\nax.bar(dist.keys(),dist.values())\nax.set_xlabel('Release Years')\nax.set_ylabel('Running Shows')\nax.set_xticks(list(dist.keys()))\nax.set_xticklabels(xticklabels)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"fVwTt7O065Te","trusted":true},"cell_type":"code","source":"# rating distribution\ndist = df.groupby(['rating']).count().reset_index()[['rating','show_id']]\nfig, ax = plt.subplots(facecolor='white',figsize=(10,8))\nax.bar(dist['rating'],dist['show_id'])\nticks = np.arange(len(dist['rating']))\nax.set_xticks(ticks)\nax.set_xticklabels(dist.rating)\nax.set_xlabel('Content Ratings')\nax.set_ylabel('Shows Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"orRdh5lX68-X","trusted":true},"cell_type":"code","source":"# tags dist\ntmp_tags = []\nfor i in df['listed_in']:\n    tags = [c.strip() for c in i.split(',')]\n    tmp_tags = tmp_tags + tags\n\ndist = {k:v for k,v in sorted(dict(Counter(tmp_tags)).items(),key=lambda x: x[1])}\n\nfig, ax = plt.subplots(facecolor='white',figsize=(10,20))\nyticks = sorted(np.arange(len(dist.keys())))\nax.barh(list(dist.keys()),dist.values())\nax.set_yticks(yticks)\nax.set_yticklabels(dist.keys())\nax.set_frame_on(False)\nax.grid(True,axis='x')\n\nplt.title('Tags Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"ob7JEqQb6-XJ","trusted":true},"cell_type":"code","source":"# description\nwc = wordcloud.WordCloud(width=2000,height=2000)\ntexts = \" \".join([w for w in df.description])\nwc.generate(texts)\nfig, ax = plt.subplots(figsize=(10,10))\nax.imshow(wc, interpolation='bilinear')\nax.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"jGgzFpJW7D6F"},"cell_type":"markdown","source":"# Recommender \ninput: a movie name.\n\noutput: N movies similar to that.\n\n---\nways to achieve:\n1. description similarity measure\n2. cluster. find in which cluster the movie is. rank that cluster by similarity measure.\n\n## Preprocessing\n- stopwords\n- stemming","execution_count":null},{"metadata":{"id":"-XRv3Fm_7ItO","trusted":false},"cell_type":"code","source":"from nltk.stem.snowball import EnglishStemmer\nfrom nltk.corpus import stopwords\nes = EnglishStemmer(ignore_stopwords=False)\nsw = set(stopwords.words('english'))\ndef clean(sent):\n#     cleaned = [es.stem(w) for w in sent.split() if w not in sw]\n    sent = sent.lower()\n    cleaned = [w for w in sent.split() if w not in sw]\n    return \" \".join(cleaned)\n\nfor i in range(df.shape[0]):\n    df.loc[i,'description'] = clean(df.loc[i,'description'])","execution_count":null,"outputs":[]},{"metadata":{"id":"DKMOzAJW7Oyk"},"cell_type":"markdown","source":"## Similarity Measure on Description\n","execution_count":null},{"metadata":{"id":"Er9at8ARWZ1P"},"cell_type":"markdown","source":"### Using Word Embedding with Cosine Similarity","execution_count":null},{"metadata":{"id":"ElvP6HS87Tpa","outputId":"5619dfc8-851f-483a-a3f2-1bfcd4fd669c","trusted":true},"cell_type":"code","source":"try:\n    import fasttext.util\nexcept:\n    !pip install fasttext\n    import fasttext.util\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import text\nfrom scipy import spatial\n!pip install python-levenshtein\nfrom Levenshtein import ratio\nimport random\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfasttext.util.download_model('en',if_exists='ignore') # english\nft = fasttext.load_model('cc.en.300.bin')\ns1 = ft.get_sentence_vector('I am sad').reshape(1,-1)\ns2 = ft.get_sentence_vector('I am happy').reshape(1,-1)\nprint(cosine_similarity(s1,s2)[0][0])","execution_count":null,"outputs":[]},{"metadata":{"id":"y91EA6ICBcD8","outputId":"b0215f41-c755-4a46-d624-19af2c5e2c73","trusted":true},"cell_type":"code","source":"ITEM = random.randint(0,df.shape[0])\n# ITEM = 5285\ns1 = ft.get_sentence_vector(df.loc[ITEM,'description']).reshape(1,-1)\nprint('==================Target==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(df.loc[ITEM,'title'],df.loc[ITEM,'listed_in'],df.loc[ITEM,'description']))\nsims = []\nfor i in np.random.randint(0,df.shape[0]-1,100):\n    s2 = ft.get_sentence_vector(df.loc[i,'description']).reshape(1,-1)\n    sim = cosine_similarity(s1,s2)\n    sims.append((i,sim[0][0]))\ntop = sorted(sims,key=lambda x: x[1],reverse=True)[:5]\nfor tpl in top[:10]:\n    print('==================%.2f==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(tpl[1],df.loc[tpl[0],'title'],df.loc[tpl[0],'listed_in'],df.loc[tpl[0],'description']))","execution_count":null,"outputs":[]},{"metadata":{"id":"h_mp5LLzBi8K"},"cell_type":"markdown","source":"### TfIdf ","execution_count":null},{"metadata":{"id":"gE2alqkCBl_7","outputId":"005f44c9-9ec7-4240-de80-d1415862c894","trusted":true},"cell_type":"code","source":"tfvec = TfidfVectorizer(ngram_range=(1,1))\ntfvec.fit(df['description'])","execution_count":null,"outputs":[]},{"metadata":{"id":"ghvmH6u5Bq93","outputId":"e667a094-515e-4956-c010-b2ac28f58eb2","trusted":true},"cell_type":"code","source":"# this needs to be changed for tfvec\nITEM = random.randint(0,df.shape[0])\n# ITEM = 5285\ns1 = ft.get_sentence_vector(df.loc[ITEM,'description']).reshape(1,-1)\nprint('==================Target==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(df.loc[ITEM,'title'],df.loc[ITEM,'listed_in'],df.loc[ITEM,'description']))\nsims = []\nfor i in np.random.randint(0,df.shape[0]-1,100):\n    s2 = ft.get_sentence_vector(df.loc[i,'description']).reshape(1,-1)\n    sim = cosine_similarity(s1,s2)\n    sims.append((i,sim[0][0]))\ntop = sorted(sims,key=lambda x: x[1],reverse=True)[:5]\nfor tpl in top[:10]:\n    print('==================%.2f==================\\nTitle: %s\\nCategory: %s\\nDescription: %s\\n===================================='%(tpl[1],df.loc[tpl[0],'title'],df.loc[tpl[0],'listed_in'],df.loc[tpl[0],'description']))","execution_count":null,"outputs":[]},{"metadata":{"id":"ioM1n94BB1m9"},"cell_type":"markdown","source":"## Cluster First, Ranking Later","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"remove NaN from 'rating'  attribute","execution_count":null},{"metadata":{"id":"vZ8o3pYCB46_","outputId":"f311af78-d2bc-45f5-fa84-1ed6ed1eb3f9","trusted":true},"cell_type":"code","source":"df = df.dropna(subset=['rating'],axis=0).reset_index()\ndf.drop(columns=['index'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"pPWp25AjB9IU"},"cell_type":"markdown","source":"### OneHotEncoding","execution_count":null},{"metadata":{"id":"mR4pL0BPB-lH","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"id":"HaQo68QyCBnX","trusted":true},"cell_type":"code","source":"def customOneHotEncoder(X):\n    \"\"\"\n    Custom one hot encoding of 'listed_in' features\n    Parameters\n    ----------\n    X: dataframe like 2d array\n    \n    Returns\n    -------\n    X: Dataframe\n    \"\"\"\n    Nsamples = X.shape[0]\n    tmp_tags = []\n    for i in X['listed_in']:\n        tags = [c.strip() for c in i.split(',')]\n        tmp_tags = tmp_tags + tags\n    unq_tags = ['listed_in_'+t for t in set(tmp_tags)]\n    df = pd.DataFrame(data=np.zeros((Nsamples,len(unq_tags))),columns=unq_tags)\n    \n    for i in range(Nsamples):\n        tags = [c.strip() for c in X.loc[i,'listed_in'].split(',')]\n        for t in tags:\n            df.loc[i,'listed_in_'+t] = 1\n    return pd.DataFrame(df)","execution_count":null,"outputs":[]},{"metadata":{"id":"UxJdyhwrCGJ2","trusted":true},"cell_type":"code","source":"X = df[['type','listed_in','rating']]\nX = customOneHotEncoder(X)","execution_count":null,"outputs":[]},{"metadata":{"id":"LN8vpC93CZbM"},"cell_type":"markdown","source":"### Clustering","execution_count":null},{"metadata":{"id":"8uddG6nyCJgM","trusted":true},"cell_type":"code","source":"import sklearn.cluster as skc\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AffinityPropagation\n\n# KMeans\nkm = KMeans(n_clusters=30)\nkm.fit(X)\nX['cluster'] = km.labels_\ndf['cluster'] = km.labels_","execution_count":null,"outputs":[]},{"metadata":{"id":"TnohiHBiCMOR","trusted":true},"cell_type":"code","source":"def predict(target, scope, n=5):\n    \"\"\"\n    Predicts similar N movies by Cosine similarity with description. If target has attribute **cluster**, function will only match movies in the same cluster.\n    Params\n    ------\n    target: Series. shape: (n_features,)\n    scope: dataframe on which to search (n_samples,n_features)\n    Returns\n    -------\n    Y: dataframe. columns: [rank, similarity] + X.columns\n    \"\"\"\n    # tfvec = TfidfVectorizer(ngram_range=(1,3))\n    \n#     tf_target = tfvec.transform([target['description']])\n    cluster = True if 'cluster' in scope.columns else False\n    sims = []\n\n    if cluster:\n\n        idx = scope[scope['cluster']==target['cluster']].index\n\n        # X = tfvec.fit_transform(scope.loc[idx,'description'])\n        # tf_target = tfvec.transform([target['description']])\n        ft_target = ft.get_sentence_vector(target['description']).reshape(1,-1)\n\n        for i in range(len(idx)):\n            if scope.loc[idx[i],'show_id'] == target['show_id']:\n                continue\n            # tf_text = X[i]\n            # tf_sim = cosine_similarity(tf_text,tf_target)\n            # sims.append((scope.loc[idx[i],'show_id'],tf_sim,scope.loc[idx[i],'cluster']))\n            # print(idx[i])\n            \n            ft_text = ft.get_sentence_vector(scope.loc[idx[i],'description']).reshape(1,-1)\n            ft_sim = cosine_similarity(ft_target,ft_text)\n            sims.append((scope.loc[idx[i],'show_id'],ft_sim,scope.loc[idx[i],'cluster']))\n            \n    else:\n        tfvec.fit_transform(scope.loc[idx,'description'])\n        tf_target = tfvec.transform([target['description']])\n        \n        for i in range(scope.shape[0]):\n            text = scope.loc[i,'description']\n            tf_text = tfvec.transform([text])\n            tf_sim = cosine_similarity(tf_text,tf_target)\n            sims.append((scope.loc[idx[i],'show_id'],tf_sim,scope.loc[idx[i],'cluster']))\n            \n    top = sorted(sims,key=lambda x: x[1],reverse=True)\n    return top[:5]\n\ndef showbyid(df,obj):\n    \"\"\"\n    Returns movies in a dataframe.\n    \"\"\"\n    idx = [i[0] for i in obj]\n    confidence = [i[1][0][0] for i in obj]\n    \n    tmp = pd.DataFrame(columns=df.columns)\n    for i in idx:\n        tmp = tmp.append(df.loc[df['show_id']==i,:])\n    tmp['confidence'] = confidence\n    return tmp.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"id":"CUWkju4xCP_G","outputId":"240a3daa-cc15-48d0-9503-8ef28d02a5db","trusted":true},"cell_type":"code","source":"test = random.randint(0,df.shape[0]-1)\nprint(\"-----Query--\\n\",df.loc[test])\nres = predict(df.loc[test],df)\nsimilar_movies = showbyid(df,res)\nsimilar_movies","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"ml","language":"python","name":"ml"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}