{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Description (from: https://www.kaggle.com/kaamraankhan/heart-attack-eda\n\nage : Age of the patient\n\nsex : Sex of the patient\n\ncp : Chest Pain\n\ntrtbps : resting blood pressure (in mm Hg)\n\nchol : cholestoral in mg/dl\n\nfbs : fasting blood sugar\n\nrestecg : resting electrocardiographic results\n\nthalachh : Maximum heart rate\n\nexang: exercise induced angina\n\nold peak : Previous peak\n\nslp : Slope\n\ncaa: number of major vessels\n\noutput : 0= less chance of heart attack 1= more chance of heart attack","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\n# o_df = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/o2Saturation.csv')\ndf.head(5)\n# o_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict = {}\nfor i in list(df.columns): dict[i] = df[i].value_counts().shape[0]\n# dict = dict({{i : df[i].value_counts().shape[0]} for i in list(df.columns)})\npd.DataFrame(dict,index=[\"unique count\"]) #.transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(15,8))\n# sns.heatmap(data.corr(),cmap=\"Blues\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1,2, figsize=(16,8))\n\ncolors = [\"#FA5858\", \"#64FE2E\"]\nlabels =\"Did not Open Term Suscriptions\", \"Opened Term Suscriptions\"\n\nplt.suptitle('Percentage of person with heart disease attack in the dataset', fontsize=20)\n\ndf[\"output\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n                                             labels=labels, fontsize=12, startangle=25)\n\n\n# ax[0].set_title('State of Loan', fontsize=16)\nax[0].set_ylabel('% ссуды', fontsize=14)\n\n# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n# ax[1].set_title('Condition of Loans', fontsize=20)\n# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\npalette = [\"#64FE2E\", \"#FA5858\"]\n\n# sns.barplot(x=\"education\", y=\"balance\", hue=\"deposit\", data=df, palette=palette, estimator=lambda x: len(x) / len(df) * 100)\n# ax[1].set(ylabel=\"(%)\")\n# ax[1].set_xticklabels(df[\"education\"].unique(), rotation=0, rotation_mode=\"anchor\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Подключаем класс для предобработки данных\n# from sklearn import preprocessing\n\n# # Напишем функцию, которая принимает на вход DataFrame, кодирует числовыми значениями категориальные признаки\n# # и возвращает обновленный DataFrame и сами кодировщики.\n# def number_encode_features(init_df):\n#     result = init_df.copy() # копируем нашу исходную таблицу\n#     encoders = {}\n#     for column in result.columns:\n#         if result.dtypes[column] == np.object: # np.object -- строковый тип / если тип столбца - строка, то нужно его закодировать\n#             encoders[column] = preprocessing.LabelEncoder() # для колонки column создаем кодировщик\n#             result[column] = encoders[column].fit_transform(result[column]) # применяем кодировщик к столбцу и перезаписываем столбец\n#     return result, encoders\n\n# encoded_data, encoders = number_encode_features(df) # Теперь encoded data содержит закодированные кат. признаки \n# encoded_data.head() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del dict\nprint(';\\t'.join(f\"{k} {v}\" for k, v in dict(df.dtypes).items())); df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Есть ли пропуски?\nimport seaborn as sns\nfrom matplotlib.pyplot import figure\n\nfigure(figsize = (10, 5))\nsns.heatmap(df.isnull(), cbar=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# категориальные колонки\n#cat_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','poutcome']\ncat_columns = list(df.columns)\ndf[cat_columns].hist(figsize=(18, 8), \n#                                layout=(3,3), \n                               bins=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Corellation matrix\nplt.subplots(figsize=(12, 10))\nsns.heatmap(df.corr(), square = True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot(subplots=True, figsize = (10, 20))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# ... и регуляризация\n# np.arange(5).std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# https://colab.research.google.com/drive/1c91O0TOvY0RatJQGKncPf_p6uZRdRv_y?authuser=1#scrollTo=OgCz9pjaRBgO&line=4&uniqifier=1","metadata":{}},{"cell_type":"code","source":"y = df['output']\ny\nX = df\ndel X['output']\nX, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_tain, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import dummy\n\n# Будем использовать модель k ближайших соседей #~, которую проходили на 5 занятии\nfrom sklearn.neighbors import KNeighborsClassifier\n# импортируем и создаем knn классификатор #~ по аналогии\nknn = KNeighborsClassifier(n_neighbors=59) \n\n# тренируем для knn и для dummy\nclf_knn = knn.fit(X_train, y_tain)\nclf_mp = dummy.DummyClassifier(\"most_frequent\").fit(X_train, y_tain)\nclf_knn, clf_mp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# получаем от них предикты\ny_knn = clf_knn.predict(X_test)\ny_mp = clf_mp.predict(X_test)\nnp.array(y_test), y_knn, y_mp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint ('knn =', metrics.accuracy_score(y_test, y_knn), 'mp =', metrics.accuracy_score(y_test, y_mp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Подготовим кросс-валидацию\nfrom sklearn.model_selection import GridSearchCV\n\n# Зададим се+тку - среди каких значений выбирать наилучший параметр.\nknn_grid = {'n_neighbors': np.array(np.linspace(15, 35, 20), dtype='int')} # перебираем по параметру <<n_neighbors>>, по сетке заданной np.linspace(2, 100, 10)\n\n# Создаем объект кросс-валидации\ngs = GridSearchCV(knn, knn_grid, cv=5, n_jobs = -1)\n\n# Обучаем его\ngs.fit(X, y)\ngs.predict(X_test)\nprint ('gs =', metrics.accuracy_score(y_test, y_knn))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#`?\n# # Подключаем класс для предобработки данных\n# from sklearn import preprocessing\n\n# # Напишем функцию, которая принимает на вход DataFrame, кодирует числовыми значениями категориальные признаки\n# # и возвращает обновленный DataFrame и сами кодировщики.\n# def number_encode_features(init_df):\n#     result = init_df.copy() # копируем нашу исходную таблицу\n#     encoders = {}\n#     for column in result.columns:\n#         if result.dtypes[column] == np.object: # np.object -- строковый тип / если тип столбца - строка, то нужно его закодировать\n#             encoders[column] = preprocessing.LabelEncoder() # для колонки column создаем кодировщик\n#             result[column] = encoders[column].fit_transform(result[column]) # применяем кодировщик к столбцу и перезаписываем столбец\n#     return result, encoders\n\n# encoded_data, encoders = number_encode_features(df) # Теперь encoded data содержит закодированные кат. признаки \n# encoded_data.head(), \\\n# encoders, encoded_data, df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\ny_test, y_knn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#~^ encoders = df\n# Confusion matrix\nimport matplotlib\n\ndef conf_matr(y_test, y_knn):\n    fig = plt.figure(figsize=(8,8))\n    # nn_mtx = metrics.confusion_matrix(y_test, y_knn)\n    nn_mtx = metrics.confusion_matrix(y_test, gs)\n    print(nn_mtx)\n    font = {'weight' : 'bold', 'size'   :22}\n\n    matplotlib.rc('xtick', labelsize=20) \n    matplotlib.rc('ytick', labelsize=20) \n    sns.heatmap(nn_mtx, annot=True, fmt=\"d\", \n    #`\n    #             xticklabels=df['output'], #.classes_,\n    #             yticklabels=df['output'], #.classes_,\n               )\n    plt.ylabel(\"Real value\")\n    plt.xlabel(\"Predicted value\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}