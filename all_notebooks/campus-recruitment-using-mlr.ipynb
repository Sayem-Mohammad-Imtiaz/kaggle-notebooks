{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict whether the student is placed or not\ncampus_df = pd.read_csv('../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv')\ncampus_df = campus_df.iloc[:,0:-1].copy() #we dnt require salary field as we just have to decide whether the student is placed or not\ncampus_df.head()\ncampus_df_eda = campus_df.iloc[:,0:-1].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Indexing\ncampus_df.index = campus_df.sl_no\ncampus_df = campus_df.drop('sl_no',axis = 1)\ncampus_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"campus_df.info() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = campus_df.iloc[:,1:-2] #independent variables\nX.head()\nY = campus_df.status #dependent valariable\n#Y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"campus_df.describe() #show details of only numeric data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"campus_df.corr() #checking the correlation between the numeric fileds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Handling the categorical data\n#changing the object datypes to category datatypes because the  operations are faster in such cols than object datatype\ncampus_df.gender = campus_df.gender.astype('category')\ncampus_df.ssc_b = campus_df.ssc_b.astype('category')\ncampus_df.hsc_b = campus_df.hsc_b.astype('category')\ncampus_df.hsc_s = campus_df.hsc_s.astype('category')\ncampus_df.degree_t = campus_df.degree_t.astype('category')\ncampus_df.workex = campus_df.workex.astype('category')\ncampus_df.specialisation = campus_df.specialisation.astype('category')\ncampus_df.status = campus_df.status.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the unique values of each categorical data\nprint(campus_df.gender.unique())\nprint(campus_df.ssc_b.unique())\nprint(campus_df.hsc_b.unique())\nprint(campus_df.hsc_s.unique())\nprint(campus_df.degree_t.unique())\nprint(campus_df.workex.unique())\nprint(campus_df.specialisation.unique())\nprint(campus_df.status.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#as there are only two unique values using label encoder\nlabel_enc = LabelEncoder()\ncampus_df.gender = label_enc.fit_transform(campus_df.gender) #1 for MALE and 0 for FEMALE\ncampus_df.ssc_b = label_enc.fit_transform(campus_df.ssc_b) #1 for OTHERS and 0 for CENTRAL\ncampus_df.hsc_b = label_enc.fit_transform(campus_df.hsc_b) #1 for OTHERS and 0 for CENTRAL\ncampus_df.workex = label_enc.fit_transform(campus_df.workex) #1 for YES and 0 for NO\ncampus_df.specialisation = label_enc.fit_transform(campus_df.specialisation) #1 for Mkt&HR and 0 for Mkt&Fin\ncampus_df.status = label_enc.fit_transform(campus_df.status) #1 for PLACED and 0 for NOT PLACED\n#campus_df.status = campus_df.status.round()\ncampus_df.head()\n\n#usning Dummy trap from OneHotEncoding\n\n#for hsc_b\nfield = pd.get_dummies(campus_df.hsc_s)\ncampus_df = pd.concat([campus_df,field], axis = 1)\ncampus_df = campus_df.drop('hsc_s', axis = 1)\n#for degree_t\ndegree = pd.get_dummies(campus_df.degree_t)\ncampus_df = pd.concat([campus_df,degree],axis = 1)\ncampus_df = campus_df.drop('degree_t',axis= 1)\n\n\ncampus_df_cat = campus_df.copy()\n\ncampus_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we can perform regression as all the features are converted into numeric values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"campus_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FEATURE EXTRACTION\n#Now we need to select the features which has highest impact on the target value using SlectKBest\n#internal statistics used - chi2\nXnew = campus_df.drop('status',axis = 1)\nXnew.head()\nYnew = campus_df.status\n#Ynew.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for multicollinearity using  varaince_inflation_factor\nmodel_before = campus_df\nseries_before = pd.Series([variance_inflation_factor(Xnew.values, i) for i in range(Xnew.shape[1])], index = Xnew.columns)\nprint('DATA BEFORE')\nprint('-'*100)\nprint(series_before)\n\n# all values are less than 5, therefore no multicollinearity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bstfeatures = SelectKBest(score_func = chi2, k = 12)\nfit = bstfeatures.fit(Xnew,Ynew)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(Xnew.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fscore = pd.concat([dfcolumns,dfscores], axis = 1)\nfscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using OLS model\nXnew = sm.add_constant(Xnew)\nXnew.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sm.OLS(Ynew,Xnew).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splliting the training and the testing data\nxtrain, xtest, ytrain, ytest = train_test_split(Xnew, Ynew, test_size = .20, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using LinearRegression method to find the accuracy\n#defining the model\nlinearreg = LinearRegression()\nlinearreg.fit(xtrain, ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = linearreg.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = r2_score(ytest,y_pred)\nres*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Actual': ytest, 'Predicted': y_pred.round()})\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Findind the accuracy using features with high P value that we got using SelectKBest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = campus_df[['ssc_p', 'hsc_p', 'degree_p', 'workex', 'etest_p', 'specialisation', 'mba_p']]\ny = campus_df.status","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sm.add_constant(x)\nmodel = sm.OLS(y,x).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .20, random_state = 1)\nlr = LinearRegression()\nlr.fit(xtrain,ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = lr.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ress = r2_score(ytest,y_predict)\nress*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy is reduced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Doing some EDA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(campus_df_eda.gender.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = 'Male', 'Female'\nsize = [139,76]\nplt.pie(size, labels=labels,  autopct='%1.1f%%', shadow=True) #startangle=140)\nplt.show()\n#From this pie chart we can say that more Males are placed than Females","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['ssc_p','hsc_p','mba_p','degree_p']\nvalues = [(campus_df_eda['ssc_p'].mean()),(campus_df_eda['hsc_p'].mean()),(campus_df_eda['mba_p'].mean()),\n          (campus_df_eda['degree_p'].mean())]\nplt.bar(names, values)\nplt.ylabel('Average Percentage')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}