{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"%capture\npip install celluloid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Goals\n\n1. Implement dedicated practice.\n2. Finish book sections.\n3. Discuss probabilistic perspective.\n4. Use regression to predict housing prices.\n5. Use Naive Bayes to classify the fashion MNIST dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%pylab inline\n\nimport numpy as np\nimport pandas as pd\n\n#import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# What is machine learning?\n\n## Categories of ML\n- Supervised.\n$$P(y|X)$$\n    - Regression.\n    - Classification.\n- Unsupervised.\n$$P(X)$$\n    - Clustering.\n    - Dimensionality reduction.\n- Semi-supervised.\n- Reinforcement learning."},{"metadata":{},"cell_type":"markdown","source":"# Scikit-learn\n\n## Data representation\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"iris = sns.load_dataset('iris')\niris.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples, n_features = iris.shape  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_iris = iris.drop('species', axis=1)\ny_iris = iris['species']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(iris, hue='species', height=1.5);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Scikit-learn API\n\n## The basics\n1. Choose a class of model by importing the appropriate class from Scikit-learn.\n2. Choose hyperparameters by instantiating this class with desired values.\n3. Arrange data into features matrix and target vector.\n4. Fit the model to your data calling the `fit` method of the model instance.\n5. Apply the model to new data.\n    - Supervised: `predict`.\n    - Unsupervised: `transform` or `predict`.\n    \n## Supervised learning\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"rng = np.random.RandomState(42)\nx = 10 * rng.rand(50)\ny = 2 * x - 1 + rng.randn(50)\nplt.scatter(x, y);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Choose model class.\n\n[Linear regression](https://scikit-learn.org/stable/modules/linear_model.html)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.c_[np.ones(len(x)), x]\nprint(X.shape)\nnp.dot(X.T, y.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def myreg(x, y, n_iter=30, alpha=0.01):\n    '''Creates an animation of training a regressor'''\n    from IPython.display import HTML\n    from celluloid import Camera\n\n    fig = plt.figure()\n    camera = Camera(fig)\n    mu = x.mean()\n    sigma = x.std()\n    x = (x - mu) / sigma\n    X = np.c_[np.ones(len(x)), x]\n    m = X.shape[1]\n    w = np.random.rand(X.shape[1])\n    h = lambda X, w: X @ w\n    preds = [h(X, w)]\n    for i in range(n_iter):\n        y_pred = h(X, w)\n        w = w - alpha * (1/m) * (y_pred - y) @ X\n        preds.append(y_pred)\n        plt.scatter(x=x, y=y)\n        t = plt.plot(x, y_pred)\n        plt.legend(t, [f'iteration {i} w = {w}'])\n        camera.snap()\n    animation = camera.animate()\n    return HTML(animation.to_html5_video())\nmyreg(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"?LinearRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Choose model hyperparameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression(fit_intercept=True)\nmodel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Arrange features and target."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = x[:, np.newaxis]\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Fit."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x, y)\nplt.plot(x, model.predict(X))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Predict labels for unknown data.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"xfit = np.linspace(-1, 11)\nXfit = xfit[:, np.newaxis]\nyfit = model.predict(Xfit)\n\nplt.scatter(x, y)\nplt.plot(xfit, yfit)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Why learn regression?\n\nRegression summarizes how predictions of an _outcome_ vary across individuals by a set of _predictors_.\n\nThere are four main uses:\n1. Prediction.\n2. Exploring associations.\n3. Extrapolation.\n4. Causal inference.\n\n<figure>\n    <figcaption class=\"text-center small\">Causal inference will become important for simulation studies.</figcaption> \n    <img src=\"https://www.basicbooks.com/wp-content/uploads/2017/12/9780465097609.jpg?fit=436%2C675\" alt=\"The Book of Why\" width=200>    \n</figure>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# enable internet\n\nf_hibbs = 'http://www.stat.columbia.edu/~gelman/arm/examples/ElectionsEconomy/hibbs.dat'\ndf_elec = pd.read_table(f_hibbs, sep=' ')\ndf_elec.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 6), \n                               sharex=True, sharey=True)\n\n# add years as text\ndf_elec.plot(kind='scatter', x='growth', y='inc.party.vote', ax=ax1,\n             alpha=0.5)\nfor row in df_elec.iterrows():\n    ax1.text(x=row[1]['growth'], y=row[1]['inc.party.vote'], s=row[1]['year'])\n\nsns.regplot(data=df_elec, x='growth', y='inc.party.vote', ax=ax2,\n            scatter=True)\n\ndef format_ax(ax):\n    ax.spines['right'].set_visible(False)\n    ax.spines['top'].set_visible(False)\n    ax.set_xlabel('Average recent % growth in personal income')\n    ax.set_ylabel('Incumbent party\\'s vote share')\n    \nformat_ax(ax1)\nformat_ax(ax2)\n\nax1.set_title('Forecasting the election from the economy')\nax2.set_title('Data and linear fit')\n\nplt.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_The `statsmodels` package_"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\ndat = pd.DataFrame(dict(x=df_elec['growth'], \n                        y=df_elec['inc.party.vote']))\nres = smf.ols('y ~ x', data=dat).fit()\nres.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__$R^2$__\n\n__Standard error__\n\n__p-value__\n\n[StatQuest](https://www.youtube.com/watch?v=2AQKmw14mHM&ab_channel=StatQuestwithJoshStarmer)"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Iris classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_iris, y_iris, random_state=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification on digits"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_digits\ndigits = load_digits()\ndigits.images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = digits.data\ny = digits.target\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, random_state=0\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GaussianNB()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nmat = confusion_matrix(y_test, y_pred)\n\nsns.heatmap(mat, square=True, annot=True, cbar=False)\nplt.xlabel('predicted value')\nplt.ylabel('true value');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameters and model validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncross_val_score(model, X, y, cv=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bias vs variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dat['x'], dat['y'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat['y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearRegression()\nreg.fit(dat['x'].to_frame(), dat['y'])\nplt.scatter(dat['x'], dat['y'])\nplt.plot(dat['x'], reg.predict(dat['x'].to_frame()));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree=10)\nX_poly = poly.fit_transform(dat['x'].to_frame())\nreg = LinearRegression()\nreg.fit(X_poly, dat['y'])\n\nx = dat['x']\ny = reg.predict(X_poly)\n\nlists = sorted(zip(*[x, y]))\nnew_x, new_y = list(zip(*lists))\n\n\nplt.scatter(new_x, new_y)\nplt.plot(new_x, new_y);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}