{"cells":[{"metadata":{},"cell_type":"markdown","source":"Source:\n\nhttps://docs.python.org/3/library/codecs.html#standard-encodings\n\nhttps://www.kaggle.com/devghiles/step-by-step-solution-with-f1-score-as-a-metric\n\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n\nTo rename:\nhttps://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n\nTo change cols:\nhttps://stackoverflow.com/questions/12329853/how-to-rearrange-pandas-column-sequence/23741704\n\nhttps://rajacsp.github.io/mlnotes/python/data-wrangling/advanced-custom-lambda/\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FILEPATH = '/kaggle/input/sms-spam-collection-dataset/spam.csv'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(FILEPATH, encoding='cp852', engine = 'c') # engine 'c' used instead of 'python' for higher performance\ndf.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete unnecessary cols\ncols = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n\ndf.drop(cols, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Title change v1 = result, v2 = input\n\ndf.columns = ['result', 'input']\n\n# we can also use df.rename() option here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reorder options - must be applicable for all cols\ndf = df[['input','result']]\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename cols by using .rename - can be used for selected cols\n\ndf.rename(columns = {'input' : 'my_new_input', 'result' : 'my_new_result'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print first string\n\ndf.iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[2][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_message_length(msg):\n    \n    msg_words = msg.split(' ')\n    \n    msg_len = len(msg_words)\n    \n    return msg_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(find_message_length('spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['input_words_count'] = df['my_new_input'].apply(find_message_length)\ndf.head()\n\n# ref: https://rajacsp.github.io/mlnotes/python/data-wrangling/advanced-custom-lambda/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the unique labels\n\nset(df['my_new_result'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_length(msg):\n    \n    msg_len = len(msg)\n    \n    return msg_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(find_length(df.iloc[0][0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['input_char_length'] = df['my_new_input'].apply(find_length)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# History words count\n\nimport matplotlib.pyplot as plt\n\n# to avoid popups use inline\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.hist(data['label'], bins=3, weights=np.ones(len(data['label'])) / len(data['label']))\n\nimport numpy as np\n\nplt.hist(df['input_words_count'], bins = 100, weights = np.ones(len(df['input_words_count'])) / len(df['input_words_count']))\n\nplt.xlabel('Word Length')\nplt.ylabel('Group Count')\nplt.title('Word Length Histogram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find more than 80 words\ndf['input_words_count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_above_80 = df[df['input_words_count'] > 80]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_above_80.sort_values(by='input_words_count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nplt.hist(df['input_char_length'], bins = 100, weights = np.ones(len(df['input_char_length'])) / len(df['input_char_length']))\n\nplt.xlabel('Char Length')\nplt.ylabel('Group Count')\nplt.title('Char Length Histogram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spams = df['my_new_input'].iloc[(df['my_new_result'] == 'spam').values]\nhams = df['my_new_input'].iloc[(df['my_new_result'] == 'ham').values]\nprint(spams[:10])\nprint(hams[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.my_new_result.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spams = df[df['my_new_result']=='spam'].iloc[: ,0]\nspams[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hams = df[df['my_new_result']=='ham'].iloc[:,0]\nhams[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(spams.apply(lambda msg : len(msg)),bins = 100,label = 'Spams')\n\nplt.hist(hams.apply(lambda msg : len(msg)),bins=100,label='Hams',alpha=0.3)\n\nplt.xlabel('Message length')\n\nplt.ylabel('Count')\n\nplt.title('String lengths')\n\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tokenisation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nnlp = spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(msg):\n    \n    doc = nlp(msg)\n    \n    res=[]\n    \n    #for sent in doc.sents:\n     #   print(sent.text)\n    \n    for token in doc:\n        \n        \n        if(token.is_stop or token.is_digit or token.is_punct or not(token.is_oov)):\n            \n            pass\n        \n        else:\n            \n            res.append(token.lemma_.lower())\n    \n    return res\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalize('spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its 23 main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_tokens = []\nfor spam in spams:\n    spam_tokens += normalize(spam)\n    \nham_tokens = []\nfor ham in hams:\n    ham_tokens += normalize(ham)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Stop words removal\nfor word in spams:\n    word = normalize(word)\n\nfor word in hams:\n    word = normalize(word)\n\nprint(spams)\nprint(hams)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenise(words):\n    res = []\n    \n    for word in words:\n        doc = nlp(word)\n        \n        for token in doc:\n            res.append(token.text)\n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_tokens = tokenise(spams)\nham_tokens = tokenise(hams)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common_tokens_in_spams = Counter(spam_tokens).most_common(20)\nmost_common_tokens_in_hams = Counter(ham_tokens).most_common(20)\n\nprint(most_common_tokens_in_spams,end=\"\\n\\n\")\nprint(most_common_tokens_in_hams)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr, te = train_test_split(df, test_size = 0.2)\nprint(\"Training set length:\", len(tr))\nprint(\"Test set length:\", len(te))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_vectorizer = CountVectorizer(binary=True)\ncount_vectorizer = CountVectorizer()\ntfidf_vectorizer = TfidfVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_extraction(msg):\n    \n    mat = pd.DataFrame(tfidf_vectorizer.fit_transform(msg).toarray(),columns=tfidf_vectorizer.get_feature_names(),index=None)\n    return mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['my_new_result']=df['my_new_result'].map({\"ham\":0,\"spam\":1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=feature_extraction(df['my_new_input'])\nprint(k.shape,df['my_new_result'].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x,train_y, test_x,test_y = train_test_split(k,df['my_new_result'], test_size=0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfs = {\n    'mnb': MultinomialNB(),\n    'gnb': GaussianNB(),\n    'svm1': SVC(kernel='linear'),\n    'svm2': SVC(kernel='rbf'),\n    'svm3': SVC(kernel='sigmoid'),\n    'mlp1': MLPClassifier(),\n    'mlp2': MLPClassifier(hidden_layer_sizes=[100, 100]),\n    'ada': AdaBoostClassifier(),\n    'dtc': DecisionTreeClassifier(),\n    'rfc': RandomForestClassifier(),\n    'gbc': GradientBoostingClassifier(),\n    'lr': LogisticRegression()\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_scores = dict()\nfor clf_name in clfs:\n    clf = clfs[clf_name]\n    clf.fit(train_x, test_x)\n    y_pred = clf.predict(train_y)\n    f1_scores[clf_name] = f1_score(y_pred, test_y)\n    print(clf_name, f1_scores[clf_name])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solver=['lbfgs', 'sgd', 'adam']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_f1_score = float('-inf')\nbest_solver = None\n\nfor s in solver:\n    \n    clf = MLPClassifier(solver = s)\n    clf.fit(train_x, test_x)\n    y_pred = clf.predict(train_y)\n    current_f1_score = f1_score(y_pred, test_y)\n    if current_f1_score > max_f1_score:\n        max_f1_score = current_f1_score\n        best_solver = s\n        \nprint('Best Solver: {0}'.format(best_solver))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha_values = [i * 0.1 for i in range(11)]\nmax_f1_score = float('-inf')\nbest_alpha = None\nfor alpha in alpha_values:\n    clf = MLPClassifier(solver = 'adam')\n    clf.fit(train_x, test_x)\n    y_pred = clf.predict(train_y)\n    current_f1_score = f1_score(y_pred, test_y)\n    if current_f1_score > max_f1_score:\n        max_f1_score = current_f1_score\n        best_alpha = alpha\n        \nprint('Best f1-score: {0}'.format(max_f1_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best alpha: {0}'.format(best_alpha))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MLPClassifier(solver = 'lbfgs', alpha=0.4)\nclf.fit(train_x, test_x)\ny_pred = clf.predict(train_y)\nprint(confusion_matrix(y_pred, test_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=test_y,y=y_pred,marker=\"*\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}