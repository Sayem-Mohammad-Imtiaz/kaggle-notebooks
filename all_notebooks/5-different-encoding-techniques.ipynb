{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This Kernel shows 5 different types of Encodings you could use in your project\n\n1. Label Encoding\n2. One Hot Encoding\n3. Frequency Encoding\n4. Leave One Out Encoding\n5. Helmert Encoding\n\nWe would only use a subset of columns to execute the 5 techniques","metadata":{}},{"cell_type":"code","source":"import os\nfrom IPython.display import Image\nImage(filename=\"../input/encodings/encodings.jpg\", width= 1200, height=800)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:57:47.089295Z","iopub.execute_input":"2021-05-29T12:57:47.089598Z","iopub.status.idle":"2021-05-29T12:57:47.113221Z","shell.execute_reply.started":"2021-05-29T12:57:47.089563Z","shell.execute_reply":"2021-05-29T12:57:47.111936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-29T12:57:24.612309Z","iopub.execute_input":"2021-05-29T12:57:24.612623Z","iopub.status.idle":"2021-05-29T12:57:24.628323Z","shell.execute_reply.started":"2021-05-29T12:57:24.612598Z","shell.execute_reply":"2021-05-29T12:57:24.627087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Read the training data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/analytics-vidhya-job-a-thon-may-2021/train_s3TEQDk.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:34.991956Z","iopub.execute_input":"2021-05-29T12:53:34.99232Z","iopub.status.idle":"2021-05-29T12:53:35.274058Z","shell.execute_reply.started":"2021-05-29T12:53:34.992296Z","shell.execute_reply":"2021-05-29T12:53:35.273463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns =  [_c.upper() for _c in data.columns]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:36.947273Z","iopub.execute_input":"2021-05-29T12:53:36.947617Z","iopub.status.idle":"2021-05-29T12:53:36.952092Z","shell.execute_reply.started":"2021-05-29T12:53:36.947592Z","shell.execute_reply":"2021-05-29T12:53:36.950823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:37.899974Z","iopub.execute_input":"2021-05-29T12:53:37.900387Z","iopub.status.idle":"2021-05-29T12:53:37.915561Z","shell.execute_reply.started":"2021-05-29T12:53:37.900332Z","shell.execute_reply":"2021-05-29T12:53:37.91357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['CHANNEL_CODE', 'OCCUPATION']","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:38.511541Z","iopub.execute_input":"2021-05-29T12:53:38.511814Z","iopub.status.idle":"2021-05-29T12:53:38.515863Z","shell.execute_reply.started":"2021-05-29T12:53:38.511791Z","shell.execute_reply":"2021-05-29T12:53:38.5151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Label Encoding","metadata":{}},{"cell_type":"code","source":"label_encode_var =  data[cols]\n\nfrom sklearn.preprocessing import LabelEncoder\nfor col in cols:\n    label_encode_var.loc[:,f'{col}_ENCODED'] = LabelEncoder().fit_transform(label_encode_var[col])\n\nlabel_encode_var.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:40.171699Z","iopub.execute_input":"2021-05-29T12:53:40.172087Z","iopub.status.idle":"2021-05-29T12:53:40.284407Z","shell.execute_reply.started":"2021-05-29T12:53:40.172056Z","shell.execute_reply":"2021-05-29T12:53:40.283196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. One Hot Encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\none_hot_encode_var =  data[cols]\none_hot = OneHotEncoder()\n\nfor col in cols:\n    enc = one_hot.fit_transform(one_hot_encode_var[col].values.reshape(-1,1)).toarray()\n    df_enc = pd.DataFrame(enc, columns = [col + str('_') + str(one_hot.categories_[0][i]) for i in range(len(one_hot.categories_[0]))])\n    df_enc = df_enc.iloc[:,1:]\n    one_hot_encode_var = pd.concat([one_hot_encode_var, df_enc], axis = 1)\n    \none_hot_encode_var.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:42.809287Z","iopub.execute_input":"2021-05-29T12:53:42.809682Z","iopub.status.idle":"2021-05-29T12:53:42.963501Z","shell.execute_reply.started":"2021-05-29T12:53:42.809658Z","shell.execute_reply":"2021-05-29T12:53:42.962621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Frequency Encoding","metadata":{}},{"cell_type":"code","source":"freq_encode_var =  data[cols]\n\nfor col in cols:\n    freq = freq_encode_var.groupby(col).size() / len(freq_encode_var)\n    freq_encode_var.loc[:,f'{col}_ENCODED'] = freq_encode_var[col].map(freq)\n    \nfreq_encode_var.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:45.252605Z","iopub.execute_input":"2021-05-29T12:53:45.253086Z","iopub.status.idle":"2021-05-29T12:53:45.3374Z","shell.execute_reply.started":"2021-05-29T12:53:45.253049Z","shell.execute_reply":"2021-05-29T12:53:45.336574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Leave One Out Encoding","metadata":{}},{"cell_type":"code","source":"from category_encoders import *","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:48.520985Z","iopub.execute_input":"2021-05-29T12:53:48.521278Z","iopub.status.idle":"2021-05-29T12:53:48.52677Z","shell.execute_reply.started":"2021-05-29T12:53:48.521255Z","shell.execute_reply":"2021-05-29T12:53:48.525679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"leave_one_out_encode_var = data[['CHANNEL_CODE', 'OCCUPATION', 'IS_LEAD']]\n\ny = leave_one_out_encode_var.IS_LEAD\nX = leave_one_out_encode_var.iloc[:,:-1]\nenc = LeaveOneOutEncoder(cols=cols).fit(X, y)\nenc_dataset = enc.transform(X)\n\n\nenc_dataset.columns = [_c.upper() + '_ENCODED' for _c in enc_dataset.columns]\nleave_one_out_encode_var = pd.concat([leave_one_out_encode_var,enc_dataset], axis = 1)\nleave_one_out_encode_var.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:48.703717Z","iopub.execute_input":"2021-05-29T12:53:48.703991Z","iopub.status.idle":"2021-05-29T12:53:48.962335Z","shell.execute_reply.started":"2021-05-29T12:53:48.703967Z","shell.execute_reply":"2021-05-29T12:53:48.960978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Helmert Encoding","metadata":{}},{"cell_type":"code","source":"helmert_encode_var = data[['CHANNEL_CODE', 'OCCUPATION', 'IS_LEAD']]\n\ny = helmert_encode_var.IS_LEAD\nX = helmert_encode_var.iloc[:,:-1]\nenc = HelmertEncoder(cols=cols,  handle_unknown='value', handle_missing='value').fit(X, y)\nenc_dataset = enc.transform(X)\n\n\nenc_dataset.columns = [_c.upper() + '_ENCODED' for _c in enc_dataset.columns]\nhelmert_encode_var = pd.concat([helmert_encode_var,enc_dataset], axis = 1)\nhelmert_encode_var.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:53:51.986295Z","iopub.execute_input":"2021-05-29T12:53:51.986646Z","iopub.status.idle":"2021-05-29T12:53:52.329897Z","shell.execute_reply.started":"2021-05-29T12:53:51.986622Z","shell.execute_reply":"2021-05-29T12:53:52.329334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### All encoding has their pros and cons which I will cover in a different Kernel. \n\n### *If found helpful, please leave an UPVOTE üëç*","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}