{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Understand data\nProblem Statement:\n\nConsider a real estate company that has a dataset containing the prices of properties in the Delhi region. It wishes to use the data to optimise the sale prices of the properties based on important factors such as area, bedrooms, parking, etc.\n\nEssentially, the company wants â€”\n\nTo identify the variables affecting house prices, e.g. area, number of rooms, bathrooms, etc.\n\nTo create a linear model that quantitatively relates house prices with variables such as number of rooms, area, number of bathrooms, etc.\n\nTo know the accuracy of the model, i.e. how well these variables can predict house prices.\n\n\n## 1. Import libraries and data set"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport warnings\nwarnings.filterwarnings\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/Housing.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look for more info on data set \ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" We can see there are no null values in our data set. But, there are 7 features with object type.\n "},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#first get all features with data type as object\ndata.columns[data.dtypes == object]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert all nominal data to numerical data\ndata['mainroad'] = data['mainroad'].map({'yes':1,'no':0})\ndata['guestroom'] = data['guestroom'].map({'yes':1,'no':0})\ndata['basement'] = data['basement'].map({'yes':1,'no':0})\ndata['hotwaterheating'] = data['hotwaterheating'].map({'yes':1,'no':0})\ndata['airconditioning'] = data['airconditioning'].map({'yes':1,'no':0})\ndata['prefarea'] = data['prefarea'].map({'yes':1,'no':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check furnishingstatus values\ndata.furnishingstatus.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variable 'furnishingstatus' had three levels. We need to convert it to integer."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating a dummy variable for 'furnishingstatus'\nfurnishingstatus = pd.get_dummies(data['furnishingstatus'])\nfurnishingstatus.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we don't need 3 columns.\n# we can use drop_first = True to drop the first column from furnishingstatus df.\nfurnishingstatus = pd.get_dummies(data['furnishingstatus'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding the results to the master dataframe\ndata = pd.concat([data,furnishingstatus],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's see the head of our dataframe.\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping furnishingstatus as we have created the dummies for it\ndata.drop(['furnishingstatus'],axis=1,inplace=True)\n\n# Now let's see the head of our dataframe.\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating a new variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us create the new metric and assign it to \"areaperbedroom\"\ndata['areaperbedroom'] = data['area']/data['bedrooms']\n# Metric:bathrooms per bedroom\ndata['bbratio'] = data['bathrooms']/data['bedrooms']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rescaling the Features\n\nwe can rescale using normalization(min-max scaling)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize (x): \n    return ( (x-np.min(x))/ (max(x) - min(x)))\n                                            \n                                              \n# applying normalize ( ) to all columns \ndata = data.apply(normalize) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Split data into train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Putting feature variable to X\nX = data[data.columns[1:]]\n# Putting response variable to y\ny = data[data.columns[:1]]\n\n#random_state is the seed used by the random number generator, it can be any integer.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Feature selection\nFeature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 9\nlm = LinearRegression()\nrfe = RFE(lm, 9)             # running RFE\nrfe = rfe.fit(X_train, y_train)\nprint(rfe.support_)           # Printing the boolean results\nprint(rfe.ranking_)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build model using sklearn"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.tools.tools as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.regression.linear_model as sm\nlm = sm.OLS(y_train,X_train_rfe).fit()   # Running the linear model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nX = data.drop(['price','area','bedrooms','stories','basement','semi-furnished','areaperbedroom'], axis=1)\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif.sort_values(by='VIF Factor', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's use our model to make predictions.\n\n# Creating X_test_6 dataframe by dropping variables from X_test\nX_test_rfe = X_test[col]\n\n# Adding a constant variable \nX_test_rfe = sm.add_constant(X_test_rfe)\n\n# Making predictions\ny_pred = lm.predict(X_test_rfe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's check how well our model is able to make predictions.\n\n# Importing the required libraries for plots.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual and Predicted\nc = [i for i in range(1,165,1)] # generating index \nfig = plt.figure() \nplt.plot(c,y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\") #Plotting Actual\nplt.plot(c,y_pred, color=\"red\",  linewidth=2.5, linestyle=\"-\") #Plotting predicted\nfig.suptitle('Actual and Predicted', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                               # X-label\nplt.ylabel('Housing Price', fontsize=16)                       # Y-label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error terms\nc = [i for i in range(1,165,1)]\nfig = plt.figure()\nplt.plot(c,y_test.price - y_pred, color=\"blue\", linewidth=2.5, linestyle=\"-\")\nfig.suptitle('Error Terms', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                      # X-label\nplt.ylabel('ytest-ypred', fontsize=16)                # Y-label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)                          # Y-label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the error terms to understand the distribution.\nfig = plt.figure()\nsns.distplot((y_test.price-y_pred),bins=50)\nfig.suptitle('Error Terms', fontsize=20)                  # Plot heading \nplt.xlabel('y_test-y_pred', fontsize=18)                  # X-label\nplt.ylabel('Index', fontsize=16)                          # Y-label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's check the Root Mean Square Error of our model.\nimport numpy as np\nfrom sklearn import metrics\nprint('RMSE :', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}