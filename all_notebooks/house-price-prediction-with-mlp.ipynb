{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\nfrom tensorflow.keras.models import model_from_json, load_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nprint(tf.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    if filenames:\n        train_csv_path = os.path.join(dirname, filenames[0])\n        test_csv_path = os.path.join(dirname, filenames[1])\n        sample_submission_csv_path = os.path.join(dirname, filenames[2])\n\nprint(train_csv_path)\nprint(test_csv_path)\nprint(sample_submission_csv_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's Load Train data and analyze about Columns in dataframe"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(train_csv_path)\ndf_cols = df_train.columns.values.tolist()\nprint(df_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model 1 : Only using Numerical Feature columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['POSTED_BY','BHK_OR_RK','ADDRESS']\nfor col in categorical_columns:\n    df_cols.remove(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = df_train[df_cols[-1]].values\nX = df_train[df_cols[:-1]].values\nX, Y = shuffle(X, Y)\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epoches = 80\nbatch_size = 128\nval_split = 0.15","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standard Normalize Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"Xscalar = StandardScaler()\nXscalar.fit(X)\n\nXtrain = Xscalar.transform(X)\nYtrain = Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Yscalar = StandardScaler()\n# Yscalar.fit(Y.reshape(-1, 1))\n\n# Ytrain = Yscalar.transform(Y.reshape(-1, 1))\n# Ytrain = Ytrain.squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classifier1():\n    n_features = Xtrain.shape[1]\n    inputs = Input(shape=(n_features,))\n    x = Dense(512, activation='relu')(inputs)\n    x = Dense(256, activation='relu')(x)\n#     x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    outputs = Dense(1)(x)\n    model = Model(inputs, outputs)\n    \n    model.compile(\n        loss='mse',\n        optimizer='adam'\n    )\n    history = model.fit(\n                    Xtrain,\n                    Ytrain,\n                    batch_size=batch_size,\n                    epochs=num_epoches,\n                    validation_split=val_split\n                    )\n    return history, model\n    \ndef plot_metrics(history):\n    loss_train = history.history['loss']\n    loss_val = history.history['val_loss']\n    \n    loss_train = np.cumsum(loss_train) / np.arange(1,num_epoches+1)\n    loss_val = np.cumsum(loss_val) / np.arange(1,num_epoches+1)\n    plt.plot(loss_train, 'r', label='Training loss')\n    plt.plot(loss_val, 'b', label='validation loss')\n    plt.title('Training and Validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1, model1 = classifier1()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics(history1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(test_csv_path)\ndf_cols_test = df_test.columns.values.tolist()\n\ncategorical_columns = ['POSTED_BY','BHK_OR_RK','ADDRESS']\nfor col in categorical_columns:\n    df_cols_test.remove(col)\ndf_cols_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest = df_test[df_cols_test].values\nXtest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest = Xscalar.transform(Xtest)\nYpred = model1.predict(Xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(sample_submission_csv_path)\nsubmission_df['TARGET(PRICE_IN_LACS)'] = Ypred\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_csv_path = '/kaggle/working/submission.csv'\nsubmission_df.to_csv(submission_csv_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}