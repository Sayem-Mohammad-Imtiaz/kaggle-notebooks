{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Libraries \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport os\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the input images and putting them into a numpy array\ndata=[]\nlabels=[]\n\nheight = 32\nwidth = 32\nchannels = 3\nclasses = 43\n\nfor i in range(classes) :\n    path = \"../input/gtsrb-german-traffic-sign/train/{0}/\".format(i)\n    \n    Class=os.listdir(path)\n    \n    for a in Class:\n        \n        image=cv2.imread(path + a)\n        image_from_array = Image.fromarray(image, 'RGB')  \n        size_image = image_from_array.resize((height, width))\n\n        data.append(np.array(size_image))\n        labels.append(i)\n        \n        \ndata = np.array(data)\nlabels = np.array(labels)\n\n#normalising data to values between 0 to 1.\n\ndata = data.astype('float32')/255\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading test data\ny_test = pd.read_csv(\"../input/gtsrb-german-traffic-sign/Test.csv\")\npaths =  y_test['Path'].as_matrix()\ny_test = y_test['ClassId'].values\n\ntest_data=[]\n\nfor p in paths:\n    image = cv2.imread('../input/gtsrb-german-traffic-sign/test/'+p.replace('Test/', ''))\n    image_from_array = Image.fromarray(image, 'RGB')\n    \n    size_image = image_from_array.resize((height, width))\n    test_data.append(np.array(size_image))\n\nX_test=np.array(test_data)\n#normalising test data\nX_test = X_test.astype('float32')/255 \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the train and test classes distribution\nfig, axs = plt.subplots(1, 2, sharex=True, figsize=(30, 10))\naxs[0].set_title('Train classes distribution')\naxs[0].set_xlabel('Class')\naxs[0].set_ylabel('Count')\naxs[1].set_title('Test classes distribution')\naxs[1].set_xlabel('Class')\naxs[1].set_ylabel('Count')\n\nsns.countplot(labels, ax=axs[0], color='blue')\nsns.countplot(y_test, ax=axs[1], color='red')\naxs[0].set_xlabel('Class ID');\naxs[1].set_xlabel('Class ID');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Spliting the images into train and validation sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(data,\n                                                    labels,\n                                                    test_size=0.25,\n                                                    random_state=42)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing sample images from the dataset\n\ndef show_images(images, labels, pred_labels=[], amount=16):\n    ids = np.random.randint(len(images), size=amount)\n    \n    plt.figure(figsize=(24,10))\n    for i, id in enumerate(ids):\n        plt.subplot(int(amount/8)+1, 8,1+i)\n        plt.axis('off')\n        if(len(pred_labels)):\n            plt.title(\"true- \" + str(labels[id]) + \"  pred- \" + str(pred_labels[id]))\n        else:\n            plt.title(str(labels[id]))\n        plt.imshow(images[id])\n    \nprint(\"Train images\")\nshow_images(X_train, y_train, amount=24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using one hote encoding for the train and validation labels\nfrom keras.utils import to_categorical\n\ny_train = to_categorical(y_train, 43)\ny_val = to_categorical(y_val, 43)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building the CNN model\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(4, 4), activation='relu', input_shape=X_train.shape[1:]))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(4, 4), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(43, activation='softmax'))\n\n#Compilation of the model\nmodel.compile(\n    loss='categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using ten epochs for the training and saving the accuracy for each epoch\nepochs = 10\nhistory = model.fit(X_train, y_train, batch_size=24, epochs=epochs, validation_data=(X_val, y_val))\n\n#Ploting accuracy and loss values vs epochs for train and val data\n\nplt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy with the test data\ntest_pred = model.predict_classes(X_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confussion matrix \nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=75) \n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n            plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \nclass_names = range(43)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the output in a confusion matrix. \nplt.figure(figsize=(15,15))\ncm = confusion_matrix(y_test, test_pred)\n\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#showing few predicted images with their true values\n\nshow_images(X_test, y_test, test_pred, 32)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}