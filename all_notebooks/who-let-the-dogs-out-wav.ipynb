{"cells":[{"metadata":{},"cell_type":"markdown","source":"#Codes from Eu Jin Lok  https://www.kaggle.com/ejlok1/audio-emotion-part-5-data-augmentation/notebook"},{"metadata":{},"cell_type":"markdown","source":"![](https://media2.giphy.com/media/CtCjbVbZGY5zi/200.webp?cid=790b76113d6cccd61fcd7d2d29d9f99e86fdb0a52f18014a&rid=200.webp)"},{"metadata":{},"cell_type":"markdown","source":"Who let the dogs out?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Other  \nimport librosa\nimport librosa.display\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport seaborn as sns\nimport glob \nimport os\nfrom tqdm import tqdm\nimport pickle\nimport IPython.display as ipd  # To play sound in the notebook","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take one audio file and run it through all the different types to get a feel for how they work. From there we'll then take a few forward for our model training. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use one audio file in previous parts again\nfname = '/kaggle/input/urbansound8k/fold10/30344-3-0-4.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Paly it again to refresh our memory\nipd.Audio(data, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Augmentations Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"def noise(data):\n    \"\"\"\n    Adding White Noise.\n    \"\"\"\n    # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n    noise_amp = 0.05*np.random.uniform()*np.amax(data)   # more noise reduce the value to 0.5\n    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add static noise in the background."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = noise(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shift Method"},{"metadata":{"trusted":true},"cell_type":"code","source":"def shift(data):\n    \"\"\"\n    Random Shifting.\n    \"\"\"\n    s_range = int(np.random.uniform(low=-5, high = 5)*1000)  #default at 500\n    return np.roll(data, s_range)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = shift(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We go to stretch, Thanks Eu Jin Lok @ejlok1"},{"metadata":{"trusted":true},"cell_type":"code","source":"def stretch(data, rate=0.8):\n    \"\"\"\n    Streching the Sound. Note that this expands the dataset slightly\n    \"\"\"\n    data = librosa.effects.time_stretch(data, rate)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = stretch(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pitch, this method accentuates the high pitch notes."},{"metadata":{"trusted":true},"cell_type":"code","source":"def pitch(data, sample_rate):\n    \"\"\"\n    Pitch Tuning.\n    \"\"\"\n    bins_per_octave = 12\n    pitch_pm = 2\n    pitch_change =  pitch_pm * 2*(np.random.uniform())   \n    data = librosa.effects.pitch_shift(data.astype('float64'), \n                                      sample_rate, n_steps=pitch_change, \n                                      bins_per_octave=bins_per_octave)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pitch(data, sampling_rate)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dynamic change"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dyn_change(data):\n    \"\"\"\n    Random Value Change.\n    \"\"\"\n    dyn_change = np.random.uniform(low=-0.5 ,high=7)  # default low = 1.5, high = 3\n    return (data * dyn_change)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dyn_change(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def speedNpitch(data):\n    \"\"\"\n    peed and Pitch Tuning.\n    \"\"\"\n    # you can change low and high here\n    length_change = np.random.uniform(low=0.8, high = 1)\n    speed_fac = 1.2  / length_change # try changing 1.0 to 2.0 ... =D\n    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n    minlen = min(data.shape[0], tmp.shape[0])\n    data *= 0\n    data[0:minlen] = tmp[0:minlen]\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = speedNpitch(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://media.tenor.com/images/afb854c4633cad8c07acc30d357ed1f6/tenor.gif)"},{"metadata":{},"cell_type":"markdown","source":"Kaggle Notebook Runner: Mar√≠lia Prata @mpwolke "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}