{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/glass-quality/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/glass-quality/Test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There is no missing value\n- There is no object type column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Findings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1.Huge diff in this column in Training and Test dataset\n\n- Pixel_area \n\nTrain\n\n**mean** 1903.402798\t______ **std Dev**  3839.156721\n \nTest\n\n**mean** 2368.331046\t______ **std Dev**   7376.877610\t","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.Pixel_area and log_area have almost same mean and std","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We'll see how to use them as we proceed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.kurt()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring each Column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. grade_A_Component_1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['grade_A_Component_1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.countplot(data=train,x='grade_A_Component_1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Vs Target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train.groupby(['grade_A_Component_1','class'])['class'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='grade_A_Component_1',hue='class')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"grade_A_Component_1\" zero has more tendancy for class 1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. grade_A_Component_2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['grade_A_Component_2'].value_counts()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the count is same as the grade_A_Component_1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train.groupby(['grade_A_Component_2','class'])['class'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='grade_A_Component_2',hue='class')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"grade_A_Component_2\" ONE has more tendancy for class 1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Conlusion : grade_A_Component_1 and grade_A_Component_2 are just opposite of one another, thus we just need to keep one","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### #2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.drop(\"grade_A_Component_2\",axis=1,inplace=True)\n# test.drop(\"grade_A_Component_2\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. max_luminosity -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['max_luminosity'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['max_luminosity'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of max_luminosity\ntrain['max_luminosity'].plot(kind='hist',figsize=(13,8),bins=100,edgecolor='k',\n                              title='max_luminosity Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. thickness -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['thickness'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['thickness'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of loan amount\ntrain['thickness'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n                              title='thickness Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. xmin -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['xmin'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train['xmin'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['xmin'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of loan amount\ntrain['xmin'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n                              title='xmin Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. xmax -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['xmax'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['xmax'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of loan amount\ntrain['xmax'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n                              title='xmax Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. ymin -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ymin'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['ymin'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of loan amount\ntrain['ymin'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n                              title='ymin Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **All are unique values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 8. ymax -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ymax'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['ymax'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of loan amount\ntrain['ymax'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n                              title='ymax Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All are unique values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 9. pixel_area -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['pixel_area'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['pixel_area'].head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of pixel_area \ntrain['pixel_area'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n                              title='pixel_area Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['pixel_area'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. log_area -- continous","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_area'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the distribution of log_area \ntrain['log_area'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n                              title='log_area Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"log_area and pixel_area Both are same column take any one.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.scatterplot(data=train,x='pixel_area',y='log_area');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. x_component_1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['x_component_1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_1',hue='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train.groupby(['x_component_1','class'])['class'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n**if \"x_component_1\"is ONE then only one class is possible i.e 1** \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 12. x_component_2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['x_component_2'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_2',hue='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train.groupby(['x_component_2','class'])['class'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conlusion\n**If x_component_2 is ONE then only one class is possible**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 13. x_component_3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['x_component_3'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_3',hue='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train.groupby(['x_component_3','class'])['class'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conlusion\n**If x_component_3 is ONE then only one class is possible**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 14. x_component_4","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['x_component_4'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_4',hue='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train.groupby(['x_component_4','class'])['class'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_4')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conlusion\n**If x_component_4 is ONE then only one class is possible**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 15. x_component_5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['x_component_5'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_5',hue='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train.groupby(['x_component_5','class'])['class'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train,x='x_component_5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conlusion\n1. **If x_component_5 is ONE then only one class is possible i,e 1**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 16. class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the ratio of the two classes is {0:0.3f}\".format(887/471))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for duplicate Entries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for duplicated data\ntrain.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ------------------------------------------------------DONE EXPLORING COLUMNS--------------------------------------------------------","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# So let's sum all the findings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. Huge diff in Pixel_area column in Training and Test dataset\n\n2. grade_A_Component_1 and grade_A_Component_2 are just opposite of one another, thus we just need to keep one\n\n3. ymin all values are unique\n\n4. ymax all values are unique\n\n5. Pixel_area and log_area have almost same\n   Thus Keeping only log_area ( since it has decimal precission)\n\n6. if \"x_component_1\" is ONE then only one class is possible i.e 1\n\n7. if \"x_component_2\" is ONE then only one class is possible i.e 1\n\n8. if \"x_component_3\" is ONE then only one class is possible i.e 1\n\n9. if \"x_component_4\" is ONE then only one class is possible i.e 1\n\n10. if \"x_component_5\" is ONE then only one class is possible i.e 1\n\n11. The ratio of the two classes is 1.8 in Target Variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Dropping ymin and ymax","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### #1 Dont know what to do","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# -------------","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### #2 Grade1 = 1 / Grade2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Already Done by dropping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### #3 Dropping Ymin","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.drop(\"ymin\",axis=1,inplace=True)\n# test.drop(\"ymin\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### #4 Dropping Ymax","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.drop(\"ymax\",axis=1,inplace=True)\n# test.drop(\"ymax\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### #5 Dropping Pixel ARea","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.drop(\"pixel_area\",axis=1,inplace=True)\n# test.drop(\"pixel_area\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### #6 #7 #8 #9 #10","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Known RECORDS IN training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"one = train[train['x_component_1']==1]\none = np.array(one.index)\n# one\n\ntwo = train[train['x_component_2']==1]\ntwo = np.array(two.index)\n# two\n\nthree = train[train['x_component_3']==1]\nthree = np.array(three.index)\n# three\n\nfour = train[train['x_component_4']==1]\nfour = np.array(four.index)\n# four\n\nfive = train[train['x_component_5']==1]\nfive = np.array(five.index)\n# five\n\n\nknown_index_train = []\n\nfor i in range(len(one)):\n    known_index_train.append(one[i])\n    \nfor i in range(len(two)):\n    known_index_train.append(two[i])\n    \nfor i in range(len(three)):\n    known_index_train.append(three[i])\n    \nfor i in range(len(four)):\n    known_index_train.append(four[i])\n    \nfor i in range(len(five)):\n    known_index_train.append(five[i])\n    \n    \nprint(len(known_index_train))\nknown_train_set = set(known_index_train)\nprint(len(known_train_set))      # f**k almost 609 out of 1358 are supposed to belong class \"1\"\n\n\nknown_index_train = np.array(known_index_train)\nknown_index_train.sort()\n# known_index_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Known Records in TESTING Dataset\n##### i.e If any of the five column has a value == 1 then Target class = \"1\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"one = test[test['x_component_1']==1]\none = np.array(one.index)\n# one\n\ntwo = test[test['x_component_2']==1]\ntwo = np.array(two.index)\n# two\n\nthree = test[test['x_component_3']==1]\nthree = np.array(three.index)\n# three\n\nfour = test[test['x_component_4']==1]\nfour = np.array(four.index)\n# four\n\nfive = test[test['x_component_5']==1]\nfive = np.array(five.index)\n# five\n\nknown_index_test = []\n\nfor i in range(len(one)):\n    known_index_test.append(one[i])\n    \nfor i in range(len(two)):\n    known_index_test.append(two[i])\n    \nfor i in range(len(three)):\n    known_index_test.append(three[i])\n    \nfor i in range(len(four)):\n    known_index_test.append(four[i])\n    \nfor i in range(len(five)):\n    known_index_test.append(five[i])\n    \n    \nprint(len(known_index_test))\nknown_set_test = set(known_index_test)\nknown_index_test = np.array(known_index_test)\nknown_index_test.sort()\nprint(len(known_set_test))  \n\nprint(\"Thus out of 583 we know the classes of {0} values i.e {1:0.03f} percentage from the testing dataset\".format(257,(257/583)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NEW FEATURE about the x_component","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"known_train_series = []\nfor i in range(1358):\n    known_train_series.append(3)\n\n    \nknown_test_series = []\nfor i in range(583):\n    known_test_series.append(3)\n    \n    \nfor i in range(1358):\n    if i in known_index_train:         # if that element exist in the indexes we know, then\n        known_train_series[i] = 1                           #we will assign it as ONE\n    else:\n        known_train_series[i]= 2                            #and rest as TWO        \n        \nfor i in range(583):\n    if i in known_index_test:\n        known_test_series[i] = 1\n    else:\n        known_test_series[i]= 2\n        \nknown_train_series = np.array(known_train_series)\nknown_test_series = np.array(known_test_series)\n\n\ntrain['known'] =known_train_series\ntest['known'] =known_test_series\n\nprint(train['known'].value_counts())                   #i.e we are 100% sure about 609 values\n\n\nprint(test['known'].value_counts()  )                 #i.e we are 100% sure about 257 values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## #11 Balancing the classes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['class'],axis=1)\ny = train['class']\n\nfrom imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state = 2,sampling_strategy='all') \nX, y = sm.fit_sample(X, y) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CORELATION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can calculate the Pearson correlation coefficient between every variable and the target using the .corr dataframe method.\n\nThe correlation coefficient gives us an idea of possible relationships within the data. Some general interpretations of the absolute value of the correlation coefficent are:\n\n1. .00 -.19 “very weak”\n2. .20 -.39 “weak”\n3. .40 -.59 “moderate”\n4. .60 -.79 “strong”\n5. .80 -1.0 “very strong”","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(X,y,left_index=True,right_index=True)\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cor = train.corr()\nplt.figure(figsize=(25,13))\nsns.heatmap(cor,annot=True,cmap='plasma',linecolor='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making new features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Log transfromations\n# train['max_luminosity'] = np.log1p(train['max_luminosity'])\n# train['log_thickness'] = np.log1p(train['thickness'])\n# train['ymin'] = np.log1p(train['ymin'])\n# train['ymax'] = np.log1p(train['ymax'])\n# train['log_area'] = np.log1p(train['log_area'])\n\n# #Log transfromations for Test\n\n# test['max_luminosity'] = np.log1p(test['max_luminosity'])\n# test['log_thickness'] = np.log1p(test['thickness'])\n# test['ymin'] = np.log1p(train['ymin'])\n# test['ymax'] = np.log1p(train['ymax'])\n# test['log_area'] = np.log1p(train['log_area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Log transfromations\ntrain['log_max_luminosity'] = np.log1p(train['max_luminosity'])\ntrain['log_thickness'] = np.log1p(train['thickness'])\ntrain['log_ymin'] = np.log1p(train['ymin'])\ntrain['log_ymax'] = np.log1p(train['ymax'])\ntrain['log_log_area'] = np.log1p(train['log_area'])\n\n#Log transfromations for Test\n\ntest['log_max_luminosity'] = np.log1p(test['max_luminosity'])\ntest['log_thickness'] = np.log1p(test['thickness'])\ntest['log_ymin'] = np.log1p(train['ymin'])\ntest['log_ymax'] = np.log1p(train['ymax'])\ntest['log_log_area'] = np.log1p(train['log_area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ratio_of_xmin_ymin'] = train['xmin'] / train['log_ymin']\ntrain['ratio_of_xmin_ymin'] = np.log1p(train['ratio_of_xmin_ymin'])\ntrain['ratio_of_xmax_ymax'] = train['xmax'] / train['log_ymax']\ntrain['ratio_of_xmax_ymax'] = np.log1p(train['ratio_of_xmax_ymax'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['ratio_of_xmin_ymin'] = test['xmin'] / test['log_ymin']\ntest['ratio_of_xmin_ymin'] = np.log1p(test['ratio_of_xmin_ymin'])\ntest['ratio_of_xmax_ymax'] = test['xmax'] / train['log_ymax']\ntest['ratio_of_xmax_ymax'] = np.log1p(test['ratio_of_xmax_ymax'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # #Check for the distribution of loan amount\n# test['ratio_of_xmin_ymin'].plot(kind='hist',figsize=(10,6),bins=100,edgecolor='k',\n#                               title='ratio_of_xmax_ymax Distribution').autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### now checking skewness and kurt","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.kurt()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### BackuP copy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_test = test.copy()\ntemp_train = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test = temp_test\n# train = temp_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ------------------------------------------------Train/Test Split--------------------------------------------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y,y0):\n    return log_loss(y,y0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(set(train.columns)-set(['class']))\ntarget = 'class'\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom catboost import CatBoostClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import ExtraTreesClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split,cross_val_predict\nfrom sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cross_valid(model,train,features,target,cv=3):\n    results = cross_val_predict(model, train[features], train[target], method=\"predict_proba\",cv=cv)\n    return metric(train[target],results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [lgb.LGBMClassifier(), xgb.XGBClassifier(), GradientBoostingClassifier(), \n#           LogisticRegression(max_iter=110), \n              RandomForestClassifier(),ExtraTreesClassifier(), \n#           CatBoostClassifier(),\n             ]\n\nfor i in models:\n    model = i\n    error = cross_valid(model,train,features,target,cv=10)\n    print(str(model).split(\"(\")[0], error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# error = cross_valid(CatBoostClassifier(),train,features,target,cv=10)\n# print(error)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Selective Scaling ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# cat_features = ['grade_A_Component_1','grade_A_Component_2', 'x_component_1', 'x_component_2',\n#                 'x_component_3', 'x_component_4', 'x_component_5','known']\n# num_features = ['max_luminosity', 'thickness', 'xmin', 'xmax', 'ymin', 'ymax', 'pixel_area', 'log_area']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # train_c = train.copy()\n# from sklearn.preprocessing import StandardScaler\n# std = StandardScaler()\n# train_scaled_num = std.fit_transform(train[num_features])\n# test_scaled_num = std.transform(test[num_features])\n\n\n# train[num_features] = pd.DataFrame(train_scaled_num, columns=num_features)\n# test[num_features] = pd.DataFrame(test_scaled_num, columns=num_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# X and y, split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['class'],axis=1)\ny = train['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Transforming Test Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_test = scaler.transform(test)    # to be run only once","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ntemp_pca = PCA(n_components=None)\nX_temp =temp_pca.fit_transform(X_train)\nvariance = temp_pca.explained_variance_ratio_\nprint(variance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.plot(np.cumsum(temp_pca.explained_variance_ratio_))\nplt.xlim(0,21,1)\nplt.xlabel('Number of components')\nplt.ylabel('Cumulative explained variance')\nplt.show()\n# ploting cum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pca = PCA(n_components=13)\n# X_train =pca.fit_transform(X_train)\n# X_test = pca.transform(X_test)\n# test = pca.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBClassifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### HyperOpt XGBClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def model(params):\n#     clf = XGBClassifier(**params)\n#     return cross_val_score(clf, X, y).mean()\n\n\n# space = {\n#     'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.2, 0.05)),\n#     'max_depth':        hp.choice('max_depth',        np.arange(5, 20, 1, dtype=int)),\n# #     'num_leaves': hp.choice('num_leaves', np.arange(16, 40, 2, dtype=int)),\n# #     'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n#     'n_estimators':     hp.choice('n_estimators', np.arange(100,1000,10, dtype=int)),\n#     'random_state': 51,\n#     'boosting_type': 'gbdt'\n# }\n\n\n# def objective(params):\n#     acc = model(params)\n#     return {'loss': -acc, 'status': STATUS_OK}\n\n# trials = Trials()\n# best = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=trials)\n\n# print(best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from xgboost import XGBClassifier\n\n# clf= XGBClassifier(\n#                    learning_rate=0.06, \n#                    n_estimators=400,\n#                    max_depth=14,\n# #                     objective= 'binary:logistic',\n#                   )\n\n# clf.fit(X_train, y_train)\n\n# y_pred = clf.predict_proba(X_test)\n# print('XGboost log_loss {}'. format(log_loss(y_test, y_pred)))\n# clf.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ExtraTreesClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_estimators=100,   ##\n#     criterion='gini',  ## entropy\n#     max_depth=None,\n#     min_samples_split=2, ##The minimum number of samples required to split an internal node:\n#     min_samples_leaf=1,  ##The minimum number of samples required to be at a leaf node.\n#     min_weight_fraction_leaf=0.0,  #float\n#     max_features='auto',  #sqrt , log2\n#     max_leaf_nodes=None,  # If None then unlimited number of leaf nodes.\n#     min_impurity_decrease=0.0,\n#     min_impurity_split=None,\n#     bootstrap=False,\n#     oob_score=False,\n#     n_jobs=None,\n#     random_state=21,\n#     verbose=0,\n#     warm_start=False,  #bool\n#     class_weight=None,\n#     ccp_alpha=0.0,\n#     max_samples=None,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(params):\n    clf = ExtraTreesClassifier(**params)\n    return cross_val_score(clf, X, y).mean()\n\n\nspace = {\n    'n_estimators': hp.choice('n_estimators', np.arange(100, 300, 10, dtype=int)),\n#     'max_depth':    hp.choice('max_depth', np.arange(5, 25, 1, dtype=int)),\n    'min_samples_split' : hp.choice('min_samples_split', np.arange(2, 10, 1, dtype=int)),\n    'min_samples_leaf' : hp.choice('min_samples_leaf', np.arange(1, 10, 1, dtype=int)),\n    'max_features':'auto', #sqrt,log2\n    'random_state':21,\n    'warm_start':False,\n}\n\n\ndef objective(params):\n    acc = model(params)\n    return {'loss': -acc, 'status': STATUS_OK}\n\ntrials = Trials()\nbest = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=trials)\n\nprint(best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nclf= ExtraTreesClassifier(\n                    n_estimators=105,\n#                     max_depth= 19,\n                    min_samples_split= 2,\n#                     min_samples_leaf= 1,\n                    max_features=  'sqrt',\n                    random_state= 21   ,\n                    warm_start=  False\n                    )\n\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict_proba(X_test)\nprint('ExtraTreesClassifier log_loss {}'. format(log_loss(y_test, y_pred)))\nclf.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ExtC = ExtraTreesClassifier()\n# from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n# kfold = StratifiedKFold(n_splits=10)\n\n# ## Search grid for optimal parameters\n# ex_param_grid = {\"max_depth\": [None],\n# \"min_samples_split\": [2, 3, 10],\n# \"min_samples_leaf\": [1, 3, 10],\n# \"bootstrap\": [False],\n# \"n_estimators\" :[100,300],\n# \"criterion\": [\"gini\"]}\n\n\n# gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n\n# gsExtC.fit(X_train,y_train)\n\n# ExtC_best = gsExtC.best_estimator_\n\n# # Best score\n# gsExtC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ExtC_best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred = gsExtC.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('ExtraTreesClassifier log_loss {}'. format(log_loss(y_test, y_pred)))\n# clf.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### HyperOpt for CatBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# def model(params):\n#     clf = CatBoostClassifier(**params)\n#     return cross_val_score(clf, X, y).mean()\n\n\n# space = {\n#     'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.2, 0.05)),\n#     'max_depth':        hp.choice('max_depth',        np.arange(5, 20, 1, dtype=int)),\n# #     'num_leaves': hp.choice('num_leaves', np.arange(16, 40, 2, dtype=int)),\n# # #     'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n# # #     'num_leaves':        hp.choice('num_leaves', 200, 400,5, dtype=int),\n#     'n_estimators':     hp.choice('n_estimators', np.arange(200,100,10, dtype=int)),\n# #     'random_state': 51,\n# #     'boosting_type': 'gbdt'\n# }\n\n\n# def objective(params):\n#     acc = model(params)\n#     return {'loss': -acc, 'status': STATUS_OK}\n\n# trials = Trials()\n# best = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=trials)\n\n\n# print(best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from catboost import CatBoostClassifier\n\n# clf= CatBoostClassifier(\n#                          depth=6,\n#                          random_seed=42, \n#                          iterations=1000, \n#                          learning_rate=0.07,\n#                          leaf_estimation_iterations=1,\n#                          l2_leaf_reg=1, \n#                          bootstrap_type='Bayesian', \n#                          bagging_temperature=1, \n#                          random_strength=1,\n#                          od_type='Iter', \n#                          od_wait=200,\n#                         )\n\n# clf.fit(X_train, y_train)\n\n# y_pred = clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('CatBoostClassifier log_loss {}'. format(log_loss(y_test, y_pred)))\n# clf.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cross_val_score Accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nacc = cross_val_score(estimator=clf,X=X,y=y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(acc)\nprint(acc.mean())\nprint(acc.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred, labels=[1, 2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#               precision    recall  f1-score   support\n\n#            1       0.93      0.88      0.90        90\n#            2       0.88      0.93      0.91        88\n\n#     accuracy                           0.90       178\n#    macro avg       0.91      0.90      0.90       178\n# weighted avg       0.91      0.90      0.90       178","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Training on whole dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Predecting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict_proba(scaled_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[2]  # belongs to class 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred[2][0])\nprint(y_pred[2][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count =0\nfor i in range(583):\n    if y_pred[i][1]>0.5:   # counting class 2 predictions\n        count +=1\n        \nprint(\"Class 2 \",count)\nprint(\"Class 1 \",583-count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(known_index_test)\n# known_index_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(583):\n    if i in known_index_test:\n        y_pred[i][0]=1\n        y_pred[i][1]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfor i in range(583):\n    if y_pred[i][1] > 0.95:\n        count += 1\n\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(583):\n#     if y_pred[i][0] >0.95:\n#         y_pred[i][0]=1\n#         y_pred[i][1]=0\n#     elif y_pred[i][1] >0.95:\n#         y_pred[i][0]=0\n#         y_pred[i][1]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_data_df = pd.DataFrame(y_pred,columns=['1','2'])\nresult_data_df.to_excel('submission.xlsx',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_data_df.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}