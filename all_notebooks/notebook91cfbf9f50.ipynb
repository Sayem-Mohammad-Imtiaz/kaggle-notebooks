{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T10:15:30.801304Z","iopub.execute_input":"2021-06-28T10:15:30.801632Z","iopub.status.idle":"2021-06-28T10:15:30.811508Z","shell.execute_reply.started":"2021-06-28T10:15:30.801594Z","shell.execute_reply":"2021-06-28T10:15:30.810359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:30.83731Z","iopub.execute_input":"2021-06-28T10:15:30.837647Z","iopub.status.idle":"2021-06-28T10:15:30.843613Z","shell.execute_reply.started":"2021-06-28T10:15:30.837615Z","shell.execute_reply":"2021-06-28T10:15:30.842843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Read CSV**","metadata":{}},{"cell_type":"code","source":"dt = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndt.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:30.844987Z","iopub.execute_input":"2021-06-28T10:15:30.845462Z","iopub.status.idle":"2021-06-28T10:15:30.870732Z","shell.execute_reply.started":"2021-06-28T10:15:30.845433Z","shell.execute_reply":"2021-06-28T10:15:30.870108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Prepare Data For Modeling**\n\n**Assign**\n\n* the 13 features to X,\n* the last column(target) to classification predictor Y.","metadata":{}},{"cell_type":"code","source":"X = dt.iloc[:, :-1].values\ny = dt.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:30.871936Z","iopub.execute_input":"2021-06-28T10:15:30.87231Z","iopub.status.idle":"2021-06-28T10:15:30.876363Z","shell.execute_reply.started":"2021-06-28T10:15:30.872274Z","shell.execute_reply":"2021-06-28T10:15:30.875666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split**\n\nThe data set into the Training and Test Set.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=10) #split the data","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:30.877544Z","iopub.execute_input":"2021-06-28T10:15:30.877956Z","iopub.status.idle":"2021-06-28T10:15:30.89298Z","shell.execute_reply.started":"2021-06-28T10:15:30.877916Z","shell.execute_reply":"2021-06-28T10:15:30.892052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalize** \n\nStandardizing the data will transform the data so that its distribution will have a mean of 0 and a standard deviation of 1.","metadata":{}},{"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:30.894294Z","iopub.execute_input":"2021-06-28T10:15:30.894556Z","iopub.status.idle":"2021-06-28T10:15:30.905971Z","shell.execute_reply.started":"2021-06-28T10:15:30.89453Z","shell.execute_reply":"2021-06-28T10:15:30.9051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create Model List**\nInitially, default models are assigned to best_models array. After tuning, default models are updated with tuned models.","metadata":{}},{"cell_type":"code","source":"best_models = []\nbest_models.append(['Logistic Regression',LogisticRegression(random_state=0)])\nbest_models.append(['SVM',SVC(random_state=0)])\nbest_models.append(['KNeigbors',KNeighborsClassifier()])\nbest_models.append(['GaussianNB',GaussianNB()])\nbest_models.append(['DecisionTree',DecisionTreeClassifier(random_state=0)])\nbest_models.append(['RandomForest',RandomForestClassifier(random_state=0)])\nbest_models.append(['MLPClassifier',MLPClassifier(random_state = 42, max_iter=1000)])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:30.907538Z","iopub.execute_input":"2021-06-28T10:15:30.9079Z","iopub.status.idle":"2021-06-28T10:15:30.917283Z","shell.execute_reply.started":"2021-06-28T10:15:30.90786Z","shell.execute_reply":"2021-06-28T10:15:30.916383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Tune parameters**","metadata":{}},{"cell_type":"code","source":"grid_models = [(LogisticRegression(),[{'C': [0.001,0.01,0.1,1,10,100], 'penalty':['l1','l2'], 'solver':['liblinear', 'saga']}]),\n               (SVC(random_state=0),[{'C':[0.1 , 1, 10 , 100,1000]}]),\n               (KNeighborsClassifier(),[{'n_neighbors':np.arange(1, 100), 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n               (GaussianNB(),[{'var_smoothing': np.logspace(0,-9, num=100)}]),\n               (DecisionTreeClassifier(),[{'criterion':['gini','entropy'],'max_depth':np.arange(1, 50), 'min_samples_leaf':[1,2,4]}]), \n               (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'], 'min_samples_leaf':[2, 10, 30]}]),\n               (MLPClassifier(max_iter = 1000),[{'solver':['lbfgs', 'sgd', 'adam'], 'learning_rate' :['constant', 'invscaling', 'adaptive']}]),\n              ]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:30.91859Z","iopub.execute_input":"2021-06-28T10:15:30.919051Z","iopub.status.idle":"2021-06-28T10:15:30.929478Z","shell.execute_reply.started":"2021-06-28T10:15:30.919022Z","shell.execute_reply":"2021-06-28T10:15:30.928535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Tuning**\n* Train various Classification Models on the Training set.","metadata":{}},{"cell_type":"code","source":"modelIndex = 0\nfor i,j in grid_models:\n    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'roc_auc',cv = 5)\n    grid.fit(X_train,y_train)\n    best_score = grid.best_score_\n    best_param = grid.best_params_\n    best_model = grid.best_estimator_\n    best_models[modelIndex][1] = best_model\n    modelIndex = modelIndex + 1\n    print(' {}: \\n Best score: {:.1f} %'.format(i,best_score*100))\n    print('')\n    print(best_param)\n    print('')\n    print('-'*50)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:15:31.050727Z","iopub.execute_input":"2021-06-28T10:15:31.051055Z","iopub.status.idle":"2021-06-28T10:16:27.362759Z","shell.execute_reply.started":"2021-06-28T10:15:31.051025Z","shell.execute_reply":"2021-06-28T10:16:27.36165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Test**\n* See which model has highest accuracy.\n* Compare accuracy of Classification Models.","metadata":{}},{"cell_type":"code","source":"lst_1 = []\ncmlist = []\nfor m in range(len(best_models)):\n    lst_2 = []\n    model = best_models[m][1]\n    y_pred = model.predict(X_test)\n    cm = confusion_matrix(y_test,y_pred)\n    cmlist.append(cm)\n    accuracies = cross_val_score(estimator= model, X = X_train,y = y_train, cv=10)\n\n# k-fOLD Validation\n    roc = roc_auc_score(y_test,y_pred)\n    print(best_models[m][0],':')\n    print('')\n    print(cm)\n    print('')\n    print('Accuracy Score: ',accuracy_score(y_test,y_pred))\n    print('')\n    print('K-Fold Validation Mean Accuracy: {:.2f} %'.format(accuracies.mean()*100))\n    print('')\n    print('ROC AUC Score: {:.2f}'.format(roc))\n    print('')\n    print(classification_report(y_test, y_pred))\n    print('-'*60)\n    lst_2.append(best_models[m][0])\n    lst_2.append(accuracy_score(y_test,y_pred)*100)\n    lst_2.append(format(accuracies.mean()*100))\n    lst_2.append(roc)\n    lst_1.append(lst_2)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:16:27.365034Z","iopub.execute_input":"2021-06-28T10:16:27.365858Z","iopub.status.idle":"2021-06-28T10:16:38.174576Z","shell.execute_reply.started":"2021-06-28T10:16:27.365803Z","shell.execute_reply":"2021-06-28T10:16:38.173514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Creating Confusion Matrix Plots**","metadata":{}},{"cell_type":"code","source":"cm_lr = cmlist[0]\ncm_svm = cmlist[1]\ncm_knn = cmlist[2]\ncm_gnb = cmlist[3]\ncm_dtc = cmlist[4]\ncm_rf = cmlist[5]\ncm_mlp = cmlist[6]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:16:38.180204Z","iopub.execute_input":"2021-06-28T10:16:38.182634Z","iopub.status.idle":"2021-06-28T10:16:38.190473Z","shell.execute_reply.started":"2021-06-28T10:16:38.182568Z","shell.execute_reply":"2021-06-28T10:16:38.189438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(25,8))\n\nplt.suptitle(\"Confusion Matrixes\",fontsize=24)\nplt.subplots_adjust(wspace = 0.4, hspace= 0.4)\n\nplt.subplot(2,4,1)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(cm_lr,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 16})\n\nplt.subplot(2,4,2)\nplt.title(\"K Nearest Neighbors Confusion Matrix\")\nsns.heatmap(cm_knn,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 16})\n\nplt.subplot(2,4,3)\nplt.title(\"Support Vector Machine Confusion Matrix\")\nsns.heatmap(cm_svm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 16})\n\nplt.subplot(2,4,5)\nplt.title(\"Gaussian Naive Bayes Confusion Matrix\")\nsns.heatmap(cm_gnb,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 16})\n\nplt.subplot(2,4,6)\nplt.title(\"Decision Tree Classifier Confusion Matrix\")\nsns.heatmap(cm_dtc,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 16})\n\nplt.subplot(2,4,7)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_rf,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 16})\n\nplt.subplot(2,4,8)\nplt.title(\"Multilayer Perceptron Confusion Matrix\")\nsns.heatmap(cm_mlp,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 16})\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:16:38.195243Z","iopub.execute_input":"2021-06-28T10:16:38.197854Z","iopub.status.idle":"2021-06-28T10:16:39.084017Z","shell.execute_reply.started":"2021-06-28T10:16:38.197793Z","shell.execute_reply":"2021-06-28T10:16:39.082703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame(lst_1,columns=['Model','Accuracy','K-Fold Mean Accuracy','ROC_AUC'])\n\ndf2.sort_values(by=['Accuracy'],inplace=True,ascending=False)\ndf2","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:16:39.085526Z","iopub.execute_input":"2021-06-28T10:16:39.085943Z","iopub.status.idle":"2021-06-28T10:16:39.103307Z","shell.execute_reply.started":"2021-06-28T10:16:39.085886Z","shell.execute_reply":"2021-06-28T10:16:39.10225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.barplot(x='Accuracy',y='Model',data=df2,color='b')\nplt.title('Model Comparison');\nplt.savefig(\"sample.png\", dpi=100)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:16:39.104756Z","iopub.execute_input":"2021-06-28T10:16:39.105078Z","iopub.status.idle":"2021-06-28T10:16:39.377491Z","shell.execute_reply.started":"2021-06-28T10:16:39.105048Z","shell.execute_reply":"2021-06-28T10:16:39.376489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predictions**  \n**Scenario:** \n* A patient has cardiac symptoms\n* You use his vitals as input into the Machine Learning Algorithm.   \n1. He is a 20 year old male, with a chest pain value of 2 (atypical angina), with resting blood pressure of 110.\n2. In addition he has a serum cholestoral of 230 mg/dl.\n3. He is fasting blood sugar > 120 mg/dl.\n4. He has a resting electrocardiographic result of 1.\n5. The patients maximum heart rate achieved is 140.\n6. Also, he was exercise induced angina.\n7. His ST depression induced by exercise relative to rest value was 2.2.\n8. The slope of the peak exercise ST segment is flat.\n9. He has no major vessels colored by fluoroscopy, and in addition his maximum heart rate achieved is a reversible defect.\n10. Based on this information, can you classify this patient with Heart Disease?","metadata":{}},{"cell_type":"code","source":"for m in range(len(best_models)):\n    model = best_models[m][1]\n    print(best_models[m][0],':')\n    print(model.predict(sc.transform([[20,1,2,110,230,1,1,140,1,2.2,2,0,2]])))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:16:39.378746Z","iopub.execute_input":"2021-06-28T10:16:39.379036Z","iopub.status.idle":"2021-06-28T10:16:39.401109Z","shell.execute_reply.started":"2021-06-28T10:16:39.379009Z","shell.execute_reply":"2021-06-28T10:16:39.400169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusions**\n1. 13 features are examined but the top 4 significant features help us classify between positive and negative Diagnosis.  \n   These features are chest pain type(cp), maximum hearth rate achieved(thalach), number of major vessels(ca) and St depression.  \n2. Machine learning models can classify patients with Hearth Disease. Worse symptoms from arising later may be prevented by diagnosing detecting these features early.","metadata":{}}]}