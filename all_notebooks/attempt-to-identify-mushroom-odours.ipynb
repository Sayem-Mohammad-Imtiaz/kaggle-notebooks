{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nFrom the Mushroom Classification dataset, we will attempt to create a classifier that determines the odour of a mushroom from its other features."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"mushrooms = pd.read_csv(\"../input/mushroom-classification/mushrooms.csv\")\nmushrooms.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thankfully there are no nulls, which will simplify things.\n\nFor now, let's just peek at the dataset to see what it looks like."},{"metadata":{"trusted":true},"cell_type":"code","source":"mushrooms.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushrooms.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the attribute information of the dataset:\n\nalmond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n\nCounting up all the examples of each odour type in the dataset shows that our dataset is heavily imbalanced. Non-odourous and foul mushrooms basically dominate the entire dataset, while musty or creosote mushrooms are barely represented."},{"metadata":{"trusted":true},"cell_type":"code","source":"mushrooms['odor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n\nWe're trying to find the odour of a mushroom, given all its other properties. So we must separate the the odour column from the rest of the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_data = mushrooms.drop('odor',axis=1)\nodours = mushrooms['odor']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking into the csv file (and from the attribute information of the dataset), we see that all the features are categorical and their values are represented by letters. We will encode the categories into numeric values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nEncoder_pred = LabelEncoder() \nfor col in pred_data.columns:\n    pred_data[col] = Encoder_pred.fit_transform(pred_data[col])\nEncoder_odours = LabelEncoder()\nodours = Encoder_odours.fit_transform(odours)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We split the dataset into training and test sets (80 train - 20 test)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\npred_data_train, pred_data_test, odours_train, odours_test = train_test_split(pred_data, odours, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall that our dataset is heavily imbalanced. We will try to resolve this by oversampling the minority odour classes (in the training set) by randomly re-sampling them until they are equal to the majority."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before resampling:\\n{}\".format(np.asarray(np.unique(odours_train, return_counts=True)).T))\n\nfrom imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=1)\npred_data_train, odours_train = ros.fit_resample(pred_data_train, odours_train)\n\nprint(\"After resampling:\\n{}\".format(np.asarray(np.unique(odours_train, return_counts=True)).T))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using Categorical Naive Bayes Classifier\n\nLet us use a Categorical Naive Bayes classifier to model the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import CategoricalNB\n\nclf = CategoricalNB()\nclf.fit(pred_data_train, odours_train)\n\nprint(clf.score(pred_data_train, odours_train))\nprint(clf.score(pred_data_test, odours_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These accuracy scores for training and test data aren't particularly useful in showing us where the algorithm is struggling. We shall use their confusion matrices to retrieve more information."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef visualize_confusion(classifier, pred_data_test, odours_test, encoder):\n    conf = confusion_matrix(odours_test, classifier.predict(pred_data_test), normalize='true')\n    fig, ax = plt.subplots(figsize=(10,10))\n    labels = encoder.inverse_transform(classifier.classes_)\n    sns.heatmap(conf, annot=True, fmt='.2f', xticklabels=labels, yticklabels=labels)\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.show(block=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_confusion(clf, pred_data_train, odours_train, Encoder_odours)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The confusion matrix above is for the training set; the one below for the test set.\n\nInterestingly, we see (in both matrices) that the Categorical Naive Bayes classifier is doing a really good job predicting 'c', 'm', 'n', 'p' odours. That is:\n1. When the odour is actually 'c', 'm', 'n' or 'p' - the classifier almost always guesses correctly\n2. When the classifier guesses 'c', 'm', 'n' or 'p' - the actual odour almost always matches the guess\n\nSo the classifier can identify those mushrooms very well (and it isn't just blindly guessing 'c', 'm', 'n' or 'p' all the time either.)\n\nThe classifier is less accurate with identifying 'f' mushrooms, but the real problem lies in differentiating between:\n1. 'l' and 'a' mushrooms\n2. 's' and 'y' mushrooms"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_confusion(clf, pred_data_test, odours_test, Encoder_odours)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The struggle with 'l' and 'a' mushrooms (and 's' and 'y')\n\nLet us take a step back - all the way back to the original dataset.\n\nFirst, let's look at what is happening with the 'l' and 'a' mushrooms. We select all the 'l' and 'a' mushrooms from the original dataset and numerically encode their features. Then we can use chi2() to test the independence of the odour from the other features (using the p-values - my understanding of sklearn's chi2() is that its returned chi2 stats are not the same thing as the conventional chi2 test stats.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"la_mushrooms = mushrooms[mushrooms.odor.isin(['l', 'a'])]\nencoded_la = pd.DataFrame()\nfor col in la_mushrooms.columns:\n    encoded_la[col] = LabelEncoder().fit_transform(la_mushrooms[col])\n\nla_data = encoded_la.drop('odor', axis=1)\nla_odours = encoded_la['odor']\nfrom sklearn.feature_selection import chi2\n_, pval = chi2(la_data, la_odours)\npval","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each entry of pval corresponds to the p-value a feature among the 'l' and 'a' mushrooms. The 1's suggest that for those features, they are not very correlated with the odour - which does not help us differentiate between 'l' and 'a' mushrooms.\n\nFrom the code output below, we see that the NaN entries actually correspond to features with only one observed category among all 'l' and 'a' mushrooms. Hence those features cannot help differentiate between 'l' and 'a' mushrooms either"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col_name in la_mushrooms.drop('odor', axis=1).columns:\n    print(\"{}: {}\\n\".format(col_name, np.asarray(np.unique(la_mushrooms[col_name], return_counts=True)).T))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Repeating this process for the 's' and 'y' mushrooms, we also see that it is very likely that the odour is independent from the other features.\n\nOnce again, the NaNs represent features who only have one observed category among the 's' and 'y' mushrooms."},{"metadata":{"trusted":true},"cell_type":"code","source":"sy_mushrooms = mushrooms[mushrooms.odor.isin(['s', 'y'])]\nencoded_sy = pd.DataFrame()\nfor col in sy_mushrooms.columns:\n    encoded_sy[col] = LabelEncoder().fit_transform(sy_mushrooms[col])\n\nsy_data = encoded_sy.drop('odor', axis=1)\nsy_odours = encoded_sy['odor']\n_, pval = chi2(sy_data, sy_odours)\npval","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col_name in sy_mushrooms.drop('odor', axis=1).columns:\n    print(\"{}: {}\\n\".format(col_name, np.asarray(np.unique(sy_mushrooms[col_name], return_counts=True)).T))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Attempts at Training a Second Classifier for 'l', 'a', 's', 'y' Mushrooms\n\nBelow are a couple of attempts to train a second classifier, specifically to differentiate between 'l', 'a', 's', and 'y' mushrooms - as a way to improve upon the accuracy of the Categorical Naive Bayes classifier above. None of them performed particularly well.\n\n## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the 'l', 'a', 's', 'y' mushrooms\nlasy_mushrooms = mushrooms[mushrooms.odor.isin(['l', 'a', 's', 'y'])]\nlasy_data = lasy_mushrooms.drop('odor',axis=1)\nlasy_odours = lasy_mushrooms['odor']\n\n# Encoding categorical values into numerical ones\nlasy_encoder_pred = LabelEncoder() \nfor col in lasy_data.columns:\n    lasy_data[col] = lasy_encoder_pred.fit_transform(lasy_data[col])\nlasy_encoder_odours = LabelEncoder()\nlasy_odours = lasy_encoder_odours.fit_transform(lasy_odours)\n\n# Need to use one-hot encoding for classifiers that do not interpret categorical features correctly\n# This will split all the categorical variables into binary ones - we will use PCA later to reduce dimensionality (while trying to retain variance information)\nlasy_data = pd.get_dummies(lasy_data,columns=lasy_data.columns,drop_first=True)\n\n# Split the dataset into training and test sets\nlasy_data_train, lasy_data_test, lasy_odours_train, lasy_odours_test = train_test_split(lasy_data, lasy_odours, test_size=0.2, random_state=1)\n\n# Oversample the training data for balance\nros = RandomOverSampler(random_state=1)\nlasy_data_train, lasy_odours_train = ros.fit_resample(lasy_data_train, lasy_odours_train)\n\n# PCA Step - Use Cumulative Summation of the Explained Variance to choose a good number of components\nfrom sklearn.decomposition import PCA\npca = PCA().fit(lasy_data_train)\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us say we reduce down to 15 components, we only lose a little over 5% of the variance information."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=15)\nlasy_data_train = pca.fit_transform(lasy_data_train)\nlasy_data_test = pca.transform(lasy_data_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVC\n\nBelow is a plot of SVC accuracy scores, over several different values of C (regularization parameter.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\ntrain_acc = []\ntest_acc = []\nc_range = [0.05, 0.1, 0.2, 0.3, 0.5, 1, 1.5, 2, 3, 5, 10, 15, 20, 30, 40, 50, 100]\n\nfor c in c_range:\n    svc = SVC(C=c, kernel='rbf',random_state=1)\n    svc.fit(lasy_data_train, lasy_odours_train)\n    train_acc.append(svc.score(lasy_data_train, lasy_odours_train))\n    test_acc.append(svc.score(lasy_data_test, lasy_odours_test))\n    \nplt.plot(c_range, train_acc, label=\"training accuracy\")\nplt.plot(c_range, test_acc, label=\"test accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"C\")\nplt.xscale(\"log\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even among the best choices of C we've tried (say C=0.1), the classifier still performs poorly on both training and test datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(C=0.1, kernel='rbf',random_state=1)\nsvc.fit(lasy_data_train, lasy_odours_train)\nvisualize_confusion(svc, lasy_data_train, lasy_odours_train, lasy_encoder_odours)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_confusion(svc, lasy_data_test, lasy_odours_test, lasy_encoder_odours)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier\n\nBelow is a plot of Decision Tree accuracy scores, over several different maximum tree depths - for both entropy of information and gini coefficient criteria."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntrain_acc_ent = []\ntest_acc_ent = []\ntrain_acc_gini = []\ntest_acc_gini = []\n\ndepth_range = range(1, 31, 1)\n\nfor n in depth_range:\n    dtc = DecisionTreeClassifier(max_depth=n, criterion='entropy', random_state=1)\n    dtc.fit(lasy_data_train, lasy_odours_train)\n    train_acc_ent.append(dtc.score(lasy_data_train, lasy_odours_train))\n    test_acc_ent.append(dtc.score(lasy_data_test, lasy_odours_test))\n    \n    dtc = DecisionTreeClassifier(max_depth=n, criterion='gini', random_state=1)\n    dtc.fit(lasy_data_train, lasy_odours_train)\n    train_acc_gini.append(dtc.score(lasy_data_train, lasy_odours_train))\n    test_acc_gini.append(dtc.score(lasy_data_test, lasy_odours_test))\n\nplt.plot(depth_range, train_acc_ent, label=\"training accuracy ent\")\nplt.plot(depth_range, test_acc_ent, label=\"test accuracy ent\")\nplt.plot(depth_range, train_acc_gini, label=\"training accuracy gini\")\nplt.plot(depth_range, test_acc_gini, label=\"test accuracy gini\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Max Depth\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc = DecisionTreeClassifier(max_depth=3, criterion='entropy', random_state=1)\ndtc.fit(lasy_data_train, lasy_odours_train)\nvisualize_confusion(dtc, lasy_data_train, lasy_odours_train, lasy_encoder_odours)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_confusion(dtc, lasy_data_test, lasy_odours_test, lasy_encoder_odours)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K Nearest Neighbours Classifier\n\nBelow is a plot of K Nearest Neighbours accuracy scores, over several different numbers of neighbours"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\ntrain_acc = []\ntest_acc = []\n\nk_range = range(1, 51, 1)\n\nfor k in k_range:\n    knc = KNeighborsClassifier(n_neighbors=k)\n    knc.fit(lasy_data_train, lasy_odours_train)\n    train_acc.append(knc.score(lasy_data_train, lasy_odours_train))\n    test_acc.append(knc.score(lasy_data_test, lasy_odours_test))\n\nplt.plot(k_range, train_acc, label=\"training accuracy\")\nplt.plot(k_range, test_acc, label=\"test accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"# of Neighbours\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knc = KNeighborsClassifier(n_neighbors=45)\nknc.fit(lasy_data_train, lasy_odours_train)\nvisualize_confusion(knc, lasy_data_train, lasy_odours_train, lasy_encoder_odours)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_confusion(knc, lasy_data_test, lasy_odours_test, lasy_encoder_odours)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}