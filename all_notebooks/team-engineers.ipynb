{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n# Team members\n#Varun M:01FB16ECS434\n#Varshini:01FB16ECS433\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfile_path= \"../input/Absenteeism_at_work.csv\"\ndataset=pd.read_csv(file_path)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a384ea9aeeb8db4e31137c869193e6bc1af4d64b"},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"139f8c325590f584232a6ad2eb782476b2df4e5f"},"cell_type":"code","source":"    #Correlation matrix for the features    \n    corr = dataset.corr()\n    fig, ax = plt.subplots(figsize=(10, 10))\n    colormap = sns.diverging_palette(220, 10, as_cmap=True)\n    sns.heatmap(corr, cmap=colormap, annot=True, fmt=\".2f\")\n    plt.xticks(range(len(corr.columns)), corr.columns);\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f236732cd324797e550b0ad4c00513f592ca121b"},"cell_type":"code","source":"#the outliers are removed in the preprocessing stage\nsns.boxplot(dataset['Absenteeism time in hours'])\nmedian = np.median(dataset['Absenteeism time in hours'])\nq75, q25 = np.percentile(dataset['Absenteeism time in hours'], [75 ,25])\ninterquartile = q75 - q25\nprint(\"Upper bound:\",q75 + (1.5*interquartile))\nprint(\"Lower bound:\",q25 - (1.5*interquartile))\n#setting the lower and upper bounds for outliers\ndataset= dataset[dataset['Absenteeism time in hours']<=17]\ndataset= dataset[dataset['Absenteeism time in hours']>=-7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40b6b2bdcbed99070b9d7b2e7df45029d187d319"},"cell_type":"code","source":"X=dataset.drop(['Absenteeism time in hours'], axis=1)\ny=dataset['Absenteeism time in hours']\nfrom sklearn import preprocessing\nx = X.values\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nX = pd.DataFrame(x_scaled,columns=list(X.columns))\n\nX_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size=0.3)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72a122d45d5b8070481813cb5af78341e8b0896e"},"cell_type":"code","source":"#performing scaling of the features\nfrom sklearn.preprocessing import StandardScaler  \nscaler = StandardScaler()  \nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)  \nX_test = scaler.transform(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3919faf5468119cfb347f8b93153dae696509354"},"cell_type":"code","source":"#Model 1\n#K-nearest-neighbour\nerror = []\nfor i in range(1, 40):  \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error.append(np.mean(pred_i != y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"770304f5fc318a189c0b33bc891010e0883f5912"},"cell_type":"code","source":"plt.figure(figsize=(12, 6))  \nplt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',  \n         markerfacecolor='blue', markersize=10)\nplt.title('Error Rate K Value')  \nplt.xlabel('K Value')  \nplt.ylabel('Mean Error') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9991c3d778b004e591681adb578b26077bbbd5e8"},"cell_type":"code","source":"\n#Training and Predictions\nfrom sklearn.neighbors import KNeighborsClassifier  \nclassifier = KNeighborsClassifier(n_neighbors=30)  \nclassifier.fit(X_train, y_train) \ny_pred = classifier.predict(X_test)  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"616209b1e41baf103d2205677bc28deae5dda9b6"},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix  \nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))  \nprint(classification_report(y_test, y_pred))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c72af1b788b3f76c014311d698813eab7481844f"},"cell_type":"code","source":"#Model 2\n#Support vector Machine(SVM)\nfrom sklearn.svm import SVC  \nsvclassifier = SVC(kernel='sigmoid')  \nsvclassifier.fit(X_train, y_train) \ny_pred = svclassifier.predict(X_test)  \nfrom sklearn.metrics import classification_report, confusion_matrix  \nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test,y_pred))  \nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb8806a664ca57250ad8b5e2a693faa771f3759e"},"cell_type":"code","source":"#Model 3 \n#Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier \n\ndtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \ny_pred = dtree_model.predict(X_test) \nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"------------------------\\n\")\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a3ebef3dfae65d9aa69113353712f67c1aad1e8"},"cell_type":"code","source":"#Conclusions\n#The accuracy for Decision tree classifier is the highest amongst all other models.\n#Also precision and F1 score of the Decision tree classifier is the highest.\n#Hence the Best model for this dataset would be the decision tree classifier followed by support vector machine followed by k nearest neighbours.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}