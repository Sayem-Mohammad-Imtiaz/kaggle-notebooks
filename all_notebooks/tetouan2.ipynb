{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom keras.layers import Input, Dense, Conv2D, Flatten\nfrom keras.models import Model\nfrom keras.optimizers import SGD, Adam\n\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* On va devoir classifier des images contenant des chiffres écrits à la main en 10 classes (0, 1, 2 ... 9), il s'agit d'un problème de clasiification multi-classe.\n* Le réseau de neurones va avoir une couche de sortie contenant 10 neurones. Chaque neurone correspond à une classe (un chiffre). On doit donc lui donner 10 vecteurs, chaque vecteur représentera un chiffre\n* les données que nous avons contiennent une colonne \"label\" avec des valeurs entre 0 et 9 indiquant le contenu de l'image. On ne peut pas utiliser directement ce vecteur au niveau de la sortie du réseau de neurones, on doit le restructurer de manière à ce que chaque classe soit encoder dans un vecteur différent. Pour cela, on utilisera la fonction to_categorical de keras.\n* Voici un exemple d'utilisation, soit y = [0,1,2,1,0]. Ce vecteur possède 3 classes 0, 1 et 2\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#et voici le résultat de la transformation.\nnp_utils.to_categorical([0,1,2,1,0])\n\n#On peut voir 3 colonnes, chaquue colonne correspond à une classe, (première colonne est la classe 0,\n#deuxième colonne est la classe 1, troisième colonne est la classe 2).\n#On voit que la première colonne contient des 1 pour les lignes appartenant à\n#la classe 0 (première et dernière ligne), etc\n\n#cette technique de transformation est appelée le One Hot Encoding (ohe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mnist-digit-recognizer/train.csv')\n\ndfX = df.drop('label', axis=1).values\ndfY = df.label.values\ndfX = dfX/255.\n\ndfY_ohe = np_utils.to_categorical(dfY) #Application du One Hot Encoding\nprint(dfY_ohe.shape)# Nous avons bien 10 vecteurs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dense_model():\n    inpt = Input ( (784,) )\n    \n    x = Dense(128, activation='relu', name='couche1')(inpt)\n    x = Dense(128, activation='relu', name='couche2')(x)\n    \n    x = Dense(10, activation='softmax', name='output')(x) # la couche de sortie contient 10 neurones\n    #chaque neurones va apprendre à prédire la classe qui lui correspond\n    #Dans un problème multi_classification, on utilise l'activation softmax au lieu de la sigmoid\n    \n    model = Model( inpt, x )\n    return model\n\nmodel = create_dense_model()\nmodel.summary()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = StratifiedKFold(n_splits=2)\nfor train_idx, test_idx in cv.split(dfX, dfY):\n    model = create_dense_model()\n    model.compile( loss='mse' , optimizer=Adam(), metrics=['accuracy'])\n    \n    es = EarlyStopping(patience=5, monitor='val_accuracy', mode='max')\n    mc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n    \n    trainX = dfX[train_idx]\n    trainY = dfY_ohe[train_idx] #on utilise dfY_ohe et non dfY\n    \n    testX  = dfX[test_idx]    \n    testY  = dfY_ohe[test_idx]\n    \n    model.fit( trainX, trainY, validation_data=[testX, testY], callbacks = [es,mc],\n              epochs=1000)\n    \n    \n    model.load_weights('./weights.h5')#On charge les meilleurs poids sauvegardés par le ModelCheckpoint\n    #on prédit le Test\n    preds = model.predict(testX)\n    score_test = accuracy_score( dfY[test_idx], np.argmax(preds, axis=1) )#j'expliquerai au cours\n    print (' LE SCORE DE TEST : ', score_test)\n    print('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ceci est un exemple des résultats d'un epoch du réseau de neurone :\n#### loss: 0.0167 - accuracy: 0.8902 - val_loss: 0.0097 - val_accuracy: 0.9363\n\n#### puisque nous avons fixé loss='mse' \n* loss         : c'est l'erreur mse du TRAIN\n* val_loss     : c'est l'erreur mse du TEST\n* accuracy     : c'est la performance du réseau en utilisant la mesure (metric) accuracy sur le TRAIN\n* val_accuracy : c'est la performance du réseau en utilisant la mesure (metric) accuracy sur le TEST\n#### ---------------------------------------\n* Par défaut, le earlystopping va monitorer (surveiller) l'évolution du val_loss du TEST, avec mode='min' puiqu'on souhaite minimiser le loss.\n* Or on souhaite maximiser l'accuracy du TEST. On va donc dire à EarlyStopping de surveiller val_accuracy avec mode='max'\n* Le même principe s'applique à ModelCheckpoint. Mais on doit indiquer save_best_only=True afin que seuls les meilleurs poids soit sauvegardés dans le fichier, sinon ils seront remplacés par les epochs suivantes\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_cnn_model():\n    inpt = Input ( (28, 28, 1) )\n    \n    x = Conv2D(filters=16, kernel_size=(4,4), strides=(2, 2), activation='relu')(inpt)\n    x = Conv2D(filters=32, kernel_size=(4,4), strides=(2, 2), activation='relu')(x)\n    x = Conv2D(filters=64, kernel_size=(4,4), strides=(2, 2), activation='relu')(x)\n    x = Flatten()(x)\n    x = Dense(128, activation='relu')(x)  \n    x = Dense(10, activation='softmax', name='output')(x)     \n    model = Model( inpt, x )\n    return model\n\nmodel = create_cnn_model()\nmodel.summary()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = StratifiedKFold(n_splits=2)\nfor train_idx, test_idx in cv.split(dfX, dfY):\n    model = create_cnn_model()\n    model.compile( loss='mse' , optimizer=Adam(), metrics=['accuracy'])\n    \n    es = EarlyStopping(patience=5, monitor='val_accuracy', mode='max')\n    mc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n    \n    trainX = dfX[train_idx]\n    trainY = dfY_ohe[train_idx] #on utilise dfY_ohe et non dfY\n    trainX = np.reshape( trainX, (-1,28,28, 1) )#on transforme les vecteurs de pixels en matrices représentant les images\n    \n    testX  = dfX[test_idx]    \n    testY  = dfY_ohe[test_idx]\n    testX = np.reshape( testX, (-1,28,28, 1) )\n    \n    model.fit( trainX, trainY, validation_data=[testX, testY], callbacks = [es,mc],\n              epochs=1000)\n    \n    \n    model.load_weights('./weights.h5')#On charge les meilleurs poids sauvegardés par le ModelCheckpoint\n    #on prédit le Test\n    preds = model.predict(testX)\n    score_test = accuracy_score( dfY[test_idx], np.argmax(preds, axis=1) )#j'expliquerai au cours\n    print (' LE SCORE DE TEST : ', score_test)\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}