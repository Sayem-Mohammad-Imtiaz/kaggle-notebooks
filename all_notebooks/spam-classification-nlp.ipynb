{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Spam Classification using NLP"},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport nltk","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"csv = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv', encoding=\"ISO-8859-1\")\ndf = pd.DataFrame(csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check class distribution\nclasses = df[df.columns[0]]\nprint(classes.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess the Data"},{"metadata":{},"cell_type":"markdown","source":"Data exploration/data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert class labels to binary values, 0 = ham  1 = spam\n\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\nY = encoder.fit_transform(classes)\n\n# quick check\nprint(classes[:10])\nprint(Y[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store SMS message data\ntext_messages = df[df.columns[1]]\nprint(text_messages[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# expressions can be found at https://regexlib.com/\n# use regular expressions to replace email addresses, urls, phone numbers, etc.\n\n# replace email addresses with 'emailaddr\nprocessed = text_messages.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$', 'emailaddr')\n\n# replace urls with 'webaddress'\nprocessed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n# replace money symbols with 'moneysymb'\nprocessed = text_messages.str.replace(r'£|\\$', 'moneysymb')\n\n# replace 10 digit phone numbers with 'phonenum'\nprocessed = text_messages.str.replace(r'^[2-9]\\d{2}-\\d{3}-\\d{4}$', 'phonenum')\n\n# replace normal numbers with 'num'\nprocessed = text_messages.str.replace(r'\\d+(\\.\\d+)?', 'num')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove punctuation\nprocessed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n\n# replace whitespace between terms with a single space\nprocessed = processed.str.replace(r'\\s+', ' ')\n\n# remove leading and trailing whitespace\nprocessed = processed.str.replace(r'^\\s+|\\s+?$', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change all words to lower case\nprocessed = processed.str.lower()\nprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\n\n# remove stop words from text messages\n# stop words are basically a set of commonly used words in any language such as i, me, to, it, etc.\n\nstop_words = set(stopwords.words('english'))\n\nprocessed = processed.apply(lambda x: ' '.join(\n    term for term in x.split() if term not in stop_words))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove word stems using a Porter stemmer\n# stemming is the process of reducing a word to its word stem such as removing -ing\nps = nltk.PorterStemmer()\n\nprocessed = processed.apply(lambda x: ' '.join(\n    ps.stem(term) for term in x.split()))\n\nprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\n# create bag-of-words\nall_words = []\n\nfor message in processed:\n    words = word_tokenize(message)\n    for w in words:\n        all_words.append(w)\n\n# FreqDist class is used to encode “frequency distributions”, which count the number of times that each outcome of an experiment occurs\n\nall_words = nltk.FreqDist(all_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the total number of words and the 15 most common words\nprint('Number of words: {}'.format(len(all_words)))\nprint('Most common words: {}'.format(all_words.most_common(10)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the 1500 most common words as features\nword_features = list(all_words.keys())[:1500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find_features function will determine which of the 1500 word features are contained in the email/message\ndef find_features(message):\n    words = word_tokenize(message)\n    features = {}\n    for word in word_features:\n        features[word] = (word in words)\n\n    return features\n\n# example\nfeatures = find_features(processed[0])\nfor key, value in features.items():\n    if value == True:\n        print(key)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above words are key words that were saved as apart of the features (aka most common words) list that were found in the very first message."},{"metadata":{"trusted":true},"cell_type":"code","source":"# do it for all the messages\nmessages = list(zip(processed, Y))\n\n# define a seed for reproducibility\nseed = 1\nnp.random.seed = seed\nnp.random.shuffle(messages)\n\n# call find_features function for each SMS message\nfeaturesets = [(find_features(text), label) for (text, label) in messages]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split data into testing and training sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\n\n# split the data into training and testing datasets\ntraining, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training:',len(training))\nprint('Testing:',len(testing))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Algorithms\n## Scikit-Learn Classifiers with NLTK"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.classify.scikitlearn import SklearnClassifier\nfrom sklearn.svm import SVC\n\nmodel = SklearnClassifier(SVC(kernel = 'linear'))\n\n# train the model on the training data\nmodel.train(training)\n\n# and test on the testing dataset!\naccuracy = nltk.classify.accuracy(model, testing)*100\nprint(\"SVC Accuracy: {}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\n# define models to train\nnames = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n\nclassifiers = [\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    LogisticRegression()\n]\n\nmodels = zip(names, classifiers)\n\nfor name, model in models:\n    nltk_model = SklearnClassifier(model)\n    nltk_model.train(training)\n    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n    print(\"{} Accuracy: {}\".format(name, accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble methods - Voting classifier\nfrom sklearn.ensemble import VotingClassifier\n\nnames = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n\nclassifiers = [\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    LogisticRegression()\n]\n\nmodels = list(zip(names, classifiers))\n\nnltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\nnltk_ensemble.train(training)\naccuracy = nltk.classify.accuracy(nltk_model, testing)*100\nprint(\"Voting Classifier: Accuracy: {}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class label prediction for testing set\ntxt_features, labels = zip(*testing)\n\nprediction = nltk_ensemble.classify_many(txt_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print a confusion matrix and a classification report\nprint(classification_report(labels, prediction))\n\npd.DataFrame(\n    confusion_matrix(labels, prediction),\n    index = [['actual', 'actual'], ['ham', 'spam']],\n    columns = [['predicted', 'predicted'], ['ham', 'spam']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}