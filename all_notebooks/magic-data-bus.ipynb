{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n#Import Library ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df =  pd.read_csv('../input/bus-breakdown-and-delays.csv')\n #Import dataset ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #target variable isn't a number, will need to do regex to extract relevant information ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() #See quick summary of data- 328k total rows, but some columns have missingg values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()/df['School_Year'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isnull()) #See distribution of missing data \nplt.figsize = (5,2.5)\nplt.tight_layout()\nplt.title('Distribution of Missing Data by Variable ')\n\n#Incident number has high number of NAs ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Incident_Number'], axis = 1) #Drop incident number, most of column is missing\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = df.dropna() #Drop remainaing NAs\ndf_clean.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Delay'] = df_clean['How_Long_Delayed'].str.extract('(\\d+)') #Extract digits from string column \ndf_clean.head() #Check if regex worked- Yes!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean[df_clean['Delay'].isnull()] #Check if data is null\n#We see that there's question marks or other irregularaties- lets drop this data \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = df_clean.dropna() #Drop new NAs \ndf_clean.isnull().sum() #Check that no NAs are left ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Delay'] =  pd.to_numeric(df_clean['Delay']) #Convert string to integer ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = df_clean.drop(['How_Long_Delayed'], axis = 1) #Drop original column ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we do more data wrangling, let's do some EDA! "},{"metadata":{"trusted":true},"cell_type":"code","source":"reasons = pd.pivot_table(df_clean, index = 'Reason', values = 'Delay', aggfunc = [np.mean, np.max,np.size]).sort_values(by = \n                                                                                                    ('mean', 'Delay'), \n                                                                                        ascending = False)\nplt.figure(figsize = (5,50))\nreasons.plot(kind = 'bar', y = ('mean','Delay'), color = 'lightblue')\nplt.title('Average Delay in Minutes')\nplt.legend().remove()\nplt.xticks(rotation = 80)\n\n#See size distribution by reason\nplt.figure(figsize = (5,50))\nreasons.plot(kind = 'bar', y = ('size','Delay'), color = 'lightblue')\nplt.title('Number of Delays')\nplt.legend().remove()\nplt.xticks(rotation = 80)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot( x = df_clean['Delay'])\n#Looks like two clear outliers- 1 around 50,000 and the other around 200,000 Let's remove \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_exoutliers = df_clean[df_clean['Delay'] < 50000]\nsns.boxplot(x = df_exoutliers['Delay']) #Check if we need to remove further outliers ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Route_Number'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(df_clean, index = 'Route_Number', values = 'Delay', aggfunc = [np.mean,np.size]).sort_values(by = \n                                                                                                           ('size','Delay'), \n                                                                                                           ascending = False).head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"routes = ['1','2','3','5','4','6']\ntop_routes = df_clean[df_clean['Route_Number'].isin(routes)] #Filter to see cases where route is top 6 in # of delays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"routes_pivot = pd.pivot_table(top_routes, index = 'Route_Number', values = 'Delay', aggfunc = [np.mean,np.size])\nroutes_pivot.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Bus_Company_Name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Machine Learning Model Prep **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#First Let's remove unnecessary features, checking 1 by 1 \n\n#School Year- is it relevant? \ndf_clean['School_Year'].value_counts().plot(kind = 'bar')\nplt.xticks(rotation = 75) #Make Data cleaner to read \n\n#See an increasing trend year on year in quantity-let's investigate if there's any significant deviations in delay by year\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's first see average delay, across the dataset \ndf_clean['Delay'].mean() #Around 29 mins is the average delay time ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(df_clean, index = 'School_Year', values = 'Delay', aggfunc = np.mean).plot(kind = 'bar')\nplt.legend().remove() #Get rid of legend \nplt.title('Average Delay by Year')\nplt.xticks(rotation = 75) #Make easier to read \n\n#Doesn't look any year is terribly far off from another but also not congruent- will keep for now ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head() #Let's check what the data looked like again ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Busbreakdown_ID'].value_counts() #Data seems like no noise, we'll drop ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = df_clean.drop(['Busbreakdown_ID'], axis = 1)\ndf_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bus_num = pd.pivot_table(df_clean, index = 'Bus_No', values = 'Delay',aggfunc = np.size).sort_values(by = 'Delay', \n                                                                                                    ascending = False)\nbus_num\n\n#Create pivot to see number of delays by bus number- we see that a lot have only have 1. \n#Instead of one hot encoding, let's just convert to digits \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Bus_Number'] = df_clean['Bus_No'].str.extract('(\\d+)') #Extract digits from string column \n\ndf_clean['Bus_Number'] =  pd.to_numeric(df_clean['Bus_Number']) #Convert string to integer \ndf_clean.isnull().sum() #We now have some more NAs- let's do a quick investigation \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean[df_clean['Bus_Number'].isnull()] #Looks like noisy data, will drop \ndf_clean = df_clean.dropna()\ndf_clean = df_clean.drop(['Bus_No'], axis = 1) #Drop original column ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head() #Look familiar? ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.corr() #Let's look at the current correlation across features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Run_Type'].value_counts().plot(kind = 'bar') \nplt.title('Trip distribution ')\nplt.xticks(rotation = 75) #Data heavily weighted towards Special Ed AM in terms of quantity \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.nunique() #See number of unique values per feature ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = df_clean['Delay'] #store target variable\ndf_model = df_clean.drop(['Delay'], axis = 1)\nX = df_model[['Run_Type','Reason','Boro','Number_Of_Students_On_The_Bus','Breakdown_or_Running_Late',\n             'School_Age_or_PreK']] #store some basic features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_df = pd.get_dummies(X) #Convert data to dummies to enable modeling\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dummy_df.shape) \nprint(y.shape)\n\n#Check that number of rows match number of labels (target) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split Data into test, train \nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test,y_train, y_test = train_test_split(dummy_df,y,test_size = .2, random_state = 40) #Split into 20% test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor \nmodel = RandomForestRegressor(n_estimators = 100) #create model \nmodel.fit(X_train,y_train) #Run model on training set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test) #Predict on testing set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics \n\nprint('MAE:', metrics.mean_absolute_error(y_test,predictions)) #We see that average error is 12.92 mins- compared to the naive guess of 28 mins","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's change the model up by adding more features and check out the impact "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = df_clean['Delay'] #store target variable\nX = df_model[['School_Year','Run_Type','Reason','Boro','Bus_Company_Name','Number_Of_Students_On_The_Bus','Breakdown_or_Running_Late',\n             'School_Age_or_PreK']] #Added bus company name/school year features\ndummy_df = pd.get_dummies(X) #Convert data to dummies to enable modeling\nprint(dummy_df.shape)\nprint(y.shape)\n\n#Shape of both datasets is matching, ok to proceed to next step ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split Data into test, train \nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test,y_train, y_test = train_test_split(dummy_df,y,test_size = .2, random_state = 40) #Split into 20% test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Run model again \n\nfrom sklearn.ensemble import RandomForestRegressor \nmodel = RandomForestRegressor(n_estimators = 150) #create model \nmodel.fit(X_train,y_train) #Run model on training set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics \n\npredictions = model.predict(X_test) #Predict on testing set\nprint('MAE:', metrics.mean_absolute_error(y_test,predictions)) #We see that average error is 11.13 mins- down from the last model!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the importance of the features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_values = pd.DataFrame(model.feature_importances_,\n                              index = X_train.columns,\n                              columns = ['importance']).sort_values('importance',\n                                                                    ascending=False)\nfeature_values.head(8).plot(kind = 'bar', color = 'lightgreen')\nplt.xticks(rotation = 85)\nplt.title('Feature Importance')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's work with the Schools Serviced Feature "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Size'] = df_clean.groupby('Schools_Serviced')['Delay'].transform(len) #Create a column to see count of Bus\ndf_clean.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Size'].nunique() #365 unique values for Schools Serviced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean[df_clean['Size'] > 500]['Size'].nunique() #Cut down number of unique schools serviced to 58 by filtering value count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['Schools_Serviced2'] = np.where(df_clean['Size'] > 500,df_clean['Schools_Serviced'], 'other')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny = df_clean['Delay'] #store target variable\nX = df_clean[['School_Year','Run_Type','Reason','Boro','Bus_Company_Name','Number_Of_Students_On_The_Bus','Breakdown_or_Running_Late',\n             'School_Age_or_PreK','Schools_Serviced2']] #added additional feature\ndummy_df = pd.get_dummies(X) #look familiar? \nX_train, X_test,y_train, y_test = train_test_split(dummy_df,y,test_size = .2, random_state = 40) #Split into 20% test data\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Re-run Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(n_estimators = 150) #create model \nmodel.fit(X_train,y_train) #Run model on training set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test) #Predict on testing set\nprint('MAE:', metrics.mean_absolute_error(y_test,predictions)) #Down to 10.99- can we get to single digits? ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's dive into the contractor notification features "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(df_clean, index = 'Has_Contractor_Notified_Schools', values = 'Delay', aggfunc = np.mean)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(df_clean, index = 'Has_Contractor_Notified_Parents', values = 'Delay', aggfunc = np.mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_clean['Delay'] #store target variable\nX = df_clean[['School_Year','Run_Type','Reason','Boro','Bus_Company_Name','Number_Of_Students_On_The_Bus','Breakdown_or_Running_Late',\n             'School_Age_or_PreK','Schools_Serviced2', 'Has_Contractor_Notified_Parents','Has_Contractor_Notified_Schools']] \n    #added additional features related to contractors \ndummy_df = pd.get_dummies(X) #look familiar? \nX_train, X_test,y_train, y_test = train_test_split(dummy_df,y,test_size = .2, random_state = 40) #Split into 20% test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(n_estimators = 150) #create model \nmodel.fit(X_train,y_train) #Run model on training set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test) #Predict on testing set\nprint('MAE:', metrics.mean_absolute_error(y_test,predictions)) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}