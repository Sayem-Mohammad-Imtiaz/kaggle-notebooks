{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Simpler Preprocessing on the Indonesian Hate & Abusive Text \n[Previous kernel](https://www.kaggle.com/ilhamfp31/preprocessing-the-indonesian-hate-abusive-text) follow the original paper [1] and preprocess the data in 5 steps:\n1. Lower casing all text, \n2. Data cleaning by removing unnecessary characters such as re-tweet symbol (RT), username, URL, and punctuation\n3. Normalization using 'Alay' dictionary \n4. Stemming using PySastrawi [2]\n5. Stop words removal using list from [3]\n\nThis kernel will only follow step 1-3."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n!ls '../input'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/indonesian-abusive-and-hate-speech-twitter-text/data.csv', encoding='latin-1')\n\nalay_dict = pd.read_csv('../input/indonesian-abusive-and-hate-speech-twitter-text/new_kamusalay.csv', encoding='latin-1', header=None)\nalay_dict = alay_dict.rename(columns={0: 'original', \n                                      1: 'replacement'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Text Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape: \", data.shape)\ndata.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.HS.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Abusive.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Toxic shape: \", data[(data['HS'] == 1) | (data['Abusive'] == 1)].shape)\nprint(\"Non-toxic shape: \", data[(data['HS'] == 0) & (data['Abusive'] == 0)].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Alay Dict"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape: \", alay_dict.shape)\nalay_dict.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef lowercase(text):\n    return text.lower()\n\ndef remove_unnecessary_char(text):\n    text = re.sub('\\n',' ',text) # Remove every '\\n'\n    text = re.sub('rt',' ',text) # Remove every retweet symbol\n    text = re.sub('user',' ',text) # Remove every username\n    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n    text = re.sub('  +', ' ', text) # Remove extra spaces\n    return text\n    \ndef remove_nonaplhanumeric(text):\n    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n    return text\n\nalay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\ndef normalize_alay(text):\n    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n\nprint(\"remove_nonaplhanumeric: \", remove_nonaplhanumeric(\"Halooo,,,,, duniaa!!\"))\nprint(\"lowercase: \", lowercase(\"Halooo, duniaa!\"))\nprint(\"remove_unnecessary_char: \", remove_unnecessary_char(\"Hehe\\n\\n RT USER USER apa kabs www.google.com\\n  hehe\"))\nprint(\"normalize_alay: \", normalize_alay(\"aamiin adek abis\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(text):\n    text = lowercase(text) # 1\n    text = remove_nonaplhanumeric(text) # 2\n    text = remove_unnecessary_char(text) # 2\n    text = normalize_alay(text) # 3\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Tweet'] = data['Tweet'].apply(preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape: \", data.shape)\ndata.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save Preprocessed Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('preprocessed_indonesian_toxic_tweet.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References\n\n[1] Muhammad Okky Ibrohim and Indra Budi. 2019. Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter. In ALW3: 3rd Workshop on Abusive Language Online, 46-57.   \n[2] https://github.com/har07/PySastrawi\n[3] Tala, F. Z. (2003). A Study of Stemming Effects on Information Retrieval in Bahasa Indonesia. M.Sc. Thesis. Master of Logic Project. Institute for Logic, Language and Computation. Universiteit van Amsterdam, The Netherlands.  "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}