{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# create model\nmodel = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  train sample\nx = np.array([5,15,25,35,45,55]).reshape((-1,1))\ny = np.array([5,20,14,32,22,38])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# start training\nmodel.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print output\nprint('score',model.score(x,y))\nprint('intercept',model.intercept_)\nprint('corefficient',model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test\nmodel.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# identical way to predict\ny_pred = model.intercept_ + model.coef_ * x\nprint('predicted response:', y_pred, sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression\n` the algorithm try to understand the relationship between dependent and independent variable `\n* intercept is scalar and coef is array\n* the value bo = 5.63 ilustrates that your model predicts the repsonse 5.63 when z is zero\n* the value b1 = 0.54 means that predicted reponse raise by 0.54 when x is increased by one"},{"metadata":{},"cell_type":"markdown","source":"# SVM "},{"metadata":{"trusted":true},"cell_type":"code","source":"# imoport data set from sklearn\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split \n\ncancer = datasets.load_breast_cancer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Features:\", cancer.feature_names)\nprint(\"Labels: \", cancer.target_names) \nprint('Shape:', cancer.data.shape)\nprint('Top5 row data:', len(cancer.data[0:5][0]))\nprint('Cancer labels (0:malignant, 1:benign)', cancer.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# spliting train set and test set\nX_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating model\n#Import svm model\nfrom sklearn import svm\n#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n#Train the model using the training sets\nclf.fit(X_train, y_train)\n# Predict the response for test dataset\ny_pred = clf.predict(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate model\nfrom sklearn import metrics \nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# facial expression recognition svm"},{"metadata":{"trusted":true},"cell_type":"code","source":"import argparse\nimport errno\nimport scipy.misc\nimport dlib\nimport cv2\n\nfrom skimage.feature import hog\n\n# initialization\nimage_height = 48\nimage_width = 48\nwindow_size = 24\nwindow_step = 6\nONE_HOT_ENCODING = False\nSAVE_IMAGES = False\nGET_LANDMARKS = False\nGET_HOG_FEATURES = False\nGET_HOG_WINDOWS_FEATURES = False\nSELECTED_LABELS = []\nIMAGES_PER_LABEL = 500\nOUTPUT_FOLDER_NAME = \"fer2013_features\"\n\n# parse arguments and initialize variables:\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-j\", \"--jpg\", default=\"no\", help=\"save images as .jpg files\")\nparser.add_argument(\"-l\", \"--landmarks\", default=\"yes\", help=\"extract Dlib Face landmarks\")\nparser.add_argument(\"-ho\", \"--hog\", default=\"yes\", help=\"extract HOG features\")\nparser.add_argument(\"-hw\", \"--hog_windows\", default=\"yes\", help=\"extract HOG features from a sliding window\")\nparser.add_argument(\"-o\", \"--onehot\", default=\"no\", help=\"one hot encoding\")\nparser.add_argument(\"-e\", \"--expressions\", default=\"0,1,2,3,4,5,6\", help=\"choose the faciale expression you want to use: 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\")\nargs = parser.parse_args()\nif args.jpg == \"yes\":\n    SAVE_IMAGES = True\nif args.landmarks == \"yes\":\n    GET_LANDMARKS = True\nif args.hog == \"yes\":\n    GET_HOG_FEATURES = True\nif args.hog_windows == \"yes\":\n    GET_HOG_WINDOWS_FEATURES = True\nif args.onehot == \"yes\":\n    ONE_HOT_ENCODING = True\nif args.expressions != \"\":\n    expressions  = args.expressions.split(\",\")\n    for i in range(0,len(expressions)):\n        label = int(expressions[i])\n        if (label >=0 and label<=6 ):\n            SELECTED_LABELS.append(label)\nif SELECTED_LABELS == []:\n    SELECTED_LABELS = [0,1,2,3,4,5,6]\nprint( str(len(SELECTED_LABELS)) + \" expressions\")\n\n# loading Dlib predictor and preparing arrays:\nprint( \"preparing\")\npredictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\noriginal_labels = [0, 1, 2, 3, 4, 5, 6]\nnew_labels = list(set(original_labels) & set(SELECTED_LABELS))\nnb_images_per_label = list(np.zeros(len(new_labels), 'uint8'))\ntry:\n    os.makedirs(OUTPUT_FOLDER_NAME)\nexcept OSError as e:\n    if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME):\n        pass\n    else:\n        raise\n\ndef get_landmarks(image, rects):\n    # this function have been copied from http://bit.ly/2cj7Fpq\n    if len(rects) > 1:\n        raise BaseException(\"TooManyFaces\")\n    if len(rects) == 0:\n        raise BaseException(\"NoFaces\")\n    return np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()])\n\ndef get_new_label(label, one_hot_encoding=False):\n    if one_hot_encoding:\n        new_label = new_labels.index(label)\n        label = list(np.zeros(len(new_labels), 'uint8'))\n        label[new_label] = 1\n        return label\n    else:\n        return new_labels.index(label)\n\ndef sliding_hog_windows(image):\n    hog_windows = []\n    for y in range(0, image_height, window_step):\n        for x in range(0, image_width, window_step):\n            window = image[y:y+window_size, x:x+window_size]\n            hog_windows.extend(hog(window, orientations=8, pixels_per_cell=(8, 8),\n                                            cells_per_block=(1, 1), visualise=False))\n    return hog_windows\n\nprint( \"importing csv file\")\ndata = pd.read_csv('fer2013.csv')\n\nfor category in data['Usage'].unique():\n    print( \"converting set: \" + category + \"...\")\n    # create folder\n    if not os.path.exists(category):\n        try:\n            os.makedirs(OUTPUT_FOLDER_NAME + '/' + category)\n        except OSError as e:\n            if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME):\n               pass\n            else:\n                raise\n    \n    # get samples and labels of the actual category\n    category_data = data[data['Usage'] == category]\n    samples = category_data['pixels'].values\n    labels = category_data['emotion'].values\n    \n    # get images and extract features\n    images = []\n    labels_list = []\n    landmarks = []\n    hog_features = []\n    hog_images = []\n    for i in range(len(samples)):\n        try:\n            if labels[i] in SELECTED_LABELS and nb_images_per_label[get_new_label(labels[i])] < IMAGES_PER_LABEL:\n                image = np.fromstring(samples[i], dtype=int, sep=\" \").reshape((image_height, image_width))\n                images.append(image)\n                if SAVE_IMAGES:\n                    scipy.misc.imsave(category + '/' + str(i) + '.jpg', image)\n                if GET_HOG_WINDOWS_FEATURES:\n                    features = sliding_hog_windows(image)\n                    f, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n                                            cells_per_block=(1, 1), visualise=True)\n                    hog_features.append(features)\n                    hog_images.append(hog_image)\n                elif GET_HOG_FEATURES:\n                    features, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n                                            cells_per_block=(1, 1), visualise=True)\n                    hog_features.append(features)\n                    hog_images.append(hog_image)\n                if GET_LANDMARKS:\n                    scipy.misc.imsave('temp.jpg', image)\n                    image2 = cv2.imread('temp.jpg')\n                    face_rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n                    face_landmarks = get_landmarks(image2, face_rects)\n                    landmarks.append(face_landmarks)            \n                labels_list.append(get_new_label(labels[i], one_hot_encoding=ONE_HOT_ENCODING))\n                nb_images_per_label[get_new_label(labels[i])] += 1\n        except Exception as e:\n            print( \"error in image: \" + str(i) + \" - \" + str(e))\n\n    np.save(OUTPUT_FOLDER_NAME + '/' + category + '/images.npy', images)\n    if ONE_HOT_ENCODING:\n        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/labels.npy', labels_list)\n    else:\n        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/labels.npy', labels_list)\n    if GET_LANDMARKS:\n        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/landmarks.npy', landmarks)\n    if GET_HOG_FEATURES or GET_HOG_WINDOWS_FEATURES:\n        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/hog_features.npy', hog_features)\n        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/hog_images.npy', hog_images)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}