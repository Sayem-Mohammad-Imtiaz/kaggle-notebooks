{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Unsupervised Learning , PCA, SVM & Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"Import basic libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/vehicle/vehicle.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Our DatTypes:\n1. We are going to deal with neumeric (Int and Float) datatype\n2. Except the Traget Column (Class) which is object"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Number of Rows in our dataset:{} & Number of columns:{}\".format(df.shape[0],df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check for the number of missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### There are some missing values for 14 columns in our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.fillna(df.median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am using median to fill the missing values , as using mean value may not be that effective if our data has outliers. \nThe Reason being, outliers may have extreme values , and when we use mean or average to fill the missing values \nit may have an impact on our analysis. So , Median can be preferred compared to mean when filling missing values.\n\nTip:ML algorithms are sensitive to outliers "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our Dataset looks somewhat good, all columns are consistent with neumeric value"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=list(df)\ndf[columns].hist(stacked=True,density=True, bins=100,color='Orange', figsize=(16,30), layout=(10,3)); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the Histogram we could infer that most of out independent variables are normally distributed and some have multiple gaussian."},{"metadata":{},"cell_type":"markdown","source":"### Traget Variable Callout\n\nOur Target variable is class , with the various silhouette attributes of vehicles in different\nangles provided, we are going to identify the type of vehicle."},{"metadata":{"trusted":true},"cell_type":"code","source":"grp=df.groupby('class')['class'].count()\ngrp.plot.pie(shadow=True, startangle=120,autopct='%.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Our Class label vehicle type consists of three types Van,Bus and Car. Among these Car's contribute to 51% of the data, Bus & van collectively contribute 49% of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_car=df[df['class']=='car']\ndf_van=df[df['class']=='van']\ndf_bus=df[df['class']=='bus']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Lets see if we can distinguish our classes based on some features."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_bus['circularity'],np.zeros_like(df_bus['circularity']),marker='s',color='Red',alpha=0.5)\nplt.scatter(df_car['circularity'],np.zeros_like(df_car['circularity']),marker='|',color='blue',alpha=0.8)\nplt.scatter(df_van['circularity'],np.zeros_like(df_van['circularity']),marker='o',color='yellow',alpha=1)\nplt.xlabel('Circularity')\nplt.show()\nplt.scatter(df_bus['distance_circularity'],np.zeros_like(df_bus['distance_circularity']),marker='s',color='Red',)\nplt.scatter(df_car['distance_circularity'],np.zeros_like(df_car['distance_circularity']),marker='|',color='blue',alpha=0.4)\nplt.scatter(df_van['distance_circularity'],np.zeros_like(df_van['distance_circularity']),marker='o',color='yellow',alpha=0.4)\nplt.xlabel('distance_circularity')\nplt.show()\nplt.scatter(df_bus['hollows_ratio'],np.zeros_like(df_bus['hollows_ratio']),marker='s',color='Red',)\nplt.scatter(df_car['hollows_ratio'],np.zeros_like(df_car['hollows_ratio']),marker='|',color='blue',alpha=0.4)\nplt.scatter(df_van['hollows_ratio'],np.zeros_like(df_van['hollows_ratio']),marker='d',color='green',alpha=0.4)\nplt.xlabel('hollows_ratio')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameters like Circularity , distnace circularity & hollows ratio for all the vehicle types Van, Bus and Car seem to overlap with each other with some slight varition and it looks tough to differentiate classes with these attributes visually."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(df_bus['elongatedness'],kde=True,color='r',hist=False,label=\"Bus\")\nsns.distplot(df_car['elongatedness'],kde=True,color='G',hist=False,label=\"Car\")\nsns.distplot(df_van['elongatedness'],kde=True,color='B',hist=False,label=\"Van\")\nplt.legend()\nplt.title(\"elongatedness Distribution\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of elongatedness for car seems to be more compared to bus and van"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(df_bus['max.length_rectangularity'],kde=True,color='r',hist=False,label=\"Bus\")\nsns.distplot(df_car['max.length_rectangularity'],kde=True,color='G',hist=False,label=\"Car\")\nsns.distplot(df_van['max.length_rectangularity'],kde=True,color='B',hist=False,label=\"Van\")\nplt.legend()\nplt.title(\"max.length_rectangularity Distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.scatterplot(df['scaled_radius_of_gyration'],df['scaled_variance'],hue=df['class'],markers='+')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaled Radius of gyration and scaled variance have a linear relationship for all vehicle types."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the corelation between columns in tabular format \n#core=df.corr()\n#print(core)\n#Using Pair plot to visualize the corelation\nsns.pairplot(df,hue='class');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Pairplot Analysis:\n\n##### Through The Diagonal :\n1. Through the diagonal, the density distribution clearly states that for each class there are some differences in the distribution of attributes though there is some overlap.\n2. Mostly, the distribution seems normal and data might have been collected from multiple gaussians or multiple source.\n3. We could see multiple peaks for same class distribution.\n\n##### Upper part of the Diagnol:\n1. In pairplot analysis , it's fine if we consider any one part of plot either the upper or lower from the diagonal as the other is the mirror image.\n2. We could observe that some features have a positive linear realtionship with each other.\n3. Some have negative linear relation ship and some do not have any relation(Cloud like Figures).\n\n#### Along the diagonal , there seem to be noise present to our data, some attributes have extended tails (both left & right) , As we proceed further its important to take care of these in data preprocessing.\n\n#### We can use some techniques like Zscore or IQR score "},{"metadata":{},"cell_type":"markdown","source":"#### Box PLot to identify the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,12))\nsns.boxplot(data=df) \nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Box Plot Observation :\n\n1. Most of out independent features have the central tendancy exactly at the middle, except some which are skewed.\n2. There are outliers in columns radius_ratio,axis aspect_ratio,max length aspect ratio, scaled radius of gyration etc, we can see if these attributes have impact on our analysis further in feature engineering. If they do we should think of options to handle outliers. \n3. If these attributes do not have impact on our analysis we could also ignore these columns before traning our model.\n4. In this dataset the attributes having outliers are getting dropped from the analysis , The reaon being these attributes also have high collineratity , In order to avoid the multicolliniearity dispute I have dropped them in the upcoming steps. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Mostly, all our attributes in the dataset have symmentrical distribution \n\n1. pr.axis_aspect_ratio,max.length_aspect_ratio,scaled_radius_of_gyration.1 have positive skewness and the tail is very high towrdas the right from the median.\n2. hollows_ratio alone has a negative skewness where the tail is towards left and away from the median."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,15))\nsns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Attribute Selection \n\nFrom the above heatmap, it is evident that there is a lot of positive correlation between the attributes.\n\nWhen we have two variables which are highly coreraled, it is better to drop one as it may cause the problem of multicollinearity. \n\nFor this problem statement , I am using a threshold of 0.93(0.93 allows me to delete one more column than 0.95) to remove variables those have high correlation and I am going to drop them as they contain redundant information."},{"metadata":{"trusted":true},"cell_type":"code","source":"Cor_Matrix=df.corr().abs()\nCor_Matrix\nupper_tri = Cor_Matrix.where(np.triu(np.ones(Cor_Matrix.shape),k=1).astype(np.bool))\n#print(upper_tri)\nto_drop =[column for column in upper_tri.columns if any(upper_tri[column] > 0.93)]\n\nprint(\"These columns can be dropped as they are redundant:\",to_drop[0:6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Attribute Selection For Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.drop(['elongatedness','pr.axis_rectangularity','max.length_rectangularity','scaled_variance','scaled_variance.1'],axis=1)\nprint(\"The Number of Rows in our dataset :{} & Number of columns after remving multicollinearity:{}\".format(df1.shape[0],df1.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,12))\nsns.boxplot(data=df1) \nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Outlier Removal : After selecting the features as above we could see that , we still have the outliers present in the dataset for some attributes.\n\n###### How are we going to handle them??\n\n###### We are going to find the IQR range for each column (Q3 -Q1 ), and remove any data points beyond that range to remove outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#IQR Calculation \n\nQ1=df1.quantile(0.25)\nQ3=df1.quantile(0.75)\nIQR= Q3 - Q1\n\nIQR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df1[~((df1 < (Q1 - 1.5 * IQR)) |(df1 > (Q3 + 1.5 * IQR))).any(axis=1)]\ndf1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we have removed outliers and the number of rows in our original data has been reduced from 846 to 815\n\n##### Lets again plot a box plot and see the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,12))\nsns.boxplot(data=df1) \nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see , Outliers have been removed from dataset and our data looks clean."},{"metadata":{},"cell_type":"markdown","source":"### SVM on Raw Data with Scaling \n\n1. We are not certain about unit of measurement for all atributes in our data, by the looks of it we could see that some have high magnitude and some have low mangnitude. \n2. Hence, it is better to scale our data to have them in the same scale.\n3. I am using Standard Scaler here "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score,RocCurveDisplay\nfrom sklearn.preprocessing import StandardScaler\n\nX_MNMX=df1.drop(['class'],axis=1)\nY_MNMX=df1['class']\n#X_MNMX=X_MNMX.apply(zscore)\nX_Train,X_Test,Y_Train,Y_Test=train_test_split(X_MNMX,Y_MNMX,test_size=0.3,random_state=23)\nsc=StandardScaler()\nX_Train=sc.fit_transform(X_Train)\nX_Test=sc.transform(X_Test)\n\n\nSVM1=SVC(C=1.0,kernel='rbf')\nSVM1.fit(X_Train,Y_Train)\n#print(SVM1.score(X_Train,Y_Train))\n#print(SVM1.score(X_Test,Y_Test))\nPRED_SVM_M1=SVM1.predict(X_Test)\nCM_SVM_M1=confusion_matrix(Y_Test,PRED_SVM_M1)\n#print(CM_SVM_M1)\n\nprint(\"#####################Classification Report & Accuracy SCore#####################\")\nprint(\"----SVM Model ----\")\nprint(\"Model Score on Training data with selected features :{}\".format(SVM1.score(X_Train,Y_Train) * 100))\nprint(\"Model Score on Testing  data with selected features :{}\".format(SVM1.score(X_Test,Y_Test) * 100))\nprint(\"Accuracy Score of SVM on Test Data:{}\".format(accuracy_score(Y_Test,PRED_SVM_M1)*100))\nprint(classification_report(Y_Test,PRED_SVM_M1))\nsns.heatmap(CM_SVM_M1,annot=True,xticklabels=True,yticklabels=True,fmt='g',linewidths=.5,cmap='tab20c_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our SVM Model has a Accuracy score of 93.46, Mostly our model has predicted the class of vehicles correctly though there are some misclassifications\n\nOur Precision & recall scores are also observed to be good."},{"metadata":{},"cell_type":"markdown","source":"### k- Fold CROSS VALIDATION "},{"metadata":{},"cell_type":"markdown","source":"#### Cross Validation is a technique to evaluate  performance of the model and see how well it can perform on \"unseen data\".\n#### The K value set  is the number of folds that splits the data into folds, when the estimator trains on k-1 folds , it tests the performance on the left out fold and publishes the score .\n#### This process is iterated and accuracy score gets collected for each iteration with change in fold.\n#### Standard deviation is calculated on the K accuracy scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying k-Fold Cross Validation \nfrom sklearn.model_selection import KFold,cross_val_score\nFolds=10\nseed=23\nkfold=KFold(shuffle=True,n_splits=Folds,random_state=seed)\naccuracies = cross_val_score(estimator = SVM1, X = X_MNMX, y = Y_MNMX, cv = kfold) \naccuracies\nprint(\"K Fold score mean:{}\".format(accuracies.mean()*100))\nprint(\"K Fold score standard deviation:{}\".format(accuracies.std()*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As you can see from the above code , we have received a mean accuracy score of 65.9% with a standard deviation of 2.38.\n#### What we can infer from this is that our SVM model on raw dataset can give us a accuracy 63.5% to 68.26% on unseen data.\n###### This score is not that great, We shall try to improve our models further"},{"metadata":{},"cell_type":"markdown","source":"### Principal Component Analysis \n#### The idea of PCA is to  reduce the dimensionality of a data set consisting of a large number of interrelated variables while retaining as much as possible of the variation present in the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import PCA from sklearn\nfrom sklearn.decomposition import PCA\nfrom scipy.stats import zscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping those columns which had high correlation that we found during EDA\ndf=df.drop(['elongatedness','pr.axis_rectangularity','max.length_rectangularity','scaled_variance','scaled_variance.1'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### PCA STEP 1 :\n######  Scaling the independent variables as different units of measure & magnitude will have impact in the PCA analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale and split data \nX_PCA=df.drop(['class'],axis=1)\nY_PCA=df['class']\nX_PCA=X_PCA.apply(zscore)\n\nPC=PCA(n_components=10,random_state=23)\nPC_DF=PC.fit_transform(X_PCA)\n#X_Train_PCA=PC.transform(X_PCA_Train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### PCA STEP 2 :\n##### Create the covarience matrix "},{"metadata":{"trusted":true},"cell_type":"code","source":"covMatrix = np.cov(X_PCA,rowvar=False)\nplt.subplots(figsize=(7,7))\nsns.heatmap(covMatrix,annot=True,cmap='afmhot_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### PCA STEP 3:\n##### Find the Eigen values & Eigen vectors"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"##############Eigen Values##############\")\nprint(PC.explained_variance_)\nprint(\"##############Eigen Vectors##############\")\nprint(PC.components_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### PCA STEP 4 :\n##### Find the amount of varience captured by each  principal components and visulize them "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(list(range(1,11)),PC.explained_variance_ratio_, align='center')\nplt.ylabel('Variation explained')\nplt.xlabel('eigen Value')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.step(list(range(1,11)),np.cumsum(PC.explained_variance_ratio_), where='mid')\nplt.ylabel('Cum of variation explained')\nplt.xlabel('eigen Value')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Principal Components that capture about 95% of the variance in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Explained variation per principal component: {}'.format(PC.explained_variance_ratio_))\nP_Components=PC.explained_variance_ratio_\nprint(\"The Ideal number of components that could explain:{}% of variance in data is 7\".format(np.sum(P_Components[0:7])*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating a dataframe  and using Principal Components instead of the original data"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_DF=pd.DataFrame(data=PC_DF,columns = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10'])\n\nPCA_DF['Y']=Y_PCA\nPCA_DF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(PCA_DF,diag_kind='kde');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As shown by the pairplot all our PCA components are independent , and we are not able to see any correlation between each other and have normal distribution"},{"metadata":{},"cell_type":"markdown","source":"#### Support Vector Machine on PCA data "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_PCA_DF=PCA_DF.drop(['Y'],axis=1)\nY_PCA_DF=PCA_DF['Y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_PCA_Train,X_PCA_Test,Y_PCA_Train,Y_PCA_Test=train_test_split(X_PCA_DF,Y_PCA_DF,test_size=0.3,random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCA_Final=PCA(n_components=7,random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM3=SVC(C=1.0,kernel='rbf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM3.fit(X_PCA_Train,Y_PCA_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PRED_PCA=SVM3.predict(X_PCA_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CM_SVM_PCA=confusion_matrix(Y_PCA_Test,PRED_PCA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"#####################Classification Report & Accuracy SCore of PCA Data  on SVM#####################\")\nprint(\"----SVM Model ----\")\nprint(\"Model Score on Training data with PCA features :{}\".format(SVM3.score(X_PCA_Train,Y_PCA_Train) * 100))\nprint(\"Model Score on Testing  data with PCA features :{}\".format(SVM3.score(X_PCA_Test,Y_PCA_Test) * 100))\nprint(\"Accuracy Score of SVM on Test Data:{}\".format(accuracy_score(Y_PCA_Test,PRED_PCA)*100))\nprint(classification_report(Y_PCA_Test,PRED_PCA))\nsns.heatmap(CM_SVM_PCA,annot=True,xticklabels=True,yticklabels=True,linewidths=.5,cmap='tab20c_r',fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### k- Fold CROSS VALIDATION "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying k-Fold Cross Validation \nfrom sklearn.model_selection import cross_val_score,KFold\nkfold_pca=KFold(shuffle=True,n_splits=10,random_state=23)\naccuracies = cross_val_score(estimator = SVM3, X = X_PCA_DF, y = Y_PCA_DF, cv = kfold_pca) \naccuracies\nprint(\"K Fold score mean:{}\".format(accuracies.mean()*100))\nprint(\"K Fold score standard deviation:{}\".format(accuracies.std()*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference : \n1. First, we did SVM on this dataset with 14 attributes and we got a model score of 93% on test data, Through KFOLD Cross   validation we evaluated that our model1 could give us accuracy of range 63.5% to 68.26% when exposed to unseen data.\n\n2. Secondly, we did PCA on the raw data. Identified that almost just 7 attributes could capture about 96% of varience in the data. This time , we perfomred the same SVM algorithm on this principal components.\n\n3. We could see that on test data on PCM components, our model gave a score of 94%. However, on K fold cross validation we could see that on unseen data our model could perform with a accuracy range 90.71 % to 97.45%. This is a really a great score.\n\nPCA plays a vital role. Ignoring the less impact variables it focuses on variables that can display high varience present in data and enhancing performance of our model.\n"},{"metadata":{},"cell_type":"markdown","source":"### Conclusion- \"When the Rubber meets the Road\"\n\n1. Though the Train and test scores of both Raw and PCA data through SVM were not that different, Evaluating their performance on unseen data using K Fold cross validation gave a phenomenol impact on  model bulit on PCA dataset. Furthermore, On large datasets PCA can be helpful minimizing the computaional cost, complexity of the model.\n2. Raw Data Cross Validation Range -  63.5% to 68.26%.\n3. PCA Data Cross Validation Range -  90.71%to 97.45% with a confidence intravel of 95%\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}