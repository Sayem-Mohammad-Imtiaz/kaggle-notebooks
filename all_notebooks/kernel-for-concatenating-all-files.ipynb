{"cells":[{"metadata":{},"cell_type":"markdown","source":"*Note:\nRealized that no data was captured during the 15th April 2020 run. Have updated the sheet with calculated values from the other fields. \n*\n\n1. Files are concatenated on the following fields: \n2. Calculated fields like `Tested /millionpeople` & `Positive /millionpeople` are removed. *I suggest those values are calculated from the actual population values, will be updating the dataset with a separate table for a country's population*\n3. Columns are normalized across all the files\n4. The following fields are subset -> `Country`, `Date`, `Tested`, `Positive`, `Positive/Tested %`,`Source_1`, `Source_2`\n5. A new field `FileDate` has been added, so that the data can be referred back to the source file\n\nModification for file for 15th April 2020\n\n1. Most of the values in the `Tests` column were missing.\n2. The value is calculated by using the following formula:\n\nTests conducted = ((Positives)/(Positive /millionpeople))* (Tests /millionpeople)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom datetime import datetime\n\nimport os\n\ndataFiles = list()\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        printName = os.path.join(dirname, filename)\n        print(printName)\n        dataFiles.append(printName)\n\nprint(len(dataFiles))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataDF = list()\n\nfor idx in range(len(dataFiles)):\n    try:\n\n        dataDict = dict()\n        filename = dataFiles[idx]\n        \n        if 'AllDates' in filename:\n            dataDict['Date'] = 'AllDates'\n        else:\n            dataDict['Date'] = filename.split('_')[-1].split('.')[0]\n        \n        if 'xlsx' in filename:\n            dataDict['Data'] = pd.read_excel(filename)\n        else:\n            dataDict['Data'] = pd.read_csv(filename)\n\n        dataDF.append(dataDict)\n        \n    except:\n        print(f\"Error in {idx}# \", filename.split('/')[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"april15Idx = None\nmar30Idx = None\n\nfor idx in range(len(dataDF)):\n    print(f\"{idx}# \", dataDF[idx]['Date'])\n    if '15Apr' in dataDF[idx]['Date']:\n        april15Idx = idx\n        \n    print(dataDF[idx]['Data'].columns)\n    print(\"#####################################\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adjusting for 15th April\n\nif april15Idx:\n    dataDF[april15Idx]['Data']['Tests'] = round(dataDF[april15Idx]['Data']['Tests /millionpeople']*(dataDF[april15Idx]['Data']['Positive']/dataDF[april15Idx]['Data']['Positive /millionpeople']), 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDF[april15Idx]['Data'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor idx in range(len(dataDF)):\n    if dataDF[idx]['Date'] == 'AllDates':\n        continue\n        \n    dataDF[idx]['Data'].rename(columns={'Country or region': 'Country', 'Country or territory': 'Country',\n                         'As of': 'Date', \n                         'Total tests': 'Tested', 'Tests': 'Tested',\n                        'Positive/ thousands': 'Positive /millionpeople', 'Positive /millionpeople': 'Positive /millionpeople',\n                        'Tests /millionpeople': 'Tested /millionpeople', 'Tests/ million': 'Tested /millionpeople',\n                                       'Source': 'Source_1'}, inplace=True)\n    try:\n        dataDF[idx]['Data']['Positive/Tested %'] = round(100*(dataDF[idx]['Data']['Positive'] / dataDF[idx]['Data']['Tested']),2)\n    except:\n        print(f\"ERROR: In calculating %age {idx}# \", dataDF[idx]['Date'])\n    \n    if 'Units' not in list(dataDF[idx]['Data'].columns):\n        dataDF[idx]['Data']['Units'] = 'NA'\n    \n    if dataDF[idx]['Date'] == 'Conducted':\n        # For the 30March File\n        dataDF[idx]['Data'] = dataDF[idx]['Data'][['Country', 'Date', 'Tested','Source_1']]\n    else:\n\n        try:\n            dataDF[idx]['Data'] = dataDF[idx]['Data'][['Country', 'Date', 'Tested', 'Units','Positive', 'Positive/Tested %','Source_1', 'Source_2']]\n        except:\n            print(f\"ERROR: In subsetting columns {idx}# \", dataDF[idx]['Date'])\n\n    # Normalize the dates to the same format %d %b %Y ie 26 Apr 2020 (final expected)\n    \n    splitDate = dataDF[idx]['Data']['Date'].str.split().loc[0]\n    if len(splitDate) == 2:\n        dataDF[idx]['Data']['Date'] = dataDF[idx]['Data']['Date'].str.split().str.join(' ') + ' 2020' \n    else:\n        dataDF[idx]['Data']['Date'] = dataDF[idx]['Data']['Date'].str.split().str.join(' ')\n    \n    dataDF[idx]['Data']['FileDate'] = dataDF[idx]['Date']\n    \n    dataDF[idx]['Data'].reset_index(inplace=True, drop=True)\n    \n#     if 'Positive /millionpeople' in dataDF[idx]['Data'].columns.to_list():\n#         dataDF[idx]['Data']['Tests_calculated'] = (dataDF[idx]['Data']['Positive']/ dataDF[idx]['Data']['Positive /millionpeople'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDF[1]['Data'].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"completeDF = pd.DataFrame()\n\nfor idx in range(len(dataDF)):\n    if dataDF[idx]['Date'] == 'AllDates':\n        continue\n    completeDF = pd.concat([completeDF, dataDF[idx]['Data']])\n\ncompleteDF.dropna(subset=['Date'], inplace=True)\n\ncompleteDF.reset_index(inplace=True, drop=True)\nprint(completeDF.shape)\ncompleteDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment if you are not comfortable with using the 15th April 2020 data\n# completeDF = completeDF.drop(completeDF[completeDF['FileDate'] == '15April2020'].index)\n# completeDF['FileDate'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"completeDF.to_csv('TestsConducted_AllDates_11May2020.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}