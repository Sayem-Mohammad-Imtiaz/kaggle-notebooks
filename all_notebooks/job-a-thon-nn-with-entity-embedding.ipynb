{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nseed = 123\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom catboost import CatBoostClassifier \nfrom skopt.space import Real, Categorical, Integer\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nuse_pretrained =  False\nuse_pca = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/jobathon-analytics-vidhya/train.csv\")\ntest = pd.read_csv(\"../input/jobathon-analytics-vidhya/test.csv\")\nsample = pd.read_csv(\"../input/jobathon-analytics-vidhya/sample_submission.csv\")\ntrain.rename(columns={'Health Indicator': 'Health_Indicator'}, inplace=True)\ntest.rename(columns={'Health Indicator': 'Health_Indicator'}, inplace=True)\ntrain = train.drop([\"ID\"], axis=1)\ntest = test.drop([\"ID\"], axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if use_pretrained:\n    train = pd.read_csv('/kaggle/input/jobathon/x.csv')\n    test = pd.read_csv('/kaggle/input/jobathon/test.csv')\n    y = pd.read_csv('/kaggle/input/jobathon/y.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['City_Code', 'Region_Code', 'Accomodation_Type', 'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse', 'Health_Indicator', \n            'Holding_Policy_Duration',  'Holding_Policy_Type', 'Reco_Policy_Cat']\nnumeric_col = 'Reco_Policy_Premium'\ntarget = 'Response'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scalar = StandardScaler()\ntrain[numeric_col] = scalar.fit_transform(train[numeric_col].values.reshape((-1,1)))\ntest[numeric_col] = scalar.fit_transform(test[numeric_col].values.reshape((-1,1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    print(f' {col} --> {train[col].nunique()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing embedding inputs layers\ninputs = []\nmodels = []\n\ndef create_mlp(train, cat_cols):\n\n    for col in cat_cols:\n        num_of_unique = int(train[col].nunique())\n        embedding_size = int(min(np.ceil(num_of_unique/2), 50))\n        print(f'{col} unique_value --> {num_of_unique}')\n        print(f'{col} embedding size {embedding_size}')\n\n        cat_in = tf.keras.layers.Input(shape=(1,))\n        x = tf.keras.layers.Embedding(num_of_unique + 1,embedding_size, name=col )(cat_in)\n        x = tf.keras.layers.SpatialDropout1D(0.3)(x)\n        out = tf.keras.layers.Reshape(target_shape=(embedding_size,))(x)\n        inputs.append(cat_in)\n        models.append(out)\n\n\n    numeric_in = tf.keras.layers.Input(shape=(1,), name='Reco_Policy_Premium')\n    out = tf.keras.layers.Dense(2048, activation='relu' )(numeric_in)\n    out =  tf.keras.layers.Dense(1024, activation='relu' )(out)\n    inputs.append(numeric_in)\n    models.append(out)\n\n    # dense layers\n    model = tf.keras.layers.Concatenate()(models)\n\n    x = tf.keras.layers.Dense(1024, activation='relu')(model)\n    x = tf.keras.layers.Dropout(.35)(x)\n    x = tf.keras.layers.Dense(512, activation='relu')(x)\n    x = tf.keras.layers.Dropout(.15)(x)\n    x = tf.keras.layers.Dense(256, activation='relu')(x)\n    x = tf.keras.layers.Dropout(.15)(x)\n    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    \n\n\n\n    model = tf.keras.Model(inputs, output)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n    return model\n    print('model compiled')\nmodel = create_mlp(train, cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, test_x, train_y, test_y = train_test_split(train.drop(target, axis=1), train[target], stratify=train[target], random_state=seed, test_size=0.2)\ntrain_x.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if use_pca:\n    for i in range(20,76, 5):\n        pca = PCA(n_components=i, svd_solver='full')\n        pca.fit_transform(train)\n        print('components: ',i,'explained variance: ', pca.explained_variance_ratio_.sum() * 100)\n    pca =  PCA(n_components=75, svd_solver='full')\n    \n    transformed = pca.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting data to list format to match the network structure\ndef preproc(X_train, X_val, X_test):\n\n    input_list_train = []\n    input_list_val = []\n    input_list_test = []\n    \n    #the cols to be embedded: rescaling to range [0, # values)\n    for c in cat_cols:\n        raw_vals = X_train[c].unique()\n        val_map = {}\n        for i in range(len(raw_vals)):\n            val_map[raw_vals[i]] = i       \n        input_list_train.append(X_train[c].map(val_map).values)\n        input_list_val.append(X_val[c].map(val_map).fillna(0).values)\n        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\n     \n    #the rest of the columns\n#     other_cols = [c for c in X_train.columns if (not c in numeric_col)]\n    input_list_train.append(X_train[numeric_col].values)\n    input_list_val.append(X_val[numeric_col].values)\n    input_list_test.append(X_test[numeric_col].values)\n    \n    return input_list_train, input_list_val, input_list_test    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, test_x, test = preproc(train_x, test_x, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"epochs = 200\nbatch_size = 512\n\n\nearlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=20,\n                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('./model.h5', monitor='val_auc', verbose=1, save_best_only=True, mode='max')\nreduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n                                      patience=20, min_lr=1e-6, mode='max', verbose=1)\n\nhistory = model.fit(train_x, train_y.values, \n                    validation_data=(test_x, test_y.values),\n                    callbacks=[earlyStopping, reduce_lr_loss, checkpoint],\n                    batch_size=batch_size,\n                    epochs=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.load_model('./model.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss']) \nplt.plot(history.history['auc']) \nplt.title('model auc') \nplt.ylabel('auc')\nplt.xlabel('epoch') \nplt.legend(['loss', 'auc'], loc='upper left') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = np.zeros((len(train)))\ntest_preds = np.zeros((len(test)))\n\nskf = StratifiedKFold(n_splits=50)\nfor train_index, test_index in skf.split(train_x, train[target].values):\n    X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n    X_train = X_train.reset_index(drop=True)\n    X_test = X_test.reset_index(drop=True)\n    y_train, y_test = X_train.target.values, X_test.target.values\n    train_x, test_x, test = preproc(train_x, test_x, test)\n    model = create_model(data, features)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n    X_train = [X_train.loc[:, features].values[:, k] for k in range(X_train.loc[:, features].values.shape[1])]\n    X_test = [X_test.loc[:, features].values[:, k] for k in range(X_test.loc[:, features].values.shape[1])]\n    \n    earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=20,\n                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint('./model.h5', monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n    reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n                                      patience=13, min_lr=1e-6, mode='max', verbose=1)\n    \n    model.fit(X_train,\n              utils.to_categorical(y_train),\n              validation_data=(X_test, utils.to_categorical(y_test)),\n              verbose=1,\n              batch_size=1024,\n              callbacks=[earlyStopping, checkpoint, reduce_lr_loss],\n              epochs=100\n             )\n    valid_fold_preds = model.predict(X_test)[:, 1]\n    test_fold_preds = model.predict(test_data)[:, 1]\n    oof_preds[test_index] = valid_fold_preds.ravel()\n    test_preds += test_fold_preds.ravel()\n    print(metrics.roc_auc_score(y_test, valid_fold_preds))\n    K.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(columns=['ID','Response'])\ntest_ = pd.read_csv('../input/jobathon/tabnet4_2021-02-27_0.703923581379631.csv')\nsub.ID = test_.ID\nsub.Response = model.predict(test).reshape(-1,)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('nn_sub5.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}