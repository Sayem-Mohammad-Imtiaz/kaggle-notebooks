{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import libraries and dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this first phase we import all the needed libraries and the data. We visualize a small sample of the data to have a fist understanding of the data structure.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import spacy\nimport numpy as np\nimport pandas as pd\nnlp = spacy.load('en_core_web_lg')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"true=pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")\nfalse=pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.sample(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, it seems that the text of the true news begins always with: \"CITY NAME (Reuters) - \", this doesn't happen in the fake news dataset as you can observe below.\nWe will remove this first part to have a more clean and homogeneous dataset, if fact, we wish that our classifier can learn to distinguish fake news from true news based on underlying pattern in the text. Mantaining this original setting we run the risk of a trivial classification based only in the presence of this initial part.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"false.sample(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From a first look we can notice an interesting behaviour: the title of a fake news seems to present a higher number of capital letters and punctuation rather than in the title of true news. We will study this phenomenon in the Exploratory Data Analysis session.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\nFirst of all we clean the True dataset. Each news text will start after the sentence \"CITY NAME (Reuters) - \".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_true_news(text):\n    try:\n        match = re.search(r'\\WReuters\\W\\s-\\s',text)\n        new_text=text[match.span()[1]:]\n    except: \n        new_text=text\n    return new_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true['text']=true['text'].apply(clean_true_news)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create the dicotomic target variable: it takes 1 if the news is true 0 if it's fake. \n\nWe then join the two dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"true[\"target\"]=1\nfalse[\"target\"]=0\ndf=pd.concat([true,false])\ndf.reset_index(drop=True,inplace=True)\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this session we will explore different patterns and visualize them to see if they can discriminate true news from fake news.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of token in the text:\ndef token_len(row_text):\n    row=nlp(row_text)\n    return len(row)\n\n#Number of sentences in the text\ndef n_of_sentences(row_text):\n    row=nlp(row_text)\n    tot_sent=[sentence for sentence in row.sents]\n    return len(tot_sent)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We compute the number of tokens both in the title than in the text.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title_len']=df['title'].apply(token_len)\ndf['text_len']=df['text'].apply(token_len)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also calculate the number of sentences in the news text.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text_sent']=df['text'].apply(n_of_sentences)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As mentioned before we add a feature that counts the number of capital letters in the title.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['capital_letters']=df['title'].apply(lambda x: len(re.findall(r'[A-Z]',x)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We finally add a feature to count the number of punctuation signs in the news title.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['non_alpha']=df['title'].apply(lambda x: len(re.findall(r'\\W',x)))\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two classes are almost balanced.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"chart=sns.countplot(x = \"subject\", hue = \"target\" , data = df)\nlabels=chart.get_xticklabels()\nchart.set_xticklabels(labels,rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The subject of the news seems to be extremely discriminative, there is only a subject where true news and fake news overlap: \"worldnews\". As we don't really know how the this subject is assigned and if the criteria are the same and to avoid that the classifier will overfit this specific dataset we won't use this variable during our classification.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"target\", y=\"title_len\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe that fake news generally have a longer title rather than true news.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"target\", y=\"text_len\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"target\", y=\"text_sent\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of tokens and of sentences are more or less the same. These fields are not discriminative for our problem.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"target\", y=\"capital_letters\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"target\", y=\"non_alpha\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we guess before, the two boxplots clearly show that the number of both capital letters and puctuation signs are higher in fake news rather than in true news. This is an important discovery as we can leverage this information to further improve ore classification.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blanks = []  \nfor i,text in df['text'].items():  \n    if text.isspace():         \n        blanks.append(i)     \nprint(len(blanks))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even if there are no missing values, some text are composed by blanks, i.e. just a white space, we won't discard this observations because as we can see in the next session, we will consider the title and the text jointly.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## News classification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will perform a two steps classification:\n1. First we will classify news only based on their text considering the title and the text together. The dataset will be transformed in a data term matrix with the term frequency-inverse document frequency (TF-IDF) method.\n2. The prediction of the first model will be used as input of a second model which takes in input also: the length of the title, the number of capital letters and the number of punctuation signs.\n\nWe will use for both the two steps a **Support Vector Machine** with linear kernel.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df['title']+' '+df['text']\ny=df['target']\nX_2=df[['title_len','capital_letters','non_alpha']]\nX_train, X_test, X_2_train, X_2_test, y_train, y_test = train_test_split(X,X_2,y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_1m, X_test_1m, X_test_2m, X_train_2m, y_1m, y_2m = train_test_split(X_train,X_2_train,y_train,test_size=0.5,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this second split we will use:\n* X_train_1m to train the first model, that one based only on the text\n* X_train_2m to train the second model based on the prediction of the first model and: title_len,capital_letters,non_alpha. The prediction of the first model is done on the dataset X_test_1m.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text_clf=Pipeline([('tfidf',TfidfVectorizer()),\n                  ('clf',LinearSVC())])\ntext_clf.fit(X_train_1m,y_1m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat1=text_clf.predict(X_test)\nprint(metrics.classification_report(y_test,yhat1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to see the improvment of this two steps method we first see the performance that we would obtain with just the first model:.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.accuracy_score(y_test,yhat1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the prediction field for the second step model:\nX_train_2m['y_predict']=text_clf.predict(X_test_1m)\n#save the prediction on the test set for the final model:\nX_2_test['y_predict']=text_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=LinearSVC(max_iter=10000,dual=False)\nclf.fit(X_train_2m,y_2m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat2=clf.predict(X_2_test)\nprint(metrics.classification_report(y_test,yhat2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.accuracy_score(y_test,yhat2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe how the used setting of the double step classifcation improves the results of the simple text classification model.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}