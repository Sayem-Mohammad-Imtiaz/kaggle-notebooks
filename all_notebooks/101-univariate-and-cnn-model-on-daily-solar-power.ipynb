{"cells":[{"metadata":{},"cell_type":"markdown","source":"These notebooks are based on the excellent article by Jason Brownlee:\nHow to Develop Convolutional Neural Network Models for Time Series Forecasting.  \nhttps://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/\n\nThese are the notebook that follow:  \n102_Multivariate_multiple_input_series_CNN  \n103_Sol_Elec_Gas_2_1B_Multivariate_mulitple_input  \n104_Sol_Elec_Gas_2_C_Multivariate_parallel_series_CNN_Model  \n105_Sol_Elec_Gas_2_D_Multivariate_parallel_multi_output_CNN_Model  \n106_Sol_Elec_Gas_3_Univariate_Multi_Step_CNN_Model  \n107_Sol_Elec_Gas_4_Multivariate_Multi_Step_CNN_Model  \n108_Sol_Elec_Gas_1_Univariate_LSTM_and_CNN_Model  \n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nimport tensorflow as tf\nimport keras\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test 101 : test prediction solarpower with Univariate series and CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('tf version', tf.__version__)\nprint('keras version', keras.__version__)\nprint('numpy version', np.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This notebook uses: tf 2.0.0  \nkeras 2.2.4\nnumpy 1.16.4"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsolarpower = pd.read_csv(\"../input/solarpanelspower/PV_Elec_Gas3.csv\",header = None,skiprows=1 ,names = ['date','cum_power','Elec_kW', \n                                                                            'Gas_mxm'], sep=',',usecols = [0,1,2,3],\n                     \n                     parse_dates={'dt' : ['date']}, infer_datetime_format=True,index_col='dt')\nprint(solarpower.head(2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make solar power stationary\n\nsolarpower2 = solarpower.shift(periods=1, freq='D', axis=0)\nsolarpower['cum_power_shift'] = solarpower2.loc[:,'cum_power']\nsolarpower['day_power'] = solarpower['cum_power'].values - solarpower['cum_power_shift']\nsolarpower.iloc[0:1].day_power.value = 0.\nA = solarpower.dropna()\ndel A['cum_power'], A['cum_power_shift']\nsolarpower = A","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solarpower.head(2), solarpower.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = solarpower[:'2018-10-28']\nX_valid = solarpower['2018-10-29':'2019-10-28'] # is 365 days\nX_train.shape, X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.tail(2), X_valid.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid_start_cum_power = solarpower2['2018-10-28':'2018-10-28'].cum_power.values\nX_valid_start_cum_power # we need this to predict cumulative power on validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we devide the series into multiple input and output patterns\n\ndef my_split_window(series, window):\n    '''\n    the series is split in (len(series)-window)-blocks of window size, \n    y is the next value that comes after the block, \n    every block starts with the next value in the series.\n    The last block ends with the last-but-one value in the series.\n    '''\n    X = []\n    y = []\n    n_steps = len(series) - window\n    for step in range(n_steps):\n        X.append(series[step:window+step])\n        y.append(series[step + window])\n    X = np.array(X)\n    y = np.array(y)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# test my_split_window\nmy_series = np.array([10,20,30,40,50,60,70,80,90])\nX_, y_ = my_split_window(my_series, 3)\nX_, y_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply my_split_window on dayly solar power with a window of 365 days (we do not make account for leap years)\n# the input series is the daily solar power\ntrain_power_series = X_train.day_power.values\nwindow = 365\nX, y = my_split_window(train_power_series, window)\n# print a sample\nfor i in range(3):\n    print(X[i][-5:], y[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want to use a one-dimensional Convolutional Neural Network (1D CNN). Just like in a CNN for images,  \na 1D CNN extracts features. It is very usefull in timeseries. More info is on theze links:  \nhttps://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/  \nhttps://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# we have an input shape = window size, number of features \n# we use only 1 feature (it is univariate) and we have a window size of one year (365 days) \n# we have to reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv1D(filters=32, kernel_size=4, activation='relu', \n                                 input_shape=(window, n_features)))\nmodel.add(tf.keras.layers.MaxPooling1D(pool_size=2))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(50, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\nmodel.compile(optimizer='adam', loss='mae')  # metrics=['mae'])\n# fit model\nhistory = model.fit(X, y, epochs=600, verbose=0)\n\n# graph of the loss shows convergence\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title('loss')\nplt.xlabel('epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting next year\nx_input = np.array(X_train.day_power[-365:]) #  next value based on data of last year\nx_input = x_input.reshape((1, window, n_features)) # the model expects three dimensions as input (samples, window, features)\n\nfor i in range(365):\n    y_hat = model.predict(x_input, verbose=0)\n    new_x = y_hat.reshape((1,1,1))\n    x_input = np.concatenate((x_input[:, -364:], new_x), axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_predicted = x_input.reshape((x_input.shape[1]))\nplt.plot(y_predicted, label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_r2_score = r2_score(y_true, y_predicted) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true, y_predicted)\nprint('r2_score %.4f' % first_r2_score)\nprint('mae %.2f' % first_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data = X_valid.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data['101_predicted_from_predicted'] = y_predicted\npredicted_data.to_hdf('../predicted_data.hdf5', key = 'predicted_data ', table='true', mode='a')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"100 epochs : \nr2_score 0.2358\nmae 5.32"},{"metadata":{},"cell_type":"markdown","source":"# but the cumulative power is actually much more interesting.#\n# It tels us what the the total expected solar power of that year will be. #"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cumulate(series, start=0):\n    '''\n    start is the starting cumulative power, the series is the daily solar power\n    a list with daily cumulative power is the result\n    '''\n    cum = [start]\n    for i in range(len(series)):\n        sum_plus = cum[i] + series[i]\n        cum.append(sum_plus)\n    return cum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_predicted)\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error increases after 4 months"},{"metadata":{"trusted":true},"cell_type":"code","source":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# But what if we use y_hat to train the model again for every day?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting next year\nx_input = np.array(X_train.day_power[-365:]) #  next value based on data of last year\nx_input = x_input.reshape((1, window, n_features))\ny_hat = model.predict(x_input, verbose=0)\nfor i in range(365):\n    new_x = y_hat.reshape((1,))\n    train_power_series = np.concatenate((train_power_series, new_x), axis=0)\n    X, y = my_split_window(train_power_series, window)\n    X = X.reshape((X.shape[0], X.shape[1], n_features))\n    history = model.fit(X, y, epochs=3, verbose=0)\n    x_input = train_power_series[-365:]\n    x_input = x_input.reshape((1, window, n_features))\n    y_hat = model.predict(x_input, verbose=0)\n    if i % 40 ==0:\n        print('at i=', i, 'y_hat',y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predicted = x_input.reshape((x_input.shape[1]))\nplt.plot(y_predicted, label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_true, y_predicted) # Best possible score is 1.0 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae = mean_absolute_error(y_true, y_predicted)\nprint('mae %.2f' % mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now look at the cumulative power over one year"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_predicted)\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is better than without retraining but it grows too fast at the end"},{"metadata":{"trusted":true},"cell_type":"code","source":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data['101_predicted_from_retrained'] = y_predicted\npredicted_data.to_hdf('predicted_data.hdf5', key = 'predicted_data ', table='true', mode='a')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need both r2 score and mae to evaluate the quality of the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}