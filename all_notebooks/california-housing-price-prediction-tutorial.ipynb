{"cells":[{"metadata":{},"cell_type":"markdown","source":"## California Housing Price Prediction\n\nThe original dataset appeared in R. Kelley Pace and Ronald Barry, [“Sparse Spatial Autoregressions,” Statistics\n& Probability Letters 33, no. 3 (1997): 291–297](hhttp://www.spatial-statistics.com/pace_manuscripts/spletters_ms_dir/statistics_prob_lets/html/ms_sp_lets1.html)\n\nThe task is to build a model of housing prices in California using the California census dataset. This data has metrics such as the population, median income, median housing price, and so on for each block group (district) in California.\n\n\nWe need to predict district’s median housing prices. Thus, we need to train a model to predict a district's median housing price based on other data of the district. We will use the census data for this purpose.\n\nSo the task at hand is clearly a typical supervised learning task. Moreover, it is also a multivariate regression task, since we are asked to predict a value. We will be using Root Mean Square Error (RMSE) as our performance measure.\n\nPress \"Upvote\" the notebook if you find the notebook interesting and helpful. You can also \"Fork\" at the top-right of this screen to run this notebook yourself and build each of the examples."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing required libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Loading the dataset\nhousing  = pd.read_csv('../input/california-housing-prices/housing.csv')\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To get a quick desciption of the data, in particular the total number of rows, and each attribute’s type and number of non-null values \nhousing.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are **20,640** instances in the dataset. Notice that the ***total_bedrooms*** attribute has only 20,433 non-null values, meaning that 207 districts are missing this feature. All attributes are numerical, except the ***ocean_proximity*** field. "},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"ocean_proximity\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To undestand the summary of the numerical attributes.\nhousing.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To plot a histogram to understand the data\nhousing.hist(bins=50, figsize=(20,15))\nplt.savefig(\"attribute_histogram_plots.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a test set\nWe select random 20% of dataset as a test set using Scikit-Learn's *train_test_split* function."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The median income is a very important attribute to predict median housing prices.\n# We need to ensure that the test set is representative of the various categories of incomes in the whole dataset.\n# Therefore, we are creating an income category column to divide median_income is different categories (5 here)\n\nhousing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n                               labels=[1, 2, 3, 4, 5])\n\nhousing[\"income_cat\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"income_cat\"].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we need to do stratified sampling based on the income category. \nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To check whether we have divided the instances in all the income categories proportionally.\nhousing[\"income_cat\"].value_counts() / len(housing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the income_cat column from the datasets\nfor set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Discover and visualize the data to gain insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = strat_train_set.copy()\nhousing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize = (8,6), alpha=0.1)\nplt.savefig(\"visualization_plot.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot shows density of houses respective to its longitude & latitude."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's take housing prices into consideration\nhousing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.title('California housing prices')\nplt.legend()\nplt.savefig(\"housing_prices_scatterplot.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The radius of each circle represents the district’s population (s), and the color represents the price (c).\n\nWe used a predefined color map (option cmap) called jet, which ranges from blue (low values) to red (high prices)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# If you are aware of California map, you can see that the housing prices are high near the coastal area.\n\n# Optional\nimport matplotlib.image as mpimg\ncalifornia_img=mpimg.imread('../input/california-housing-feature-engineering/california.png')\nax = housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize=(10,7),\n                       s=housing['population']/100, label=\"Population\",\n                       c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n                       colorbar=False, alpha=0.4,\n                      )\nplt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5,\n           cmap=plt.get_cmap(\"jet\"))\nplt.ylabel(\"Latitude\", fontsize=14)\nplt.xlabel(\"Longitude\", fontsize=14)\n\nprices = housing[\"median_house_value\"]\ntick_values = np.linspace(prices.min(), prices.max(), 11)\ncbar = plt.colorbar()\ncbar.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\ncbar.set_label('Median House Value', fontsize=16)\n\nplt.legend(fontsize=16)\nplt.savefig(\"california_housing_prices_plot.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's look for correlations between attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the corr_matrix, we can see the attributes that are likely to be correlate. \n\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\"housing_median_age\"]\nscatter_matrix(housing[attributes], figsize=(12, 8))\nplt.savefig(\"scatter_matrix_plot.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The median house value seems to be highly correlated to the median_income among others.\n\nhousing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)\nplt.axis([0, 16, 0, 550000])\nplt.savefig(\"income_vs_house_value_scatterplot.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations from the scatter plot:\n1. The correlation is indeed very strong, you can clearly see the upward trend and the points are not too dispersed.\n2. The price cap that we noticed earlier is clearly visible as a horizontal line at USD 500,000.\n3. There is less obvious straight lines at USD 450,000 &  USD 350,000."},{"metadata":{},"cell_type":"markdown","source":"Now the total number of rooms or bedrooms in a district is not very useful. The number of rooms per household, bedrooms per rooms and population per household seems useful attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\nhousing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\nhousing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the correlation\ncorr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare the Data for Machine Learning Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\nhousing_labels = strat_train_set[\"median_house_value\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_incomplete_rows = housing[housing.isnull().any(axis=1)]\nsample_incomplete_rows.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning\n\nOnly the total_bedrooms attribute discloses missing values. We can either delete those instances or delete the total_bedrooms attribute, or replace the missing values with median.\n\nNow, this selected dataset have missing values in only one attribute,  but we cannot be sure that there won’t be any missing values in new data. Therefore, we use Scikit-Learn's Imputer function to take care of all the missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n#housing.drop(\"total_bedrooms\", axis=1) # option 2\n#housing[\"total_bedrooms\"].fillna(housing[\"total_bedrooms\"].median()) # option 3\n\n# We are using Scikit-Learn's Imputer function here.\n\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy=\"median\")\n\n#Remove the text attribute because median can only be calculated on numerical attributes\nhousing_num = housing.drop('ocean_proximity', axis=1)\n\nimputer.fit(housing_num)\n\n# The imputer has simply computed the median of each attribute and stored the result in its statistics_ instance variable.\nimputer.statistics_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The trained imputer can transform the training set by replacing missing values by the learned medians\nX = imputer.transform(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X is a Numpy Array, change it to dataframe using pandas DataFrame function. \nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,index=housing.index)\nhousing_tr.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling Text and Categorical Attributes\n\nThe categorical attribute *ocean_proximity* needs to be taken care of. We change the text labels to numbers using Scikit-Learn's OrdinalEncoder function. It encode categorical features as an integer array.\n\nFurther, we use OneHotEncoder encoder to convert integer categorical values into one-hot vectors to create one binary attribute per category.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nhousing_cat = housing[[\"ocean_proximity\"]]\ncat_encoder = OneHotEncoder(sparse=False)\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create a custom transformer to add extra attributes using Scikit-Learn's FunctionTransformer class that lets you easily create a transformer based on a transformation function."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import FunctionTransformer\n\n# get the right column indices: safer than hard-coding indices 3, 4, 5, 6\nrooms_ix, bedrooms_ix, population_ix, household_ix = [\n    list(housing.columns).index(col)\n    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n\ndef add_extra_features(X, add_bedrooms_per_room=True):\n    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n    population_per_household = X[:, population_ix] / X[:, household_ix]\n    if add_bedrooms_per_room:\n        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n        return np.c_[X, rooms_per_household, population_per_household,\n                     bedrooms_per_room]\n    else:\n        return np.c_[X, rooms_per_household, population_per_household]\n\nattr_adder = FunctionTransformer(add_extra_features, validate=False,\n                                 kw_args={\"add_bedrooms_per_room\": False})\nhousing_extra_attribs = attr_adder.fit_transform(housing.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build a pipeline for preprocessing the numerical attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n        ('std_scaler', StandardScaler()),\n    ])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_num_tr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])\n\nhousing_prepared = full_pipeline.fit_transform(housing)\nhousing_prepared.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}