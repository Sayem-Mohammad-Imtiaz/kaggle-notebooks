{"cells":[{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"### Tasks:\n\n\n\n\n\n\n### 1) Understanding the data\n### 2) Cleaning the data\n### 3) Visualising the data\n### 4) Analysing the data"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Understanding the data"},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"#### We have a dataset containing the business statistics of the existing Ramen brands and their perfomance in the countries across the world. We will use this dataset in our analysis and try to arrive at a feasable business model."},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/ramen-ratings/ramen-ratings.csv') # Loading the dataset\ndf.head() # Printing the fist 5 rows to see the available features","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"shape = df.shape\nprint(\"Rows :\",shape[0])\nprint(\"Columns :\",shape[1])","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"df.info(verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"#### Data Extracted from info() function:\n\n#### 1) Rows are 2580 and Columns are 7\n#### 2) There are 5 categorical columns and 2 numerical columns\n#### 3) Memory consumption: 141.2 KB"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Although stars is numberic but it is stored as string in the dataframe\n#Let's convert it into numeric value.\ndf['Stars']=pd.to_numeric(df['Stars'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"df.describe(include =\"all\")","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"#different types of Ramen styles\ndf['Style'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"#what columns have NaN values\ndf.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"# Sum of NaNs in each column\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Cleaning the data "},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"#### We see that column \"Style\" has <font color='orange'>2</font>, \"Stars\" has <font color='orange'>3</font>  and \"Top Ten\" has <font color='orange'>2543</font> NaNs. It is imperative that we handle these values before we jump in for EDA."},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# For all the NaNs in \"Top Ten\" column, we have assigned a temporary value 0.\n# we will deal with \"Top Ten\" column later.\ndf['Top Ten'].fillna(0, inplace=True)\n\n#section of dataframe with NaN values\ndf[df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Handling NaNs in Column \"Style\""},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"#Imputing style is not relevant in this case\n#espescially when only two rows have missing style values\n#so dropping the two rows with NaN in style\ndf.drop(2152, axis=0,inplace=True)\ndf.drop(2442, axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Handling NaNs in Column \"Stars\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#storing data with NaN in seperate dataframe\ndf_with_Nan = df[df.isnull().any(axis=1)]\ndf_with_Nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Taking mean rating of specific brand from specific country from where it is mssing.\n\nBelow is the logic used which will be generalized with for loop in next cell.\n\nOttogi = df.loc[(df['Brand']=='Ottogi') & (df['Country']=='South Korea')]\n\ndf.loc[32,'Stars'] = round(Ottogi.Stars.mean(),2)\n\n\nSamyang = df.loc[(df['Brand']=='Samyang Foods') & (df['Country']=='South Korea')]\n\ndf.loc[122,'Stars'] = round(Samyang.Stars.mean(),2)\n\n\nMi = df.loc[(df['Brand']=='Mi E-Zee') & (df['Country']=='South Korea')]\n\ndf.loc[993,'Stars'] = Mi(Samyang.Stars.mean(),2)"},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"for i in df_with_Nan.index:\n    subDf = df.loc[(df['Brand']==df_with_Nan.loc[i,'Brand']) & (df['Country']==df_with_Nan.loc[i,'Country'])]\n    mean = subDf['Stars'].mean()\n    df.loc[i,'Stars'] = round(mean,2)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"df.isna().sum() # Checking again for NaNs","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Remember we had stored dummy value \"0\" to the NaNs of column \"Top Ten\". Let us see how we can handle it."},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"df[df['Top Ten'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can we still '\\n' in our data\n# considering it as missing value let's fill it with 0 temporarily\ntop_ten_with_n=df[df['Top Ten'] == '\\n']\nfor i in top_ten_with_n.index:\n    df.loc[i,'Top Ten']=0","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"#creating seperate columns for each year\n#and fill with NaN\nyears=['2012','2013','2014','2015','2016']\nfor y in years:\n    df[y+'_rank']=np.nan","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"# for specific year with the help of regex.\n#Stroring the row number for each value.\n#Extracting the rank which is at the end of the string.\n#Storing the rank at the specific year column and specific row index we stored at step2.\n#Dropping the \"Top Ten\" column.\nfor rank in df['Top Ten'].values:\n    for y in years:\n        if re.search('^'+y,str(rank)):\n            index = df[df['Top Ten']==rank].index.values\n            rank_number = str(rank).split()[-1]\n            df.loc[index,y+'_rank'] = int(''.join([i for i in rank_number if i.isdigit()]))\ndf.drop('Top Ten', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"#it very clean that no rank is equal to 0 rank\ndf.fillna(0, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"df[\"2012_rank\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"df[\"2013_rank\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"df[\"2014_rank\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"df[\"2015_rank\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"df[\"2016_rank\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Visualise and Analyse"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Q) What is the popularity of ramens across the countries?"},{"metadata":{"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"v = df.Country.value_counts()\nv=v.sort_values(ascending=True)\nfig, ax = plt.subplots(figsize=(12,8))\nv.plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"#### Ramen is very popular and highly preferred in Asian countries like Japan,China,South korea etc. Exceptions are USA and UK. We can say that migration of people from Asian countries to USA and UK is high and that has resulted in high Ramen Consumption in those 2 countries."},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Q) Number of varities in each brand?"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"brands_name = df.Brand.value_counts()[:10].index\nbrand_size = df.Brand.value_counts()[:10].values\n\nfig,ax=plt.subplots(figsize=(15,4))\nax.bar(brands_name, brand_size, data=df)\nax.set_ylabel('Number of products')\nfor p in ax.patches:\n    an=ax.annotate(str(p.get_height()), xy=(p.get_x(),p.get_height()))\n    an.set_size(12)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"#### We see \"Nissin\" brand to be having the highest number of varities followed by \"Nongshim\" and \"Maruchan\" . "},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Q) Most prefered Ramen style"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"style=df.Style.value_counts()\nstyle","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"plt.pie(style[0:4],pctdistance=1.5,autopct=\"%2.01f%%\",radius=1.7,labels=['Pack','Bowl','Cup','Tray'],\n        explode=[0,0,0,0.3],\n       textprops={'fontsize': 14})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"a4_dims = (4, 10)\nfig, ax = plt.subplots(figsize=a4_dims)\nsns.scatterplot(ax=ax, data=df,y='Country',x='Style')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"#### \"Pack\" Style is most preferred with 59.6% and followed by \"Bowl\" and \"Cup\"(~18% each)"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Q) What is the density distribution for the \"Stars\" of Ramen?"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"sns.distplot(df['Stars'],hist=True,kde=True,bins=5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"#### The plot of density of \"Stars\" shows that it is \"Left Skewed\"."},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Have you noticed that Japan, USA and South Korea are the top 3 consumers of Ramen?"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"v = df.Country.value_counts()\nv=v.sort_values(ascending=True)\nfig, ax = plt.subplots(figsize=(12,8))\nv.plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Let's analyse further...."},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Top 3 most preferred brands in Japan, USA and South Korea?"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"japan=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4.5)]\nusa=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4.5)]\nsouth_korea=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4.5)]\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n\n# TITLE\nfig.suptitle('TOP RAMEN BRANDS')\naxes[0].set_title('TOP 3 MOST PREFFERED RAMEN BRANDS IN JAPAN',fontsize=10)\naxes[1].set_title('TOP 3 MOST PREFFERED RAMEN BRANDS IN USA',fontsize=10)\naxes[2].set_title('TOP 3 MOST PREFFERED RAMEN BRANDS IN SOUTH KOREA',fontsize=10)\naxes[0].set_ylabel('PREFFERED TIMES', fontsize=10)\naxes[0].set_xlabel('BRANDS', fontsize=10)\naxes[1].set_ylabel('PREFFERED TIMES', fontsize=10)\naxes[1].set_xlabel('BRANDS', fontsize=10)\naxes[2].set_ylabel('PREFFERED TIMES', fontsize=10)\naxes[2].set_xlabel('BRANDS', fontsize=10)\n\n# JAPAN\nx_jp= japan['Brand'].value_counts()\nx_jp= x_jp[:3,]\nsns.barplot(ax=axes[0],x=x_jp.index, y=x_jp.values,palette=\"Paired\")\n\n# USA\nx_usa= usa['Brand'].value_counts()\nx_usa= x_usa[:3,]\nsns.barplot(ax=axes[1],x=x_usa.index,y= x_usa.values,palette=\"hls\")\n\n# SOUTH KOREA\nx_sk= south_korea['Brand'].value_counts()\nx_sk= x_sk[:3,]\nsns.barplot(ax=axes[2],x=x_sk.index,y= x_sk.values,palette=\"Paired\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"}},"cell_type":"markdown","source":"### Star Rating Analysis in Japan"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"# NISSIN\njn1=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4)& (df['Brand']=='Nissin')]\njn2=df.loc[(df['Country'] == 'Japan') & (df['Stars'] < 4)& (df['Brand']=='Nissin')]\ntotjnp=jn1['Review #'].sum()\ntotjnn=jn2['Review #'].sum()\nrev1 = totjnp,totjnn\n\n# MYOJO\njmy1=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4)& (df['Brand']=='Myojo')]\njmy2=df.loc[(df['Country'] == 'Japan') & (df['Stars'] < 4)& (df['Brand']=='Myojo')]\ntotmyp=jmy1['Review #'].sum()\ntotmyn=jmy2['Review #'].sum()\nrev2 = totmyp,totmyn\n\n# MARUCHAN\njma1=df.loc[(df['Country'] == 'Japan') & (df['Stars'] >= 4)& (df['Brand']=='Maruchan')]\njma2=df.loc[(df['Country'] == 'Japan') & (df['Stars'] < 4)& (df['Brand']=='Maruchan')]\ntotmap=jma1['Review #'].sum()\ntotman=jma2['Review #'].sum()\nrev3 = totmap,totman\nlabels = 'Above 4.0','Below 4.0'\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0) \nfig ,ax=plt.subplots(1,3,figsize=(15,15))\nax[0].pie(rev1, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[1].pie(rev2, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[2].pie(rev3, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[0].set_title('NISSIN',fontsize=10)\nax[1].set_title('MYOJO',fontsize=10)\nax[2].set_title('MARUCHAN',fontsize=10)\nplt.show()\njapan_b1=df.loc[(df['Country'] == 'Japan') & (df['Brand']=='Nissin')]\njapan_b2=df.loc[(df['Country'] == 'Japan') & (df['Brand']=='Myojo')]\njapan_b3=df.loc[(df['Country'] == 'Japan') & (df['Brand']=='Maruchan')]\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\nfig.suptitle('Ratings Comparision')\naxes[0].set_title('NISSIN',fontsize=10)\naxes[1].set_title('MYOJO',fontsize=10)\naxes[2].set_title('MARUCHAN',fontsize=10)\nsns.countplot(ax=axes[0],x=\"Stars\", data=japan_b1, palette=\"muted\")\nsns.countplot(ax=axes[1],x=\"Stars\", data=japan_b2, palette=\"muted\")\nsns.countplot(ax=axes[2],x=\"Stars\", data=japan_b3, palette=\"muted\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"}},"cell_type":"markdown","source":"### Star Rating Analysis in USA"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"#Nongshim \nub1=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4)& (df['Brand']=='Nongshim')]\nusb1=df.loc[(df['Country'] == 'USA') & (df['Stars'] < 4)& (df['Brand']=='Nongshim')]\ntotub1=ub1['Review #'].sum()\ntotusb1=usb1['Review #'].sum()\nus1 = totub1,totusb1\n\n# NISSIN\nub2=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4)& (df['Brand']=='Nissin')]\nusb2=df.loc[(df['Country'] == 'USA') & (df['Stars'] < 4)& (df['Brand']=='Nissin')]\ntotub2=ub2['Review #'].sum()\ntotusb2=usb2['Review #'].sum()\nus2 = totub2,totusb2\n\n#Yamachan\nub3=df.loc[(df['Country'] == 'USA') & (df['Stars'] >= 4.5)& (df['Brand']=='Yamachan')]\nusb3=df.loc[(df['Country'] == 'USA') & (df['Stars'] < 4.5)& (df['Brand']=='Yamachan')]\ntotub3=ub3['Review #'].sum()\ntotusb3=usb3['Review #'].sum()\nus3 = totub3,totusb3\nlabels = 'Above 4.0','Below 4.0'\nlabel1=\"Above 4.5\",\"Below 4.5\"\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0) \nfig ,ax=plt.subplots(1,3,figsize=(15,15))\nax[0].pie(us1, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[1].pie(us2, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[2].pie(us3, explode=explode, labels=label1, colors=colors,autopct='%1.1f%%')\nax[0].set_title('Nongshim',fontsize=15)\nax[1].set_title('NISSIN',fontsize=15)\nax[2].set_title('Yamachan',fontsize=15)\nplt.show()\nusa_b1=df.loc[(df['Country'] == 'USA') &  (df['Brand']=='Nongshim')]\nusa_b2=df.loc[(df['Country'] == 'USA') &  (df['Brand']=='Nissin')]\nusa_b3=df.loc[(df['Country'] == 'USA') &  (df['Brand']=='Yamachan')]\nfig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\nfig.suptitle('Ratings Comparision')\naxes[0].set_title('NONGSHIM',fontsize=10)\naxes[1].set_title('NISSIN',fontsize=10)\naxes[2].set_title('YAMACHAN',fontsize=10)\nsns.countplot(ax=axes[0],x=\"Stars\", data=usa_b1, palette=\"muted\")\nsns.countplot(ax=axes[1],x=\"Stars\", data=usa_b2, palette=\"muted\")\nsns.countplot(ax=axes[2],x=\"Stars\", data=usa_b3, palette=\"muted\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"}},"cell_type":"markdown","source":"### Star Rating Analysis in South Korea"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"# PALDO\nsk1=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Paldo')]\nskb1=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] < 4)& (df['Brand']=='Paldo')]\ntotsk1=sk1['Review #'].sum()\ntotskb1=skb1['Review #'].sum()\nrev1 = totsk1,totskb1\n\n# NONGSHIM\nsk2=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Nongshim')]\nskb2=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] < 4)& (df['Brand']=='Nongshim')]\ntotsk2=sk2['Review #'].sum()\ntotskb2=skb2['Review #'].sum()\nrev2 = totsk2,totskb2\n\n# SAMYANG FOODS\nsk3=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Samyang Foods')]\nskb3=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] < 4)& (df['Brand']=='Samyang Foods')]\ntotsk3=sk3['Review #'].sum()\ntotskb3=skb3['Review #'].sum()\nrev3 = totsk3,totskb3\nlabels = 'Above 4.0','Below 4.0'\ncolors = ['yellowgreen', 'lightskyblue']\nexplode = (0.1, 0) \nfig ,ax=plt.subplots(1,3,figsize=(15,15))\nax[0].pie(rev1, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[1].pie(rev2, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[2].pie(rev3, explode=explode, labels=labels, colors=colors,autopct='%1.1f%%')\nax[0].set_title('PALDO',fontsize=15)\nax[1].set_title('NONGSHIM',fontsize=15)\nax[2].set_title('SAMYANG FOODS',fontsize=15)\nplt.show()\nsouth_k_b1=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Paldo')]\nsouth_k_b2=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Nongshim')]\nsouth_k_b3=df.loc[(df['Country'] == 'South Korea') & (df['Stars'] >= 4)& (df['Brand']=='Samyang Foods')]\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\nfig.suptitle('Ratings Comparision')\naxes[0].set_title('PALDO',fontsize=10)\naxes[1].set_title('NONGSHIM',fontsize=10)\naxes[2].set_title('SAMYANG FOODS',fontsize=10)\nsns.countplot(ax=axes[0],x=\"Stars\", data=south_k_b1, palette=\"muted\")\nsns.countplot(ax=axes[1],x=\"Stars\", data=south_k_b2, palette=\"muted\")\nsns.countplot(ax=axes[2],x=\"Stars\", data=south_k_b3, palette=\"muted\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This analysis is a team work by.\n1. Sujan Shirol (me)\n2. [Suhas](https://www.linkedin.com/in/suhasvs95/)\n3. [Subhomoy Chattopadhyay](https://www.linkedin.com/in/subhomoy-chattopadhyay-8664b21b5/)\n4. Yashovardhan T\n5. [Sonia Tripathi](https://www.linkedin.com/in/sonia-tripathi-400861178)\n6. [Shruthi M](https://www.linkedin.com/in/shruthi-m-989136116/)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}