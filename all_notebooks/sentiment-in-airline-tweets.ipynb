{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gensim\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\ndf_tweets = pd.read_csv('../input/Tweets.csv')\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tweets.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"list(df_tweets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6632cdb60cadc3cfd9c759a4e61bb56810bb0f4"},"cell_type":"code","source":"df_tweets[1:10][\n['airline_sentiment', \n 'airline_sentiment_confidence',\n 'negativereason',\n 'negativereason_confidence',\n 'airline',\n 'text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with pd.option_context('display.max_colwidth', 250):\n    for a in range(5):\n        print(df_tweets[a:a + 1]['text'].to_string())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a33e28a14d7a1b43687027c806c3a06c8c644518"},"cell_type":"code","source":"df_tweets['tweet'] = df_tweets['text'].str.split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00a2ff396d587eefbbb85c27f5c2f02fd05fc5b8"},"cell_type":"code","source":"#Convert each tweet to an array\ntweet_count = len(df_tweets['tweet'])\nprint(\"We have \" + str(tweet_count) + \" tweets.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c614d923f5896f90005fc1a3be201173ee6f934c"},"cell_type":"code","source":"model = gensim.models.Word2Vec( df_tweets['tweet'], size=50, window=10, min_count=2, workers=10)\nmodel.save(\"Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f1d3901a28475fd1b7ebb7884bf64aa68b155bc"},"cell_type":"code","source":"word = 'great'\nvector = model.wv.most_similar(positive=word)\n\nprint(word)\nprint(vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word = 'terrible'\nvector = model.wv.most_similar(positive=word)\n\nprint(word)\nprint(vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ffff0bfe908ee5036bd8d4a7ebf3d487b17fc88","scrolled":true},"cell_type":"code","source":"#Spacy Version\nimport spacy\nfrom spacy.tokenizer import Tokenizer\n\nnlp = spacy.load('en_core_web_lg') \ntokenizer = Tokenizer(nlp.vocab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33310555ce6a540e07c4482a671bf745033e3693"},"cell_type":"code","source":"df_model = df_tweets.loc[df_tweets['airline_sentiment'] != 'neutral']\ntotal_tweets = len(df_model)\nprint(\"Total tweets: \", total_tweets )\n\npositive_tweets = len(df_tweets['airline_sentiment'].loc[df_tweets['airline_sentiment'] == 'positive'])\nnegative_tweets = total_tweets - positive_tweets\n\nprint(\"Positive tweets: \", positive_tweets, '  ', round(100 * positive_tweets / total_tweets,2), '%' )\nprint(\"Negative tweets: \", negative_tweets, '  ', round(100 * negative_tweets / total_tweets,3), '%' )\n\n\ndf_model['target'] = pd.get_dummies(df_model['airline_sentiment'])['positive']\n\ndf_model = df_model.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8a675b7e1ca14ff015c8e2d75b878c0f2fee820"},"cell_type":"code","source":"\ndf_length = len(df_model)\ninputs = []\nfor n_step in range(0, df_length ):\n    if n_step %1000 == 0:\n        with pd.option_context('display.max_colwidth', 250):\n            print(df_model['text'][n_step:n_step+1])\n    tokens = nlp(str(df_model['text'][n_step:n_step+1]))\n    inputs.append(tokens.vector)\n    \ndf_vect = pd.DataFrame(inputs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"249c7b4b1e767bd8c4c23a00cc6a9230ce5f618b"},"cell_type":"code","source":"df_vect['text'] = df_model['text']\ndf_vect['target'] = df_model['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4428e4555666c82b9445dff7a7d38ab6252bf27"},"cell_type":"code","source":"df_vect.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e0e831e1bbcc84f9560809faca6e51e9cbc5018"},"cell_type":"code","source":"print(len(df_vect.loc[df_vect['target'] == 0]))\nprint(len(df_vect.loc[df_vect['target'] == 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a682207685243704f15b37cb8ef9788c49377d56"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\n\nfeat_list = list(df_vect)[:-2]\n\nforest = RandomForestClassifier()\n\nvals = cross_val_score(forest, df_vect[feat_list], df_vect['target'], cv = 5 )\nprint(vals)\nprint(sum(vals)/len(vals))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Positive tweets: \", positive_tweets, '  ', round(100 * positive_tweets / total_tweets,2), '%' )\nprint(\"Negative tweets: \", negative_tweets, '  ', round(100 * negative_tweets / total_tweets,3), '%' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7484da1bde422d8e9b8a40d89491067b59dd52e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df_vect[feat_list], df_vect['target'], test_size=0.2)\n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caa6450d85ca10ac42e3c82a900edc054d05675d"},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nfrom sklearn.model_selection import train_test_split\n\n\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\nX_test_res, y_test_res = sm.fit_sample(X_test, y_test.ravel())\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n\n# Before OverSampling, counts of label '1': [345]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d58947e45fe8292c332c4ce7d50b7418968a349b"},"cell_type":"code","source":"print(\"Original: \")\nprint(y_train.value_counts())\n\ntotal_data = len(y_train_res)\npercent_positive = sum(y_train_res)/ total_data\n\nprint('\\n\\nNew Data:')\nprint('Data Points: ', total_data)\nprint('\\nPositive Tweets: ', int(total_data * percent_positive), '   ', 100 * percent_positive, '%')\nprint('Negative Tweets: ', int(total_data * (1- percent_positive)), '   ', 100 * (1-percent_positive), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build a Random Forrest Model with the balanced data."},{"metadata":{"trusted":true,"_uuid":"0e208b57789cc73cf2415eb508bb5af668ea910f"},"cell_type":"code","source":"forest = RandomForestClassifier(n_estimators=140, max_depth=4)\nforest.fit(X_train_res, y_train_res)\nprint(round(100 * forest.score(X_test_res, y_test_res), 2), '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d79da01f1ae6a61e893dd70095fecdb809c705b"},"cell_type":"code","source":"import time\nt0 = time.time()\ngb_model = GradientBoostingClassifier( learning_rate=0.1, n_estimators=100)\ngb_model.fit(X_train_res, y_train_res)\nprint(round(100 * gb_model.score(X_test_res, y_test_res), 2), '%')\nprint(round(time.time() - t0, 2), 'seconds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12bcefcf8590b1079f849b3de6e97f243aba17f7"},"cell_type":"code","source":"t0 = time.time()\ngb_model1 = GradientBoostingClassifier( learning_rate=0.1, n_estimators=200)\ngb_model1.fit(X_train_res, y_train_res)\nprint(round(100 * gb_model1.score(X_test_res, y_test_res), 2), '%')\nprint(round(time.time() - t0, 2), 'seconds')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}