{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/sign-language-mnist/amer_sign2.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"get the dataset which in csv format as pandas dataframe object","execution_count":null},{"metadata":{"_uuid":"bdb7c381-ac32-48c3-91a5-f39a85f81554","_cell_guid":"9492bb75-f8e5-49dd-b851-a221fce8278e","trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\")\ntest_df = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\")\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"get the required colums(pixels and labels) in numpy ndarray objects","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = train_df[\"label\"].values\ntest_labels = test_df[\"label\"].values\n\ntrain_pixels = train_df.drop(\"label\", axis=1).values.astype(\"float32\")\ntest_pixels = test_df.drop(\"label\", axis=1).values.astype(\"float32\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"shape of all the numpy ndarrays","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"training images shape\", train_pixels.shape)\nprint(\"training targets shape \",train_labels.shape)\nprint(\"test images shape\", test_pixels.shape)\nprint(\"test targets shape\", test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"change the shape in appropriate form (batch, channels, width, height)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_pixels.reshape(train_pixels.shape[0], 1, 28, 28)\ntest_images = test_pixels.reshape(test_pixels.shape[0], 1, 28, 28)\n\nprint(\"training images shape\", train_images.shape)\nprint(\"test images shape\", test_images.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"preprocess the data and visualise any one of them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntrain_images = train_images\ntest_images = test_images\n\nimage = train_images[0].squeeze()\nlabel = train_labels[0]\n\nplt.title(f\"label {label}\")\nplt.imshow(image, cmap=\"gray\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"change the numpy ndarray into pytorch tensor for gradient calculations and gpu computation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\ntrain_image_tensor = torch.tensor(train_images) / 255.0\ntest_image_tensor  = torch.tensor(test_images) / 255.0\ntrain_label_tensor = torch.tensor(train_labels)\ntest_label_tensor  = torch.tensor(test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"join the train_images and labels to prepare a training set similary a test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset\ntrain_set = TensorDataset(train_image_tensor, train_label_tensor)\ntest_set = TensorDataset(test_image_tensor, test_label_tensor)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create a validation set from training set by keeping aside 20 percent of training data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"create a dataloader for training and test data sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 16\nnum_workers = 2\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntest_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"visualise a batch of images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.utils import make_grid\nimport numpy as np\n\ndef show(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n    \nimages, labels = next(iter(train_loader))\ngrid = make_grid(images, nrow=4)\nshow(grid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create a modal to classify the training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\nmodal = nn.Sequential(\n    nn.Conv2d(1, 32, 5),\n    nn.ReLU(),\n    nn.Dropout2d(0.4),\n\n    nn.MaxPool2d(2, 2),\n    nn.BatchNorm2d(32),\n\n    nn.Conv2d(32, 64, 5),\n    nn.ReLU(),\n    nn.Dropout2d(0.4),\n\n    nn.MaxPool2d(2, 2),\n    nn.BatchNorm2d(64),\n\n    nn.Flatten(start_dim=1),\n    \n    nn.Linear(1024, 128),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    \n    nn.BatchNorm1d(128),\n\n    nn.Linear(128, 26)\n)\n\nmodal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"declare loss function and optimizer for modal","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\nlearning_rate = 0.001\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(modal.parameters(), lr = learning_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create a training loop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodal.to(device)\n\ntotal_train_loss = []\ntotal_val_loss = []\n\nepochs = 10\nprint(f\"training on {device}\")\nfor epoch in range(epochs):\n    train_loss = 0\n    val_loss = 0\n    \n    modal.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device=device), labels.to(device=device)\n        optimizer.zero_grad()\n        preds = modal(images)\n        loss = criterion(preds, labels)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * train_loader.batch_size\n        \n    modal.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device=device), labels.to(device=device)\n            preds = modal(images)\n            loss = criterion(preds, labels)\n            \n            val_loss += loss.item() * test_loader.batch_size\n    \n    total_train_loss.append(train_loss / len(train_loader))\n    total_val_loss.append(val_loss / len(test_loader))\n    \n    print(\n        f\"epoch: {epoch+1}/{epochs} train_loss: {total_train_loss[-1]} val_loss: {total_val_loss[-1]}\"\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot training loss and validation loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(total_train_loss, label=\"train loss\")\nplt.plot(total_val_loss, label=\"val loss\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"get the accuracy on test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def no_of_correct(preds, targets):\n    return targets.eq(preds.argmax(dim=1)).sum().item()\n\ntotal_correct = 0\nmodal.eval()\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device=device), labels.to(device=device)\n        preds = modal(images)\n        total_correct += no_of_correct(preds, labels)\n\nprint(f\"{total_correct}/{len(test_set)} correct Accuracy: {(total_correct/len(test_set))*100:.3f}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}