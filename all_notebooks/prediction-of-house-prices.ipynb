{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Prediction of house prices in King County"},{"metadata":{},"cell_type":"markdown","source":"We will analyse the data and try to predict the prices of the houses with different regression models."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/kc_house_data.csv\")\ndf = df.sample(frac=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"price\"].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The mean price is around 550 thousand dollars.**"},{"metadata":{},"cell_type":"markdown","source":"Let's ignore the id and the zipcode for now."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"id\",\"zipcode\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The dataset contains 21613 entries, 19 columns and no null values**"},{"metadata":{},"cell_type":"markdown","source":"We don't need to apply any one hot encoding on the data, the only category is \"waterfront\" which is already one hot encoded."},{"metadata":{},"cell_type":"markdown","source":"Let's change the date into something more usable : a timestamp."},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport datetime\n\ndef transfo(date):\n    year = date[:4]\n    month = date[4:6]\n    day = date[6:8]\n    \n    s=day+\"/\"+month+\"/\"+year\n\n    ans = time.mktime(datetime.datetime.strptime(s, \"%d/%m/%Y\").timetuple())\n    \n    return ans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"date\"]=df[\"date\"].apply(transfo)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df[\"date\"].head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%matplotlib inline\ndf.hist(bins=20, figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the training and testing datasets"},{"metadata":{},"cell_type":"markdown","source":"**It is important to create a training dataset representative of the complete dataset**\n\nWe will use stratified sampling to ensure a good amount of houses of every price category."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"price\"].hist(bins=100, figsize=(10,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"price_category\"] = pd.cut(df[\"price\"],\n                            bins=list(range(0,2000001,100000))+[np.inf],\n                            labels=list(range(21)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"price_category\"].hist(figsize=(10,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\nfor train_index, test_index in split.split(df, df[\"price_category\"]):\n    train_set = df.loc[train_index]\n    test_set = df.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test_set[\"price_category\"].value_counts() / len(test_set)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df[\"price_category\"].value_counts() / len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sets are well split with respect to the price of the houses.\n\nWe can now remove the \"price_category\" column."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set=train_set.drop(\"price_category\", axis = 1)\ntest_set=test_set.drop(\"price_category\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Geographical position of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"prices = train_set.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices.plot(kind=\"scatter\", x=\"long\", y=\"lat\", alpha = 0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To have an idea of the correlation between prices and geographical position, we need to calculate the average price by zone.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We round those values in order to identify zones\nprices[\"new_lat\"]=round(prices[\"lat\"],2)\nprices[\"new_long\"]=round(prices[\"long\"],2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is the indicator of a zone, each value for this column corresponds to a certain geographical zone\nprices[\"zone\"]=prices[\"new_lat\"]*1000+prices[\"new_long\"]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# The only columns we need for this representation\nprices=prices[[\"zone\",\"price\", \"lat\", \"long\"]]\n# This column will be used to count the number of houses in a zone\nprices[\"number\"]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Will contain the average price for each zone\ndf=prices.groupby('zone').mean()\n# Will contain the number of houses for each zone\ndf1=prices.groupby('zone').sum()\ndf[\"number\"]=df1[\"number\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(kind=\"scatter\", x=\"long\", y=\"lat\", alpha=0.5,\n        s=df[\"number\"]*2, label=\"population\",\n        figsize=(15,10),c=\"price\", cmap=plt.get_cmap(\"jet\"), colorbar=True)\nplt.legend()\nplt.savefig(\"prices\",format=\"png\",resolution=300)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this representation, the size of the bubble is proportional to the number of house sales in the zone."},{"metadata":{},"cell_type":"markdown","source":"**This representation does not give a lot of information because the highest values are too high**"},{"metadata":{},"cell_type":"markdown","source":"Let's use a logarithmic scale"},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import log\ndf[\"log_price\"]=df[\"price\"].apply(log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(kind=\"scatter\", x=\"long\", y=\"lat\", alpha=0.5,\n        s=df[\"number\"]*2, label=\"population\",\n        figsize=(15,10),c=\"log_price\", cmap=plt.get_cmap(\"jet\"), colorbar=True)\nplt.legend()\nplt.savefig(\"log_prices\",format=\"png\",resolution=300)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The prices do not appear in an explicit way but we can easily see the correlation between the position and the price."},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr_matrix = train_set.corr()\ncorr_matrix[\"price\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the price is heavily correlated to the square footage of the home."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_data = train_set.drop(\"price\", axis=1) # drop labels for training set\nhouses_labels = train_set[\"price\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_set.drop(\"price\", axis=1)\ntest_labels = test_set[\"price\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstd_scaler = StandardScaler()\nhouses_prepared = std_scaler.fit_transform(houses_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_prepared.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The preprocessing is complete, we can now train a model**"},{"metadata":{},"cell_type":"markdown","source":"## Testing some regression models"},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(houses_prepared, houses_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nhouses_predictions = lin_reg.predict(houses_prepared)\nlin_mse = mean_squared_error(houses_labels, houses_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The RMSE is quite high on the training data, as shown earlier, the price is not correlated enough to the other data to obtain a good model**"},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state=1, max_depth = 12)\ntree_reg.fit(houses_prepared, houses_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_predictions = tree_reg.predict(houses_prepared)\ntree_mse = mean_squared_error(houses_labels, houses_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ntree_scores = cross_val_score(tree_reg, houses_prepared, houses_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-tree_scores)\n\nprint(\"Scores : \",tree_rmse_scores)\nprint(\"Mean : \",tree_rmse_scores.mean())\nprint(\"Standard deviation : \",tree_rmse_scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The RMSE on the training data is way better but the model tends to overfit the training set**"},{"metadata":{},"cell_type":"markdown","source":"### SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\n\nsvm_reg = SVR(gamma='scale')\nsvm_reg.fit(houses_prepared, houses_labels)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"svm_scores = cross_val_score(svm_reg, houses_prepared, houses_labels,\n                             scoring=\"neg_mean_squared_error\", cv=10)\n\nsvm_rmse_scores = np.sqrt(-svm_scores)\n\nprint(\"Scores : \",svm_rmse_scores)\nprint(\"Mean : \",svm_rmse_scores.mean())\nprint(\"Standard deviation : \",svm_rmse_scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=50, random_state=1)\nforest_reg.fit(houses_prepared, houses_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_predictions = forest_reg.predict(houses_prepared)\nforest_mse = mean_squared_error(houses_labels, houses_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_scores = cross_val_score(forest_reg, houses_prepared, houses_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\n\nforest_rmse_scores = np.sqrt(-forest_scores)\n\nprint(\"Scores : \",forest_rmse_scores)\nprint(\"Mean : \",forest_rmse_scores.mean())\nprint(\"Standard deviation : \",forest_rmse_scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The RMSE is much better with this model**"},{"metadata":{},"cell_type":"markdown","source":"Let's search the best hyperparameters for this model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [{\"max_depth\" : [10,15,20,30],\n               \"n_estimators\" : [10, 50, 100]}]\n\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search.fit(houses_prepared, houses_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = grid_search.best_params_\ndepth_param = params['max_depth']\nestimator_param = params['n_estimators']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_reg = RandomForestRegressor(max_depth=depth_param, n_estimators=estimator_param, random_state=1)\nforest_reg.fit(houses_prepared, houses_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_prepared = std_scaler.transform(test_data)\ntest_predict = forest_reg.predict(test_prepared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_mse = mean_squared_error(test_labels, test_predict)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The RMSE with this model is {} dollars on the validation dataset.'.format(forest_rmse))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}