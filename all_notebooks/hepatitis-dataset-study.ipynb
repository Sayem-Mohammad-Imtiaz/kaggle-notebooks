{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing all the libraries i will make use:","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\n\n%matplotlib inline\n\npd.set_option('display.max_columns', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The data first check is performed by simply looking at the dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hepatitis-c-dataset/HepatitisCdata.csv')\ndf = df.drop(['Unnamed: 0'], axis = 'columns')\ndf = df.dropna()\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Before going for the predictive models, I would like to answer few simple questions:\n* #### How many people are there per category and sex?\n* #### Age distribution of the sample population\n* #### Do the disease affects more males or females in the data?","metadata":{}},{"cell_type":"code","source":"df.Category.value_counts(normalize = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_male = df.Sex.value_counts().loc['m']\nnum_female = df.Sex.value_counts().loc['f']\nprint('Number of males: {}'.format(num_male))\nprint('Number of females: {}'.format(num_female))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Largest part of my DataFrame is made of by healthy blood donors and only a rough 10% of people with the disease. This might be an issue for the accuracy later on in the model fitting, since that 10% is to be divided by all 3 possible stages of the disease. Male and female however in roughly 3 by 2 ratio","metadata":{}},{"cell_type":"code","source":"df_grp = df.groupby(['Sex', 'Category'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Percentage of diseased females: {:.2%}'.format((num_female - len(df_grp.get_group(('f', '0=Blood Donor'))))/len(df_grp.get_group(('f', '0=Blood Donor')))))\nprint('Percentage of diseased males: {:.2%}'.format((num_male - len(df_grp.get_group(('m', '0=Blood Donor'))))/len(df_grp.get_group(('m', '0=Blood Donor')))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In the above calculation i considered the worst case scenario where a \"suspect blood donor\" is considered as diseased. However they impact only for a 1% in total so negligible for the purpose of the study.\n### The disease occurrs more in males than femals in the dataset","metadata":{}},{"cell_type":"code","source":"df.describe() #i check the statistics of the df. a first glimps on how the data are distributed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From the table above I check the statistics for each of the dataset features. There surely are some outliers but I am not going to remove them, for the following reasons:\n\n* #### I am not a doctor in medicine, namely I do not have that sensibility to discern between features to consider important or not for the study\n\n* #### Blood analysis values for each feature can differ in orders of magnitude between healthy and unhealthy individual and the outliers in this DataFrame may contain some important information for the models to come in order to predict the disease. \n\n* #### I can count only on a limited amount of data, namely 589 usable data. That is very few and most of them refer to healthy people so i mean to exploit each and every single one of them.","metadata":{}},{"cell_type":"code","source":"### Now its time to encode the categorical data. In this case I only have only two categorical which is the column \"Sex\" and \"Category\". The last one is also my target for the models\n\nfrom sklearn.preprocessing import LabelEncoder\nle_Category = LabelEncoder()\nle_Sex = LabelEncoder()\ndfle = df.copy()\n\n\ndfle.Category = le_Category.fit_transform(dfle.Category)\ndfle.Sex = le_Sex.fit_transform(dfle.Sex)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### I create my input \"X\" and target \"y\" datasets to be used for the models\n\nX = dfle.drop(['Category'], axis = 'columns')\ny = dfle.Category\nX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Modelling\n#### I will create a dictionary of models and paramenters to iterate in GridSearchCV in order to be able to rank the model chosen and find the best one","metadata":{}},{"cell_type":"code","source":"## Data modelling\n\nmodel_param = {\n    'Randomforest': {\n        \n        'model': RandomForestClassifier(),\n        'param': {\n            'n_estimators':[1,5,10,15,20,25,30,40,50,60,80,100]\n        }\n    },\n    \n    'LogisticRegression':{\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'param': {\n            'C': [1,5,10,15,20]\n        }\n        \n    },\n    \n    'GaussianNB':{\n        'model': GaussianNB(),\n        'param': {\n            \n        }\n    },\n    \n    'MultinomialNB':{\n        'model': MultinomialNB(),\n        'param': {\n            \n        }\n    },\n    \n    'DecisionTreeClassifier':{\n        'model': DecisionTreeClassifier(),\n        'param': {\n            'criterion': ['gini','entropy'],\n        }\n    },\n    \n    'SVM':{\n        'model': SVC(gamma='auto'),\n        'param': {\n            'C': [0.001,0.1,1],\n            'kernel':['rbf', 'linear']\n        }\n        \n    }\n    \n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nscores = []\n\nfor model_name, mp in model_param.items():\n    clf = GridSearchCV(mp['model'], mp['param'], cv=5, return_train_score=None)\n    clf.fit(X,y)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = pd.DataFrame(scores)\ndataframe.sort_values(by=['best_score'], inplace = True, ascending=False)\ndataframe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The models in the first three positions have roughly the same accuracy score, which changes slightly running again the cells. I decide to make use of Logistic Regression algorithm for predictions and I want to see where this fails by using che confusion matrix.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\nlr = LogisticRegression(solver='liblinear',multi_class='auto', C=1)\nlr.fit(X_train,y_train)\nlr_prediction = lr.predict(X_test)\nscore = lr.score(X_test, y_test)\nprint('Logistic Regression model has {:.2%} accuracy'.format(score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, lr_prediction)\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')\nplt.title('LR Confusion matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions\n#### From the results above, I can see that all of the methods adopted in this study can predict with the same lavel of accuracy (>>90%). The Logistic regression, Random forest classifier and SVM performs slightly better in terms of score other than approaches do.\n#### However that level of accuracy refers mostly respect to blood donors than hepatitis due to the fact that most of our samples belong to healty individuals. Few errors appears when it comes of disease data ans seen in the confusion matrix. That means that in order to properly predict the disease we need more samples with that particular disease and less NaN within the dataset","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}