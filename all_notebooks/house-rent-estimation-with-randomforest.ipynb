{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing standard libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(r\"/kaggle/input/usa-housing-listings/housing.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Before imputing the null values let's remove the unwanted features as these features does not play any role in the estimation of house rent"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"id\",\"url\",\"region_url\",\"image_url\",\"description\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With region name itself we can know in which state the house is located , so there is no use for this state column.\nso we can remove this state column also."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"state\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most important feature is sqfeet,region,type,no of bedrooms and bathrooms\nOther features also play a role for rental price but that is of less importance\nBut we can take the other features also for estimation, as all those combining together play some role in estimation."},{"metadata":{},"cell_type":"markdown","source":"### Now let's impute the null values with proper values of central tendencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['laundry_options'] = df['laundry_options'].fillna(df['laundry_options'].mode()[0])\ndf['parking_options'] = df['parking_options'].fillna(df['parking_options'].mode()[0])\ndf['lat'] = df['lat'].fillna(df['lat'].mean())\ndf['long'] = df['long'].fillna(df['long'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many values present\ndf.laundry_options.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many values present\ndf.parking_options.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many values present\ndf.region.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many values present\ndf.type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many values present\ndf.baths.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can convert this float values to int\ndf[\"baths\"]=df[\"baths\"].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking how many values present\ndf.beds.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### A house can have maximum of 4 bedrooms and above that are not the normal range\n### so we can remove the entries above 4\n### If there is maximum of 4 bedrooms then the bathroom will be maximum of 4\n### So we can remove the values above 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier1 = ((df[\"beds\"]>4) | (df[\"baths\"]>4))\nprint(\"There is {} outlier\".format(df[outlier1][\"beds\"].count()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[~outlier1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(30,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see there are \"0\" values present in the column of price and sq feet\n### According to zoning regulations, the minimum square footage for a house is 120 square feet (single room house).\n### so we can remove the entries which are below 120\n### The sq feet for a big houses can be around 5,000 sqfeeet at the maximum\n### so we can remove the values above 5,000\n### so we can have the values above 100 for price and less than 10,000 as the minimum sq feet is 120 and maximum is 5,000.\n### At the maximum a person can pay 10,000 dollars as rent, if above that means he may buy his own house and pay the EMI rather than paying rent monthly."},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier2 = ((df[\"sqfeet\"]<120) | (df[\"sqfeet\"]>5000) | (df[\"price\"]<100) | (df[\"price\"]>10000))\nprint(\"There is {} outlier\".format(df[outlier2][\"cats_allowed\"].count()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[~outlier2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### we can see there are two columns named dogs_allowed & cats_allowed\n### we can combine those make a single column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"cats_allowed\"],axis=1)\ndf.rename(columns = {'dogs_allowed':'pets_allowed'}, inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"type\"])\nfig = plt.gcf()\nfig.set_size_inches(15,10)\nplt.title('Which type of house is more')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=df[\"type\"],y=df[\"price\"])\nfig = plt.gcf()\nfig.set_size_inches(15,10)\nplt.title('Which type of house has more price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=df[\"type\"],y=df[\"sqfeet\"])\nfig = plt.gcf()\nfig.set_size_inches(15,10)\nplt.title('Which type of house has more sqfeet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=df[\"parking_options\"],y=df[\"price\"])\nfig = plt.gcf()\nfig.set_size_inches(15,10)\nplt.title('Which type of parking option has more price')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Encoding the categorical string values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le=LabelEncoder()\ndb=df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"db[\"region\"]=le.fit_transform(df[\"region\"])\ndb[\"type\"]=le.fit_transform(df[\"type\"])\ndb[\"laundry_options\"]=le.fit_transform(df[\"laundry_options\"])\ndb[\"parking_options\"]=le.fit_transform(df[\"parking_options\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"db.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=db.drop(columns=[\"price\"])\ny=db[\"price\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scatter plot to understand the relation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,30), facecolor='white')\nplotnumber = 1\n\nfor column in x:\n    if plotnumber<=16 :\n        ax = plt.subplot(4,4,plotnumber)\n        plt.scatter(x[column],y)\n        plt.xlabel(column,fontsize=20)\n        plt.ylabel('Price',fontsize=20)\n    plotnumber+=1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscalar=StandardScaler()\nx_scaled=scalar.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF\"] = [variance_inflation_factor(x_scaled,i) for i in range(x_scaled.shape[1])]\nvif[\"Features\"] = x.columns\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Also checking multicollinearity with heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrl = db.corr()\nplt.figure(figsize=(20,20))\nsns.heatmap(corrl, cbar=True, square= True,fmt='.1f', annot=True, annot_kws={'size':12}, cmap='twilight_shifted_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From the above graph and the vif we can say that there is no multicollinearity in this dataset"},{"metadata":{},"cell_type":"markdown","source":"# Splitting the dataset for train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size = 0.30,random_state=470)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the models for training the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr = DecisionTreeRegressor()\nran = RandomForestRegressor(n_estimators=90)\nlin = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\"Decision tree\" : dtr,\n          \"Random forest\" : ran,\n          \"Linear Regression\" : lin}\nscores= { }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key, value in models.items():    \n    model = value\n    model.fit(x_train, y_train)\n    scores[key] = model.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_frame = pd.DataFrame(scores, index=[\"Accuracy Score\"]).T\nscores_frame.sort_values(by=[\"Accuracy Score\"], axis=0 ,ascending=False, inplace=True)\nscores_frame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## we can see that the Random Forest Regression is giving good results than other models"},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=ran.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint('R^2:',metrics.r2_score(y_test, y_pred))\nprint('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_pred))*(len(y_train)-1)/(len(y_train)-x_train.shape[1]-1))\nprint('MAE:',metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:',metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"### By comparing the above results we can take the Random forest Regressor for the estimation of house rent, with Random forrest regressor we can estimate the house rent with 86% accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}