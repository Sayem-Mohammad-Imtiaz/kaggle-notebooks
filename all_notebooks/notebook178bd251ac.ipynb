{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.applications.densenet import DenseNet169\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Input, Dense\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/mura-v11/MURA-v1.1'\n\ntrain_dir = data_dir + '/train' # Chemin d'accès au répertoire de train set\nval_dir = data_dir + '/valid' # Chemin d'accès au répertoire de test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Affichage d'une image osseuse anormale\nimg_abnormal = load_img('../input/mura-v11/MURA-v1.1/train/XR_ELBOW/patient00069/study1_positive/image2.png')\nprint('ABNORMAL')\nplt.imshow(img_abnormal)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Affichage d'une image osseuse normale\nimg_normal = load_img('../input/mura-v11/MURA-v1.1/train/XR_ELBOW/patient00011/study1_negative/image1.png')\nprint('NORMAL')\nplt.imshow(img_normal)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#les etudes de train set avec labels\ndf=pd.read_csv('../input/mura-v11/MURA-v1.1/train_labeled_studies.csv', names=['Train_Image','Train_Label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compter les étiquettes dans le train set\ncases_count = df['Train_Label'].value_counts()\nprint(cases_count)\n\n# Tracer les résultats\nplt.figure(figsize=(4,4))\nsns.barplot(x=cases_count.index, y=cases_count.values)\nplt.title('Number of cases', fontsize=12)\nplt.xlabel('Case type', fontsize=10)\nplt.ylabel('Count', fontsize=10)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Abnormal(1)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ajout d'étiquettes aux images individuelles dans le train set\ndf=pd.read_csv('../input/mura-v11/MURA-v1.1/train_image_paths.csv', names=['Train_Image'])\nnames=df['Train_Image'].values\ntrain_labels=[]\n\nfor i in names:\n  if ('positive' in i):\n    train_labels.append('1')\n  elif('negative' in i):\n    train_labels.append('0')\n\ntrain_labels = np.array(train_labels)\n#labels = pd.DataFrame(labels, columns=['Image', 'Label'])\ndf.insert(1, 'Train_Label', train_labels)\ndf.to_csv('Train_set.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compter le nombre d'étiquettes individuelles des images dans le train set\ncases_count = df['Train_Label'].value_counts()\nprint(cases_count)\n\n# Tracer les résultats\nplt.figure(figsize=(4,4))\nsns.barplot(x=cases_count.index, y=cases_count.values)\nplt.title('Number of labels', fontsize=12)\nplt.xlabel('Case type', fontsize=10)\nplt.ylabel('Count', fontsize=10)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Abnormal(1)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#les etudes d'ensembles de validation avec labels\ndf=pd.read_csv('../input/mura-v11/MURA-v1.1/valid_labeled_studies.csv', names=['Valid_Image','Valid_Label'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compter les étiquettes dans le jeu de validation\ncases_count = df['Valid_Label'].value_counts()\nprint(cases_count)\n\n# Tracer les résultats \nplt.figure(figsize=(4,4))\nsns.barplot(x=cases_count.index, y=cases_count.values)\nplt.title('Number of cases', fontsize=12)\nplt.xlabel('Case type', fontsize=10)\nplt.ylabel('Count', fontsize=10)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Abnormal(1)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ajout d'étiquettes aux images individuelles dans le jeu de validation\ndf=pd.read_csv('../input/mura-v11/MURA-v1.1/valid_image_paths.csv', names=['Valid_Image'])\nnames=df['Valid_Image'].values\nvalid_labels=[]\n\nfor i in names:\n  if ('positive' in i):\n    valid_labels.append('1')\n  elif('negative' in i):\n    valid_labels.append('0')\n\nvalid_labels = np.array(valid_labels)\n#labels = pd.DataFrame(labels, columns=['Image', 'Label'])\ndf.insert(1, 'Valid_Label', valid_labels)\ndf.to_csv('Valid_set.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compter le nombre d'étiquettes individuelles des images dans l'ensemble de validation\ncases_count = df['Valid_Label'].value_counts()\nprint(cases_count)\n\n# Tracer les résultats \nplt.figure(figsize=(4,4))\nsns.barplot(x=cases_count.index, y=cases_count.values)\nplt.title('Number of labels', fontsize=12)\nplt.xlabel('Case type', fontsize=10)\nplt.ylabel('Count', fontsize=10)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Abnormal(1)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lire les fichiers .csv de training set et de valid set\ntrain_df = pd.read_csv(\"../input/mydata/Train_set.csv\", dtype=str)\nvalid_df = pd.read_csv(\"../input/mydata/Valid_set.csv\", dtype=str)\n\n\nprint(train_df.shape)\nprint(valid_df.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image Preprocessing and augmentation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image Preprocessing\ndatagen = ImageDataGenerator(rescale=1./255, rotation_range=30)\n\ntrain_generator = datagen.flow_from_dataframe(dataframe=train_df, directory=None,\n                                              x_col=\"Train_Image\", y_col=\"Train_Label\",\n                                              target_size=(224,224), class_mode=\"binary\",\n                                              batch_size=16, validate_filenames=False)\n\nvalid_generator = datagen.flow_from_dataframe(dataframe=valid_df, directory=None,\n                                              x_col=\"Valid_Image\", y_col=\"Valid_Label\",\n                                              target_size=(224,224), class_mode=\"binary\",\n                                              batch_size=16, shuffle=True, validate_filenames=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_generator.n)\nprint(valid_generator.n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Densenet169 pre-trained model**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import densenet169 pre-trained model\ndense_model = DenseNet169(include_top=True, weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dense_model.layers.pop()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\npredictions = Dense(1, activation='sigmoid')(dense_model.layers[-1].output)\nmodel = Model(inputs=dense_model.input, outputs=predictions)\n\nmodel.compile(optimizer = Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of train and validation steps\ntrain_steps=train_generator.n//train_generator.batch_size\nvalid_steps=valid_generator.n//valid_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_steps)\nprint(valid_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, verbose=1, mode='max')\nepoche_nbr = 15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit_generator(generator=train_generator,\n#                     steps_per_epoch=train_steps,\n#                     validation_data=valid_generator,\n#                     validation_steps=valid_steps,\n#                     epochs=epoche_nbr,\n#                     callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plots for training and testing process: loss and accuracy\ndef plot_model_history(model_name, history, epochs):\n  \n  print(model_name)\n  plt.figure(figsize=(15, 5))\n  \n  # summarize history for accuracy\n  plt.subplot(1, 2 ,1)\n  plt.plot(np.arange(0, len(history['accuracy'])), history['accuracy'], 'r')\n  plt.plot(np.arange(1, len(history['val_accuracy'])+1), history['val_accuracy'], 'g')\n  plt.xticks(np.arange(0, epochs+1, epochs/10))\n  plt.title('Training Accuracy vs. Validation Accuracy')\n  plt.xlabel('Num of Epochs')\n  plt.ylabel('Accuracy')\n  plt.legend(['train', 'validation'], loc='best')\n  \n  plt.subplot(1, 2, 2)\n  plt.plot(np.arange(1, len(history['loss'])+1), history['loss'], 'r')\n  plt.plot(np.arange(1, len(history['val_loss'])+1), history['val_loss'], 'g')\n  plt.xticks(np.arange(0, epochs+1, epochs/10))\n  plt.title('Training Loss vs. Validation Loss')\n  plt.xlabel('Num of Epochs')\n  plt.ylabel('Loss')\n  plt.legend(['train', 'validation'], loc='best')\n  \n  \n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_model_history('Densenet169', history.history, epoche_nbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **VGG pre-trained model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow.keras.applications.vgg16 import VGG16\n\nbase_model_vgg = VGG16(input_shape = (224, 224, 3), # Shape of our images\ninclude_top = False, # Leave out the last fully connected layer\nweights = 'imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in base_model_vgg.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model_vgg.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(512, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.5)(x)\n\n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.models.Model(base_model_vgg.input, x)    \n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vgghist = model.fit(train_generator, validation_data = valid_generator, steps_per_epoch = train_steps, epochs = epoche_nbr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plots for training and testing process: loss and accuracy\ndef plot_model_history1(model_name, history, epochs):\n  \n  print(model_name)\n  plt.figure(figsize=(15, 5))\n  \n  # summarize history for accuracy\n  plt.subplot(1, 2 ,1)\n  plt.plot(np.arange(0, len(history['acc'])), history['acc'], 'r')\n  plt.plot(np.arange(1, len(history['val_acc'])+1), history['val_acc'], 'g')\n  plt.xticks(np.arange(0, epochs+1, epochs/10))\n  plt.title('Training Accuracy vs. Validation Accuracy')\n  plt.xlabel('Num of Epochs')\n  plt.ylabel('Accuracy')\n  plt.legend(['train', 'validation'], loc='best')\n  \n  plt.subplot(1, 2, 2)\n  plt.plot(np.arange(1, len(history['loss'])+1), history['loss'], 'r')\n  plt.plot(np.arange(1, len(history['val_loss'])+1), history['val_loss'], 'g')\n  plt.xticks(np.arange(0, epochs+1, epochs/10))\n  plt.title('Training Loss vs. Validation Loss')\n  plt.xlabel('Num of Epochs')\n  plt.ylabel('Loss')\n  plt.legend(['train', 'validation'], loc='best')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_model_history1('VGG16', vgghist.history, epoche_nbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **ResNet pre-trained model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\nbase_model_res = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in base_model_res.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nbase_model_res = Sequential()\nbase_model_res.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\nbase_model_res.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model_res.compile(optimizer = tf.keras.optimizers.SGD(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# base_model_res.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resnet_history = base_model_res.fit(train_generator, validation_data = valid_generator, steps_per_epoch = train_steps, epochs = epoche_nbr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_model_history1('ResNet50', resnet_history.history, epoche_nbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **InceptionV3 pre-trained model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nbase_model_inc = InceptionV3(input_shape = (224, 224,3), include_top = False, weights = 'imagenet')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in base_model_inc.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\nx = layers.Flatten()(base_model_inc.output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.models.Model(base_model_inc.input, x)\n\nmodel.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inc_history = model.fit_generator(train_generator, validation_data = valid_generator, steps_per_epoch=train_steps, epochs = epoche_nbr, validation_steps=valid_steps, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_model_history1('InceptionV3', inc_history.history, epoche_nbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inception V2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport pandas as pd\nimport cv2\nfrom skimage.transform import rescale, resize\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn.utils import class_weight\nimport tensorflow_addons as tfa\nimport pickle\nfrom skimage.io import imread\nfrom sklearn.utils import shuffle\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To get the filenames for a task\ndef filenames(part,train=True):\n    root='../input/mura-v11/'\n    if train:\n        csv_path=\"../input/mura-v11/MURA-v1.1/train_image_paths.csv\"\n    else:\n        csv_path=\"../input/mura-v11/MURA-v1.1/valid_image_paths.csv\"\n    \n    with open(csv_path, 'rb') as F:\n        d = F.readlines()\n        if part == 'all':\n            imgs = [root + str(x, encoding='utf-8').strip() for x in d]  # 所有图片的存储路径, [:-1]目的是抛弃最末尾的\\n\n        else:\n            imgs = [root + str(x, encoding='utf-8').strip() for x in d if\n                            str(x, encoding='utf-8').strip().split('/')[2] == part]\n\n    #imgs= [x.replace(\"/\", \"\\\\\") for x in imgs]\n    labels= [x.split('_')[-1].split('/')[0] for x in imgs]\n    return imgs,labels\n\n\n#To icrop a image from center\ndef crop_center(img,cropx,cropy):\n    y,x,_ = img.shape\n    startx = x//2-(cropx//2)\n    starty = y//2-(cropy//2)    \n    return img[starty:starty+cropy,startx:startx+cropx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,\n    ToFloat, ShiftScaleRotate\n)\nfrom albumentations.augmentations.transforms import Resize\nAUGMENTATIONS_TRAIN = Compose([\n    HorizontalFlip(p=0.5),\n    RandomContrast(limit=0.2, p=0.5),\n    RandomGamma(gamma_limit=(80, 120), p=0.5),\n    RandomBrightness(limit=0.2, p=0.5),\n    ShiftScaleRotate(\n        shift_limit=0.0625, scale_limit=0.1, \n        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n    ToFloat(max_value=255)\n])\nAUGMENTATIONS_TEST = Compose([\n    # CLAHE(p=1.0, clip_limit=2.0),\n    ToFloat(max_value=255)\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"albumentation_list =  [\n    HorizontalFlip(p=0.5),\n    RandomContrast(limit=0.2, p=0.5),\n    RandomGamma(gamma_limit=(80, 120), p=0.5),\n    RandomBrightness(limit=0.2, p=0.5),\n    ShiftScaleRotate(\n        shift_limit=0.0625, scale_limit=0.1, \n        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n    ToFloat(max_value=255)\n]\nroot='../input/mura-v11/'\nchosen_image= imread(root+'MURA-v1.1/train/XR_ELBOW/patient01055/study1_positive/image3.png')\nimg_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\nimg= resize(chosen_image,(300,300,3))\nimg_matrix_list.append(img)\nimg_matrix_list.append(crop_center(img,224,224))\n\nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\",\"Horizontal Flip\",\"Random Contrast\",\"Random Gamma\",\"RandomBrightness\",\n               \"Shift Scale Rotate\",\"Resizing\", \"Cropping\"]\n\ndef plot_multiple_img(img_matrix_list, title_list, ncols, main_title=\"Data Augmentation\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=2, ncols=ncols, squeeze=True)\n    fig.suptitle(main_title, fontsize = 30)\n    #fig.subplots_adjust(wspace=0.3)\n    #fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i // ncols][i % ncols].imshow(img)\n        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()\n    \nplot_multiple_img(img_matrix_list, titles_list, ncols = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class My_Custom_Generator(keras.utils.Sequence) :\n  \n  def __init__(self, image_filenames, labels, batch_size,transform) :\n    self.image_filenames = image_filenames\n    self.labels = labels\n    self.batch_size = batch_size\n    self.t= transform\n    \n  def __len__(self) :\n    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n  \n  \n  def __getitem__(self, idx) :\n    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n    x=[]\n    for file in batch_x:\n        img= imread(file)\n        img= self.t(image=img)[\"image\"]\n        img= resize(img,(300,300,3))\n        img= crop_center(img,224,224)\n        x.append(img)\n    x=np.array(x)/255.0\n    y= np.array(batch_y)\n    return x,y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"part='XR_WRIST'\nimgs,labels= filenames(part=part)\nvimgs,vlabels= filenames(part=part,train=False)\nprint(labels.count('positive'),labels.count('negative'))\ntraining_data= labels.count('positive')+labels.count('negative')\nprint(\"Training Data: \", training_data)\ny_data= [0 if x=='positive' else 1 for x in labels]\ny_data= keras.utils.to_categorical(y_data)\nprint(vlabels.count('positive'),vlabels.count('negative'))\nvalidation_data= vlabels.count('positive')+vlabels.count('negative')\nprint(\"Validation Data: \", validation_data)\nvy_data= [0 if x=='positive' else 1 for x in vlabels]\nvy_data= keras.utils.to_categorical(vy_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\ny_integers = np.argmax(y_data, axis=1)\nclass_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\nd_class_weights = dict(enumerate(class_weights))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nimgs, y_data = shuffle(imgs, y_data)\n#vimgs, vy_data = shuffle(vimgs, vy_data)\nmy_training_batch_generator = My_Custom_Generator(imgs, y_data, batch_size,AUGMENTATIONS_TRAIN)\nmy_validation_batch_generator = My_Custom_Generator(vimgs, vy_data, batch_size,AUGMENTATIONS_TEST)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"part='XR_WRIST'\ncheckpoint_path = root+\"MURA-v1.1/\"+part+\"/WRIST.h5\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\nmy_callbacks = [\n    keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=0, save_best_only=True,\n                                       save_weights_only=False, mode='auto'),\n    keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,patience=3,\n                                         min_delta=0.001, verbose=1, min_lr=0.000000001)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Inception=keras.applications.InceptionResNetV2(include_top=False,input_shape=(224,224,3))\n#for layer in Inception.layers[:4]:\n#  layer.trainable=False\ninput_image=keras.layers.Input((224,224,3))\nx=Inception (input_image)\n\n#x=keras.layers.GlobalAveragePooling2D()(x)\nx=keras.layers.Flatten()(x)\n#x=keras.layers.Dense(1024)(x)\n#x=keras.layers.Activation(activation='relu')(x)\n#x= keras.layers.Dropout(0.5)(x)\nx=keras.layers.Dense(256)(x)\nx=keras.layers.Activation(activation='relu')(x)\nx= keras.layers.Dropout(0.5)(x)\nx=keras.layers.Dense(2)(x)\nout=keras.layers.Activation(activation='softmax')(x)\n\nmodel=keras.Model(inputs=input_image,outputs=out)\nmodel.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit_generator(generator=my_training_batch_generator,\n                   steps_per_epoch = int(training_data // batch_size),\n                   epochs = 10,\n                   verbose = 1,\n                   class_weight=d_class_weights,\n                   validation_data = my_validation_batch_generator,\n                   validation_steps = int(validation_data // batch_size), \n                   callbacks=my_callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_model_history2(model_name, history, epochs):\n  \n  print(model_name)\n  plt.figure(figsize=(15, 5))\n  \n  # summarize history for accuracy\n  plt.subplot(1, 2 ,1)\n  plt.plot(np.arange(0, len(history['accuracy'])), history['accuracy'], 'r')\n  plt.plot(np.arange(1, len(history['val_accuracy'])+1), history['val_accuracy'], 'g')\n  plt.xticks(np.arange(0, epochs+1, epochs/10))\n  plt.title('Training Accuracy vs. Validation Accuracy')\n  plt.xlabel('Num of Epochs')\n  plt.ylabel('Accuracy')\n  plt.legend(['train', 'validation'], loc='best')\n  \n  plt.subplot(1, 2, 2)\n  plt.plot(np.arange(1, len(history['loss'])+1), history['loss'], 'r')\n  plt.plot(np.arange(1, len(history['val_loss'])+1), history['val_loss'], 'g')\n  plt.xticks(np.arange(0, epochs+1, epochs/10))\n  plt.title('Training Loss vs. Validation Loss')\n  plt.xlabel('Num of Epochs')\n  plt.ylabel('Loss')\n  plt.legend(['train', 'validation'], loc='best')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model_history2('InceptionV2', history.history, 10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}