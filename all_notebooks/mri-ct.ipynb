{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import Callback\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import datasets, layers, optimizers, Sequential, metrics, Model\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\nimport os\nimport pathlib\nimport random\nimport nibabel as nib\nimport imageio\nimport os, random, json, PIL, shutil, re, imageio, glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## parameters","metadata":{}},{"cell_type":"markdown","source":"**Because the model have been trained, here set epochs to 21 for presentation**","metadata":{}},{"cell_type":"markdown","source":"**the total epochs have trained is 120**","metadata":{}},{"cell_type":"code","source":"BUFFER_SIZE = 5000\nHEIGHT = 256\nWIDTH = 256\nCHANNELS = 1\nBATCH_SIZE = 4\nEPOCHS = 21\nTRANSFORMER_BLOCKS = 6\nGENERATOR_LR = 2e-4\nDISCRIMINATOR_LR = 2e-4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preprocess datasets","metadata":{}},{"cell_type":"code","source":"def preprocess_image_T2(image):\n    image= tf.image.decode_png(image, channels=1)\n    image = tf.image.pad_to_bounding_box(image, offset_height=0, offset_width=0, target_height=256, target_width=256)\n    image = tf.image.resize(image, [256, 256])\n    image = tf.image.rot90(image, k=3) # rotate 270ยบ\n    image = tf.image.flip_up_down(image)\n    image = (image-127.5)/127.5\n    return image\n\ndef preprocess_image(image):\n    image= tf.image.decode_png(image, channels=1)\n    #image = tf.image.pad_to_bounding_box(image, offset_height=0, offset_width=60, target_height=256, target_width=256)\n    image = tf.image.resize(image, [256, 256])\n    image = (image-127.5)/127.5\n    return image\n\ndef preprocess_image_test(image):\n    image= tf.image.decode_png(image, channels=1)\n    image = tf.image.pad_to_bounding_box(image, offset_height=0, offset_width=0, target_height=256, target_width=256)\n    image = tf.image.resize(image, [256, 256])\n    image = (image-127.5)/127.5\n    return image\n\ndef load_and_preprocess_image(path):\n    image = tf.io.read_file(path)\n    return preprocess_image(image)\n\ndef load_and_preprocess_image_test(path):\n    image = tf.io.read_file(path)\n    return preprocess_image_test(image)\n\ndef load_and_preprocess_image_T2(path):\n    image = tf.io.read_file(path)\n    return preprocess_image_T2(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_root = pathlib.Path('../input/ixit2-slices/image slice-T2')\nall_image_paths_T2 = list(data_root.glob('*/*'))\nall_image_paths_T2.sort()\nnew_all_image_paths_T2 = []\nfor i in range(len(all_image_paths_T2)):\n    if (i+4)%10 == 0:\n        new_all_image_paths_T2.append(all_image_paths_T2[i])\nall_image_paths_T2 = new_all_image_paths_T2\nall_image_paths_T2 = [str(path) for path in all_image_paths_T2[:500]]\nimage_count = len(all_image_paths_T2)\nds_T2 = tf.data.Dataset.from_tensor_slices((all_image_paths_T2))\ndataset_T2 = ds_T2.map(load_and_preprocess_image_T2).batch(BATCH_SIZE).repeat().shuffle(512)\ndataset_T2 = dataset_T2.cache()\ndataset_T2_test = ds_T2.map(load_and_preprocess_image_T2).batch(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_root = pathlib.Path('../input/head-ct-hemorrhage/head_ct')\nall_image_paths_ct = list(data_root.glob('*/*'))\nall_image_paths_ct.sort()\nall_image_paths_ct = [str(path) for path in all_image_paths_ct]\nimage_count = len(all_image_paths_ct)\nds_ct = tf.data.Dataset.from_tensor_slices((all_image_paths_ct))\ndataset_ct = ds_ct.map(load_and_preprocess_image).batch(BATCH_SIZE).repeat().shuffle(512)\ndataset_ct = dataset_ct.cache()\ndataset_ct_test = ds_ct.map(load_and_preprocess_image).batch(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## encoder block ","metadata":{}},{"cell_type":"code","source":"conv_initializer = tf.random_normal_initializer(mean=0.0, stddev=0.02)\ngamma_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \ndef encoder_block(input_layer, filters, size=3, strides=2, apply_instancenorm=True, activation=layers.ReLU(), name='block_x'):\n    block = layers.Conv2D(filters, size, \n                     strides=strides, \n                     padding='same', \n                     use_bias=False, \n                     kernel_initializer=conv_initializer, \n                     name=f'encoder_{name}')(input_layer)\n\n    if apply_instancenorm:\n        block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n        \n    block = activation(block)\n\n    return block\n\ndef transformer_block(input_layer, size=3, strides=1, name='block_x'):\n    filters = input_layer.shape[-1]\n    \n    block = layers.Conv2D(filters, size, strides=strides, padding='same', use_bias=False, \n                     kernel_initializer=conv_initializer, name=f'transformer_{name}_1')(input_layer)\n#     block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n    block = layers.ReLU()(block)\n    \n    block = layers.Conv2D(filters, size, strides=strides, padding='same', use_bias=False, \n                     kernel_initializer=conv_initializer, name=f'transformer_{name}_2')(block)\n#     block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n    \n    block = layers.Add()([block, input_layer])\n\n    return block\n\ndef decoder_block(input_layer, filters, size=3, strides=2, apply_instancenorm=True, name='block_x'):\n    block = layers.Conv2DTranspose(filters, size, \n                              strides=strides, \n                              padding='same', \n                              use_bias=False, \n                              kernel_initializer=conv_initializer, \n                              name=f'decoder_{name}')(input_layer)\n\n    if apply_instancenorm:\n        block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n\n    block = layers.ReLU()(block)\n    \n    return block\n\n# Resized convolution\ndef decoder_rc_block(input_layer, filters, size=3, strides=1, apply_instancenorm=True, name='block_x'):\n    block = tf.image.resize(images=input_layer, method='bilinear', \n                            size=(input_layer.shape[1]*2, input_layer.shape[2]*2))\n    \n#     block = tf.pad(block, [[0, 0], [1, 1], [1, 1], [0, 0]], \"SYMMETRIC\") # Works only with GPU\n#     block = L.Conv2D(filters, size, strides=strides, padding='valid', use_bias=False, # Works only with GPU\n    block = layers.Conv2D(filters, size, \n                     strides=strides, \n                     padding='same', \n                     use_bias=False, \n                     kernel_initializer=conv_initializer, \n                     name=f'decoder_{name}')(block)\n\n    if apply_instancenorm:\n        block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n\n    block = layers.ReLU()(block)\n    \n    return block","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## generator","metadata":{}},{"cell_type":"code","source":"def generator_fn(height=HEIGHT, width=WIDTH, channels=CHANNELS, transformer_blocks=TRANSFORMER_BLOCKS):\n    OUTPUT_CHANNELS = 1\n    inputs = layers.Input(shape=[height, width, channels], name='input_image')\n\n    # Encoder\n    enc_1 = encoder_block(inputs, 64,  7, 1, apply_instancenorm=False, activation=layers.ReLU(), name='block_1') # (bs, 256, 256, 64)\n    enc_2 = encoder_block(enc_1, 128, 3, 2, apply_instancenorm=True, activation=layers.ReLU(), name='block_2')   # (bs, 128, 128, 128)\n    enc_3 = encoder_block(enc_2, 256, 3, 2, apply_instancenorm=True, activation=layers.ReLU(), name='block_3')   # (bs, 64, 64, 256)\n    \n    # Transformer\n    x = enc_3\n    for n in range(transformer_blocks):\n        x = transformer_block(x, 3, 1, name=f'block_{n+1}') # (bs, 64, 64, 256)\n\n    # Decoder\n    x_skip = layers.Concatenate(name='enc_dec_skip_1')([x, enc_3]) # encoder - decoder skip connection\n    \n    dec_1 = decoder_block(x_skip, 128, 3, 2, apply_instancenorm=True, name='block_1') # (bs, 128, 128, 128)\n    x_skip = layers.Concatenate(name='enc_dec_skip_2')([dec_1, enc_2]) # encoder - decoder skip connection\n    \n    dec_2 = decoder_block(x_skip, 64,  3, 2, apply_instancenorm=True, name='block_2') # (bs, 256, 256, 64)\n    x_skip = layers.Concatenate(name='enc_dec_skip_3')([dec_2, enc_1]) # encoder - decoder skip connection\n\n    outputs = last = layers.Conv2D(OUTPUT_CHANNELS, 7, \n                              strides=1, padding='same', \n                              kernel_initializer=conv_initializer, \n                              use_bias=False, \n                              activation='tanh', \n                              name='decoder_output_block')(x_skip) # (bs, 256, 256, 3)\n\n    generator = Model(inputs, outputs)\n    \n    return generator\nsample_generator = generator_fn()\nsample_generator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## discriminator ","metadata":{}},{"cell_type":"code","source":"def discriminator_fn(height=HEIGHT, width=WIDTH, channels=CHANNELS):\n    inputs = layers.Input(shape=[height, width, channels], name='input_image')\n    #inputs_patch = L.experimental.preprocessing.RandomCrop(height=70, width=70, name='input_image_patch')(inputs) # Works only with GPU\n\n    # Encoder    \n    x = encoder_block(inputs, 64,  4, 2, apply_instancenorm=False, activation=layers.LeakyReLU(0.2), name='block_1') # (bs, 128, 128, 64)\n    x = encoder_block(x, 128, 4, 2, apply_instancenorm=True, activation=layers.LeakyReLU(0.2), name='block_2')       # (bs, 64, 64, 128)\n    x = encoder_block(x, 256, 4, 2, apply_instancenorm=True, activation=layers.LeakyReLU(0.2), name='block_3')       # (bs, 32, 32, 256)\n    x = encoder_block(x, 512, 4, 1, apply_instancenorm=True, activation=layers.LeakyReLU(0.2), name='block_4')       # (bs, 32, 32, 512)\n\n    outputs = layers.Conv2D(1, 4, strides=1, padding='valid', kernel_initializer=conv_initializer)(x)                # (bs, 29, 29, 1)\n    \n    discriminator = Model(inputs, outputs)\n    \n    return discriminator\n\n\nsample_discriminator = discriminator_fn()\nsample_discriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## create generator and discriminator","metadata":{}},{"cell_type":"code","source":"T1_generator = generator_fn() # transforms T2 to T1\nT2_generator = generator_fn() # transforms T1 paintings to be T2\n\nT1_discriminator = discriminator_fn() # differentiates real T1 and generated T1\nT2_discriminator = discriminator_fn() # differentiates real T2 and generated T2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## If continue training, load saved model.\n## if new training, please make it Markdown cell","metadata":{}},{"cell_type":"code","source":"T1_generator = tf.keras.models.load_model('../input/mrict-model/T1/generate_mri_3_22')\nT1_discriminator = tf.keras.models.load_model('../input/mrict-model/T1/discriminate_mri_3_22')\nT2_generator = tf.keras.models.load_model('../input/mrict-model/T2/generate_ct_3_22')\nT2_discriminator = tf.keras.models.load_model('../input/mrict-model/T2/discriminate_ct_3_22')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## build cycle gan","metadata":{}},{"cell_type":"code","source":"class CycleGan(keras.Model):\n    def __init__(\n        self,\n        T1_generator,\n        T2_generator,\n        T1_discriminator,\n        T2_discriminator,\n        lambda_cycle=10,\n    ):\n        super(CycleGan, self).__init__()\n        self.T1_gen = T1_generator\n        self.T2_gen = T2_generator\n        self.T1_disc = T1_discriminator\n        self.T2_disc = T2_discriminator\n        self.lambda_cycle = lambda_cycle\n        \n    def compile(\n        self,\n        T1_gen_optimizer,\n        T2_gen_optimizer,\n        T1_disc_optimizer,\n        T2_disc_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n        cycle_loss_fn,\n        identity_loss_fn\n    ):\n        super(CycleGan, self).compile()\n        self.T1_gen_optimizer = T1_gen_optimizer\n        self.T2_gen_optimizer = T2_gen_optimizer\n        self.T1_disc_optimizer = T1_disc_optimizer\n        self.T2_disc_optimizer = T2_disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        \n    def train_step(self, batch_data):\n        real_T1, real_T2 = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            # T2 to T1 back to T2\n            fake_T1 = self.T1_gen(real_T2, training=True)\n            cycled_T2 = self.T2_gen(fake_T1, training=True)\n\n            # T1 to T2 back to T1\n            fake_T2 = self.T2_gen(real_T1, training=True)\n            cycled_T1 = self.T1_gen(fake_T2, training=True)\n\n            # generating itself\n            same_T1 = self.T1_gen(real_T1, training=True)\n            same_T2 = self.T2_gen(real_T2, training=True)\n\n            # discriminator used to check, inputing real images\n            disc_real_T1 = self.T1_disc(real_T1, training=True)\n            disc_real_T2 = self.T2_disc(real_T2, training=True)\n\n            # discriminator used to check, inputing fake images\n            disc_fake_T1 = self.T1_disc(fake_T1, training=True)\n            disc_fake_T2 = self.T2_disc(fake_T2, training=True)\n\n            # evaluates generator loss\n            T1_gen_loss = self.gen_loss_fn(disc_fake_T1)\n            T2_gen_loss = self.gen_loss_fn(disc_fake_T2)\n\n            # evaluates total cycle consistency loss\n            total_cycle_loss = self.cycle_loss_fn(real_T1, cycled_T1, self.lambda_cycle) + self.cycle_loss_fn(real_T2, cycled_T2, self.lambda_cycle)\n\n            # evaluates total generator loss\n            total_T1_gen_loss = T1_gen_loss + total_cycle_loss + self.identity_loss_fn(real_T1, same_T1, self.lambda_cycle)\n            total_T2_gen_loss = T2_gen_loss + total_cycle_loss + self.identity_loss_fn(real_T2, same_T2, self.lambda_cycle)\n\n            # evaluates discriminator loss\n            T1_disc_loss = self.disc_loss_fn(disc_real_T1, disc_fake_T1)\n            T2_disc_loss = self.disc_loss_fn(disc_real_T2, disc_fake_T2)\n\n        # Calculate the gradients for generator and discriminator\n        T1_generator_gradients = tape.gradient(total_T1_gen_loss,\n                                                  self.T1_gen.trainable_variables)\n        T2_generator_gradients = tape.gradient(total_T2_gen_loss,\n                                                  self.T2_gen.trainable_variables)\n\n        T1_discriminator_gradients = tape.gradient(T1_disc_loss,\n                                                      self.T1_disc.trainable_variables)\n        T2_discriminator_gradients = tape.gradient(T2_disc_loss,\n                                                      self.T2_disc.trainable_variables)\n\n        # Apply the gradients to the optimizer\n        self.T1_gen_optimizer.apply_gradients(zip(T1_generator_gradients,\n                                                 self.T1_gen.trainable_variables))\n\n        self.T2_gen_optimizer.apply_gradients(zip(T2_generator_gradients,\n                                                 self.T2_gen.trainable_variables))\n\n        self.T1_disc_optimizer.apply_gradients(zip(T1_discriminator_gradients,\n                                                  self.T1_disc.trainable_variables))\n\n        self.T2_disc_optimizer.apply_gradients(zip(T2_discriminator_gradients,\n                                                  self.T2_disc.trainable_variables))\n        \n        return {\n            \"T1_gen_loss\": total_T1_gen_loss,\n            \"T2_gen_loss\": total_T2_gen_loss,\n            \"T1_disc_loss\": T1_disc_loss,\n            \"T2_disc_loss\": T2_disc_loss\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**loss function**","metadata":{}},{"cell_type":"code","source":"def discriminator_loss(real, generated):\n     real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n\n     generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n\n     total_disc_loss = real_loss + generated_loss\n\n     return total_disc_loss * 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(generated):\n    return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n\n    return LAMBDA * loss1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_loss(real_image, same_image, LAMBDA):\n    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return LAMBDA * 0.5 * loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## tune the learning rate by steps","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef linear_schedule_with_warmup(step):\n    \"\"\" Create a schedule with a learning rate that decreases linearly after\n    linearly increasing during a warmup period.\n    \"\"\"\n    lr_start   = 2e-4\n    lr_max     = 2e-4\n    lr_min     = 0.\n    \n    steps_per_epoch = int(max(500, 500)//BATCH_SIZE)\n    total_steps = EPOCHS * steps_per_epoch\n    warmup_steps = 1\n    hold_max_steps = total_steps * 0.8\n    \n    if step < warmup_steps:\n        lr = (lr_max - lr_start) / warmup_steps * step + lr_start\n    elif step < warmup_steps + hold_max_steps:\n        lr = lr_max\n    else:\n        lr = lr_max * ((total_steps - step) / (total_steps - warmup_steps - hold_max_steps))\n        if lr_min is not None:\n            lr = tf.math.maximum(lr_min, lr)\n\n    return lr\n\nsteps_per_epoch = int(max(500, 500)//BATCH_SIZE)\ntotal_steps = EPOCHS * steps_per_epoch\nrng = [i for i in range(0, total_steps, 50)]\ny = [linear_schedule_with_warmup(x) for x in rng]\n\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=(20, 6))\nplt.plot(rng, y)\nprint(f'{EPOCHS} total epochs and {steps_per_epoch} steps per epoch')\nprint(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_T1_gen = lambda: linear_schedule_with_warmup(tf.cast(T1_generator_optimizer.iterations, tf.float32))\nlr_T2_gen = lambda: linear_schedule_with_warmup(tf.cast(T2_generator_optimizer.iterations, tf.float32))\n    \nT1_generator_optimizer = optimizers.Adam(learning_rate=lr_T1_gen, beta_1=0.5)\nT2_generator_optimizer = optimizers.Adam(learning_rate=lr_T2_gen, beta_1=0.5)\n\n# Create discriminators\nlr_T1_disc = lambda: linear_schedule_with_warmup(tf.cast(T1_discriminator_optimizer.iterations, tf.float32))\nlr_T2_disc = lambda: linear_schedule_with_warmup(tf.cast(T2_discriminator_optimizer.iterations, tf.float32))\n    \nT1_discriminator_optimizer = optimizers.Adam(learning_rate=lr_T1_disc, beta_1=0.5)\nT2_discriminator_optimizer = optimizers.Adam(learning_rate=lr_T2_disc, beta_1=0.5)\n\n# Create GAN\ngan_model = CycleGan(T1_generator, T2_generator, \n                     T1_discriminator, T2_discriminator)\n\ngan_model.compile(T1_gen_optimizer=T1_generator_optimizer,\n                      T2_gen_optimizer=T2_generator_optimizer,\n                      T1_disc_optimizer=T1_discriminator_optimizer,\n                      T2_disc_optimizer=T2_discriminator_optimizer,\n                      gen_loss_fn=generator_loss,\n                      disc_loss_fn=discriminator_loss,\n                      cycle_loss_fn=calc_cycle_loss,\n                      identity_loss_fn=identity_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make a callback, on every epoch end, save models and figures","metadata":{}},{"cell_type":"code","source":"# Callbacks\nclass GANMonitor(Callback):\n    \"\"\"A callback to generate and save images after each epoch\"\"\"\n\n    def __init__(self, num_img=4, T1_path='T1', T2_path='T2'):\n        self.num_img = num_img\n        self.T1_path = T1_path\n        self.T2_path = T2_path\n        # Create directories to save the generate images\n        if not os.path.exists(self.T1_path):\n            os.makedirs(self.T1_path)\n        if not os.path.exists(self.T2_path):\n            os.makedirs(self.T2_path)\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch%7 == 0:\n            fig = plt.figure(figsize=(12,8))\n            for i, img in enumerate(dataset_ct_test.take(self.num_img)):\n                prediction = T1_generator(img, training=False).numpy()\n                prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n                cycle = T2_generator(prediction, training=False)\n                plt.subplot(6,4,i +1)\n                plt.imshow(img[0], cmap = 'gray')\n                plt.axis('off')\n                plt.subplot(6,4,i +5)\n                plt.imshow(prediction[0], cmap = 'gray')\n                plt.axis('off')\n                plt.subplot(6,4,i +9)\n                plt.imshow(cycle[0], cmap = 'gray')\n                plt.axis('off')\n            \n       \n            for i, img in enumerate(dataset_T2_test.take(self.num_img)):\n                prediction = T2_generator(img, training=False).numpy()\n                prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n                cycle = T1_generator(prediction, training=False)\n                plt.subplot(6,4,i + 13)\n                plt.imshow(img[0], cmap = 'gray')\n                plt.axis('off')\n                plt.subplot(6,4,i + 17)\n                plt.imshow(prediction[0], cmap = 'gray')\n                plt.axis('off')\n                plt.subplot(6,4,i + 21)\n                plt.imshow(cycle[0], cmap = 'gray')\n                plt.axis('off')\n            plt.show()\n            plt.savefig(f'{self.T1_path}/visualiation_{i}_{epoch+1}')\n        if epoch%7 == 0:\n            tf.keras.models.save_model(T1_generator, f'{self.T1_path}/generate_mri_{i}_{epoch+1}')\n            tf.keras.models.save_model(T1_discriminator, f'{self.T1_path}/discriminate_mri_{i}_{epoch+1}')\n            tf.keras.models.save_model(T2_generator, f'{self.T2_path}/generate_ct_{i}_{epoch+1}')\n            tf.keras.models.save_model(T2_discriminator, f'{self.T2_path}/discriminate_ct_{i}_{epoch+1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train model","metadata":{}},{"cell_type":"code","source":"gan_ds = tf.data.Dataset.zip((dataset_T2, dataset_ct))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history =   gan_model.fit(gan_ds,\n                          epochs=EPOCHS,\n                          callbacks=[GANMonitor()],\n                          steps_per_epoch=(max(500, 500)//BATCH_SIZE) ).history    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## show results","metadata":{}},{"cell_type":"code","source":"test_ds = tf.data.Dataset.zip((dataset_T2_test, dataset_ct_test)).shuffle(10) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def estimation_generator_T1(T1_generator, test_ds):\n    fig = plt.figure(figsize= (16,5)) \n    psnr = []\n    ssim = []\n\n    for i, img in enumerate(test_ds.take(8)): \n        image_T1, image_T2 = img\n        generated_T1 = T1_generator(image_T2)\n        plt.subplot(2,8,(i+1))\n        plt.imshow(image_T2[0], cmap = 'gray')\n        plt.title('CT image')\n        plt.axis('off')\n        plt.subplot(2,8, (i+9))\n        plt.imshow(generated_T1[0], cmap = 'gray')\n        plt.title('Generated \\n MRI image')\n        plt.axis('off')\n    \n    for i, img in enumerate(test_ds.take(100)):   \n        image_T1, image_T2 = img\n        generated_T1 = T1_generator(image_T2)\n        psnr.append( tf.image.psnr(generated_T1, image_T1, max_val=2))\n        ssim.append( tf.image.ssim(generated_T1, image_T1, max_val=2))\n\n    psnr_mean = np.mean(psnr)\n    psnr_std = np.std(psnr, ddof=1)\n    ssim_mean = np.mean(ssim) \n    ssim_std = np.std(ssim, ddof=1)\n    print('========CT to MRI =========')\n    print('PSNR ={}, std ={}'.format(psnr_mean, psnr_std))\n    print('SSIM ={}, std ={}'.format(ssim_mean, ssim_std))\n    plt.show()\n    \n    \ndef estimation_generator_T2(T2_generator, test_ds):\n    fig = plt.figure(figsize= (16,5)) \n    psnr = []\n    ssim = []\n\n    for i, img in enumerate(test_ds.take(8)): \n        image_T1, image_T2 = img\n        generated_T2 = T2_generator(image_T1)\n        plt.subplot(2,8,(i+1))\n        plt.imshow(image_T1[0], cmap = 'gray')\n        plt.title('MRI image')\n        plt.axis('off')\n        plt.subplot(2,8, (i+9))\n        plt.imshow(generated_T2[0], cmap = 'gray')\n        plt.title('Generated \\n CT image')\n        plt.axis('off')\n    \n    for i, img in enumerate(test_ds.take(100)):   \n        image_T1, image_T2 = img\n        generated_T2 = T2_generator(image_T1)\n        psnr.append( tf.image.psnr(generated_T2, image_T2, max_val=2))\n        ssim.append( tf.image.ssim(generated_T2, image_T2, max_val=2))\n\n    psnr_mean = np.mean(psnr)\n    psnr_std = np.std(psnr, ddof=1)\n    ssim_mean = np.mean(ssim) \n    ssim_std = np.std(ssim, ddof=1)\n    print('========MRI to CT =========')\n    print('PSNR ={}, std ={}'.format(psnr_mean, psnr_std))\n    print('SSIM ={}, std ={}'.format(ssim_mean, ssim_std))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimation_generator_T2(T2_generator, test_ds)\nestimation_generator_T1(T1_generator, test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}