{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Favourite movies from Global-Neflix in 2020\n**The Intention of my work is to use the current data, to find the movies which I like in global netflix now. I have divided my work into the following part**\n\n* Clean up the data\n* Create one pandas dataframe include all the data\n* Algorithm to find the movies a user may like (recomendation)\n\n    1.  Find the customers who watched atleast 30 same movies\n    2.  Isolate customers with strong correlation with the user\n    3.  For each customer who has strong correlation, find the movies which they watched\n    4.  Of these movies find the movies which they rated to be 4 or above\n    5.  Recommend the user which have been repeatedly recommend by these users\n    6.  Oreder the recommendation based on how many times they were recommended.\n\n\n* The above algorithms takes hours to compile due to millions of rows.\n* I recommend using cupy code(which I will give the code) with GPU, since I found it to be 300% faster\n\n## How to use the above code to find global moveis in Netlix?\n\n* I have collected the Imdb data, from another database in Kaggle, which has common movies with the list here.\n* I shall leave the link to the database here.\n* I write a function which give you a movie to rate from 1 to 5, if you have watched it (rating=0)\n* I recommend find atleast 50 movies which you like.\n* At the end you can add yourself as an user and find the movies which you will like from the database\n* Finally I will give the rapid api link, where you can access the current Netlix movies.\n[https://rapidapi.com/unogs/api/unogsng](http://)\n* If you need the code to access, I can share.\n* You are allowed only 100 requests per day for free, and 100 movies per request.\n* I found 12900 movies in Netlix globally now","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom IPython.display import clear_output\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# I am on loading combine_data_1\ndf1=pd.read_csv('/kaggle/input/netflix-prize-data/combined_data_1.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n#df2=pd.read_csv('/kaggle/input/netflix-prize-data/combined_data_2.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n#df3=pd.read_csv('/kaggle/input/netflix-prize-data/combined_data_3.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n#df4=pd.read_csv('/kaggle/input/netflix-prize-data/combined_data_4.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n#df=[df1,df2,df3,df4]\n#df=pd.concat(df,axis=0)\n\n# The rows with customr Id has ':' is the movie id\n# For example the first row the '1:' is the movie id\n# On 548 row the customer id '2:' is the movie id\n\nprint(df1.head())\nprint(df1[df1.Rating.isna()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hence add column movie id and fill that witht the movie id\n# For example '1' for index 0 to 547\n# Then drop all rows with NaN \n\n\nn=df1.loc[pd.isnull(df1.Rating)].index\ndf1['Movie_id']=np.zeros(df1.shape[0])\nfor i in range(len(n)-1):\n    df1.iloc[np.arange(n[i],n[i+1]),-1]=int(df1.iloc[n[i],0][:-1])\ndf1.dropna(axis=0,inplace=True)\ndf1[['Cust_Id','Rating','Movie_id']]=df1[['Cust_Id','Rating','Movie_id']].astype('int32')\nprint(df1.iloc[545:550,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Corelation function\n### Filtered array: array containing all the customers who watched atleast n number of movies as the user\n### c1: array containing all the movies watched by a user\n### ids of all the customers\n\n\n\ndef corr_function(filtered_array,c1,ids):\n\n    corr_list=np.zeros(ids.shape[0])\n\n    for i in np.arange(ids.shape[0]):\n      id2=ids[i]\n      c2=filtered_array[np.where(filtered_array[:,0]==id2)]\n      n2=c2[np.where(np.in1d(c2[:,1],c1[:,0]))]\n      n1=c1[np.where(np.in1d(c1[:,0],c2[:,1]))]\n      corr_list[i]=np.corrcoef(n2[:,2],n1[:,1])[0,1]\n      \n    return corr_list\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n###Cupy is found to be much faster than numpy\n\n#import cupy as cp\n#def corr_function_cp(filtered_array,c1,ids):\n#  cp.cuda.Device().synchronize()\n# with cp.cuda.Device(0):\n#    corr_list=cp.zeros(ids.shape[0])\n    \n#    for i in cp.arange(ids.shape[0]):\n#      id2=ids[i]\n#      c2=filtered_array[cp.where(filtered_array[:,0]==id2)]\n#      n2=c2[np.where(cp.in1d(c2[:,1],c1[:,0]))]\n#      n1=c1[np.where(cp.in1d(c1[:,0],c2[:,1]))]\n#      corr_list[i]=cp.corrcoef(n2[:,2],n1[:,1])[0,1]\n      \n#  return corr_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"req_id=822109\n## Find all the customers who watched the same movies as the required user\n\ncust_unique=df1.loc[df1.Cust_Id==req_id]\ndf_filtered=df1.loc[df1.Movie_id.isin(cust_unique.Movie_id.values)]\n\n# Num of minimum common movies between the user and any given customer\n# bls contains all the ids of customers who have minimum 30 movies or greater common\nnum_of_movies=15\n\nbls=df_filtered.groupby(['Cust_Id']).apply(lambda x: len(x) >= num_of_movies)\nbls=bls[bls.values==True].index\nbls=bls[bls!=req_id]\nprint(['Total customers with minimum 30 movies: '+str(len(bls))])\n\n\nfiltered_array_values=df_filtered[['Cust_Id','Movie_id','Rating']].dropna(axis=0).values\n\n\n# Dataframe values where req_id is present\nc1=df_filtered.loc[df_filtered.Cust_Id==req_id,['Movie_id','Rating']].dropna(axis=0).values\n\ncorrelation_values=corr_function(filtered_array_values,c1,np.array(bls))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Using Cupy in case of GPU\n#with cp.cuda.Device(0):\n # filtered_array_cupy=cp.asarray(filtered_array)\n  #arc1=df_filtered.loc[df_filtered.Cust_Id==req_id,['Movie_id','Rating']].dropna(axis=0).values\n  #arc1_cupy=cp.asarray(arc1)\n  #start_time=time.time()\n\n#cProfile.run('corr_function_cp(filtered_array_cupy,arc1_cupy,cp.array(bls[range(1000)]))')\n#correlation_values=corr_function_cp(filtered_array_cupy,arc1_cupy,cp.array(bls[range(10)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### \n#Ids=corr_function_cp(filtered_array_cupy,arc1_cupy,cp.array(bls))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Correlated Ids: Ids of the coustomers who have correlation greater than 0.7\n# we can take the negative also, but for in this case I am neglecting, since I found only few ids based\n#on my experience of running \n\n# 0.7 is arbitrary value I took, but I guess we can use 0.75 or 0.8 based on our experience\n\nCorrelated_Ids=[]\nfor x,y in zip(bls,correlation_values):\n  if y>0.7:\n    #print(y)\n    Correlated_Ids.append(x)\nlen(Correlated_Ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The function finds the movies which are not watched by the user but rated high by the customer\n# pass the customer id to get the moovies list\n\ndef Recommended_Movies_from_an_Id(id):\n  Movie_Test=df1.loc[(df1.Cust_Id==id)&(df1.Rating>3),['Movie_id']].values\n  Movie_Test=list(Movie_Test)\n  for each in df_filtered.Movie_id.unique():\n    try:\n      Movie_Test.remove(each)\n    except:\n      pass\n  Movie_Test=df1.loc[(df1.Cust_Id==id)&(df1.Movie_id.isin(Movie_Test)),['Movie_id','Rating']]\n  return Movie_Test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## The list of all recommended movies for a particular user\nAll_Recommended_Movies=[]\nfor each in Correlated_Ids:\n  All_Recommended_Movies.append(Recommended_Movies_from_an_Id(each))\nAll_Recommended_Movies=pd.concat(All_Recommended_Movies)\nAll_Recommended_Movies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Select only the movies which are recommended more than 'filter_count' times, in this case\n# I am passing the values 5\n\ndef Repeated_Recomendation(movies_list,filter_count):\n  records_array = np.array(movies_list)\n  vals, inverse, count = np.unique(records_array, return_inverse=True,\n                                return_counts=True)\n\n  idx_vals_repeated = np.where(count > filter_count)[0]\n  vals_repeated = vals[idx_vals_repeated]\n  return vals_repeated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vals_repeated=Repeated_Recomendation(All_Recommended_Movies.Movie_id.values,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load the movies titles to dataframe list of movies\nlist_of_movies=pd.read_csv('/kaggle/input/netflix-prize-data/movie_titles.csv', usecols = [0,1,2],encoding = \"ISO-8859-1\",header=None,names=['id','year','Name'])\nlist_of_movies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the movies which are repeated\n\nmovies_repeated=list_of_movies.loc[list_of_movies.id.isin(vals_repeated),['Name','year']]\n# Recomendation is simply based on the sum of ratings \nmovies_repeated['recomendation']=All_Recommended_Movies.loc[All_Recommended_Movies.Movie_id.isin(vals_repeated)].groupby(['Movie_id'])['Rating'].sum().sort_values(ascending=False).values\nmovies_repeated['recomendation']=movies_repeated['recomendation']/movies_repeated['recomendation'].max()\ndecimals = 2    \n# Lets set the  the maximum sum to 1, the rest are fraction of that \nmovies_repeated['recomendation'] = movies_repeated['recomendation'].apply(lambda x: round(x, decimals))\nprint(movies_repeated.shape)\nprint(movies_repeated.head(50))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **    **The End of Part 1: Recommending the movies: For a user from list ******","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Part2: An algorithm to find the movies we like (you and me)**\n* ** We need to find the genre of each movie in the list of movie**\n* **It is impossible to find the movies which we like without knowing the genre, it filters our alot of mives**\n* Hence, I used another database from Kaggle I leave the link here,this database consists of movies from Imdb\n[https://www.kaggle.com/stefanoleone992/imdb-extensive-dataset](http://)\n* Load that database,I will upload for my program here","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Imdb=pd.read_csv('/kaggle/input/imdbdata/AllMoviesDetailsCleaned.csv',encoding = \"ISO-8859-1\",error_bad_lines=False,sep=';')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_movies.Name=list_of_movies.Name.apply(lambda x:x.lower())\nImdb['year']=pd.to_datetime(Imdb.release_date)\nImdb.title=Imdb.title.astype(str)\nImdb['title']=Imdb.title.apply(lambda x:x.lower())\nImdb.year=Imdb.year.apply(lambda x:x.year)\nImdb.year=Imdb.year.fillna(0)\nImdb.year.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Find the genres for movies in imdb list\n## I am merging both dataframes\nlist_of_movies.rename({'Name':'title'},axis=1,inplace=True)\nMovies_in_Imdb_set=list_of_movies.merge(Imdb,left_on=['title',\"year\"],right_on=['title','year'])\nprint('Number of movies available in Imdb Dataset: '+ str(Movies_in_Imdb_set.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create a random id in database for you\n## Make sure Id doesn't exist in current database\n\nnew_user_id=np.random.randint(1,2649429,1)\nwhile new_user_id in df1.Cust_Id.values:\n  new_user_id=np.random.randint(1,2649429,1)\nprint(new_user_id)\n## Lets create a dataframe to attach to the main dataset\ndf_input=[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert this cell to code to run the loop\n\n## Show the user a random\n## If he watch rate between 1 and 5\n## Didn't watch rate it as 0\n## Remove the movie he watched from the list to\n## Every time you execute you can add new conditions, so feel free to run this any number of times\n\n\n\nyr=input('Enter the minimum year ')\ngen=input('Enter the Genre ')\n\ngenre_data=Movies_in_Imdb_set[Movies_in_Imdb_set.genres.str.contains(gen)&(Movies_in_Imdb_set.year>int(yr))&(Movies_in_Imdb_set.spoken_languages.str.contains('|'.join(['English','Hindi'])))].sort_values(by=['vote_average'],ascending=False)\ntry:\n  genre_data=genre_data.iloc[:100]\nexcept:\n  pass\nwhile len(df_input)<60:\n  movie_selected=genre_data.iloc[np.random.randint(0,np.min(np.array([100,genre_data.shape[0]])),1)]\n  print(len(df_input))\n\n  print(movie_selected.iloc[0])\n  rating = input()\n  clear_output(wait=True)\n  Movies_in_Imdb_set=Movies_in_Imdb_set.loc[Movies_in_Imdb_set.title!=movie_selected.iloc[0].title]\n  genre_data=genre_data.loc[genre_data.title!=movie_selected.iloc[0].title]\n  try:\n    if (int(rating!=0))&(int(rating)<6):\n      df_input.append(pd.DataFrame({'Cust_Id':new_user_id,'Movie_id':movie_selected.id,'Rating':int(rating)}))\n      print(len(df_input))\n  except:\n    pass\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Convert this cell to code to make it work**\n#Once you have completed adding the movies you like concat the data to Dataframe df1\n\ndf_input=pd.concat(df_input)\ndf1=pd.concat([df1,df_input])\n\n\n## in cell 5 replace this with your id and execute to get the movies that you like","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# END:Now you can use the movies from Rapid api, I am sharing \n**Here you can find in which country, movie is available in Neflix-Global**\n\n[https://rapidapi.com/unogs/api/unogsng](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}