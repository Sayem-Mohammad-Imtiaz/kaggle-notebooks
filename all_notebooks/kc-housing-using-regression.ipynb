{"cells":[{"metadata":{},"cell_type":"markdown","source":"id - Unique ID for each home sol<br>\n\ndate - Date of the home sale <br>\n\nprice - Price of each home sold <br>\n\nbedrooms - Number of bedrooms <br>\n\nbathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower <br>\n\nsqft_living - Square footage of the apartments interior living space <br>\n\nsqft_lot - Square footage of the land space <br>\n\nfloors - Number of floors <br>\n\nwaterfront - A dummy variable for whether the apartment was overlooking the waterfront or not <br>\n\nview - An index from 0 to 4 of how good the view of the property was <br>\n\ncondition - An index from 1 to 5 on the condition of the apartment,<br>\n\ngrade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design. <br>\n\nsqft_above - The square footage of the interior housing space that is above ground level <br>\n\nsqft_basement - The square footage of the interior housing space that is below ground level <br>\n\nyr_built - The year the house was initially built <br>\n\nyr_renovated - The year of the house’s last renovation <br>\n\nzipcode - What zipcode area the house is in <br>\n\nlat - Lattitude <br>\n\nlong - Longitude <br>\n\nsqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors <br>\n\nsqft_lot15 - The square footage of the land lots of the nearest 15 neighbors <br>"},{"metadata":{},"cell_type":"raw","source":"Multivariate Normality– Multiple regression assumes that the residuals are normally distributed.\n\nNo Multicollinearity— Multiple regression assumes that the independent variables are not highly correlated with each other.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/kc-housesales-data/kc_house_data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() #Getting the datatype of features","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping id and date column as they are not of any significance in predicting price\ndf = df.drop(['id', 'date'], axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding categorical and numerical columns\ncategorical_columns = []\n\nfor i in df.columns:\n  unique_values = len(pd.unique(df[i])) \n  if unique_values < 90:\n    print(f\"Unique values in {i} are {len(pd.unique(df[i]))}\")\n    categorical_columns.append(i)\nprint('Categorical Columns', categorical_columns)\nprint('No. of categorical columns',len(categorical_columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nfig, axs = plt.subplots(ncols=2, nrows=5, figsize=(20, 30)) #specifies how many diagrams we want is each row\nindex = 0\n\naxs = axs.flatten()\nprint('length after flatten', len(axs))\nprint(axs[index])\nfor k,v in df.items():\n    if k not in categorical_columns:\n        sns.boxplot(y=k, data=df, ax=axs[index])\n        index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0) #adjusting padding between figures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating percentage outlier in all numerical columns\nfor column in df.columns:\n    \n    if column not in categorical_columns:\n        count = 0\n        column_array = np.array(sorted(list(df[column])))\n        q1 = np.percentile(column_array, 25)\n        q3 = np.percentile(column_array, 75)\n        iqr =  q3 - q1\n        for i in column_array:\n            if i < (q1 - 1.5*iqr):\n                count +=1\n            elif i > (q3 + 1.5*iqr):\n                count +=1\n       \n        print(f'Total outliers in {column} = {((count/len(column_array)) * 100)}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting correlation\ncorrMatrix = df.corr()\nplt.figure(figsize=(25,10)) # Plotting the figure of required size\nax = sns.heatmap(corrMatrix, vmin=0, vmax=1, center=0, annot=True,\n                 cmap=\"YlGnBu\", linewidths = 1.0,\n                 square=True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,1:]\nY = df.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 41)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regression = linear_model.LinearRegression()\nregression.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Evaluating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = regression.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.mean_absolute_error(Y_test, Y_pred))\nprint(metrics.mean_squared_error(Y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MSE = np.square(np.subtract(Y_test,Y_pred)).mean() \nprint(MSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}