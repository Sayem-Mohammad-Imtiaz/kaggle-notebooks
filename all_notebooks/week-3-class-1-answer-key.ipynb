{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> Try to finish the Pokemon and NFL statsheet problems in class. If time permits, go over the Austin weather problem as well; if not, assign it as optional homework.\n> Remember that you are *guiding* the students through completing these projects! Use your best judgement to control the flow of the class while letting the class give their best attempts at solving the problems.","metadata":{}},{"cell_type":"markdown","source":"# Beginning a Pokemon Journey\n\nYou’re beginning your Pokemon journey and your goal is to become the most powerful gym leader. To do that, you have to pick a Pokemon type to train. Using Python and Pandas, decide which team you should begin training!\n\nTo start, \n* **Import Pandas** and **read in pokemon_data.csv**. \n* Familiarize yourself with the data by **printing the columns** as well as the **first 9 rows**.","metadata":{}},{"cell_type":"code","source":"import pandas as pd \n\ndf = pd.read_csv('../input/week3class1review/pokemon_data.csv')\nprint(df.columns, '\\n')\ndf.head(9)\n#or \n#print(df.head(9))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a beginner, you can’t catch any legendaries yet! \n* **Remove all legendary Pokemon** (Legendary == True) from the dataframe.","metadata":{}},{"cell_type":"code","source":"#Need .index to specify rows\n#This statement is dropping the rows indicated by the indices\n#   where Legendary == True\ndf = df.drop(df.loc[df['Legendary'] == True].index)\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, find out the stat total for each Pokemon. \n* **Add a column called ‘Total’** to your dataframe and make it the **sum** of HP, Attack, Defense, Special Attack, Special Defense, and Speed for each Pokemon. ","metadata":{}},{"cell_type":"code","source":"#[:, 4:10] -> all the rows, columns 4-9\n#.sum(axis=1) -> summing columns (horizontally)\ndf['Total'] = df.iloc[:, 4:10].sum(axis=1)\ndf\n\n#or\n#df['Total'] = df['HP'] + df['Attack'] + df['Defense'] + df['SpAtk'] + df['SpDef'] + df['Speed']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, to select a type to train,\n* **Create a pivot table** with **Type1 as the row index and Total as the column values**. The pivot table should display the average stat total for each primary type. \n* **Sort your pivot table by descending**, and note the type with the highest stat total. This will be the type of your team!","metadata":{}},{"cell_type":"code","source":"df_pivot = pd.pivot_table(df, index='Type1', values='Total')\ndf_pivot = df_pivot.sort_values('Total', ascending=False)\ndf_pivot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Filter** the dataframe from earlier so it only displays Pokemon where **Type1 or Type2** is equal to the type you chose in the last part.\n* **Sort** this filtered dataframe by descending. The top six Pokemon will be your team!","metadata":{}},{"cell_type":"code","source":"df.loc[(df['Type1'] == 'Dragon') | (df['Type2'] == 'Dragon')].sort_values('Total', ascending=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing a Statsheet for NFL Commentators\n\nThe Dallas Cowboys and Tampa Bay Buccaneers will play the first game of the 2021 NFL season. Your job is to prepare stat sheets for the announcers to reference during the game. Given multiple files of data from last year’s season, merge and clean the data according to the liking of the announcers. This is the format that they asked for -\n\n*Columns from left to right:*\n* Week\n* Tampa Bay Opponent\n* Tampa Bay Total Offensive Yards Gained\n* Tampa Bay Total Defensive Yards Allowed\n* Dallas Opponent\n* Dallas Total Offensive Yards Gained\n* Dallas Total Defensive Yards Allowed","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n#Open both files\ndf_tam = pd.read_csv('../input/week3class1review/tampa_stats.csv')\ndf_dal = pd.read_csv('../input/week3class1review/dallas_stats.csv')\n\ndf_tam.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Delete the unneeded columns for the Tampa Bay statsheet\ndf_tam2 = df_tam.drop(df_tam.iloc[:, 1:9], axis=1)\n#df_tam2.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since you can't input multiple splices to .iloc,\n#   you'll have to go step by step and check for the first one\ndf_tam2 = df_tam2.drop(df_tam2.iloc[:, 2:5], axis=1)\n#df_tam2.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The last slice, and the rest of the values after the\n#   last desired column\ndf_tam2 = df_tam2.drop(df_tam2.iloc[:, 3:7], axis=1)\ndf_tam2 = df_tam2.drop(df_tam2.iloc[:, 4:], axis=1)\n#df_tam2.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now, change the column titles to the ones in row 0 and delete row 0\n#This is a change we have to make since the original file has two headers\ndf_tam2 = df_tam2.rename(columns={'Unnamed: 0': 'Week',\n                        'Unnamed: 9': 'TampaOpp',\n                        'Unnamed: 13': 'TampaOffensiveTotYd',\n                        'Unnamed: 18': 'TampaDefensiveTotYd'})\ndf_tam2 = df_tam2.drop([0], axis=0)\ndf_tam2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Repeat all of these steps for the Dallas file\n#Note that you can easily copy and paste all of this from \n#   earlier and change the variable names\ndf_dal2 = df_dal.drop(df_dal.iloc[:, 1:9], axis=1)\ndf_dal2 = df_dal2.drop(df_dal2.iloc[:, 2:5], axis=1)\ndf_dal2 = df_dal2.drop(df_dal2.iloc[:, 3:7], axis=1)\ndf_dal2 = df_dal2.drop(df_dal2.iloc[:, 4:], axis=1)\ndf_dal2 = df_dal2.rename(columns={'Unnamed: 0': 'Week',\n                        'Unnamed: 9': 'DallasOpp',\n                        'Unnamed: 13': 'DallasOffensiveTotYd',\n                        'Unnamed: 18': 'DallasDefensiveTotYd'})\ndf_dal2 = df_dal2.drop([0], axis=0)\ndf_dal2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merge the two dataframes\ndf = pd.merge(df_tam2, df_dal2, on='Week')\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking Into Austin Weather\n\nA weather station in Austin, Texas has given you a very large collection of data that has been gathered over the years 2013-2017. They need you to clean and summarize this data for a project they are working on. Below are the instructions they have given.\n* **Import pandas** and **read in austin_weather.csv**.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/week3class1review/austin_weather.csv')\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For this project, the meteorologists are not concerned with anything to do with humidity or wind. \n* **Drop the columns** that relate to these measurements.","metadata":{}},{"cell_type":"code","source":"df2 = df.drop(columns=['HumidityHighPercent', 'HumidityAvgPercent', 'HumidityLowPercent'])\ndf2 = df2.drop(columns=['WindHighMPH', 'WindAvgMPH', 'WindGustMPH'])\ndf2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Print all the weather data** from the **first day of every year** recorded.\n* **Print the days from 2016** when the **high temperature was greater than or equal to 90 degrees fahrenheit**.","metadata":{}},{"cell_type":"code","source":"df2.loc[(df2['Month'] == 1) & (df2['Day'] == 1)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.loc[(df2['Year'] == 2016) & (df2['TempHighF'] >= 90)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The weather station's data has been corrupted, so all of the recorded days with no rain have null values in the Precipitation column.\n* First, **print all the rows with null values**.\n* **Fill all null values in the Precipitation column with 0**. \n* Then, **print all days in April when it rained**.","metadata":{}},{"cell_type":"code","source":"df2.isnull()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.fillna(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.loc[(df2['Month'] == 4) & df2['PrecipitationSumInches'] > 0]","metadata":{},"execution_count":null,"outputs":[]}]}