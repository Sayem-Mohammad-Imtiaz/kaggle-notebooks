{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Построение прогноза выживших на Титанике**\n\n\nПервая попытка поучаствовать в соревнованиях Kaggle :)\n\n**Целями этой работы являются:**\n1. Тренировка воркфлоу работы с данными\n2. Знакомство с функционалом Kaggle и принципами работы соревнований\n3. Знакомство с ML моделями прогнозирования и особенностями подготовки данных для них\n\n**Краткое описание проблемы** - зная из датасета **train** пассажиров, их характеристики и погибли они или нет, создать модель, которая бы предсказывала выжил или погиб пассажир в датасете **test**.\n\n[Ссылка на детальное описание соревнования](https://www.kaggle.com/c/titanic).\n\nИтак, приступим)\n"},{"metadata":{},"cell_type":"markdown","source":"# 1. Импортируем библиотеки необходимые для первичного изучения данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Библиотеки для работы с данными\nimport pandas as pd\nimport numpy as np\n\n#Библиотеки для визуализации\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Считываем датасеты, смотрим как они выглядят и сразу же проверяем описательные статистики train.\\\nTest пока не смотрим, т.к. там по идее тоже самое что и в train, но без указания выжил человек или погиб."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/titanic/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include=\"all\").round()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Первоначальные наблюдения:**\n* Как и было указано в описании, всего в датасете train есть информация о 891 пассажире\n* Видим что в колонках Age, Cabin и Embarked не все данные (count для этих строк меньше 891). Проверяем дополнительно с помощью **isna()**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* У нас действительно нет данных о возрасте для 177 пассажиров. Это надо будет как-то заполнить, так как возраст совершенно точно существенно влияет на выживаемость, учитывая приказ капитана Титаника о загрузке шлюпок в первую очередь женщинами и детьми (спасибо Wiki). Удалять эти строки я бы не стал, так как они составляют достаточно крупную часть датасета (около 20%).\n* Также отсутствует информация о номере кабины / каюты для 687 пассажиров. Почитав форумы Keggle, нашел теорию что номера кают отсутсвуют у более бедных классов (Ticket class). Ниже построим график, чтобы это проверить и потом решим что делать.\n* Отсуствие данных о порте погрузки для 2-х человек несущественно. Думаю что заменим на какое-нибудь значение.\n"},{"metadata":{},"cell_type":"markdown","source":"# 2. Заполнение пропущенных значений\n**Начнем с колонки age, в которой не хватает 177 значений. Наиболее очевидные варианты заполнить их это:**\n1. Попробовать предсказать примерную возрастную группу с помощью гоноративов (Mr, Mrs, Miss и т.п.)\n2. Взять данные с какого-нибудь сайта, где они уже есть в полном виде (ну или более полном)\n\n\nВторой вариант хоть и не очень спортивен, правилами совернования не запрещен, поэтому попробуем реализовать именно его. Так мы получим наиболее точные данные о возрасте и одновременно потренируем веб-скрейпинг. Доставать данные о возрасте было решено с https://en.wikipedia.org/wiki/Passengers_of_the_Titanic.\n\nПоскольку Kaggle не поддерживает BeautifulSoup, который я использовал для получения веб-данных, то вот [ссылка на код с github](https://nbviewer.jupyter.org/github/NikitaVhr/Training-public-/blob/2a78fa39e9336f073d4364c16c6921e26c923210/Code%20for%20Wiki%20Scraping.ipynb), итогом которого стал датасет **scraped_age**. Однако просто взять и сджойнить его здесь с данными в соревновании пока нельзя по той причине, что ключ (имя), по которому я планировал их объединить, у многих людей отличаются. Так, например, человек с именем ***Moran, Mr. James*** в одном датафрейме указан как ***Moran, Mr. Daniel James*** в данных с Wikipedia.\n\nРешить эту проблему помог Excel, а точнее функция vlookup, в которой есть параметр, позволяющий подтянуть как точно совпадающие значения, так и приблизительные.\nВ итоге, перед загрузкой сюда, **scraped_age** был доработан в Excel следующим образом:\n1. Объединены имена и возраст из таблиц train и test, чтобы получить единую полную таблицу для всех пассажиров\n2. Сначала к именам без возраста подтянуты ВПР'ом точно совпадающие значения с Wiki\n3. Затем к осташимся именам без возраста подтянуты приблизительные значения c Wiki\n\nПосле описанных выше преобразований получился датасет **scraped_age** в котором для 1308 пассажиров был указан возраст."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cчитываем датасет и смотрим как он выгялдит\nscraped_age = pd.read_csv('../input/scraped-age/scraped_age.csv')\nscraped_age.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем к train данные о возрасте, которые взяли из Википедии\ntrain = train.merge(scraped_age, on='Name', how='left')\n\n# Заполяем пропущенные значения Age данными из датасета scraped_age\ntrain['Age'] = train['Age'].fillna(train['Age_full'])\n\n# Убираем только что добавленную колонку, т.к. она нам теперь не нужна\ntrain = train.drop(['Age_full'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посколкьку у нас есть еще датасет test, сразу же смотрим его и делаем то же самое что и для train."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем данные о возрасте, которые взяли в Википедии\ntest = test.merge(scraped_age, on='Name', how='left')\n\n# Заполяем пропущенные значения Age данными из датасета scraped_age\ntest['Age'] = test['Age'].fillna(test['Age_full'])\n\n# Убираем только что добавленную колонку, т.к. она нам теперь не нужна и возникшие при джойне дубликаты\ntest = test.drop(['Age_full'], axis = 1)\ntest = test.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Решаем что делать с отсутствующей информацией о номере кабины / каюты пассажиров**\n\n\nИнформации нет для 687 пассажиров (77% датафрейма). Это много.\n\nЕсли теория о том, что номера кают отсутсвуют у более бедных классов (Ticket class), то думаю что мы эту колонку просто удалим, так как предполагаю, что номер каюты должен быть тесно связан с классом, информация о котором у нас есть в полном объеме."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Задаем параметры для отображения нескольких графиков + настраиваем их размер\nfig, ax = plt.subplots(1, 2,figsize=(15,5))\n\n# Создаем \"булевую\" колонку, чтобы посмотреть влияет ли наличие информации о каюте как-то на выживаемость\ntrain[\"CabinBool\"] = train[\"Cabin\"].notnull().astype('int')\ntest[\"CabinBool\"] = test[\"Cabin\"].notnull().astype('int')\nsns.barplot(x=\"CabinBool\", y=\"Survived\", data=train,ax=ax[0])\n\n# Строим каунтплот чтобы проверить теорию о том, что данные о каютах отсутствуют у более бедного класса\nsns.countplot(x=\"Pclass\", data=train[train.CabinBool == 0], ax=ax[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Похоже, теория о том, что люди, у которых данные о каютах отсутствуют, были из более бедного класса, подтвердилась. Большая часть людей без номера каюты была из 2-го и 3-го класса.\n* Тут же отмечу, что у пассажиров, у которых номер каюты указан, было больше шансов выжить (около 65%).\n* В итоге решаю что **колонку Cabin можно исключить из датафреймов**, но созданную CabinBool оставлю.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Заполняем все оставшиеся пробелы**\n\n\nПомним, что в **train** у нас еще осталась пара пропущенных значений в колонке **Embarked**, а в **test** есть пропущенное значение в **Fare**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим, в каком порту больше всего село людей\nsns.countplot(x=\"Embarked\", data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Раз большинство людей сели в Southampton (S), то им же пропущенные значения и заполним.\ntrain = train.fillna({\"Embarked\": \"S\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим у кого не хватает данных о стоимости билета\nfare_check = test[test['Fare'].isnull()]\nfare_check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вставляем вместо пропуска среднюю стоимость билета того же класса (3-го)\nmean_fare = round(test[test.Pclass == 3].Fare.mean(), 4)\ntest = test.fillna({\"Fare\": mean_fare})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проверяем, что все данные мы заполнили и идем дальше)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Визуализируем данные и смотрим у кого было больше шансов выжить"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 6,figsize=(30,5))\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train, ax=ax[0]).set_title('Class')\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train, ax=ax[1]).set_title('Sex')\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train, ax=ax[2]).set_title('# of siblings / spouses aboard')\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train, ax=ax[3]).set_title('# of parents / children aboard')\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train, ax=ax[4]).set_title('Port of Embarkation')\nsns.countplot(x=\"Survived\", data=train, ax=ax[5]).set_title('# of people survived / died')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Наблюдения:**\n* **Pclass** - Люди из более высокого класса имеют более высокую выживаемость (около 63%).\n* **Sex** - Женщины имели гораздо больший шанс (около 74%) на выживание, чем мужчины.\n* **SibSp** - Чем больше у тебя родственников, тем меньше шанс на выживание. Низкий процент у людей без родственников, скорее всего, объясняется тем, что в одиночку по большей части путешествовали мужчины.\n* **Parch** - Люди, у которых менее четырех/пяти детей на борту выживут с большей вероятностью. Как и в предыдущем случае,  у людей, путешествующих в одиночку, меньше шансов выжить, чем у людей с 1–3 детьми. \n* **Embarked** - Как ни странно, но похоже что у людей севших в Cherbourg (C) шанс выжить (около 55%) был больше чем у людей севших в двух других портах.\n* Большая часть людей погибла, выжили лишь около 39% людей.\n\n**Отдельно смотрим Age, так как чтобы увидеть там что-то внятное надо сначала преобразовать данные.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\n\n# Делим возраст (континуальная переменная) на категории\nbins = [-0.5, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['Age_Group'] = pd.cut(train[\"Age\"], bins, labels = labels)\ntest['Age_Group'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n# Рисуем график выживаемости по возрастным группам\nsns.barplot(x=\"Age_Group\", y=\"Survived\", data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Дети в возрасте до 5 лет имели наибольший шанс выжить, что ожидаемо, учитывая приказ [«Сначала женщины и дети»](https://en.wikipedia.org/wiki/Women_and_children_first)."},{"metadata":{},"cell_type":"markdown","source":"# 4. Удаление ненужных данных\nЗаполнив пробелы и изучив данные, смотрим что у нас осталось и удаляем колонки, которые нам не понадобятся в будущем."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Данные о номере билета вряд ли коррелируют с выживаемостью, поэтому удаляем.\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\n# ID пассажира в train тоже вряд ли коррелирует с выживаемостью, поэтому удаляем.\n# В test оставляем, так как ID'шники потом понадобятся нам в итогом файле который будем сабмитить.\ntrain = train.drop(['PassengerId'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Создание новых признаков\nПоскольку пока мои знания о ML оставляют желать лучшего, пришлось обратиться к [решению более опытного аналитика](https://www.kaggle.com/startupsci/titanic-data-science-solutions), чтобы узнать что делать дальше.\n\nИз вышеупомянутого решения понял, что для обучения модели и построения хорошего прогноза необходимо понимать тип проблемы и требования к ее решению.\nВ нашем случае это **проблема классификации и регрессии**, так как мы хотим определить взаимосвязь между выходными данными (выжил человек или нет) с другими переменными / признаками (пол, возраст, порт и т.д). Помимо этого, стоит упомянуть, что категория машинного обучения, реализуемая здесь, называется **\"Обучение с учителем\"**, поскольку мы обучаем нашу модель с заданным набором данных. Используя эти два критерия - контролируемое обучение плюс классификация и регрессия, мы можем выбрать наиболее подходящиее для этого модели (список опять же взят [здесь](https://www.kaggle.com/startupsci/titanic-data-science-solutions)):\n* Logistic Regression\n* KNN or k-Nearest Neighbors\n* Support Vector Machines\n* Naive Bayes classifier\n* Decision Tree\n* Random Forrest\n* Perceptron\n\nОднако, прежде чем обучать модели, необходимо преобразовать оставшиеся параметры в числовые значения, т.к. этого требует большинство алгоритмов моделей. \nТакже, помимо работы с существующими параметрами, в сопроводительном ролике к соревнованию, [советуют](https://www.youtube.com/watch?v=8yZMXCaFshs) поэксперементировать и попробовать задезайнить / создать свои параметры.\n\nКод для создания переменной Title был взят [здесь](https://www.kaggle.com/startupsci/titanic-data-science-solutions)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаем объединенную группу из обоих датасетов\ncombine = [train, test]\n\n# Достаем гоноратив из имен пассажиров в обоих датасетах и помещаем в отдельную колонку\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# Смотрим что вытащили и как оно распределилось в зависиости от пола\npd.crosstab(train['Title'], train['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Объединяем гоноративы в более крупные группы и смотрим у кого был больше шанс выжить\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False)\\\n                            .mean()\\\n                            .round(2)\\\n                            .sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Конвертируем текст в числа\ntitle_map = {\"Mrs\": 1, \"Miss\": 2, \"Master\": 3, \"Rare\": 4, \"Mr\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_map)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n# Удаляем параметр 'Имя', т.к. дальше он нам уже не понадобится.\ntrain = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)\n\n# Смотрим, что получилось\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Преобразоввание оставшихся признаков в числовые значения"},{"metadata":{},"cell_type":"markdown","source":"**Признак Age_Group**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Конвертируем возрастные группы из текста в числа\nage_map = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['Age_Group'] = train['Age_Group'].map(age_map)\ntest['Age_Group'] = test['Age_Group'].map(age_map)\n\n# Удаляем параметр 'Возраст', т.к. дальше он нам уже не понадобится.\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Признак Sex**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Конвертируем пол в бинарную переменную\nsex_map = {\"male\": 0, \"female\": 1}\ntrain['Sex'] = train['Sex'].map(sex_map)\ntest['Sex'] = test['Sex'].map(sex_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Признак Embarked**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Конвертируем порты в числовые значения\nembarked_map = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain['Embarked'] = train['Embarked'].map(embarked_map)\ntest['Embarked'] = test['Embarked'].map(embarked_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Признак Fare**\n\n\nОбъединим в группы по тому же принципу что и возраст. Определение интервалов отдадим pandas'у. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Fare_Group'] = pd.cut(train[\"Fare\"], 4)\ntrain[['Fare_Group','Survived']].groupby(['Fare_Group'], as_index=False)\\\n                                .mean()\\\n                                .sort_values(by='Fare_Group', ascending=True)\\\n                                .round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Присваиваем определенным выше интервалам номера от 1 до 4\nbins = [-1, 128.082, 256.165, 384.247, 512.330]\nlabels = [1, 2, 3, 4]\ntrain['Fare_Group'] = pd.cut(train[\"Fare\"], bins, labels = labels)\ntest['Fare_Group'] = pd.cut(test[\"Fare\"], bins, labels = labels)\n\n# Удаляем параметр 'Fare', т.к. дальше он нам уже не понадобится.\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Смотрим еще раз как выглядят данные**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Тестируем и выбираем модель\nСписок моделей с которыми мы определились ранее:\n* Logistic Regression\n* KNN or k-Nearest Neighbors\n* Support Vector Machines\n* Naive Bayes\n* Decision Tree\n* Random Forrest\n* Perceptron\n\nДатасет train мы разделим на две части (80% и 20%) и будем использовать меньшую, чтобы проверять точность моделей. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\npredictors = train.drop(\"Survived\", axis=1)\ntarget = train[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_val)\nacc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_logreg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN or k-Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_val)\nacc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machines\nfrom sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_val)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_svc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\ngaussian = GaussianNB()\ngaussian.fit(x_train, y_train)\ny_pred = gaussian.predict(x_val)\nacc_gaussian = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gaussian)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecisiontree = DecisionTreeClassifier()\ndecisiontree.fit(x_train, y_train)\ny_pred = decisiontree.predict(x_val)\nacc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_decisiontree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_val)\nacc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_randomforest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perceptron\nfrom sklearn.linear_model import Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(x_train, y_train)\ny_pred = perceptron.predict(x_val)\nacc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_perceptron)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сравнимаем результаты"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'KNN', 'Support Vector Machines', 'Gaussian Naive Bayes', 'Decision Tree', 'Random Forest', 'Perceptron'],\n    'Score': [acc_logreg, acc_knn, acc_svc, acc_gaussian, acc_decisiontree, acc_randomforest, acc_perceptron]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Загружаем лучший результат"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cоздаем переменные с ID пассажиров из test и предсказанной выживаемостью\nID = test['PassengerId']\npredictions = gaussian.predict(test.drop('PassengerId', axis=1))\n\n# В датафрейм output помещаем данные из созданных выше переменных и сохраняем в csv-файл\noutput = pd.DataFrame({'PassengerId' : ID, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Источники, изучение которых помогло лучше разобраться что как работает**\n* https://www.kaggle.com/startupsci/titanic-data-science-solutions\n* https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner/comments"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}