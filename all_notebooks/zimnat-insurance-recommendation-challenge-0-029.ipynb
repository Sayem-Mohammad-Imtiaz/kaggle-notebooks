{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport copy\nfrom catboost import CatBoostClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\n\n\nfrom itertools import  combinations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/zimnat-insurance-recommendation-challenge/Train.csv', parse_dates=['join_date'])\ntest = pd.read_csv('/kaggle/input/zimnat-insurance-recommendation-challenge/Test.csv', parse_dates=['join_date'])\nsubmission = pd.read_csv('/kaggle/input/zimnat-insurance-recommendation-challenge/SampleSubmission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Product_QTY'] = np.sum(train.iloc[:,8:], axis = 1)\ntest['Product_QTY'] = np.sum(test.iloc[:,8:], axis = 1)\n\ntest['Product_QTY'] = test['Product_QTY'].apply(lambda x: x+1)\n\n\ntrain['year'] = train['join_date'].apply(lambda x: x.year)\ntest['year'] = test['join_date'].apply(lambda x: x.year)\n\ntrain.drop(['join_date'], axis = 1, inplace = True)\ntest.drop(['join_date'], axis = 1, inplace = True)\n\ntrain.fillna(method = 'bfill', inplace = True)\ntest.fillna(method = 'bfill', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['ID', 'sex', 'marital_status', 'birth_year', 'branch_code', 'occupation_code', \n        'occupation_category_code','Product_QTY', 'year', 'P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR',\n        'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D',\n        'J9JW', 'GHYX', 'ECY3' ]\n\ntrain = train[cols].copy()\ntest = test[cols].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = []\nall_features = []\nX_train_columns = train.columns\nc = 0\nfor v in train.values:\n    info = v[:9]\n    binary = v[9:]\n    index = [k for k, i in enumerate(binary) if i == 1]\n    all_features.append(index)\n    for i in index:\n#         all_features.append(all_features)\n        c+=1\n        for k in range(len(binary)):\n            if k == i:\n                binary_transformed = list(copy.copy(binary))\n                binary_transformed[i] = 0\n                X_train.append(list(info) + binary_transformed + [X_train_columns[9+k]])\n\nX_train = pd.DataFrame(X_train)\nX_train.columns = ['ID', 'sex', 'marital_status', 'birth_year', 'branch_code', 'occupation_code', \n        'occupation_category_code','Product_QTY', 'year', 'P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR',\n        'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D',\n        'J9JW', 'GHYX', 'ECY3', 'label' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = X_train.pop('label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = []\ntrue_values = []\nc = 0\nfor v in test.values:\n    c += 1\n    info = v[:9]\n    binary = v[9:]\n    index = [k for k, i in enumerate(binary) if i == 1]\n    X_test.append(list(info) + list(binary))\n    for k in test.columns[9:][index]:\n        true_values.append(v[0] + ' X ' + k)\n\nX_test = pd.DataFrame(X_test)\nX_test.columns = ['ID', 'sex', 'marital_status', 'birth_year', 'branch_code', 'occupation_code', \n        'occupation_category_code','Product_QTY', 'year', 'P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR',\n        'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D',\n        'J9JW', 'GHYX', 'ECY3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train = []\nfeatures_test = []\ncolumns = []\n\nappend_features = ['ID','P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n'ECY3',  'Product_QTY', 'year','sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n'birth_year']\nfor v in append_features:\n    features_train.append(X_train[v].values.reshape(-1, 1))\n    features_test.append(X_test[v].values.reshape(-1, 1))\n    columns.append(np.array([v]))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train = np.concatenate(features_train, axis=1)\nfeatures_test = np.concatenate(features_test, axis=1)\ncolumns = np.concatenate(np.array(columns))\n\nX_train = pd.DataFrame(features_train)\nX_train.columns = columns\nX_test = pd.DataFrame(features_test)\nX_test.columns = columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nle = LabelEncoder()\ndata = X_train.append(X_test)\nfor v in X_train.select_dtypes('object').columns[1:]:\n    data.loc[:,v] = le.fit_transform(data.loc[:,v])\nX_train = data[:X_train.shape[0]]\nX_test = data[-X_test.shape[0]:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.fillna(0)\nX_test = X_test.fillna(0)\ny_train = y_train.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain = LabelEncoder()\ny_train = ytrain.fit_transform(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['sex', 'marital_status', 'birth_year', 'branch_code', 'occupation_code', 'occupation_category_code']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"1800\n1500\n1200\n1000\n800","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(CatBoostClassifier(random_state=17, num_trees=1800, max_depth = 3, cat_features = cat_features, task_type= 'GPU'))\nmodels.append(CatBoostClassifier(random_state=18, num_trees=1500, max_depth=5, cat_features = cat_features, task_type= 'GPU'))\nmodels.append(CatBoostClassifier(random_state=19, num_trees=1200, max_depth = 6, cat_features = cat_features, task_type= 'GPU'))\nmodels.append(CatBoostClassifier(random_state=20, num_trees=1000, max_depth=7, cat_features = cat_features, task_type= 'GPU'))\nmodels.append(CatBoostClassifier(random_state=21, num_trees=800, max_depth=8, cat_features = cat_features, task_type= 'GPU'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, random_state = 101,  shuffle = True)\n\nresult =pd.DataFrame()\nsubmission_cluster = pd.DataFrame()\n\nnew = 0\nfor fold, (train_idx, test_idx) in tqdm(enumerate(kf.split(X_train))):\n    train = X_train.loc[X_train.index[train_idx]].copy()\n    test =  y_train[train_idx].copy()\n    \n\n    for counter in tqdm(range(len(models))):\n        models[counter].fit(train.drop('ID', axis = 1), test, verbose = False)\n\n        proba = models[counter].predict_proba(X_test.drop('ID', axis = 1))\n        y_test = pd.DataFrame(proba)\n        y_test.columns = ytrain.inverse_transform(y_test.columns)\n\n\n        answer_mass = []\n        for i in range(X_test.shape[0]):\n            id = X_test['ID'].iloc[i]\n            for c in y_test.columns:\n                answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n\n\n        df_answer = pd.DataFrame(answer_mass)\n        df_answer.columns = ['ID X PCODE', 'Label']\n        \n#         print('goes to submission_cluster--',df_answer.shape)\n        \n\n        if new == 0:\n            submission_cluster = pd.concat([submission_cluster, df_answer])\n        else:\n            submission_cluster = pd.merge(submission_cluster, df_answer, on = 'ID X PCODE')\n\n\n        print('Fold--', fold, ' Counter--', counter, ' Score--', models[counter].best_score_ )    \n   \n#     result = pd.concat([result,submission_cluster])     \n    \n        new += 1\nprint('Sape of output--', submission_cluster.shape)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_cluster['Label'] = submission_cluster.iloc[:,1:].mean(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_cluster['Label'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_cluster['Label'] = submission_cluster['Label_'].apply(lambda x: 0 if x < 0.025 else x)\nsubmission_cluster = submission_cluster[['ID X PCODE', 'Label']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in tqdm(range(submission_cluster.shape[0])):\n    if submission_cluster['ID X PCODE'].iloc[i] in true_values:\n        submission_cluster['Label'].iloc[i] = 1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_cluster[['ID X PCODE', 'Label']].to_csv('SampleDabmission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}