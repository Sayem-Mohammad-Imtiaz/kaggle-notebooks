{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os, cv2\nimport numpy as np\nimport pandas as pd\nimport random, tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n!pip install -q -U segmentation-models-pytorch albumentations > /dev/null\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport albumentations as album\nimport segmentation_models_pytorch as smp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rootdir = \"../input/massachusetts-buildings-dataset/tiff/\"\nx_train_dir = os.path.join(rootdir, 'train')\ny_train_dir = os.path.join(rootdir, 'train_labels')\n\nx_valid_dir = os.path.join(rootdir, 'val')\ny_valid_dir = os.path.join(rootdir, 'val_labels')\n\nx_test_dir = os.path.join(rootdir, 'test')\ny_test_dir = os.path.join(rootdir, 'test_labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classlabeldict = pd.read_csv(\"../input/massachusetts-buildings-dataset/label_class_dict.csv\")\nclasnames = classlabeldict['name'].tolist()\nclass_rgb_values = classlabeldict[['r','g','b']].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"select_class_indices = [clasnames.index(cls.lower()) for cls in clasnames]\nselect_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n\nprint(select_class_rgb_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def displayimages(**images):\n    n_images = len(images)\n    plt.figure(figsize=(16,8))\n    for idx,(name,image) in enumerate(images.items()):\n        plt.subplot(1, n_images, idx + 1)\n        plt.xticks([]); \n        plt.yticks([])\n        plt.title(name.replace('_',' ').title(), fontsize=20)\n        plt.imshow(image)\n    plt.show()\n    \ndef onehotencode(label,labelvals):\n    semanticmap = []\n    for color in labelvals:\n        equality = np.equal(label,color)\n        classmap = np.all(equality,axis=-1)\n        semanticmap.append(classmap)\n    semanticmap = np.stack(semanticmap, axis=-1)\n    return semanticmap\n\ndef reverseonehot(image):\n    rev = np.argmax(image,axis=-1)\n    return rev\n\ndef color_code_segment(image,labelvals):\n    colorcodes = np.array(labelvals)\n    ccs = colorcodes[image.astype(int)]\n    return ccs\n\ndef training_augmentations():\n    transform = [    \n        album.RandomCrop(height=256, width=256, always_apply=True),\n        album.OneOf([album.HorizontalFlip(p=1),album.VerticalFlip(p=1),album.RandomRotate90(p=1)],p=0.75)]\n    return album.Compose(transform)\n\ndef validation_augmentations():   \n    transform = [album.PadIfNeeded(min_height=1536, min_width=1536, always_apply=True, border_mode=0)]\n    return album.Compose(transform)\n\ndef convert_to_tensor(x,**kwargs):\n    return x.transpose(2,0,1).astype(\"float32\")\n\ndef func_for_preprocessing(preprocessing_fn=None):\n    transform = []\n    if preprocessing_fn:\n        transform.append(album.Lambda(image=preprocessing_fn))\n    transform.append(album.Lambda(image=convert_to_tensor,mask=convert_to_tensor))\n    return album.Compose(transform)\n\ndef crop_image(image, target_image_dims=[1500,1500,3]):\n   \n    target_size = target_image_dims[0]\n    image_size = len(image)\n    padding = (image_size - target_size) // 2\n\n    return image[\n        padding:image_size - padding,\n        padding:image_size - padding,\n        :,]\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetCreation(torch.utils.data.Dataset):\n    def __init__(self,images_dir,masks_dir,class_rgb_vals=None, augment=None,preprocess=None):\n        self.imagespath = [os.path.join(images_dir,imageid) for imageid in sorted(os.listdir(images_dir))]\n        self.maskspath = [os.path.join(masks_dir,maskid) for maskid in sorted(os.listdir(masks_dir))]\n        self.class_rgb_vals = class_rgb_vals\n        self.augment = augment\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.imagespath)\n        \n    def __getitem__(self,i):\n        image = cv2.cvtColor(cv2.imread(self.imagespath[i]),cv2.COLOR_BGR2RGB)\n        mask = cv2.cvtColor(cv2.imread(self.maskspath[i]),cv2.COLOR_BGR2RGB)\n        mask = onehotencode(mask,self.class_rgb_vals).astype(\"float\")\n        if self.augment:\n            sample = self.augment(image=image, mask=mask)\n            image,mask = sample['image'],sample['mask']\n        if self.preprocess:\n            sample = self.preprocess(image=image,mask=mask)\n            image,mask = sample['image'],sample['mask']\n        return image,mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ORIGINAL IMAGES\n\ndataset = DatasetCreation(x_train_dir, y_train_dir, class_rgb_vals=select_class_rgb_values)\nrandom_idx = random.randint(0, len(dataset)-1)\nimage,mask = dataset[random_idx]\n\ndisplayimages(original_image=image,ground_truth_mask=color_code_segment(reverseonehot(mask),select_class_rgb_values),\n             onehot_encoded_image = reverseonehot(mask))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = \"resnet101\"\nencoder_weights = \"imagenet\"\nactivation = \"sigmoid\"\n\nmodel = smp.DeepLabV3Plus(encoder_name=encoder,encoder_weights=encoder_weights,\\\n                         classes=len(clasnames),activation=\"sigmoid\")\n\npreprocess_func = smp.encoders.get_preprocessing_fn(encoder,encoder_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = DatasetCreation(x_train_dir,y_train_dir,augment = training_augmentations(),\n                           preprocess = func_for_preprocessing(preprocess_func),\n                           class_rgb_vals = select_class_rgb_values)\n\nvaliddata = DatasetCreation(x_valid_dir,y_valid_dir,augment = validation_augmentations(),\n                           preprocess = func_for_preprocessing(preprocess_func),\n                           class_rgb_vals = select_class_rgb_values)\n\ntrainloader = DataLoader(traindata,batch_size=16,shuffle=True)\nvalidloader = DataLoader(validdata,batch_size=1,shuffle=False)\n\ntrainmodel = True\nepochs = 100\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nloss = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU(threshold=0.5)]\noptimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.0001)])\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2, eta_min=5e-5)\n\nif os.path.exists('./deeplabv3-using-pytorch/bestmodel.pth'):\n    model = torch.load('./deeplabv3using-pytorch/bestmodel.pth', map_location=device)\n\ntrainepoch = smp.utils.train.TrainEpoch(model,loss=loss,optimizer=optimizer,metrics=metrics,device=device,verbose=True)\nvalidepoch = smp.utils.train.ValidEpoch(model,loss=loss,metrics=metrics,device=device,verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if trainmodel:\n    best_iou_score = 0.0 \n    train_logs_list, valid_logs_list = [], []\n    for i in range(0,epochs):\n        print('\\nEpoch: {}'.format(i))\n        trainlogs = trainepoch.run(trainloader)\n        validlogs = validepoch.run(validloader)\n        train_logs_list.append(trainlogs)\n        valid_logs_list.append(validlogs)\n        if best_iou_score < validlogs['iou_score']:\n            best_iou_score = validlogs['iou_score']\n            torch.save(model, './best_model.pth')\n    print(\"Model Training completed successfully !\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if os.path.exists('./best_model.pth'):\n    best_model = torch.load('./best_model.pth', map_location=device)\n    print('Loaded DeepLabV3+ model from this run.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata = DatasetCreation(x_test_dir,y_test_dir,augment = validation_augmentations(),\n                           preprocess = func_for_preprocessing(preprocess_func),\n                           class_rgb_vals = select_class_rgb_values)\n\ntestloader = DataLoader(testdata)\n\ntestdata_without_preprocess = DatasetCreation(x_test_dir,y_test_dir,augment = validation_augmentations(),\n                           class_rgb_vals = select_class_rgb_values)\n\nrandom_idx = random.randint(0, len(testdata_without_preprocess)-1)\nimage, mask = testdata_without_preprocess[random_idx]\n\ndisplayimages(original_image=image,ground_truth_mask=color_code_segment(reverseonehot(mask),select_class_rgb_values),\n             onehot_encoded_image = reverseonehot(mask))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_preds_folder = 'sample_predictions/'\nif not os.path.exists(sample_preds_folder):\n    os.makedirs(sample_preds_folder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in range(len(testdata)):\n\n    image, gt_mask = testdata[idx]\n    image_vis = crop_image(testdata_without_preprocess[idx][0].astype('uint8'))\n    x_tensor = torch.from_numpy(image).to(device).unsqueeze(0)\n    # Predict test image\n    pred_mask = best_model(x_tensor)\n    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n    # Convert pred_mask from `CHW` format to `HWC` format\n    pred_mask = np.transpose(pred_mask,(1,2,0))\n    # Get prediction channel corresponding to building\n    pred_building_heatmap = pred_mask[:,:,clasnames.index('building')]\n    pred_mask = crop_image(color_code_segment(reverseonehot(pred_mask), select_class_rgb_values))\n    # Convert gt_mask from `CHW` format to `HWC` format\n    gt_mask = np.transpose(gt_mask,(1,2,0))\n    gt_mask = crop_image(color_code_segment(reverseonehot(gt_mask), select_class_rgb_values))\n#     cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n    \n    displayimages(\n        original_image = image_vis,\n        ground_truth_mask = gt_mask,\n        predicted_mask = pred_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testepoch = smp.utils.train.ValidEpoch(\n    model,\n    loss=loss, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)\n\nvalid_logs = testepoch.run(testloader)\nprint(\"Evaluation on Test Data: \")\nprint(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\nprint(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_logs_df = pd.DataFrame(train_logs_list)\nvalid_logs_df = pd.DataFrame(valid_logs_list)\ntrain_logs_df.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_logs_df.to_csv(\"trainlogs.csv\")\nvalid_logs_df.to_csv(\"validlogs.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(),'g-',lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(),'ro' ,lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('IoU Score', fontsize=20)\nplt.title('IoU Score Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.savefig('iou_score_plot.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(),'g-', lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(),'ro', lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('Dice Loss', fontsize=20)\nplt.title('Dice Loss Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.savefig('dice_loss_plot.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}