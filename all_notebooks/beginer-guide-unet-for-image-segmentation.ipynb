{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True \nsession = InteractiveSession(config=config)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport cv2 \nimport sys \nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd  \nfrom time import time \nimport matplotlib.pyplot as plt \nfrom tqdm import tqdm \nfrom itertools import chain \nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label \n\nimport tensorflow as tf \nfrom tensorflow.keras.layers import Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Activation, Add, multiply, add, concatenate, LeakyReLU, ZeroPadding2D, UpSampling2D, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras import backend as K \n\nfrom sklearn.metrics import classification_report, confusion_matrix\n%matplotlib inline \n\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nIMG_CHANNEL = 3\nIMG_PATH = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_images'\nMASK_PATH = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_masks'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42 \nrandom.seed = seed\nnp.random.seed = seed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_train_images.csv')\ntest_df = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_test_images.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_pneumo = train_df[train_df['has_pneumo'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Getting and Resizing Train Images, Train Mask, and Adding Label ...\\n\\n\")\n\n# Create X_train, Y_train, and Label\nX_train_seg = np.zeros((len(train_df_pneumo), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)\nY_train_seg = np.zeros((len(train_df_pneumo), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\nLabel_seg = np.zeros(len(train_df_pneumo), dtype=np.uint8)\n\nimg_data = list(train_df_pneumo.T.to_dict().values())\n\nfor i, data_row in tqdm(enumerate(img_data), total=len(img_data)):\n    \n    patientImage = data_row['new_filename']\n    imageLabel  = data_row['has_pneumo']\n\n    imagePath = os.path.join(IMG_PATH, patientImage)\n    lungImage = imread(imagePath)\n    lungImage = np.expand_dims(resize(lungImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n    \n    X_train_seg[i] = lungImage\n\n    Label_seg[i] = imageLabel\n\n    maskPath = os.path.join(MASK_PATH, patientImage)\n    maskImage = imread(maskPath)\n    maskImage = np.expand_dims(resize(maskImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n\n    Y_train_seg[i] = maskImage\n\nprint('\\n\\nProcess ... C O M P L E T E')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Illustrate the train images and masks\nplt.figure(figsize=(20, 16))\nx, y = 12, 4\nfor i in range(y):\n    for j in range(x):\n        plt.subplot(y*2, x, i*2*x+j+1)\n        pos = i*120 + j*10\n        plt.imshow(X_train_seg[pos], cmap=plt.cm.bone)\n        plt.title('Image #{}'.format(pos))\n        plt.axis('off')\n        plt.subplot(y*2, x, (i*2+1)*x+j+1)\n\n        plt.imshow(np.squeeze(Y_train_seg[pos]), cmap='gray_r')\n        plt.title('Mask #{}\\nLabel: {}'.format(pos, Label_seg[pos]))\n        plt.axis('off')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def iou_loss_score(y_pred, y_true, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n    iou = (intersection + smooth)/(union + smooth)\n    return iou\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return score\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\ndef bce_logdice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def UNetPlusPlus(num_class=1, deep_supervision=False):\n    nb_filter = [32, 64, 128, 256, 512]\n    img_rows = IMG_HEIGHT\n    img_cols = IMG_WIDTH\n    color_type = 3\n    bn_axis = 3\n\n    img_input = Input(shape=(img_rows, img_cols, color_type), name='main_input')\n\n    conv1_1 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(img_input)\n    conv1_1 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_1)\n    pool1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n\n    conv2_1 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(pool1)\n    conv2_1 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(conv2_1)\n    pool2 = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n\n    up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n    conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=bn_axis)\n    conv1_2 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_2)\n    conv1_2 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_2)\n\n    conv3_1 = Conv2D(nb_filter[2], (3, 3), activation='relu', padding='same')(pool2)\n    conv3_1 = Conv2D(nb_filter[2], (3, 3), activation='relu', padding='same')(conv3_1)\n    pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n\n    up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n    conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=bn_axis)\n    conv2_2 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(conv2_2)\n    conv2_2 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(conv2_2)\n\n    up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n    conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=bn_axis)\n    conv1_3 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_3)\n    conv1_3 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_3)\n\n    conv4_1 = Conv2D(nb_filter[3], (3, 3), activation='relu', padding='same')(pool3)\n    conv4_1 = Conv2D(nb_filter[3], (3, 3), activation='relu', padding='same')(conv4_1)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n\n    up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n    conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=bn_axis)\n    conv3_2 = Conv2D(nb_filter[2], (3, 3), activation='relu', padding='same')(conv3_2)\n    conv3_2 = Conv2D(nb_filter[2], (3, 3), activation='relu', padding='same')(conv3_2)\n\n    up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n    conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=bn_axis)\n    conv2_3 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(conv2_3)\n    conv2_3 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(conv2_3)\n\n    up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n    conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=bn_axis)\n    conv1_4 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_4)\n    conv1_4 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_4)\n\n    # conv5_1 = standard_unit(pool4, stage='51', nb_filter=nb_filter[4])\n    conv5_1 = Conv2D(nb_filter[4], (3, 3), activation='relu', padding='same')(pool4)\n    conv5_1 = Conv2D(nb_filter[4], (3, 3), activation='relu', padding='same')(conv5_1)\n\n    up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n    conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n    conv4_2 = Conv2D(nb_filter[3], (3, 3), activation='relu', padding='same')(conv4_2)\n    conv4_2 = Conv2D(nb_filter[3], (3, 3), activation='relu', padding='same')(conv4_2)\n\n    up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n    conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=bn_axis)\n    conv3_3 = Conv2D(nb_filter[2], (3, 3), activation='relu', padding='same')(conv3_3)\n    conv3_3 = Conv2D(nb_filter[2], (3, 3), activation='relu', padding='same')(conv3_3)\n\n    up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n    conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=bn_axis)\n    conv2_4 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(conv2_4)\n    conv2_4 = Conv2D(nb_filter[1], (3, 3), activation='relu', padding='same')(conv2_4)\n\n    up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n    conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=bn_axis)\n    conv1_5 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_5)\n    conv1_5 = Conv2D(nb_filter[0], (3, 3), activation='relu', padding='same')(conv1_5)\n\n    nestnet_output_1 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_2)\n    nestnet_output_2 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_3)\n    nestnet_output_3 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_3', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_4)\n    nestnet_output_4 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_4', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_5)\n\n    model = Model(inputs=img_input, outputs=[nestnet_output_4])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = UNetPlusPlus()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=Adam(learning_rate=1e-5),\n    loss='binary_crossentropy',\n    metrics=[bce_dice_loss, iou_loss_score]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduceLROnPlat = ReduceLROnPlateau(monitor='val_bce_dice_loss', factor=0.20, min_delta=1e-15 ,patience=3, \n                                   verbose=1, mode='auto')\n\ncallbacks = [reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nmodel.fit(X_train_seg, Y_train_seg, validation_split=0.1, batch_size=16, epochs=epochs, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The first 90% used for training\npred_train = model.predict(X_train_seg[:int(X_train_seg.shape[0]*0.9)].astype(np.float16), verbose=1)\n# The last 10% used for validation\npred_val = model.predict(X_train_seg[int(X_train_seg.shape[0]*0.9):].astype(np.float16), verbose=1)\n\n# pred_test = model.predict(X_test, verbose=1)\n\n# Thresholds prediction\npred_train_threshold = (pred_train > 0.4).astype(np.float16)\npred_val_threshold = (pred_val > 0.4).astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Showing our predicted masks on our training data\nix = random.randint(0, 682)\nplt.figure(figsize=(20, 28))\n\n# Our original training image\nplt.subplot(131)\nimshow(X_train_seg[ix])\nplt.title('Image')\n\n# Our original combined mask\nplt.subplot(132)\nimshow(np.squeeze(Y_train_seg[ix]), cmap='gray_r')\nplt.title('Mask')\n\n# The mask of our model U-Net prediction\nplt.subplot(133)\nimshow(np.squeeze(pred_train_threshold[ix] > 0.4), cmap='gray_r')\nplt.title('Prediction')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}