{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"<font size=\"10\" color=\"black\">Transformação de variáveis</font>\n\nEduardo Chaves Ferreira\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"## O que será tratado no curso\n\n- Escalonamento de variáveis\n\n- Transformação de variáveis\n\n- Correlação entre variáveis categóricas\n\n\n\n\n"},{"metadata":{"_uuid":"b89ace3ccc30394de0b5c6cfe3df4353822b30b3"},"cell_type":"markdown","source":"# 1- Importação de bibliotecas e funções gerais usadas no caderno"},{"metadata":{"_uuid":"f37277b0a0b0d139417f496eb641102f2d8c77a5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport random\nimport pandas as pd\nimport scipy.stats as stat\nimport seaborn as sns\nimport os\nimport pandas\nimport sklearn\n\nfrom IPython.display import Image\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.cluster import KMeans\n\n# Para ter repetibilidade nos resultados\nrandom_state = 1\n\n# Tratar valores infinitos como np.NaN\npandas.options.mode.use_inf_as_na = True\n\n# IMPORTANTE para tornar figuras interativas\n%matplotlib notebook\n\n# Tamanho padrão das figuras\nfigsize=(10,6)\n\n# Verificação do local para carga de dados\npath = os.environ['PATH']\n\nif path.startswith('C'):\n    IN_KAGGLE = False\nelse:\n    IN_KAGGLE = True\n    \n\n# Bibliotecas específicas do livro Introduction to Machine Learning with Python\n# https://github.com/amueller/introduction_to_ml_with_python\n# pip install mglearn\n\nimport mglearn\n\n\n# Configuração do número de linhas e colunas a serem apresentadas em listagens\npd.set_option('display.max_row', 1000)\n\npd.set_option('display.max_columns', 50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1fcbffb5dd4c49ffb0cbd6c87bdb3623b3a623a"},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9014ec6968dc5613ac6d28aae8d7afea7a24771"},"cell_type":"code","source":"# Função de conversão de dados copiada de https://github.com/shakedzy/dython/blob/master/dython/_private.py\n# Autor Shaked Zychlinski\n\ndef convert(data, to):\n    converted = None\n    if to == 'array':\n        if isinstance(data, np.ndarray):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values\n        elif isinstance(data, list):\n            converted = np.array(data)\n        elif isinstance(data, pd.DataFrame):\n            converted = data.as_matrix()\n    elif to == 'list':\n        if isinstance(data, list):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values.tolist()\n        elif isinstance(data, np.ndarray):\n            converted = data.tolist()\n    elif to == 'dataframe':\n        if isinstance(data, pd.DataFrame):\n            converted = data\n        elif isinstance(data, np.ndarray):\n            converted = pd.DataFrame(data)\n    else:\n        raise ValueError(\"Unknown data conversion: {}\".format(to))\n    if converted is None:\n        raise TypeError('cannot handle data conversion of type: {} to {}'.format(type(data),to))\n    else:\n        return converted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a3f09bce6c0d925ac7b1050023ce6291d3eb870"},"cell_type":"markdown","source":"## Treinamento de rede neural para regressão\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"},{"metadata":{"_uuid":"5eced01f10b015a9c1ec3a23447aaf196cb496a3","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\n\ndef redes_neurais_regressao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    #Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n        Y_escale = Y_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_escale, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPRegressor(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Rede - Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    mean_error = mean_absolute_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorNN.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorNN,r2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aff2949bdf0163433a74054dad0958d245a1c08e"},"cell_type":"markdown","source":"## Treinamento de rede neural para classificação\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"},{"metadata":{"_uuid":"5eced01f10b015a9c1ec3a23447aaf196cb496a3","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndef redes_neurais_classificacao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPClassifier(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Rede - Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    # TN FP\n    # FN TP\n    confusion = confusion_matrix(y_test, estimatorNN.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorNN.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorNN.predict(x_test)-y_test))/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorNN.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorNN,erro","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9992b33438f4c538e84a84bfd2e0f5205296da"},"cell_type":"markdown","source":"## Treinamento de árvore de decisão para regressão\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html"},{"metadata":{"_uuid":"07b481b67566137b174f98dfd739244708b06bb8","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndef arvore_regressao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeRegressor(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Árvore - Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    print('Importâncias {}'.format(estimatorTree.feature_importances_))\n    \n    mean_error = mean_absolute_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorTree.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorTree,r2\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9992b33438f4c538e84a84bfd2e0f5205296da"},"cell_type":"markdown","source":"## Treinamento de árvore de decisão para classificação\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/auto_examples/tree/plot_tree_Classifier.html"},{"metadata":{"_uuid":"07b481b67566137b174f98dfd739244708b06bb8","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndef arvore_classificacao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeClassifier(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Árvore - Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n\n    \n    \n    print('Importâncias {}'.format(estimatorTree.feature_importances_))\n    \n    confusion = confusion_matrix(y_test, estimatorTree.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorTree.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorTree.predict(x_test)-y_test))/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorTree.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorTree,erro\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9d0b6d33af5ef15943cdaeced9a80462aa70fd3"},"cell_type":"markdown","source":"# 2- Carga de dados\n\n\n"},{"metadata":{"_uuid":"bf6d83547c87e91c887dfd0d90feeebcc9994541"},"cell_type":"markdown","source":"## Dados de exemplo\n\nWorld happiness report (http://worldhappiness.report/).\n\nSomente variáveis numéricas"},{"metadata":{"_uuid":"a33e914fc27cbdb5d46cd13d4cf36ab031ae8c89","trusted":true},"cell_type":"code","source":"if IN_KAGGLE:\n    world_happiness = pd.read_csv(\"../input/world-happiness/2016.csv\")\nelse:\n    world_happiness = pd.read_csv(\"2016.csv\")\n\n# Conjunto completo\nworld_happiness = world_happiness.loc[:,['Country', 'Region', 'Happiness Rank', 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']]\n\n\n\n#world_happiness = shuffle(world_happiness).reset_index(drop=True)\n\n# Conjunto resumido para treinamento de modelos\nworld_happiness_resumido = world_happiness.loc[:,[ 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity']]\n\n# Cria variáveis para treinamento de modelos\n\ncolunas_fonte = [ \n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity'\n]\n\ncolunas_objetivo = [ \n       'Happiness Score'\n]\n\nworld_happiness_resumido_X = world_happiness_resumido.loc[:,colunas_fonte] \nworld_happiness_resumido_Y = world_happiness_resumido.loc[:,colunas_objetivo]\n\n\nworld_happiness.head(35)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"648bdf45822c79f5d3ea778738fa8f204a28abca"},"cell_type":"markdown","source":"## Carrega dados para exercício\n"},{"metadata":{"_uuid":"f19b485f7b6db74b6b9a046a57ef90b2f4a2eb72"},"cell_type":"markdown","source":"Data set de gorgetas com variáveis categóricas"},{"metadata":{"trusted":true,"_uuid":"18be13ca95dc229a6244ae0045fcad0f0c84f6ae"},"cell_type":"code","source":"if IN_KAGGLE:\n    tips = pd.read_csv('../input/snstips/tips.csv')\n    if 'Unnamed: 0' in tips.columns:\n        tips.drop(['Unnamed: 0'], inplace=True, axis=1)\nelse:\n    tips = sns.load_dataset('tips')\n\ntips.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a8aef273babfb3ab3f8366694517ea9f80dcca"},"cell_type":"markdown","source":"Dados sobre tumores (somente informações numéricas)\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"},{"metadata":{"_uuid":"fbd3fcbc4e5624d48f4c41e6bf16ce31a609158d","trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\n\ncancer = load_breast_cancer()\n\ncancer_data = cancer['data']\n# 1 benigno, 0 maligno\ncancer_target = cancer['target']\ncancer_target_names  = cancer['target_names']\ncancer_feature_names = cancer['feature_names']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"847b2f3ad98bfc2256612d5cacfd724bd290ff09"},"cell_type":"code","source":"cancer_data_DF = pd.DataFrame(cancer_data,columns=cancer_feature_names) \ncancer_data_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd7c3e30d711a5dcd04fd474c987484bf3acd9f8"},"cell_type":"code","source":"cancer_target_DF = pd.DataFrame(cancer_target,columns=['target']) \ncancer_target_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db173217cf53dd8decfe7cb94e786a8fe6b0f219"},"cell_type":"markdown","source":"# 5- Escalonamento de variáveis\n\nhttp://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler\n\nEscalonamento é uma forma de transformação de variáveis. O objetivo é:\n\n- Diminuir as diferenças existentes entre atributos por conta de diferenças de escala\n\n- Diminuir a influência de outliers\n\n\nEm ambos os casos a transformação é importante para visualização correta dos dados, cálculos estatísticos e para o correto funcionamento de algoritmos de mineração de dados.\n\nO escalonamento pode ser necessário quando variáveis são medidas em escalas diferentes ou quando as medidas, ainda que na mesma escala, tenham valores muito diferentes. Além disso, há algoritmos que somente aceitam entradas e saídas em determinadas faixas de valores."},{"metadata":{"trusted":true,"_uuid":"4240d7324e3ee303a86c29618fd1596d7273cafc"},"cell_type":"code","source":"np.random.seed(random_state)\n\n\nmu, sigma = 1, 1 \ns = np.random.normal(mu, sigma, 1000)\nruido = np.random.rand(1000)*100\ns_transformado = np.power(10+s*10, 2)+ruido\n\ndata_frame_exemplo = pd.DataFrame(data={'col1': s, 'col2': s_transformado, 'col3': s_transformado, 'grupo':[2]*1000})\n\ndata_frame_exemplo.loc[(data_frame_exemplo.col1<1)&(data_frame_exemplo.col2<500),'grupo'] = 1\ndata_frame_exemplo.loc[(data_frame_exemplo.col1>=0)&\n                       (data_frame_exemplo.col2>=500)&\n                       (data_frame_exemplo.col1<=2)&\n                       (data_frame_exemplo.col2<=1000),'grupo'] = 2\ndata_frame_exemplo.loc[(data_frame_exemplo.col1>2)&\n                       (data_frame_exemplo.col2>1000),'grupo'] = 3\n\n\ndata_frame_exemplo.iloc[0,:] = [-1.022201,23.687699,50000,1]\n\ndata_frame_exemplo.describe()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17bc0c94d5449116d282d82d364581fae94e73a8"},"cell_type":"code","source":"data_frame_exemplo.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06d307ba7f8fe6e8f362f3493f7e811b307f215f"},"cell_type":"code","source":"data_frame_exemplo.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f17cccd5d332dfafede641acff03410addf5d966"},"cell_type":"code","source":"\nf, ax = plt.subplots(figsize=figsize)\n_ = pd.plotting.scatter_matrix(data_frame_exemplo, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef5eebf60fecb33ed72313b3d8516e017db955cd"},"cell_type":"code","source":"data_frame_exemplo.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8aa8c0c66ef83bb95c2c659f2d9f37c64709793"},"cell_type":"code","source":"def analise(data_frame, col1, col2):\n    # Plota dados \n    fig = plt.figure(figsize=figsize)\n    plt.scatter(data_frame[col1], \n                data_frame[col2], \n                c=data_frame.grupo, \n                s=data_frame.grupo*100, \n                alpha=0.3,\n                       cmap='viridis')\n    plt.xlabel(col1)\n    plt.ylabel(col2)\n    plt.title('Col X Col')\n    plt.grid(True) \n    plt.show()\n    \n    # Classifica com rede neural\n    estimatorNN,erro = redes_neurais_classificacao(data_frame.loc[:,[col1,col2]],\n                                                   data_frame.loc[:,['grupo']],\n                                                   to_scale=False)\n    # Classificação Árvore\n    estimatorNN,erro = arvore_classificacao(data_frame.loc[:,[col1,col2]],\n                                                   data_frame.loc[:,['grupo']],\n                                                   to_scale=False)\n    # Clusteriza\n    y_pred = KMeans(n_clusters=3, random_state=random_state).fit_predict(data_frame.loc[:,[col1,col2]])\n    y_pred = y_pred+1\n    fig = plt.figure(figsize=figsize)\n    plt.scatter(data_frame[col1], \n                data_frame[col2], \n                c=y_pred, \n                s=y_pred*100, \n                alpha=0.3,\n                       cmap='viridis')\n    plt.xlabel(col1)\n    plt.ylabel(col2)\n    plt.title('Clusterização')\n    plt.grid(True) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"3c1c1a55fb46dbaf1d5e54deb8bdbe2ccac703d2"},"cell_type":"code","source":"analise(data_frame_exemplo,'col1','col2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"c49ed3a2a383d650054d73af3e1defc226f4c77e"},"cell_type":"code","source":"analise(data_frame_exemplo,'col1','col3')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f849cdc084427d84a4648eb97e60303605563a6"},"cell_type":"markdown","source":"## Standardization\n\nConverte média em zero e desvio padrão em um"},{"metadata":{"trusted":true,"_uuid":"85a32783b2286c02226a9522036ebdeddcc22cf6"},"cell_type":"code","source":"standard = preprocessing.StandardScaler()\ndata_frame_exemplo_scaled = standard.fit_transform(data_frame_exemplo.loc[:,['col1','col2','col3']])\ndata_frame_exemplo_scaled = pd.DataFrame(data=data_frame_exemplo_scaled, columns=['col1','col2','col3']) \ndata_frame_exemplo_scaled.loc[:,'grupo'] = data_frame_exemplo.grupo\ndata_frame_exemplo_scaled.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"937dee473580d8d6e98ead81c0f121be5e977a83"},"cell_type":"code","source":"data_frame_exemplo_scaled.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e1ab53fb086f77df8993a8edf335b83dbb0a67aa"},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e44cfcd0cff87caf0f60ed5e96a32f2d6f354c74"},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col3')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e63f17ca4557752d8c9559ff92ee836cbe7f79a8"},"cell_type":"markdown","source":"## MinMax\n\nEscalona valores para o intervalo [0, 1] ou outro passado como parâmetro"},{"metadata":{"trusted":true,"_uuid":"d19ea29c0a0235e43d5acec6f85e3df36eb9f844"},"cell_type":"code","source":"\nstandard = preprocessing.MinMaxScaler()\ndata_frame_exemplo_scaled = standard.fit_transform(data_frame_exemplo.loc[:,['col1','col2','col3']])\ndata_frame_exemplo_scaled = pd.DataFrame(data=data_frame_exemplo_scaled, columns=['col1','col2','col3']) \ndata_frame_exemplo_scaled.loc[:,'grupo'] = data_frame_exemplo.grupo\ndata_frame_exemplo_scaled.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04dae939e20eedf216537f18932851465d05b658"},"cell_type":"code","source":"data_frame_exemplo_scaled.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e802b5b24302adf2c928268a604932344a7e2bd4"},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"d32e5c169c4645c2ed30f6e479bbbaf771da2d10"},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col3')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12a39df792c387bdee007afc244cfd3bdd9cd792"},"cell_type":"markdown","source":"## Normalização\n\nVetores de mesmo tamanho"},{"metadata":{"trusted":true,"_uuid":"dcbd8306e8149f3d074804747d5c9ce5559e8b04"},"cell_type":"code","source":"\n\nstandard = preprocessing.Normalizer(norm='l2')\ndata_frame_exemplo_scaled = standard.fit_transform(data_frame_exemplo.loc[:,['col1','col2']])\ndata_frame_exemplo_scaled = pd.DataFrame(data=data_frame_exemplo_scaled, columns=['col1','col2']) \ndata_frame_exemplo_scaled.loc[:,'grupo'] = data_frame_exemplo.grupo\ndata_frame_exemplo_scaled.describe()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9009c47fe9007334d40e770416b8ec093d68cc69"},"cell_type":"code","source":"data_frame_exemplo_scaled.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d9139735d9846e56d923f6e39e943be57cedc9f"},"cell_type":"code","source":"data_frame_exemplo_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3956d15720ddc5fa1ea10dd56fc8e4fa8fd73fd0","scrolled":false},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92e80623f5e6acf5318e02023bbcfe037bb71be2"},"cell_type":"code","source":"\n\nstandard = preprocessing.Normalizer(norm='l2')\ndata_frame_exemplo_scaled = standard.fit_transform(data_frame_exemplo.loc[:,['col1','col3']])\ndata_frame_exemplo_scaled = pd.DataFrame(data=data_frame_exemplo_scaled, columns=['col1','col3']) \ndata_frame_exemplo_scaled.loc[:,'grupo'] = data_frame_exemplo.grupo\ndata_frame_exemplo_scaled.describe()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daedab7f94885711df3194d65fbca79e0eb0cfb4","scrolled":false},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col3')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba70e1f05edcab33a6dd80ef44e1855b38df38ac"},"cell_type":"markdown","source":"## Quantile"},{"metadata":{"trusted":true,"_uuid":"e9fc72192b4c91061bf67fb8b36f07a85cee799b"},"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\n\n\n\nstandard = QuantileTransformer(n_quantiles=10, random_state=random_state)\ndata_frame_exemplo_scaled = standard.fit_transform(data_frame_exemplo.loc[:,['col1','col2','col3']])\ndata_frame_exemplo_scaled = pd.DataFrame(data=data_frame_exemplo_scaled, columns=['col1','col2','col3']) \ndata_frame_exemplo_scaled.loc[:,'grupo'] = data_frame_exemplo.grupo\ndata_frame_exemplo_scaled.describe()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db5c0322459945ca73f32b9717eed75b36e9fca9"},"cell_type":"code","source":"data_frame_exemplo_scaled.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7d74acad36fdf694e30962620a0b82cbef9470fd"},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"d4989961e8f4f8cc7e32e05e640d0f0b6be8fdf0"},"cell_type":"code","source":"analise(data_frame_exemplo_scaled,'col1','col3')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0054f7808ae0fed5c64517caa2bc9c66ff66fa07"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nEscalone cancer_data (min_max) e refaça as seguintes análises:\n\n- Boxplot dos dados\n- Correlações (heatmap) entre dados numéricos de cancer_data\n- Para cancer_data gráfico de coordenadas paralelas (class_column = target)\n\nPergunta: o escalonamento influencia os valores de correlação?\n\n\nUsar redes neurais para classificar dados antes e depois do escalonamento\n\n"},{"metadata":{"trusted":true,"_uuid":"8a0deb36621db346951ea574dcf7fe8174b3cf11"},"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\ncancer_data_DF_scaled = min_max_scaler.fit_transform(cancer_data_DF)\ncancer_data_DF_scaled = pd.DataFrame(cancer_data_DF_scaled,columns=cancer_feature_names) \ncancer_data_DF_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f322b926096299e05a6526f3316764fddfa6276c"},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=figsize)\nf.suptitle('Cancer data', fontsize=14)\n\nsns.boxplot(data=cancer_data_DF_scaled,  ax=ax)\n#ax.set_xticklabels(cancer_data_DF.columns)\nax.set_xlabel(\"Atributos\",size = 12,alpha=0.8)\nax.set_ylabel(\"Valores\",size = 12,alpha=0.8)\nplt.xticks(rotation=60)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97c985e2d6d3d1667fb601d84846204b01894490","trusted":true},"cell_type":"code","source":"# Correlação entre dados\n\nf, ax = plt.subplots(figsize=figsize)\ncorr = pd.concat([cancer_data_DF_scaled, cancer_target_DF], axis=1).corr()\nhm = sns.heatmap(corr, annot=True, ax=ax, cmap=\"coolwarm\",fmt='.0f',\n                 linewidths=.05)\nf.subplots_adjust(bottom=0.3)\nt= f.suptitle('Correlação entre variáveis', fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db1edd3873289eec0a35f9df28e7e891bba98f34","trusted":true},"cell_type":"code","source":"from pandas.plotting import parallel_coordinates\nfig, ax = plt.subplots(1, 1, figsize=figsize)\n\nparallel_coordinates(frame=pd.concat([cancer_data_DF_scaled, cancer_target_DF], axis=1), \n                     class_column='target'\n                     , ax = ax, )\nplt.xticks(rotation=60)\nfig.subplots_adjust(bottom=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c20e2b79917b0a1e9087da58d4b811899d63b46"},"cell_type":"code","source":"pd.concat([cancer_data_DF, cancer_target_DF], axis=1).corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf6aef43904d9fb41dc2d048a43c46bf549cc984"},"cell_type":"code","source":"pd.concat([cancer_data_DF_scaled, cancer_target_DF], axis=1).corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8622d8e8a22491bd8a24060defd56a8d73f126d3"},"cell_type":"code","source":"estimatorNN,erro = redes_neurais_classificacao(cancer_data_DF,\n                                                   cancer_target_DF,\n                                                   to_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec52529c13accaf9e558bf5421929961a23775aa"},"cell_type":"code","source":"estimatorNN,erro = redes_neurais_classificacao(cancer_data_DF_scaled,\n                                                   cancer_target_DF,\n                                                   to_scale=False)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f711882d532105c9bb356ecc0fb5a2ca155df55"},"cell_type":"code","source":"estimatorNN,erro = arvore_classificacao(cancer_data_DF,\n                                                   cancer_target_DF,\n                                                   to_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a490a8b7300c3dd018f5ac404a8c6a255b8c8a61"},"cell_type":"code","source":"# Classificação Árvore\nestimatorNN,erro = arvore_classificacao(cancer_data_DF_scaled,\n                                                   cancer_target_DF,\n                                                   to_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bdf7866c4016679bef244e5c76545e03ae1f83a"},"cell_type":"markdown","source":"# 6- Transformação de variáveis\n\n"},{"metadata":{"trusted":true,"_uuid":"a88a70dd659b9e1235317b8f332315b2d02d3920"},"cell_type":"code","source":"if IN_KAGGLE:\n    tips = pd.read_csv('../input/snstips/tips.csv')\n    if 'Unnamed: 0' in tips.columns:\n        tips.drop(['Unnamed: 0'], inplace=True, axis=1)\nelse:\n    tips = sns.load_dataset('tips')\n\ntips.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c18fd6602e87c65f3dda7693303273fa54d0ee66"},"cell_type":"markdown","source":"## Label encoding"},{"metadata":{"trusted":true,"_uuid":"b49eea8922da7ec2229f7527eaa78b1747cc931f"},"cell_type":"code","source":"# Códigos de categorias são estabelecidos na ordem alfabética dos valores da coluna\n# Primeiro transformar a coluna em 'category'\n\ntips['sex'] = tips['sex'].astype('category')\ntips['sex_cat'] = tips['sex'].cat.codes\n\ntips.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fd447863ab498c14e97a7295fdc124baa64a892"},"cell_type":"markdown","source":"## Dummies"},{"metadata":{"trusted":true,"_uuid":"2c2e38ead5fb7c345b23b3c2acfb4fc538b39056"},"cell_type":"code","source":"# A coluna original é apagada\n# Usar colchetes na definição das colunas a serem codificadas\n\ntips = pd.get_dummies(tips, columns=['smoker'], prefix=['s'])\ntips.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1209a27aff5f8bb0241cf82fc48029f62e746b88"},"cell_type":"markdown","source":"## Categorização personalizada"},{"metadata":{"trusted":true,"_uuid":"ce74e6cab0d0e6bd2516bd70c6e1f300445e5293"},"cell_type":"code","source":"# as codificações não seguem a posição dos elementos das categorias, as numerações são atribuídas iniciando em 0 na medida em que os valores aparecem\n\nfrom pandas.api.types import CategoricalDtype\n\ncat_type = CategoricalDtype(categories=['Mon','Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],  ordered=True)\ntips['day'] = tips['day'].astype(cat_type)\ntips['day_cat'] =tips['day'].cat.codes\n\ntips.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2fcd6ccd5c882d5746a0f438572a3297a9ea9b3"},"cell_type":"markdown","source":"## Categorização personalizada"},{"metadata":{"trusted":true,"_uuid":"b29c51c8881b11393f49f3cb1bb505acd609b72b"},"cell_type":"code","source":"meals = {'breakfast': 1, 'Lunch' : 2, 'Dinner' : 3 }\ntips['time_cat'] = tips.time.replace(meals, inplace=False)\ntips['time_cat'] = tips.time_cat.astype('int')\ntips.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"acecbbb16622abb8c4dd7a1d043601121da308a6"},"cell_type":"markdown","source":"## Discretização"},{"metadata":{"trusted":true,"_uuid":"a7b6dff92404f384fafc11563159fc71c664c1ab"},"cell_type":"code","source":"#from sklearn.preprocessing import KBinsDiscretizer\n#enc = KBinsDiscretizer(n_bins=10, encode='ordinal')\n#X_binned = enc.fit_transform(tips.tip)\n#X_binned","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09c1d730b50a97487e8e4aa46cf337f697eb9709"},"cell_type":"code","source":"'''\nif IN_KAGGLE:\n    tips = pd.read_csv('../input/snstips/tips.csv')\n    if 'Unnamed: 0' in tips.columns:\n        tips.drop(['Unnamed: 0'], inplace=True, axis=1)\nelse:\n    tips = sns.load_dataset('tips')\n\ntips.head()\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"551d9a3f864b4fe6411952841aafde5d10c4a2a8"},"cell_type":"code","source":"from sklearn.preprocessing import Binarizer\nX_binned = preprocessing.Binarizer(threshold=1.1).fit_transform(tips.tip.values.reshape(-1, 1))\nX_binned[:5,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa8eeb0a65139d306df40a4b2d084a763025eaad"},"cell_type":"code","source":"tips['TOTAL_LOG'] = np.log(tips.total_bill)\ntips['TOTAL_LOG_INT']  = tips.TOTAL_LOG.astype(int, copy=False)\ntips.TOTAL_LOG_INT.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8eb141a2f457fb5ab68af3218c1c0a5a95c2344f"},"cell_type":"markdown","source":"## Análise de variáveis transformadas"},{"metadata":{"trusted":true,"_uuid":"cf6a5620f47333a0a7bf125b690eaa752472eaa5"},"cell_type":"code","source":"tips.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b41f6070e33a12e5578fa644329f14d0f770d0bb"},"cell_type":"code","source":"tips.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dd110588d41cac046e287fa04072a2ae92598b3"},"cell_type":"code","source":"#tips","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"487e378ae50eaedb7eebc9cc4d84a689be1b4673"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nCalcule os coeficientes de correlação para tips\n"},{"metadata":{"trusted":true,"_uuid":"6ad92903204cd426980c7e2baed283ee118b10f9"},"cell_type":"code","source":"tips.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0c64ab158e5ec3de5691ad32499614bb904d92d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42dc0d66fa4813984e56eaf7d724123d13d4ec0c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8e241c76378a36eedca71d5dcf6dac9c765c9b0"},"cell_type":"markdown","source":"# 7- Correlação entre variáveis categóricas\n\nhttps://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9"},{"metadata":{"trusted":true,"_uuid":"b04a8ae98bbf28443e7764706efe4d4243bb7f49"},"cell_type":"code","source":"from collections import Counter\n\ndef conditional_entropy(x, y):\n\n    \"\"\"\n\n    Calculates the conditional entropy of x given y: S(x|y)\n\n\n\n    Wikipedia: https://en.wikipedia.org/wiki/Conditional_entropy\n\n\n\n    :param x: list / NumPy ndarray / Pandas DataFrame\n\n        A sequence of measurements\n\n    :param y: list / NumPy ndarray / Pandas DataFrame\n\n        A sequence of measurements\n\n    :return: float\n\n    \"\"\"\n\n    # entropy of x given y\n\n    y_counter = Counter(y)\n\n    xy_counter = Counter(list(zip(x,y)))\n\n    total_occurrences = sum(y_counter.values())\n\n    entropy = 0.0\n\n    for xy in xy_counter.keys():\n\n        p_xy = xy_counter[xy] / total_occurrences\n\n        p_y = y_counter[xy[1]] / total_occurrences\n\n        entropy += p_xy * math.log(p_y/p_xy)\n\n    return entropy\n\ndef cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = stat.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n    rcorr = r-((r-1)**2)/(n-1)\n    kcorr = k-((k-1)**2)/(n-1)\n    return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n\ndef theils_u(x, y):\n\n    \"\"\"\n\n    Calculates Theil's U statistic (Uncertainty coefficient) for categorical-categorical association.\n\n    This is the uncertainty of x given y: value is on the range of [0,1] - where 0 means y provides no information about\n\n    x, and 1 means y provides full information about x.\n\n    This is an asymmetric coefficient: U(x,y) != U(y,x)\n\n\n\n    Wikipedia: https://en.wikipedia.org/wiki/Uncertainty_coefficient\n\n\n\n    :param x: list / NumPy ndarray / Pandas DataFrame\n\n        A sequence of categorical measurements\n\n    :param y: list / NumPy ndarray / Pandas DataFrame\n\n        A sequence of categorical measurements\n\n    :return: float\n\n        in the range of [0,1]\n\n    \"\"\"\n\n    s_xy = conditional_entropy(x,y)\n\n    x_counter = Counter(x)\n\n    total_occurrences = sum(x_counter.values())\n\n    p_x = list(map(lambda n: n/total_occurrences, x_counter.values()))\n\n    s_x = stat.entropy(p_x)\n\n    if s_x == 0:\n\n        return 1\n\n    else:\n\n        return (s_x - s_xy) / s_x\n    \ndef correlation_ratio(categories, measurements):\n\n    \"\"\"\n\n    Calculates the Correlation Ration (sometimes marked by the greek letter Eta) for categorical-continuous association.\n\n    Answers the question - given a continuous value of a measurement, is it possible to know which category is it\n\n    associated with?\n\n    Value is in the range [0,1], where 0 means a category cannot be determined by a continuous measurement, and 1 means\n\n    a category can be determined with absolute certainty.\n\n\n\n    Wikipedia: https://en.wikipedia.org/wiki/Correlation_ratio\n\n\n\n    :param categories: list / NumPy ndarray / Pandas DataFrame\n\n        A sequence of categorical measurements\n\n    :param measurements: list / NumPy ndarray / Pandas DataFrame\n\n        A sequence of continuous measurements\n\n    :return: float\n\n        in the range of [0,1]\n\n    \"\"\"\n\n    categories = convert(categories, 'array')\n\n    measurements = convert(measurements, 'array')\n\n    fcat, _ = pd.factorize(categories)\n\n    cat_num = np.max(fcat)+1\n\n    y_avg_array = np.zeros(cat_num)\n\n    n_array = np.zeros(cat_num)\n\n    for i in range(0,cat_num):\n\n        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n\n        n_array[i] = len(cat_measures)\n\n        y_avg_array[i] = np.average(cat_measures)\n\n    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n\n    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n\n    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n\n    if numerator == 0:\n\n        eta = 0.0\n\n    else:\n\n        eta = numerator/denominator\n\n    return eta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abd17ab635fcc3722bad5fa8af998c411aa35718"},"cell_type":"code","source":"if IN_KAGGLE:\n    tips = pd.read_csv('../input/snstips/tips.csv')\n    if 'Unnamed: 0' in tips.columns:\n        tips.drop(['Unnamed: 0'], inplace=True, axis=1)\nelse:\n    tips = sns.load_dataset('tips')\n\ntips.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae85afdb20244396310abf380864a94700471725"},"cell_type":"code","source":"conditional_entropy(tips.sex,tips.tip)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2947d5f9e9126d4a678344697e2347863d863536"},"cell_type":"code","source":"cramers_v(tips.sex,tips.tip)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2be61fb29f3b20eba32ddb525178a5c1832c6cfc"},"cell_type":"code","source":"theils_u(tips.sex,tips.day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f95cdf36cf034ec4027ba66e42d08dcd657c0d11"},"cell_type":"code","source":"#correlation_ratio(tips.sex,tips.day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31f881c1f95db7216dd1e81deb6fba3ee03d912f"},"cell_type":"code","source":"pd.crosstab(tips.sex,tips.day)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"060915bd6f225186dd76e68bdc3d3f95c69a50e3"},"cell_type":"markdown","source":"# Referências\n\nLivros usados como referência:\n\nIntroduction to Machine Learning with Python\n\nPython Data Science Handbook (https://www.oreilly.com/library/view/python-data-science/9781491912126/)\n\nVisualização:\n\nhttps://python-graph-gallery.com/\n\nhttp://www.apnorton.com/blog/2016/12/19/Visualizing-Multidimensional-Data-in-Python/\n\nhttps://towardsdatascience.com/the-art-of-effective-visualization-of-multi-dimensional-data-6c7202990c57\n\nhttps://www.oreilly.com/library/view/python-data-science/9781491912126/ch04.html\n\nhttps://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}