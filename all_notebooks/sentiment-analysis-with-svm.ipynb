{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Summary\n\nWe face the problem of predicting tweets sentiment. \nWe have coded the text as Bag of Words and applied an SVM model. We have built a pipeline to check different hyperparameters using cross-validation. At the end, we have obtained a good model which achieve an AUC of **0.92** ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data loading and cleaning","execution_count":null},{"metadata":{"_uuid":"db376733d0954ea531a81ee31675624c5968706f","_cell_guid":"d5db572f-3b58-42a5-979a-464769d52524","trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk.tokenize import TweetTokenizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, accuracy_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"data = pd.read_csv(\"../input/Tweets.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We take only the tweets we are very confident with. We use the BeautifulSoup library to process html encoding present in some tweets because scrapping.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data_clean = data.copy()\ndata_clean = data_clean[data_clean['airline_sentiment_confidence'] > 0.65]\ndata_clean['sentiment'] = data_clean['airline_sentiment'].\\\n    apply(lambda x: 1 if x=='negative' else 0)\n\ndata_clean['text_clean'] = data_clean['text'].apply(lambda x: BeautifulSoup(x, \"lxml\").text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to distinguish two cases: tweets with negative sentiment and tweets with non-negative sentiment","execution_count":null},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"data_clean['sentiment'] = data_clean['airline_sentiment'].apply(lambda x: 1 if x=='negative' else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_clean = data_clean.loc[:, ['text_clean', 'sentiment']]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"data_clean.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We split the data into training and testing set:","execution_count":null},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"train, test = train_test_split(data_clean, test_size=0.2, random_state=1)\nX_train = train['text_clean'].values\nX_test = test['text_clean'].values\ny_train = train['sentiment']\ny_test = test['sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def tokenize(text): \n    tknzr = TweetTokenizer()\n    return tknzr.tokenize(text)\n\ndef stem(doc):\n    return (stemmer.stem(w) for w in analyzer(doc))\n\nen_stopwords = set(stopwords.words(\"english\")) \n\nvectorizer = CountVectorizer(\n    analyzer = 'word',\n    tokenizer = tokenize,\n    lowercase = True,\n    ngram_range=(1, 1),\n    stop_words = en_stopwords)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to use cross validation and grid search to find good hyperparameters for our SVM model. We need to build a pipeline to don't get features from the validation folds when building each training model.","execution_count":null},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"np.random.seed(1)\n\npipeline_svm = make_pipeline(vectorizer, \n                            SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\n\ngrid_svm = GridSearchCV(pipeline_svm,\n                    param_grid = {'svc__C': [0.01, 0.1, 1]}, \n                    cv = kfolds,\n                    scoring=\"roc_auc\",\n                    verbose=1,   \n                    n_jobs=-1) \n\ngrid_svm.fit(X_train, y_train)\ngrid_svm.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.best_score_","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def report_results(model, X, y):\n    pred_proba = model.predict_proba(X)[:, 1]\n    pred = model.predict(X)        \n\n    auc = roc_auc_score(y, pred_proba)\n    acc = accuracy_score(y, pred)\n    f1 = f1_score(y, pred)\n    prec = precision_score(y, pred)\n    rec = recall_score(y, pred)\n    result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n    return result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how the model (with the best hyperparameters) works on the test data:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"report_results(grid_svm.best_estimator_, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def get_roc_curve(model, X, y):\n    pred_proba = model.predict_proba(X)[:, 1]\n    fpr, tpr, _ = roc_curve(y, pred_proba)\n    return fpr, tpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"roc_svm = get_roc_curve(grid_svm.best_estimator_, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fpr, tpr = roc_svm\nplt.figure(figsize=(14,8))\nplt.plot(fpr, tpr, color=\"red\")\nplt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Roc curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if our model has some bias or variance problem ploting its learning curve:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, test_scores = \\\n    learning_curve(grid_svm.best_estimator_, X_train, y_train, cv=5, n_jobs=-1, \n                   scoring=\"roc_auc\", train_sizes=np.linspace(.1, 1.0, 10), random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def plot_learning_curve(X, y, train_sizes, train_scores, test_scores, title='', ylim=None, figsize=(14,8)):\n\n    plt.figure(figsize=figsize)\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"lower right\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_learning_curve(X_train, y_train, train_sizes, \n                    train_scores, test_scores, ylim=(0.7, 1.01), figsize=(14,6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like there isn't a big bias or variance problem, but it is clear that our model would work better with more data:. if we can get more labeled data the model performance will increase.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Examples\n\nWe are going to apply the obtained machine learning model to some example text. If the output is **1** it means that the text has a negative sentiment associated:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.predict([\"flying with @united is always a great experience\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.predict([\"flying with @united is always a great experience. If you don't lose your luggage\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.predict([\"I love @united. Sorry, just kidding!\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.predict([\"@united very bad experience!\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.predict([\"@united very bad experience!\"])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}