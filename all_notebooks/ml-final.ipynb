{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ndataset = pd.read_csv('../input/heart-disease-uci/heart.csv')\nX = dataset.iloc[:,:-1].values\ny = dataset.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding Categorical Data\nfrom sklearn.preprocessing import OneHotEncoder\n#cp\noneHotEncoder = OneHotEncoder(categorical_features=[2], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#restecg\noneHotEncoder = OneHotEncoder(categorical_features=[8], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#slope\noneHotEncoder = OneHotEncoder(categorical_features=[13], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#ca\noneHotEncoder = OneHotEncoder(categorical_features=[15], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#thal\noneHotEncoder = OneHotEncoder(categorical_features=[19], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n\nfrom sklearn.preprocessing import StandardScaler\nscalerX = StandardScaler()\nX = scalerX.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Logistic Regression :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"K Nearest Neighbors :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Gaussian Naive Bayes :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier as DT\nclassifier = DT(criterion='entropy', random_state=0)\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Decision Tree Classifier :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier as RF\nclassifier = RF(n_estimators=10, criterion='entropy', random_state=0)\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Random Forest Classifier :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Artificial Neural Network\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n#Initialising ANN\nclassifier = Sequential()\n\n#Adding the first hidden layer or the input layer\nclassifier.add(Dense(activation='relu',\n                     kernel_initializer='uniform',\n                     input_dim=22,\n                     units=12))\n#Adding the second hidden layer\nclassifier.add(Dense(activation='relu',\n                     kernel_initializer='uniform',\n                     units=12))\n#Adding the output layer\nclassifier.add(Dense(activation='sigmoid',\n                     kernel_initializer='uniform',\n                     units=1))\n\n#Compiling the ANN\nclassifier.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])\nprint(classifier.summary())\n\n#Fitting the ANN\nhistory = classifier.fit(XTrain, yTrain, batch_size=3, epochs=20, verbose=1)\nfrom matplotlib import pyplot as plt\nplt.plot(history.history['accuracy'],'green')\nplt.plot(history.history['loss'],'red')\nplt.title('Model Accuracy-Loss')\nplt.xlabel('Epoch')\nplt.legend(['Accuracy','Loss'])\nplt.show()\n\n#Predicting the Test set Results\nyPred = classifier.predict(XTest)\nyPred = (yPred>0.5) #Since output is probability\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Artificial Neural Network Classifier :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}