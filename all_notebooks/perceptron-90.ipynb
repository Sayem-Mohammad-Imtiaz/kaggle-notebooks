{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random as rnd\nfrom numpy import append\nimport csv\nfrom string import punctuation, digits\nimport nltk\n\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstop = stopwords.words('english')\n\n\nwith open(\"../input/fake-and-real-news-dataset/True.csv\") as csvfile:\n    true = np.array(list(csv.DictReader(csvfile)))\n\n\nwith open(\"../input/fake-and-real-news-dataset/Fake.csv\") as csvfile:\n    false = np.array(list(csv.DictReader(csvfile)))\n\n\n\ntf = np.append(true , false)\n\nstop\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef extract_words(input_string):\n    \n    for c in punctuation + digits:\n        input_string = input_string.replace(c, ' ' + c + ' ')\n\n    return input_string.lower().split()\n\n\ndef bag_of_words(texts):\n    dictionary = {} \n    for text in texts:\n        word_list = extract_words(text)\n        for word in word_list:\n            if (word not in dictionary) and (word not in stop):\n                dictionary[word] = len(dictionary)\n    return dictionary\n\ndef extract_bow_feature_vectors(reviews, dictionary):\n    \"\"\"\n    Inputs a list of string reviews\n    Inputs the dictionary of words as given by bag_of_words\n    Returns the bag-of-words feature matrix representation of the data.\n    The returned matrix is of shape (n, m), where n is the number of reviews\n    and m the total number of entries in the dictionary.\n\n    Feel free to change this code as guided by Problem 9\n    \"\"\"\n\n    num_reviews = len(reviews)\n    feature_matrix = np.zeros([num_reviews, len(dictionary)])\n\n    for i, text in enumerate(reviews):\n        word_list = extract_words(text)\n        for word in word_list:\n            if word in dictionary:\n                feature_matrix[i, dictionary[word]] = 1\n    return feature_matrix\n\n\ntrain = []\nf = [1]\nw = []\ns = []\n\nfor i in range(len(tf)):\n    s.append(tf[i]['text'])\n\nfor i in range(50):\n    train.append(true[i]['text'])\n    w.append(1)\n    train.append(false[i]['text'])\n    w.append(-1)\n\n\nfor i in range(len(true)-1):\n    f.append([1])\n\nfor i in range(len(false)):\n    f.append([-1])\n\n\ndictionary = bag_of_words(train)\n\ntrain_vector = extract_bow_feature_vectors(train, dictionary)\n\ntest_vector = extract_bow_feature_vectors(s, dictionary)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perceptron_single_step_update(\n        feature_vector,\n        label,\n        current_theta,\n        current_theta_0):\n    \"\"\"\n    Properly updates the classification parameter, theta and theta_0, on a\n    single step of the perceptron algorithm.\n\n    Args:\n        feature_vector - A numpy array describing a single data point.\n        label - The correct classification of the feature vector.\n        current_theta - The current theta being used by the perceptron\n            algorithm before this update.\n        current_theta_0 - The current theta_0 being used by the perceptron\n            algorithm before this update.\n\n    Returns: A tuple where the first element is a numpy array with the value of\n    theta after the current update has completed and the second element is a\n    real valued number with the value of theta_0 after the current updated has\n    completed.\n    \"\"\"\n    if label * (np.dot(current_theta, feature_vector) + current_theta_0) <= 0:\n        current_theta += label * feature_vector\n        current_theta_0 += label\n    return (current_theta, current_theta_0)    \n\n\n#pragma: coderesponse template\ndef perceptron (feature_matrix, labels, T):\n    \"\"\"\n    Runs the full perceptron algorithm on a given set of data. Runs T\n    iterations through the data set, there is no need to worry about\n    stopping early.\n\n    Args:\n        feature_matrix -  A numpy matrix describing the given data. Each row\n            represents a single data point.\n        labels - A numpy array where the kth element of the array is the\n            correct classification of the kth row of the feature matrix.\n        T - An integer indicating how many times the perceptron algorithm\n            should iterate through the feature matrix.\n\n    Returns: A tuple where the first element is a numpy array with the value of\n    theta, the linear classification parameter, after T iterations through the\n    feature matrix and the second element is a real number with the value of\n    theta_0, the offset classification parameter, after T iterations through\n    the feature matrix.\n    \"\"\"\n\n    (nsamples, nfeatures) = feature_matrix.shape\n    theta = np.zeros(nfeatures)\n    theta_0 = 0.0    \n    for t in range(T):\n        for i in range(len(feature_matrix)):\n            theta, theta_0 = perceptron_single_step_update(\n                feature_matrix[i], labels[i], theta, theta_0)\n    return (theta, theta_0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef accuracy(preds, targets):\n \n    s = len(preds)\n    e = 0\n    for i in range(s):\n        if(preds[i] == targets[i]):\n            e+=1\n    return (e/s)*100\n\n\ndef classify(feature_matrix, theta, theta_0):\n    \"\"\"\n    A classification function that uses theta and theta_0 to classify a set of\n    data points.\n\n    Args:\n        feature_matrix - A numpy matrix describing the given data. Each row\n            represents a single data point.\n                theta - A numpy array describing the linear classifier.\n        theta - A numpy array describing the linear classifier.\n        theta_0 - A real valued number representing the offset parameter.\n\n    Returns: A numpy array of 1s and -1s where the kth element of the array is\n    the predicted classification of the kth row of the feature matrix using the\n    given theta and theta_0. If a prediction is GREATER THAN zero, it should\n    be considered a positive classification.\n    \"\"\" \n    (nsamples, nfeatures) = feature_matrix.shape\n    predictions = np.zeros(nsamples)\n    for i in range(nsamples):\n        feature_vector = feature_matrix[i]\n        prediction = np.dot(theta, feature_vector) + theta_0\n        if (prediction > 0):\n            predictions[i] = 1\n        else:\n            predictions[i] = -1\n    return predictions\n\n\ndef classifier_accuracy(\n        classifier,\n        train_feature_matrix,\n        val_feature_matrix,\n        train_labels,\n        val_labels,\n        T):\n    \"\"\"\n    Trains a linear classifier and computes accuracy.\n    The classifier is trained on the train data. The classifier's\n    accuracy on the train and validation data is then returned.\n\n    Args:\n        classifier - A classifier function that takes arguments\n            (feature matrix, labels, **kwargs) and returns (theta, theta_0)\n        train_feature_matrix - A numpy matrix describing the training\n            data. Each row represents a single data point.\n        val_feature_matrix - A numpy matrix describing the training\n            data. Each row represents a single data point.\n        train_labels - A numpy array where the kth element of the array\n            is the correct classification of the kth row of the training\n            feature matrix.\n        val_labels - A numpy array where the kth element of the array\n            is the correct classification of the kth row of the validation\n            feature matrix.\n        **kwargs - Additional named arguments to pass to the classifier\n            (e.g. T or L)\n\n    Returns: A tuple in which the first element is the (scalar) accuracy of the\n    trained classifier on the training data and the second element is the\n    accuracy of the trained classifier on the validation data.\n    \"\"\"\n    theta, theta_0 = classifier(train_feature_matrix, train_labels, T)\n    train_predictions = classify(train_feature_matrix, theta, theta_0)\n    val_predictions = classify(val_feature_matrix, theta, theta_0)\n    train_accuracy = accuracy(train_predictions, train_labels)\n    validation_accuracy = accuracy(val_predictions, val_labels)\n    return (train_accuracy, validation_accuracy)\n\n\ntr_ac , tf_ac = classifier_accuracy(perceptron,train_vector,test_vector,w,f,10) \nprint(tf_ac)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}