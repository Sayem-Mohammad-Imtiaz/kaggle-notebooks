{"cells":[{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"**Acknowledgements****\n\nPlease cite the following papers if you use this dataset:\n\nMoosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.\n\nMoosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. \"Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.\" In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019."},{"metadata":{},"cell_type":"markdown","source":"### Importing the libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing other Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data= pd.read_csv(\"/kaggle/input/us-accidents/US_Accidents_May19.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Data Pre-processing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding out the columns with null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are many columns that contain null values. We will deal with these null values later."},{"metadata":{},"cell_type":"markdown","source":"Finding the correlation between the variables with the help of a heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.gcf()\nfig.set_size_inches(20,20)\nfig=sns.heatmap(data.corr(),annot=True,linewidths=1,linecolor='k',square=True,mask=False, \n                vmin=-1, vmax=1,cbar_kws={\"orientation\": \"vertical\"},cbar=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Exploratory Data Analysis**"},{"metadata":{},"cell_type":"markdown","source":"Let us find out which state has the most number of accidents recorded. For this, we will find out the top 10 states that are prone to accidents."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig=plt.plot()\nclr = (\"blue\", \"green\", \"red\", \"orange\", \"purple\",'black','pink','gray','darkgreen','brown')\ndata.State.value_counts().sort_values(ascending=False)[:10].sort_values().plot(kind='barh',color=clr)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that **California is the most accident prone state** followed by Texas and Florida."},{"metadata":{},"cell_type":"markdown","source":"Let us take a look at the **weather conditions** when the accidents occured. We will cosider **Top 10 weather conditions ** for this analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax=plt.subplots()\ndata['Weather_Condition'].value_counts().sort_values(ascending=False).head(10).plot.bar(width=0.5,edgecolor='k',align='center')\nplt.xlabel('Weather_Condition')\nplt.ylabel('Number of Accidents')\nax.tick_params()\nplt.title('Top 10 Weather Condition for accidents')\nplt.ioff()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" It can be seen that **most accidents have occured when the weather was clear**. Thus, it can be inferred that people drive more carefully in severe weather conditions hence the probability of accidents is less as compared to that in a clear weather."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the date and time in the standard format.\ndata['time'] = pd.to_datetime(data.Start_Time, format='%Y-%m-%d %H:%M:%S')\ndata = data.set_index('time')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding an extra column as Day of the week to get the weekday name.\ndata['Start_Time'] = pd.to_datetime(data['Start_Time'], format=\"%Y/%m/%d %H:%M:%S\")\ndata['Day'] = data['Start_Time'].dt.weekday_name\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the graph \nfig, ax=plt.subplots()\ndata['Day'].value_counts().plot.bar(width=0.5,edgecolor='k',align='center')\nplt.xlabel('Day of the Week')\nplt.ylabel('Number of accidents')\nax.tick_params(labelsize=20)\nplt.title('Accidents per day')\nplt.ioff()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of accidents is more during the weekdays as compared to the weekends."},{"metadata":{},"cell_type":"markdown","source":"#### Feature Selection for the algorithms\nWe will select only a certain columns for the algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"features=['Source','TMC','Severity','Start_Lng','Start_Lat','Distance(mi)','Side','City','County',\n             'State','Timezone','Temperature(F)','Humidity(%)','Pressure(in)', 'Visibility(mi)',\n             'Wind_Direction','Weather_Condition','Amenity','Bump','Crossing','Give_Way','Junction',\n             'No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal',\n             'Turning_Loop','Sunrise_Sunset','Day']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data[features].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop the rows with the missing values in the selected features."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=df.columns[df.isnull().mean()!=0], how='any', axis=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us select the state of California for further analysis since it is the most accident prone state. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the state of California\nstate='CA'\ndf_state=df.loc[df.State==state].copy()\ndf_state.drop('State',axis=1, inplace=True)\ndf_state.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map of accidents, color code by county\n\nsns.scatterplot(x='Start_Lng', y='Start_Lat', data=df_state, hue='County', legend=False, s=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the state of California, we will select San Fransisco as the county."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select San Francisco as the county\ncounty='San Francisco'\ndf_county=df_state.loc[df_state.County==county].copy()\ndf_county.drop('County',axis=1, inplace=True)\ndf_county.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the data into train and test samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dealing with categorical variables\n#Categorical variables are converted into dummy indicator variables.\ndf_dummy = pd.get_dummies(df_county,drop_first=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target='Severity'\ny=df_dummy[target]\nx=df_dummy.drop(target,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting using the train-test split.\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1. Performing Logistic Regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"lreg=LogisticRegression(random_state=0)\nresult=lreg.fit(x_train,y_train)\nresult\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred1=lreg.predict(x_test)\nacc1=accuracy_score(y_test, y_pred1)\nacc1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Performing knn"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(x_train,y_train)\ny_pred2 = knn.predict(x_test)\n\n# Get the accuracy score\nacc2=accuracy_score(y_test, y_pred2)\nacc2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Decision Tree with Entropy"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndt = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n\n\n# Fit dt_entropy to the training set\ndt.fit(x_train, y_train)\n\n# Use dt_entropy to predict test set labels\ny_pred3= dt.predict(x_test)\n\n# Evaluate accuracy_entropy\nacc3 = accuracy_score(y_test, y_pred3)\nacc3\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Decision Tree with Gini index"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n\n\n# Fit dt_entropy to the training set\ndt_gini.fit(x_train, y_train)\n\n# Use dt_entropy to predict test set labels\ny_pred4= dt_gini.predict(x_test)\n\n# Evaluate accuracy_entropy\naccuracy_gini = accuracy_score(y_test, y_pred4)\naccuracy_gini","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"#### 5. Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nrfc=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nrfc.fit(x_train,y_train)\n\ny_pred5=rfc.predict(x_test)\n\n\n# Get the accuracy score\nacc5=accuracy_score(y_test, y_pred5)\n\nacc5\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Random Forest Classifier performs the best on this dataset with an accuracy of 92.54%\nSimilarly, we can build models for different states or counties using different feature sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}