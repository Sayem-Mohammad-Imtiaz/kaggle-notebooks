{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"05ca8cd4-b906-6def-6b43-533bb1b7ae40"},"source":"This notebook has functions and execution code to load users' data from the CSV files.\nIt also has examples of how to train a model to classify a single context-label based on input sensor-features and how to properly evaluate the performance of the model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45bb28c8-e617-c562-1cd8-636970bc43bc"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"2c41f837-9caf-e2e5-9fa2-1280cbcae4d1"},"source":"Functions to load users' data from the CSV files:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"415a961a-c1bb-d784-06cc-1da730148097"},"outputs":[],"source":"from io import StringIO;\nimport os;\nimport os.path;\n\ndef parse_header_of_csv(headline):\n    # Isolate the headline columns:\n#    headline = csv_str[:csv_str.index('\\n')];\n    columns = headline.split(',');\n\n    # The first column should be timestamp:\n    assert columns[0] == 'timestamp';\n    # The last column should be label_source:\n    assert columns[-1] == 'label_source';\n    \n    # Search for the column of the first label:\n    for (ci,col) in enumerate(columns):\n        if col.startswith('label:'):\n            first_label_ind = ci;\n            break;\n        pass;\n\n    # Feature columns come after timestamp and before the labels:\n    feature_names = columns[1:first_label_ind];\n    # Then come the labels, till the one-before-last column:\n    label_names = columns[first_label_ind:-1];\n    for (li,label) in enumerate(label_names):\n        # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n        assert label.startswith('label:');\n        label_names[li] = label.replace('label:','');\n        pass;\n    \n    return (feature_names,label_names);\n\ndef parse_body_of_csv(csv_str,n_features):\n    # Read the entire CSV body into a single numeric matrix:\n    full_table = np.loadtxt(StringIO(csv_str),delimiter=',');#,skiprows=1);\n    \n    # Timestamp is the primary key for the records (examples):\n    timestamps = full_table[:,0].astype(int);\n    \n    # Read the sensor features:\n    X = full_table[:,1:(n_features+1)];\n    \n    # Read the binary label values, and the 'missing label' indicators:\n    trinary_labels_mat = full_table[:,(n_features+1):-1]; # This should have values of either 0., 1. or NaN\n    M = np.isnan(trinary_labels_mat); # M is the missing label matrix\n    Y = np.where(M,0,trinary_labels_mat) > 0.; # Y is the label matrix\n    \n    return (X,Y,M,timestamps);\n\n'''\nInterpret the feature names to figure out for each feature what is the sensor it was extracted from.\n'''\ndef get_sensor_names_from_features(feature_names):\n    feat_sensor_names = np.array([None for feat in feature_names]);\n    for (fi,feat) in enumerate(feature_names):\n        if feat.startswith('raw_acc'):\n            feat_sensor_names[fi] = 'Acc';\n            pass;\n        elif feat.startswith('proc_gyro'):\n            feat_sensor_names[fi] = 'Gyro';\n            pass;\n        elif feat.startswith('raw_magnet'):\n            feat_sensor_names[fi] = 'Magnet';\n            pass;\n        elif feat.startswith('watch_acceleration'):\n            feat_sensor_names[fi] = 'WAcc';\n            pass;\n        elif feat.startswith('watch_heading'):\n            feat_sensor_names[fi] = 'Compass';\n            pass;\n        elif feat.startswith('location'):\n            feat_sensor_names[fi] = 'Loc';\n            pass;\n        elif feat.startswith('location_quick_features'):\n            feat_sensor_names[fi] = 'Loc';\n            pass;\n        elif feat.startswith('audio_naive'):\n            feat_sensor_names[fi] = 'Aud';\n            pass;\n        elif feat.startswith('audio_properties'):\n            feat_sensor_names[fi] = 'AP';\n            pass;\n        elif feat.startswith('discrete'):\n            feat_sensor_names[fi] = 'PS';\n            pass;\n        elif feat.startswith('lf_measurements'):\n            feat_sensor_names[fi] = 'LF';\n            pass;\n        else:\n            raise ValueError(\"!!! Unsupported feature name: %s\" % feat);\n\n        pass;\n\n    return feat_sensor_names;  \n\n'''\nRead the data (precomputed sensor-features and labels) for a user.\nThis function assumes the user's data file is present.\n'''\ndef read_user_data(uuid):\n    user_data_file = os.path.join('../input','%s.features_labels.csv' % uuid);\n\n    # Read the entire csv file of the user:\n    with open(user_data_file,'r') as fid:\n        csv_headline = fid.readline().strip();\n        csv_body = fid.read();\n        pass;\n\n    (feature_names,label_names) = parse_header_of_csv(csv_headline);\n    feat_sensor_names = get_sensor_names_from_features(feature_names);\n    n_features = len(feature_names);\n    (X,Y,M,timestamps) = parse_body_of_csv(csv_body,n_features);\n\n    return (X,Y,M,timestamps,feature_names,feat_sensor_names,label_names);\n\ndef validate_column_names_are_consistent(old_column_names,new_column_names):\n    if len(old_column_names) != len(new_column_names):\n        raise ValueError(\"!!! Inconsistent number of columns.\");\n        \n    for ci in range(len(old_column_names)):\n        if old_column_names[ci] != new_column_names[ci]:\n            raise ValueError(\"!!! Inconsistent column %d) %s != %s\" % (ci,old_column_names[ci],new_column_names[ci]));\n        pass;\n    return;\n\ndef read_multiple_users_data(uuids):\n    feature_names = None;\n    feat_sensor_names = None;\n    label_names = None;\n    X_parts = [];\n    Y_parts = [];\n    M_parts = [];\n    timestamps_parts = [];\n    uuid_inds_parts = [];\n    for (ui,uuid) in enumerate(uuids):\n        (X_i,Y_i,M_i,timestamps_i,feature_names_i,feat_sensor_names_i,label_names_i);\n        # Make sure the feature names are consistent among all users:\n        if feature_names is None:\n            feature_names = feature_names_i;\n            feat_sensor_names = feat_sensor_names_i;\n            pass;\n        else:\n            validate_column_names_are_consistent(feature_names,feature_names_i);\n            pass;\n        # Make sure the label names are consistent among all users:\n        if label_names is None:\n            label_names = label_names_i;\n            pass;\n        else:\n            validate_column_names_are_consistent(label_names,label_names_i);\n            pass;\n        # Accumulate this user's data:\n        X_parts.append(X_i);\n        Y_parts.append(Y_i);\n        M_parts.append(M_i);\n        timestamps_parts.append(timestamps_i);\n        uuid_inds_parts.append(ui*np.ones(len(timestamps_i)));\n        pass;\n    \n    # Combine all the users' data:\n    X = np.concatenate(tuple(X_parts),axis=0);\n    Y = np.concatenate(tuple(Y_parts),axis=0);\n    M = np.concatenate(tuple(M_parts),axis=0);\n    timestamps = np.concatenate(tuple(timestamps_parts),axis=0);\n    uuid_inds = np.concatenate(tuple(uuid_inds_parts),axis=0);\n    \n    return (X,Y,M,uuid_inds,timestamps,feature_names,feat_sensor_names,label_names);\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b22d0d1-e4b2-6e64-34a7-4b3da8b05beb"},"outputs":[],"source":"# Let's load data for the two users:\n(X1,Y1,M1,timestamps1,feature_names,feat_sensor_names,label_names) = read_user_data('user1');\n(X2,Y2,M2,timestamps2,feature_names2,feat_sensor_names2,label_names2) = read_user_data('user2');\n\n# The columns of all the users' files should be consistent,\n# but if you want to make sure, you can validate it:\nvalidate_column_names_are_consistent(feature_names,feature_names2);\nvalidate_column_names_are_consistent(label_names,label_names2);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca9f32c9-989a-3700-9b37-49fd90b505bf"},"outputs":[],"source":"print(\"User 1 has %d examples. User 2 has %d examples\" % (X1.shape[0],X2.shape[0]));\nprint(\"There are %d sensor-features from %d sensors in the data\" % (len(feature_names),len(set(feat_sensor_names))));\nprint(\"There is information about %d context-labels\" % len(label_names));"},{"cell_type":"markdown","metadata":{"_cell_guid":"c7f1bf7c-34fb-c435-007e-ab850e093b77"},"source":"Training a linear model to predict the context-labels from the sensor-features:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bcde873-927f-4a05-4905-c10cc360b505"},"outputs":[],"source":"import sklearn.linear_model;\n\ndef project_features_to_selected_sensors(X,feat_sensor_names,sensors_to_use):\n    use_feature = np.zeros(len(feat_sensor_names),dtype=bool);\n    for sensor in sensors_to_use:\n        is_from_sensor = (feat_sensor_names == sensor);\n        use_feature = np.logical_or(use_feature,is_from_sensor);\n        pass;\n    X = X[:,use_feature];\n    return X;\n\ndef estimate_standardization_params(X_train):\n    mean_vec = np.nanmean(X_train,axis=0);\n    std_vec = np.nanstd(X_train,axis=0);\n    return (mean_vec,std_vec);\n\ndef standardize_features(X,mean_vec,std_vec):\n    # Subtract the mean, to centralize all features around zero:\n    X_centralized = X - mean_vec.reshape((1,-1));\n    # Divide by the standard deviation, to get unit-variance for all features:\n    # * Avoid dividing by zero, in case some feature had estimate of zero variance\n    normalizers = np.where(std_vec > 0., std_vec, 1.).reshape((1,-1));\n    X_standard = X_centralized / normalizers;\n    return X_standard;\n\ndef train_model(X_train,Y_train,M_train,feat_sensor_names,label_names,sensors_to_use,target_label):\n    # Project the feature matrix to the features from the desired sensors:\n    X_train = project_features_to_selected_sensors(X_train,feat_sensor_names,sensors_to_use);\n    print(\"== Projected the features to %d features from the sensors: %s\" % (X_train.shape[1],', '.join(sensors_to_use)));\n\n    # It is recommended to standardize the features (subtract mean and divide by standard deviation),\n    # so that all their values will be roughly in the same range:\n    (mean_vec,std_vec) = estimate_standardization_params(X_train);\n    X_train = standardize_features(X_train,mean_vec,std_vec);\n    \n    # The single target label:\n    label_ind = label_names.index(target_label);\n    y = Y_train[:,label_ind];\n    missing_label = M_train[:,label_ind];\n    existing_label = np.logical_not(missing_label);\n    \n    # Select only the examples that are not missing the target label:\n    X_train = X_train[existing_label,:];\n    y = y[existing_label];\n    \n    # Also, there may be missing sensor-features (represented in the data as NaN).\n    # You can handle those by imputing a value of zero (since we standardized, this is equivalent to assuming average value).\n    # You can also further select examples - only those that have values for all the features.\n    # For this tutorial, let's use the simple heuristic of zero-imputation:\n    X_train[np.isnan(X_train)] = 0.;\n    \n    print(\"== Training with %d examples. For label '%s' we have %d positive and %d negative examples.\" % \\\n          (len(y),target_label,sum(y),sum(np.logical_not(y))) );\n    \n    # Now, we have the input features and the ground truth for the output label.\n    # We can train a logistic regression model.\n    \n    # Typically, the data is highly imbalanced, with many more negative examples;\n    # To avoid a trivial classifier (one that always declares 'no'), it is important to counter-balance the pos/neg classes:\n    lr_model = sklearn.linear_model.LogisticRegression(class_weight='balanced');\n    lr_model.fit(X_train,y);\n    \n    # Assemble all the parts of the model:\n    model = {\\\n            'sensors_to_use':sensors_to_use,\\\n            'target_label':target_label,\\\n            'mean_vec':mean_vec,\\\n            'std_vec':std_vec,\\\n            'lr_model':lr_model};\n    \n    return model;"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a36e454d-ed8d-877c-6245-e640822d6ed8"},"outputs":[],"source":"# Let's train a model to use the features from \n# the phone accelerometer (Acc) and the watch-accelerometer (WAcc)\n# to predict the label 'Walking':\nsensors_to_use = ['Acc','WAcc'];\ntarget_label = 'FIX_walking'; # this is just code name for the cleaned version of the label 'Walking'\nmodel = train_model(X1,Y1,M1,feat_sensor_names,label_names,sensors_to_use,target_label);"},{"cell_type":"markdown","metadata":{"_cell_guid":"80bd1cf6-aa7f-6167-e038-bf23c6c465df"},"source":"Testing the performance of the trained model:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"259da84e-7b20-c863-6079-c35677e673c6"},"outputs":[],"source":"%matplotlib inline\nimport matplotlib as mpl;\nimport matplotlib.pyplot as plt;\n\ndef test_model(X_test,Y_test,M_test,timestamps,feat_sensor_names,label_names,model):\n    # Project the feature matrix to the features from the sensors that the classifier is based on:\n    X_test = project_features_to_selected_sensors(X_test,feat_sensor_names,model['sensors_to_use']);\n    print(\"== Projected the features to %d features from the sensors: %s\" % (X_test.shape[1],', '.join(model['sensors_to_use'])));\n\n    # We should standardize the features the same way the train data was standardized:\n    X_test = standardize_features(X_test,model['mean_vec'],model['std_vec']);\n    \n    # The single target label:\n    label_ind = label_names.index(model['target_label']);\n    y = Y_test[:,label_ind];\n    missing_label = M_test[:,label_ind];\n    existing_label = np.logical_not(missing_label);\n    \n    # Select only the examples that are not missing the target label:\n    X_test = X_test[existing_label,:];\n    y = y[existing_label];\n    timestamps = timestamps[existing_label];\n\n    # Do the same treatment for missing features as done to the training data:\n    X_test[np.isnan(X_test)] = 0.;\n    \n    print(\"== Testing with %d examples. For label '%s' we have %d positive and %d negative examples.\" % \\\n          (len(y),model['target_label'],sum(y),sum(np.logical_not(y))) );\n    \n    # Preform the prediction:\n    y_pred = model['lr_model'].predict(X_test);\n    \n    # Naive accuracy (correct classification rate):\n    accuracy = np.mean(y_pred == y);\n    \n    # Count occorrences of true-positive, true-negative, false-positive, and false-negative:\n    tp = np.sum(np.logical_and(y_pred,y));\n    tn = np.sum(np.logical_and(np.logical_not(y_pred),np.logical_not(y)));\n    fp = np.sum(np.logical_and(y_pred,np.logical_not(y)));\n    fn = np.sum(np.logical_and(np.logical_not(y_pred),y));\n    \n    # Sensitivity (=recall=true positive rate) and Specificity (=true negative rate):\n    sensitivity = float(tp) / (tp+fn);\n    specificity = float(tn) / (tn+fp);\n    \n    # Balanced accuracy is a more fair replacement for the naive accuracy:\n    balanced_accuracy = (sensitivity + specificity) / 2.;\n    \n    # Precision:\n    # Beware from this metric, since it may be too sensitive to rare labels.\n    # In the ExtraSensory Dataset, there is large skew among the positive and negative classes,\n    # and for each label the pos/neg ratio is different.\n    # This can cause undesirable and misleading results when averaging precision across different labels.\n    precision = float(tp) / (tp+fp);\n    \n    print(\"-\"*10);\n    print('Accuracy*:         %.2f' % accuracy);\n    print('Sensitivity (TPR): %.2f' % sensitivity);\n    print('Specificity (TNR): %.2f' % specificity);\n    print('Balanced accuracy: %.2f' % balanced_accuracy);\n    print('Precision**:       %.2f' % precision);\n    print(\"-\"*10);\n    \n    print('* The accuracy metric is misleading - it is dominated by the negative examples (typically there are many more negatives).')\n    print('** Precision is very sensitive to rare labels. It can cause misleading results when averaging precision over different labels.')\n    \n    fig = plt.figure(figsize=(10,4),facecolor='white');\n    ax = plt.subplot(1,1,1);\n    ax.plot(timestamps[y],1.4*np.ones(sum(y)),'|g',markersize=10,label='ground truth');\n    ax.plot(timestamps[y_pred],np.ones(sum(y_pred)),'|b',markersize=10,label='prediction');\n    \n    seconds_in_day = (60*60*24);\n    tick_seconds = range(timestamps[0],timestamps[-1],seconds_in_day);\n    tick_labels = (np.array(tick_seconds - timestamps[0]).astype(float) / float(seconds_in_day)).astype(int);\n    \n    ax.set_ylim([0.5,5]);\n    ax.set_xticks(tick_seconds);\n    ax.set_xticklabels(tick_labels);\n    plt.xlabel('days of participation',fontsize=14);\n    ax.legend(loc='best');\n    plt.title('%s\\nGround truth vs. predicted' % model['target_label']);\n    \n    return;"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33ad7fa3-9f2c-c7a2-0da3-6c9a23be8744"},"outputs":[],"source":"# First, let's test the goodness-of-fit - how well the model fit to the training data (user1's data):\ntest_model(X1,Y1,M1,timestamps1,feat_sensor_names,label_names,model);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7a2dd0a-c7f1-54c5-51f8-4b3203b3feac"},"outputs":[],"source":"# Now, let's look at the more important evaluation - generalization.\n# Meaning, how well the model predicts the context for unseen people (test on user2):\ntest_model(X2,Y2,M2,timestamps2,feat_sensor_names,label_names,model);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"537bfd06-1d5b-88c6-7422-78b28b2d9d33"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}