{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Audio Sentiment Analysis\n\nThe aim of this challenge is to read the audio (.wav) files and classify them into 3 sentiments (Positive, Neutral, or Negative).\n\nSentiments:-\n- Positive\n- Negative\n- Neutral\n\nWe will be applying following Ensemble Algorithms:-\n\n- NN with Tensorflow\n\n# Reading & Understanding Data\n## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys, os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport random, os\nimport librosa, IPython\nimport librosa.display as lplt\nfrom skimage.io import imread\nseed = 12\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPath = '/kaggle/input/audio-speech-sentiment/TRAIN/'\ntestPath = '/kaggle/input/audio-speech-sentiment/TEST/'\ndf_base = pd.read_csv('/kaggle/input/audio-speech-sentiment/TRAIN.csv')\ndf_base.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### About the dataset"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(\"Dataset has\",df_base.shape[0],\"samples\")\nprint(\"Count of Positive and Negative samples\")\ndf_base['Class'].value_counts().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_rate = 44100\ndef loadAudio(fp):\n    return librosa.load(fp, res_type='kaiser_fast', duration=2.5, offset=0.5, sr=sample_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MelSpec -> Array"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scanFeatures(path, avgFeat=0):\n    features = []\n    minFeat = sys.maxsize\n    maxFeat = 0\n    files = sorted(os.listdir(path))\n    print(\"Scanning\", path)\n\n    for i, fp in enumerate(files):\n        X, sr = loadAudio(os.path.join(path, fp))\n\n        f = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n        f = librosa.amplitude_to_db(f, ref=np.max)\n\n        shapeY = f.shape[1]\n        if shapeY < minFeat:\n            minFeat = shapeY\n\n        if shapeY > maxFeat:\n            maxFeat = shapeY\n\n        features.append(f)\n    if avgFeat == 0:\n        avgFeat = int((minFeat+maxFeat)/2)\n    feat_mat = np.zeros((len(files), f.shape[0], avgFeat))\n    for i, x in enumerate(features):\n        xWidth = min(x.shape[1],avgFeat)\n        feat_mat[i, :, :xWidth] = x[:,:xWidth]\n    return feat_mat, files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_dim = 128\ntrain_data, train_files = scanFeatures(trainPath, f_dim)\ntest_data, test_files = scanFeatures(testPath, train_data.shape[1])\nprint(train_data.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MelSpec -> Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def saveImg(f, fp):\n    f = np.flip(f, axis=0)\n    plt.figure()\n    plt.axis('off')\n    plt.imsave(fp, f, format='png')\n    plt.clf()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def saveFeatureToImage(path, saveDir, avgFeat=0):\n    global sample_rate\n    files = sorted(os.listdir(path))\n    print(\"Scanning\", path)\n\n    for i, fp in enumerate(files):\n        X, sr = loadAudio(os.path.join(path, fp))\n\n        f = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n        f = librosa.amplitude_to_db(f, ref=np.max)\n\n        img = np.zeros((f.shape[0], avgFeat))\n        xWidth = min(f.shape[1],avgFeat)\n        img[:, :xWidth] = f[:,:xWidth]\n        fname = os.path.join(saveDir, fp.split('.')[0] + '.png')\n        saveImg(img, fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"f_dim = 128\ntrain_img_dir = './train_images'\ntest_img_dir = './test_images'\nif not os.path.exists(train_img_dir):\n    os.mkdir(train_img_dir)\n    saveFeatureToImage(trainPath, train_img_dir, f_dim)\nif not os.path.exists(test_img_dir):\n    os.mkdir(test_img_dir)\n    saveFeatureToImage(testPath, test_img_dir, train_data.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scanImgFeatures(path):\n    features = []\n    files = sorted(os.listdir(path))\n    for x in files:\n        fp = os.path.join(path, x)\n        img = imread(fp)[:,:,:3]/255.0\n        features.append(img)\n    return np.array(features), files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if os.path.exists(train_img_dir):\n    train_data_img, train_files_img = scanImgFeatures(train_img_dir)\nif os.path.exists(test_img_dir):\n    test_data_img, test_files_img = scanImgFeatures(test_img_dir)\n    plt.imshow(test_data_img[0])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getPathLabels(p):\n    return [df_base[df_base['Filename'] == x].iloc[0,1] for x in p]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = getPathLabels(train_files)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_fp = '/kaggle/input/audio-speech-sentiment/TRAIN/1.wav'\naudio_data, sr = loadAudio(audio_fp)\naudio_data, _ = librosa.effects.trim(audio_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# play sample file\nIPython.display.Audio(audio_data, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot sample file\nplt.figure(figsize=(15,5))\nlplt.waveplot(audio_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Default FFT window size\nn_fft = 2048 # window size\nhop_length = 512 # window hop length for STFT\n\nstft = librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length)\nstft_db = librosa.amplitude_to_db(stft, ref=np.max)\n\nplt.figure(figsize=(12,4))\nlplt.specshow(stft, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()\nplt.title(\"Spectrogram with amplitude\")\nplt.show()\n\nplt.figure(figsize=(12,4))\nlplt.specshow(stft_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\nplt.colorbar()\nplt.title(\"Spectrogram with decibel log\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"melspec = librosa.feature.melspectrogram(audio_data, sr=sample_rate)\nmelspec_db = librosa.amplitude_to_db(melspec, ref=np.max)\n\nplt.figure(figsize=(12,4))\nlplt.specshow(melspec, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()\nplt.title(\"Spectrogram with amplitude\")\nplt.show()\n\nplt.figure(figsize=(12,4))\nlplt.specshow(melspec_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\nplt.colorbar()\nplt.title(\"Spectrogram with decibel log\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation\n"},{"metadata":{},"cell_type":"markdown","source":"## Encode Genre Label"},{"metadata":{"trusted":true},"cell_type":"code","source":"# map labels to index\nlabel_index = dict()\nindex_label = dict()\nfor i, x in enumerate(df_base['Class'].unique()):\n    label_index[x] = i\n    index_label[i] = x\nprint(label_index)\nprint(index_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# update labels in df to index\ntrain_labels_idx = [label_index[l] for l in train_labels]\ntrain_labels_idx[::10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Train & Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# shuffle samples\ndf_shuffle = df_base.sample(frac=1, random_state=seed).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove irrelevant columns\ndf_shuffle.drop(['Filename'], axis=1, inplace=True)\ndf_y = df_shuffle.pop('Class')\n\n# split into train dev and test\ny_train, y_test = skms.train_test_split(df_y, train_size=0.8, random_state=seed, stratify=df_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train set has {y_train.shape[0]} records out of {len(df_shuffle)} which is {round(y_train.shape[0]/len(df_shuffle)*100)}%\")\nprint(f\"Test set has {y_test.shape[0]} records out of {len(df_shuffle)} which is {round(y_test.shape[0]/len(df_shuffle)*100)}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stratified split check\nprint(y_train.value_counts())\nprint(y_test.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide train_data into X_train and X_test\nX_train = train_data[y_train.index.tolist(), :, :]\nX_test = train_data[y_test.index.tolist(), :, :]\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide train_data_img into X_train_img and X_test_img\nX_train_img = train_data_img[y_train.index.tolist(), :, :]\nX_test_img = train_data_img[y_test.index.tolist(), :, :]\nX_test_img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.array([train_labels_idx[x] for x in y_train.index.tolist()])\ny_test = np.array([train_labels_idx[x] for x in y_test.index.tolist()])\ny_train[::10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scale the Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale features\nscaler = skp.MinMaxScaler()\nX_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\nX_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\ntest_data = scaler.transform(test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K\ntf.random.set_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bestModelPath = './best_model.hdf5'\nACCURACY_THRESHOLD = 0.98\n\nclass myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True\n\nacc_callback = myCallback()\n\n\ndef trainModel(model, epochs, optimizer, vb=1):\n    cbs = [#k.callbacks.ReduceLROnPlateau(patience=5, verbose=1), \n           k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)]\n    batch_size = 64\n    callback = myCallback()\n    model.compile(optimizer=optimizer,\n                  loss='sparse_categorical_crossentropy',\n                  metrics='accuracy'\n    )\n    return model.fit(X_train, y_train, \n#                      validation_data=(X_test, y_test), \n                     epochs=epochs, verbose=vb,\n                     validation_split=0.2,\n                     batch_size=batch_size, callbacks=cbs)\n\ndef plotHistory(history):\n    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model_1 = k.models.Sequential([\n    k.layers.Conv1D(256, 8, padding='same', activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n#     k.layers.Conv1D(256, 8, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.2),\n    k.layers.MaxPooling1D(pool_size=(8)),\n    k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n#     k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n#     k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.2),\n    k.layers.MaxPooling1D(pool_size=(5)),\n#     k.layers.Conv1D(64, 8, padding='same', activation='relu'),\n    k.layers.Conv1D(64, 8, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n#     k.layers.Dense(64, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n])\nprint(model_1.summary())\nmodel_1_history = trainModel(model=model_1, epochs=50, optimizer='adam', vb=0)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plotHistory(model_1_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model_2 = k.models.Sequential([\n    k.layers.Conv1D(256, 5, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.3),\n    k.layers.MaxPooling1D(pool_size=(2)),\n    k.layers.Conv1D(128, 3, activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.3),\n    k.layers.MaxPooling1D(pool_size=(3)),\n    k.layers.Conv1D(64, 3, activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n    k.layers.Dense(32, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n])\nprint(model_2.summary())\nmodel_2_history = trainModel(model=model_2, epochs=100, optimizer='adam', vb=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotHistory(model_2_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model_3 = k.models.Sequential([\n    k.layers.Bidirectional(k.layers.LSTM(256, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])),\n\n    k.layers.Bidirectional(k.layers.LSTM(128, return_sequences=False)),\n\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dropout(0.2),\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dropout(0.2),\n    k.layers.Dense(32, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n])\nprint(model_3.summary())\nmodel_3_history = trainModel(model=model_3, epochs=100, optimizer='rmsprop', vb=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotHistory(model_3_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make features 3D with last dim as 1 for 1DConv\nX_train = np.expand_dims(X_train, axis=3)\nX_test = np.expand_dims(X_test, axis=3)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model_4 = k.models.Sequential([\n    k.layers.Conv2D(256, (5,5), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.3),\n    k.layers.Conv2D(128, (3,3), activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.3),\n    k.layers.Conv2D(64, (3,3), padding='valid', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n\n])\nprint(model_4.summary())\nmodel_4_history = trainModel(model=model_4, epochs=50, optimizer='adam', vb=0)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plotHistory(model_4_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputShape = (X_train.shape[1], X_train.shape[2], 1)\nmodel_5 = k.models.Sequential([\n    k.layers.TimeDistributed(k.layers.Conv1D(256, 5), input_shape=inputShape),\n    k.layers.TimeDistributed(k.layers.BatchNormalization()),\n    k.layers.TimeDistributed(k.layers.MaxPooling1D((2))),\n    k.layers.TimeDistributed(k.layers.Dropout(0.3)),\n\n    k.layers.TimeDistributed(k.layers.Conv1D(128, 3), input_shape=inputShape),\n    k.layers.TimeDistributed(k.layers.BatchNormalization()),\n    k.layers.TimeDistributed(k.layers.MaxPooling1D((2))),\n    k.layers.TimeDistributed(k.layers.Dropout(0.3)),\n    k.layers.TimeDistributed(k.layers.Flatten())\n\n], name=\"conv_3d7\")\n\nmodel_5.add(k.layers.Bidirectional(k.layers.LSTM(256, return_sequences=True)))\nmodel_5.add(k.layers.Dropout(0.3))\n\nmodel_5.add(k.layers.Bidirectional(k.layers.LSTM(128)))\nmodel_5.add(k.layers.Dropout(0.3))\n\nmodel_5.add(k.layers.Dense(64, activation='relu'))\nmodel_5.add(k.layers.Dropout(0.3))\n\nmodel_5.add(k.layers.Dense(len(index_label), activation='softmax'))\n\nprint(model_5.summary())\nmodel_5_history = trainModel(model=model_5, epochs=100, optimizer='adam', vb=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotHistory(model_5_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model using Image Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelPath = './best_model.hdf5'\nACCURACY_THRESHOLD = 0.95\n\nclass myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True\n\nacc_callback = myCallback()\n\ncbs = [#k.callbacks.ReduceLROnPlateau(patience=3, verbose=1), \n       k.callbacks.ModelCheckpoint(filepath=modelPath, monitor='val_loss', verbose=1, save_best_only=True)]\n\ndef trainImgModel(model, epochs, optimizer, vb=1):\n    batch_size = 64\n    callback = myCallback()\n    model.compile(optimizer=optimizer,\n                  loss='sparse_categorical_crossentropy',\n                  metrics='accuracy'\n    )\n    return model.fit(X_train_img, y_train, \n                     validation_data=(X_test_img, y_test), epochs=epochs, verbose=vb,\n                     batch_size=batch_size, callbacks=cbs)\n\ndef plotHistory(history):\n    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model_6 = k.models.Sequential([\n    k.layers.Conv2D(256, 3, activation='relu', input_shape=(128, 128, 3)),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.2),\n    k.layers.Conv2D(128, 3, activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.2),\n    k.layers.Conv2D(64, 3, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n\n])\nprint(model_6.summary())\nmodel_6_history = trainImgModel(model=model_6, epochs=100, optimizer='rmsprop', vb=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotHistory(model_6_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test_img, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_data = np.expand_dims(test_data, axis=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.argmax(k.models.load_model(bestModelPath).predict(test_data_img), axis=1)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.DataFrame({\n    'Filename': test_files,\n    'Class': list(map(lambda x:index_label[x], predictions))\n})\ndf_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file = 'submission.csv'\ndf_sub.to_csv(submission_file, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}