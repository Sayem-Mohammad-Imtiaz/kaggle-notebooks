{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns\n\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"arabica_data = pd.read_csv('../input/coffee-quality-database-from-cqi/arabica_data_cleaned.csv')\narabica_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clustering\n### Reference(my notebook) : [Coffee_Clustering](https://www.kaggle.com/choihanbin/coffee-clustering)"},{"metadata":{"scrolled":false,"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"arabica_data_wet = arabica_data.loc[arabica_data['Processing.Method'] == 'Washed / Wet']\n\n# variety가 없는 경우 Other로 묶기\narabica_data_wet['Variety'] = arabica_data_wet['Variety'].fillna('Other')\n\narabica_data_wet['Coffee_Name'] = [arabica_data_wet['Country.of.Origin'].iloc[i] + '_' + arabica_data_wet['Variety'].iloc[i]\n                                     if arabica_data_wet['Variety'].iloc[i] != 'Other'\n                                     else arabica_data_wet['Country.of.Origin'].iloc[i]\n                                     for i in range(len(arabica_data_wet))]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"# Ordering\ntastes = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance']\nuniformity_sweetness = ['Uniformity', 'Sweetness']\n\n\nfor i in range(len(tastes)):\n    arabica_data_wet['{}_Rating'.format(tastes[i])] = 0\n\nfor i in range(len(arabica_data_wet)):\n    ratings = arabica_data_wet[tastes].iloc[i].sort_values(ascending = False).index\n    for rating in range(len(ratings)):\n        arabica_data_wet['{}_Rating'.format(ratings[rating])].iloc[i] = rating + 1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"### Ordering(순서를 매겨, 6 * 5 * 4 * 3 * 2 * 1의 컬럼개수만큼 만듦, 일단 데이터의 개수가 적어 해당 features는 만들지 않음.)\n\n\"\"\"arabica_data_wet['Ordering'] = 0\nOrdering = set()\n\nfeatures = tastes + uniformity_sweetnees + ['Ordering']\nfor column in arabica_data_wet.columns:\n    if column in features:\n        coffee[column] = arabica_data_wet[column]\n\"\"\"\n\n\"\"\"\n# categorical feature : 더미변수후 cluster_data와 합침\nOrder_dummies =  pd.concat((coffee['Coffee_Name'], pd.get_dummies(coffee['Ordering'])), axis = 1).groupby('Coffee_Name').max().reset_index()\ncluster_data = pd.concat((cluster_data, Order_dummies.drop(['Coffee_Name'], axis = 1)), axis = 1)\ncluster_data.shape\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"# numerical features : 커피 종류에 따른 mean value 추가\ncluster_data = pd.DataFrame({'Coffee_Name' : arabica_data_wet.groupby('Coffee_Name')['Aroma'].mean().index})\nratings = ['Aroma_Rating', 'Flavor_Rating', 'Aftertaste_Rating', 'Acidity_Rating', 'Body_Rating', 'Balance_Rating']\nfeatures = tastes + uniformity_sweetness + ratings\nfor column in features:\n    cluster_data[column] = arabica_data_wet.groupby('Coffee_Name')[column].mean().values\n    ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"# TSNE에는 정규화를 거치지 않은 X\nmodel = TSNE(n_components = 2, random_state = 0, perplexity = 50)\ntsne = model.fit_transform(cluster_data.drop(['Coffee_Name'], axis = 1).values)\n\n# PCA에는 정규화된 X\nstd = StandardScaler()\ns = std.fit_transform(cluster_data.drop(['Coffee_Name'], axis = 1))\n\npca = PCA(n_components = 7)\npca.fit(cluster_data.drop(['Coffee_Name'], axis = 1))\npc = pca.transform(cluster_data.drop(['Coffee_Name'], axis = 1))\nkmeans = KMeans(n_clusters = 35)\nkmeans.fit(pc)\n\nfr = pd.DataFrame({'tsne1' : tsne[:,0], 'tsne2' : tsne[:, 1], 'cluster' : kmeans.labels_})\n#sns.lmplot(data = fr, x = 'tsne1', y = 'tsne2', hue = 'cluster', fit_reg = False)\nprint(np.sum(pca.explained_variance_ratio_))\n\ncluster_data['Cluster'] = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Blending Classification by cluster."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Blending Classification by Cluster\n# Country : [Country1, Country2 ...]\n# Rate : [0.4, 0.2, ...] / {X1 + X2 + ... + Xn = 1}\n\ndef blending_clustering(Country, Rate, Variety = None):\n    blend = 0\n    for i in range(len(Country)):\n        if Variety == None:\n            blend += arabica_data_wet.loc[arabica_data_wet['Country.of.Origin'] == Country[i]][features].mean().apply(lambda x: x * Rate[i])\n        else:\n            if Variety[i] == None:\n                blend += arabica_data_wet.loc[arabica_data_wet['Country.of.Origin'] == Country[i]][features].mean().apply(lambda x: x * Rate[i])\n            else:\n                blend += arabica_data_wet.loc[arabica_data_wet['Coffee_Name'] == \"{}_{}\".format(Country[i], Variety[i])][features].mean().apply(lambda x: x * Rate[i])\n    blend = pd.DataFrame([blend])\n    \n    \n    # Modeling : DecistionTreeClassifier()\n    \n    model = DecisionTreeClassifier()\n    model.fit(cluster_data.drop(['Cluster', 'Coffee_Name'], axis = 1), kmeans.labels_)\n    print(blend)\n    model.predict(blend)\n    \n    print(\"\\n cluster는 '{}'입니다. \\n\".format(int(model.predict(blend))))\n    print(\"\\n 같은 cluster 안에 '{}'이 있습니다.\".format(list(cluster_data['Coffee_Name'].loc[cluster_data['Cluster'] == model.predict(blend)[0]])))\n    \n    return \n\n# Checking Country in this dataset.\ndef check_Country():\n    return set(arabica_data_wet['Country.of.Origin'])\n\n# Checking Variety in the Country\ndef check_Variety(Country):\n    return set(arabica_data_wet['Variety'].loc[arabica_data_wet['Country.of.Origin'] == Country].values)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"check_Country()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_Variety('Brazil')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Country = ['Costa Rica', 'Ethiopia', 'Colombia', 'Brazil']\nRate = [.25, .25, .25, .25]\nVariety = [None, 'Ethiopian Yirgacheffe', None, None]\nblending_clustering(Country, Rate, Variety)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary\n\n### blending\nAlthough these arithmetic mean can't be present for blending's tastes. When Checking the clusters, it's classification is not bad. However if I develop classification models in function of blending_clustering, like Logistick Regression, RandomForest or SVM and ensemble them, It could be more accurate. I will upgrade them."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}