{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv('/kaggle/input/moneyball-mlb-stats-19622012/baseball.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.subplots(figsize=(15,10))\nsns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_playoff=df.groupby('Playoffs')\ndf_playoff_0=df_playoff.get_group(0)\ndf_playoff_1=df_playoff.get_group(1)\n# Plotting scatterplotplt.\n#figure(figsize=(10,8))\nplt.scatter(x=df_playoff_0.W,y = df_playoff_0.RS,c=\"red\")\nplt.scatter(x=df_playoff_1.W,y = df_playoff_1.RS,c=\"blue\")\nplt.xlabel(\"Wins\")\nplt.ylabel(\"Runs Scored\")\nplt.axvline(x = 100)\nplt.axhline(y=800)\n## To enter into the playoff minimum of 100 wins is required.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_playoff=df.groupby('Playoffs')\ndf_playoff_0=df_playoff.get_group(0)\ndf_playoff_1=df_playoff.get_group(1)\n# Plotting scatterplotplt.\n#figure(figsize=(10,8))\nplt.scatter(x=df_playoff_0.W,y = df_playoff_0.RA,c=\"red\")\nplt.scatter(x=df_playoff_1.W,y = df_playoff_1.RA,c=\"blue\")\nplt.xlabel(\"Wins\")\nplt.ylabel(\"Runs Scored\")\nplt.axvline(x=100)\nplt.axhline(y=600)\n## To get a clear win runs allowed should be less than 600.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RA - Runs Allowed\n#RS - Runs Scored\n#OBP - On Base Percentage\n#SLG - Slugging Percentage\n#BA - Batting Average\n#OOBP - Opponent's OBP\n#OSLG - Opponent's SLG\n#W - No of wins in that season\n#Statistical Analysis Clip from Moneyball (2011)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Some columnns like Playoffs, RankSeason, RankPlayoffs information is available only after the game is over.\n## So dropping these columns.\ndf.drop(['Playoffs', 'RankSeason', 'RankPlayoffs'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## From the correlation matrix\n# The RS and RA are having inverse correaltion i.e if more runs allowed the chances of winning will be less.\n# Similarly OBP, SLG are highly correlated with W (wins).\n# Simarly OOBP,OSLG are negatively correlated with W, which states more and more run you allowed the chances of winning reduces.\n# RS is highly correlated with OBP,SLG.\n# RA is highly correlated with OOBP, OSLG.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We are replicating the year 2002, so only considering the year before 2002 to predict the win in 2002.\n## Replicate data before 2002\ndf1=df[df['Year']<2002].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['RD']=df1['RS']-df1['RA']\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_med=df1[['RS','RA','OBP','SLG','OOBP','OSLG','W']].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets check the ols summary.\nimport statsmodels.api as sm\n\ndf_med['OOBP'].fillna(value=df_med['OOBP'].median(),inplace=True)\ndf_med['OSLG'].fillna(value=df_med['OSLG'].median(),inplace=True)\nX=df_med[['RS','RA','OBP','SLG','OOBP','OSLG']]\nxc=sm.add_constant(X)\nY=df_med['W']\nmodel=sm.OLS(Y,xc).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Only RA, RS model pass the statistical test.\n## But due to high correlation between the dependent columns, it is better to work on different models than on one single model.\n## So one model will be RA=beta0+beta1*OOBP+beta2*OSLG\n## Second model will be RS=beta0+beta1*OBP+beta2*SLG.\n## and the wins will be predicted with the RD (Runs Difference)\n## The equation will be W=beta0+beta1*RD\n## Please note the beta values are different for every model.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Again looking for the correlation matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.subplots(figsize=(15,10))\nsns.heatmap(df_med.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## The new columns RD is highly correlated with the W column.\n# Now dropping all the other irrelevant columns.\ndf1.drop(['Team','League','Year'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Going for the linear test, so checking distribution of data.\nfor i in df1.columns:\n    df1.hist(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Here are the Oakland Athletics statistics in 2001 before the playoffs.\n\nThe production data is already given,therefore aim is not to bulid a model but to check how model perform.\n\nOBP: 0.339\n\nSLG: 0.430\n\nOOBP: 0.307\n\nOSLG: 0.373 Lets plug in these values into the above models to generate predictions.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Median Imputation model building.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_med.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting our variables from the dataframe.\nfrom sklearn.linear_model import LinearRegression\nx = df_med[['OBP','SLG']].values\ny = df_med[['RS']].values# Calling our model object.\nRS_model = LinearRegression()# Fitting the model.\nRS_model.fit(x,y)# Printing model intercept and coefficients.\nprint(RS_model.intercept_)\nprint(RS_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting our variables from the dataframe.\nx = df_med[['OOBP','OSLG']].values\ny = df_med[['RA']].values# Calling our model object.\nRA_model = LinearRegression()# Fitting the model.\nRA_model.fit(x,y)# Printing model intercept and coefficients.\nprint(RA_model.intercept_)\nprint(RA_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_med['RD']=df1['RD']\nx = df_med[['RD']].values\ny = df_med[['W']].values# Calling our model object.\nW_model = LinearRegression()# Fitting the model.\nW_model.fit(x,y)# Printing model intercept and coefficients.\nprint(W_model.intercept_)\nprint(W_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RS_model.predict([[0.339,0.430]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RA_model.predict([[0.307,0.373]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W_model.predict(RS_model.predict([[0.339,0.430]])-RA_model.predict([[0.307,0.373]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Dropping any null values\n#df_drop=df1.dropna()\ndf_drop.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_drop=df1.dropna()\nfrom sklearn.linear_model import LinearRegression\n# Extracting our variables from the dataframe.\nx = df_drop[['OBP','SLG']].values\ny = df_drop[['RS']].values# Calling our model object.\nRS_model = LinearRegression()# Fitting the model.\nRS_model.fit(x,y)\n# Printing model intercept and coefficients.\nprint(RS_model.intercept_)\nprint(RS_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting our variables from the dataframe.\nx = df_drop[['OOBP','OSLG']].values\ny = df_drop[['RA']].values# Calling our model object.\nRA_model = LinearRegression()# Fitting the model.\nRA_model.fit(x,y)# Printing model intercept and coefficients.\nprint(RA_model.intercept_)\nprint(RA_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx = df_drop[['RD']].values\ny = df_drop[['W']].values# Calling our model object.\nW_model = LinearRegression()# Fitting the model.\nW_model.fit(x,y)# Printing model intercept and coefficients.\nprint(W_model.intercept_)\nprint(W_model.coef_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for runs scored.\nRS_model.predict([[0.339,0.430]])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RA_model.predict([[0.307,0.373]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RS_model.predict([[0.339,0.430]])-RA_model.predict([[0.307,0.373]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W_model.predict([[179.11250606]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Applying KNN imputation Technique.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import KNNImputer\nImp=KNNImputer(n_neighbors=6)\ndf_knn=pd.DataFrame(Imp.fit_transform(df1),columns=df1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting our variables from the dataframe.\nx = df_knn[['OOBP','OSLG']].values\ny = df_knn[['RA']].values# Calling our model object.\nRA_model = LinearRegression()# Fitting the model.\nRA_model.fit(x,y)# Printing model intercept and coefficients.\nprint(RA_model.intercept_)\nprint(RA_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting our variables from the dataframe.\nx = df_knn[['OBP','SLG']].values\ny = df_knn[['RS']].values# Calling our model object.\nRS_model = LinearRegression()# Fitting the model.\nRS_model.fit(x,y)# Printing model intercept and coefficients.\nprint(RS_model.intercept_)\nprint(RS_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_knn[['RD']].values\ny = df_knn[['W']].values# Calling our model object.\nW_model = LinearRegression()# Fitting the model.\nW_model.fit(x,y)# Printing model intercept and coefficients.\nprint(W_model.intercept_)\nprint(W_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for runs scored.\nRS_model.predict([[0.339,0.430]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RA_model.predict([[0.307,0.373]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RS_model.predict([[0.339,0.430]])-RA_model.predict([[0.307,0.373]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W_model.predict([[299.45173576]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Applying Iterative Imputation\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\n# now you can import normally from sklearn.impute\nfrom sklearn.impute import IterativeImputer\nimp_mean = IterativeImputer(random_state=0)\ndf_it=pd.DataFrame(imp_mean.fit_transform(df1),columns=df1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting our variables from the dataframe.\nx = df_it[['OOBP','OSLG']].values\ny = df_it[['RA']].values# Calling our model object.\nRA_model = LinearRegression()# Fitting the model.\nRA_model.fit(x,y)# Printing model intercept and coefficients.\nprint(RA_model.intercept_)\nprint(RA_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting our variables from the dataframe.\nx = df_it[['OBP','SLG']].values\ny = df_it[['RS']].values# Calling our model object.\nRS_model = LinearRegression()# Fitting the model.\nRS_model.fit(x,y)# Printing model intercept and coefficients.\nprint(RS_model.intercept_)\nprint(RS_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_it[['RD']].values\ny = df_it[['W']].values# Calling our model object.\nW_model = LinearRegression()# Fitting the model.\nW_model.fit(x,y)# Printing model intercept and coefficients.\nprint(W_model.intercept_)\nprint(W_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for runs scored.\nRS_model.predict([[0.339,0.430]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RA_model.predict([[0.307,0.373]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W_model.predict(RS_model.predict([[0.339,0.430]])-RA_model.predict([[0.307,0.373]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Inference Iterative Imputer is providing much more accurate score than all other imputation methods.\n## The actual score was 103, so Iterative Imputer provides very near to that score.\n## Still the scope of non linear model is left out.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}