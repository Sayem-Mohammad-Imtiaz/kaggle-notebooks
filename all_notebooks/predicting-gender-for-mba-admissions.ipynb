{"cells":[{"metadata":{"_uuid":"1956dbbf-71c2-489c-a5f3-2a59b5931750","_cell_guid":"6866e003-41b6-4788-b13d-b285ed770fe0","trusted":true},"cell_type":"code","source":"import operator as op\nimport random\nrandom.seed(123)\n\nimport numpy as np \nimport pandas as pd \n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as skm\n\n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(rc={'figure.figsize':(12,8)})\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64d8dd69-d481-45ca-8cd6-d4c5ab8ca8c7","_cell_guid":"9dcad445-8f46-41b8-b7af-8927b6ccc68a","trusted":true},"cell_type":"code","source":"# Loading the data\ndf = pd.read_csv('/kaggle/input/others/MBA_ADMISSIONS.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e0124f8-b6c3-49c3-adc3-1407f3442c7a","_cell_guid":"1defe886-3103-438e-965a-b621401b00d0","trusted":true},"cell_type":"code","source":"# Encoding \ncat_vars = ['Gender','STATE', 'Previous_Degree','Marital_status',\n            'Place_you_belong_to', 'perceived#Job#Skill', 'Specialization']\nfor i in cat_vars:\n    df[i+\"_cat\"] = df[i].astype('category').cat.codes\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e4d04dc-3288-4335-b344-dacc125693f1","_cell_guid":"09b82001-e47c-4885-8bd3-0c6e23415161","trusted":true},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"_uuid":"1c8d47a2-4787-4557-826e-d5a457acd83a","_cell_guid":"e861de62-be28-4191-91cb-b2dfb3964def","trusted":true},"cell_type":"markdown","source":"## 1. What's the correlation between all of our variables?"},{"metadata":{"_uuid":"92848957-73d9-441b-aa7c-0ec50b069f38","_cell_guid":"1cb4887b-6396-4300-82c4-2bfd77829728","trusted":true},"cell_type":"code","source":"# Masking to show only one side of the matrix\ncorr = np.corrcoef(df.corr())                        \nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\n# Axtual Correlation matrix as a heatmap\nsns.heatmap(df.corr(), annot=True, mask=mask)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84f6c33c-a57d-44e5-a2d5-f2cfe32f966a","_cell_guid":"5fdf448e-7ee0-41c7-92f2-7d0ba280d247","trusted":true},"cell_type":"markdown","source":"## 2. What are the demographics of this  MBA class?"},{"metadata":{"_uuid":"731cd644-f7ec-495e-8adf-a2c46fdefc01","_cell_guid":"afa3db0c-6d23-4d8c-b41f-f5a4584a97f0","trusted":true},"cell_type":"code","source":"#Distribution of the target variable\nsns.histplot(data=df, x='Age_in_years', hue='Gender')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42c3174b-7247-41b6-9855-413f56facb41","_cell_guid":"6d1c988b-0681-480e-9747-56e64155ba9c","trusted":true},"cell_type":"markdown","source":"## 3. How do men and women differ in their MBA performance?"},{"metadata":{"_uuid":"f8db18d0-6594-4ace-95aa-4b577d84ccef","_cell_guid":"c86e39f2-098c-4c8f-a9cb-012a354c2912","trusted":true},"cell_type":"code","source":"# Distribution of all independent variables by Gender\nfig = plt.figure()\ngs = fig.add_gridspec(2, 3, hspace=0.4, wspace=0.3)\n(ax1, ax2, ax3), (ax4, ax5, ax6) = gs.subplots(sharex=False, sharey=False)\nfig.suptitle('Histograms for School Performance')\n\nsns.histplot(ax= ax1, data=df, x ='pre_score', hue='Gender', \n             bins=10, palette=[\"green\", \"red\"], stat='count')\nax1.set_title(\"Pre-Score\")\n\nsns.histplot(ax= ax2, data=df, x ='post_score', hue='Gender',  \n             bins=10, palette=[\"green\", \"red\"], stat='count')\nax2.set_title(\"Post-Score\")\n\nsns.histplot(ax= ax3, data=df, x ='Percentage_in_10_Class', hue='Gender',  \n             bins=10, palette=[\"green\", \"red\"], stat='count')\nax3.set_title(\"% in 10 classes\")\n\nsns.histplot(ax= ax4, data=df, x ='Percentage_in_12_Class', hue='Gender', \n             bins=10, palette=[\"green\", \"red\"], stat='count')\nax4.set_title(\"% in 12 classes\")\n\nsns.histplot(ax= ax5, data=df, x ='Percentage_in_Under_Graduate', hue='Gender',  \n             bins=10, palette=[\"green\", \"red\"], stat='count')\nax5.set_title(\"% in UndergGrad\")\n\nsns.histplot(ax= ax6, data=df, x ='percentage_MBA', hue='Gender',  \n             bins=10, palette=[\"green\", \"red\"], stat='count')\nax6.set_title(\"% in MBA\")\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9bb9d3a-7a73-4bb9-ad01-9cd8ac2eb275","_cell_guid":"6a9d3e4d-181d-4bfa-bc29-7b9d383ad066","trusted":true},"cell_type":"markdown","source":"## 4. Does undergrad grades predict future performance in MBA?"},{"metadata":{"_uuid":"5120127a-2e77-4e0e-b9fc-2f5ab8747a04","_cell_guid":"38b18a88-9b6a-4a23-b298-bd0f1f2600b9","trusted":true},"cell_type":"code","source":"# Scatterplots between % in Undergrad in key performance metrics by Genders\nfig = plt.figure()\ngs = fig.add_gridspec(3, 1, hspace=0.1, wspace=0.4)\n(ax1), (ax2), (ax3) = gs.subplots(sharex=True, sharey=False)\nfig.suptitle(\"Scatterplots with '% in Undergrad' as predictor and Gender as Category\")\nsns.scatterplot(ax=ax1, data=df, x='Percentage_in_Under_Graduate', y='pre_score', hue='Gender')\n\nsns.scatterplot(ax=ax2, data=df, x='Percentage_in_Under_Graduate', y='post_score', hue='Gender')\n\nsns.scatterplot(ax=ax3, data=df, x='Percentage_in_Under_Graduate', y='percentage_MBA', hue='Gender')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd4aa7fd-204b-4d2f-b2a7-f93171116702","_cell_guid":"0a1ef53f-ea10-4d41-b3da-aabc6e6460ec","trusted":true},"cell_type":"markdown","source":"## 5. Does maturity, denoted by age, impact performance in MBA?"},{"metadata":{"_uuid":"c7c7e9c3-ccad-42b2-8921-1a16ebecf8be","_cell_guid":"bc954ba2-9357-43c7-85d3-8e965f9759bf","trusted":true},"cell_type":"code","source":"# Barplots by Ages\nfig = plt.figure()\ngs = fig.add_gridspec(3, 1, hspace=0.05, wspace=0.4)\n(ax1), (ax2), (ax3) = gs.subplots(sharex=True, sharey=False)\nfig.suptitle(\"Scatterplots with '% in Undergrad' as predictor and Gender as Category\")\nsns.barplot(ax=ax1, data=df, x='Age_in_years', y='pre_score', hue='Gender')\n\nsns.barplot(ax=ax2, data=df, x='Age_in_years', y='post_score', hue='Gender')\n\nsns.barplot(ax=ax3, data=df, x='Age_in_years', y='percentage_MBA', hue='Gender')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d336a2f-7f0e-4155-a15e-bf8f634ffd7f","_cell_guid":"9cf09823-9909-422c-b623-435ac38a8389","trusted":true},"cell_type":"markdown","source":"## 6. How does MBA performance differ by marital status and location?"},{"metadata":{"_uuid":"da590824-dc7c-46f8-83ee-84e602fb5d0b","_cell_guid":"60ab4f4f-80b2-45e2-8ea6-872971805f11","trusted":true},"cell_type":"code","source":"# Barplots by Ages\nfig = plt.figure()\ngs = fig.add_gridspec(1, 2, hspace=0.4, wspace=0.1)\n(ax1, ax2) = gs.subplots(sharex=False, sharey=True)\n\nsns.violinplot(ax=ax1, data=df, x='Marital_status', y='post_score', \n               order=['Single', 'Married'], hue='Gender', split=True)\nax1.set_title(\"Post_score by Marital Status\")\n\nsns.violinplot(ax=ax2, data=df, x='Place_you_belong_to',y='post_score', \n               order=['Urban', 'Semi Urban', 'Rural'], hue='Gender', split=True)\nax2.set_title(\"Post_score by Location\")\nfor ax in fig.get_axes():\n    ax.label_outer()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30332e51-d4e8-484f-9caf-94584cde79d3","_cell_guid":"b255f8b5-eea5-4c82-b273-4ee456a06c17","trusted":true},"cell_type":"markdown","source":"## 7. Does a more technical undergrad background ensure MBA success?"},{"metadata":{"_uuid":"404d67bf-f2a2-42c2-8082-3a3d84096a2e","_cell_guid":"52763bbb-b4ec-438f-89ab-5406d26fff3d","trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, x=\"post_score\", y=\"Previous_Degree\", hue='Gender')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62ec45bd-e8f1-4dcc-bcdc-802c4dd6926a","_cell_guid":"cd12600b-2a99-4eaf-9470-54e392e9c1ae","trusted":true},"cell_type":"markdown","source":"# Model Building & Evaluation"},{"metadata":{"_uuid":"3d931ee5-c7ab-4500-b72f-d277ef7b1a35","_cell_guid":"7e2168bd-fb72-476b-9938-5a09d4ca4229","trusted":true},"cell_type":"code","source":"# Models for all categorical variables\nclass clf_models():\n    def __init__(self, iters=None):\n        self.iters = iters\n        \n    def fit(self, X_train, Y_train, X_test, Y_test):\n        self.X_train = X_train\n        self.Y_train = Y_train\n        self.X_test = X_test\n        self.Y_test = Y_test\n\n    def predict_knn(self):\n    \n        # Using Kbest to build kNN\n        kbest = self.elbow_method(self.iters)\n        model_knn = KNeighborsClassifier(n_neighbors=kbest)\n        model_knn.fit(self.X_train, self.Y_train)\n        pred_knn = model_knn.predict(self.X_test)\n        \n        return pred_knn\n    \n    def predict_nb(self):\n        # Naive Bayes\n        model_nb = GaussianNB()\n        model_nb.fit(self.X_train, self.Y_train)\n        pred_nb = model_nb.predict(self.X_test)\n    \n        return pred_nb\n    \n    def accuracy(self, Y_pred):\n        return skm.accuracy_score(self.Y_test, Y_pred)\n    \n    def elbow_method(self, iters):\n        # Elbow Method to find k-best\n        # May rewrite it using a while loop and a margin\n        errors = {}    \n        for i in range(1, iters):\n            model_i = KNeighborsClassifier(n_neighbors=i)\n            model_i.fit(self.X_train, self.Y_train)\n            pred_i = model_i.predict(self.X_test)\n            errors[i] = np.mean(pred_i != self.Y_test)\n        return min(errors.items(), key=op.itemgetter(1))[0]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing for the binary categories\ndef visualize(ax, var, Y_test, pred_knn, pred_NB):\n    # Benchmark for prediction of only 1s (only men)\n    bm_pred = [0 for _ in range(len(Y_test))]\n    bm_auc  = roc_auc_score(Y_test, bm_pred)\n    bm_fpr, bm_tpr, _ = roc_curve(Y_test, bm_pred)\n\n    knn_auc = roc_auc_score(Y_test, pred_knn)\n    NB_auc = roc_auc_score(Y_test, pred_NB)\n    knn_fpr, knn_tpr, _ = roc_curve(Y_test, pred_knn)\n    NB_fpr, NB_tpr, _ = roc_curve(Y_test, pred_NB)\n    \n    ax.plot(bm_fpr, bm_tpr, linestyle='--', label='Benchmark')\n    ax.plot(NB_fpr, NB_tpr, marker='.', label='Naive Bayes')\n    ax.plot(knn_fpr, knn_tpr, marker='.', label='kNN')\n    text = ': BM =%.2f, K-NN =%.2f, Naive Bayes =%.2f'\n    ax.set_title(var+text % (bm_auc,knn_auc, NB_auc))\n    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n    for ax in fig.get_axes():\n        ax.label_outer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    targets = ['Gender_cat', 'Marital_status_cat']\n    scores = {}\n    \n    vars, Y_tests, preds_knn, preds_nb = [], [], [], []\n    \n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2, hspace=0.5, wspace=0.3)\n    (ax1, ax2) = gs.subplots(sharex='all', sharey='all')\n    \n    for t in targets:\n        X = df.drop(cat_vars+[t], axis=1).values\n        Y = df[t].values\n\n        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n                                                            test_size = 0.2, \n                                                            random_state = 0)\n\n        model_knn = clf_models(iters=10)\n        model_knn.fit(X_train, Y_train, X_test, Y_test)\n        pred_knn = model_knn.predict_knn()\n        knn_acc = model_knn.accuracy(pred_knn)\n        \n        model_nb = clf_models(iters=None)\n        model_nb.fit(X_train, Y_train, X_test, Y_test)\n        pred_nb = model_nb.predict_nb()\n        nb_acc = model_nb.accuracy(pred_nb)\n        scores[t[:-4]] = [round(knn_acc, 4), round(nb_acc, 4)]\n        \n        vars.append(t[:-4])\n        Y_tests.append(Y_test)\n        preds_knn.append(pred_knn)\n        preds_nb.append(pred_nb) \n        \n    \n    ax1 = visualize(ax1, vars[0], Y_tests[0], preds_knn[0], preds_nb[0])\n    ax2 = visualize(ax2, vars[1], Y_tests[1], preds_knn[1], preds_nb[1])\n    for ax in fig.get_axes():\n        ax.label_outer()\n    \n    plt.legend()\n    plt.show()\n\n    scores_df = pd.DataFrame.from_dict(scores, orient='index', \n                                  columns = ['accuracy_knn', 'accuracy_nb'])\n    print(scores_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}