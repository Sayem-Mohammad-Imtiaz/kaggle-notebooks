{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install deep-pipe","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport os\nfrom pathlib import Path\nimport numpy as np\nimport glob\nfrom tqdm import tqdm\nimport nibabel\nfrom dpipe.io import load_numpy, save_numpy\nfrom dpipe.im.metrics import dice_score\n\nimport numpy as np\nimport pandas as pd\nfrom skimage.transform import rotate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_3x3(in_c, out_c):\n    return nn.Sequential(\n                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n                nn.ReLU(inplace=True)\n    )\n\ndef conv(in_c, out_c):\n    return nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n\nclass Unet(nn.Module):\n    def __init__(self, ):\n        super().__init__()\n        \n        self.max_pool2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.down_conv_1 = conv_3x3(1, 16)\n        self.down_conv_2 = conv_3x3(16, 32)\n        self.down_conv_3 = conv_3x3(32, 64)\n        self.down_conv_4 = conv_3x3(64, 128)\n        self.bottleneck_conv = conv_3x3(128, 128)\n        \n        self.upsample_1 = conv(128, 128)\n        self.up_conv_1 = conv_3x3(128, 64)\n        self.upsample_2 = conv(64, 64)\n        self.up_conv_2 = conv_3x3(64, 32)\n        self.upsample_3 = conv(32, 32)\n        self.up_conv_3 = conv_3x3(32, 16)\n        self.upsample_4 = conv(16, 16)\n        self.up_conv_4 = conv_3x3(16, 8)\n        \n        self.segm = nn.Sequential(\n            nn.Conv2d(8, 8, kernel_size=3, padding=1),\n            nn.Conv2d(8, 1, kernel_size=1)\n        )\n        \n        \n    def forward(self, x):\n        \n        # down/contracting\n        x1 = self.down_conv_1(x)\n        x2 = self.max_pool2x2(x1)\n        \n        x3 = self.down_conv_2(x2)\n        x4 = self.max_pool2x2(x3)\n        \n        x5 = self.down_conv_3(x4)\n        x6 = self.max_pool2x2(x5)\n        \n        x7 = self.down_conv_4(x6)\n        x8 = self.max_pool2x2(x7)\n        \n        x = self.bottleneck_conv(x8)\n        \n        # up/expansive\n        x = self.upsample_1(F.interpolate(x, x7.shape[2:], mode='bilinear', align_corners=False))\n        x = self.up_conv_1(x+x7)\n        \n        x = self.upsample_2(F.interpolate(x, x5.shape[2:], mode='bilinear', align_corners=False))\n        x = self.up_conv_2(x+x5)\n        \n        x = self.upsample_3(F.interpolate(x, x3.shape[2:], mode='bilinear', align_corners=False))\n        x = self.up_conv_3(x+x3)\n        \n        x = self.upsample_4(F.interpolate(x, x1.shape[2:], mode='bilinear', align_corners=False))\n        x = self.up_conv_4(x+x1)\n\n        # segm\n        x = self.segm(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef conv_3x3(in_c, out_c):\n    return nn.Sequential(\n                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n                nn.ReLU(inplace=True)\n    )\n\ndef conv(in_c, out_c):\n    return nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n\nclass UnetOld(nn.Module):\n    def __init__(self, ):\n        super().__init__()\n        \n        self.max_pool2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.down_conv_1 = conv_3x3(1, 16)\n        self.down_conv_2 = conv_3x3(16, 32)\n        self.down_conv_3 = conv_3x3(32, 64)\n        self.bottleneck_conv = conv_3x3(64, 64)\n        \n        self.upsample_1 = conv(64, 64)\n        self.up_conv_1 = conv_3x3(64, 32)\n        self.upsample_2 = conv(32, 32)\n        self.up_conv_2 = conv_3x3(32, 16)\n        self.upsample_3 = conv(16, 16)\n        self.up_conv_3 = conv_3x3(16, 8)\n        \n        self.segm = nn.Sequential(\n            nn.Conv2d(8, 8, kernel_size=3, padding=1),\n            nn.Conv2d(8, 1, kernel_size=1)\n        )\n        \n        \n    def forward(self, x):\n        \n        # down/contracting\n        x1 = self.down_conv_1(x)\n        x2 = self.max_pool2x2(x1)\n        \n        x3 = self.down_conv_2(x2)\n        x4 = self.max_pool2x2(x3)\n        \n        x5 = self.down_conv_3(x4)\n        x6 = self.max_pool2x2(x5)\n        \n        x = self.bottleneck_conv(x6)\n        \n        # up/expansive\n        x = self.upsample_1(F.interpolate(x, x5.shape[2:], mode='bilinear', align_corners=False))\n        x = self.up_conv_1(x+x5)\n        \n        x = self.upsample_2(F.interpolate(x, x3.shape[2:], mode='bilinear', align_corners=False))\n        x = self.up_conv_2(x+x3)\n        \n        x = self.upsample_3(F.interpolate(x, x1.shape[2:], mode='bilinear', align_corners=False))\n        x = self.up_conv_3(x+x1)\n\n        # segm\n        x = self.segm(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DataFrame Creator"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_folder = Path('/kaggle/input/brats-slices/brats_slices')\ndf = []\n\nfor path, _, files in tqdm(os.walk(data_folder)):\n    for file in files:\n        \n        subject_id = path.split('/')[-1].split('_')[-1]\n        slice_id = file.split('.')[0].split('_')[0]\n        sample_id = f\"{subject_id}_{slice_id}\" # SubjectID_SliceIndex\n        is_mask = 'mask' in file\n        if is_mask:\n            mask = np.load(Path(path) / file, allow_pickle=True)\n            is_nonzero_mask =  np.any(mask)\n        else:\n            is_nonzero_mask = np.nan\n        \n        df.append([Path(Path(path).stem) / file, sample_id, is_mask, subject_id, is_nonzero_mask])\n        \ndf = pd.DataFrame(df, columns = ['relative_path', 'sample_id', 'is_mask', 'subject_id', 'is_nonzero_mask'])\nprint(df.is_nonzero_mask.value_counts())\n\ndf.to_csv('./meta.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BraTSDataset(Dataset):\n    def __init__(self, meta: pd.DataFrame, source_folder: [str, Path], nonzero_mask=False, transform=None):\n        if isinstance(source_folder, str):\n            source_folder = Path(source_folder)\n            \n        if nonzero_mask:\n            meta = meta[meta.sample_id.isin(meta.query('is_nonzero_mask == True').sample_id)]\n            \n        self.source_folder = source_folder\n        self.meta_images = meta.query('is_mask == False').sort_values(by='sample_id').reset_index(drop=True)\n        self.meta_masks = meta.query('is_mask == True').sort_values(by='sample_id').reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return self.meta_images.shape[0]\n\n    def __getitem__(self, i):\n        image = np.load(self.source_folder / self.meta_images.iloc[i]['relative_path'], allow_pickle=True)\n        mask = np.load(self.source_folder / self.meta_masks.iloc[i]['relative_path'], allow_pickle=True)\n        sample = image, mask\n        \n        if self.transform:\n            image, mask = self.transform(sample)\n\n        return torch.from_numpy(image).reshape(1, 240, 240), torch.from_numpy(mask).reshape(1, 240, 240).double()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_folder = '/kaggle/input/brats-slices/brats_slices'\ndf = pd.read_csv('./meta.csv', index_col=0)\ndf = df.sort_values(by=['subject_id'], ignore_index=True)\n\ntrain_size = int(0.8 * df.shape[0])\nval_size = df.shape[0] - train_size\n\nborder_id = df['subject_id'][train_size]\n\ntrain_df = df[df['subject_id'] < border_id]\nval_df = df[df['subject_id'] >= border_id]\n\n\n\ndf['relative_path'] = df['relative_path'] \ndataset = BraTSDataset(df, data_folder, nonzero_mask=True) #\ndataset_loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True, num_workers=8)\ndevice = (\"cuda\" if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_crop(sample):\n    \n    image, mask = sample\n    delta_h, delta_w = 20, 20\n    h, w = image.shape\n    new_h, new_w = 120, 120\n    top = np.random.randint(0, h - delta_h - new_h)\n    left = np.random.randint(0, w - delta_w - new_w)\n\n    image = image[top: top + new_h,\n                  left: left + new_w]\n    \n    mask = mask[top: top + new_h,\n                  left: left + new_w]\n    \n    return image, mask\n\ndef random_rotate(sample):\n    \n    image, mask = sample\n    angles = [0, 90, 180, 270]\n    np.random.shuffle(angles)\n    angle = angles[0]    \n    return rotate(image, angle), rotate(mask, angle)\n    \ndef to_tensor(sample):\n    image, mask = sample\n    image = image.reshape(1, image.shape[0], image.shape[1])\n    return torch.from_numpy(image), np.sum(mask, axis=(0,1)).astype(bool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_step(images, labels, architecture, criterion, optimizer):\n    device = (\"cuda\" if torch.cuda.is_available() else 'cpu')\n    images, labels = images.to(device), labels.to(device)\n    architecture.train() # enforce training regime\n\n    pred_logits = architecture(images)\n    loss = criterion(pred_logits, labels)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    return loss.data.cpu().numpy()\n\ntrain_transform = torchvision.transforms.Compose([\n                    random_crop,\n                    random_rotate,\n                    to_tensor\n            ])\nval_transform = to_tensor\n\ntrain_dataset = BraTSDataset(train_df, data_folder, nonzero_mask=True)\nval_dataset = BraTSDataset(val_df, data_folder, nonzero_mask=True)\n\n\n# train_dataset = BraTSDataset(train_df, data_folder, nonzero_mask=True, transform=train_transform)\n# val_dataset = BraTSDataset(val_df, data_folder, nonzero_mask=True, transform=val_transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                             batch_size=128, shuffle=True,\n                                             num_workers=2)\nval_loader = torch.utils.data.DataLoader(val_dataset,\n                                             batch_size=128, shuffle=False,\n                                             num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = (\"cuda\" if torch.cuda.is_available() else 'cpu')\nmodel = Unet().to(device)\ncriterion = nn.BCEWithLogitsLoss() \noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.load_state_dict(torch.load('./unet.pth'))\n\nfor epoch in range(5):\n    epoch_loss = 0\n    for X_batch, y_batch in tqdm(dataset_loader):\n\n        loss = train_step(X_batch, y_batch, model, criterion, optimizer)\n        \n        epoch_loss += loss     \n\n    print(f'Epoch {epoch+0:03}: | Loss: {epoch_loss/len(dataset_loader):.5f}')\n\ntorch.save(model.state_dict(), './unet.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = model.load_state_dict(torch.load('./unet.pth'))\n_ = model.eval()\n\nx, y = dataset[700]\ny_pred = np.exp(model(x.reshape(1,1,240,240).to('cuda'))[0].to('cpu').detach().numpy()) > 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 3, figsize=(15, 5))\n\nax[0].imshow(x[0, ...], cmap='gray')\nax[0].set_title('Image')\nax[1].imshow(y[0, ...], cmap='gray')\nax[1].set_title('Ground truth mask')\nax[2].imshow(y_pred[0, ...], cmap='gray')\nax[2].set_title('Predicted mask');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}