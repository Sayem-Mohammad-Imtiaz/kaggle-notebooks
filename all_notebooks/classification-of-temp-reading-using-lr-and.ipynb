{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Predicting the given temperature as temperature in the room or temperature outside the room.**\n\n\nAs we can see we have many variables but we are not concerned above the variables like \"id\" , \"room_id/id\" , \"noted_date\" because this are classified as noisy or\nwe can say un-useful data because they don't have any impact on the class of our output.\nWe can consider \"noted_date\" as a parameter but we will not in our example as it will increase the complexity of the algorithm.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading the csv file\ndf = pd.read_csv(\"/kaggle/input/temperature-readings-iot-devices/IOT-temp.csv\")\n# Printing the first 5 entries in the Dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the number of rows and columns\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the dimensions of the Dataframe\ndf.ndim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Information regarding the dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the unique values from the id columns\nunique_id = df['id'].unique()\nprint(len(unique_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_room_id = df['room_id/id'].unique()\nprint(unique_room_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decribing our dataset to get the insights of dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the userful data into the \"data\" dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.iloc[:,3:]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Confirming the dimensions of the data, as we can see we have 97606 rows and 2 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can't work with text data so we encode it to get it in integer format"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlec = LabelEncoder()\ndata['out/in'] = lec.fit_transform(data['out/in'])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here '0' means 'in' and '1' means 'out'.**"},{"metadata":{},"cell_type":"markdown","source":"Plotting the pair plot of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(data = data , hue = 'out/in')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting a scatter plot of temperature against the class"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(data['temp'],data['out/in'])\nplt.title('Temperatur Scatter Plot')\nplt.xlabel('Temperature')\nplt.ylabel('IN/OUT')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting the data into numpy array"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data['temp'].values\nprint(X[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = data['out/in'].values\nprint(Y[0:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reshaping the data, becuase after converting into numpy it will convert the dataframe into an array of values,\nso we will have to reshape it to be rows x columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape\nX = X.reshape(-1,1)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As their is a diversity between input and output variables or we can say dependent and independent variables, we standardize the data to get better results"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler().fit(X)\nX = sc.transform(X)\nprint(X[0:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting data into training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train , x_test , Y_train , y_test = train_test_split(X,Y,test_size = 0.3)\nprint(X_train[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(x_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training our classifier on Logistic Regression as this is a cassification problem and we don't have diverse data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(solver = 'liblinear')\nclassifier.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validating the classifier on different partitions of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate\nresults = cross_validate(classifier , X , Y , cv=5)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting the values for x_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the accuracy score of our classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Using Support Vector Machine for Classification**"},{"metadata":{},"cell_type":"markdown","source":"I know that the data is not large, but the data has some temp reading that are corresponding to both in and out, so to split them, we have to introduce a kernel for that we use SVM."},{"metadata":{},"cell_type":"markdown","source":"Training our model on SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier2 = SVC(gamma = 'auto')\nclassifier2.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross Validating the SVM classifier on different distributions of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM_results = cross_validate(classifier2 , X, Y , cv=5)\nprint(SVM_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting and checking the accuracy score of our SVM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_classifier2 = classifier2.predict(x_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_pred_classifier2,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see SVM performed better then Logistic Regression as the their were some observations that fell into both classes , due to the hyperplane technique of SVM. it was able to classify the temp is of what class , if it would have been a clear classification problem Logistic Regression would have performed well on this dataset.\nSo the final conclusion is we can assure a 80% accuracy from SVM and a 76% accuracy from Logistic Regression."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}