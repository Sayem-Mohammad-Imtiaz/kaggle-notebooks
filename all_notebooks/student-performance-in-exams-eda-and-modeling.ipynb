{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ML Project 1\n## Introduction\nThe objective of this project is to train several classification models, and practice model tuning (bias/varience) tradeoff. \n\n## Agenda\n1. Data Set Selection \n1. EDA\n1. Models\n1. AutoML\n\n## Team members\n1. Eden Zere\n1. Essey Abraham Tezare\n1. Hussien Mohamed Bayoumy Mohamed Elgabry\n1. Mario Arismendi Matos\n1. Moustafa Ahmed Galal Bahnasawy\n1. Youssef Samy Mounir\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Set Selection\n\nObjective is to understand the influence of various factors like economic, personal and social on the students performance\nInferences would be :\n* How to imporve the students performance in each test ?\n* What are the major factors influencing the test scores ?\n* Effectiveness of test preparation course?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Import libraries","execution_count":null},{"metadata":{"_cell_guid":"cfdaacbc-23a3-423d-8d4d-120939ac7383","trusted":true},"cell_type":"code","source":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport missingno as missing\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\nimport random\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import learning_curve, validation_curve\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.metrics import roc_curve, roc_auc_score ,auc, plot_roc_curve\nfrom sklearn import svm\nimport sklearn.metrics\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Reading the data","execution_count":null},{"metadata":{"_cell_guid":"3ab4c525-a5cb-4183-9468-c1dd005c4c78","trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv(\"../input/studentperformancebig/StudentsPerformanceBig.csv\")\n\n# preview the data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 Data Dictionary\n1. **gender** -- Male or Female\n1. **race/ethnicity** -- group A,B, ...\n1. **Parental Level of education** --\tMaster, Bachelor, ... \n1. **lunch** -- standared or free\t\n1. **test preparation course**\t-- complete, none\n1. **math score** -- score of math course\n1. **reading score** -- score of reading course\t\n1. **writing score** -- score of writing course","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.4 Training Data Info","execution_count":null},{"metadata":{"_cell_guid":"86179af8-3cb4-4661-84ea-addd2c7679d4","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Our data seems to be clean of missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.5 Data description","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.6 Distict values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check the no. of unique items present in the categorical column\n\ndf.select_dtypes('object').nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Checking for Skewness","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.distplot(df['math score'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(df['reading score'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(df['writing score'])\n\nplt.suptitle('Checking for Skewness', fontsize = 15)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Relation between features and Score","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.2.1 Race/ethnicity VS Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"race/ethnicity\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"race/ethnicity\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"race/ethnicity\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.2 Lunch vs Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"lunch\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"lunch\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"lunch\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.3 Parental level of education vs Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"parental level of education\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.xticks(rotation = 90)\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"parental level of education\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.xticks(rotation = 90)\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"parental level of education\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.xticks(rotation = 90)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.4 Test preparation course vs Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"test preparation course\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"test preparation course\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"test preparation course\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.5 Relation between scores","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,6))\nsns.pairplot(data=df,hue='gender',plot_kws={'alpha':0.2})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.6 Mapping score to Pass or Fail\nTo be passed in a course, you have to get 60 or more. and to be marked as \"Passed\" you have to pass the 3 courses.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['math_pass']=np.where(df['math score'] >= 65,'P','F')\ndf['reading_pass']=np.where(df['reading score'] >= 65,'P','F')\ndf['writing_pass']=np.where(df['writing score'] >= 65,'P','F')\ndf['Pass'] = df.apply(lambda x :1 if x['math score'] >= 65 and \n                      x['reading score'] >= 65 and \n                      x['writing score'] >= 65 \n                      else 0, axis =1)\ndf.head()\ndf.Pass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\n\nplt.subplot(4,3,1)\nsns.countplot(x='parental level of education', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.subplot(4,3,2)\nsns.countplot(x='parental level of education', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.subplot(4,3,3)\nsns.countplot(x='parental level of education', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\n\nplt.subplot(4,3,4)\nsns.countplot(x='gender', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Gender - Writing Pass\")\nplt.subplot(4,3,5)\nsns.countplot(x='gender', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Gender - Math Pass\")\nplt.subplot(4,3,6)\nsns.countplot(x='gender', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Gender - Reading Pass\")\n\nplt.subplot(4,3,7)\nsns.countplot(x='test preparation course', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Preparation - Writing Pass\")\nplt.subplot(4,3,8)\nsns.countplot(x='test preparation course', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Preparation - Math Pass\")\nplt.subplot(4,3,9)\nsns.countplot(x='test preparation course', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Preparation - Reading Pass\")\n\nplt.subplot(4,3,10)\nsns.countplot(x='race/ethnicity', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Race - Writing Pass\")\nplt.subplot(4,3,11)\nsns.countplot(x='race/ethnicity', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Race - Math Pass\")\nplt.subplot(4,3,12)\nsns.countplot(x='race/ethnicity', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Race - Reading Pass\")\n\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.6 Overall Comparison by mapping","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"map1 = {\"high school\": 1, \"some high school\": 1,\n        \"associate's degree\": 2,\n        \"some college\": 3,\n        \"bachelor's degree\": 4,\n        \"master's degree\": 5}\ndf['parental level of education']  = df['parental level of education'].map(map1)\n\nmap2 = {\"free/reduced\": 0,\n        \"standard\": 1}\ndf['lunch']  = df['lunch'].map(map2)\n\nmap3 = {\"none\": 0,\n        \"completed\": 1}\ndf['test preparation course']  = df['test preparation course'].map(map3)\n\nmap4 = {\"female\": 0,\n        \"male\": 1}\ndf['gender']  = df['gender'].map(map4)\n\nmap5 = {\"group A\": 1,\n        \"group B\": 2,\n        \"group C\": 3,\n        \"group D\": 4,\n        \"group E\": 5}\ndf['race/ethnicity']  = df['race/ethnicity'].map(map5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13,10))\n\nplt.subplot(4,3,1)\nsns.barplot(x = \"parental level of education\" , y=\"writing score\" , data=df)\nplt.title(\"Parental level - Writing Scores\")\nplt.subplot(4,3,2)\nsns.barplot(x = \"parental level of education\" , y=\"math score\" , data=df)\nplt.title(\"Parental level - Math Scores\")\nplt.subplot(4,3,3)\nsns.barplot(x = \"parental level of education\" , y=\"reading score\" , data=df)\nplt.title(\"Parental level - Reading Scores\")\n\nplt.subplot(4,3,4)\nsns.barplot(x = \"gender\" , y=\"writing score\" , data=df)\nplt.title(\"Gender - Writing Scores\")\nplt.subplot(4,3,5)\nsns.barplot(x = \"gender\" , y=\"math score\" , data=df)\nplt.title(\"Gender - Math Scores\")\nplt.subplot(4,3,6)\nsns.barplot(x = \"gender\" , y=\"reading score\" , data=df)\nplt.title(\"Gender - Reading Scores\")\n\nplt.subplot(4,3,7)\nsns.barplot(x = \"test preparation course\" , y=\"writing score\" , data=df)\nplt.title(\"Preparation - Writing Scores\")\nplt.subplot(4,3,8)\nsns.barplot(x = \"test preparation course\" , y=\"math score\" , data=df)\nplt.title(\"Preparation - Math Scores\")\nplt.subplot(4,3,9)\nsns.barplot(x = \"test preparation course\" , y=\"reading score\" , data=df)\nplt.title(\"Preparation - Reading Scores\")\n\nplt.subplot(4,3,10)\nsns.barplot(x = \"race/ethnicity\" , y=\"writing score\" , data=df)\nplt.title(\"Race - Writing Scores\")\nplt.subplot(4,3,11)\nsns.barplot(x = \"race/ethnicity\" , y=\"math score\" , data=df)\nplt.title(\"Race - Math Scores\")\nplt.subplot(4,3,12)\nsns.barplot(x = \"race/ethnicity\" , y=\"reading score\" , data=df)\nplt.title(\"Race - Reading Scores\")\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.7 Correclation Matrix between features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,10)) \nsns.heatmap(df.corr(), annot = True, fmt = \".2f\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.9 Drop unneccessary columns\nNow we can drop math score, reading score and writing score, as we will use the pass column instead.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfDrop = df.drop(['math score','reading score','writing score', 'math_pass', 'reading_pass','writing_pass'], axis=1)\ndfDrop.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfDrop.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,10)) \nsns.heatmap(dfDrop.corr(), annot = True, fmt = \".2f\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### This function is for drawing the learning curve.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Learning curve is a measurement to check how well the model learns. This is measured by taking a reading of the accuracy of the algorithm as it trains and also while it is testing. This are plotting to see the convergence.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotLearningCurves(X_train, y_train, classifier, title):\n    train_sizes, train_scores, test_scores = learning_curve(\n            classifier, X_train, y_train, cv=5, scoring=\"accuracy\")\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\" ,label=\"Training Error\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\" ,label=\"Cross Validation Error\")\n    \n    plt.legend()\n    plt.grid()\n    plt.title(title, fontsize = 18, y = 1.03)\n    plt.xlabel('Data Size', fontsize = 14)\n    plt.ylabel('Error', fontsize = 14)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This function is for drawing the validation curve.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Cross validation is a measure of how well our model can generalize from what it learns. How well will it perform with data it has neven seen before. This is done by saving part of the data to later predict and measure the accuracy. The training data is split with differing testing folds to be used. Default in this case is k=5 folds.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotValidationCurves(X_train, y_train, classifier, param_name, param_range, title):\n    train_scores, test_scores = validation_curve(\n        classifier, X_train, y_train, param_name = param_name, param_range = param_range,\n        cv=5, scoring=\"accuracy\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.plot(param_range, train_scores_mean, 'o-', color=\"b\" ,label=\"Training Error\")\n    plt.plot(param_range, test_scores_mean, 'o-', color=\"r\" ,label=\"Cross Validation Error\")\n\n    plt.legend()\n    plt.grid()\n    plt.title(title, fontsize = 18, y = 1.03)\n    plt.xlabel('Complexity', fontsize = 14)\n    plt.ylabel('Error', fontsize = 14)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This function is for printing the confusion matrix","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The confusion matrix shows the frequency for True Positives, True Negatives, False Positives, and False Negative. Also a summary of the different properties can be presented here, along with the accuracy for predicted values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def printConfusionMatrix(y_train, pred):\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, pred))\n    print(\"Classification Report:\",)\n    print (classification_report(y_test, pred))\n    print(\"Accuracy:\", accuracy_score(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1 DTree ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=3,\n                                    min_samples_split=9,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred1 = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 1'\nplotLearningCurves(X_train, y_train, rf, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Random Forest Validation Curve 1'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, rf_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(rf, X_test, y_test)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Using Entropy instead of default (gini)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=3,\n                                    criterion='entropy',\n                                    min_samples_split=9,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred2 = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 2'\nplotLearningCurves(X_train, y_train, rf, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Validation Curve 2'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, rf_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=3,\n                                    criterion='entropy',\n                                    min_samples_split=10,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred3 = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 3'\nplotLearningCurves(X_train, y_train, rf, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Random Forest Validation Curve 3'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, rf_pred3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=5,\n                                    criterion='entropy',\n                                    min_samples_split=9,\n                                    min_samples_leaf=10\n                                   )\nrf.fit(X_train, y_train)\nrf_pred4 = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 4'\nplotLearningCurves(X_train, y_train, rf, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Random Forest Validation Curve 4'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, rf_pred4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=5,\n                                    criterion='entropy',\n                                    max_features='sqrt',\n                                    min_samples_split=9,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred5 = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 5'\nplotLearningCurves(X_train, y_train, rf, title)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Random Forest Validation Curve 5'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprintConfusionMatrix(y_test, rf_pred5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GridSearch Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Classifier = RandomForestClassifier()\ngrid_obj = GridSearchCV(Classifier,\n                        {'n_estimators': [4, 6, 9],\n                         'max_features': ['log2', 'sqrt','auto'],\n                         'criterion': ['entropy', 'gini'],\n                         'max_depth': [2, 3, 5, 8],\n                         'min_samples_split': [2, 5, 8, 10],\n                         'min_samples_leaf': [1, 3, 5]\n                        },\n                        scoring=make_scorer(accuracy_score))\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nClassifier = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nClassifier.fit(X_train, y_train)\n\npredictions = Classifier.predict(X_test)\n\nprint(\"Best Params: \" , grid_obj.best_estimator_)\nprint(\"Best Score: \" , grid_obj.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 SVM ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"SVM is used for classification.It uses a technique called kernel trick to transform data and based on these transformation it finds an optimal boundary between the possible outputs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svmC=svm.SVC(kernel = 'linear' , gamma=0.01, C=0.05)\nsvmC.fit(X_train,y_train)\n\nsvm_pred1=svmC.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='Support Vector Machine Learning Curve 1'\nplotLearningCurves(X_train,y_train,svmC,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Support Vector Machine Validation Curve 1'\nparam_name = 'C'\nparam_range = [0.1,1, 10]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, svmC, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, svm_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(svmC, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svmC=svm.SVC(kernel = 'rbf' , gamma=0.05, C=1)\nsvmC.fit(X_train,y_train)\n\nsvm_pred2=svmC.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='Support Vector Machine Learning Curve 2'\nplotLearningCurves(X_train,y_train,svmC,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Support Vector Machine Validation Curve 2'\nparam_name = 'C'\nparam_range = [0.1,1, 10]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, svmC, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, svm_pred2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(svmC, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we used kernel=rbf, C=1, gamma=0.05 it showed us in the learning curve as the data increased the variance is decreasing too. In the validation curve we can see that there is high Error as \"C\"(Cost) increases. And we got 70% AUC which is okay, lets try other kernel with some hyper parameter. Lets try other hyper-parameter and see our result\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmC=svm.SVC(kernel = 'sigmoid' , gamma=1, C=100)\nsvmC.fit(X_train,y_train)\n\nsvm_pred3=svmC.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='Support Vector Machine Learning Curve 3'\nplotLearningCurves(X_train,y_train,svmC,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Support Vector Machine Validation Curve 3' \nparam_name = 'C'\nparam_range = [0.1,1, 10]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, svmC, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, svm_pred3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(svmC, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we used kernel=sigmoid, C=100, gamma=1 it showed us in the learning curve as the data size increased and the variance is decreasing, there is low variance and the error started to decrease as data increased. In the validation curve we can see that there is low variance as \"C\"(Cost) increases they are overlapping and the error is decreasing. And we got 37% AUC which is bad, lets try other kernel with some hyper parameter. Lets try other hyper-parameter and see our result with grid search\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Grid Search Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.05, 1,10, 20], 'gamma': [0.01,0.1,0.2,1],'kernel': ['sigmoid', 'rbf','linear']}\ngrid = GridSearchCV(svm.SVC(),param_grid,refit=True,verbose=2)\nsvclassifier = grid.fit(X_train,y_train)\nSvcPredictions = svclassifier.predict(X_test)\n\nprint(\"Best Params: \" , grid.best_estimator_)\nprint(\"Best Score: \" , grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"svm uses three hyperparameters kernel,Cost,gamma.From Kernel we used linear, sigmoid and rbf, with some hyper-parameter.They gave us different results based on the hyper-parameter. With grid search we put different values hyper-parameter and the best it gave us is with C=10 gamma=0.2 and score is 68%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.3 KNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=3)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred1=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 1'\nplotLearningCurves(X_train,y_train,knn,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'KNN Validation Curve 1' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, knn_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=7)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred2=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 2'\nplotLearningCurves(X_train,y_train,knn,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'KNN Validation Curve 2' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, knn_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=10)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred3=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 3'\nplotLearningCurves(X_train,y_train,knn,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'KNN Validation Curve 3' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, knn_pred3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=20)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred4=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 4'\nplotLearningCurves(X_train,y_train,knn,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'KNN Validation Curve 4' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, knn_pred4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=17)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred5=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 5'\nplotLearningCurves(X_train,y_train,knn,title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'KNN Validation Curve 5' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, knn_pred5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid Search Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create new a knn model\nknn2=KNeighborsClassifier()\n#create a dictionary of all values we want to test for n_neighbors\nparam_grid= {'n_neighbors': np.arange(1, 20)}\n#use gridsearch to test all values for n_neighbors\nknn_gscv=GridSearchCV(knn2, param_grid, cv=5)\n#fit model to data\nknn_gscv.fit(X, y)\n\nprint(\"Best Params: \" , knn_gscv.best_estimator_)\nprint(\"Best Score: \" , knn_gscv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.4 MLP","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"oneHotEncoder is used to encode categiorical columns into values that can be digested by the used algorithm implementation, in our case it.\n\nThe MLP configured above will iterate 3000 times, use hidden layers and 17, 13, 7, solver stochastic gradient descent. Our data was devided into a 80/20 train/set splits to train and evaluate your classifier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding categorical inputs\nencoder = OneHotEncoder(handle_unknown=\"ignore\")\nencoder.fit(X)\nX = encoder.transform(X)\n\n# 80/20 train split ratio\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier(\n    max_iter=3000,\n    hidden_layer_sizes=[17, 13, 7], \n    solver=\"sgd\", \n    random_state=1,\n    verbose=False\n).fit(X_train, y_train)\n\nmlp_pred1 = mlp.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compute learning curve for MLP","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_scores_as_dataframe(labels, train_scores, test_scores):\n    learning_data = {\"labels\": [], \"type\": [], \"score\": []}\n\n    for i in range(len(train_sizes)):\n        for j in range(len(train_scores)):\n            learning_data[\"labels\"].append(labels[i])\n            learning_data[\"type\"].append(\"train\")\n            learning_data[\"score\"].append(train_scores[i][j])\n            learning_data[\"labels\"].append(labels[i])\n            learning_data[\"type\"].append(\"test\")\n            learning_data[\"score\"].append(test_scores[i][j])\n            \n    return pd.DataFrame.from_dict(learning_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(mlp, X, y)\n\nlearning_curve_df = format_scores_as_dataframe(train_sizes, train_scores, test_scores)\n\n# train and test learning scores results\nax = sns.lineplot(x=\"labels\", y=\"score\", hue=\"type\", data=learning_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Learning Curve for MLP Algorithm\")\ndev_null = ax.set(xlabel=\"Samples\", ylabel=\"Error\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compute cross-validation curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(mlp, X, y)\n\nscores, scores.mean(), scores.std()\n\ndev_null = sns.lineplot(x=[1,2,3,4,5], y=scores)\ndev_null.set_title(\"Cross Score Distribution\")\ndev_null = dev_null.set(xlabel=\"# of runs\", ylabel=\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The curve above shows the cross-validation scores for the default 5 runs in the cross-validation process for the MLP model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncross_val_result = cross_validate(mlp, X, y, return_train_score=True)\n\n\n#validation_curve(mlp, X, y, param_name=\"alpha\", param_range=[0.0001, 0.001, 0.05])\ntrain_scores, test_scores = validation_curve(mlp, X, y, param_name=\"hidden_layer_sizes\", param_range=([5], [10], [10,5], [15, 10], [25,10,5]))\n\nval_curve_data = {\"labels\": [], \"type\": [], \"scores\": []}\nparam_ranges = [\"[5]\", \"[10]\", \"[10,5]\", \"[15,10]\", \"[25,10,5]\"]\n\nfor i in range(len(train_scores)):\n    for j in range(len(train_scores[i])):\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"train\")\n        val_curve_data[\"scores\"].append(train_scores[i][j])\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"test\")\n        val_curve_data[\"scores\"].append(test_scores[i][j])\n        \nval_curve_df = pd.DataFrame.from_dict(val_curve_data)\n\nax = sns.lineplot(x=\"labels\", y=\"scores\", hue=\"type\", data = val_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Validation Curve for our MLP model\")\ndev_null = ax.set(xlabel=\"Layers/Neurons\", ylabel=\"Accuracy Score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprintConfusionMatrix(y_test, mlp_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(mlp, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier(\n    max_iter=3000,\n    hidden_layer_sizes=[17, 13, 7], \n    solver=\"sgd\",\n    activation=\"logistic\",\n    random_state=1,\n    verbose=False\n).fit(X_train, y_train)\n\nmlp_pred2 = mlp.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(mlp, X, y)\n\nlearning_curve_df = format_scores_as_dataframe(train_sizes, train_scores, test_scores)\n\n# train and test learning scores results\nax = sns.lineplot(x=\"labels\", y=\"score\", hue=\"type\", data=learning_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Learning Curve for MLP Algorithm\")\ndev_null = ax.set(xlabel=\"Samples\", ylabel=\"Error\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(mlp, X, y)\n\nscores, scores.mean(), scores.std()\n\ndev_null = sns.lineplot(x=[1,2,3,4,5], y=scores)\ndev_null.set_title(\"Cross Score Distribution\")\ndev_null = dev_null.set(xlabel=\"# of runs\", ylabel=\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_result = cross_validate(mlp, X, y, return_train_score=True)\n\n#validation_curve(mlp, X, y, param_name=\"alpha\", param_range=[0.0001, 0.001, 0.05])\ntrain_scores, test_scores = validation_curve(mlp, X, y, param_name=\"hidden_layer_sizes\", param_range=([5], [10], [10,5], [15, 10], [25,10,5]))\n\nval_curve_data = {\"labels\": [], \"type\": [], \"scores\": []}\nparam_ranges = [\"[5]\", \"[10]\", \"[10,5]\", \"[15,10]\", \"[25,10,5]\"]\n\nfor i in range(len(train_scores)):\n    for j in range(len(train_scores[i])):\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"train\")\n        val_curve_data[\"scores\"].append(train_scores[i][j])\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"test\")\n        val_curve_data[\"scores\"].append(test_scores[i][j])\n        \nval_curve_df = pd.DataFrame.from_dict(val_curve_data)\n\nax = sns.lineplot(x=\"labels\", y=\"scores\", hue=\"type\", data = val_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Validation Curve for our MLP model\")\ndev_null = ax.set(xlabel=\"Layers/Neurons\", ylabel=\"Accuracy Score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printConfusionMatrix(y_test, mlp_pred2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(mlp, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid Search Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    \"hidden_layer_sizes\": [[8], [5]], #, [2], [8,8], [8,5], [5,8], [5,2], [2,2], [8,5,2], [8,5,5], [13,8,4], [17,13,7]\n    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"], \n    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"], \n    \"max_iter\": [200, 500, ] #1000, 2000, 3000, 5000\n}\n\n# Brace yourself, this will take a while\nmlp = MLPClassifier()\ngs = GridSearchCV(mlp, parameters)\ngs.fit(X_train, y_train)\ngs.predict(X_test)\n\nprint(\"Best Params: \" , gs.best_estimator_)\nprint(\"Best Score: \" , gs.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Best Model (Over All AUC) and AutoML","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.1 AUC curve over all models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Instantiate the classfiers and make a list\nclassifiers = [RandomForestClassifier(),\n                MLPClassifier(), \n               svm.SVC(),\n               KNeighborsClassifier()]\n\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n\n\n# print('auc =', auc)\nlr_fpr1, lr_tpr1, _ = roc_curve(y_test, rf_pred3)\nlr_fpr2, lr_tpr2, _ = roc_curve(y_test,  mlp_pred1)\nlr_fpr3, lr_tpr3, _ = roc_curve(y_test, svm_pred1)\nlr_fpr4, lr_tpr4, _ = roc_curve(y_test, knn_pred5)\n\n# fpr , tpr, _= roc_curve(X_test, predict6_test)\nauc1 = roc_auc_score(y_test, rf_pred3)\nauc2 = roc_auc_score(y_test,  mlp_pred1)\nauc3 = roc_auc_score(y_test, svm_pred1)\nauc4 = roc_auc_score(y_test, knn_pred5)\n \n    \nresult_table = result_table.append({'classifiers':RandomForestClassifier.__class__.__name__,\n                                     'fpr':lr_fpr1, \n                                     'tpr':lr_tpr1, \n                                     'auc':auc1}, ignore_index=True)\n\nresult_table = result_table.append({'classifiers':MLPClassifier.__class__.__name__,\n                                     'fpr':lr_fpr2, \n                                     'tpr':lr_tpr2, \n                                     'auc':auc2}, ignore_index=True)\n\nresult_table = result_table.append({'classifiers':svm.SVC.__class__.__name__,\n                                     'fpr':lr_fpr3, \n                                     'tpr':lr_tpr3, \n                                     'auc':auc3}, ignore_index=True)\n\nresult_table = result_table.append({'classifiers':KNeighborsClassifier.__class__.__name__,\n                                     'fpr':lr_fpr4, \n                                     'tpr':lr_tpr4, \n                                     'auc':auc4}, ignore_index=True)\n\nfig = plt.figure(figsize=(8,6))\n\nplt.plot(result_table.loc[0]['fpr'], \n         result_table.loc[0]['tpr'], \n         label=\"RandomForestClassifier, AUC={:.3f}\".format( result_table.loc[0]['auc']))\n\nplt.plot(result_table.loc[1]['fpr'], \n         result_table.loc[1]['tpr'], \n         label=\"MLPClassifier, AUC={:.3f}\".format( result_table.loc[1]['auc']))\n\nplt.plot(result_table.loc[2]['fpr'], \n         result_table.loc[2]['tpr'], \n         label=\"SVM, AUC={:.3f}\".format( result_table.loc[2]['auc']))\n\nplt.plot(result_table.loc[3]['fpr'], \n         result_table.loc[3]['tpr'], \n         label=\"KNeighborsClassifier, AUC={:.3f}\".format( result_table.loc[3]['auc']))\n\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 AutoML","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt-get remove swig \n!apt-get install swig3.0 build-essential -y\n!ln -s /usr/bin/swig3.0 /usr/bin/swig\n!apt-get install build-essential\n!pip install --upgrade setuptools\n!pip install auto-sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import autosklearn.classification\nimport sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\nimport os  \nimport autosklearn.regression\n\n\nautoml = autosklearn.classification.AutoSklearnClassifier(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n    tmp_folder='/tmp/autosklearn_cv_example_tmp5',\n    output_folder='/tmp/autosklearn_cv_example_out5',\n    delete_tmp_folder_after_terminate=False,\n    resampling_strategy='cv',\n    resampling_strategy_arguments={'folds': 5},\n)\n\n# fit() changes the data in place, but refit needs the original data. We\n# therefore copy the data. In practice, one should reload the data\nautoml.fit(X_train.copy(), y_train.copy(), dataset_name='Students')\n# During fit(), models are fit on individual cross-validation folds. To use\n# all available data, we call refit() which trains all models in the\n# final ensemble on the whole dataset.\nautoml.refit(X_train.copy(), y_train.copy())\n\nprint(automl.show_models())\n\npredictions = automl.predict(X_test)\nprint(\"Accuracy as per AutoML: \", sklearn.metrics.accuracy_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References: \n\n* http://roycekimmons.com/tools/generated_data/exams\n* https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n* https://www.kaggle.com/roshansharma/student-performance-analysis\n* https://www.kaggle.com/spscientist/student-performance-in-exams\n* https://www.kaggle.com/nitindatta/eda-in-depth\n* http://scikit-learn.sourceforge.net/stable/auto_examples/model_selection/plot_validation_curve.html#example-model-selection-plot-validation-curve-py\n* https://chrisalbon.com/machine_learning/model_evaluation/plot_the_validation_curve/\n* https://datascience.stackexchange.com/questions/76304/gridsearchcv-with-random-forest-classifier\n* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=A%20random%20forest%20classifier.%20A%20random%20forest%20is,to%20improve%20the%20predictive%20accuracy%20and%20control%20over-fitting.\n* https://scikit-learn.org/stable/modules/multiclass.html#multioutput-regression\n* https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n* https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_classification_algorithms_random_forest.htm\n* https://florianhartl.com/thoughts-on-machine-learning-dealing-with-skewed-classes.html\n* https://www.kaggle.com/ahmedengu/lanl-master-s-features-autosklearn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}