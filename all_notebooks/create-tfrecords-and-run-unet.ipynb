{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, we will convert the TrayDataset to TFRecords and then use UNet model predict the mask using TPU."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport glob\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = [256, 256]\nEPOCHS = 5\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(file_path):\n    image = tf.io.read_file(file_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = image.numpy().flatten() #TFRecord only accept 1-dim array\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def serialize_example(image, mask):\n  feature = {\n      'image': tf.train.Feature(float_list=tf.train.FloatList(value=image)),\n      'mask': tf.train.Feature(float_list=tf.train.FloatList(value=mask))\n  }\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path_train = 'train.tfrecords'\nfile_path_test = 'test.tfrecords'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will create the TFRecords. In order to use this file with TPU, we need to put them in a dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_tfrecord(folder_path, subset, saveFile_path):\n    writer = tf.io.TFRecordWriter(saveFile_path)\n    for index, file_path_input in enumerate(glob.glob(folder_path+\"X\"+subset+\"/*\")):\n        file_path_output = file_path_input.replace(\"/X\"+subset, \"/y\"+subset)\n        file_path_output = file_path_output.replace(\".jpg\", \".png\").replace(\".JPG\", \".png\")\n        print(file_path_input, file_path_output)\n        image, mask = decode_image(file_path_input), decode_image(file_path_output)\n        writer.write(serialize_example(image, mask))\n    writer.close()\ncreate_tfrecord(\"/kaggle/input/tray-food-segmentation/TrayDataset/TrayDataset/\", \"Train\", file_path_train)\ncreate_tfrecord(\"/kaggle/input/tray-food-segmentation/TrayDataset/TrayDataset/\", \"Test\", file_path_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From here we will use TPU.\nThe created tfrecords can be found on Kaggle named: traydataset-256x256-tfrecords-image-mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('traydataset-256x256-tfrecords-image-mask')\nprint(GCS_DS_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path_train = GCS_DS_PATH+ '/train.tfrecords'\nfile_path_test = GCS_DS_PATH+'/test.tfrecords'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_fn(data_record):\n    features = {\n        'image': tf.io.FixedLenFeature([256*256*3], tf.float32),\n        'mask': tf.io.FixedLenFeature([256*256*3], tf.float32)\n    }\n    sample = tf.io.parse_example(data_record, features)\n    image = sample['image']\n    image = tf.reshape(image, IMAGE_SIZE+[3])\n    mask = sample['mask']\n    mask = tf.reshape(mask, IMAGE_SIZE+[3])\n    return image, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count(file_path):\n    dataset = tf.data.TFRecordDataset([file_path])\n    dataset = dataset.map(extract_fn)\n    dataset = dataset.enumerate()\n\n    count = 0\n    for element in dataset.as_numpy_iterator():\n      #print(\"element:\", len(element))\n      count+=1\n    print(\"count\", count)\ncount(file_path_train)\ncount(file_path_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ndef load_dataset(file_path):\n    dataset = tf.data.TFRecordDataset([file_path])\n    dataset = dataset.map(extract_fn)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\ndataset_train = load_dataset(file_path_train)\ndataset_test = load_dataset(file_path_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\nfrom tensorflow.keras.layers import Dense, Flatten, Input\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\ndef get_model(IMG_HEIGHT, IMG_WIDTH):\n    in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n    preprop = in1\n    #preprop = tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\")(preprop)\n    #preprop = tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)(preprop)\n\n    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(preprop)#(in1)\n    conv1 = Dropout(0.2)(conv1)\n    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n    conv2 = Dropout(0.2)(conv2)\n    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n    conv3 = Dropout(0.2)(conv3)\n    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n\n    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n    conv4 = Dropout(0.2)(conv4)\n    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n\n    up1 = concatenate([UpSampling2D((2, 2))(conv4), conv3], axis=-1)\n    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up1)\n    conv5 = Dropout(0.2)(conv5)\n    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n\n    up2 = concatenate([UpSampling2D((2, 2))(conv5), conv2], axis=-1)\n    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n    conv6 = Dropout(0.2)(conv6)\n    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n\n    up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n    conv7 = Dropout(0.2)(conv7)\n    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n    segmentation = Conv2D(3, (1, 1), activation='sigmoid', name='seg')(conv7)\n\n    model = Model(inputs=[in1], outputs=[segmentation])\n\n    losses = {'seg': 'binary_crossentropy'}\n\n    metrics = {'seg': ['acc']}\n    model.compile(optimizer=\"adam\", loss = losses, metrics=metrics)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = get_model(256, 256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(dataset_train, epochs=EPOCHS+100, batch_size=BATCH_SIZE, validation_data=dataset_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nmodel.save(\"model\", options=save_locally)\nmodel.save(\"model.h5\", options=save_locally)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmetrics = history.history\n\nplt.plot(history.epoch, metrics['loss'], metrics['acc'])\nplt.legend(['loss', 'acc'])\nplt.savefig(\"fit-history.png\")\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndataset = tf.data.TFRecordDataset([file_path_train])\ndataset = dataset.map(extract_fn)\ndataset = dataset.enumerate()\n\ncount = 0\nfor element in dataset.as_numpy_iterator():\n    #print(\"element:\", element)\n    image = element[1][0]\n    mask = element[1][1]\n    predicted = model.predict(np.array([image]))[0]\n    f, axarr = plt.subplots(1,3)\n    axarr[0].imshow(image)\n    axarr[1].imshow(mask)\n    axarr[2].imshow(predicted)\n    plt.show()                    \n    count+=1\nprint(\"count\", count)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}