{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sentiment'] = df['sentiment'].map({'positive':1,'negative':0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sentiment.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentence_to_vec(s,embedding_dict,stopwords,tokenizer):\n    words = str(s).lower()\n    words = tokenizer(words)\n    words = [word for word in words if word not in string.punctuation]\n    words = [word for word in words if word not in stopwords]\n    words = [word for word in words if word.isalpha()]\n    \n    M = []\n    for w in words:\n        if w in embedding_dict:\n            M.append(embedding_dict[w])\n            \n    if len(M)==0:\n        return np.zeros(300)\n    M=np.array(M)\n    v = M.sum(axis=0)\n    return v/np.sqrt((v**2).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_embeddings(file):\n    f = open(file,'r')\n    gloveModel = {}\n    for line in f:\n        splitLines = line.split()\n        word = splitLines[0]\n        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n        gloveModel[word]=wordEmbedding        \n    \n    return gloveModel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loading embeddings')\nembeddings = load_embeddings('../input/glove-embeddings/glove.6B.300d.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectors = []\nfor review in df.review.values:\n    vectors.append(sentence_to_vec(s= review,embedding_dict=embeddings,stopwords=[],tokenizer=word_tokenize))\n    \n    \nvectors = np.array(vectors)\ny = df.sentiment.values\nprint('Done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(vectors,y,test_size=0.2,stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = logreg.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy of the model : {:.3f}'.format(accuracy_score(y_test,y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}