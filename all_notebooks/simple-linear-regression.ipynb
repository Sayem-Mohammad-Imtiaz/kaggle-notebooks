{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\n\n\n#loading the dataset\ncal = pd.read_csv(\"../input/simplelinearregression/1st/calrories_consumed.py\")\n\n#2.\tWork on each feature of the dataset to create a data dictionary as displayed in the below image\n#######feature of the dataset to create a data dictionary\n\n#######feature of the dataset to create a data dictionary\ndescription  = [\"important data weight gained in grams \",\n                \"Consumptation in Calories\"]\n\nd_types =[\"Ratio\",\"Ratio\"]\n\ndata_details =pd.DataFrame({\"column name\":cal.columns,\n                            \"data types \":d_types,\n                            \"description\":description,\n                            \"data type(in Python)\": cal.dtypes})\n\n            #3.\tData Pre-processing\n          #3.1 Data Cleaning, Feature Engineering, etc\n          \n          \n#details of cal \ncal.info()\ncal.describe()          \n\n\n#rename the columns\ncal.rename(columns = {'Weight gained (grams)':'weight', 'Calories Consumed':'calories'}, inplace = True) \n\n#data types        \ncal.dtypes\n\n\n#checking for na value\ncal.isna().sum()\ncal.isnull().sum()\n\n#checking unique value for each columns\ncal.nunique()\n\n\n\"\"\"\tExploratory Data Analysis (EDA):\n\tSummary\n\tUnivariate analysis\n\tBivariate analysis \"\"\"\n    \n\n\nEDA ={\"column \": cal.columns,\n      \"mean\": cal.mean(),\n      \"median\":cal.median(),\n      \"mode\":cal.mode(),\n      \"standard deviation\": cal.std(),\n      \"variance\":cal.var(),\n      \"skewness\":cal.skew(),\n      \"kurtosis\":cal.kurt()}\n\nEDA\n\n# covariance for data set \ncovariance = cal.cov()\ncovariance\n\n\n####### graphical repersentation \n\n##historgam and scatter plot\nimport seaborn as sns\nsns.pairplot(cal.iloc[:, :])\n\n\n#boxplot for every columns\ncal.columns\ncal.nunique()\n\ncal.boxplot(column=['weight', 'calories'])   #no outlier\n\n\n\n\"\"\"\n5.\tModel Building:\n5.1\tPerform Simple Linear Regression on the given datasets\n5.2\tApply different transformations such as exponential, log, polynomial transformations and calculate RMSE values, R-Squared values, Correlation Coefficient for each model\n5.3\tBuild the models and choose the best fit model\n5.4\tBriefly explain the model output in the documentation\t \n \"\"\"\n\n\n#model bulding \n# Linear Regression model\nCo_coe_val_1  =np.corrcoef(cal.calories, cal.weight)\nCo_coe_val_1\n# Import library\nimport statsmodels.formula.api as smf\n\n\nmodel1= smf.ols('calories ~ weight' , data = cal).fit()\nmodel1.summary()\n\n#perdicting on whole data\npred = model1.predict(pd.DataFrame(cal['weight']))\n\nimport matplotlib.pyplot as plt\n\n# Regression Line\nplt.scatter(cal.weight, cal.calories)\nplt.plot(cal.weight, pred, \"r\")\nplt.legend(['Predicted line', 'Observed data'])\nplt.show()\n\nimport numpy as np\n# Error calculation\nrmse =  np.sqrt(((pred-cal['calories'])**2).mean())\nrmse\n\n#model 2\n\n# Transformation Techniques\n# Log transformation applied on 'x'\n# input = log(x); output = y\n######### Model building on Transformed Data\n# Log Transformation\n\nplt.scatter(x = np.log(cal['calories']), y = cal[\"weight\"], color = 'brown')\nCo_coe_val_2  =np.corrcoef(np.log(cal.calories), cal.weight) #correlation\nCo_coe_val_2\n\nmodel2 = smf.ols('calories ~ np.log(weight)', data =cal).fit()\nmodel2.summary()\n\n\npred2 = model2.predict(pd.DataFrame(cal[\"weight\"]))\n\n# Regression Line\n\nplt.scatter(np.log(cal.weight),cal.calories)\nplt.plot(np.log(cal.weight), pred2, \"r\")\nplt.legend(['Predicted line', 'Observed data'])\nplt.show()\n\n# Error calculation\nrmse2 =  np.sqrt(((pred2-cal['calories'])**2).mean()) \nrmse2\n\n# Log transformation applied on 'y'\n# input = x; output = log(y) \n#### Exponential transformation \n# x = waist; y = log(at) \n\nplt.scatter(x = cal['calories'], y = np.log(cal['weight']), color = 'orange') \nCo_coe_val_2  =    np.corrcoef(cal.calories, np.log(cal['weight'])) #correlation\nCo_coe_val_2  \n#model3\n\nmodel3 = smf.ols('np.log(cal.calories) ~ cal.weight ', data = cal).fit() \nmodel3.summary() \n\n\npred3 = model3.predict(pd.DataFrame(cal['weight']))\npred3_at = np.exp(pred3) \npred3_at \n\n# Regression Line\n\nplt.scatter(cal['weight'], np.log(cal['calories'])) \nplt.plot(cal['weight'], pred3, \"r\") \nplt.legend(['Predicted line', 'Observed data']) \nplt.show()\n\n# Error calculation\nrmse3 =  np.sqrt(((pred3_at-cal['calories'])**2).mean())\nrmse3   \n\n\n\n#### Polynomial transformation\n# x = waist; x^2 = waist*waist; y = log(at)\n\nmodel4 = smf.ols('np.log(calories) ~ weight + I(weight*weight)', data = cal).fit() \nmodel4.summary() \n\n\npred4 = model4.predict(pd.DataFrame(cal.weight)) \npred4_at = np.exp(pred4) \npred4_at  \n\n\n# Regression line\nfrom sklearn.preprocessing import PolynomialFeatures  \npoly_reg = PolynomialFeatures(degree = 2)  \nX = cal.iloc[:, 0:1].values  \nX_poly = poly_reg.fit_transform(X) \n# y = wcat.iloc[:, 1].values\n\nplt.scatter(cal.weight, np.log(cal.calories)) \nplt.plot(cal['weight'], pred4, color = 'red') \nplt.legend(['Predicted line', 'Observed data']) \nplt.show() \n\n\n\n# Error calculation\nrmse4 =  np.sqrt(((pred4_at -cal['calories'])**2).mean()) \nrmse4\n\n\n\n# Choose the best model using RMSE\nModel_details = pd.DataFrame({\"MODEL\":pd.Series([\"SLR\", \"Log model\", \"Exp model\", \"Poly model\"]), \n        \"RMSE\":pd.Series([rmse, rmse2, rmse3, rmse4]),\n        \"R-squared\": pd.Series([model1.rsquared,model2.rsquared,model3.rsquared,model4.rsquared]),\n        \"Adj. R-squared\" : pd.Series([model1.rsquared_adj,model2.rsquared_adj,model3.rsquared_adj,model4.rsquared_adj])})\n\nModel_details\n\n###################\n# The best model\n\nfrom sklearn.model_selection import train_test_split\n\ntrain , test = train_test_split(cal, test_size = 0.5 , random_state = 7)\n\nfinalmodel = smf.ols('calories ~ weight', data = train).fit()\nfinalmodel.summary()\n\n# Predict on test data\ntest_pred = finalmodel.predict(pd.DataFrame(test))\n\n\n# Model Evaluation on Test data\ntest_rmse = np.sqrt(((test_pred-test.calories)**2).mean())\ntest_rmse\n\n# Prediction on train data\ntrain_pred = finalmodel.predict(pd.DataFrame(train))\n\n\n# Model Evaluation on train data\ntrain_rmse = np.sqrt(((train_pred-train.calories)**2).mean())\ntrain_rmse\n\n\n\n# Result\n## Applying transformation is decreasing Multiple R Squared Value. So model doesnot need further transformation, Multiple R-squared:  0.911","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}