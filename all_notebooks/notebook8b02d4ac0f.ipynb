{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain_data = pd.read_csv('../input/titanic/train.csv')\ntest_data = pd.read_csv('../input/titanic/test.csv')\n\ntrain_data.head()\n\ntest_data.head()\n\nprint(\"Total number of rows in training data \", train_data.shape[0])\nprint(\"Total number of columns in training data \", train_data.shape[1])\nprint(\"Total number of rows in test data \", test_data.shape[0])\nprint(\"Total number of columns in test data \", test_data.shape[1])\n\nplt.figure(figsize = (13,5))\nplt.bar(train_data.columns, train_data.isna().sum())\nplt.xlabel(\"Columns name\")\nplt.ylabel(\"Number of missing values in training data\")\nplt.show()\n\nplt.figure(figsize = (13,5))\nplt.bar(test_data.columns, test_data.isnull().sum().values, color = 'red')\nplt.xlabel(\"Columns name\")\nplt.ylabel(\"Number of missing values in test data\")\nplt.show()\n\nsns.countplot('Survived', data = train_data)\nplt.show()\n\nsns.countplot('Embarked', data = train_data)\nplt.show()\n\nsns.countplot('Survived', hue = 'Sex', data = train_data)\nplt.plot()\n\nsns.countplot(\"Survived\", hue = 'Pclass', data = train_data)\nplt.show()\n\nsns.countplot('Survived', hue = 'Embarked', data = train_data)\nplt.show()\n\nsns.boxplot('Fare', data = train_data)\nplt.show()\n\nsns.boxplot('Age', data = train_data)\nplt.show()\n\ninterval = 10\nvalue_for_bin = np.ceil((train_data.Age.max() - train_data.Age.min()) / interval).astype(int)\n\nplt.hist(train_data.Age, bins = value_for_bin)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number\")\nplt.show()\n\nplt.figure(figsize = (10,4))\nplt.hist(train_data.Fare, bins = 10, color = 'lime')\nplt.xlabel(\"Fare\")\nplt.ylabel(\"Number\")\nplt.show()\n\ngrid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()\nplt.show()\n\ngrid = sns.FacetGrid(train_data, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()\nplt.show()\n\ncorr_train = train_data.corr()\nsns.heatmap(corr_train)\nplt.show()\n\n((train_data.groupby(['Sex','Survived']).Survived.count() * 100) / train_data.groupby('Sex').Survived.count())\n\n(train_data.groupby(['Pclass','Survived']).Survived.count() * 100) / train_data.groupby('Pclass').Survived.count()\n\n(train_data.groupby(['Embarked','Survived']).Survived.count() * 100) / train_data.groupby('Embarked').Survived.count()\n\ntrain_data.groupby(by=['Survived']).mean()[\"Age\"]\n\ntrain_data.drop('Cabin', axis = 1, inplace = True)\ntest_data.drop('Cabin', axis = 1, inplace = True)\n\ncombined_data = [train_data, test_data]\nfor data in combined_data:\n    print(data.isnull().sum())\n    print('*' * 20)\n    \nfor data in combined_data:\n    data.Age.fillna(data.Age.mean(), inplace = True)\n    data.Fare.fillna(data.Fare.mean(), inplace = True)\n    \ntrain_data.Embarked.fillna('S', inplace = True)\n\ndef change_gender(x):\n    if x == 'male':\n        return 0\n    elif x == 'female':\n        return 1\ntrain_data.Sex = train_data.Sex.apply(change_gender)\ntest_data.Sex = test_data.Sex.apply(change_gender)\n\nchange = {'S':1,'C':2,'Q':0}\ntrain_data.Embarked = train_data.Embarked.map(change)\ntest_data.Embarked = test_data.Embarked.map(change)\n\ntrain_data['Alone'] = train_data.SibSp + train_data.Parch\ntest_data['Alone'] = test_data.SibSp + test_data.Parch\n\ntrain_data.Alone = train_data.Alone.apply(lambda x: 1 if x == 0 else 0)\ntest_data.Alone = test_data.Alone.apply(lambda x: 1 if x == 0 else 0)\n\ntrain_data.drop(['SibSp','Parch'], axis = 1, inplace = True)\ntest_data.drop(['SibSp','Parch'], axis = 1, inplace = True )\n\ntrain_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False).unique().size\n\nfor data in combined_data:\n    data['Title'] = data.Name.str.extract('([A-Za-z]+)\\.', expand = False)\n    data.drop('Name', axis = 1, inplace = True)\n       \ntrain_data.Title.value_counts()\n    \ntest_data.Title.unique()\n\nleast_occuring = [ 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess','Dona',\n       'Jonkheer']\nfor data in combined_data:\n    data.Title = data.Title.replace(least_occuring, 'Rare')\n    \ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor data in combined_data:\n    data['Title'] = data['Title'].map(title_mapping)\n    \ncolumns_to_drop = ['PassengerId','Ticket']\ntrain_data.drop(columns_to_drop, axis = 1, inplace = True)\ntest_data.drop(columns_to_drop[1], axis = 1, inplace = True)\n\nfor dataset in combined_data:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n    \nfor data in combined_data:\n    data.loc[data['Fare'] < 30, 'Fare'] = 1\n    data.loc[(data['Fare'] >= 30) & (data['Fare'] < 50),'Fare'] = 2\n    data.loc[(data['Fare'] >= 50) & (data['Fare'] < 100),'Fare'] = 3\n    data.loc[(data['Fare'] >= 100),'Fare'] = 4\n    \nX_train = train_data.drop(\"Survived\", axis=1)\nY_train = train_data[\"Survived\"]\nX_test = test_data.drop(\"PassengerId\", axis = 1)\nprint(\"shape of X_train\",X_train.shape)\nprint(\"Shape of Y_train\",Y_train.shape)\nprint(\"Shape of x_test\",X_test.shape)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.ensemble import VotingClassifier\n\nKNN=KNeighborsClassifier()\nNAIVE=GaussianNB()\nSVM=SVC()\nDT=DecisionTreeClassifier()\nLR = LogisticRegression()\nRF = RandomForestClassifier()\nEnsemble = VotingClassifier( estimators= [('KNN',KNN),('NB',NAIVE),('SVM',SVM),('DT',DT),('LR',LR),('RF',RF)], voting = 'hard')\n\nEnsemble.fit(X_train,Y_train)\n\npredict = Ensemble.predict(X_test)\n\npredict\n\nsubmit = pd.DataFrame({\"PassengerId\":test_data.PassengerId, 'Survived':predict})\nsubmit.to_csv(\"final_submission.csv\",index = False)\n\nfrom sklearn import metrics\nY_pred_rand = (Ensemble.predict(X_train) > 0.5).astype(int)\nprint('Precision : ', np.round(metrics.precision_score(Y_train, Y_pred_rand)*100,2))\nprint('Accuracy : ', np.round(metrics.accuracy_score(Y_train, Y_pred_rand)*100,2))\nprint('Recall : ', np.round(metrics.recall_score(Y_train, Y_pred_rand)*100,2))\nprint('F1 score : ', np.round(metrics.f1_score(Y_train, Y_pred_rand)*100,2))\nprint('AUC : ', np.round(metrics.roc_auc_score(Y_train, Y_pred_rand)*100,2))\n\nmatrix = metrics.confusion_matrix(Y_train, Y_pred_rand)\nsns.heatmap(matrix, annot = True,fmt = 'g')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T04:15:41.65176Z","iopub.execute_input":"2021-05-22T04:15:41.652105Z","iopub.status.idle":"2021-05-22T04:15:46.402516Z","shell.execute_reply.started":"2021-05-22T04:15:41.652072Z","shell.execute_reply":"2021-05-22T04:15:46.401766Z"},"trusted":true},"execution_count":null,"outputs":[]}]}