{"cells":[{"metadata":{},"cell_type":"markdown","source":"The Mall Customer Segmentation task is to categorize customers into similar groups which will then inform marketing strategies based on group attributes. Data for this task was gathered from membership cards and consists of customer's age, income, and a spending score. The spending score was generated from customer behaviors captured by the membership cards. The methodolgoy for creating the spending score was not given.\n\nPresumably a viable clustering scheme can be developed on the data and customers can be segmented. Targeted efforts, such as advertisements, discounts, or benefits can be tailored to customers according to their clusters.\n\nI wanted to take a slightly different approach to this problem. The customer score is generated from some unknown scoring process after a membership card has been issued. If the scores are created from customer spending habits and behavior, then some period of time must pass before the necessary data is collected to calculate the spending scores. \n\nI'd like to build a model that predicts if a new card holder will be given a high spending score. Having this information on the front end of the spending score creation might give the mall a competetive edge not found in an after-the-fact classification scheme. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#Checking for normal distribution\nfrom statsmodels.graphics.gofplots import qqplot\nfrom scipy.stats import shapiro\n\n#Cross Validation, Normalization, and adjusted sampling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\n\n#My Model\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\n#Model Evaluation\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix,classification_report\nfrom sklearn import metrics\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Mall_Customers.csv')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.set_index('CustomerID',inplace=True)\ndf.columns=['Gender','Age','Annual_Income','Spending_Score']\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gender will be converted to nominal data where x is in {0,1} and 1 = to male."},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating binary gender categories\ndf['Gender']=df['Gender'].astype('category').cat.codes\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for null\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My intent is to segment the mall's customers into groups based on their spending score. I'm going to evaluate the spending score distribution to assess what likely cutoff points I can find."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(ncols =3, figsize =(35,10))\nsns.boxplot(df.Spending_Score, ax=ax1)\nsns.distplot(df.Spending_Score,ax=ax2)\n#add ';' at the end to stop repeating charts. this is a notebook issue.\nqqplot(df.Spending_Score, line ='s',ax=ax3);\n\nstat, p = shapiro(df.Spending_Score)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Spending_Score.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The p-value of the Shapiro-Wilk test is .0002 which rejects the null hypothesis. This means the distribution is normal. Quantile-Quantile (QQ) plots are a visual method to assess the distribution of a dataset. QQ plots compare a dataset's quantiles against a set of normally distributed quantiles. The dataset's quantiles should closely follow the diagonal x=y line. My QQ plot has loose tails but is largely following the x=y line. \n\nThe distribution plot for the Spending Score shows the bins are slightly skewed right which starts near spending score 80. Additionally, the 75% percentile is at spending score 73. I'm not comfortable with selecting 73 as the cutoff score because a strong separation appears at about 80 in the distribution plot. Instead I'm going to cut the difference between the 75% and the visual block at 80 by selecting spending scores at or above the second standard deviation as my target. The second deviation is 76."},{"metadata":{"trusted":true},"cell_type":"code","source":"sigma=df.Spending_Score.std()\nmean= df.Spending_Score.mean()\nTwodev= sigma+mean\nTwodev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Target']= np.where(df.Spending_Score<Twodev,0,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm curious to see the distribution of Targets and Non-Targets across both Age and Income. The charts are at different scales which makes the distributions seem to equal in height, but that's not correct. Age seems like a really good predictor and annual income has a slight inverse effect on target/non-target."},{"metadata":{"trusted":true},"cell_type":"code","source":"chart=df.drop([\"Spending_Score\"],axis=1)\n\nfig,(ax1,ax2) = plt.subplots(ncols=2, figsize=(16,5))\n\nsns.kdeplot(chart.Age[chart.Target==1], label='Target', shade=True, ax=ax1)\nsns.kdeplot(chart.Age[chart.Target==0], label='Non_Target', shade=True, ax=ax1)\nax1.set_ylabel('Distribution')\nax1.set_xlabel('Age')\n\nsns.kdeplot(chart.Annual_Income[chart.Target==1], label='Target', shade=True, ax=ax2)\nsns.kdeplot(chart.Annual_Income[chart.Target==0], label='Non-Target', shade=True, ax=ax2)\nax2.set_ylabel('Distribution')\nax2.set_xlabel('Annual Income')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='Annual_Income',y='Age', hue='Target',data=chart,fit_reg=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm running a supervised classification system for binary data. During my visual inspection of the data I can see the relationships are less linear and therefore perhaps SVM would be the best classification option. SVM will be using my vectors to create a decision boundary between positive and negative outcomes, therefore vector magnitude is relevant. Large distance differences between variables could make significant differences, therefore I'm going to scale the dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#SCALED\nscaler = StandardScaler()\nmodel_df=df.drop(['Target','Spending_Score'],axis=1)\nscaled_df= scaler.fit_transform(model_df)\nscaled_df=pd.DataFrame(scaled_df)\nscaled_df.columns=('Gender','Age','Annual_Income')\n\n#Train, Test, Split\nX_train, X_test, y_train, y_test = train_test_split(scaled_df,\n                                                    df['Target'],\n                                                    test_size=0.3,\n                                                    random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(ncols=2, figsize=(15, 5))\nax1.set_title('Before Scaling')\nsns.kdeplot(df['Age'], ax=ax1)\nsns.kdeplot(df['Annual_Income'], ax=ax1)\n\nax2.set_title('After Standard Scaler')\nsns.kdeplot(scaled_df['Age'], ax=ax2)\nsns.kdeplot(scaled_df['Annual_Income'], ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall earlier that my distribution for the classifier totaled 36 positives and 164 negatives. I'm going to balance this data for a better 50/50 set. SVM works better with a balanced set."},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=100)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10,100,1000],\n              'gamma': [100,10,1,.1,.01], \n              'kernel': ['rbf', 'sigmoid' ]} \ngrid_search = GridSearchCV(SVC(),param_grid,refit=True,verbose=1)\ngrid_search.fit(X_train_res,y_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_predictions = grid_search.predict(X_test)\ngrid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,grid_predictions))\nprint(\"Accuracy score: {}\".format(accuracy_score(y_test,grid_predictions)))\nprint(\"Recall score: {}\".format(recall_score(y_test,grid_predictions)))\nprint(\"Precision score: {}\".format(precision_score(y_test,grid_predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, grid_predictions)\nsns.heatmap(cm, annot=True); #annot=True to annotate cells\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I define success for this model in two ways. First, an accurracy score of 80% is successful and meaningful because the model was built on a balanced dataset. Second, the moderate to high recall rate is successful because the model is correctly identifying 73 out of 100 true observations.\n\nI believe my model has demonstrated that sufficient data exists to forecast whether or not a new card holder will later become a top 15% spender.\n\nEnsuring the model is correct would require a randomized control experiement on new card holders, wherein new card holders are randomly assigned to a treatment group or control group. A/B testing with some quantifiable goal, such as the rate of spending score increases, the quantities that treatment vs control are spending, or customer survey feedback could inform the value of this model."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}