{"cells":[{"metadata":{"_uuid":"729a392d2eff9d1a67eb73c4af20ada55a90b7f6"},"cell_type":"markdown","source":"# Introduction\n\n<p>\n\nMy approach to this project was to explore the data firstly, then draw out the distinct questions that come to mind a first glance of the data:\n\n<ul>\n  <li>Has crime changed over the years? Is it decreasing?</li>\n  <li>Which are the highest and lowest crimes?</li> \n  <li>What Skewed Distribution is this dataset?</li>\n  <li>Is there a particular day(s) of the week where crimes occur more?</li>\n  <li>Is there a trend of crime per year on all crime?</li>\n  <li>Which neighbourhood of the city are the hotspots for crime?</li> \n  <li>Has crime types change over the years? Have they decreased?</li>\n</ul>    \n\nThe outcome to all this would be to answers the questions that came up in the analysis in the data exploration, identify high crime areas, and predicting crimes from historical data of data-time and location.  \n</p>\n\n# Selected Techniques\nAcquiring the data from the City of Vancouver Open Data Catalogue website, the data custodian is the Vancouver Police Department where the departments GeoDASH Crime Map is the authoritative source.\n\nUsing Jupyter Notebook and Python is a great and flexible tool to create readable analyses where code, images, comments and plots are kept in one place. I started off by adding some Styling (CSS) to my project. I then proceed with my code to import all the libraries needed. \n\nThe next approach was to prepare the data and in doing so I needed to identify any anomalies and missing data. Cleaning the data by filling in defaults of the blank rows in each column as well as enriching the data by adding new columns. \n\nI then was ready to explore and visualize the dataset, along with implementing the algorithm techniques.\n\n# Technique Implementation\nIn any analysis, a great guide or roadmap keeps things on track and defined the final outcome. \nA summary list of roadmap goals:\n\n- Exploring Data set\n- Heatmap\n- Decision Tree"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"#import gmplot\nimport numpy as np # linear algebra\nimport pyproj as pp\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport plotly.plotly as py\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cross_validation import train_test_split\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cccc9e6a87feab9ea18df62a8e06314e34907de7"},"cell_type":"markdown","source":"### Cleaning and Transforming the Dataset \n<ul>\n         <li> Defaulting records by filling the blank data for \"HOUR\" column to \"00\".</li>\n         <li> Blank records for \"NEIGHBOURHOOD\" as \"N/A\".</li>\n         <li> Blank records for \"HUNDRED_BLOCK\" as \"N/A\".</li>\n         <li> Deleting \"MINUTE\" column as predicting information to the actual minute is not necessary here.</li>\n         <li> Adding \"NeighbourhoodID\" column as a category key ID for Neighbourhood.</li>\n         <li> Adding \"CrimeTypeID\" column as a category key ID for \"TYPE\" as in type of crime.</li>\n         <li> Adding \"Incident\" column as a row count to keep track of incident totals per crime type, etc.</li>\n         <li> Combining date fields and adding a column \"Date\" format.</li>\n         <li> Using \"Date\" to get weekday name's.</li>\n         <li> Before excluding 2017 data from the main DataFrame, creating another DataFrame just for 2017 data</li>\n         <li> Excluded data for the current year 2017, in order to work with full sets of years.</li>\n    </ul>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"# Importing Dataset into a DataFrame\ndfcrime = pd.read_csv('..//input/crime.csv')\n\n# Cleaning & Transforming the data\ndfcrime['HOUR'].fillna(00, inplace = True)\ndfcrime['NEIGHBOURHOOD'].fillna('N/A', inplace = True)\ndfcrime['HUNDRED_BLOCK'].fillna('N/A', inplace = True)\ndel dfcrime['MINUTE']\ndfcrime['NeighbourhoodID'] = dfcrime.groupby('NEIGHBOURHOOD').ngroup().add(1)\ndfcrime['CrimeTypeID'] = dfcrime.groupby('TYPE').ngroup().add(1)\ndfcrime['Incident'] = 1\ndfcrime['Date'] = pd.to_datetime({'year':dfcrime['YEAR'], 'month':dfcrime['MONTH'], 'day':dfcrime['DAY']})\ndfcrime['DayOfWeek'] = dfcrime['Date'].dt.weekday_name\ndfcrime['DayOfWeekID'] = dfcrime['Date'].dt.weekday\ndfpred = dfcrime[(dfcrime['YEAR'] >= 2017)]\ndfcrime = dfcrime[(dfcrime['YEAR'] < 2017)]\n\n# Calling a dataframe results\ndfcrime.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8b5f64563c62919e8aaeb99273ad483d0444a75b"},"cell_type":"markdown","source":"## 1. Exploration and Visualization\n### Has crime changed over the years? Is it decreasing?\nBy the graph below we can determine that crime has decreased over the years with a slight uptake in 2016. Having it been an anomaly or an event that occurred this spike in the data."},{"metadata":{"trusted":true,"_uuid":"870f2df59d9976bd54cd9ecfe07a088974e3221a","collapsed":true},"cell_type":"code","source":"%matplotlib inline\n# Setting plot style for all plots\nplt.style.use('seaborn')\n\n# Count all crimes and group by year\ndfCrimeYear = pd.pivot_table(dfcrime, values=[\"Incident\"],index = [\"YEAR\"], aggfunc='count')\n\n# Graph results of Year by Crimes\nf, ax = plt.subplots(1,1, figsize = (12, 4), dpi=100)\nxdata = dfCrimeYear.index\nydata = dfCrimeYear\nax.plot(xdata, ydata)\nax.set_ylim(ymin=0, ymax=60000)\nplt.xlabel('Year')\nplt.ylabel('Number of Crimes')\nplt.title('Vancouver Crimes from 2003-2017')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a2067981746e93304ccffa5977276fe6746b50"},"cell_type":"markdown","source":"### Which are the highest and lowest crimes?\n\n<p>Noticing the bar graph, the evidence is that \"Theft from Vehicle\" is the highest crime with \"Homicide\" being the lowest crime from 2003 - 2017. </p>"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"85173baa3acf655679460b8569405452c504c180","collapsed":true},"cell_type":"code","source":"%matplotlib inline\n# Pivoting dataframe by Crime Type to calculate Number of Crimes\ndfCrimeType = pd.pivot_table(dfcrime, values=[\"Incident\"],index = [\"TYPE\"], aggfunc='count')\n\ndfCrimeType = dfCrimeType.sort_values(['Incident'], ascending=True)\n\n# Create bar graph for number of crimes by Type of Crime\ncrimeplot = dfCrimeType.plot(kind='barh',\n               figsize = (6,8),\n               title='Number of Crimes Committed by Type'\n             )\n\nplt.rcParams[\"figure.dpi\"] = 100\nplt.legend(loc='lower right')\nplt.ylabel('Crime Type')\nplt.xlabel('Number of Crimes')\nplt.show(crimeplot)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fb45e16b38d507eb83d8060dacbaaf1889cfbeb"},"cell_type":"markdown","source":"### What Skewed Distribution is this dataset?\n\nThis is a right skewed distribution or referred to as a positive skewness. It would be great to see how many arrests are made per year and cased closed to offset the crimes they have per year or per crime. From that theory we could see if we might get a normal distribution from or even a left skewed distribution (more arrests made in some years than crimes)."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"066899bb4b106d29a2ce32915bf8cb8b0402ecbb","collapsed":true},"cell_type":"code","source":"%matplotlib inline\n# Count of Incidents per Year By Type\ndfPivYearType = pd.pivot_table(dfcrime, values=[\"Incident\"],index = [\"YEAR\", \"TYPE\"], aggfunc='count')\n\ndfCrimeByYear = dfPivYearType.reset_index().sort_values(['YEAR','Incident'], ascending=[1,0]).set_index([\"YEAR\", \"TYPE\"])\n\n# Plot data on box whiskers plot\nNoOfCrimes = dfCrimeByYear[\"Incident\"]\nplt.boxplot(NoOfCrimes)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b3b5fec3d0dc131167f32d8f82ca843394edbfd"},"cell_type":"markdown","source":"### Is there a particular day(s) of the week where crimes occur more?\n\n<p>Weekends do look higher than weekdays of when crimes happen most.</p>"},{"metadata":{"trusted":true,"_uuid":"f7ef254c8e538a5ce94b04716f48a483cf189c52","collapsed":true},"cell_type":"code","source":"%matplotlib inline\n# Adding Days Lookup\ndays = ['Monday','Tuesday','Wednesday',  'Thursday', 'Friday', 'Saturday', 'Sunday']\n\n# Grouping dataframe by Day of Week ID and plotting\ndfcrime.groupby(dfcrime[\"DayOfWeekID\"]).size().plot(kind='barh')\n\n# Customizing Plot \nplt.ylabel('Days of the week')\nplt.yticks(np.arange(7), days)\nplt.xlabel('Number of crimes')\nplt.title('Number of Crimes by Day of the Week')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"182a3e9256442862418a7242986b31165c7943a2"},"cell_type":"markdown","source":"### Is there a trend of crime per year on all crime?\n\n<p>\n<ul>\n    <li>At first glance, you can see that crime is increasing as the heapmap gets darker moving to 2016</li>\n    <li>Homicide, Mischef, Vehicle collisions(All collisions) crimes look constant on the heatmap of the years</li>\n    <li>Studying the heatmap, 2010-2013 seem to display the lowest crime years </li>\n</ul>\n</p>"},{"metadata":{"trusted":true,"_uuid":"7d0343eaad8f37aeedfde0accd6a366a72776f47","collapsed":true},"cell_type":"code","source":"%matplotlib inline\n# Create a pivot table with month and category. \ndfPivYear = dfcrime.pivot_table(values='Incident', index='TYPE', columns='YEAR', aggfunc=len)\n\nfig, ax = plt.subplots(1, 1, figsize = (12, 6), dpi=300)\nplt.title('Type of Crime By Year', fontsize=16)\nplt.tick_params(labelsize=10)\n\nsns.heatmap(\n    dfPivYear.round(), \n    linecolor='lightgrey',\n    linewidths=0.1,\n    cmap='viridis', \n    annot=True, \n    fmt=\".0f\"\n);\n\n# Remove labels\nax.set_ylabel('Crime Type')    \nax.set_xlabel('Year')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d693e344c468690c12cb129660b06252945a1ad"},"cell_type":"markdown","source":"## 2. Heatmap\n### Which neighbourhood of the city are the hotspots for crime?\n\nWe can't work with the full dataset as not all coordinates were logged correctly but we can still get a good idea which neighbourhoods are the crime hot-spots. Vancouver CBD being the most noticeable, Kitsilando, Kerrisdale, Sunset(South Vancouver) and Marpole. \n<br></br>\n\nAttempted to acquire data of population within Vancouver city (no solid dataset is available), I was trying to draw up a correlation of population density to the crime per location. "},{"metadata":{"trusted":true,"_uuid":"422dcdf8d1f7daddb4f2d003bc3e87b5355ce50a","collapsed":true},"cell_type":"code","source":"'''\nimport gmplot \n# Clean the data of zero points of latitude amd longitude as we can not plot those coordinates\ndfCoord = dfcrime[(dfcrime.Latitude != 0.0) & (dfcrime.Longitude != 0.0)]\n\n# Assign datapoints in variables\nlatitude = dfCoord[\"Latitude\"]\nlongitude = dfCoord[\"Longitude\"]\n\n# Creating the location we would like to initialize the focus on. \n# Parameters: Lattitude, Longitude, Zoom\ngmap = gmplot.GoogleMapPlotter(49.262, -123.135, 11)\n\n# Overlay our datapoints onto the map\ngmap.heatmap(latitude, longitude)\n\n# Generate the heatmap into an HTML file\ngmap.draw(\"crime_heatmap.html\")\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5cf1f007f0531f3c275f59660beba8c02e01e83f"},"cell_type":"markdown","source":"<i>Code above produces the heatmap shown below in a HTML file and I then took a screen shot of the image</i>"},{"metadata":{"_uuid":"66078cd807b7c6c445983510713b5bfe079f43fa"},"cell_type":"markdown","source":"![vancouverheatmap.PNG](http://<blockquote class=\"imgur-embed-pub\" lang=\"en\" data-id=\"a/jm6qq8C\"><a href=\"//imgur.com/jm6qq8C\"></a></blockquote><script async src=\"//s.imgur.com/min/embed.js\" charset=\"utf-8\"></script>)\n\n<figure>\n  <img src=\"\" style=\"width:60%;border-radius: 8px\">\n  <figcaption style=\"text-align: center;\">Fig. 1 - Vancouver Crime Heatmap</figcaption>\n</figure>","attachments":{}},{"metadata":{"_uuid":"8ab6da769975ad5efc77c4c3f571242550c31dad"},"cell_type":"markdown","source":"### Has crime types change over the years? Have they decreased? \n\n<p>There is a mixture of events per crime. At a glance it can be perceived that the majority of the crimes are decreasing over the years. Studying it closer the crime though to have decrease seems to be on the rise again. To determine this, I would have to look at other variables that influence the each crime from weather, arrests, sales, construction in the area, etc.  \n<br></br>\n\nContinuing with the data set I can make some theoretical correlations, comparably of when one crime increases another  may decrease. For example, has Police presence decreased, are more people buying bicycles or merely finding it easier to travel to work with a bicycle, thus the drop of vehicle theft has decreased and why Bicycle theft may have increased. Awareness campaigns of people rights has maybe increased over the years and notably \"Offence Against a Person\" has decreased. </p>"},{"metadata":{"trusted":true,"_uuid":"e1794583173b7d668f0232397307302507a505c7","collapsed":true},"cell_type":"code","source":"%matplotlib inline\n# Crime count by Category per year\ndfPivCrimeDate = dfcrime.pivot_table(values='Incident'\n                                     ,aggfunc=np.size\n                                     ,columns='TYPE'\n                                     ,index='YEAR'\n                                     ,fill_value=0)\nplo = dfPivCrimeDate.plot(figsize=(15, 15), subplots=True, layout=(-1, 3), sharex=False, sharey=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e0b7e4eb67681f86f13f340ab5943babc9a218e"},"cell_type":"markdown","source":"## 3. Decision Tree\n### Create Training And Test Data Sets\n\n<p>We can look at the shape of all the data to make sure we did everything correctly. We expect the training features number of columns and observations to match the testing feature number of columns and observations to match for the respective training and testing features and the labels. \n<br></br>\n<br></br>\n\nProceeding with the test and training data to determine a targeted prediction the Decision tree Classifier algorithm will be used.\n</p>\n"},{"metadata":{"trusted":true,"_uuid":"7394b6f85a567a35568f9befbf191893605aec39","collapsed":true},"cell_type":"code","source":"# New DataFrame to filter out columns needed\ndfRandomF = dfcrime\n\n# Split data for training and testing\n#dfRandomF['train'] = np.random.uniform(0, 1, len(dfRandomF)) <= .70\n\nX = dfRandomF[['YEAR', 'MONTH', 'DAY','HOUR', 'NeighbourhoodID']]\n\nY = dfRandomF[['TYPE']]\n\n# To create a training and testing set, I am splitting the data\n# by 70% training and 30% testing\nX_train , X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 5)\n\nprint('Number of observations and columns in the training data:', X_train.shape, y_train.shape)\nprint('Number of observations and columns in the testing data:',X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"867208413df9b6da00ec9612c3f970ac1f4c150f"},"cell_type":"markdown","source":"### Decision Tree Classifier with criterion gini index"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7dacf01ec77575def41522b9cbd508343d2e68d6","collapsed":true},"cell_type":"code","source":"clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 5,\n                               max_depth=5, min_samples_leaf=8)\nclf_gini.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"909d38992368ea0c4d0ab2a2d342467502123cc0"},"cell_type":"code","source":"# Adding prediction test\ny_pred_gn = clf_gini.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98476da77f63694f1a75bae52e9a7d6df4ba359a"},"cell_type":"markdown","source":"### Decision Tree Classifier with criterion information gain"},{"metadata":{"trusted":true,"_uuid":"de8e14a00bd34b6b2d8ea28df457300aca87e8da","collapsed":true},"cell_type":"code","source":"clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 5,\n                                    max_depth=5, min_samples_leaf=8)\nclf_entropy.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"978732ec4e6c09b2cbaaa482fe8a9ae64ed9a050"},"cell_type":"code","source":"# Adding prediction test\ny_pred_en = clf_entropy.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f3c289ee2a37f96153119208ffb1acd7f71581d","collapsed":true},"cell_type":"code","source":"# Random values for prediction \nclf_gini.predict([[2017,1,5,15.0,12]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e840f3a21fb2563f0199b82001cd5aa35d4a4b04","collapsed":true},"cell_type":"code","source":"# Using the same parameters for predition\ndfpred[(dfpred['YEAR'] == 2017) & \n        (dfpred['MONTH'] == 1) & \n        (dfpred['DAY'] == 5) & \n        (dfpred['HOUR'] == 15.0) &\n        (dfpred['NeighbourhoodID'] == 12)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6da497d154ce3622c55ffbdbd3b0e06087c0d5a0"},"cell_type":"markdown","source":"### Using the same parameters and excluding the Hour there is a 20% chance of accuracy on my selection."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3ad5ad8bdb6e7cbdc412d97e3b12869be76ef2ec","collapsed":true},"cell_type":"code","source":"dfpred[(dfpred['YEAR'] == 2017) & \n        (dfpred['MONTH'] == 1) & \n        (dfpred['DAY'] == 5) & \n        (dfpred['NeighbourhoodID'] == 12)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af9a931b7c89f2e810d715c8f06df7cba74d2d1b","collapsed":true},"cell_type":"code","source":"print ('Accuracy is', accuracy_score(y_test,y_pred_gn)*100, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a8833702ba21049192f05f61a190823f7ef4a13","collapsed":true},"cell_type":"code","source":"print ('Accuracy is', accuracy_score(y_test,y_pred_en)*100, '%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bf3696d18fbd03dc7a33925eb3a644b11943e57"},"cell_type":"markdown","source":"## Reference\n\nAnon., n.d. Open Data Pilot Project, City of Vancouver. [Online] Available at: http://data.vancouver.ca/datacatalogue/crime-data.htm [Accessed 14 5 2018].\n\nOsaku, Wilian, 2017. EDA of Crime in Vancouver (2003 - 2017)\nAvailable at: https://www.kaggle.com/wosaku/eda-of-crime-in-vancouver-2003-2017\n[Accessed 14 5 2018].\n\nSaxena,Rahul., 2017. Building Decision Tree Algorithm In Python With Scikit Learn. [Online] \nAvailable at: http://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/\n[Accessed 02 7 2018].\n\nJonathan P., 2018. How to Generate a Geographical Heatmap with Python. [Online] \nAvailable at: https://eatsleepdata.com/data-viz/how-to-generate-a-geographical-heatmap-with-python.html\n[Accessed 02 7 2018].\n\nKoehrsen, William., 2017. Random Forest in Python. [Online] \nAvailable at: https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n[Accessed 02 7 2018].\n\nA special thanks for Philip Mostert and Leon Van Vuuren for some coding guidance."},{"metadata":{"trusted":true,"_uuid":"dd773245a56ef5da08af6c3f7bbc67c8714e7b26","collapsed":true},"cell_type":"code","source":"'''\n# Style Report\nfrom IPython.core.display import HTML\ncss_file = 'style.css'\nHTML(open(css_file, 'r').read())\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}