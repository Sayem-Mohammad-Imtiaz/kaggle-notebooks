{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_true = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")\ndf_fake = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_true.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_true[\"true\"] = 1\ndf_fake[\"true\"] = 0\n\ndf = pd.concat([df_true,df_fake])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"title\"] = df[\"title\"]+\" \"+df[\"text\"]+\" \"+df[\"subject\"]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['date']\ndel df['text']\ndel df['subject']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nplt.figure(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wc = WordCloud (max_words = 30000, stopwords = set(stopwords.words(\"english\"))).generate(\" \".join(df.title))\nplt.imshow(wc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom nltk.stem.porter import PorterStemmer\nX = df.title.values\ny = df.true.values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = PorterStemmer()\n\ncorpus = []\n\nfor i in range (len(X)):\n    sent = re.sub(\"[^A-Za-z]\", \" \", X[i])\n    sent = sent.lower().split()\n    sent = [word for word in sent if word not in set(stopwords.words('english'))]\n    sent = \" \".join(sent)    \n    corpus.append(sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(corpus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(max_features = 10000)\nX_processed = cv.fit_transform (corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size= 0.2,random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the Data in train and test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size = 0.2\nX_train = X_processed[:int(len(X_processed)*(1-test_size))]\nX_test = X_processed[int(len(X_processed)*(1-test_size)):]\ny_train = y[:int(len(X_processed)*(1-test_size))]\ny_test = y[int(len(X_processed)*(1-test_size)):]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training model in multiple folds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = 10)\ncvscores = []\n\nfor train, test in kfold.split(X_train, y_train):\n    ann = Sequential ()\n    ann.add(Dense(output_dim = 128,  activation = 'relu', input_dim = 10000))\n    ann.add(Dense(output_dim = 4,  activation = 'relu', input_dim = 10000))\n    ann.add(Dense(units = 1 , activation = 'sigmoid'))\n\n    ann.compile (optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    ann.fit(X_train[train], y_train[train], batch_size = 100,epochs = 5)\n    \n    scores = ann.evaluate(X_train[test], y_train[test], verbose=0)\n    print(\"%s: %.2f%%\" % (ann.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculating the the Accuracy in the Test Set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}