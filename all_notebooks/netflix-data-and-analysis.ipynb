{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport nltk\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom  wordcloud import WordCloud\nimport matplotlib as plt\nimport random\nfrom collections import Counter\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Get a look at the Data**"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/netflix-shows/netflix_titles.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic and Quick Analysis\n"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Helper Functions**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"def generic_filter(colName, value):\n    return df[df[colName]==value]\n\ndef get_uniques(df, colName):\n    lst = df[colName].unique().tolist()\n    #remove NaN values\n    cleanedList = [x for x in lst if x == x]\n    return cleanedList\n\ndef generic_get(df, colname):\n    if colname == 'listed_in':\n        return get_genres(df)\n    return df[colname]\n\ndef get_length(colName):\n    return len(df[colName])\n\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Specific Functions**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"\ndef get_num_titles_together(actor, director):\n    x =df[df['cast'].str.count(actor)>0]\n    z=x[x['director'].str.count(director)>0]\n    return len(z)\n\ndef get_genres(df):\n    genre_list = get_uniques(df, 'listed_in')\n    new_list=[]\n    for grouped_genres in genre_list:\n        if ',' in grouped_genres:\n            s=grouped_genres.split(',')\n            for genre in s:\n                if(genre[0]==' '):\n                    genre=genre[1:]\n                new_list.append(genre)\n        else:\n            new_list.append(grouped_genres)\n\n    return list(new_list)\n\ndef get_actors(df):\n    actor_list = get_uniques(df, 'cast')\n    new_list=[]\n    for grouped_actors in actor_list:\n        if ',' in grouped_actors:\n            s=grouped_actors.split(',')\n            for actor in s:\n                if(actor[0]==' '):\n                    actor=actor[1:]\n                new_list.append(actor)\n        else:\n            new_list.append(grouped_actors)\n\n    return list(new_list)\n\n\ndef get_directors(df):\n    director_list = get_uniques(df, 'director')\n    new_list=[]\n    for grouped_director in director_list:\n        if ',' in grouped_director:\n            s=grouped_director.split(',')\n            for director in s:\n                if(director[0]==' '):\n                    director=director[1:]\n                new_list.append(director)\n        else:\n            new_list.append(grouped_director)\n\n    return list(new_list)\n\n\ndef get_unique_genres(df):\n    return list(set(get_genres(df)))\n\ndef get_unique_countries(df):\n    c = get_uniques(df,'country')\n    new_list=[]\n    for grouped_countries in c:\n        if type(grouped_countries) != float:\n            grouped_countries = grouped_countries.split(',')\n            for country in grouped_countries:\n                if country != '':\n                    if(country[0]==' '):\n                        country=country[1:]\n                new_list.append(country)\n    \n    return list(set(new_list))[1:]\n\ndef get_content_by_country(country):\n      return df[df['country'].str.contains(country, na=False)]\n\n\ndef get_words_from_genre(genre):\n    sub = generic_filter('listed_in', genre)\n    descriptions = generic_get(sub, 'description')\n    descriptions = [x for x in descriptions if x not in stopwords.words('english')]\n\n    text=[]\n    sp = stopwords.words('english')\n    sp.append(\"-\")\n    for  description in descriptions:\n        words=description.split(' ')\n        for word in words:\n           if word not in sp:\n                if '\"' in word:\n                    word.replace('\"', '')\n                text.append(word)\n    text=(\" \").join(text)            \n    return(text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Functions that Plot**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"\n\ndef plot_most_popular_genres(country, n):\n    country_content = get_content_by_country(country)\n    genres= generic_get(country_content, 'listed_in')\n    genres = Counter(genres)\n    most_common_genres=genres.most_common(n)\n    temp = pd.DataFrame(most_common_genres, columns =['Genre','Count']) \n    temp.plot.bar(x='Genre', y='Count', title='Top '+ str(n) +' Popular Genres in '+ country)\n\ndef plot_most_popular_ratings(country, n):\n    country_content = get_content_by_country(country)\n    ratings = generic_get(country_content, 'rating')\n    ratings = Counter(ratings)\n    most_common_ratings = ratings.most_common(n)\n    temp = pd.DataFrame(most_common_ratings, columns =['Rating','Count']) \n    temp.plot.bar(x='Rating', y='Count', title='Top '+ str(n) +' Popular Ratings in '+ country)\n\ndef plot_show_type_over_time(df, years):\n    data={'Movies':[],\n         'TV Shows':[]}\n    for year in years:\n        temp=df[df['release_year']==year]\n        \n        tv=temp[temp['type']==\"TV Shows\"]\n        movies= temp[temp['type']==\"Movie\"]\n        data['Movies'].append()\n        num_tv = Counter(tv)\n        num_movie= Counter(movies)\n        \n        data['Movies'].append(num_movie)\n        data['TV Shows'].append(num_tv)\n        \n    \n    plot= pd.Dataframe(data ,years)\n    plot.plot.line()\n\ndef genre_wordcloud(genre):\n    try:\n        text = get_words_from_genre(genre)\n        wordcloud = WordCloud(max_font_size=40).generate(text)\n        plt.pyplot.figure()\n        plt.pyplot.imshow(wordcloud, interpolation=\"bilinear\")\n        plt.pyplot.axis(\"off\")\n        plt.pyplot.title(genre)\n        plt.pyplot.show(wordcloud)\n    except:\n        return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Understanding what content is available in different countries\n\n"},{"metadata":{},"cell_type":"markdown","source":"We can look at the amount of content by genre available in each country. I collect a random sample from the list of unique countries and use a helper function to plot that countries data based on 'n' genres. Some countries only have shows with fewer than 'n' genres."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size=5\n\nunique_countries =get_unique_countries(df)\n\nsample= random.sample(unique_countries, sample_size)\n\nnumber_of_genres_to_plot=5\n\nfor country in sample:\n    plot_most_popular_genres(country, number_of_genres_to_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similar to the previous example, we can look at the count of the top n ratings for a sample of countries. Some countries have fewer than 'n' ratings."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size=5\n\nunique_countries =get_unique_countries(df)\n\nsample= random.sample(unique_countries, sample_size)\n\ntop_n_ratings=5\n\nfor country in sample:\n    plot_most_popular_ratings(country, top_n_ratings)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Identifying similar content by matching text-based features\n"},{"metadata":{},"cell_type":"markdown","source":"Lets look at the most popular words used in the descriptions of titles and generate a wordcloud based on the genre. I use a helper function to append a list of words in each show's description, according to genre. I then remove stopwords based on the english nltk.stopwords list. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngenres = get_unique_genres(df)\nfor genre in genres:\n    genre_wordcloud(genre)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can analyze each genre to generate a heat map based on the intersection of the words in their descriptions. "},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"\nintersection_matrix = np.empty(shape=(len(genres),len(genres)))\n\nfor i in range(len(genres)):\n    text1 = set(get_words_from_genre(genres[i]))\n    for j in range(len(genres)):\n        text2 = set(get_words_from_genre(genres[j]))\n        intersect = len(text2.intersection(text1))\n        intersection_matrix[i,j]=int(intersect)\n\nheatmap = pd.DataFrame(intersection_matrix.astype(int), index=genres, columns=genres)\n\n'''\nSome genres only contain descriptions that are not in english\nunfortunately cleaning the list with english stopwords makes the text return an empty list\nwe want to remove the rows and columns that returned an empty list and would have 0 as intersection. \n'''\n\nheatmap = heatmap[(heatmap.T != 0).any()]\nheatmap = heatmap.T[(heatmap != 0).any()].T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting the style for the dataframe that will be used as a heatmap. "},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"\nheatmap.style.background_gradient(cmap='Greens')\\\n    .set_caption('Lengths of Set Intersections of Words in Genre Descriptions')\n        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Has Netflix been increasingly focusing on TV rather than movies in recent years?"},{"metadata":{},"cell_type":"markdown","source":"Collect a list of `years` from the `years_added` column"},{"metadata":{"trusted":true},"cell_type":"code","source":"dates=list(df['date_added'])\nyear_data={'year_added':[]}\nyears=[]\nfor date in dates:\n    if date == date:\n        year = date[len(date)-4: len(date)]\n        years.append(int(year))\n        year_data['year_added'].append(year)\n    else:\n        print(years[len(years)-1])\n        year_data['year_added'].append('0')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using a boxplot to show the distribution of years. We can see that:\n* **median** is 2018\n* **Q1** 2014-2017\n* **Q2** 2017-2018\n* **Q3** 2018-2019\n* **Q4** 2019-2020\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, ax1 = plt.pyplot.subplots()\nax1.set_title('Distribution of Years that Titles are Added')\nax1.boxplot(years,0, '',vert=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To analyze the data, I am going to assume that the minimum year would be the median and filter out years that dont meet this criteria"},{"metadata":{"trusted":true},"cell_type":"code","source":"median = 2018\nmin_year = median\nrecent_years = [year for year in years if year >= median ]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yr ={\"year_added\":years}\ndf['year_added']=year_data['year_added']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I use  a sub dataframe to get only the columns we need and then use a lambda expression to search for any substring in any row that is in the `recent_years` \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"recent_years_str = list(map(str, recent_years))\nsub = df[['type','year_added']]\nmask = sub.year_added.apply(lambda x: any(item for item in recent_years_str if item in x))\nsub[mask]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets take a look at the growth of TV titles "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_show_type_over_time(x, years):\n    tv_shows=[]\n    movie=[]\n    diff=[]\n    \n    for year in years:\n        temp=x[x['year_added']==str(year)]\n        \n        tv=temp[temp['type']==\"TV Show\"]\n        movies= temp[temp['type']==\"Movie\"]\n        \n        movie.append(len(movies))\n        tv_shows.append(len(tv))\n        diff.append(len(tv)/len(movies))\n        \n    plot = pd.DataFrame({\n   '':diff\n   }, index=years)\n    plot.plot.line()\n\nv=list(sub['year_added'].unique())\nv.sort()\nv.remove(\"0\")\nplot_show_type_over_time(sub, v)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}