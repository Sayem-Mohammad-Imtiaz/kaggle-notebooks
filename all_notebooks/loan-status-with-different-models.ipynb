{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing some important librarys\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple process for the data"},{"metadata":{},"cell_type":"markdown","source":"### Missing values\n\nhere i am just going to use a simple techniques to handle the missing data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will separate the numerical columns from the categorical\n\ncat_data = []\nnum_data = []\n\nfor i,c in enumerate(df.dtypes):\n    if c == object:\n        cat_data.append(df.iloc[:, i])\n    else :\n        num_data.append(df.iloc[:, i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = pd.DataFrame(cat_data).transpose()\nnum_data = pd.DataFrame(num_data).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cat_data\n# If you want to fill every column with its own most frequent value you can use\n\ncat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\ncat_data.isnull().sum().any() # no more missing data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# num_data\n# fill every missing value with their previous value in the same column\n\nnum_data.fillna(method='bfill', inplace=True)\nnum_data.isnull().sum().any() # no more missing data ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### categorical columns\n\n* we are going to use **LabelEncoder** :\n\n    what it is actually do it encode labels with value between 0 and n_classes-1 , [for more examples](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) ."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder  \nle = LabelEncoder()\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the target column\n\ntarget_values = {'Y': 0 , 'N' : 1}\n\ntarget = cat_data['Loan_Status']\ncat_data.drop('Loan_Status', axis=1, inplace=True)\n\ntarget = target.map(target_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform other columns\n\nfor i in cat_data:\n    cat_data[i] = le.fit_transform(cat_data[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([cat_data, num_data, target], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the data\n\n* we will stop here for know and train the data.\n\n    we are going to use **StratifiedShuffleSplit**, for more [information](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) ."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([cat_data, num_data], axis=1)\ny = target ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will use StratifiedShuffleSplit to split the data Taking into consideration that we will get the same ratio on the target column\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train, test in sss.split(X, y):\n    X_train, X_test = X.iloc[train], X.iloc[test]\n    y_train, y_test = y.iloc[train], y.iloc[test]\n    \nprint('X_train shape', X_train.shape)\nprint('y_train shape', y_train.shape)\nprint('X_test shape', X_test.shape)\nprint('y_test shape', y_test.shape)\n\n# almost same ratio\nprint('\\nratio of target in y_train :',y_train.value_counts().values/ len(y_train))\nprint('ratio of target in y_test :',y_test.value_counts().values/ len(y_test))\nprint('ratio of target in original_data :',df['Loan_Status'].value_counts().values/ len(df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\n# 'LogisticRegression': LogisticRegression(random_state=42),\n#     'KNeighborsClassifier': KNeighborsClassifier(),\n#     'SVC': SVC(random_state=42),\n\nmodels = {\n    \n    'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=1, random_state=42)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n\ndef loss(y_true, y_pred, retu=False):\n    pre = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    loss = log_loss(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    \n    if retu:\n        return pre, rec, f1, loss, acc\n    else:\n        print('  pre: %.3f\\n  rec: %.3f\\n  f1: %.3f\\n  loss: %.3f\\n  acc: %.3f' % (pre, rec, f1, loss, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_eval_train\n\ndef train_eval_train(models, X, y):\n    for name, model in models.items():\n        print(name,':')\n        model.fit(X, y)\n        loss(y, model.predict(X))\n        print('-'*30)\n        \ntrain_eval_train(models, X_train, y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n\ndef train_eval_cross(models, X, y, folds):\n   \n    y = pd.DataFrame(y)\n    idx = [' pre', ' rec', ' f1', ' loss', ' acc']\n    for name, model in models.items():\n        ls = []\n        print(name,':')\n\n        for train, test in folds.split(X, y):\n            model.fit(X.iloc[train], y.iloc[train]) \n            y_pred = model.predict(X.iloc[test]) \n            ls.append(loss(y.iloc[test], y_pred, retu=True))\n        print(pd.DataFrame(np.array(ls).mean(axis=0), index=idx)[0])  \n        print('-'*30)\n        \ntrain_eval_cross(models, X_train, y_train, skf)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some explanation of the above function\n\nx = []\nidx = [' pre', ' rec', ' f1', ' loss', ' acc']\n\n# we will use one model\nlog = LogisticRegression()\n\nfor train, test in skf.split(X_train, y_train):\n    log.fit(X_train.iloc[train], y_train.iloc[train])\n    ls = loss(y_train.iloc[test], log.predict(X_train.iloc[test]), retu=True)\n    x.append(ls)\n    \n# thats what we get\npd.DataFrame(x, columns=idx)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# features engineer"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndata_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nX_train['new_col'] = X_train['CoapplicantIncome'] / X_train['ApplicantIncome']  \nX_train['new_col_2'] = X_train['LoanAmount'] * X_train['Loan_Amount_Term'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# first lets take a look at the value counts of every label\n\nfor i in range(X_train.shape[1]):\n    print(X_train.iloc[:,i].value_counts(), end='\\n------------------------------------------------\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### we will work on the features that have varied values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_col_2\n\n\nfrom scipy.stats import norm\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\n\nsns.distplot(X_train['new_col_2'], ax=ax[0], fit=norm)\nax[0].set_title('new_col_2 before log')\n\nX_train['new_col_2'] = np.log(X_train['new_col_2'])  # logarithm of all the values\n\nsns.distplot(X_train['new_col_2'], ax=ax[1], fit=norm)\nax[1].set_title('new_col_2 after log');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we will evaluate our models, and i will do that continuously ,so i don't need to mention that every time\n\ntrain_eval_cross(models, X_train, y_train, skf)\n\n# wooow our models improved really good by just doing the previous step .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_col\n\n# most of our data is 0 , so we will try to change other values to 1\n\nprint('before:')\nprint(X_train['new_col'].value_counts())\n\nX_train['new_col'] = [x if x==0 else 1 for x in X_train['new_col']]\nprint('-'*50)\nprint('\\nafter:')\nprint(X_train['new_col'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n\n# ok we are improving our models as we go ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for i in range(X_train.shape[1]):\n    print(X_train.iloc[:,i].value_counts(), end='\\n------------------------------------------------\\n')\n    \n# looks better","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outliers\n\n#### there is different techniques to handle outliers, here we are going to use [**IQR**](https://www.youtube.com/watch?v=qLYYHWYr8xI)"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"\n\nsns.boxplot(X_train['new_col_2']);\nplt.title('new_col_2 outliers', fontsize=15);\nplt.xlabel('');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"threshold = 0.1  \n            \nnew_col_2_out = X_train['new_col_2']\nq25, q75 = np.percentile(new_col_2_out, 25), np.percentile(new_col_2_out, 75) # Q25, Q75\nprint('Quartile 25: {} , Quartile 75: {}'.format(q25, q75))\n\niqr = q75 - q25\nprint('iqr: {}'.format(iqr))\n\ncut = iqr * threshold\nlower, upper = q25 - cut, q75 + cut\nprint('Cut Off: {}'.format(cut))\nprint('Lower: {}'.format(lower))\nprint('Upper: {}'.format(upper))\n\noutliers = [x for x in new_col_2_out if x < lower or x > upper]\nprint('Nubers of Outliers: {}'.format(len(outliers)))\nprint('outliers:{}'.format(outliers))\n\ndata_outliers = pd.concat([X_train, y_train], axis=1)\nprint('\\nlen X_train before dropping the outliers', len(data_outliers))\ndata_outliers = data_outliers.drop(data_outliers[(data_outliers['new_col_2'] > upper) | (data_outliers['new_col_2'] < lower)].index)\n\nprint('len X_train before dropping the outliers', len(data_outliers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data_outliers.drop('Loan_Status', axis=1)\ny_train = data_outliers['Loan_Status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(X_train['new_col_2']);\nplt.title('new_col_2 without outliers', fontsize=15);\nplt.xlabel('');\n\n# good :)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# evaluate the models on Test_data\n\nhere we will just repeat what we did in training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_new = X_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = []\n\nX_test_new['new_col'] = X_test_new['CoapplicantIncome'] / X_test_new['ApplicantIncome']  \nX_test_new['new_col_2'] = X_test_new['LoanAmount'] * X_test_new['Loan_Amount_Term']\nX_test_new.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)\n\nX_test_new['new_col_2'] = np.log(X_test_new['new_col_2'])\n\nX_test_new['new_col'] = [x if x==0 else 1 for x in X_test_new['new_col']]\n\n#X_test_new.drop(['Self_Employed'], axis=1, inplace=True)\n\n# drop all the features Except for Credit_History\n#X_test_new.drop(['Self_Employed','Dependents', 'new_col_2', 'Education', 'Gender', 'Property_Area','Married', 'new_col'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name,model in models.items():\n    print(name, end=':\\n')\n    loss(y_test, model.predict(X_test_new))\n    print('-'*40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DecisionTreeClassifier:\n  pre: 0.850\n  rec: 0.447\n  f1: 0.586\n  loss: 6.739\n  acc: 0.805"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}