{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HackerEarth Machine Learning Challenge - Adopt a Pet Buddy \n## Best Score - 89.58 (Top 4%)"},{"metadata":{},"cell_type":"markdown","source":"## Problem Statement"},{"metadata":{},"cell_type":"markdown","source":"A leading pet adoption agency is planning to create a virtual tour experience for \ntheir customers showcasing all animals that are available in their shelter. \nTo enable this tour experience, you are required to build a Machine Learning model that \ndetermines type and breed of the animal based on its physical attributes and other factors."},{"metadata":{},"cell_type":"markdown","source":"## Importing Modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pandas_profiling import ProfileReport\nfrom imblearn.over_sampling import SMOTE,SMOTENC,SVMSMOTE\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score,make_scorer\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,classification_report\nfrom sklearn.metrics import f1_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom datetime import date\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/hackerearth-ml-challenge-pet-adoption/train.csv')\ndf_test = pd.read_csv('../input/hackerearth-ml-challenge-pet-adoption/test.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Overview"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile = ProfileReport(df_train,title='Detailed Customer Report')\nprofile.to_widgets()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate():\n    # f1 score\n    s1 = f1_score(y_test,y_pred_breed,average='weighted')\n    s2 = f1_score(y_test,y_pred_pet,average='weighted')\n    score = 100*((s1+s2)/2)\n    return score\n\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndef generate_model_report(y_actual, y_predicted):\n    print(\"Accuracy = \" , accuracy_score(y_actual, y_predicted))\n    print(\"Precision = \" ,precision_score(y_actual, y_predicted,average='weighted'))\n    print(\"Recall = \" ,recall_score(y_actual, y_predicted,average='weighted'))\n    print(\"F1 Score = \" ,f1_score(y_actual, y_predicted,average='weighted'))\n    pass\n\ndef generate_auc_roc_curve(y_test, y_score,n_classes):\n   # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot of a ROC curve for a specific class\n    for i in range(n_classes):\n        plt.figure()\n        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic example')\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1) To clean the data and see which are the redundant or unnecessary cols\ndef del_col(col,data):\n    clean_data = data.drop(col, axis=1)\n    return clean_data\n\n# 2) Dropping the duplicates from the dataset.\ndef del_duplicates(data):\n    clean_data = data.drop_duplicates(keep='first')\n    return clean_data\n\n# 3) Imputing missing data\ndef impute_col(data,filler):\n    data.fillna(filler,inplace=True)\n    return data\n\n# 4) Typecasting Variables\ndef typecast_col(col,data,types):\n    clean_data = data.col.astype(types)\n    return clean_data\n  \n# 5) To Replace the spaces between the strings with '_' and also converting all strings to LowerCase\ndef convert_case(col,data,chars):\n    data = data.str.replace(' ',chars) \n    data = data.str.lower() \n    return data\n\n# 6) Encoding using Label Encoder or OHE which converts categorical features to numerical features\ndef label_encoder(data):\n    le = LabelEncoder()\n    data = le.fit_transform(data)\n    return data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing Unnecessary Columns\nX = del_col('pet_id',df_train)\n\n# Generating new feature \nX[['issue_date','listing_date']] = X[['issue_date','listing_date']].apply(pd.to_datetime) #if conversion required\nX['diff_days'] = (X['listing_date'] - X['issue_date']).dt.days\nX = del_col('issue_date',X)\nX = del_col('listing_date',X)\n\n# Imputing missing values with new category \nX['condition'] = impute_col(X['condition'],3.0)\nX['condition'] = X['condition'].astype('int')\n\n# Standardization - converting cm to mts\n# X['height(cm)'] = X['height(cm)']*0.01\nX['length(cm)'] = X['length(m)'].apply(lambda x: x*100)\nX = del_col('length(m)',X)\n# replace all 0 length with mean of lengths\nval = X['length(cm)'].mean()\nX['length(cm)'] = X['length(cm)'].replace(to_replace=0, value=val)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"### Quantile Based Binning"},{"metadata":{"trusted":true},"cell_type":"code","source":"quantile_list = [0, .25, .5, .75, 1.]\nquantiles = X['length(cm)'].quantile(quantile_list)\nquantiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']\nX['length_label'] = pd.qcut(X['length(cm)'],q=quantile_list, labels=quantile_labels)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Custom Based Binning"},{"metadata":{"trusted":true},"cell_type":"code","source":"X['diff_days'] = abs(X['diff_days'])\nX['diff_days'] =np.array(np.array(X['diff_days']) / 365.)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding category using One Hot Encoding\nX = pd.concat([X,pd.get_dummies(X['condition'], prefix='condition')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['X2'], prefix='X2')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['X1'], prefix='X1')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['color_type'], prefix='color_type')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['length_label'], prefix='length_label')],axis=1)\n\nX = del_col('condition',X)\nX = del_col('color_type',X)\nX = del_col('X2',X)\nX = del_col('X1',X)\nX = del_col('length(cm)',X)\nX = del_col('length_label',X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['breed_category'] = X['breed_category'].astype('int')\nX['pet_category'] = X['pet_category'].astype('int')\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y1 = X['breed_category']\nY2 = X['pet_category']\n\n#Splitting up for MultiLabel Classification\nX1 = X.drop(['pet_category','breed_category'], axis=1)\nX2 = X.drop(['pet_category','breed_category'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SMOTE Analysis for highly imbalaced class Balancing"},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = SMOTE('auto',random_state=42)\nX_train1_smote,y_train1_smote = smote.fit_resample(X1,Y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote1 = SMOTE('auto',random_state=42)\nX_train2_smote,y_train2_smote = smote1.fit_resample(X2,Y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nprint(\"Before SMOTE :\", Counter(Y1))\nprint(\"Before SMOTE :\", Counter(y_train1_smote))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nprint(\"Before SMOTE :\", Counter(Y2))\nprint(\"Before SMOTE :\", Counter(y_train2_smote))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{},"cell_type":"markdown","source":"### CatBoost Classifier used with different set of parameters separately "},{"metadata":{},"cell_type":"markdown","source":"### Model to predict Breed category"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\ncategorical_features_indices=[0]\nrf1_2 = CatBoostClassifier(learning_rate=0.055, \n                          n_estimators=1000, \n                          subsample=0.075, \n                          max_depth=3, \n                          verbose=100,\n                          l2_leaf_reg = 7,\n                          bootstrap_type=\"Bernoulli\",\n                          class_weights=[1, 1, 1],\n                          loss_function='MultiClass')\n#                           eval_metric='F1')\n\nkf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\nf1 = []\n\nfor fold,(t_id,v_id) in enumerate(kf.split(X_train1_smote,y_train1_smote)):\n    tx = X_train1_smote.iloc[t_id]; ty = y_train1_smote.iloc[t_id]\n    vx = X_train1_smote.iloc[v_id]; vy = y_train1_smote.iloc[v_id]\n    rf1_2.fit(tx,ty)        \n    val_y = rf1_2.predict(vx)\n    \n    F1_score = f1_score(vy, val_y,average='weighted')\n    f1.append(F1_score)\n    print(f\"fold {fold} f1 {F1_score}\")\n    print(confusion_matrix(val_y, vy))\n\nprint(f\"Mean f1 score {np.mean(f1)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model to predict Pet category"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features_indices=[0]\nfrom catboost import CatBoostClassifier\nrf2_2 = CatBoostClassifier(learning_rate=0.035, \n                          n_estimators=1000, \n                          subsample=0.075, \n                          max_depth=4,\n                          l2_leaf_reg = 40,\n                          verbose=100,\n                          bootstrap_type=\"Bernoulli\",\n                          class_weights=[1, 1, 1, 1],\n                          loss_function='MultiClass')\n\nkf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\nf1 = []\n\nfor fold,(t_id,v_id) in enumerate(kf.split(X_train2_smote,y_train2_smote)):\n    tx = X_train2_smote.iloc[t_id]; ty = y_train2_smote.iloc[t_id]\n    vx = X_train2_smote.iloc[v_id]; vy = y_train2_smote.iloc[v_id]\n    rf2_2.fit(tx,ty)\n           \n    val_y = rf2_2.predict(vx)\n    F1_score = f1_score(vy, val_y,average='weighted')\n    f1.append(F1_score)\n    print(f\"fold {fold} f1 {F1_score}\")\n    print(confusion_matrix(val_y, vy))\n\nprint(f\"Mean f1 score {np.mean(f1)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction on Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_profile = ProfileReport(df_test,title='Detailed Customer Report')\ntest_profile.to_widgets()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing Unnecessary Columns\nZ = del_col('pet_id',df_test)\n\n\n# Imputation\nZ['condition'] = impute_col(Z['condition'],3.0)\nZ['condition'] = Z['condition'].astype('int')\n\n# Standardization - converting cm to mts\nZ['length(cm)'] = Z['length(m)'].apply(lambda x: x*100)\nZ = del_col('length(m)',Z)\nval = Z['length(cm)'].mean()\nZ['length(cm)'] = Z['length(cm)'].replace(to_replace=0, value=val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z[['issue_date','listing_date']] = Z[['issue_date','listing_date']].apply(pd.to_datetime) #if conversion required\nZ['diff_days'] = (Z['listing_date'] - Z['issue_date']).dt.days\nZ = del_col('issue_date',Z)\nZ = del_col('listing_date',Z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Diff days Standardization\nZ['diff_days'] = abs(Z['diff_days'])\nZ['diff_days'] =np.array(np.array(Z['diff_days']) / 365.)\n\n# Quantile Based Binning\nquantile_list = [0, .25, .5, .75, 1.]\nquantiles = Z['length(cm)'].quantile(quantile_list)\nquantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']\nZ['length_label'] = pd.qcut(Z['length(cm)'],q=quantile_list, labels=quantile_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z = pd.concat([Z,pd.get_dummies(Z['condition'], prefix='condition')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['X2'], prefix='X2')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['X1'], prefix='X1')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['color_type'], prefix='color_type')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['length_label'], prefix='length_label')],axis=1)\n\nZ = del_col('condition',Z)\nZ = del_col('color_type',Z)\nZ = del_col('X2',Z)\nZ = del_col('X1',Z)\nZ = del_col('length(cm)',Z)\nZ = del_col('length_label',Z)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding Missing Columns from training Set\nZ['color_type_Black Tiger'] = 0\nZ['color_type_Brown Tiger'] = 0\nZ['X1_3'] = 0\nZ['X1_19'] = 0\nZ = Z[X1.columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"breed_category = rf1_2.predict(Z)\nbreed_category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pet_category = rf2_2.predict(Z)\npet_category","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(df_test['pet_id'],columns=['pet_id',])\nsubmission['breed_category'] = breed_category\nsubmission['pet_category'] = pet_category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['breed_category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['pet_category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}