{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/iris-flower-dataset/IRIS.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The describe function helps us no the basic statistics of the dataset, including the 5 point stats summary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for null values\ndf.isna().apply(pd.value_counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the major time that a data scientist spends is in cleaning of the data. Thanks to the Almighty Mahadev, there is no missing data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.distplot(df['sepal_length'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['sepal_width'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['petal_length'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['petal_width'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking out the normalization of all the variables, we can predict that the variables consist of outliers and some variables are more on the higher length and width of sepals & petals. We will draw boxplots to check out the outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sepal_length and sepal_width are positivley skewed as we can depict it in the distplot function itself, while petal_length & petal_width are negatively skewed. A fatter tail on the left side of the distribution is negatively skewed while fatter tail on the right side represents positive skewness.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, hue='species')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Boxplots to check outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['sepal_length'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['sepal_width'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In sepal_width, the outliers are clearly visible.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['petal_length'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['petal_width'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using heatmap for better presentation of correlation of the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,10))\nsns.heatmap(corr, cmap='RdYlGn', vmax = 1.0, vmin = -1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the variables seem to highly correlate with each other. To learn the basic hacks of data visualization using seaborn visit this link https://datamahadev.com/13-ultimate-seaborn-tricks-using-python/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Applying different classification models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[0:,:4]\ny = df['species']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import logistic regression and training data set\nmodel = LogisticRegression(random_state=1)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification Report\nprint(classification_report(y_test, y_pred, digits = 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"K Nearest Neighbor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n#Running KNN model for k=3\n\nknn = KNeighborsClassifier(n_neighbors = 3)\n\n#fitting the model in train data\n\nknn.fit(X_train, y_train)\n\n#predicting the model with k=3\n\nknn_pred = knn.predict(X_test)\n\n#printing the accuracy\n\nprint(accuracy_score(y_test, knn_pred))\n\n#Running KNN model for k=5\n\nknn = KNeighborsClassifier(n_neighbors = 5)\n\n#fitting the model in train data\n\nknn.fit(X_train, y_train)\n\n#predicting the model with k=5\n\nknn_pred = knn.predict(X_test)\n\n#printing the accuracy\n\nprint(accuracy_score(y_test, knn_pred))\n\n#Running KNN model for k=9\n\nknn = KNeighborsClassifier(n_neighbors = 9)\n\n#fitting the model in train data\n\nknn.fit(X_train, y_train)\n\n#predicting the model with k=9\n\nknn_pred = knn.predict(X_test)\n\n#printing the accuracy\n\nprint(accuracy_score(y_test, knn_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_mat1 = confusion_matrix(y_test, knn_pred)\nconf_mat1\n#confusion matrix with heatmap\nplt.figure(figsize = (9,7))\nsns.heatmap(conf_mat1, annot=True,cmap='Blues', fmt='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing naive bayes\nfrom sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nclf.fit(X_train, y_train)\n#predicting the values\nnb_predict = clf.predict(X_test)\nnb_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing the accuracy\naccuracy_score(y_test, nb_predict, normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_mat2 = confusion_matrix(y_test, nb_predict)\nconf_mat2\n#confusion matrix with heatmap\nplt.figure(figsize = (9,7))\nsns.heatmap(conf_mat1, annot=True,cmap='Blues', fmt='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_model = SVC(C= .1, kernel='linear', gamma= 1)\nsvc_model.fit(X_train, y_train)\n\nprediction = svc_model.predict(X_test)\nprediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the accuracy on the training set\nprint(svc_model.score(X_train, y_train))\nprint(svc_model.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#confusion matrix with heatmap\nconf_mat3 = confusion_matrix(y_test, prediction)\nsns.heatmap(conf_mat3, annot=True,cmap='Blues', fmt='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you have reached till here, thanks a lot do upvote and if you want to Follow AI & Data Sciences religiously, visit https://datamahadev.com and subscribe to my blog & publishing website as the Kaggle community support is much needed.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}