{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-07T15:05:36.782975Z","iopub.execute_input":"2021-07-07T15:05:36.783583Z","iopub.status.idle":"2021-07-07T15:05:36.795851Z","shell.execute_reply.started":"2021-07-07T15:05:36.783543Z","shell.execute_reply":"2021-07-07T15:05:36.794824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Objectives**\n\nFrom the title of the project, its obvious that the objective is the correct identification of pulsar stars.\n\nThis will be a simple prediction and labelling project, with no statistic calculations involved.","metadata":{}},{"cell_type":"markdown","source":"**Libraries**\n\nThe first step is to load the libraries necessary to view and analyze the data as well as the ones to create the prediction models.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import KNNImputer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:36.798952Z","iopub.execute_input":"2021-07-07T15:05:36.799315Z","iopub.status.idle":"2021-07-07T15:05:36.806829Z","shell.execute_reply.started":"2021-07-07T15:05:36.799282Z","shell.execute_reply":"2021-07-07T15:05:36.805909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading and Analysing the Files**\n\nThere are two `csv` files:\n+ `pulsar_data_test.csv`, with the testing data;\n+ `pulsar_data_train.csv`, with the training data;","metadata":{}},{"cell_type":"markdown","source":"**Test data**","metadata":{}},{"cell_type":"code","source":"test_set = pd.read_csv(\"../input/predicting-pulsar-starintermediate/pulsar_data_test.csv\")\ntest_set.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:36.808013Z","iopub.execute_input":"2021-07-07T15:05:36.80857Z","iopub.status.idle":"2021-07-07T15:05:36.852882Z","shell.execute_reply.started":"2021-07-07T15:05:36.808517Z","shell.execute_reply":"2021-07-07T15:05:36.852093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train data**","metadata":{}},{"cell_type":"code","source":"train_set = pd.read_csv(\"../input/predicting-pulsar-starintermediate/pulsar_data_train.csv\")\ntrain_set.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:36.853977Z","iopub.execute_input":"2021-07-07T15:05:36.854419Z","iopub.status.idle":"2021-07-07T15:05:36.896886Z","shell.execute_reply.started":"2021-07-07T15:05:36.854374Z","shell.execute_reply":"2021-07-07T15:05:36.895794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Renaming columns**\n\nIn order to be able to easyli manipulate the dataframes, the columns will be renamed.","metadata":{}},{"cell_type":"code","source":"new_names = [\"Mean_IP\", \"STD_IP\", \"EK_IP\", \"SK_IP\", \"Mean_DMSNR\", \"STD_DMSNR\", \"EK_DMSNR\", \"SK_DMSNR\", \"target_class\"]\ntest_set.columns = new_names\ntrain_set.columns = new_names","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:36.898311Z","iopub.execute_input":"2021-07-07T15:05:36.89891Z","iopub.status.idle":"2021-07-07T15:05:36.90468Z","shell.execute_reply.started":"2021-07-07T15:05:36.898868Z","shell.execute_reply":"2021-07-07T15:05:36.903889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Missing Data**\n\nThe missing data will affect the accuracy of the prediction models, so it's necessary to handle those missing values.","metadata":{}},{"cell_type":"code","source":"def missing(dataset):\n    return dataset.isnull().sum(), msno.matrix(dataset.sample(5370))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:36.908705Z","iopub.execute_input":"2021-07-07T15:05:36.908989Z","iopub.status.idle":"2021-07-07T15:05:36.917697Z","shell.execute_reply.started":"2021-07-07T15:05:36.908962Z","shell.execute_reply":"2021-07-07T15:05:36.916694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test set**","metadata":{}},{"cell_type":"code","source":"missing(test_set)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:36.919246Z","iopub.execute_input":"2021-07-07T15:05:36.919817Z","iopub.status.idle":"2021-07-07T15:05:37.497118Z","shell.execute_reply.started":"2021-07-07T15:05:36.91977Z","shell.execute_reply":"2021-07-07T15:05:37.496284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a lot of missing values in three variables (the fourth is the classifications, wich in this dataset is empty), but accordingly to the graph they cannot be simply removed, or the sample size would be greatly reduced.","metadata":{}},{"cell_type":"markdown","source":"**Train set**","metadata":{}},{"cell_type":"code","source":"missing(train_set)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:37.498347Z","iopub.execute_input":"2021-07-07T15:05:37.498648Z","iopub.status.idle":"2021-07-07T15:05:37.990863Z","shell.execute_reply.started":"2021-07-07T15:05:37.498619Z","shell.execute_reply":"2021-07-07T15:05:37.989765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this set there are a lot more missing values compared to the `test_set`.\n\nNow that we have a sense of how the missing values are distributed, and their dimension, it's important to define a method to tackle this issue.","metadata":{}},{"cell_type":"markdown","source":"**Data distribution**\n\nIn order to better understand if all of this variables afect the classification of the stars, two models of machine learning will be implemented: one wich all of the variables enter the equation, and one where only the variables considered relevant come into play. \n\nTo do this first we will need to divide the `train_set` into to two, depending on the target class.\n\nIn the `test_set`, since the classification is not defined, the column `target_class` will be eliminated.","metadata":{}},{"cell_type":"code","source":"# dividing the train_set\nnot_pulsar = train_set[train_set['target_class'] == 0]\n#not_pulsar.head()\n\npulsar = train_set[train_set['target_class'] == 1]\n#pulsar.head()\n\n# eliminating the classification column from test_set\ntest_set = test_set.drop([\"target_class\"], axis=1)\n#test_set.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:37.992922Z","iopub.execute_input":"2021-07-07T15:05:37.993356Z","iopub.status.idle":"2021-07-07T15:05:38.021249Z","shell.execute_reply.started":"2021-07-07T15:05:37.993313Z","shell.execute_reply":"2021-07-07T15:05:38.020368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Calculating Statistics**\n\nTo get a better sense of the data that afect the prediction of pulsar stars, a satistics analysis will be perfomed to get a better sense of the data.\n\nBefore checking the influence between variables, its important to see the spread of the data. This will be performed using plots to see the means, medians and standard deviations, and to see if there are a considerable amount of outliers.\n\nThe graphs will be:\n+ histograms\n+ box plots","metadata":{}},{"cell_type":"markdown","source":"**Means, medians and spread**","metadata":{}},{"cell_type":"code","source":"# data spread function\nclass Spread:\n    \n    def __init__(self, dataset):\n        self.dataset = dataset\n    \n    def sum_stats(self):\n        #Each column mean\n        print(\"Average:\")\n        print(self.dataset.mean())\n        print(\"\\n\")\n\n        #Each column median\n        print(\"Median:\")\n        print(self.dataset.median())\n        print(\"\\n\")\n\n        #Each column standard deviation\n        print(\"Standard Deviation:\")\n        print(self.dataset.std())\n        print(\"\\n\")\n    \n    #histograms\n    def hist(self):\n        df = self.dataset\n        plt.figure(figsize = (20, 15))\n        rows = len(df.columns) / 3\n        for i in range(1, len(df.columns)):\n            plt.subplot(rows, 3, i)\n            plt.hist(df[df.columns[i - 1]])\n            plt.title(df.columns[i - 1])\n            \n    #box plots\n    def box(self):\n        plt.figure(figsize = (15, 10))\n        df = self.dataset.drop([\"target_class\"], axis=1)\n        chart = sns.boxplot(data = df)\n        chart.set_xticklabels(chart.get_xticklabels(), rotation = \"vertical\")\n        plt.title(\"Box Plots\")\n\n        \n#overlapping histograms\ndef over_hist(df1, df2):\n    plt.figure(figsize = (20, 15))\n    for i in range(1, len(df1.columns)):\n        plt.subplot(len(df1.columns) / 3, 3, i)\n        plt.hist(df1[df1.columns[i - 1]], alpha = 0.5)\n        plt.hist(df2[df2.columns[i - 1]], alpha = 0.5)\n        plt.title(df1.columns[i - 1])\n        plt.legend([\"Pulsar star\", \"Non pulsar star\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:38.022569Z","iopub.execute_input":"2021-07-07T15:05:38.022983Z","iopub.status.idle":"2021-07-07T15:05:38.036448Z","shell.execute_reply.started":"2021-07-07T15:05:38.022943Z","shell.execute_reply":"2021-07-07T15:05:38.035438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pulsar set**","metadata":{}},{"cell_type":"code","source":"pulsar_stats = Spread(pulsar)\npulsar_stats.sum_stats()\npulsar_stats.hist()\npulsar_stats.box()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:38.038336Z","iopub.execute_input":"2021-07-07T15:05:38.039021Z","iopub.status.idle":"2021-07-07T15:05:39.675709Z","shell.execute_reply.started":"2021-07-07T15:05:38.038976Z","shell.execute_reply":"2021-07-07T15:05:39.674744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Non pulsar set**","metadata":{}},{"cell_type":"code","source":"nonpulsar_stats = Spread(not_pulsar)\nnonpulsar_stats.sum_stats()\nnonpulsar_stats.hist()\nnonpulsar_stats.box()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:39.677014Z","iopub.execute_input":"2021-07-07T15:05:39.677603Z","iopub.status.idle":"2021-07-07T15:05:41.155333Z","shell.execute_reply.started":"2021-07-07T15:05:39.677558Z","shell.execute_reply":"2021-07-07T15:05:41.154239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# overlapping histograms\nover_hist(pulsar, not_pulsar)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:41.157073Z","iopub.execute_input":"2021-07-07T15:05:41.157533Z","iopub.status.idle":"2021-07-07T15:05:42.885307Z","shell.execute_reply.started":"2021-07-07T15:05:41.157486Z","shell.execute_reply":"2021-07-07T15:05:42.884137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, all of the variables have a considerable diference between pulsar and non pulsar stars.\n\nTo build the prediction model all varaiables will be considered, wich means that only one model of supervised machine learning will be built.\n\nBefore building the model there are two important task to be performed, the fullfilment of the missing values, and the normalization of the values.\n\nThe last task will allow for a better model, in the sense that will equallize the weight of all the variables.","metadata":{}},{"cell_type":"markdown","source":"**Filling the missing values**\n\nThere are several ways to fill the missing values, but the one that seemed the most adequate for this particular dataset is imputation using k-NN. This method uses machine learning to fill the missing values based on other values with the most similar characteristics.\n\nAlthough is the best method, it as a disadvantage, it's sensitive to outliers. Considering that the columns with the missing values have outliers, these do not disperse away from the core of the values, allowing for a better result.","metadata":{}},{"cell_type":"code","source":"#filling missin data with imputation\ndef fill_miss(dataset, n):\n    imputer = KNNImputer(n_neighbors = n)\n    imputed = imputer.fit_transform(dataset)\n    df = pd.DataFrame(data=imputed, columns=pulsar.columns)\n    print(df.isnull().sum())\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:42.886807Z","iopub.execute_input":"2021-07-07T15:05:42.887232Z","iopub.status.idle":"2021-07-07T15:05:42.892828Z","shell.execute_reply.started":"2021-07-07T15:05:42.887188Z","shell.execute_reply":"2021-07-07T15:05:42.89167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train set**","metadata":{}},{"cell_type":"code","source":"train_set_filled = fill_miss(train_set, 3)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:42.894122Z","iopub.execute_input":"2021-07-07T15:05:42.894588Z","iopub.status.idle":"2021-07-07T15:05:45.592063Z","shell.execute_reply.started":"2021-07-07T15:05:42.894518Z","shell.execute_reply":"2021-07-07T15:05:45.590315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test set**","metadata":{}},{"cell_type":"code","source":"imputer = KNNImputer(n_neighbors = 3)\nimputed = imputer.fit_transform(test_set)\ntest_set_filled = pd.DataFrame(imputed, columns = test_set.columns)\ntest_set_filled.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:45.593231Z","iopub.execute_input":"2021-07-07T15:05:45.593553Z","iopub.status.idle":"2021-07-07T15:05:46.142228Z","shell.execute_reply.started":"2021-07-07T15:05:45.593512Z","shell.execute_reply":"2021-07-07T15:05:46.141319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalizing data**\n\nIn order to allow the variables to have the simular weight in the prediction model, it's necessary to normalize the values.\n\nAnalysing the box plots its possible to see that the presence of outliers is quite substancial, meaning that the min-max normalization is not the most sensitive method. On the other hand the values from standard deviation range from 0.33 up to 107, meaning that the weight diference wil not be greatly reduced.\n\nAfter considereing these facts the option is to go for the min-max normalization method.","metadata":{}},{"cell_type":"code","source":"def minmax(dataset):\n    columns = dataset.columns\n    new_arr = []\n    for column in columns:\n        norm = []\n        min_val = dataset[column].min()\n        max_val = dataset[column].max()\n        for i in range(dataset.shape[0]):\n            new_val = (dataset[column][i] - min_val) / (max_val - min_val)\n            norm.append(new_val)\n        new_arr.append(norm)\n        \n    new_df = pd.DataFrame(np.transpose(new_arr), columns = columns)\n    if len(new_df.columns) == 9:\n        new_df[\"target_class\"] = dataset[\"target_class\"]\n        \n    return new_df","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:46.143515Z","iopub.execute_input":"2021-07-07T15:05:46.14381Z","iopub.status.idle":"2021-07-07T15:05:46.150847Z","shell.execute_reply.started":"2021-07-07T15:05:46.143781Z","shell.execute_reply":"2021-07-07T15:05:46.149998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = minmax(train_set_filled)\ntest_set = minmax(test_set_filled)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:46.151989Z","iopub.execute_input":"2021-07-07T15:05:46.15243Z","iopub.status.idle":"2021-07-07T15:05:47.649349Z","shell.execute_reply.started":"2021-07-07T15:05:46.152389Z","shell.execute_reply":"2021-07-07T15:05:47.648259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Machine Learning Model**\n\nWe come to the last step of this project, the creation of the prediction model.\n\nThe model that best fits this case is the K-Nearest Neighbors.","metadata":{}},{"cell_type":"code","source":"def predt(training_points, training_labels, k, unlabelled):\n    classifier = KNeighborsClassifier(n_neighbors = k)\n    classifier.fit(training_points, training_labels)\n    predictions = classifier.predict(unlabelled)\n    \n    return predictions\n\ndef bestk(training_points, training_labels, test_points, test_labels):\n    \n    accuracies = []\n    for k in range(1, 100, 2):\n        classifier = KNeighborsClassifier(n_neighbors = k)\n        classifier.fit(training_points, training_labels)\n        accuracies.append(classifier.score(test_points, test_labels))\n        \n    plt.plot(range(len(accuracies)), accuracies)\n    plt.xlabel(\"k\")\n    plt.ylabel(\"Score\")\n    plt.title(\"Best k\")\n    \n    k_best = accuracies.index(max(accuracies))\n    \n    classifier = KNeighborsClassifier(n_neighbors = k_best)\n    classifier.fit(training_points, training_labels)\n    guesses = classifier.predict(test_points)\n    accuracy = accuracy_score(test_labels, guesses)\n    recall = recall_score(test_labels, guesses)\n    precision = precision_score(test_labels, guesses)\n    f1 = f1_score(test_labels, guesses)\n    \n    print(\"Score:\", max(accuracies))\n    print(\"Recall:\", recall)\n    print(\"Accuracy:\", accuracy)\n    print(\"Precision:\", precision)\n    print(\"F1:\", f1)\n    print(\"Best k: {bestk}\".format(bestk = k_best))\n    \n    return k_best","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:47.651287Z","iopub.execute_input":"2021-07-07T15:05:47.651722Z","iopub.status.idle":"2021-07-07T15:05:47.663558Z","shell.execute_reply.started":"2021-07-07T15:05:47.651679Z","shell.execute_reply":"2021-07-07T15:05:47.662185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_points, test_points, tr_labels, tt_labels = train_test_split(train_set[[\"Mean_IP\", \"STD_IP\", \"EK_IP\", \"SK_IP\", \"Mean_DMSNR\", \"STD_DMSNR\", \"EK_DMSNR\", \"SK_DMSNR\"]],\n                                                                        train_set[\"target_class\"], test_size = 0.2,\n                                                                        random_state = 1)\n\nbest_k = bestk(train_points, tr_labels, test_points, tt_labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:47.665116Z","iopub.execute_input":"2021-07-07T15:05:47.665518Z","iopub.status.idle":"2021-07-07T15:05:56.622618Z","shell.execute_reply.started":"2021-07-07T15:05:47.665485Z","shell.execute_reply":"2021-07-07T15:05:56.621613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using this model the results obtained are very satisfactory, providing a score of 98%.\n\nThe best number of neighbors obtained is 9, wich will be used to make the predictions in the `test_set`.","metadata":{}},{"cell_type":"markdown","source":"**Classifying test set**","metadata":{}},{"cell_type":"code","source":"classifier = predt(train_points, tr_labels, best_k, test_set)\ntest_set[\"target_class\"] = classifier\ntest_set","metadata":{"execution":{"iopub.status.busy":"2021-07-07T15:05:56.623952Z","iopub.execute_input":"2021-07-07T15:05:56.624347Z","iopub.status.idle":"2021-07-07T15:05:56.919837Z","shell.execute_reply.started":"2021-07-07T15:05:56.624303Z","shell.execute_reply":"2021-07-07T15:05:56.918855Z"},"trusted":true},"execution_count":null,"outputs":[]}]}