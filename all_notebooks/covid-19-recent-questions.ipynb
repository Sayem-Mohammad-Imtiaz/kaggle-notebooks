{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# load the meta data from the CSV file using 3 columns (abstract, title, authors),\ndf=pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv', usecols=['title','abstract','authors','doi','publish_time'])\nprint (df.shape)\n#drop duplicates\n#df=df.drop_duplicates()\ndf = df.drop_duplicates(subset='abstract', keep=\"first\")\n#drop NANs \ndf=df.dropna()\n# convert abstracts to lowercase\ndf[\"abstract\"] = df[\"abstract\"].str.lower()\n#show 5 lines of the new dataframe\nprint (df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import functools\nfrom IPython.core.display import display, HTML\nfrom nltk import PorterStemmer\n\n#tell the system how many sentences are needed\nmax_sentences=5\n\n# function to stem keywords into a common base word\ndef stem_words(words):\n    stemmer = PorterStemmer()\n    singles=[]\n    for w in words:\n        singles.append(stemmer.stem(w))\n    return singles\n\n# list of lists for topic words realting to tasks\ndisplay(HTML('<h1>COVID-19 Recent Questions</h1>'))\ndisplay(HTML('<h3>Table of Contents (ctrl f and search the hash tag and words below to find table</h3>'))\ntasks = [['outcomes', 'ventilator'],['environmental', 'transmission'],['air','pollution','risk'],['routes', 'infection'],['effective', 'movement', 'control'],['infection','control','measures'],['personal', 'protective','equipment']]\nz=0\nfor terms in tasks:\n    stra=' '\n    stra=' '.join(terms)\n    k=str(z)\n    #display(HTML('<a href=\"#'+k+'\">'+stra+'</a>'))\n    display(HTML('# '+stra))\n    z=z+1\n# loop through the list of lists\nz=0\nfor search_words in tasks:\n    df_table = pd.DataFrame(columns = [\"pub_date\",\"authors\",\"title\",\"excerpt\"])\n    str1=''\n    # a make a string of the search words to print readable search\n    str1=' '.join(search_words)\n    search_words=stem_words(search_words)\n    # add cov to focus the search the papers and avoid unrelated documents\n    search_words.append(\"covid\")\n    # search the dataframe for all the keywords\n    dfa=df[functools.reduce(lambda a, b: a&b, (df['abstract'].str.contains(s) for s in search_words))]\n    search_words.pop()\n    search_words.append(\"-cov-\")\n    dfb=df[functools.reduce(lambda a, b: a&b, (df['abstract'].str.contains(s) for s in search_words))]\n    # remove the cov word for sentence level analysis\n    search_words.pop()\n    #combine frames with COVID and cov and drop dups\n    frames = [dfa, dfb]\n    df1 = pd.concat(frames)\n    df1=df1.drop_duplicates()\n    \n    display(HTML('<h3>Task Topic: '+str1+'</h3>'))\n    display(HTML('# '+str1+' <a></a>'))\n    z=z+1\n    # record how many sentences have been saved for display\n    # loop through the result of the dataframe search\n    for index, row in df1.iterrows():\n        pub_sentence=''\n        sentences_used=0\n        #break apart the absracrt to sentence level\n        sentences = row['abstract'].split('. ')\n        #loop through the sentences of the abstract\n        for sentence in sentences:\n            # missing lets the system know if all the words are in the sentence\n            missing=0\n            #loop through the words of sentence\n            for word in search_words:\n                #if keyword missing change missing variable\n                if word not in sentence:\n                    missing=missing+1\n            # after all sentences processed show the sentences not missing keywords limit to max_sentences\n            if missing<len(search_words) and sentences_used < max_sentences and len(sentence)<1000 and sentence!='':\n                sentence=sentence.capitalize()\n                if sentence[len(sentence)-1]!='.':\n                    sentence=sentence+'.'\n                pub_sentence=pub_sentence+'<br><br>'+sentence\n        if pub_sentence!='':\n            sentence=pub_sentence\n            sentences_used=sentences_used+1\n            authors=row[\"authors\"].split(\" \")\n            link=row['doi']\n            title=row[\"title\"]\n            linka='https://doi.org/'+link\n            linkb=title\n            sentence='<p align=\"left\">'+sentence+'</p>'\n            final_link='<p align=\"left\"><a href=\"{}\">{}</a></p>'.format(linka,linkb)\n            to_append = [row['publish_time'],authors[0]+' et al.',final_link,sentence]\n            df_length = len(df_table)\n            df_table.loc[df_length] = to_append\n    filename=str1+'.csv'\n    df_table.to_csv(filename,index = False)\n        #display(HTML('<b>'+sentence+'</b> - <i>'+title+'</i>, '+'<a href=\"https://doi.org/'+link+'\" target=blank>'+authors[0]+' et al.</a>'))\n    df_table=HTML(df_table.to_html(escape=False,index=False))\n    display(df_table)\nprint (\"done\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}