{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introducción\nVamos a hacer un estudio sobre la base de datos *Suicide Rates Overview 1985 to 2016*, que es un conjunto compilado de otras 4 fuentes de informació, *United Nations Development Program*, *World Bank*, un dataset de *kaggle* denominado *Suicide in the Twenty-First Century* y la *World Health Organization*. El conjunto de estos datos forma esta base de datos que contiene el ratio de suicidios por país y año dividido por lo diferentes grupos que hay en la ciudad, grupos distingidos por sexo y franja de edad. Si bien no hay un objetivo especificado la motivación de este conjunto de datos es la prevención de los suicidios, es por esto que vamos a afrontar con diferentes enfoques para ver si se puede realizar un estudio que nos ayude a predecir las causas de estos sucesos."},{"metadata":{},"cell_type":"markdown","source":"# Librerias\nLas diferentes librerías que se han necesitado se encuentran aquí."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_regression\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport scipy.stats\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport math\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\nfrom matplotlib.pyplot import figure\nfrom sklearn.metrics import r2_score\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport category_encoders as ce #pip install category_encoders\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.cluster import KMeans\nimport pandas_profiling as pdp #conda install -c conda-forge pandas-profiling","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploratory Data Analysis\nLo primero que se va a hacer es cargar los datos en un objeto *dataframe* de la librería *pandas* para poder hacer el EDA y eliminar aquellas columnas que aporten información redundante. Identificaremos que atributos contiene la base de datos y si tiene sentido tenerlos en cuenta en nuestro estudio."},{"metadata":{},"cell_type":"markdown","source":"En esta función cargamos los datos en un objeto dataframe de la libreria de pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(path):\n    dataset = pd.read_csv(path, header=0, delimiter=',')\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con esta función eliminamos las columnas que tengan más de un 65% de los datos perdidos, y para los que tienen menos de un 65% eliminamos toda la fila"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values(dataset):\n    nanNum = dataset.isnull().sum()\n    print(nanNum/dataset.shape[0]*100)\n    #Si columna con 30% de valores missing la eliminamos\n    for (index, item) in enumerate(nanNum):\n        if item > dataset.shape[0]*0.65:\n            dataset = dataset.drop(dataset.columns[index], axis=1)\n            \n    #Si hay algún missing value eliminamos la fila\n    dataset = dataset.dropna(axis=0)\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aplicando la técnica de *Z-Score* identificaremos los valores que son demasiado distantes de la distribución y los eliminaremos considerandolos *outliers*."},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_outliers(df, df_entero):\n    z_scores = scipy.stats.zscore(df)\n    abs_z_scores = np.abs(z_scores)\n    filtered_entries = (abs_z_scores < 3).all(axis=1)\n    return df_entero[filtered_entries]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aqui cargamos los datos y observamos como son nuestros datos"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"path = '../input/suicide-rates-overview-1985-to-2016/master.csv'\ndataset = load_dataset(path)\nprint('Dimensión inicial del dataset es de ', dataset.shape)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver estos datos van a tener que adaptarse para poder trabajar con ellos ya que existen muchos valores discretos que no podemos tratar tal y como estan. También vemos que la columna *HDI for year* tiene los 5 primeros valores a *NaN*, esto nos hace sospechar así que mirarmemos si son solo estos o esta columna tiene demasiados valores así.\n\nAntes de continuar vamos a describir todos los atributos que contienen nuestros datos de manera que cuando avancemos y tomemos ciertas decisiones se entienda bien lo que se esta haciendo:\n\n- *country*: País donde ha ocurrido.\n\n- *year*: Año que ha sucedido.\n\n- *sex*: Genero del fallecido.\n\n- *age*: Edad del fallecido.\n\n- *suicides_no*: Número de suicidios.\n\n- *population*: Población.\n\n- *suicides/100k pop*: Proporción del número de suicidios por cada 100 mil personas.\n\n- *country-year*: País y año del suceso.\n\n- *HDI for year: Índice de desarrollo humano, es una media aritmética de tres indices, tener una vida larga y saludable, adquirir conocimientos y disfrutar de un nivel de vida digno.\n- gdp_for_year (\\$)*: PIB por año.\n\n- *gdp_per_capita (\\$)*: PIB per cápita.\n\n- *generation*: Generación del fallecido.\n\nAhora que ya tenemos una idea de como es nuestro *dataframe* vamos a ver el report de los datos, analizaremos lo más importante para poder tomar posteriores decisiones de manera correcta."},{"metadata":{"trusted":true},"cell_type":"code","source":"prof = pdp.ProfileReport(dataset)\nprof.to_file(output_file='report.html')\nprof","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo primero que vamos a mirar son los missing values, en este caso ningún atributo tiene, excepto la columna *HDI for year* que contiene el 69.9% de valores *NaN*. Para solucionar esto vamos a aplicar la función que habíamos creado antes que si una columna tenía más de 65% de valores perdidos se eliminaba directamente.\n\nLo segundo que vemos es que los atributos *country*, *country-year* y *gdp_for_year (\\$)* tienen una alta cardinalidad, pero no hay que preocuparse, ya que el último es simplemente que el formato está mal, debería ser de tipo numérico pero está representado como si fuese un *string*. El caso del *country-year* es que es un atributo de la combinación de *country* y de *year* así que acabará siendo eliminado.\n\nLos atributos *age*, *sex*, *country-year* y *gdp_for_year (\\$)* están balanceados lo cuál es bueno, ya que esto va hacer que no se distorsionen los cálculos.\n\nLas columnas *suicides_no* y *suicides/100k pop* tiene muchos valores que son 0, concretamente el 15.4%, el atributo *suicides_no* no importa porque será eliminado, ya que mirar el número de suicidios en total es bastante deficiente y nos basaremos en la proporción por cada 100 mil personas, pero ese atributo también tiene muchos 0, es algo que de momento obviaremos y más adelante lo retomaremos para darle una solución.\n\nMirando el mapa de correlaciones podemos ver que excepto el número de suicidios con la población no hay atributos muy correlacionados, pero esto es lo que comentabamos antes de porque vamos a eliminar la columna *suicides_no*. Otra cosa que no se puede apreciar en el mapa de correlaciones es que el PIB per cápita y el de por año siguen una correlación de 1, ya que son proporcionales, así que eliminaremos el *gdp_for_year (\\$)*, ya que al no estar en formato numérico habría que transformarlo y es más simple utilizar el otro. La generación también se puede eliminar ya que tiene una alta relación con el atributo de la franja de edad, nos viene a explicar prácticamente lo mismo, además sabiendo el año y la franja de edad puedes saber la generación, realmente no es información adicional.\n\nLo que también se puede observar son los valores extremos de cada atributo, los atributos que tenemos que mirar a fondo para ver si hay *outliers* son los numéricos. El año no posee outliers ya que se mueve entre valores comprendidos entre 1985 y 2016, tal y como se especifica en el título de la página de la base de datos de *kaggle*. Los atributos que hemos dicho que vamos a eliminar no vamos a analizarlos. La población si que posee algunos *outliers* ya que el tercr percentil es de 1486143.25 y el percentil 95 es de 8850239.6 y si nos vamos al valor máximo es de \t43805214, estas diferencias entre los percentiles son demasiado grandes. El caso de *suicides/100k pop* también es grande, en el tercer percentil es de 16.62 y en el percentil 95 es de 50.5305 y el valor máximo asciende a 224.97. El *gdp_per_capita (\\$)* también tiene algunos, ya que del percentil 95 que es de 54294 asciendo el valor máximo a 126352.\n\nAntes de modificar las tablas vamos a analizar si estos outliers son anomalias o es por la descompensación entre paises, para hacer esto lo que vamos a hacer es ver de donde salen estos datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.sort_values(by=['population'], ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí parece que la descompensación esta en la población de estados unidos que es muy grande y por lo tanto distorsiona los datos, pero en este caso es mejor no eliminar estas filas ya que lo que haremos es dejar de tener en cuenta a la población de Estados Unidos y no sabiendo eso no podemos decir que aplique como estudio universal."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.sort_values(by=['suicides/100k pop'], ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el caso del ratio de suicidios si que son casos donde mejor no contarlos en la estadistica, ya son paises de población muy baja y que se han suicidado muy pocas personas, pero hace que la proporcion sea muy alta, y además no es siempre el mismo país por lo que parece que no es una tendencia de ese país si con son situaciones atípicas. Aunque si lo que vemos relevante es que la majoría de sitios que ocurre son en la Republica de Korea, así que aunque los vayamos a tratar como valores atípocos hay que tene en cuenta que no todos lo son."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.sort_values(by=['gdp_per_capita ($)'], ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo primero que vemos es que Luxemburgo es país muy rico, pero si nos fijamos es siempre del mismo año, vamos a analizar si para este país son valores normales, si lo son habrá que dejarlos, pero si no lo son habrá que eliminarlos.\n\nDespués de ver esto concluimos que solo tenemos que eliminar los *outliers* de la columna *suicides/100k pop*."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[dataset['country'] == 'Luxembourg']['gdp_per_capita ($)'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parece ser que este es un país bastante rico, por lo que tampoco deberiamos eliminar los *outliers*."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset2 = missing_values(dataset)\ndataset2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que lo que deciamos anteriormente se corresponde con la ejecución de nuestra función y por lo tanto la columna *HDI for year* ha sido eliminada. El siguiente paso es eliminar aquellas columnas que anteriormente hemos dicho que no nos eran útiles porque estan formadas a través de la composición de otras o es información redundante que indice a errores a los algoritmos."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset3 = dataset2.drop(['suicides_no', ' gdp_for_year ($) ', 'country-year', 'generation'], axis=1)\ndataset3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí podemos ver como queda nuestro dataset después de la eliminación. El siguiente paso es la eliminación de los outliers de nuestros atributos numéricos, excepto del atributo *year*, tal y como habíamos dicho anteriormente. Vamos a aplicar el método que hemos creado al principio que aplica la técnica *Z-Score*"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset4 = remove_outliers(dataset3[['suicides/100k pop']], dataset3)\ndataset4.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que varias filas han sido eliminadas y las desviaciones de los datos ya no son tan grandes y los valores máximos son más reducidos ahora."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Dimensiones del dataset limpio: ', dataset4.shape)\ndataset4.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que se han eliminado alrededor de 800 elementos, es bastante poco teniendo en cuenta la cantidad de datos que tenemos, así que seguimos contando un buen volumen de datos para hacer el estudio."},{"metadata":{},"cell_type":"markdown","source":"# 3. Experimentación\nPrimero de todo sacaremos los histogramas para ver como están distribuidos los valores de los atributos."},{"metadata":{"trusted":true},"cell_type":"code","source":"def histogramas(dataset, index):\n    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n    data = dataset.values\n    columnName = list(dataset)\n    x = data[:, index]\n    plt.figure()\n    title=\"Histograma de l'atribut \"\n    plt.title(title)\n    plt.xlabel(columnName[index])\n    plt.ylabel(\"Count\")\n    hist = plt.hist(x, bins=11, histtype=\"bar\", rwidth=0.8)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for i in range(dataset4.shape[1]):\n    histogramas(dataset4, i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo que queremos ver en este estudio es la proporción de suicidios por cada 100k habitantes. La distribución de estos es bastante malo por lo que la mejor es descomponer el estudio en otros de tal forma que podamos predecir algo. Se realizarían los siguientes estudios y luego se contrastaría la información entre estos para razonar cosas. Los estudios serían:\n\n- Por cada país mirariamos los suicidios independientemente. Aquí podriamos ver más en detalle por cada país que ocurre, si una franja de edad o un sexo es más propenso.\n\n- Por cada país y año mirariamos los suicidios totales, con este estudio podríamos ver la diferenca entre los paises y ver si paises ricos tiene más suicidios o al revés o si todos actuán de un forma similar.\n\n- Por último haríamos una clusterización para agrupar los paises y así analizar ciertas tendencias seguún las características de cada grupo."},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Estudio por paises\nEn este caso crearemos modelos predictivos para cada país para poder ver como actúa la población de un mismo lugar.\n\n### 3.1.1 Preprocesado\nLo primero que vamos a hacer es crear un diccionario donda cada entrada será un dataframe con la información de cada país. Si un país tiene menos de 50 columnas es eliminado, ya que con pocos datos no se puede hacer nada.\n\nDe estos datos tenemos que eliminar la columna de *country* ya que ha dejado de tener sentido, ya que ahora los paises serán modelos independientes. Luego de esto vamos a mirar aquellos lugares que tengan en la mediana almenos un valor de 5, ya que con menos significa que casi todo es 0 y nos sirve de poco hacer un modelo sobre un país así."},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_df = {}\ncountry_name = []\nfor item in dataset4['country'].unique():\n    df = dataset4.loc[dataset4['country'] == item]\n    if df.shape[0] > 50:\n            dict_df[item] = df\n            country_name.append(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'country' in dict_df['United States']:\n    for item in country_name:\n        dict_df[item] = dict_df[item].drop(['country'], axis=1)\ndict_df['United States'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí vemos un ejemplo de Estados Unidos de como quedan los dataset después de la eliminación de las columnas."},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = []\nfor item in country_name:\n    if dict_df[item]['suicides/100k pop'].quantile(0.50) < 5:\n        del dict_df[item]\n        aux.append(item)\nfor x in aux:\n    country_name.remove(x)\nprint('Número de países: ', len(country_name))\nprint(country_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En esta ejecución podemos ver que el número de países de los que se va hacer el estudio es de 53 y podemos ver el nombre de los países en cuestión. Ahora vamos a ver el histograma de los atributos para ver si han mejorado en algo."},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in country_name:\n    print('----------------------------------------')\n    print(item)\n    for i in range(dict_df[item].shape[1]):\n        histogramas(dict_df[item], i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Siguen sin tener la mejor forma posible pero vemos que han mejorado bastante al separarlo por paises, ahora buscaremos las correlaciones entre los atributos y para eso lo que haremos será codificar el atributo *sex*, como 1 para *male* y 0 para *female* y también codificaremos el atributo *age* de manera ordinal, ya que al hacer eferencia a edades es lógico que por ejemplo el intervalo entre 55 y 74 años tenga un valor mayor al intervalo de 15 y 24 años."},{"metadata":{"trusted":true},"cell_type":"code","source":"if dict_df['United States']['sex'].dtype != 'int64':\n    le_s = preprocessing.LabelEncoder()\n    le_a = preprocessing.LabelEncoder()\n    age = np.sort(dataset3['age'].unique())\n    for i in range(4):\n        aux = age[i]\n        age[i] = age[3]\n        age[3] = aux\n    le_s.fit(['female', 'male'])\n    le_a.classes_ = age\n    for item in country_name:\n        dict_df[item][['sex']] = le_s.transform(dict_df[item]['sex'])\n        dict_df[item][['age']] = le_a.transform(dict_df[item]['age'])\ndict_df['United States'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver como se han quedado las columnas categoricas codificadas, con esto podemos sacar las correlaciones y observar los atributos que más relacionados están."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for item in country_name:\n    corr = dict_df[item].corr()\n\n    plt.figure(figsize=(10,10))\n\n    ax = sns.heatmap(corr, annot=True, linewidths=1, center=0)\n    \n    ax.set_title(item)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Entre cada país hay variaciones, pero por lo general vemos tendencia a ver los atributos de sexo y edad como los más relacionados, lo que implica que al ser de forma positiva existe cierta tendencia de ser el género masculino el que sufre de más suicidios y en una edad más avanzada, no son los más jovenes los que se suicidan más.\n\nLos siguientes pasos son partir el dataset en test y train y estandatizarlo, para eso utilizaremos la función de abajo. Aplicaremos la estandarización *MinMaxScaler* ya que una estandarización estándar no daría bueno resultados, nuestros datos distan demasiado de una distribución normal así que que el cálculo daría unos malos resultados."},{"metadata":{"trusted":true},"cell_type":"code","source":"def standarize(x_train, x_test):\n    scaler = preprocessing.MinMaxScaler()\n    scaler.fit(x_train)\n    return scaler.transform(x_train), scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_x_y = {}\nfor item in country_name:\n    dict_x_y[item] = {}\n    dict_x_y[item]['x'] = dict_df[item].loc[:,dict_df[item].columns != \"suicides/100k pop\"].to_numpy()\n    dict_x_y[item]['y'] = dict_df[item].loc[:,\"suicides/100k pop\"].to_numpy()\n    dict_x_y[item]['x_s'], aux = standarize(dict_x_y[item]['x'], dict_x_y[item]['x'])\nprint(dict_x_y['United States']['x_s'][2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora tenemos un diccionario donde tenemos las x de estandarizadas y las y de cada país. En la ejecución podemos ver un ejemplo de una fila de atributos estandarizados de Estados Unidos.\n\nYa lo tenemos todo listo para poder realizar las experimentaciones así que en el siguiente subapartado procederemos a realizarlo."},{"metadata":{},"cell_type":"markdown","source":"### 3.1.2 Experimentación\nLo que vamos hacer en este apartado es hacer un cross validate para cada país aplicando una regresión lineal, sacaremos cual es el mejor modelo para diferentes k teniendo en cuenta la mse y el r2."},{"metadata":{"trusted":true},"cell_type":"code","source":"country_scores = {}\nfor item in country_name:\n    country_scores[item] = {}\n    for i in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n        reg = LinearRegression()\n        country_scores[item][i] = cross_validate(reg, dict_x_y[item]['x_s'], dict_x_y[item]['y'], cv=i, scoring=['neg_mean_squared_error', 'r2'], return_estimator=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_scores_resume = {}\nfor item in country_name:\n    dict_scores_resume[item] = {}\n    for k in country_scores[item]:\n        dict_scores_resume[item][k] = {}\n        for numbers in country_scores[item][k]:\n            i = 0\n            aux = 0\n            if numbers != 'estimator':\n                dict_scores_resume[item][k][numbers] = {}\n                for num in np.nditer(country_scores[item][k][numbers]):\n                    i = i + 1\n                    aux = aux + num\n                result = aux/i\n                dict_scores_resume[item][k][numbers] = result","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for pais, info_pais in dict_scores_resume.items():\n    print(pais, ':')\n    for k, info_k in info_pais.items():\n        print('k =', k, ':')\n        print('MSE:', info_k['test_neg_mean_squared_error'], 'R2:', info_k['test_r2'])\n    print('--------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver para cada país el mse y el r2 medio para cada k, hay que decir que el mse está negativo porque así lo fuerza la librería, con esto nos quieren indicar que esa variable es una variable a minimizar. Ahora lo que haremos será valorar cual es la mejor k para cada país y extraer el mejor modelo que haya creado la cross validación para poder ver los coeficientes y así ver a que atributos asigna más peso. "},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_best_k = {}\nfor pais, info_pais in dict_scores_resume.items():\n    dict_best_k[pais] = {}\n    dict_best_k[pais]['k'] = -1\n    dict_best_k[pais]['value'] = float('-inf')\n    for k, values in info_pais.items():\n        if dict_best_k[pais]['value'] < (values['test_neg_mean_squared_error'] + values['test_r2'])/2:\n            dict_best_k[pais]['value'] = (values['test_neg_mean_squared_error'] + values['test_r2'])/2\n            dict_best_k[pais]['k'] = k\n    val = country_scores[pais][dict_best_k[pais]['k']]['test_neg_mean_squared_error'] + country_scores[pais][dict_best_k[pais]['k']]['test_neg_mean_squared_error']\n    dict_best_k[pais]['iter'] = val.argmax()\nprint(dict_best_k['Spain'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí lo que hemos extraido es la mejor k con el valor medio entre el valor del mse y el del r2. Dentro de esa k el mejor modelo encontrado sería el sexto en caso de España, esto nos servirá para encontrar el mejor regresor."},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_best_regr = {}\nfor item in country_name:\n    dict_best_regr[item] = country_scores[item][dict_best_k[item]['k']]['estimator'][dict_best_k[item]['iter']]\nprint(dict_best_regr['Spain'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí tenemos un diccionario con el mejor regresor lineal por cada país, como se ve en la ejecución lo único que tenemos es el objeto del regresor lineal que nos servirá para llegar a conclusiones."},{"metadata":{},"cell_type":"markdown","source":"### 3.1.3. Conclusiones\nUna vez ya hemos encontrado el mejor modelo vamos a enseñar para cada país que pesos a asignado a cada atributos y analizaremos un poco algunos de los países más interesantes, como son España, Estados Unidos, Francia."},{"metadata":{"trusted":true},"cell_type":"code","source":"for pais, info_pais in dict_scores_resume.items():\n    print(pais, ':')\n    print('k =', dict_best_k[pais]['k'], ':')\n    print('MSE:', country_scores[pais][dict_best_k[pais]['k']]['test_neg_mean_squared_error'][dict_best_k[pais]['iter']], 'R2:', country_scores[pais][dict_best_k[pais]['k']]['test_r2'][dict_best_k[pais]['iter']])\n    print('--------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí tenemos el error y el r2 para el mejor modelo de cada país, depende del país cambian mucho los valores, para algunos paises ha sido más fácil hacer la predicción y para otros ha sido imposible predecirlos. Ahora vamos a ver el peso que le han dado a caa uno de los atributos en los regresores de cada país y así podremos ver los atributos más importantes según el lugar."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"list_attr = ['country'] + list(dict_df['Spain'])\nlist_attr.remove('suicides/100k pop')\ndf_coef = pd.DataFrame(columns=list_attr)\ni = 0\nfor pais, regr in dict_best_regr.items():\n    df_coef.loc[i, 'country'] = pais\n    df_coef.values[i, 1:] = regr.coef_\n    i += 1\ndf_coef = df_coef.set_index('country')\ndf_coef.head(df_coef.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En esta ejecución podemos ver para cada país que peso se ha asignado a cada uno de los atributos, se puede ver el país que se desee pero lo que vamos hacer es profundizar en tres países, España, Estados Unidos y Francia."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_coef[df_coef.index.isin(['Spain', 'United States', 'France'])].plot(kind='bar', figsize=[15,10],\n             title ='Agrupación de paises por la proporción de suicidios en 2014')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Empezando por Francia podemos ver que la edad es el atributo con mayor pero con diferencia, seguido del sexo y luego los años de manera negativa, la población le otorga muy poca importancia para saber el ratio de suicidios.\n\nEn cuanto a España vemos que la edad también es el atributo más relevante, pero muy seguido de la población con signo negativo, luego tenemos el género también como importante, en este caso los menos relevante son los años, prácticamente tienen valor 0.\n\nEn Estados Unidos tenemos la edad y luego el género con valores muy parejos, el resto de atributos tiene poco valor, resaltando la riqueza del país como el menos importante.\n\nDe estos tres países podemos ver que actúan de una manera muy parecida, la edad y el género cobran mucha importancia a la hora de saber la proporción de suicidios."},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Estudio conjunto del país\nLa idea de aquí es agrupar los suicidios de cada país por año y país sin distinguir por sexo ni edad, así podemos crear un modelo predictivo más general de lo que ocurre a nivel global\n\n### 3.2.1 Preprocesado\n\nPrimeramente eliminamos los atributos de sexo, edad y generación y hacemos una agrupación por país y año. Luego de esto mostraremos los atributos a ver como quedan las distribuciones de los datos, y seguidamente mostraremos las correlaciones. La variable categorica del país no es ordinal por lo que no podemos hacer esto para ver su relación, mostraremos su relación con el atributo objetivo con un boxplot y después la codificaremos de forma binaria, ya que para una codificación *One Hot* tiene demasiada cardinalidad. Finalmente separaremos las muestras en entreno y validación y estandarizaremos con el *MinMaxScaler*, para la creación del set de entreno y el de validación lo que vamos hacer es entrenar con los datos hasta 2010 y validaremos con los años restante, así veremos si creando un regesor lineal de los años pasados podemos predecir lo que ha ocurrido en los últimos años."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(columns=['country', 'year', 'population', 'suicides/100k pop', 'gdp_per_capita ($)'])\ndf['country'] = dataset4['country']\ndf['year'] = dataset4['year']\ndf['population'] = dataset4['population']\nfor i, fila in dataset4.iterrows():\n    df.loc[i, 'suicides/100k pop'] = dataset2.loc[i, 'suicides_no']\n    \ndf = df.fillna(0)\ndf = df.groupby(['country', 'year'], as_index=False).sum()\n\ndf_rich = dataset4.groupby(['country', 'year'], as_index=False).mean()\ndf['gdp_per_capita ($)'] = df_rich['gdp_per_capita ($)']\nfor i, fila in df.iterrows():\n    df.loc[i, 'suicides/100k pop'] = (fila['suicides/100k pop'] / fila['population'])*100000\n    \nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Este es el resultado de la anteriormente descrito, podemos ver que nos hemos quedado con 2321 filas y solamente 5 columnas. Lo siguiente que haremos será printar los histogramas de los atributos para ver como se distribuyen los datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(df.shape[1]):\n    histogramas(df, i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver una clara mejora de los datos en el atributo objetivo, no se puede decir que posea distribución gaussiana pero aún así ha mejorado mucho su distribución.\n\nVisto esto pasaremos a mirar las correlaciones entre atributos."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\n\nplt.figure(figsize=(10,10))\n\nax = sns.heatmap(corr, annot=True, linewidths=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ni los años ni el PIB per cápita parecen tener relación con el atributo objetivo, esto nos da que pensar que lo que determina el número de suicidios es la localización con bastante independencia de su nivel económico.\n\nVeremos como se relaciona el atributo *country* con un *boxplot*."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 100))\norder = df.groupby(by=[\"country\"])[\"suicides/100k pop\"].mean().sort_values().iloc[::-1].index\nax = sns.boxplot(y=\"country\", x=\"suicides/100k pop\", data=df, order = order)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pdemos ver que hay mucha variación dependiendo de cada país, esto nos hace pensar que este artibuto si que esta altamente correlacionado con el target, pero será el modelo quien nos determine esto exactamente.\n\nLo siguiente a hacer es aplicar la codificación para la variable *country*"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = ce.binary.BinaryEncoder(cols=['country'])\ndf_e = encoder.fit_transform(df)\ndf_e = df_e.drop('country_0', axis=1)\ndf_e.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí podemos ver como queda nuestro dataset ahora tenemos 7 columnas adicionales y hemos perdido la que nos indicaba el nombre del país con un *string*. Ahora pasaremos partir los datos en entrenamiento y validación como hemos dicho anteriormente y estandarizaremos con un *MinMaxScaler* ya que nuestros datos no tienen distribución normal y por lo tanto un *StandardScaler* daría malos resultados."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_e.loc[:,df_e.columns != \"suicides/100k pop\"].to_numpy()\ny = df_e.loc[:,\"suicides/100k pop\"].to_numpy()\n\nx_train = x[df_e.loc[:, 'year'] <= 2010]\nx_val = x[df_e.loc[:, 'year'] > 2010]\ny_train = y[df_e.loc[:, 'year'] <= 2010]\ny_val = y[df_e.loc[:, 'year'] > 2010]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_s, x_val_s = standarize(x_train, x_val)\nprint(x_train_s[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver como han quedado nuestras variables independientes estandarizadas, no pasa nada por haber estandarizado las columnas de country porque tal y como son no modican su valor y siguen siendo 1 y 0.\n\nYa tenemos todo preparado para comenzar a aplicar la regressión lineal, así que hasta aquí llega el preprocesado."},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2. Experimentación\nLo que haremos aquí es aplicar un regresor lineal de grado 1 y de grado 2 en un cross validate con diferentes k para comprobar cual es la mejor manera de entrenar los datos, extraeremos el mejor modelo y luego haremos la validación con los datos de 2010 hasta 2016. Con esto veremos si es buen modelo predictivo o no."},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = {}\nfor d in [1, 2]:\n    scores[d] = {}\n    for i in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n        reg = LinearRegression()\n        pf = PolynomialFeatures(degree=d)\n        atribut_train=pf.fit_transform(x_train_s)\n        scores[d][i] = cross_validate(reg, atribut_train, y_train, cv=i, scoring=['neg_mean_squared_error', 'r2'], return_estimator=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_resume = {}\nfor k in scores:\n    scores_resume[k] = {}\n    for degree in scores[k]:\n        scores_resume[k][degree] = {}\n        for numbers in scores[k][degree]:\n            i = 0\n            aux = 0\n            if numbers != 'estimator':\n                scores_resume[k][degree][numbers] = {}\n                for num in np.nditer(scores[k][degree][numbers]):\n                    i = i + 1\n                    aux = aux + num\n                result = aux/i\n                scores_resume[k][degree][numbers] = result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for degree, info_degree in scores_resume.items():\n    print('Regresion lineal de grado', degree, ':')\n    for k, info_k in info_degree.items():\n        print('k =', k, ':')\n        print('MSE:', info_k['test_neg_mean_squared_error'], 'R2:', info_k['test_r2'])\n    print('--------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí podemos ver la media por cada k del mse y el r2, ahora con esta información pasaremos a encontrar el mejor regresor."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_k = {}\nbest_k['degree'] = -1\nbest_k['k'] = -1\nbest_k['value'] = float('-inf')\nfor degree, info_degree in scores_resume.items():\n    for k, values in info_degree.items():\n        if best_k['value'] < (values['test_neg_mean_squared_error'] + values['test_r2'])/2:\n            best_k['value'] = (values['test_neg_mean_squared_error'] + values['test_r2'])/2\n            best_k['k'] = k\n            best_k['degree'] = degree\nval = scores[best_k['degree']][best_k['k']]['test_neg_mean_squared_error'] + scores[best_k['degree']][best_k['k']]['test_neg_mean_squared_error']\nbest_k['iter'] = val.argmax()\nprint(best_k)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí ya podemos ver cual es el mejor grado para la regresion, la mejor k y dentro de la cross validación la mejor iteración. Vamos ahora a utilizar ese regresor para hacer la validación con los últimos años."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_regr = scores[best_k['degree']][best_k['k']]['estimator'][best_k['iter']]\ny_predict = best_regr.predict(np.insert(x_val_s, 0, 1, axis=1))\nmse = mean_squared_error(y_val, y_predict)\nr2 = r2_score(y_val, y_predict)\nprint('MSE:', mse, 'R2:', r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tenemos el error y el coeficiente r2, con esto en el apartado siguiente llegaremos a las conclusiones pertinentes."},{"metadata":{},"cell_type":"markdown","source":"### 3.2.3 Conclusiones\n"},{"metadata":{},"cell_type":"markdown","source":"Vemos que el error es bastante grande y el r2 es cercano a cero y negativo, lo cual indica que este no es un buen modelo, igualemente vamos a ver una gráfica que nos muestre los que a pasado desde 2011 hasta 2016 y que el lo que ha predicho nuestro modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2)\nfig.set_figheight(5)\nfig.set_figwidth(15)\n\nax1.set(ylim=(0, 30))\nax1.set_title('Sucesos reales')\nax1.scatter(x_val[:, list(df_e).index('year')], y_val)\n\nax2.set(ylim=(0, 30))\nax2.set_title('Sucesos predecidos')\nax2.scatter(x_val[:, list(df_e).index('year')], y_predict, color='red')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En esta gráfica lo que podemos observar esque las predicciones de cada año no se corresponden demasiado con los sucesos que han pasado realmente, las predicciones por cada año son muy parecidas entre ellas. Por todo esto estimamos que las predicciones de estos últimos 6 años son malos y aproximadamente siempre nos devuelve el mismo valor. Ahora veremos una gráfica que nos muestra el error de cada muestra divididas por años. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_plot = (y_val-y_predict)\nplt.scatter(x_val[:, list(df_e).index('year')], y_plot)\nplt.axhline(y=0, color='red', linewidth=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En esta gráfica podemos ver el error que se cometido entre lo que ha ocurrido y lo que se ha predicho, los valores contra más lejos de la línea roja están más error ha habido, ninguno de los años se puede decir que sea preciso. Por último vamos a ver una gráfica de todos los valores de estos últimos 6 años que nos mostrará también el error de caa muestra pero de una manera más visual."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_val, y_predict)\nplt.plot([0, 25], [0, 25], color='red', linewidth=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El eje de las X son los valores reales y el eje vertical son los valors predichos, en una perfecta predicción los puntos seguirián la línia roja diagonal, pero este no es el caso y los puntos se encuentran muy dispersos."},{"metadata":{},"cell_type":"markdown","source":"## 3.3. Clusterización\nEn este apartado aplicaremos un algoitmo de clusterización no supervisado, el kmeans, para hacer agrupaciones de los países que más se parecen entre ellos, de esta manera podemos encontrar que países son más parecidos entre ellos y que características son más relevantes de cada uno.\n\nPara esto vamos a transformar el dataset para poder hacer una clusterización según la demografía y otra según la proporción de suicidios de cada grupo de individuos.\n\n### 3.3.1. Clusterización por demografía\nAhora en la función de abajo vamos a crear nuestro nuevo dataset, en el cuál veremos que porcentage de cada grupo de personas hay en cada país por año."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clusters_demografia = pd.DataFrame(columns=['country', 'year', 'population', 'female (%)', '5-14 years',\n                                    '15-24 years', '25-34 years', '35-54 years', '55-74 years', '75+ years',\n                                    'suicides/100k pop', 'gdp_per_capita ($)'])\ndf_clusters_demografia['country'] = dataset4['country']\ndf_clusters_demografia['year'] = dataset4['year']\ndf_clusters_demografia['population'] = dataset4['population']\nfor i, fila in dataset4.iterrows():\n    if 'female' == fila['sex']:\n        df_clusters_demografia.loc[i, 'female (%)'] = fila['population']\n    #else:\n        #df_clusters_demografia.loc[i, 'female (%)'] = fila['population']\n    df_clusters_demografia.loc[i, fila['age']] = fila['population']\n    df_clusters_demografia.loc[i, 'suicides/100k pop'] = dataset2.loc[i, 'suicides_no']\n    \ndf_clusters_demografia = df_clusters_demografia.fillna(0)\ndf_clusters_demografia = df_clusters_demografia.groupby(['country', 'year'], as_index=False).sum()\n\ndf_rich = dataset4.groupby(['country', 'year'], as_index=False).mean()\ndf_clusters_demografia['gdp_per_capita ($)'] = df_rich['gdp_per_capita ($)']\nfor i, fila in df_clusters_demografia.iterrows():\n    df_clusters_demografia.loc[i, 'suicides/100k pop'] = (fila['suicides/100k pop'] / fila['population'])*100000\n    df_clusters_demografia.loc[i, 'female (%)'] = (fila['female (%)'] / fila['population'])\n    df_clusters_demografia.loc[i, '5-14 years'] = (fila['5-14 years'] / fila['population'])\n    df_clusters_demografia.loc[i, '15-24 years'] = (fila['15-24 years'] / fila['population'])\n    df_clusters_demografia.loc[i, '25-34 years'] = (fila['25-34 years'] / fila['population'])\n    df_clusters_demografia.loc[i, '35-54 years'] = (fila['35-54 years'] / fila['population'])\n    df_clusters_demografia.loc[i, '55-74 years'] = (fila['55-74 years'] / fila['population'])\n    df_clusters_demografia.loc[i, '75+ years'] = (fila['75+ years'] / fila['population'])\n    \nscaler = preprocessing.MinMaxScaler()\na, aux = standarize(df_clusters_demografia.values[:,2:], df_clusters_demografia.values[:,2:])\nnombres = list(df_clusters_demografia)\nindice_fila = 0\nfor i, fila in df_clusters_demografia.iterrows():\n    index = 0\n    for index in range(len(nombres)-2):\n        df_clusters_demografia.loc[i, nombres[index+2]] = a[indice_fila][index]\n        index +=1\n    indice_fila += 1\n    \ndf_clusters_demografia.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como vemos tenemos atributos diferentes, pero son simplemente transformaciones de la información que ya teníamos antes, para agilizar hemos estandarizado directamente los datos con el *MinMaxScaler*. Vamos a pasar a explicar cada atributo lo que significa:\n- *country*: Es el nombre del país, no requiere estandarización, es nuestro output.\n- *year*: Año, no requiere estandarización, vamos a diferenciar los años.\n- *population*: Cantidad de población ese año en ese país.\n- *female (%)*: Porcentage de mujeres en el país.\n- *5-14 years*: Porcentage de población en el rango de edad de 5 a 14 años.\n- *15-24 years*: Porcentage de población en el rango de edad de 15 a 14 años.\n- *25-34 years*: Porcentage de población en el rango de edad de 25 a 34 años.\n- *35-54 years*: Porcentage de población en el rango de edad de 35 a 54 años.\n- *55-74 years*: Porcentage de población en el rango de edad de 55 a 74 años.\n- *75+ years*: Porcentage de población superior a los 75 años de edad.\n- *suicides/100k pop*: Proporción de suicidios por cada 100 mil personas.\n- *gdp_per_capita (\\$)*: PIB por capita.\n\nLo siguiente que vamos a hacer es ver un report de este dataframe a ver si tenemos algo relevante que destacar."},{"metadata":{"trusted":true},"cell_type":"code","source":"prof = pdp.ProfileReport(df_clusters_demografia)\nprof.to_file(output_file='clusters_demografia.html')\nprof","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No hay nada especialmente llamativo a resaltar,lo mas relevante quizas sea la alta cardinalidad del atributo *country* y que el atributo *suicides/100k pop* contiene también una alta frecuencia de zeros, pero eso es algo que hemos sufrido durante todo el estudio.\n\nLa idea ahora es la siguiente, cogeremos un año actual, como 2014 y agruparemos por clusters y luego cogeremos un año lejano, 1995, y veremos si los clusters mantienen las mismas propiedades, en caso afirmativo veremos un patrón constante durante el paso de los años, si por el contrario son diferentes veremos que el paso de los años afecta a la población."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clusters_demografia_2014 = df_clusters_demografia[df_clusters_demografia['year'] == 2014].drop(['country', 'year'], axis=1)\ndf_clusters_demografia_2014.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in nc]\nscore = [kmeans[i].fit(df_clusters_demografia_2014).score(df_clusters_demografia_2014) for i in range(len(kmeans))]\nscore\nplt.xlabel('Número de clústeres (k)')\nplt.ylabel('Suma de los errores cuadráticos')\nplt.plot(nc,score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver la elbow curve la cuál nos dice que la mejor k es aquella en la que esta curva comienza a suavizarse, en este caso sería de 10, pero analizando nuestros datos vemos que tenemos pocos atributos, en concreto 12 contando el año y el país que no se van a utilizar para el Kmeans. Así que para que no haya los mismos grupos que atributos vamos a escoger una k de 4."},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_demografia_2014 = KMeans(n_clusters=4).fit(df_clusters_demografia_2014)\nprint(kmeans_demografia_2014.cluster_centers_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver los valores de los centroides, ahora los representaremos para que sean más entendibles."},{"metadata":{"trusted":true},"cell_type":"code","source":"centroids_demografia_2014 = kmeans_demografia_2014.cluster_centers_\nname_centroids = []\nfor i in range(centroids_demografia_2014.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_demografia_2014 = pd.DataFrame(data=centroids_demografia_2014.transpose(), index=list(df_clusters_demografia_2014), columns=name_centroids)\ndf_centroids_demografia_2014","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_dem_2014 = df_centroids_demografia_2014.plot(kind='bar', figsize=[30,10],\n                                            title='Agrupación de paises por la demografía en 2014')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hemos creado 4 grupos diferentes según la demagrafía en 2014, vamos a pasar a definir cada uno de estos grupos y ver que características tiene cada uno.\n\n- Cluster 0: Es el grupo con mayor ratio de suicidios y son paises con poco nivel económico. Su población es más abundante en las franjas de edad superiores de 34 años, no hay mucha cantidad de población y el porcentage de hombre y mujeres es equilibrado pero con un ligero dominio de la población masculina.\n\n- Cluster 1: Estos paises han pocos suicidios y son los paises mas pobres, su población es abundante y equilibrada en género, las edad más habituales son la franja de 35 a 54 años y lo de 5 a 14 años.\n\n- Cluster 2: Estos son paises con gran indice de suicidios pero son los más ricos, su población es muy abundante y con predominancia entre las edades mayores a 34 años, el genero de la población esta equilibrado.\n\n- Cluster 3: Este grupo lo conforman paises con muy pocos suicidios, muy poca población y paises ricos, con poco porcentage de mujeres y población en la franja de edad joven y media, entre 25 y 54, la población mayor de esta edad es muy escasa en estos paises.\n\nAhora que ya hemos visto los 4 grupos formados en 2014, vamos a ver que 4 grupos se forman en 1995."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_clusters_demografia_1995 = df_clusters_demografia[df_clusters_demografia['year'] == 1995].drop(['country', 'year'], axis=1)\nkmeans_demografia_1995 = KMeans(n_clusters=4).fit(df_clusters_demografia_1995)\ncentroids_demografia_1995 = kmeans_demografia_1995.cluster_centers_\nname_centroids = []\nfor i in range(centroids_demografia_1995.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_demografia_1995 = pd.DataFrame(data=centroids_demografia_1995.transpose(), index=list(df_clusters_demografia_1995), columns=name_centroids)\nplot_dem_1995 = df_centroids_demografia_1995.plot(kind='bar', figsize=[30,10],\n                                                 title='Agrupación de paises por la demografía en 1995')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora en 1995 han cambiado las clases y tiene otras características diferentes:\n\n- Cluster 0: Este grupo tiene paises con un alto indice de suicidios, tienen bastante riqueza y tiene muy poca población con igualdad en género, son paises con la media de edad entre los 35 y los 74 años.\n\n- Cluster 1: Estos son paises con baja proporción de suicidios pero bastante pobres y con poca población con un ligero debalace a favor de los hombres y es una población muy joven, con dominación de la población joven entre los 5 y los 14 años.\n\n- Cluster 2: Estos son paises tiene un ratio de suicidios alto y con riqueza muy alta y con población muy abundante y equilibrada, la población mayoritaría tiene una edad comprendida entre los 35 y los 55 años.\n\n- Cluster 3: El grupo que conforma estos paises tiene mucha proporción de suicidios y son muy pobres, la población es estandard pero con mucho dominio femenino, es un población bastante equilibrada en edades, los rangos de edades más frecuentes son de 5 a 14 años y entre 53 y 74 años.\n\nDespués de ver esto pasaremos a hacer la clusterización teniendo en cuenta el ratio de suicidios de cada grupo de personas por país y año."},{"metadata":{},"cell_type":"markdown","source":"### 3.3.2. Clusterización por ratio de suicidios de grupos\nVamos a crear el nuevo dataset el con el que veremos por cada país y año que proporción de suicidios hay de cada grupo de personas."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clusters_rate = pd.DataFrame(columns=['country', 'year', 'population', 'male', 'female', '5-14 years',\n                                    '15-24 years', '25-34 years', '35-54 years', '55-74 years', '75+ years',\n                                    'suicides/100k pop', 'gdp_per_capita ($)'])\ndf_clusters_rate['country'] = dataset4['country']\ndf_clusters_rate['year'] = dataset4['year']\ndf_clusters_rate['population'] = dataset4['population']\nfor i, fila in dataset4.iterrows():\n    if 'male' == fila['sex']:\n        df_clusters_rate.loc[i, 'male'] = dataset2.loc[i, 'suicides_no']\n    else:\n        df_clusters_rate.loc[i, 'female'] = dataset2.loc[i, 'suicides_no']\n    df_clusters_rate.loc[i, fila['age']] = dataset2.loc[i, 'suicides_no']\n    df_clusters_rate.loc[i, 'suicides/100k pop'] = dataset2.loc[i, 'suicides_no']\n    \ndf_clusters_rate = df_clusters_rate.fillna(0)\ndf_clusters_rate = df_clusters_rate.groupby(['country', 'year'], as_index=False).sum()\n\ndf_rich = dataset4.groupby(['country', 'year'], as_index=False).mean()\ndf_clusters_rate['gdp_per_capita ($)'] = df_rich['gdp_per_capita ($)']\nfor i, fila in df_clusters_rate.iterrows():\n    df_clusters_rate.loc[i, 'suicides/100k pop'] = (fila['suicides/100k pop'] / fila['population'])*100000\n    df_clusters_rate.loc[i, 'male'] = (fila['male'] / fila['population'])*100000\n    df_clusters_rate.loc[i, 'female'] = (fila['female'] / fila['population'])*100000\n    df_clusters_rate.loc[i, '5-14 years'] = (fila['5-14 years'] / fila['population'])*100000\n    df_clusters_rate.loc[i, '15-24 years'] = (fila['15-24 years'] / fila['population'])*100000\n    df_clusters_rate.loc[i, '25-34 years'] = (fila['25-34 years'] / fila['population'])*100000\n    df_clusters_rate.loc[i, '35-54 years'] = (fila['35-54 years'] / fila['population'])*100000\n    df_clusters_rate.loc[i, '55-74 years'] = (fila['55-74 years'] / fila['population'])*100000\n    df_clusters_rate.loc[i, '75+ years'] = (fila['75+ years'] / fila['population'])*100000\n    \nscaler = preprocessing.MinMaxScaler()\na, aux = standarize(df_clusters_rate.values[:,2:], df_clusters_rate.values[:,2:])\nnombres = list(df_clusters_rate)\nprint(type(a))\nindice_fila = 0\nfor i, fila in df_clusters_rate.iterrows():\n    index = 0\n    for index in range(len(nombres)-2):\n        df_clusters_rate.loc[i, nombres[index+2]] = a[indice_fila][index]\n        index +=1\n    indice_fila += 1\n    \ndf_clusters_rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Igualmente que antes explicaremos los atributos nuevos que se han creado:\n- *country*: Es el nombre del país, no requiere estandarización, es nuestro output.\n- *year*: Año, no requiere estandarización, vamos a diferenciar los años.\n- *population*: Cantidad de población ese año en ese país.\n- *female*: Proporción por 100 mil personas de mujeres que se han suicidado.\n- *male*: Proporción por 100 mil personas de hombres que se han suicidado.\n- *5-14 years*:  Proporción por 100 mil personas en el rango de edad de 5 a 14 años.\n- *15-24 years*: Proporción por 100 mil personas en el rango de edad de 15 a 14 años.\n- *25-34 years*: Proporción por 100 mil personas en el rango de edad de 25 a 34 años.\n- *35-54 years*: Proporción por 100 mil personas en el rango de edad de 35 a 54 años.\n- *55-74 years*: Proporción por 100 mil personas en el rango de edad de 55 a 74 años.\n- *75+ years*: Proporción por 100 mil personas con edad superior a los 75 años.\n- *suicides/100k pop*: Proporción de suicidios por cada 100 mil personas.\n- *gdp_per_capita (\\$)*: PIB por capita.\n\nLo siguiente que vamos a hacer es ver un report de este dataframe a ver si tenemos algo relevante que destacar."},{"metadata":{"trusted":true},"cell_type":"code","source":"prof = pdp.ProfileReport(df_clusters_rate)\nprof.to_file(output_file='clusters_rate.html')\nprof","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El report nos avisa de que todas las proporciones de suicidios contiene muchos 0, por ejemplo pordemos ver que para gente entre 5 y 14 años tenemos aproximadamente un cuarto de los datos que son 0, lo que significa que en esa franja de edad hay muchos años en algunos paises que no se suicida nadie. Otra cosa curiosa que vemos es que la proporcion total de suicidios por cada 100 mil personas esta muy correlacionado con la proporción de suicidios entre las mujeres y el rango de suicidios de población entre 35 y 54 años. Luego también nos avisa como siempre sobre la alta cardinalidad del atributo con el nombre de los países.\n\nLa idea es con esto agrupar en grupos donda cada grupo contendrá unas características diferenciadoras de los demás, primero miraremos un año más actual como 2014 y un más antiguo, 1995. Por el número de muestras que contiene son los años más separados y que contiene un alto número de muestras."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clusters_rate_2014 = df_clusters_rate[df_clusters_rate['year'] == 2014].drop(['country', 'year'], axis=1)\ndf_clusters_rate_2014.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in nc]\nscore = [kmeans[i].fit(df_clusters_rate_2014).score(df_clusters_rate_2014) for i in range(len(kmeans))]\nscore\nplt.xlabel('Número de clústeres (k)')\nplt.ylabel('Suma de los errores cuadráticos')\nplt.plot(nc,score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí podemos ver la elbow curve qye no indica que la mejor k se situaría alrededos de un valor aproximado de 5, por lo que se harán agrupaciones de 5 grupos diferentes."},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_rate_204 = KMeans(n_clusters=5).fit(df_clusters_rate_2014)\nprint(kmeans_rate_204.cluster_centers_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bueno aquí tenemos los centroides de cada cluster, pero esto no es muy visual y es difícil de interpretar, por eso vamos a representarlos de manera gráfica y a partir de aquí extraeremos las conclusiones pertinentes."},{"metadata":{"trusted":true},"cell_type":"code","source":"centroids_rate_2014 = kmeans_rate_204.cluster_centers_\nname_centroids = []\nfor i in range(centroids_rate_2014.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_rate_2014 = pd.DataFrame(data=centroids_rate_2014.transpose(), index=list(df_clusters_rate_2014), columns=name_centroids)\ndf_centroids_rate_2014","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_rate_2014 = df_centroids_rate_2014.plot(kind='bar', figsize=[30,10],\n                                            title ='Agrupación de paises por la proporción de suicidios en 2014')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos a difentificar los 5 grupos formados por los ratios de suicidios de cada tipo de persona:\n\n- Cluster 0: El primer grupo lo conforman países con una alta proporción de suicidios, son países pobres y con un valor bajo de población. Los hombres se suicidan en proporción mucho más alta que los hombres y el rango de edad más propenso es el de 55 a 74 años, siendo los más pequeños los que menos se suicidan.\n\n- Cluster 1: Estos países son muy ricos pero no tiene un gran índice de suicidio, la población es grande y son también los hombres los que más se suicidan, el rango más alto en suicidios es de 55 a 74 años y los más pequeños apenas se suicidan.\n\n- Cluster 2: Son un grupo con un índice de suicidios relativamente bajo, son pobres y con bastante población, domina el género masculino como el más propenso y siendo los frecuente la población comprendida entre los 25 a los 54.\n\n- Cluster 3: Son el grupo con mayor indice de suicidios y son ligeramente mas ricos que el grupo anterior. Su población es abundante y con propensión a los suicidios de hombre entre 55 y 74 años.\n\n- Cluster 4: Este es un grupo con muy bajo índice de suicidios y con buen nivel económico, la población es escasa y son los hombre quien se suicidan en mayor proporción siendo el ranfo de 25 a 34 los que más.\n\nIgual que antes vamos a comparar si el paso de los años mantiene una tendencia en los grupos o por si lo contrario las conclusiones que se extraen de los años más antiguos no aplican en los tiempos modernos."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clusters_rate_1995 = df_clusters_rate[df_clusters_rate['year'] == 1995].drop(['country', 'year'], axis=1)\nkmeans_rate_1995 = KMeans(n_clusters=5).fit(df_clusters_rate_1995)\ncentroids_rate_1995 = kmeans_rate_1995.cluster_centers_\nname_centroids = []\nfor i in range(centroids_rate_1995.shape[0]):\n    name_centroids.append('centroid '+str(i))\ndf_centroids_rate_1995 = pd.DataFrame(data=centroids_rate_1995.transpose(), index=list(df_clusters_rate_1995), columns=name_centroids)\nplot_rate_1995 = df_centroids_rate_1995.plot(kind='bar', figsize=[30,10],\n                                            title ='Agrupación de paises por la proporción de suicidios en 1995')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora los grupos han variado así que explicaremos un poco las características de cada grupo:\n- Cluster 0: Este grupo tiene los suicidios generales relativamente bajos y son un país rico con mucha población. Es el género masculino en el rango de los 35 a los 54 el más predispuesto.\n\n- Cluster 1: Estos países son muy ricos pero con el mayor índice de suicidios, la población es grande y son también los hombres los que más se suicidan, el rango más alto en suicidios es de 55 a 74 años y los más pequeños apenas se suicidan.\n\n- Cluster 2: Son un grupo con un índice de suicidios bajo y son pobres y con poca población, domina el género masculino como el más propenso y siendo los frecuente la población comprendida entre los 25 a los 34.\n\n- Cluster 3: Son el grupo con indice de suicidios  muy grande y son muy pobres. Su población es abundante y con propensión a los suicidios de mujeres mayores de 75 y entre 15 y 24 años.\n\n- Cluster 4: Este es un grupo con alto índice de suicidios y con muy bajo nivel económico, la población es muy escasa y son los hombre quien se suicidan en mayor proporción siendo el ranfo de 25 a 34 los que más.\n\nUna vez visto esto lo que vamos a hacer es analizar lo que hemos ido haciendo en el apartado de clusterización y extraer todas las conclusiones que se pueda."},{"metadata":{},"cell_type":"markdown","source":"### 3.3.3 Conclusiones\nDespués de haber terminado con esto vamos extraer toda la información que se pueda de la clusterización que hemos realizado en los apartados anteriores."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, nrows=2)\ndf_centroids_demografia_2014.plot(kind='bar', figsize=[35,30], ax = axs[0][1],\n                                        title ='Agrupación de paises por la demografía en 2014')\ndf_centroids_demografia_1995.plot(kind='bar', figsize=[35,30], ax = axs[0][0],\n                                        title ='Agrupación de paises por la demografía en 1995')\ndf_centroids_rate_2014.plot(kind='bar', figsize=[35,30], ax = axs[1][1],\n                                        title ='Agrupación de paises por la proporción de suicidios en 2014')\ndf_centroids_rate_1995.plot(kind='bar', figsize=[35,30], ax = axs[1][0],\n                                        title ='Agrupación de paises por la proporción de suicidios en 1995')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como se puede apreciar a lo largo de los años hay pequeños cambios que hacen que no se puedan agrupar los grupos igual para todos los años, sin embargo hay tendencias que perdurán y nos da información de lo que ocurre.\n\nEn lo que respecta a la demografía vemos que el rango de edad es lo más importante a la hora de determinar la proporción de suicidios en el país, si son una población joven tienden a gaber menos suicidios que en poblaciones con edades más avanzadas.\n\nCuando hemos agrupado por ratio de suicidios de cada tipo de persona hemos visto que hay una tendencia clara, los hombres entre que comprenden edades entre los 35 y los 74 son los más propensoso al suicidio\n\nCon esto podemos ver que, a pesar de que a simple vista pueda parecer que el dinero es un factor determinante para ver si una población tiende o no al suicidio esto no es cierto. La población tampoco es algo que nos aporte demsiada información. Concluimos que sabiendo la edad de las personas que viven en estos paises y el genero podemos determinar si será un país con muchos o pocos suicidios y que seguramente la mayor porte vengan del género masculino de mediana edad."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}