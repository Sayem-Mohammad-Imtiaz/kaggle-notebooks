{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nimport os\nimport matplotlib.gridspec as gridspec\nimport matplotlib.ticker as ticker\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n#from generator import DataGenerator\nimport keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df = pd.read_csv('../input/data/Data_Entry_2017.csv')\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input','data', 'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['path'] = all_xray_df['path'].astype(str)\n\n#all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\nall_xray_df.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Fibrosis', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Consolidation', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Pneumonia', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Emphysema', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Pleural_Thickening', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Pneumothorax', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Hernia', ''))\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].astype(str)\n#all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('Hernia', ''))\n\nfrom itertools import chain\nall_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# keep at least 1000 cases\nMIN_CASES = 10\nall_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(all_xray_df[c_label].sum())) for c_label in all_labels])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.1 + number of findings\nsample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nsample_weights /= sample_weights.sum()\nall_xray_df = all_xray_df.sample(40000, weights=sample_weights)\n\nlabel_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = 100*np.mean(all_xray_df[all_labels].values,0)\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\nax1.set_xticklabels(all_labels, rotation = 90)\nax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n_ = ax1.set_ylabel('Frequency (%)')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.20, \n                                   random_state = 2018,\n                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4])\n                                     )\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df['newLabel'] = valid_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\ntrain_df['newLabel'] = train_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (224, 224)\ncore_idg = ImageDataGenerator()\n#core_idg = ImageDataGenerator(samplewise_center=True, \n #                             samplewise_std_normalization=True, \n  #                            horizontal_flip = True, \n   #                           vertical_flip = False, \n    #                          height_shift_range= 0.05, \n     #                         width_shift_range=0.1, \n      #                        rotation_range=5, \n       #                       shear_range = 0.1,\n        #                      zoom_range=0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = core_idg.flow_from_dataframe(dataframe=train_df, \n                             directory=None,\n                             x_col = 'path',\n                            y_col = 'newLabel', \n                            classes = all_labels,\n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 16)\n\nvalid_gen = core_idg.flow_from_dataframe(dataframe=valid_df, \n                             directory=None,\n                             x_col = 'path',\n                            y_col = 'newLabel', \n                            classes = all_labels,\n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32) # we can use much larger batches for evaluation\n\ntest_X, test_Y = next(core_idg.flow_from_dataframe(dataframe=valid_df, \n                             directory=None,\n                             x_col = 'path',\n                            y_col = 'newLabel', \n                            classes = all_labels,\n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 8000))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0])\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.densenet import DenseNet121, preprocess_input\n#from keras.applications.nasnet  import NASNetMobile, preprocess_input\n#from keras.applications.densenet import DenseNet201, preprocess_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dense net model\nimg_in = Input(t_x.shape[1:])              #input of model \nmodel = DenseNet121(include_top= False , # remove  the 3 fully-connected layers at the top of the network\n                weights=None,      # pre train weight \n                input_tensor= img_in, \n                input_shape= t_x.shape[1:],\n                pooling ='avg') \n\nx = model.output  \npredictions = Dense(len(all_labels), activation=\"sigmoid\", name=\"predictions\")(x)    # fuly connected layer for predict class \nmodel = Model(inputs=img_in, outputs=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(lr=0.001)\nmodel.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[keras.metrics.binary_accuracy])\nmodel.load_weights('../input/chestxray8-dataframe/pretrained_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up a checkpoint for model training\n# https://keras.io/callbacks/\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpointer = ModelCheckpoint(filepath='weights.best.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only = True)\ncallbacks_list = [checkpointer]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_steps=1,\n                                  validation_data = valid_gen, \n                                  epochs = 1 , callbacks = callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_steps=1,\n                                  validation_data = valid_gen, \n                                  epochs = 10 , callbacks = callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\ny_pred = model.predict(test_X) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\n# look at how often the algorithm predicts certain diagnoses \nfor c_label, p_count, t_count in zip(all_labels, \n                                     100*np.mean(y_pred,0), \n                                     100*np.mean(test_Y,0)):\n    print('%s: actual: %2.2f%%, predicted: %2.2f%%' % (c_label, t_count, p_count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nfrom sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), y_pred[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nplt.plot([0, 1], [0, 1], 'k--')\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(test_Y.astype(int), y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################################\nfrom sklearn.metrics import confusion_matrix\ny_pred =np.argmax(y_pred,axis=1)\ncm=confusion_matrix(np.argmax(test_Y, axis=1), y_pred)\n#########################################\nimport seaborn as sn\nimport pandas as pd\n\nplt.figure(figsize=(14, 14))\nax= plt.subplot()\n\ndf_cm = pd.DataFrame(cm, range(14), range(14))\n# plt.figure(figsize=(10,7))\nsn.set(font_scale=1.2) # for label size\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 15}, cmap='Blues',ax = ax ) # font size\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',\n                          'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'],rotation=30, ha=\"right\",rotation_mode=\"anchor\"); \nax.yaxis.set_ticklabels(['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',\n                          'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'],rotation=30,  ha=\"right\", rotation_mode=\"anchor\");\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nfrom sklearn.metrics import accuracy_score\naccuracy_score(np.argmax(test_Y, axis=1), y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom operator import itemgetter\nfrom collections import OrderedDict\n\nfrom PIL import Image\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import optim,nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as T,models\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.utils import make_grid\n\npd.options.plotting.backend = \"plotly\"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\npathology_list =['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',\n                          'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n\n#trainset, validset, testset = random_split(train_gen, [5000,303,303])\n\ndef class_accuracy(dataloader, model):\n    \n    per_class_accuracy = [0 for i in range(len(pathology_list))]\n    total = 0.0\n    \n    with torch.no_grad():\n        \n        for images,labels in dataloader:\n            \n            ps = model(images)\n            labels = labels\n            ps = (ps >= 0.5)\n        \n            for i in range(ps.shape[1]):\n                \n                x1 = ps[:,i:i+1]\n                x2 = labels[:,i:i+1]\n                per_class_accuracy[i] += int((x1 == x2).sum())\n                \n        per_class_accuracy = [(i/len(dataloader.dataset))*100.0 for i in per_class_accuracy]\n        \n    return per_class_accuracy     \n\n\ndef get_acc_data(class_names,acc_list):\n    df = pd.DataFrame(list(zip(class_names, acc_list)), columns =['Labels', 'Acc']) \n    return df ","metadata":{}},{"cell_type":"markdown","source":"print(\"Train Dataset Accuracy Report\")\nacc_list = class_accuracy(train_gen,model)\nget_acc_data(pathology_list,acc_list)","metadata":{}},{"cell_type":"markdown","source":"history = model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_steps=1,\n                                  validation_data = valid_gen, \n                                  epochs = 3 , callbacks = callbacks_list)","metadata":{}},{"cell_type":"markdown","source":"#########################################\ny_pred = model.predict(test_X) ","metadata":{}},{"cell_type":"markdown","source":"#########################################\nfrom sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), y_pred[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nplt.plot([0, 1], [0, 1], 'k--')\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')","metadata":{}},{"cell_type":"markdown","source":"#########################################\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(test_Y.astype(int), y_pred)","metadata":{}},{"cell_type":"markdown","source":"########################################\nfrom sklearn.metrics import confusion_matrix\ny_pred =np.argmax(y_pred,axis=1)\ncm=confusion_matrix(np.argmax(test_Y, axis=1), y_pred)\n#########################################\nimport seaborn as sn\nimport pandas as pd\n\nplt.figure(figsize=(14, 14))\nax= plt.subplot()\n\ndf_cm = pd.DataFrame(cm, range(14), range(14))\n# plt.figure(figsize=(10,7))\nsn.set(font_scale=1.2) # for label size\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 15}, cmap='Blues',ax = ax ) # font size\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',\n                          'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'],rotation=30, ha=\"right\",rotation_mode=\"anchor\"); \nax.yaxis.set_ticklabels(['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',\n                          'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'],rotation=30,  ha=\"right\", rotation_mode=\"anchor\");\n\n\nplt.show()","metadata":{}},{"cell_type":"markdown","source":"#########################################\nfrom sklearn.metrics import accuracy_score\naccuracy_score(np.argmax(test_Y, axis=1), y_pred)","metadata":{}}]}