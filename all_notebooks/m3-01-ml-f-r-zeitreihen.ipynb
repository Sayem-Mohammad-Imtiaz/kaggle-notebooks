{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\n# Wir nutzen RAPIDS, um die Modelle GPU-beschleunigt trainieren zu können\nimport sys\n!cp ../input/rapids/rapids.0.18.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True) # falls plotly mal nichts anzeigt, diese Zelle wieder ausführen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning für Zeitreihen\nDieses Notebook zeigt, wie klassische Machine-Learning-Algorithmen für das Forecasting von Zeitreihen genutzt werden können.","metadata":{}},{"cell_type":"markdown","source":"## Beispiel-Daten einlesen\n\nFür unsere Beispiele nutzen wir einen Datensatz von der Johns Hopkins Universität mit täglich aktualisierten Zahlen zu den gemeldeten Infektionen mit COVID-19 aus verschiedenen Ländern.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\n    'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',\n    dtype={'Country/Region':'category'}\n)\n\ndf = df.loc[df['Country/Region'].isin(['France', 'Portugal', 'Spain'])] # wir nutzen nur die Daten für Deutschland, Italien, Spanien und Frankreich\ndf = df.loc[df['Province/State'].isnull()]\ndf = df.drop(columns=['Province/State', 'Lat', 'Long']) # die Spalten brauchen wir nicht\ndf = df.melt(id_vars='Country/Region', var_name='date', value_name='value_total') # vom Wide-Format in das Long-Format transformieren\ndf['date'] = pd.to_datetime(df['date'])\ndf.sort_values('date', inplace=True) # nach Datum sortieren\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basis-Features für das Zeitreihen-Modell\nFür unsere ersten Modelle nutzen wir 4 einfache Features:\n\n- `value_daily` der tagesaktuelle Wert der neu gemeldeten Infektionen\n- `value_trend` der Durchschnittswert der letzten 7-Tage\n- `value_trend_slope` die Differenz zwischen dem aktuellen Trendwert und dem Trendwert vor 7 Tagen, was ungefähr der Steigung der Trendkurve entspricht\n- `weekday` der aktuelle Wochentag","metadata":{}},{"cell_type":"code","source":"df['value_daily'] = df.groupby('Country/Region')['value_total'].diff().fillna(0) # value_total sind die kumulierten Zahlen\ndf.loc[df['value_daily'] < 0, 'value_daily'] = 0\ndf.drop(columns='value_total', inplace=True)\n\ndf['value_trend'] = df.groupby('Country/Region')['value_daily'].rolling(window=7).mean().reset_index(level=0, drop=True)\n\ndf['value_trend_slope'] = df.groupby('Country/Region')['value_trend'].diff(7)\n\ndf['weekday'] = df['date'].dt.weekday\n\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Darstellung der Werte und des Trends mit Plotly...","metadata":{}},{"cell_type":"code","source":"df.groupby('Country/Region', observed=True)['value_daily'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(df,\n        x='date', y=['value_daily', 'value_trend'],\n        title='Täglich gemeldete Neuinfektionen mit COVID-19',\n        facet_row='Country/Region',\n        labels=dict(date='Datum', value=''))\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1])) # 'Italy' anstatt 'Country/Region=Italy' für die Beschriftung der Subplots\nfig.update_yaxes(matches=None) # individuelle y-Achsen-Skala je Diagramm\nfig.show()","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ML-Modell trainieren: mehrere direkte Modelle (eins je Horizont)\n\nWir nehmen an, dass wir die neugemeldeten Infektionen für die nächsten 14 Tage vorhersagen möchten. Wir trainieren dafür 14 Modelle - eins für jeden Vorhersagehorizont. Die Features sind für jedes Modell identisch, aber jeweils mit einem weiter verschobenen Zielwert. Wir benutzen den Random-Forest für Regressionen aus RAPIDS cuML (NVIDIA) als Algorithmus.","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrom cuml.ensemble import RandomForestRegressor\n\nhorizon = 14\n\n# Features für das Training\nX = df.dropna().copy() # nur mit Beispielen (Zeilen) trainieren, für die alle Features einen Wert haben\nX.drop(columns='date', inplace=True) # Datum nutzen wir nicht als Feature\nX['Country/Region'] = X['Country/Region'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX = X.astype('float32') # der Random Forest von RAPIDS mag nur Floats\n    \n\n# Trainieren\nmodels = [] # Liste mit Modellen je Vorhersagehorizont\nfor h in range(1, horizon+1):\n    y = X.groupby('Country/Region')['value_daily'].shift(-h) # Zielvariable aus der verschobenen Zeitreihe ableiten\n    \n    model = RandomForestRegressor(max_depth=8, n_estimators=100) # für schnelleres Training, z.B. beim Debugging: max_depth=2, n_estimators=10\n    model.fit(X[~y.isnull()], y.dropna()) # nur mit Beispielen trainieren, für die es einen Zielwert gibt\n    models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vorhersage mit mehreren direkten Modellen (eins je Horizont)\nDie Vorhersage beginnen wir nach dem letzten Zeitpunkt, für den wir noch Daten haben.","metadata":{}},{"cell_type":"code","source":"forecast_date = df['date'].max() # Vorhersagezeitpunkt (kann auch mit pd.to_datetime('2021-01-23') gesetzt werden)\n\n# Features für die Vorhersage\nXf = df[df['date']==forecast_date].copy()\nXf.drop(columns='date', inplace=True) # Datum nutzen wir nicht als Feature\nXf['Country/Region'] = Xf['Country/Region'].cat.codes # Kategorien in numerischen Wert wandeln\nXf = Xf.astype('float32') # der Random Forest von RAPIDS mag nur Floats\n\nresult = pd.DataFrame() # wird alle Vorhersagen mit Country/Region, Datum und Wert enthalten\nfor h in range(0, horizon):\n    prediction = models[h].predict(Xf)\n    tmp = Xf[['Country/Region']].assign(forecast_daily = prediction)\n    tmp['date'] = forecast_date + pd.DateOffset(h+1)\n    result = result.append(tmp)\n    \nresult['Country/Region'] = df['Country/Region'].cat.categories[result['Country/Region'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult = result.append(df.loc[df['date'] <= forecast_date][['Country/Region', 'date', 'value_daily']]) # Ist-Werte zum Ergebnis hinzufügen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ergebnis der Vorhersage plotten...","metadata":{}},{"cell_type":"code","source":"fig = px.line(result,\n              x='date', y=['forecast_daily', 'value_daily'], facet_row='Country/Region',\n              title='Titel', labels=dict(date='Datum', value=''))\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1])) # 'Italy' anstatt 'Country/Region=Italy' für die Beschriftung der Subplots\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Einfluss der Features mit Shapley-Werten erklären\n\nMit Hilfe von Shapley-Werten lässt sich der Einfluss von Feature-Werte auf die Vorhersagen eines Modells erklären. Um Zeit zu sparen, berechnen wir die Shapley-Werte nur für eine Stichprobe. Im `shap.summary_plot` wird je Feature (y-Achse) der Einfluss des Features auf die Vorhersage (x-Achse) in Abhängigkeit des Wert des Features (Farbe) gezeigt.","metadata":{}},{"cell_type":"code","source":"%%time\nimport shap\n\nfrom cuml.experimental.explainer import PermutationExplainer as cuPE\n\ncu_explainer = cuPE(model=models[horizon-1].predict, data=X) # ein wenig hacky: horizon sollte 7 sein, in X sollten die Trainingsdaten vom letzten Modell (7 Tage in die Zukunft) sein\n\nX_train_sample = X.sample(100) # nur 100 Beispiele für die Visualisierung nutzen\n\nshap_values = cu_explainer.shap_values(X_train_sample)\nshap.summary_plot(shap_values, X_train_sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Der `shap_force_plot` zeigt für eine konkrete Vorhersage die Wirkung der einzelnen Features auf die Vorhersage.","metadata":{}},{"cell_type":"code","source":"example_index = 42 # Index für ein konkretes Beispiel\nshap.initjs()\nshap.force_plot(cu_explainer.expected_value, shap_values[example_index], X_train_sample.values[example_index], feature_names=X_train_sample.columns.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Übung\n\nJetzt bist Du dran. Die Übungen wirst Du nicht mit den COVID-19-Zahlen machen, sondern mit den Daten aus dem fünften M-Wettbewerb zur Vorhersage von Zeitreihen.\n\n# Verkaufszahlen einlesen\n\nDie Daten für unseren Workshop kommen aus dem fünften M-Wettbewerb zur Vorhersage von Zeitreihen und sind Verkaufszahlen aus 10 verschiedenen Walmarts in den USA. Für diesen Workshop haben wir die Verkaufszahlen auf eine Auswahl von Produkten reduziert (die 15 meistverkauften Produkte je Abteilung). Wir nutzen für dieses Notebook nur Daten ab dem Jahr 2015.","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet('../input/m5-forecasting-parquet-and-aggregations/daily_sales_items_top105.parquet')\ndf = df.loc[df.date>='2015-01-01']\ndf['weekday'] = df['date'].dt.weekday\ndf.drop(columns=['d'], inplace=True)\nid_columns = [c for c in df.columns.values if 'id' in c]\nfor c in id_columns:\n    df[c] = df[c].astype('category')\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Aufgabe - direkte ML-Modelle\n\nErstelle Modelle für die Vorhersage der nächsten 7 Tagen. Erstelle dafür für jeden Vorhersageschritt (morgen, übermorgen, ...) ein eigenes Modell. Benutze einen gleitenden Durchschnitt über die letzten 7 Tagen und erstelle ein Trend-Feature wie im COVID-19 Beispiel ebenfalls mit einer Differenz von 7 Tagen. Nutze den Wochentag als Feature aber nicht das Datum. Plotte die Vorhersagen je Kategorie.","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"# die beiden Features value_trend und value_trend_slope erstellen, die Spalte id eignet sich für die Gruppierung","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training (7 direkte Modelle)","metadata":{}},{"cell_type":"code","source":"# dept_id, cat_id, usw. müssen kodiert werden\n# Training findet je Vorhersagehorizont statt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vorhersage (7 direkte Modelle)","metadata":{}},{"cell_type":"code","source":"# Als Vorhersagedatum das letzte Datum aus df nutzen\n# alle Vorhersagen in ein Ergbnis-Dataframe (result) schreiben","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot der Vorhersagen je Kategorie","metadata":{}},{"cell_type":"code","source":"# Zuerst den Ergebnis-Dataframe je Kategorie und Datum aggregieren, dann plotten (facet_row='cat_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Aufgabe - Shapley-Werte [*optional*]\n\nPlotte die Shapley-Werte für das letzte Modell mit dem Vorhersagehorizont von 7 Tagen.","metadata":{}},{"cell_type":"code","source":"# ggf. zuerst nur mit einer Stichprobe von 10 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Aufgabe - Direktes Modell mit variabler Schrittweite [*optional*]\n\nErstelle ein direktes Modell, dass alle sieben nächsten Tag vorhersagen kann (mit einem Feature `step_length`). Vergleiche dann die Vorhersage mit der Vorhersage aus den direkten Modellen mit statischem Vorhersagehorizont.","metadata":{}},{"cell_type":"code","source":"# 1. Die Trainingsdaten erstellen: je Vorhersagehorizont die Daten jeweils kopieren, step_length setzen und die Zielvariable mit shift berechnen\n# alles in einen DataFrame für X, am Ende die Zielwerte nach y extrahieren \n# 2. Modell auf X und y trainieren\n# 3. Xf für die Vorhersage erstellen.\n# 4. Ergebnis der Vorhersage in einen eigenen DataFrame speichern (nicht das aus der ersten Aufgabe überschreiben)\n# 5. Für den Plot zum Vergleich die beiden Ergebnis-DataFrames mergen\n# Hinweise:\n#    - ein DataFrame <mydf> kann z.B. <times>-mal kopiert werden: mydf.loc[mydf.index.repeat(times)]\n#    - eine Sequenz von <min_value> bis <max_value> kann <times>-mal wiederholt werden: list(range(min_value, max_value+1))*times","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Musterlösung: 1. Aufgabe - direkte Modelle","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"df.sort_values(['date'], inplace=True)\ndf['value_trend'] = df.groupby(['id'])['value'].rolling(window=7).mean().reset_index(level=0, drop=True)\ndf['value_trend_slope'] = df.groupby(['id'])['value_trend'].diff(7)\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training (7 direkte Modelle)","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrom cuml.ensemble import RandomForestRegressor\n\nhorizon = 7\n\n# Features für das Training\nX = df.dropna().copy() # nur mit Beispielen (Zeilen) trainieren, für die alle Features einen Wert haben\nX.drop(columns=['id', 'date'], inplace=True) # ID, Jahr und Monat nutzen wir nicht als Feature\nX['dept_id'] = X['dept_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['cat_id'] = X['cat_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['store_id'] = X['store_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['state_id'] = X['state_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['item_id'] = X['item_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX = X.astype('float32') # der Random Forest von RAPIDS mag nur Floats\n\n# Trainieren\nmodels = [] # Liste mit Modellen je Vorhersagehorizont\nfor h in range(1, horizon+1):\n    y = X.groupby(['store_id', 'dept_id', 'item_id'])['value'].shift(-h) # Zielvariable aus der verschobenen Zeitreihe ableiten\n    \n    model = RandomForestRegressor(max_depth=8, n_estimators=100)\n    model.fit(X[~y.isnull()], y.dropna()) # nur mit Beispielen trainieren, für die es einen Zielwert gibt\n    models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vorhersage (7 direkte Modelle)","metadata":{}},{"cell_type":"code","source":"forecast_date = df['date'].max()\n\n# Features für die Vorhersage\nXf = df[df['date']==forecast_date].copy()\nXf.drop(columns=['id', 'date'], inplace=True) # ID, Jahr und Monat nutzen wir nicht als Feature\n\nXf['dept_id'] = Xf['dept_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['cat_id'] = Xf['cat_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['store_id'] = Xf['store_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['state_id'] = Xf['state_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['item_id'] = Xf['item_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf = Xf.astype('float32')\n\nresult = pd.DataFrame() # wird alle Vorhersagen mit Country/Region, Datum und Wert enthalten\nfor h in range(0, horizon):\n    prediction = models[h].predict(Xf)\n    tmp = Xf[['dept_id', 'cat_id', 'store_id', 'state_id', 'item_id']].assign(forecast_value = prediction)\n    tmp['date'] = forecast_date + pd.DateOffset(days=h+1)\n    result = result.append(tmp)\n    \nresult['dept_id'] = df['dept_id'].cat.categories[result['dept_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult['cat_id'] = df['cat_id'].cat.categories[result['cat_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult['store_id'] = df['store_id'].cat.categories[result['store_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult['state_id'] = df['state_id'].cat.categories[result['state_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult['item_id'] = df['item_id'].cat.categories[result['item_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult = result.append(df.loc[df['date'] <= forecast_date][['dept_id', 'cat_id', 'store_id', 'state_id', 'item_id', 'date', 'value']]) # Ist-Werte zum Ergebnis hinzufügen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot der Vorhersagen je Kategorie","metadata":{}},{"cell_type":"code","source":"facet_column = 'cat_id' # probehalber auch mal mit state_id ausprobieren\n\nfig = px.line(result.\n                  groupby([facet_column, 'date']).\n                  agg({'value': sum, 'forecast_value': sum}).\n                  reset_index(),\n              x='date', y=['value', 'forecast_value'], facet_row=facet_column,\n              title='Titel')\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1]))\nfig.update_yaxes(matches=None)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Musterlösung: 2. Aufgabe - Shapley-Werte [*optional*]","metadata":{}},{"cell_type":"code","source":"%%time\nimport shap\n\nfrom cuml.experimental.explainer import PermutationExplainer as cuPE\n\ncu_explainer = cuPE(model=models[horizon-1].predict, data=X) # ein wenig hacky: horizon sollte 7 sein, in X sollten die Trainingsdaten vom letzten Modell (7 Tage in die Zukunft) sein\n\nX_train_sample = X.sample(100) # nur 100 Beispiele für die Visualisierung nutzen\n\nshap_values = cu_explainer.shap_values(X_train_sample)\nshap.summary_plot(shap_values, X_train_sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Aufgabe - Direktes Modell mit variabler Schrittweite [*optional*]","metadata":{}},{"cell_type":"code","source":"X = pd.DataFrame()\nhorizon = 7\nfor step_length in range(1, horizon+1):\n    tmp = df.copy()\n    tmp['step_length'] = step_length\n    tmp['target_value'] = tmp.groupby(['store_id', 'dept_id', 'item_id'])['value'].shift(-step_length)\n    X = tmp.append(X)\n\nX = X.dropna().copy() # nur mit Beispielen (Zeilen) trainieren, für die alle Features einen Wert haben\nX.drop(columns=['id', 'date'], inplace=True) # Jahr und Monat nutzen wir nicht als Feature\nX['dept_id'] = X['dept_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['cat_id'] = X['cat_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['store_id'] = X['store_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['state_id'] = X['state_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nX['item_id'] = X['item_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\n\nX = X.astype('float32') # der Random Forest von RAPIDS mag nur Floats\n\ny = X['target_value']\n\nX.drop(columns='target_value', inplace=True)\nX.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestRegressor(max_depth=8, n_estimators=100)\nmodel.fit(X[~y.isnull()], y.dropna()) # nur mit Beispielen trainieren, für die es einen Zielwert gibt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecast_date = df['date'].max()\n\nXf = df[df['date']==forecast_date].copy()\nXf.drop(columns=['id', 'date'], inplace=True) # ID, Jahr und Monat nutzen wir nicht als Feature\n\nXf['dept_id'] = Xf['dept_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['cat_id'] = Xf['cat_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['store_id'] = Xf['store_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['state_id'] = Xf['state_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\nXf['item_id'] = Xf['item_id'].cat.codes # RandomForest kann nur numerische Features handhaben => Kategorien konvertieren\n\nrow_count = len(Xf)\n\nXf = Xf.loc[Xf.index.repeat(horizon)]\nXf['step_length'] = list(range(1, horizon+1))*row_count\n\nXf = Xf.astype('float32')\n\nprediction = model.predict(Xf)\n\nresult2 = Xf[['dept_id', 'cat_id', 'store_id', 'state_id', 'item_id', 'step_length']].copy()\nresult2['date'] = forecast_date + result2['step_length'].astype('timedelta64[D]')\nresult2['forecast_value_vsl'] = prediction\n\nresult2['dept_id'] = df['dept_id'].cat.categories[result2['dept_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult2['cat_id'] = df['cat_id'].cat.categories[result2['cat_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult2['store_id'] = df['store_id'].cat.categories[result2['store_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult2['state_id'] = df['state_id'].cat.categories[result2['state_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\nresult2['item_id'] = df['item_id'].cat.categories[result2['item_id'].astype('int')] # Werte der Kategorien zurückkonvertieren\n\nresult_comparison = result.merge(result2, how='left', on=['dept_id', 'cat_id', 'store_id', 'state_id', 'item_id', 'date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facet_column = 'cat_id' # probehalber auch mal mit state_id ausprobieren\n\nfig = px.line(result_comparison.\n                  groupby([facet_column, 'date']).\n                  agg({'value': sum, 'forecast_value': sum, 'forecast_value_vsl': sum}).\n              reset_index(),\n              x='date', y=['value', 'forecast_value', 'forecast_value_vsl'], facet_row=facet_column,\n              title='Titel')\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1]))\nfig.update_yaxes(matches=None)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}