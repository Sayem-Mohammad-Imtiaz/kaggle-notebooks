{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/kritika200015/Covid19_symptoms-checker/blob/main/Tpot_classification_with_GA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"Covid-19 symptoms checker (using genetic algorithm)","metadata":{"id":"GjvFGCRSECx8"}},{"cell_type":"markdown","source":"Importing Lib and data","metadata":{"id":"Y0PyLKf6EJuV"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\ndf = pd.read_csv(\"Cleaned-Data.csv\")\ndataset = df.values","metadata":{"id":"z8TYPZPrvEFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"G-dvg9To1PdO","outputId":"f2d4c398-e1c6-4082-b43d-1872641b93cd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing","metadata":{"id":"SsDCU8q7EO22"}},{"cell_type":"code","source":"severity_columns = df.filter(like='Severity_').columns\ndf['Severity_None'].replace({1:'None',0:'No'},inplace =True)\ndf['Severity_Mild'].replace({1:'Mild',0:'No'},inplace =True)\ndf['Severity_Moderate'].replace({1:'Moderate',0:'No'},inplace =True)\ndf['Severity_Severe'].replace({1:'Severe',0:'No'},inplace =True)","metadata":{"id":"RgarqoU4vjrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Condition']=df[severity_columns].values.tolist()","metadata":{"id":"3WXcZBRxvjn3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def removing(list1):\n    list1 = set(list1) \n    list1.discard(\"No\")\n    a = ''.join(list1)\n    return a","metadata":{"id":"mXwn3n1LvjlT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Condition'] = df['Condition'].apply(removing)","metadata":{"id":"mrpx4sH1vjhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_columns = df.filter(like='Age_').columns\ngender_columns = df.filter(like='Gender_').columns\ncontact_columns = df.filter(like='Contact_').columns","metadata":{"id":"TIF1Zjewvjf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"No_risk_age = df.groupby(['Severity_None'])[age_columns].sum()\nNo_risk_gender = df.groupby(['Severity_None'])[gender_columns].sum()\nNo_risk_contact = df.groupby(['Severity_None'])[contact_columns].sum()","metadata":{"id":"urwq9dwUvjb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Low_risk_age = df.groupby(['Severity_Mild'])[age_columns].sum()\nLow_risk_gender = df.groupby(['Severity_Mild'])[gender_columns].sum()\nLow_risk_contact = df.groupby(['Severity_Mild'])[contact_columns].sum()","metadata":{"id":"PP4hUNSBvjaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Moderate_risk_age = df.groupby(['Severity_Moderate'])[age_columns].sum()\nModerate_risk_gender = df.groupby(['Severity_Moderate'])[gender_columns].sum()\nModerate_risk_contact = df.groupby(['Severity_Moderate'])[contact_columns].sum()","metadata":{"id":"VznorwuU1wGn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Severe_risk_age = df.groupby(['Severity_Severe'])[age_columns].sum()\nSevere_risk_gender = df.groupby(['Severity_Severe'])[gender_columns].sum()\nSevere_risk_contact = df.groupby(['Severity_Severe'])[contact_columns].sum()","metadata":{"id":"1TBpOwMA1wDz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(\"Country\",axis=1,inplace=True)\ndf.drop(severity_columns,axis=1,inplace=True)\ndf['Symptoms_Score'] = df.iloc[:,:5].sum(axis=1) + df.iloc[:,6:10].sum(axis=1)","metadata":{"id":"vERMs61712wG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Condition'].replace({'Mild':1,'None':0,'Moderate':1,'Severe':1},inplace =True)","metadata":{"id":"UzUOxx_k18lj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    print(\"\\nColumn Name:\",i,\"-->\",df[i].unique(),\"-->Unique Count\",len(df[i].unique()))","metadata":{"id":"dlwsjL-l195J","outputId":"db94ca16-755a-48ea-bcb2-1a491f3c4cf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow","metadata":{"id":"ijDV_YSR23KJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Downcasting ","metadata":{"id":"xnLKnIS_ET8f"}},{"cell_type":"code","source":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                      props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",props[col].dtype)\n            print(\"******************************\")\n            print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n    return props, NAlist\n","metadata":{"id":"NeFPhdANopNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, NAlist = reduce_mem_usage(df)\nprint(\"_________________\")\nprint(\"\")\nprint(\"Warning: the following columns have missing values filled with 'df['column_name'].min() -1': \")\nprint(\"_________________\")\nprint(\"\")\nprint(NAlist)","metadata":{"id":"pyyFmFqEpKWn","outputId":"444d5611-3f4e-4d32-c1f8-89251484efcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tpot","metadata":{"id":"e9G6-dqO3t6B","outputId":"1024f670-cc34-466d-c105-ee0e4fb2672c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model","metadata":{"id":"ZjiOHsrJEdRr"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx=df.drop(['Condition','Age_0-9', 'Age_10-19',\n       'Age_20-24', 'Age_25-59', 'Age_60+', 'Gender_Female', 'Gender_Male',\n       'Gender_Transgender', 'Contact_Dont-Know', 'Contact_No', 'Contact_Yes','Symptoms_Score','None_Sympton', 'Pains','None_Experiencing'],axis=1)\ny=df['Condition']\n\nx_train, x_test, y_train, y_test = train_test_split(x,y , test_size =0.2)","metadata":{"id":"q4lZe2V5s1F8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tpot import TPOTClassifier\n\n\ntpot_classifier = TPOTClassifier(generations= 5, population_size= 50,\n                                 verbosity= 2,\n                                 n_jobs = -1 , random_state = 1 , early_stop = 12,\n                                 cv = 5, scoring = 'accuracy')\ntpot_classifier.fit(x_train,y_train)","metadata":{"id":"kmIOIHJmsR_n","outputId":"efd6fa9a-4598-407d-c9fe-323e480f28ff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = tpot_classifier.score(x_test,y_test)\nprint(accuracy)","metadata":{"id":"PXmCWrLz5wqg","outputId":"f67dd2ce-5574-45ca-9c43-2362a9fec7b6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpot_classifier.export('optimal_pipeline.py')","metadata":{"id":"rk1hTccDE1R9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pipeline_suggested(df):\n\n  exported_pipeline = BernoulliNB(alpha=0.1, fit_prior=True)\n# Fix random state in exported estimator\n  if hasattr(exported_pipeline, 'random_state'):\n      setattr(exported_pipeline, 'random_state', 1)\n \n\n  exported_pipeline.fit(x_train, y_train)\n  print(f\"Train acc: {exported_pipeline.score(x_train, y_train)}\")\n  print(f\"Test acc: {exported_pipeline.score(x_test, y_test)}\")\n\n","metadata":{"id":"nR17SodwK72M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    # Copied from optimal pipeline suggested by tpot in file \"optimal_pipeline.py\"\n    # Initialize \n#exported_pipeline = make_pipeline(\n    \n    \n    \n    #PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n    #VarianceThreshold(threshold=0.2),\n    #ZeroCount(),\n    #GradientBoostingClassifier(learning_rate=1.0, max_depth=10, max_features=0.9000000000000001, min_samples_leaf=16, min_samples_split=3, n_estimators=100, subsample=0.7000000000000001)\n    #)\n    # Init training\nfrom sklearn.naive_bayes import BernoulliNB\nexported_pipeline = BernoulliNB(alpha=0.1, fit_prior=True)\nexported_pipeline.fit(x_train, y_train)\nprint(f\"Train acc: {exported_pipeline.score(x_train, y_train)}\")\nprint(f\"Test acc: {exported_pipeline.score(x_test, y_test)}\")\n   ","metadata":{"id":"ykeOVZKkMq1H","outputId":"204a4e95-b9a4-4c6c-c5f7-01398e398669"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" ","metadata":{"id":"UecgdoJGNyZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"6rsFcnhDNonx"},"execution_count":null,"outputs":[]}]}