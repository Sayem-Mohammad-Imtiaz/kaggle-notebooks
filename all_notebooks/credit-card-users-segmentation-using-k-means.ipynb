{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing all necessary libraries**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import DBSCAN\nimport collections\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import silhouette_score\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing data**\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data= pd.read_csv(\"/kaggle/input/ccdata/CC GENERAL.csv\")\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Customer ID is to be removed**\n(Customer ID is not required for clustering)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data.iloc[:,1:]\nx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Identifying Null Values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = x.isnull().sum()\nprint(missing)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x['MINIMUM_PAYMENTS'].fillna((x['MINIMUM_PAYMENTS'].mean()), inplace=True)\nx['CREDIT_LIMIT'].fillna((x['CREDIT_LIMIT'].mean()), inplace=True)\nprint(missing)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dealing with outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"z_score = np.abs(stats.zscore(x))\nprint(z_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data after removing outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_without_outlier = pd.DataFrame(x[(z_score < 3).all(axis=1)], columns = x.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shape of data without outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_without_outlier.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standardization for feature scaling\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(data_without_outlier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Applying principal component analysis (PCA) for dimensionality reduction **"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 2) \nX_principal = pca.fit_transform(X) \nX_principal = pd.DataFrame(X_principal) \nX_principal.columns = ['P1', 'P2'] \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding optimal number of clusters for K-MEANS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimal no. of clusters\nn_clusters=20\ncost=[]\nfor i in range(1,n_clusters):\n    kmean= KMeans(i)\n    kmean.fit(X_principal)\n    cost.append(kmean.inertia_)  \n   \nplt.plot(cost, 'bx-')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparing silhoutte scores for different no. of clusters **"},{"metadata":{"trusted":true},"cell_type":"code","source":"silhouette_scores = [] \nfor n_cluster in range(2, 8):\n    silhouette_scores.append(   \n        silhouette_score(X_principal, KMeans(n_clusters = n_cluster).fit_predict(X_principal))) \n    \nk = [2, 3, 4, 5, 6,7] \nplt.bar(k, silhouette_scores) \nplt.xlabel('Number of clusters', fontsize = 10) \nplt.ylabel('Silhouette Score', fontsize = 10) \nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Applying K-Means with no. of clusters as 3 because it has maximum silhoutte score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"db_default = KMeans(n_clusters=3, init='k-means++').fit(X_principal) \nlabels = db_default.labels_  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualization of clusters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"colours = {} \ncolours[0] = 'r'\ncolours[1] = 'y'\ncolours[2] = 'g'\n# Building the colour vector for each data point \ncvec = [colours[label] for label in labels] \n  \n# For the construction of the legend of the plot \n#r = plt.scatter(X_principal['P1'], X_principal['P2'], color ='r'); \n#y = plt.scatter(X_principal['P1'], X_principal['P2'], color ='y'); \n#g = plt.scatter(X_principal['P1'], X_principal['P2'], color ='g');  \n# Plotting P1 on the X-Axis and P2 on the Y-Axis  \n# according to the colour vector defined \nplt.figure(figsize =(9, 9))  \nplt.scatter(X_principal['P1'], X_principal['P2'], c = cvec) \n  \n# Building the legend \nplt.legend((r, y, g), ('Label 0','Label 1','Label 2')) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"visualizing each feature in each cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters=pd.concat([x, pd.DataFrame({'cluster':labels})], axis=1)\nclusters.head()\n\nfor cols in data_without_outlier:\n    g = sns.FacetGrid(clusters, col = 'cluster')\n    g.map(plt.hist, cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cluster analysis**\n* Cluster 0 : Customers with more usage of credit card and makes more frequent purchases of product.\n* Cluster 1 : Customers with least usage of credit card.\n* Cluster 2 : Customers with moderate usage of credit card."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}