{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\ndata=pd.read_csv(\"../input/Tweets.csv\")\n\n# Check the ratio of positive and negative tweets for each airline\ndata['countval']=1\ngroupby_object=data[['airline','airline_sentiment','countval']].groupby(['airline','airline_sentiment']).aggregate(sum)\ngroupby_object.unstack(level=1).plot(kind='bar')\nplt.show()\n\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Imports\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#####\ndata['text']=data['text'].map(lambda x: re.sub(\"^@[^\\s]+\\s\",\"\",x))\ndef getHashtag(x):\n\tg=re.match(\"^[^#]+#([^\\s]+).*\",x)\n\tif g:\n\t\treturn g.group(1)\n\telse:\n\t\treturn \"\"\n\t\ndata['hashtags']=data['text'].map(getHashtag)\n# Convert to lower case\ndata['hashtags']=data['hashtags'].str.lower() \n\nfrom nltk.corpus import stopwords\ndef review_to_words( raw_review ):\n    # Function to convert a raw review to a string of words\n    # The input is a single string (a raw movie review), and \n    # the output is a single string (a preprocessed movie review)\n    #\n    # 1. Remove HTML\n    review_text = raw_review\n    #\n    # 2. Remove non-letters        \n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n    #\n    # 3. Convert to lower case, split into individual words\n    words = letters_only.lower().split()                             \n    #\n    # 4. In Python, searching a set is much faster than searching\n    #   a list, so convert the stop words to a set\n    stops = set(stopwords.words(\"english\"))                  \n    # \n    # 5. Remove stop words\n    meaningful_words = [w for w in words if not w in stops]   \n    #\n    # 6. Join the words back into one string separated by space, \n    # and return the result.\n    return( \" \".join( meaningful_words ))   \n\nReviews=[]\ndataPos=data[data['airline_sentiment']=='positive']\nfor i in range(0, len(dataPos)):\n    Reviews.append(review_to_words(dataPos['text'].tolist()[i]))\n\nvect = TfidfVectorizer(sublinear_tf=True, max_df=0.5, analyzer='word',stop_words='english')\nvect.fit(Reviews)\nidf = vect._tfidf.idf_\nwordDict=dict(zip(vect.get_feature_names(), idf))\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"word1={k: v for k, v in wordDict.items() if v < 4}\nfrom wordcloud import WordCloud\nwordcloud = WordCloud().generate(' '.join(word1.keys()))\nplt.title('POSITIVE : TFID FREQ < 4')\nplt.imshow(wordcloud)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"word1={k: v for k, v in wordDict.items() if v > 4 and v <=5}\nfrom wordcloud import WordCloud\nwordcloud = WordCloud().generate(' '.join(word1.keys()))\nplt.title('POSITIVE : TFID FREQ between 4 and 5')\nplt.imshow(wordcloud)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"word1={k: v for k, v in wordDict.items() if v > 5 and v <= 6}\nfrom wordcloud import WordCloud\nwordcloud = WordCloud().generate(' '.join(word1.keys()))\nplt.title('POSITIVE: TFID FREQ between 5 and 6')\nplt.imshow(wordcloud)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}