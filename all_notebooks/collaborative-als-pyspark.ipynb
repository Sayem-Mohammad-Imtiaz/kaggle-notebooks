{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Installing PySpark"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Starting Spark Session with Context"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = SparkContext('local')\nspark = SparkSession(sc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To read the data, we first need to desin an scheme with appropriate data types, matching with CSV file inputs. Our dataset has three fields namely userID, songID, and rating."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_schema = StructType([\n    StructField('userID',IntegerType(), False),\n    StructField('songID',IntegerType(), False),\n    StructField('rating',IntegerType(), False),\n])\ndata = spark.read.csv(\n    '../input/dataset-for-collaborative-filters/songsDataset.csv', header=True, schema=input_schema\n).cache()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we split the data into training and test set, 78% testing and 22% test."},{"metadata":{"trusted":true},"cell_type":"code","source":"(training, test) = data.randomSplit([0.78, 0.22])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have required training and test dataset, we build collaborative filtering Alternate Least Squares model offered by PySpark. To solve the cold square problem, we use 'drop' strategy. We run our model for iterations."},{"metadata":{"trusted":true},"cell_type":"code","source":"als = ALS(maxIter=10, regParam=0.01, userCol=\"userID\", itemCol=\"songID\", ratingCol=\"rating\",\n          coldStartStrategy=\"drop\")\nmodel = als.fit(training)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we make predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We evaulate our model using MSE i.e., Mean Square Error metric."},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n                                predictionCol=\"prediction\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We find that the RMSE is 5.97. We can increase the number of iterations to better our result."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}