{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"<font size=\"10\" color=\"black\">Redução de dimensionalidade</font>\n\nEduardo Chaves Ferreira\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"## O que será tratado no curso\n\n\n- Seleção de variáveis\n\n- Criação de variáveis\n\n\n\n\n"},{"metadata":{"_uuid":"b89ace3ccc30394de0b5c6cfe3df4353822b30b3"},"cell_type":"markdown","source":"# 1- Importação de bibliotecas e funções gerais usadas no caderno"},{"metadata":{"_uuid":"f37277b0a0b0d139417f496eb641102f2d8c77a5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport random\nimport pandas as pd\nimport scipy.stats as stat\nimport seaborn as sns\nimport os\nimport pandas\nimport sklearn\n\nfrom IPython.display import Image\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n# Para ter repetibilidade nos resultados\nrandom_state = 1\n\n# Tratar valores infinitos como np.NaN\npandas.options.mode.use_inf_as_na = True\n\n# IMPORTANTE para tornar figuras interativas\n%matplotlib notebook\n\n# Tamanho padrão das figuras\nfigsize=(10,6)\n\n# Verificação do local para carga de dados\npath = os.environ['PATH']\n\nif path.startswith('C'):\n    IN_KAGGLE = False\nelse:\n    IN_KAGGLE = True\n    \n\n# Bibliotecas específicas do livro Introduction to Machine Learning with Python\n# https://github.com/amueller/introduction_to_ml_with_python\n# pip install mglearn\n\nimport mglearn\n\n\n# Configuração do número de linhas e colunas a serem apresentadas em listagens\npd.set_option('display.max_row', 1000)\n\npd.set_option('display.max_columns', 50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1fcbffb5dd4c49ffb0cbd6c87bdb3623b3a623a"},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9014ec6968dc5613ac6d28aae8d7afea7a24771"},"cell_type":"code","source":"# Função de conversão de dados copiada de https://github.com/shakedzy/dython/blob/master/dython/_private.py\n# Autor Shaked Zychlinski\n\ndef convert(data, to):\n    converted = None\n    if to == 'array':\n        if isinstance(data, np.ndarray):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values\n        elif isinstance(data, list):\n            converted = np.array(data)\n        elif isinstance(data, pd.DataFrame):\n            converted = data.as_matrix()\n    elif to == 'list':\n        if isinstance(data, list):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values.tolist()\n        elif isinstance(data, np.ndarray):\n            converted = data.tolist()\n    elif to == 'dataframe':\n        if isinstance(data, pd.DataFrame):\n            converted = data\n        elif isinstance(data, np.ndarray):\n            converted = pd.DataFrame(data)\n    else:\n        raise ValueError(\"Unknown data conversion: {}\".format(to))\n    if converted is None:\n        raise TypeError('cannot handle data conversion of type: {} to {}'.format(type(data),to))\n    else:\n        return converted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a3f09bce6c0d925ac7b1050023ce6291d3eb870"},"cell_type":"markdown","source":"## Treinamento de rede neural para regressão\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"},{"metadata":{"_uuid":"5eced01f10b015a9c1ec3a23447aaf196cb496a3","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\n\ndef redes_neurais_regressao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    #Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n        Y_escale = Y_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_escale, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPRegressor(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Rede Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    mean_error = mean_absolute_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorNN.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorNN,r2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aff2949bdf0163433a74054dad0958d245a1c08e"},"cell_type":"markdown","source":"## Treinamento de rede neural para classificação\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"},{"metadata":{"_uuid":"5eced01f10b015a9c1ec3a23447aaf196cb496a3","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndef redes_neurais_classificacao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPClassifier(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Rede Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    # TN FP\n    # FN TP\n    confusion = confusion_matrix(y_test, estimatorNN.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorNN.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorNN.predict(x_test)-y_test))/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorNN.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorNN,erro","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9992b33438f4c538e84a84bfd2e0f5205296da"},"cell_type":"markdown","source":"## Treinamento de árvore de decisão para regressão\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html"},{"metadata":{"_uuid":"07b481b67566137b174f98dfd739244708b06bb8","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndef arvore_regressao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeRegressor(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Árvore Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    print('Importâncias {}'.format(estimatorTree.feature_importances_))\n    \n    mean_error = mean_absolute_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorTree.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorTree,r2\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9992b33438f4c538e84a84bfd2e0f5205296da"},"cell_type":"markdown","source":"## Treinamento de árvore de decisão para classificação\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/auto_examples/tree/plot_tree_Classifier.html"},{"metadata":{"_uuid":"07b481b67566137b174f98dfd739244708b06bb8","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndef arvore_classificacao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeClassifier(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Árvore Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n\n    \n    \n    print('Importâncias {}'.format(estimatorTree.feature_importances_))\n    \n    confusion = confusion_matrix(y_test, estimatorTree.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorTree.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorTree.predict(x_test)-y_test))/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorTree.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorTree,erro\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9d0b6d33af5ef15943cdaeced9a80462aa70fd3"},"cell_type":"markdown","source":"# 2- Carga de dados\n\n\n"},{"metadata":{"_uuid":"bf6d83547c87e91c887dfd0d90feeebcc9994541"},"cell_type":"markdown","source":"## Dados de exemplo\n\nWorld happiness report (http://worldhappiness.report/).\n\nSomente variáveis numéricas"},{"metadata":{"_uuid":"a33e914fc27cbdb5d46cd13d4cf36ab031ae8c89","trusted":true},"cell_type":"code","source":"if IN_KAGGLE:\n    world_happiness = pd.read_csv(\"../input/world-happiness/2016.csv\")\nelse:\n    world_happiness = pd.read_csv(\"2016.csv\")\n\n# Conjunto completo\nworld_happiness = world_happiness.loc[:,['Country', 'Region', 'Happiness Rank', 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']]\n\n\n\n#world_happiness = shuffle(world_happiness).reset_index(drop=True)\n\n# Conjunto resumido para treinamento de modelos\nworld_happiness_resumido = world_happiness.loc[:,[ 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity']]\n\n# Cria variáveis para treinamento de modelos\n\ncolunas_fonte = [ \n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity'\n]\n\ncolunas_objetivo = [ \n       'Happiness Score'\n]\n\nworld_happiness_resumido_X = world_happiness_resumido.loc[:,colunas_fonte] \nworld_happiness_resumido_Y = world_happiness_resumido.loc[:,colunas_objetivo]\n\n\nworld_happiness.head(35)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"648bdf45822c79f5d3ea778738fa8f204a28abca"},"cell_type":"markdown","source":"## Carrega dados para exercício\n"},{"metadata":{"_uuid":"f19b485f7b6db74b6b9a046a57ef90b2f4a2eb72"},"cell_type":"markdown","source":"Data set de gorgetas com variáveis categóricas"},{"metadata":{"trusted":true,"_uuid":"18be13ca95dc229a6244ae0045fcad0f0c84f6ae"},"cell_type":"code","source":"if IN_KAGGLE:\n    tips = pd.read_csv('../input/snstips/tips.csv')\n    if 'Unnamed: 0' in tips.columns:\n        tips.drop(['Unnamed: 0'], inplace=True, axis=1)\nelse:\n    tips = sns.load_dataset('tips')\n\ntips.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a8aef273babfb3ab3f8366694517ea9f80dcca"},"cell_type":"markdown","source":"Dados sobre tumores (somente informações numéricas)\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"},{"metadata":{"_uuid":"fbd3fcbc4e5624d48f4c41e6bf16ce31a609158d","trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\n\ncancer = load_breast_cancer()\n\ncancer_data = cancer['data']\n# 1 benigno, 0 maligno\ncancer_target = cancer['target']\ncancer_target_names  = cancer['target_names']\ncancer_feature_names = cancer['feature_names']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"847b2f3ad98bfc2256612d5cacfd724bd290ff09"},"cell_type":"code","source":"cancer_data_DF = pd.DataFrame(cancer_data,columns=cancer_feature_names) \ncancer_data_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd7c3e30d711a5dcd04fd474c987484bf3acd9f8"},"cell_type":"code","source":"cancer_target_DF = pd.DataFrame(cancer_target,columns=['target']) \ncancer_target_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1146037874e599323023f8f496685204729f660e"},"cell_type":"markdown","source":"# 8- Redução de dimensionalidade por seleção de variáveis\n\nhttp://scikit-learn.org/stable/modules/feature_selection.html\n\nTem o objetivo de descartar parte das variáveis de forma a simplificar os modelos e facilitar sua convergência"},{"metadata":{"_uuid":"8cb585d658ce2938d0576a32dc372b34bd6fcb20"},"cell_type":"markdown","source":"## Análise de variância\n\nhttp://scikit-learn.org/stable/modules/feature_selection.html\n\nVariáveis com maior variância tendem a ser melhor descriminadores, ou seja, são mais adequadas para utilização em algoritmos de classificação e regressão.\n\nVarianceThreshold seleciona colunas cuja variância esteja acima de determinado valor, passado como parâmetro\n\n"},{"metadata":{"_uuid":"d946417c08f4ed7f4396f1c4f5aa3558aaf38cb2","trusted":true},"cell_type":"code","source":"world_happiness_resumido_X.var()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b7205017fc4abebc46aca1b3cc7e122886d50fb","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\n\nsel = VarianceThreshold(threshold=0.05)\nworld_happiness_resumido_VarianceThreshold = sel.fit_transform(world_happiness_resumido_X)\nworld_happiness_resumido_VarianceThreshold[0:5,:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffffe78b2c5e466fff383882ca0e6a3a27ac22b7","trusted":true},"cell_type":"code","source":"world_happiness_resumido_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceaefc5ac7eed71a86fa7796bfff1cdd9003a223"},"cell_type":"code","source":"world_happiness_resumido_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d569b7318a50e4d2feacb80360ed06d1f8c7ceab"},"cell_type":"code","source":"world_happiness_resumido_VarianceThreshold.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec6b37a9927c556672c697a29fd1925d81b273ef"},"cell_type":"code","source":"_,_ = redes_neurais_regressao(world_happiness_resumido_X, \n                              world_happiness_resumido_Y\n                                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9708b85ece4120c5925a0667cc73b2cc0740f836"},"cell_type":"code","source":"_,_ = redes_neurais_regressao(world_happiness_resumido_VarianceThreshold, \n                              world_happiness_resumido_Y\n                                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75b2b5ed10090231e694dd54292a6b9ac7629cbc"},"cell_type":"code","source":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_VarianceThreshold, \n                              world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cdd00dd3f8bee8e1a2dacf28c2c5025ec6502e1"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nRealize a análise acima para cancer_data_DF\n"},{"metadata":{"_uuid":"d946417c08f4ed7f4396f1c4f5aa3558aaf38cb2","trusted":true},"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\ncancer_data_DF_scaled = min_max_scaler.fit_transform(cancer_data_DF)\ncancer_data_DF_scaled = pd.DataFrame(cancer_data_DF_scaled,columns=cancer_feature_names) \ncancer_data_DF_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be1a9ab0f2463089e573d4ddac4bd740e0637823"},"cell_type":"code","source":"cancer_data_DF_scaled.var()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b7205017fc4abebc46aca1b3cc7e122886d50fb","trusted":true},"cell_type":"code","source":"cancer_data_DF_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ab3e6fe64c1d543c3d7694d81198ee4a643018c"},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\n\nsel = VarianceThreshold(threshold=0.02)\ncancer_data_DF_scaled_VarianceThreshold = sel.fit_transform(cancer_data_DF_scaled)\ncancer_data_DF_scaled_VarianceThreshold.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8310365dac90424141c620594119e9cbe8a86c4"},"cell_type":"code","source":"_,_ = redes_neurais_classificacao(cancer_data_DF_scaled, \n                              cancer_target_DF\n                                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d41abb2421cc9d62d282b7d20f10feb764bafa0e"},"cell_type":"code","source":"_,_ = redes_neurais_classificacao(cancer_data_DF_scaled_VarianceThreshold, \n                              cancer_target_DF\n                                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de889b95333fcfbfd90b3ee6b4f9fe682020fe7d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c447caeadc748e82e0961bce5b07c15d41521b95"},"cell_type":"markdown","source":"# Estatística Univariada\n\nVerifica correlações lineares entre variáveis e entre elas com a variável dependente\n\nNo caso de classificação é chamada analysis of variance (ANOVA)."},{"metadata":{"_uuid":"367b976bd71784a3b5bd9bba51cddcf7a5f45671"},"cell_type":"markdown","source":"## Análise de correlação linear\n\nhttp://scikit-learn.org/stable/modules/feature_selection.html"},{"metadata":{"_uuid":"f43f399bb5bcf345c5b21f78fd93a11001fee181","trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\n\nworld_happiness_resumido_SelectKBest = SelectKBest(f_regression, k=2).fit_transform(world_happiness_resumido_X, np.ravel(world_happiness_resumido_Y))\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(world_happiness_resumido_SelectKBest[:,0], \n            world_happiness_resumido_SelectKBest[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b0706e2ac2611ce6dc1fe2652ede235896a57d5","trusted":true},"cell_type":"code","source":"estimatorNN,_ = redes_neurais_regressao(world_happiness_resumido_SelectKBest, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfc0d59329af9e589cd38f18de3680a0d183a161"},"cell_type":"code","source":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_SelectKBest, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a48ca6c7989a9e1f234c18de982d3efdb47e1af"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nRealize a análise acima para cancer_data_DF\n\n\n"},{"metadata":{"_uuid":"f43f399bb5bcf345c5b21f78fd93a11001fee181","trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\ncancer_data_SelectKBest = SelectKBest(f_classif, k=2).fit_transform(\n    cancer_data_DF_scaled, np.ravel(cancer_target_DF))\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(cancer_data_SelectKBest[:,0], \n            cancer_data_SelectKBest[:,1], \n            s=(cancer_target_DF.values+1)*30)\nplt.grid(True)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b97b1c87866a7a95039d3f505a7d5292a1d664d"},"cell_type":"code","source":"_,_ = redes_neurais_classificacao(cancer_data_SelectKBest, \n                              cancer_target_DF\n                                       )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bff1d7b7aff0e8668aaba23113445e2334daf29"},"cell_type":"markdown","source":"## SelectFromModel\nhttp://scikit-learn.org/stable/modules/feature_selection.html"},{"metadata":{"_uuid":"b38a0ab732674333119e7ad51f1d9215c5ce4930","trusted":true,"scrolled":false},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nestimatorArvore,_ = arvore_regressao(world_happiness_resumido_X, world_happiness_resumido_Y)\n\nmodel = SelectFromModel(estimatorArvore, prefit=True)\nworld_happiness_resumido_SelectKBest = model.transform(world_happiness_resumido_X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a643fe3933037694bf6c8fe57cc7cc34f81bc1e"},"cell_type":"code","source":"world_happiness_resumido_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5521da261ebf37a96befe1b77cbc2565f8933b3b"},"cell_type":"code","source":"world_happiness_resumido_SelectKBest.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c4ec0d3cb2bf6b629c7d3465d6593b568d52344","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(world_happiness_resumido_SelectKBest[:,0], \n            world_happiness_resumido_SelectKBest[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3a97859556594ea477f4916759a5a6708849976"},"cell_type":"code","source":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_SelectKBest, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01a738ce8bcd217b13168eab11b48c0a91591cff"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nRealize a análise acima para cancer_data_DF\n"},{"metadata":{"_uuid":"b38a0ab732674333119e7ad51f1d9215c5ce4930","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nestimatorArvore,_ = arvore_classificacao(cancer_data_DF_scaled, cancer_target_DF)\n\nmodel = SelectFromModel(estimatorArvore, prefit=True)\ncancer_data_SelectKBest = model.transform(cancer_data_DF)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c4ec0d3cb2bf6b629c7d3465d6593b568d52344","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(cancer_data_SelectKBest[:,0], \n            cancer_data_SelectKBest[:,1], \n            s=(cancer_target_DF.values+1)*30)\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc8ef4b48b6c5716278a37b6c2a16130d190adc4"},"cell_type":"code","source":"_,_ = redes_neurais_classificacao(cancer_data_SelectKBest, \n                              cancer_target_DF\n                                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8bca42a9b8e861f02fcd744ecd99b8fc141eb58"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"798229d794ffadbe9af2fa99534030da247aea12"},"cell_type":"markdown","source":"## SelectPercentil"},{"metadata":{"_uuid":"8d5db2b2935e90d1a307428cae7cbcad69d59792","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectPercentile\n\nselect = SelectPercentile(percentile=50)\nselect.fit(world_happiness_resumido_X, world_happiness_resumido_Y)\nworld_happiness_resumido_SelectPercentile = select.transform(world_happiness_resumido_X)\nprint(\"X.shape: {}\".format(world_happiness_resumido_X.shape))\nprint(\"X_SelectPercentile.shape: {}\".format(world_happiness_resumido_SelectPercentile.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c4ec0d3cb2bf6b629c7d3465d6593b568d52344","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(world_happiness_resumido_SelectPercentile[:,0], \n            world_happiness_resumido_SelectPercentile[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"091b76846828931af134c1e0708355aceac43457","trusted":true},"cell_type":"code","source":"estimatorNN,_ = redes_neurais_regressao(world_happiness_resumido_SelectPercentile, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4dbf28a30c45ba7790dae0339ccf3f20e6c406c"},"cell_type":"code","source":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_SelectPercentile, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6dab864964982d698e3d0428a27f79b8966c3aa6"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nRealize a análise acima para cancer_data_DF\n"},{"metadata":{"_uuid":"8d5db2b2935e90d1a307428cae7cbcad69d59792","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c4ec0d3cb2bf6b629c7d3465d6593b568d52344","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a79795ed547317c965344b35936c36f774b4797"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cd14953098d12f6f9129c1458cf0c9a9c99fb48"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c4a046aa139583d7c8b14d1755f5e882f67cc9d"},"cell_type":"markdown","source":"# 9- Redução de dimensionalidade por criação de variáveis"},{"metadata":{"_uuid":"f53208026c48e8924863091815803a5a3927e4d1"},"cell_type":"markdown","source":"## Análise de Fatores\n\nIdentifica novas variáveis (fatores) que justifiquem as correlações existentes entre as variáveis"},{"metadata":{"_uuid":"461a9f93e6680ba582c02b20c83f7d8ad290757f","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import FactorAnalysis\nfactor = FactorAnalysis(n_components=2, random_state=random_state).fit(world_happiness_resumido_X)\nworld_happiness_resumido_factor = factor.transform(world_happiness_resumido_X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"379eed59abd4e289c80df010d24b9200b2ffe807","trusted":true},"cell_type":"code","source":"pd.DataFrame(factor.components_,columns=world_happiness_resumido_X.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c4ec0d3cb2bf6b629c7d3465d6593b568d52344","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(world_happiness_resumido_factor[:,0], \n            world_happiness_resumido_factor[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da2d5adcf3ac4edc8ede0efcf738e51f27e79355","trusted":true},"cell_type":"code","source":"_,_ = redes_neurais_regressao(world_happiness_resumido_factor, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da2d5adcf3ac4edc8ede0efcf738e51f27e79355","trusted":true},"cell_type":"code","source":"_,_ = arvore_regressao(world_happiness_resumido_factor, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91d2657fd299865ad1c989d033865ea13ef9adf2"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nRealize a análise acima para cancer_data_DF\n"},{"metadata":{"_uuid":"461a9f93e6680ba582c02b20c83f7d8ad290757f","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import FactorAnalysis\nfactor = FactorAnalysis(n_components=2, random_state=random_state).fit(cancer_data_DF)\ncancer_data_DF_factor = factor.transform(cancer_data_DF)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"379eed59abd4e289c80df010d24b9200b2ffe807","trusted":true},"cell_type":"code","source":"pd.DataFrame(factor.components_,columns=cancer_data_DF.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c4ec0d3cb2bf6b629c7d3465d6593b568d52344","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(cancer_data_DF_factor[:,0], \n            cancer_data_DF_factor[:,1], \n            s=(cancer_target_DF.values+1)*30)\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da2d5adcf3ac4edc8ede0efcf738e51f27e79355","trusted":true},"cell_type":"code","source":"_,_ = redes_neurais_classificacao(cancer_data_DF_factor, cancer_target_DF)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da2d5adcf3ac4edc8ede0efcf738e51f27e79355","trusted":true},"cell_type":"code","source":"_,_ = arvore_classificacao(cancer_data_DF_factor, cancer_target_DF)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b46ae082bcd6103ea5d93cdf471e4b7d8d5a287b"},"cell_type":"markdown","source":"## Análise de Componentes Principais (PCA)\n\nhttps://www.dummies.com/programming/big-data/data-science/data-science-using-python-to-perform-factor-and-principal-component-analysis/\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n\nRotaciona dataset de forma a diminuir correlação\n\nOs componentes são ordenados por variância\n\nHá tantos componentes quanto dimensões no espaço original\n\nUtilizado para diminuição de dimensionalidade e escolha de componentes (ou eixos) principais.\n\n"},{"metadata":{"trusted":true,"_uuid":"2f8c52639f67d7344f70ba9b4a10c31d48c9d09c"},"cell_type":"code","source":"# fonte Introduction to Machine Learning with Python\n# by Andreas C. Müller and Sarah Guido\n\nimport mglearn\nmglearn.plots.plot_pca_illustration()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15683af1090ea82b58d5a4f001b013525d090a03","trusted":true},"cell_type":"code","source":"\n\npca = PCA(random_state=random_state).fit(world_happiness_resumido_X)\nprint ('Variância por componente: {}'.format(pca.explained_variance_ratio_))\npd.DataFrame(pca.components_,columns=world_happiness_resumido_X.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75e9a971202f8c031d63cfc47f3208eec55a9ac6"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit (world_happiness_resumido_X)\nworld_happiness_resumido_X_scaled = scaler.transform(world_happiness_resumido_X)\n\npca = PCA(random_state=random_state).fit(world_happiness_resumido_X_scaled)\nprint ('Variância por componente: {}'.format(pca.explained_variance_ratio_))\npd.DataFrame(pca.components_,columns=world_happiness_resumido_X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ab46338046fa7deab97caf0be1abad8e20b047f"},"cell_type":"code","source":"# Variância do conjunto original\n\nworld_happiness_resumido_X.var()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"695a4362c0e55de0526de14df028f6976208fadd"},"cell_type":"code","source":"# Variância dos dados projetados\n\nworld_happiness_resumido_PCA = PCA(random_state=random_state).fit_transform(world_happiness_resumido_X_scaled)\nnp.var(world_happiness_resumido_PCA, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01b18e252ba0e32bee9397975ff7f2ddcf216d05","trusted":true},"cell_type":"code","source":"# PCA não garante separabilidade do conjunto\n\nfrom sklearn.decomposition import PCA\n\nworld_happiness_resumido_PCA = PCA(n_components=2,random_state=random_state).fit_transform(world_happiness_resumido_X_scaled)\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(world_happiness_resumido_PCA[:,0], world_happiness_resumido_PCA[:,1], s=world_happiness_resumido_Y.values**3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1658ce3526875e746dfd04c439c819d75275351d"},"cell_type":"markdown","source":"## TSNE\n\nMétodo de visualização de conjuntos de dados de alta dimensionalidade\n\nBusca proximidade dos pontos no espaço original e tenta preservar tal proximidade em espaço de menor dimensão"},{"metadata":{"trusted":true,"_uuid":"6c7bfb5dfcc1812c3f6e209d67949cdeec96f437"},"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne = TSNE(random_state=random_state)\n# use fit_transform instead of fit, as TSNE has no transform method\n# default 2 componentes\nworld_happiness_tsne = tsne.fit_transform(world_happiness_resumido_X_scaled)\n\nplt.figure(figsize=figsize)\nplt.scatter(world_happiness_tsne[:,0], world_happiness_tsne[:,1], s=world_happiness_resumido_Y.values**3)\n\nplt.xlabel(\"t-SNE feature 0\")\nplt.xlabel(\"t-SNE feature 1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37aa03cfc8218afcca1041099886e57cabf368dd"},"cell_type":"code","source":"world_happiness_resumido_X_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6402590daf5d98ee5919b3d0d5844b27bc39d69c"},"cell_type":"code","source":"world_happiness_tsne.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e39713872afaf1b50b31a273b51ba7403fadb87d"},"cell_type":"markdown","source":"## KernelPCA\n\nTransforma o espaço original através de Kernels para só então aplicar PCA\n\nVer exemplo em http://scikit-learn.org/stable/auto_examples/decomposition/plot_kernel_pca.html"},{"metadata":{"trusted":true,"_uuid":"8a2cf0e2481fd370d08ae80adc8705211e2c1078"},"cell_type":"code","source":"# Kernel PCA pode melhorar a separabilidade\n# http://scikit-learn.org/stable/auto_examples/decomposition/plot_kernel_pca.html#sphx-glr-auto-examples-decomposition-plot-kernel-pca-py\n\n\nfrom sklearn.decomposition import PCA, KernelPCA\n\n\nkpca = KernelPCA(\n    kernel=\"sigmoid\", \n    fit_inverse_transform=True)\n\nworld_happiness_resumido_PCA = kpca.fit_transform(world_happiness_resumido_X_scaled)\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(world_happiness_resumido_PCA[:,0], world_happiness_resumido_PCA[:,1], s=world_happiness_resumido_Y.values**3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e96eed34db1be7687feca73071a619d9f17d8fd3"},"cell_type":"code","source":"world_happiness_resumido_X_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e229884511999e0ed2203d7f7a99692c6a9cb72"},"cell_type":"code","source":"world_happiness_resumido_PCA.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2972fc3ff819271413a39f5741dd920455df5b4","trusted":true},"cell_type":"code","source":"_,_ = arvore_regressao(world_happiness_resumido_PCA, world_happiness_resumido_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"069442793c2a9e252a9eaa15b7272bd8af63bf4e"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nRealize a análise acima para cancer_data_DF\n"},{"metadata":{"trusted":true,"_uuid":"fa9fd2f6ef0b864d04ac27f619ad348e5e90711d"},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\ncancer = load_breast_cancer()\nscaler = StandardScaler()\nscaler.fit(cancer.data)\nX_scaled = scaler.transform(cancer.data)\n\nfrom sklearn.decomposition import PCA\n# keep the first two principal components of the data\npca = PCA(n_components=2)\n# fit PCA model to breast cancer data\npca.fit(X_scaled)\n# transform data onto the first two principal components\nX_pca = pca.transform(X_scaled)\nprint(\"Original shape: {}\".format(str(X_scaled.shape)))\nprint(\"Reduced shape: {}\".format(str(X_pca.shape)))\n\nplt.figure(figsize=(8, 8))\nmglearn.discrete_scatter(X_pca[:, 0], X_pca[:, 1], cancer.target)\nplt.legend(cancer.target_names, loc=\"best\")\nplt.gca().set_aspect(\"equal\")\nplt.xlabel(\"First principal component\")\nplt.ylabel(\"Second principal component\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"231a72163474b0ecd1c56999ec814ca66acdd506"},"cell_type":"code","source":"plt.matshow(pca.components_, cmap='viridis')\nplt.yticks([0, 1], [\"First component\", \"Second component\"])\nplt.colorbar()\nplt.xticks(range(len(cancer.feature_names)),\ncancer.feature_names, rotation=60, ha='left')\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Principal components\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cfbf02b8aab2d1a9ea2f10c0529da221fefb267"},"cell_type":"code","source":"_,_ = redes_neurais_classificacao(X_pca[:,0:2], cancer_target_DF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7da361b7732ae9f6aaf9a6d673023ef5cd50ea9e"},"cell_type":"code","source":"_,_ = arvore_classificacao(X_pca[:,0:2], cancer_target_DF)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"060915bd6f225186dd76e68bdc3d3f95c69a50e3"},"cell_type":"markdown","source":"# Referências\n\nLivros usados como referência:\n\nIntroduction to Machine Learning with Python\n\nPython Data Science Handbook (https://www.oreilly.com/library/view/python-data-science/9781491912126/)\n\nVisualização:\n\nhttps://python-graph-gallery.com/\n\nhttp://www.apnorton.com/blog/2016/12/19/Visualizing-Multidimensional-Data-in-Python/\n\nhttps://towardsdatascience.com/the-art-of-effective-visualization-of-multi-dimensional-data-6c7202990c57\n\nhttps://www.oreilly.com/library/view/python-data-science/9781491912126/ch04.html\n\nhttps://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}