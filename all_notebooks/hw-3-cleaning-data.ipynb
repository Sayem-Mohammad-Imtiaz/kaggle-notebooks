{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Hi, in this kernel I will try to improve my Data Cleaning skills and get used to play with Datasets\n\nthis kernel will include most of the knowledge I get from te course so far such as plots etc.\n"},{"metadata":{"_uuid":"704a731c498dcc2dced4f0859a8458aec57ac26e"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"86b658b6ea570a3064397cce5fdc1a32b3e7605f"},"cell_type":"code","source":"data = pd.read_csv(\"../input/countries of the world.csv\")  #getting the data with pandas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"550ca3292287c24dcb0215a866e1084341f9727c"},"cell_type":"code","source":"data.info()  # learning more about the data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfb22a79d1d5cbd0de309c3e4af4a642e339de2d"},"cell_type":"markdown","source":"Our very first problem seems to be data types of most columns. \nAs seen above, numerical values doesn't have a numerical data types such as int or float. But we can work on it\n\nLet's continue to explore"},{"metadata":{"trusted":true,"_uuid":"864112553b3e22142f0c1bf05d124b9cb5c487bf"},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54707ff6e521d0949cbd29a57e74f575e559ae50"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8f6253001de087a1c141602189928c256ef0603"},"cell_type":"markdown","source":"above we see only 3 columns, which is absolutely not what we desire.\n\nAs seen above with \" data.head() \" our main problem seems to be the comma( , ) instad of dot( . ) if we can replace, then we can transform our data types into float"},{"metadata":{"trusted":true,"_uuid":"2dc53c1e1a0fc779e07835056c9745e901f28041"},"cell_type":"code","source":"def comma_to_dot(data):\n    \"\"\"This function is created for the replacement of comma with dot and changing the data type to float\"\"\"\n    data = str(data);   # for any type of unexpected data types\n    data = data.replace(\",\",\".\");\n    data = float(data);\n    return data;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d971e445de0a20dad85064938d76979eaf811e66","scrolled":true},"cell_type":"code","source":"print(data.columns)    # checking the full names of each column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"450855b04313cec6041abf9038de7b5fa8f9c36e"},"cell_type":"markdown","source":"Now we can apply our function on each column we need below.\n\nUnfortunately, the data has column name inconsistency but we can use as \" data[' GDP ($ per capita ) ' ] \""},{"metadata":{"trusted":true,"_uuid":"f5db9e28c86ccbbcb1a14d5404db2d8350a27d61"},"cell_type":"code","source":"data['Pop. Density (per sq. mi.)'] = list(map(comma_to_dot,data['Pop. Density (per sq. mi.)']))\ndata['Coastline (coast/area ratio)'] = list(map(comma_to_dot,data['Coastline (coast/area ratio)']))\ndata['Net migration'] = list(map(comma_to_dot,data['Net migration']))\ndata['Infant mortality (per 1000 births)'] = list(map(comma_to_dot,data['Infant mortality (per 1000 births)']))\ndata['GDP ($ per capita)'] = list(map(comma_to_dot,data['GDP ($ per capita)']))\ndata['Literacy (%)'] = list(map(comma_to_dot,data['Literacy (%)']))\ndata['Phones (per 1000)'] = list(map(comma_to_dot,data['Phones (per 1000)']))\ndata['Arable (%)'] = list(map(comma_to_dot,data['Arable (%)']))\ndata['Crops (%)'] = list(map(comma_to_dot,data['Crops (%)']))\ndata['Other (%)'] = list(map(comma_to_dot,data['Other (%)']))\ndata['Climate'] = list(map(comma_to_dot,data['Climate']))\ndata['Birthrate'] = list(map(comma_to_dot,data['Birthrate']))\ndata['Deathrate'] = list(map(comma_to_dot,data['Deathrate']))\ndata['Agriculture'] = list(map(comma_to_dot,data['Agriculture']))\ndata['Industry'] = list(map(comma_to_dot,data['Industry']))\ndata['Service'] = list(map(comma_to_dot,data['Service']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec78ed464bb57a3f804a3379c342008292c2eb99"},"cell_type":"code","source":"data.head(10)   # to see results on dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c977d13ad5b2a0ef67c4b0cc447bcc02e6b6a3eb"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f78480eb52388810f3ad51d289faad104d29011"},"cell_type":"code","source":"data.info();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3185909ee2185cd11ee0e371ab705aeb59926a1"},"cell_type":"markdown","source":"Now we have what we wanted, our data is much more easy to work with and data types are just as we would wish.\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2052732c2c9e0eaf063601541193a3271fb5aee2"},"cell_type":"code","source":"data.Climate.value_counts(dropna=False)   \n# it is interesting that 2.0 and 3.0 is most common but the 2.5 is least common one even that it's just between most common values.\n# also we have a lot of NaN values.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"decb129a8f7a730063b9b8e273f78c284c17045e"},"cell_type":"markdown","source":"Let's drop the all null values since this notebook is for experimenting"},{"metadata":{"trusted":true,"_uuid":"ad36b871bae234be89defcc0bf268a1b7ae322d0"},"cell_type":"code","source":"data = data.dropna();\n\ndata.info();   # we still have 180 countries that we can work on easily.  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c6e3a6de91f95e0742091c07bc675ce41438080"},"cell_type":"code","source":"data.boxplot(figsize=(20,8), column='Literacy (%)', by='GDP ($ per capita)', grid=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c3f40067aa57f3814b4396e52e92f9b95fb33c9"},"cell_type":"markdown","source":"## The BoxPlot above is interesting but not surprising.\nAs seen, Literacy has very big effect on the income of people and government which is not a surprise. The surprise is that there is not many outliner values on this plot which means there is almost no exceptional cases for it.  "},{"metadata":{"_uuid":"88c2c4fd11e4317cadfa1c7f2134f03f4f291b41"},"cell_type":"markdown","source":"Let's check for correlation of our dataset."},{"metadata":{"trusted":true,"_uuid":"91f598bbce2f946a7f14e69b9d729b8938cff113"},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9068195fb3de21b0392778a6e1e8c47ec0d48e2d"},"cell_type":"code","source":"plt.clf()\nplt.figure(figsize=(20,12))\nsns.heatmap(data.corr(),annot=True,fmt='1.1f')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36aa5d85fa118e5525c1b6fa2a3cd43c5c525b9c"},"cell_type":"markdown","source":"I see that Service is very correlated with other columns such as \"Birthrate\" , \"Agriculture\" , \"Phones\" , \"Infant Mortality\".\n\nAlso, GDP per capita and Birtrate is very correlated with many different Columns too."},{"metadata":{"_uuid":"4152348aa0e5477690f86bdf5ac8b7e281307e4a"},"cell_type":"markdown","source":"I want to fix our Region values too, they have too much space which makes it hard to read."},{"metadata":{"trusted":true,"_uuid":"5f6db265ecd2ce6858fd6ee18f40301d94f09e29"},"cell_type":"code","source":"b = set(data.Region);\nprint(b)   # seems like we have a Lot of spaces, considering that they use storage unnecesarily: I want to delete whole spaces.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"299533981041925fbba295624fb98a041887c3a9"},"cell_type":"code","source":"def SpaceRemover(data):\n    \"\"\"This function is created for the replacement of Space with empty\"\"\"\n    data = str(data);   # for any type of unexpected data types\n    data = data.replace(\" \",\"\");\n    return data;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6baf3c2fe66c4408dfbf4e597e5a4327f704f825"},"cell_type":"code","source":"data['Region'] = list(map(SpaceRemover,data['Region']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9db530df6853745dc7509bfa7f79c8ab7248ce80"},"cell_type":"code","source":"print(set(data.Region))  # now not super clear but still better.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a12e28cb0dc6a8053d4eaa2b9ad733c2b2c61864"},"cell_type":"code","source":"plt.clf()\nplt.figure(figsize=(15,10));\nplt.scatter(data.Climate , data.Region, alpha=0.1, s=200, c=\"blue\")  \n\n# I made 0.1 opacity to see how often it repeats easily\n# darker the blue, often the appearence of that climate.\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cf75b125fc8e326ab622383d072f7c7e2765b65"},"cell_type":"markdown","source":"I will try to improve my data manipualtion skills such as melting or pivoting the data on the dataset."},{"metadata":{"trusted":true,"_uuid":"fe3cedba28ab6abf7bfe9180adc7f9560ec249dc"},"cell_type":"code","source":"melted_data = pd.melt(frame=data, id_vars=\"Country\", value_vars=['Literacy (%)','Birthrate','Phones (per 1000)'])\n\nmelted_data  # the picked variables are all correlated, so when I pivot it will has more sense.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a15ebb09e621adf13c56aa5bdabfc1429903414c"},"cell_type":"code","source":"pivotted_melt = melted_data.pivot(index='Country',columns=\"variable\",values='value')\n\npivotted_melt  # we can see that how dependently numbers change in each column easily.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c73307814caebe5538d97324ac86e7e61306e23a"},"cell_type":"markdown","source":"Example usage of assert on my dataset can be like:"},{"metadata":{"trusted":true,"_uuid":"888e068fed3319ab75b1b6a70d8eeef03acbd01f"},"cell_type":"code","source":"# assert pivotted_melt.Birthrate.dtype == np.dtype(int)   ## would return an error.\n\nassert pivotted_melt.Birthrate.dtype == np.dtype(float)   # returns no error because data type is really float","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d875782dc25914e6c037ef48d643b6f222bd1000"},"cell_type":"code","source":"# assert data.columns[1] == \"Efe\"  ## would return an error \n\nassert data.columns[1] != \"Efe\" # in here I assert negatively. (not \"Efe\" is true)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f8c4a7dcaab88e9c973ac62642a9517f252af48"},"cell_type":"markdown","source":"Example of Concatenaing data could be like this:"},{"metadata":{"trusted":true,"_uuid":"c4beaae4063bc9b2347e5f3b42ce64be29728231"},"cell_type":"code","source":"dataHead = data.head(10);               dataTail = data.tail(10);\n\nconcated_data = pd.concat([dataHead,dataTail],axis=0,ignore_index=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae99c2e7699638908ee6ec24e96fb8353dae456d"},"cell_type":"code","source":"concated_data   # Rigth Below we see that by \"concat\" operation of numpy we easliy created new data from 2 data(s). ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f684bf2ef12e323d0c022dc6aed3efb49503401d"},"cell_type":"code","source":"# this notebook is created for the 3rd homework of Data Science by DATAI on Udemy.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"790788f012ac34aae2aaa76af995a5b61524db39"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}