{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# General information about this notebook\n\nThis notebook devides this dataset to three following categories: Healthy, Bacterial-pneumonia and Viral-pneumonia. If a chest xray is classified as the two latters, the person is thus infected with covid-19. The reason i didnt combine bacterial and viral pneumonia in one category, namely covid, is that there are different features in images which shows if someone has a bacterial or viral infection. Combining this two in one category would thus mess up the training data and accuracy. \n\nAnother important note is that this dataset has different amount of data in respective category which affects the accuracy result. For example we have 2000+ xray images of bacterial-pneumonia and only roughly 1400 images of healthy lungs. ","metadata":{"id":"QP6Y_O3zB6u4"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport shutil\nimport os","metadata":{"id":"vRCm9x4BB6u5","execution":{"iopub.status.busy":"2021-08-03T18:04:33.693171Z","iopub.execute_input":"2021-08-03T18:04:33.693528Z","iopub.status.idle":"2021-08-03T18:04:33.700804Z","shell.execute_reply.started":"2021-08-03T18:04:33.693495Z","shell.execute_reply":"2021-08-03T18:04:33.699875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Examining the dataset","metadata":{"id":"EpLNtlCsB6u7"}},{"cell_type":"code","source":"metadata=pd.read_csv(\"../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\")\nmetadata.head()","metadata":{"id":"_APB0BMjGOfv","outputId":"bac16d58-8710-4937-eaf1-5a2e3c524a61","execution":{"iopub.status.busy":"2021-08-03T18:04:35.504197Z","iopub.execute_input":"2021-08-03T18:04:35.504509Z","iopub.status.idle":"2021-08-03T18:04:35.555044Z","shell.execute_reply.started":"2021-08-03T18:04:35.50448Z","shell.execute_reply":"2021-08-03T18:04:35.554294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2,figsize=(20, 5))\nax[0].hist(metadata['Label']);\nax[1].hist(metadata['Label_1_Virus_category'].astype(str));","metadata":{"id":"UNRpd3pEGP3b","outputId":"03ac29e9-7cf9-4b36-d62d-f7d5707c022f","execution":{"iopub.status.busy":"2021-08-03T18:04:37.117011Z","iopub.execute_input":"2021-08-03T18:04:37.117338Z","iopub.status.idle":"2021-08-03T18:04:37.387222Z","shell.execute_reply.started":"2021-08-03T18:04:37.117309Z","shell.execute_reply":"2021-08-03T18:04:37.386257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Divide the data to three categories as mentioned in beginning","metadata":{"id":"K6JM9QHZB6u9"}},{"cell_type":"code","source":"#get training data and testing data separatly from the metadata csv file\ntrain_df = metadata[metadata['Dataset_type'] == 'TRAIN']\ntest_df = metadata[metadata['Dataset_type'] == 'TEST']","metadata":{"id":"QSK3AewsGUCX","execution":{"iopub.status.busy":"2021-08-03T18:04:39.136465Z","iopub.execute_input":"2021-08-03T18:04:39.136798Z","iopub.status.idle":"2021-08-03T18:04:39.145135Z","shell.execute_reply.started":"2021-08-03T18:04:39.136748Z","shell.execute_reply":"2021-08-03T18:04:39.144289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Divide each virus with corresponding images to different variables\ntrain_virus = train_df[train_df.Label_1_Virus_category == 'Virus']['X_ray_image_name']\ntrain_bacterial=train_df[train_df.Label_1_Virus_category == 'bacteria']['X_ray_image_name']\ntrain_normal=train_df[train_df.Label == 'Normal']['X_ray_image_name']\n\nlen(train_virus),len(train_bacterial),len(train_normal)","metadata":{"id":"LxCwRByfGWdQ","outputId":"1578751a-8cfe-4fbb-82b9-c54e2245b46a","execution":{"iopub.status.busy":"2021-08-03T18:04:40.343804Z","iopub.execute_input":"2021-08-03T18:04:40.34417Z","iopub.status.idle":"2021-08-03T18:04:40.358938Z","shell.execute_reply.started":"2021-08-03T18:04:40.34414Z","shell.execute_reply":"2021-08-03T18:04:40.357779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split the data to test,valid and training**","metadata":{}},{"cell_type":"code","source":"def split_to_training_validation(data,split=0.2):\n    \"\"\"\n    This function takes a data series and split 20% of it to validation set and 80% to training set\n    \n    Args:\n    data -> data series images\n    split -> parameter to split\n    \n    returns a validation and training set\n    \"\"\"\n    \n    valid_data=data[:round(split*len(data))]\n    train_data=data[round(split*len(data)):]\n    \n    return valid_data, train_data","metadata":{"execution":{"iopub.status.busy":"2021-08-03T18:04:41.31222Z","iopub.execute_input":"2021-08-03T18:04:41.312541Z","iopub.status.idle":"2021-08-03T18:04:41.31773Z","shell.execute_reply.started":"2021-08-03T18:04:41.31251Z","shell.execute_reply":"2021-08-03T18:04:41.316727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_virus,train_virus=split_to_training_validation(train_virus)\nvalid_bacterial,train_bacterial=split_to_training_validation(train_bacterial)\nvalid_normal,train_normal=split_to_training_validation(train_normal)\n\nlen(train_virus),len(valid_virus), len(valid_normal),len(train_normal)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T18:04:42.784501Z","iopub.execute_input":"2021-08-03T18:04:42.784842Z","iopub.status.idle":"2021-08-03T18:04:42.79316Z","shell.execute_reply.started":"2021-08-03T18:04:42.784809Z","shell.execute_reply":"2021-08-03T18:04:42.792254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lables=['Healthy','Viral-pneumonia','Bacterial-pneumonia']\ntraining_data_classes=[train_normal,train_virus,train_bacterial]\nsource='../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n\nfor i in range(0,len(lables)):\n    target='/dataset/train/'+lables[i] #choose where the data from kaggle should be placed\n    \n    os.makedirs('/dataset/train/'+lables[i]) #create new folder with lables\n    move=training_data_classes[i]\n    for j in move:\n        #move everything from source path to new target path as iterating through the labels\n        path=os.path.join(source,j)\n        shutil.copy(path,target)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T18:04:45.186662Z","iopub.execute_input":"2021-08-03T18:04:45.187068Z","iopub.status.idle":"2021-08-03T18:05:26.566495Z","shell.execute_reply.started":"2021-08-03T18:04:45.187035Z","shell.execute_reply":"2021-08-03T18:05:26.565657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data_classes=[valid_normal,valid_virus,valid_bacterial]\nfor i in range(0,len(lables)):\n    target='/dataset/valid/'+lables[i] #choose where the data from kaggle should be placed\n    \n    os.makedirs('/dataset/valid/'+lables[i]) #create new folder with lables\n    move=validation_data_classes[i]\n    for j in move:\n        #move everything from source path to new target path as iterating through the labels\n        path=os.path.join(source,j)\n        shutil.copy(path,target)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T18:05:26.567934Z","iopub.execute_input":"2021-08-03T18:05:26.568267Z","iopub.status.idle":"2021-08-03T18:05:35.803368Z","shell.execute_reply.started":"2021-08-03T18:05:26.568231Z","shell.execute_reply":"2021-08-03T18:05:35.802543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_virus = test_df[test_df.Label_1_Virus_category == 'Virus']['X_ray_image_name']\ntest_bacterial=test_df[test_df.Label_1_Virus_category == 'bacteria']['X_ray_image_name']\ntest_normal=test_df[test_df.Label == 'Normal']['X_ray_image_name']\n\nlen(test_virus),len(test_bacterial),len(test_normal)","metadata":{"id":"4OClqZBLGaoM","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-03T18:05:35.805067Z","iopub.execute_input":"2021-08-03T18:05:35.805407Z","iopub.status.idle":"2021-08-03T18:05:35.816015Z","shell.execute_reply.started":"2021-08-03T18:05:35.805369Z","shell.execute_reply":"2021-08-03T18:05:35.815098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes=[test_normal,test_virus,test_bacterial]\nsource='../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\n\nfor i in range(0,len(lables)):\n    \n    target='/dataset/test/'+lables[i] #choose where the data from kaggle should be placed \n    \n    os.makedirs('/dataset/test/'+lables[i]) #create new folder with lables\n    move=classes[i]\n    for j in move:\n        #move everything from source path to new target path as iterating through the labels\n        path=os.path.join(source,j)\n        shutil.copy(path,target)","metadata":{"id":"rDegpHtOGesh","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-03T18:05:35.817474Z","iopub.execute_input":"2021-08-03T18:05:35.81797Z","iopub.status.idle":"2021-08-03T18:05:40.925383Z","shell.execute_reply.started":"2021-08-03T18:05:35.817932Z","shell.execute_reply":"2021-08-03T18:05:40.924376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get class names to confirm the division is done right**","metadata":{"id":"Sh_2brQ-B6u_"}},{"cell_type":"code","source":"import pathlib\n\n#Print out classes from the created directory\ndata_dir = pathlib.Path(\"/dataset/valid\")\nclass_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # Created a list of class_names from the subdirectories\nprint(class_names)","metadata":{"id":"aoDKyIPOXT96","outputId":"edb86c20-efb0-40bf-fc3a-e122e63eeb76","execution":{"iopub.status.busy":"2021-08-03T18:05:40.926824Z","iopub.execute_input":"2021-08-03T18:05:40.927213Z","iopub.status.idle":"2021-08-03T18:05:40.937158Z","shell.execute_reply.started":"2021-08-03T18:05:40.927174Z","shell.execute_reply":"2021-08-03T18:05:40.936278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot one random image of bacterial-pneumonia lung (it can be changed to others by changing the target_class arg)**","metadata":{"id":"CoRBZaAkB6vA"}},{"cell_type":"code","source":"import matplotlib.image as mpimg\nfrom matplotlib.pyplot import figure\nimport random\n\ndef view_random_image(target_dir, target_class):\n    # Setup the target directory \n    target_folder = target_dir+target_class\n\n    # Get a random image path\n    random_image = random.sample(os.listdir(target_folder), 1)\n    print(random_image)\n    \n    # Read in the image and plot it using matplotlib\n    plt.figure(figsize=(7, 5))\n    plt.subplot(1, 1,1)\n    \n    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n    plt.imshow(img,cmap='gray')\n    plt.title(target_class)\n    plt.axis(\"off\");\n    print(f\"Image shape: {img.shape}\") # show the shape of the image\n\n    return img","metadata":{"id":"cH0EYobvXxy7","execution":{"iopub.status.busy":"2021-08-03T18:05:48.220858Z","iopub.execute_input":"2021-08-03T18:05:48.22118Z","iopub.status.idle":"2021-08-03T18:05:48.228889Z","shell.execute_reply.started":"2021-08-03T18:05:48.221152Z","shell.execute_reply":"2021-08-03T18:05:48.227855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dir and class can be changed\nimage_1= view_random_image(target_dir=\"/dataset/valid/\",\n                        target_class=\"Bacterial-pneumonia\")","metadata":{"id":"nb_PtJTbXzXb","outputId":"90fd0d0a-ed28-40ac-a56d-07aace921782","execution":{"iopub.status.busy":"2021-08-03T18:05:50.27208Z","iopub.execute_input":"2021-08-03T18:05:50.272415Z","iopub.status.idle":"2021-08-03T18:05:50.547549Z","shell.execute_reply.started":"2021-08-03T18:05:50.272386Z","shell.execute_reply":"2021-08-03T18:05:50.54658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing data for the neural network","metadata":{"id":"jaAX2VtVB6vA"}},{"cell_type":"markdown","source":"* Validation is used when fitting the model\n* This ensures that hyperparameter tuning isnt chosen based on the unseen test data","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 64\n\ntf.random.set_seed(42)\n\n#Define training and testing directories\ntrain_dir = \"/dataset/train\"\nvalid_dir=\"/dataset/valid\"\ntest_dir = \"/dataset/test\"\n\n#Normalize images\ntrain_aug = ImageDataGenerator(rescale=1/255.,\n                               shear_range=0.1,\n                               rotation_range=20,\n                               zoom_range=0.1)\n\nvalid_gen=ImageDataGenerator(rescale=1/255.)\ntest_gen = ImageDataGenerator(rescale=1/255.)\n\n#Apply and get image tensors\ntrain_data = train_aug.flow_from_directory(train_dir,\n                                          target_size=IMG_SIZE,\n                                          color_mode='grayscale',\n                                          batch_size=BATCH_SIZE,\n                                          class_mode=\"categorical\")\n\nvalid_data=valid_gen.flow_from_directory(valid_dir,\n                                        target_size=IMG_SIZE,\n                                        color_mode='grayscale',\n                                        batch_size=BATCH_SIZE,\n                                        class_mode=\"categorical\")\n\ntest_data = test_gen.flow_from_directory(test_dir,\n                                        target_size=IMG_SIZE,\n                                        color_mode='grayscale',\n                                        batch_size=BATCH_SIZE,\n                                        class_mode=\"categorical\")","metadata":{"id":"_yoBDaGtYMGN","outputId":"d0edd999-ee1b-492d-9d62-5ad1f66d6540","execution":{"iopub.status.busy":"2021-08-03T18:05:59.355367Z","iopub.execute_input":"2021-08-03T18:05:59.355685Z","iopub.status.idle":"2021-08-03T18:05:59.679018Z","shell.execute_reply.started":"2021-08-03T18:05:59.355653Z","shell.execute_reply":"2021-08-03T18:05:59.678177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **4228** images for training\n* **1056** for validation\n* **624** for testing purpose","metadata":{}},{"cell_type":"code","source":"#Plot three images of augmented training data\nfor _ in range(3):\n    img, label = train_data.next()\n    plt.figure(figsize=(7, 7))\n    plt.imshow(img[0],cmap=\"gray\")\n    plt.show()","metadata":{"id":"mzbti_07JIBn","outputId":"e3c13ac4-8feb-47e4-a976-2888beff73ce","execution":{"iopub.status.busy":"2021-08-03T18:06:10.540444Z","iopub.execute_input":"2021-08-03T18:06:10.540837Z","iopub.status.idle":"2021-08-03T18:06:13.933942Z","shell.execute_reply.started":"2021-08-03T18:06:10.540806Z","shell.execute_reply":"2021-08-03T18:06:13.933137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\ndef create_tensorboard_callback(dir_name, experiment_name):\n\n    #store log files with filepath to tensorboard\n    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n      log_dir=log_dir\n    )\n    print(f\"Saving TensorBoard log files to: {log_dir}\")\n    return tensorboard_callback","metadata":{"id":"gl_M9hovYRYi","execution":{"iopub.status.busy":"2021-08-03T18:06:19.187592Z","iopub.execute_input":"2021-08-03T18:06:19.187989Z","iopub.status.idle":"2021-08-03T18:06:19.193419Z","shell.execute_reply.started":"2021-08-03T18:06:19.187955Z","shell.execute_reply":"2021-08-03T18:06:19.192495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create sequential deep learning model**\n\n* Get prediction probabilites later on using softmax activation function in dense layer\n* Use categorical crossentropy as loss metric","metadata":{"id":"PnNAYaO3B6vC"}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation,BatchNormalization, Dropout\n\n#Create model, increase filter and decrease kernel as going deeper since pixels are bigger than 128x128\n\nmodel=Sequential([\n    Conv2D(96, 11, 4, activation='relu', input_shape=(224,224,1)),\n    BatchNormalization(),\n    MaxPool2D(3, 2),\n    Conv2D(256, 5, 1, activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    MaxPool2D(3, 2),\n    Conv2D(384, 3, 1, activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    Conv2D(384,3, 1, activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    Conv2D(256, 3, 1, activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    MaxPool2D(3, 2),\n    Flatten(),\n    Dense(4096, activation='relu'),\n    \n    #set dropout to regularize\n    Dropout(0.5),\n    Dense(4096, activation='relu'),\n    Dropout(0.5),\n    Dense(3, activation='softmax')\n])\n\n# Compile\nmodel.compile(loss=\"categorical_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,decay=1e-5),\n                metrics=[\"accuracy\"])","metadata":{"id":"dgKMTEmrYUvT","execution":{"iopub.status.busy":"2021-08-03T18:09:33.773252Z","iopub.execute_input":"2021-08-03T18:09:33.773581Z","iopub.status.idle":"2021-08-03T18:09:33.914425Z","shell.execute_reply.started":"2021-08-03T18:09:33.773551Z","shell.execute_reply":"2021-08-03T18:09:33.91359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set checkpoint path\ncheckpoint_path = \"weights/checkpoint.ckpt\"\n\n# Create a ModelCheckpoint callback that saves the model's weights only\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                         save_best_only=True,\n                                                         save_freq=\"epoch\", # save every epoch\n                                                         verbose=1)","metadata":{"id":"-XhO3UnTYWDj","execution":{"iopub.status.busy":"2021-08-03T18:07:56.623574Z","iopub.execute_input":"2021-08-03T18:07:56.6239Z","iopub.status.idle":"2021-08-03T18:07:56.628191Z","shell.execute_reply.started":"2021-08-03T18:07:56.62387Z","shell.execute_reply":"2021-08-03T18:07:56.627378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model saving checkpoints every epoch\nepochs = 50\n\n#Train the model with 50 epochs\nhistory = model.fit(train_data,\n                          epochs=epochs,\n                          steps_per_epoch=train_data.samples//BATCH_SIZE,\n                          validation_data=valid_data,\n                          validation_steps=len(valid_data),\n                          callbacks=[create_tensorboard_callback(dir_name=\"history_callback\",\n                                                                                 experiment_name=\"Chest_Xray\"),\n                                                     checkpoint_callback])\n\n","metadata":{"id":"3Tu-3B5zYXKG","outputId":"245e57df-247e-4835-b8f2-eb0c613be0bf","_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-03T18:10:23.696998Z","iopub.execute_input":"2021-08-03T18:10:23.697332Z","iopub.status.idle":"2021-08-03T19:07:22.155227Z","shell.execute_reply.started":"2021-08-03T18:10:23.697304Z","shell.execute_reply":"2021-08-03T19:07:22.154312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluating the model as it currently is versus the best fitted model during training**","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_data)","metadata":{"id":"-oiMRWs-hUpK","outputId":"30d3d49d-cb4c-4a52-fad8-5624fd178b7c","execution":{"iopub.status.busy":"2021-08-03T19:09:08.430666Z","iopub.execute_input":"2021-08-03T19:09:08.431083Z","iopub.status.idle":"2021-08-03T19:09:14.17132Z","shell.execute_reply.started":"2021-08-03T19:09:08.431048Z","shell.execute_reply":"2021-08-03T19:09:14.170521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load best weights from the saved model on checkpoint\nmodel_best_weights= tf.keras.models.load_model('weights/checkpoint.ckpt')","metadata":{"id":"-IykArdphbj0","execution":{"iopub.status.busy":"2021-08-03T19:09:14.174313Z","iopub.execute_input":"2021-08-03T19:09:14.177128Z","iopub.status.idle":"2021-08-03T19:09:16.193925Z","shell.execute_reply.started":"2021-08-03T19:09:14.177088Z","shell.execute_reply":"2021-08-03T19:09:16.193118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The model with best weights achieved an accuracy of roughly 76%\n\n* Note: It matches the model test accuracy because the best weights were achieved for last epoch","metadata":{}},{"cell_type":"code","source":"model_best_weights.evaluate(test_data)","metadata":{"id":"oPbecGRVhk4v","outputId":"c54bcb46-ba5d-4d6a-84fb-5bb7f4e3daf0","execution":{"iopub.status.busy":"2021-08-03T19:09:16.199456Z","iopub.execute_input":"2021-08-03T19:09:16.199719Z","iopub.status.idle":"2021-08-03T19:09:22.034809Z","shell.execute_reply.started":"2021-08-03T19:09:16.199692Z","shell.execute_reply":"2021-08-03T19:09:22.03403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction and visualization\n\n* Predictions are made with the model fitted with best weights. Perhaps better result could be achieved by training longer","metadata":{}},{"cell_type":"code","source":"y_pred = model_best_weights.predict(test_data)\ny_pred.shape","metadata":{"id":"kkKArB0q4U-7","outputId":"abfb5bb7-1cc5-4518-9bf4-78f7fd6294c2","execution":{"iopub.status.busy":"2021-08-03T19:11:23.083508Z","iopub.execute_input":"2021-08-03T19:11:23.083835Z","iopub.status.idle":"2021-08-03T19:11:28.205235Z","shell.execute_reply.started":"2021-08-03T19:11:23.083803Z","shell.execute_reply":"2021-08-03T19:11:28.204467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2021-08-03T19:11:28.206722Z","iopub.execute_input":"2021-08-03T19:11:28.207069Z","iopub.status.idle":"2021-08-03T19:11:28.213756Z","shell.execute_reply.started":"2021-08-03T19:11:28.207034Z","shell.execute_reply":"2021-08-03T19:11:28.212866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predict randomly and plot**\n\nThis section takes 4 images out of testing data and classifies them using the model that was trained\n\nThe actual and predicted categories plus their prediction probability is also plotted","metadata":{"id":"IKPz2HX9B6vE"}},{"cell_type":"code","source":"# Create a function to load and prepare images for prediction\ndef load_and_prep_image(filename, img_shape=224, scale=True):\n\n  # Read in the image\n    img = tf.io.read_file(filename)\n\n    # Decode image into tensor\n    img = tf.io.decode_image(img, channels=1)\n\n    # Resize the image\n    img = tf.image.resize(img, [img_shape, img_shape])\n\n    # Scale? Yes/no\n    if scale:\n    # rescale the image (get all values between 0 and 1)\n        return img/255.\n    else:\n        return img ","metadata":{"id":"Fo5og2EJYK3D","execution":{"iopub.status.busy":"2021-08-03T19:11:37.124877Z","iopub.execute_input":"2021-08-03T19:11:37.125211Z","iopub.status.idle":"2021-08-03T19:11:37.130884Z","shell.execute_reply.started":"2021-08-03T19:11:37.125179Z","shell.execute_reply":"2021-08-03T19:11:37.129851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make preds on a series of random images\nimport os\nimport random\n\nplt.figure(figsize=(17, 10))\n\n#get for random images from testdataset and use model to predict infection\nfor i in range(4):\n    \n  # Choose random image(s) from random class(es)\n    class_name = random.choice(class_names)\n    filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n    filepath = test_dir + \"/\"+ class_name + \"/\" + filename\n\n    # Load the image and make predictions\n    img = load_and_prep_image(filepath, scale=True)\n    img_expanded = tf.expand_dims(img, axis=0)\n    print(img_expanded.shape)\n    pred_prob = model_best_weights.predict(img_expanded) # get prediction probabilities array\n    pred_class = class_names[pred_prob.argmax()] # get highest prediction probability index and match it class_names list\n    #slice out last dimension\n    img = img[:,:,0]\n    \n    plt.subplot(2, 2,i+1)\n    # Plot the images\n    print(filename)\n    plt.imshow(img,cmap='gray')\n    if (class_name == pred_class): # if predicted class matches truth class, make text green\n        title_color = \"g\"\n    else:\n        title_color = \"r\"\n    plt.title(f\"Actual class: {class_name}, Pred class: {pred_class}, Pred prob: {pred_prob.max():.2f}%\", c=title_color)\n    plt.axis(False);","metadata":{"id":"YNYnRZUXYMMO","outputId":"c1cbe9a9-6887-40c9-8c31-bc99764ef5f6","execution":{"iopub.status.busy":"2021-08-03T19:14:07.353407Z","iopub.execute_input":"2021-08-03T19:14:07.353733Z","iopub.status.idle":"2021-08-03T19:14:08.152411Z","shell.execute_reply.started":"2021-08-03T19:14:07.353702Z","shell.execute_reply":"2021-08-03T19:14:08.151659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Discussion\n\n* The above cell can be used as a further method of checking how the model performs\n\n* If the dataset contained more image data of healthy lungs then the reslut wouldve been better\n\n* The missclassified image has a probability of 47% which shows that even the model is not confident enough of its own prediction, which is self explanatory that it needs more image data of healthy lungs\n","metadata":{}}]}