{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Car Features and MSRP Dataet\n\n- `Number of Instances`: **11914**\n- `Number of Attributes`: **16**\n- `Attributes`<u>(Description of Attributes, according to me which I got from dicussions and Google beacuse it was not given in the [Kaggle](https://www.kaggle.com/CooperUnion/cardataset) page)</u>: \n  - `Make`: Make of a car(BMW, Volkswagen and so on)\n  - `Model`: Model of a car\n  - `Year`: Year when the car was manufactured\n  - `Engine Fuel Type`: Type of fuel engine needs(disel and so on)\n  - `Engine HP`: Horsepower of engine\n  - `Engine Cylinders`: Number of cylinders in engine\n  - `Transmission Type`: Type of transmission(automatic or manual)\n  - `Driven Wheels`: front, rear, all\n  - `Number of Doors`: Number of doors a car has\n  - `Market Category`: luxury, crossover and so on\n  - `Vehicle Size`: compact, midsize, large\n  - `Vehicle Style`: Style of vehicle(sedan, convertible and so on)\n  - `Highway MPG`: miles per gallon(MPG) in highway\n  - `City MPG`: miles per gallon(MPG) in city\n  - `Popularity`: Number of times the car was mentioned in a Twitter stream\n  - `MSRP`: Manufacturer's Suggested Retail Price","metadata":{}},{"cell_type":"markdown","source":"## Understand the Business Requirements\n\n**Problem statement:**\n\n`Cars dataset with features including make, model, year, engine, and other properties of the car used to predict its price.`","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis(EDA):","metadata":{}},{"cell_type":"code","source":"#Python Libraries \nimport pandas as pd #Data Processing and CSV file I/o\nimport numpy as np #for numeric operations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline \n#to make sure that plots rendered correctly in jupyter notebook\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:28:36.140156Z","iopub.execute_input":"2021-07-04T17:28:36.140573Z","iopub.status.idle":"2021-07-04T17:28:37.058852Z","shell.execute_reply.started":"2021-07-04T17:28:36.140486Z","shell.execute_reply":"2021-07-04T17:28:37.057868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df = pd.read_csv('/kaggle/input/cardataset/data.csv') #reading the .csv file which is present in archive.zip file ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:28:55.057188Z","iopub.execute_input":"2021-07-04T17:28:55.05757Z","iopub.status.idle":"2021-07-04T17:28:55.131764Z","shell.execute_reply.started":"2021-07-04T17:28:55.057537Z","shell.execute_reply":"2021-07-04T17:28:55.130619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df.head(8) #top 8 rows","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:28:59.971248Z","iopub.execute_input":"2021-07-04T17:28:59.971615Z","iopub.status.idle":"2021-07-04T17:29:00.020735Z","shell.execute_reply.started":"2021-07-04T17:28:59.971584Z","shell.execute_reply":"2021-07-04T17:29:00.019799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lowercasing all the column names and replacing space with underscores\ncar_df.columns = car_df.columns.str.lower().str.replace(' ', '_')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:01.296544Z","iopub.execute_input":"2021-07-04T17:29:01.297087Z","iopub.status.idle":"2021-07-04T17:29:01.302526Z","shell.execute_reply.started":"2021-07-04T17:29:01.297055Z","shell.execute_reply":"2021-07-04T17:29:01.301541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df.columns #columns name","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:02.851312Z","iopub.execute_input":"2021-07-04T17:29:02.851692Z","iopub.status.idle":"2021-07-04T17:29:02.858178Z","shell.execute_reply.started":"2021-07-04T17:29:02.85166Z","shell.execute_reply":"2021-07-04T17:29:02.857372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df.dtypes #data type of every column","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:04.02161Z","iopub.execute_input":"2021-07-04T17:29:04.02196Z","iopub.status.idle":"2021-07-04T17:29:04.030456Z","shell.execute_reply.started":"2021-07-04T17:29:04.02193Z","shell.execute_reply":"2021-07-04T17:29:04.029226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#similary lowercasing all the rows and replacing space with underscores\nstring_columns = list(car_df.dtypes[car_df.dtypes == 'object'].index)\nfor col in string_columns:\n    car_df[col] = car_df[col].str.lower().str.replace(' ', '_')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:04.971163Z","iopub.execute_input":"2021-07-04T17:29:04.971525Z","iopub.status.idle":"2021-07-04T17:29:05.088516Z","shell.execute_reply.started":"2021-07-04T17:29:04.971494Z","shell.execute_reply":"2021-07-04T17:29:05.087394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df.sample(4)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:06.256671Z","iopub.execute_input":"2021-07-04T17:29:06.257006Z","iopub.status.idle":"2021-07-04T17:29:06.281608Z","shell.execute_reply.started":"2021-07-04T17:29:06.256977Z","shell.execute_reply":"2021-07-04T17:29:06.280532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The Numbers of Rows and Columns in this data set are: {car_df.shape[0]} rows and {car_df.shape[1]} columns.\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:07.216218Z","iopub.execute_input":"2021-07-04T17:29:07.216575Z","iopub.status.idle":"2021-07-04T17:29:07.221944Z","shell.execute_reply.started":"2021-07-04T17:29:07.216545Z","shell.execute_reply":"2021-07-04T17:29:07.220869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Concise Summary of the DataFrame\ncar_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:08.187148Z","iopub.execute_input":"2021-07-04T17:29:08.187666Z","iopub.status.idle":"2021-07-04T17:29:08.217724Z","shell.execute_reply.started":"2021-07-04T17:29:08.187632Z","shell.execute_reply":"2021-07-04T17:29:08.216544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Statistical Summary of DataFrame\ncar_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:09.051438Z","iopub.execute_input":"2021-07-04T17:29:09.051938Z","iopub.status.idle":"2021-07-04T17:29:09.09925Z","shell.execute_reply.started":"2021-07-04T17:29:09.051906Z","shell.execute_reply":"2021-07-04T17:29:09.098121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Missing Values\ncar_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:10.051084Z","iopub.execute_input":"2021-07-04T17:29:10.051448Z","iopub.status.idle":"2021-07-04T17:29:10.069901Z","shell.execute_reply.started":"2021-07-04T17:29:10.051417Z","shell.execute_reply":"2021-07-04T17:29:10.068656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#first step should always be check the distribution of target variable(in my opinion)\nplt.figure(figsize=(5,4))\nsns.histplot(car_df['msrp'], bins=30)\nplt.title(\"Distribution of Prices\")\nplt.ylabel(\"Counts\")\nplt.xlabel(\"Price\")\nplt.show(); \n#as we have seen that max price is 2065902 so in this graph 1e6 means 10^6\n#this graph has long tail(imp)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:10.971174Z","iopub.execute_input":"2021-07-04T17:29:10.971999Z","iopub.status.idle":"2021-07-04T17:29:11.276795Z","shell.execute_reply.started":"2021-07-04T17:29:10.971941Z","shell.execute_reply":"2021-07-04T17:29:11.276021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#zooming the above graph \nplt.figure(figsize=(5,4))\nsns.histplot(car_df['msrp'][car_df['msrp'] < 100000], bins=30)\nplt.title(\"Distribution of Prices\")\nplt.ylabel(\"Counts\")\nplt.xlabel(\"Price\")\nplt.show(); \n#in this graph the long tail make quite difficult to see distribution.\n#to solve this problem we have to transform this graph by log transformation","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:12.306212Z","iopub.execute_input":"2021-07-04T17:29:12.306882Z","iopub.status.idle":"2021-07-04T17:29:12.553506Z","shell.execute_reply.started":"2021-07-04T17:29:12.306846Z","shell.execute_reply":"2021-07-04T17:29:12.552352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_price_plus1 =  np.log1p(car_df['msrp']) #``log(1 + x)``\n\nplt.figure(figsize=(5,4))\nsns.histplot(log_price_plus1, bins=30)\nplt.title(\"Distribution of Prices after Log tranformation\")\nplt.ylabel(\"Counts\")\nplt.xlabel(\"Price\")\nplt.show(); \n# +1 part important in cases that have zeroes.\n#as we can see that there is no longer, long tail is present and now the distribution resembles a bell-shaped curve.","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:13.531475Z","iopub.execute_input":"2021-07-04T17:29:13.531835Z","iopub.status.idle":"2021-07-04T17:29:13.768246Z","shell.execute_reply.started":"2021-07-04T17:29:13.531805Z","shell.execute_reply":"2021-07-04T17:29:13.767418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting data into Train, Validation and Test Sets\n\n`Full DataSet is divided into`:\n- `20% of data goes to validation`\n- `20% of data goes to test`\n- `and remainig 60% goes to train`","metadata":{}},{"cell_type":"code","source":"rows = len(car_df) # No. of Rows in car_df\n\n#calculating how many rows shoulg go to train, validation and test\nval_rows = int(0.2*rows)\ntest_rows = int(0.2*rows)\ntrain_rows = rows - (val_rows+test_rows)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:15.856078Z","iopub.execute_input":"2021-07-04T17:29:15.856471Z","iopub.status.idle":"2021-07-04T17:29:15.861054Z","shell.execute_reply.started":"2021-07-04T17:29:15.856436Z","shell.execute_reply":"2021-07-04T17:29:15.86026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a numpy array with indices from 0 to n-1 and shuffle it.\nindex = np.arange(rows)\nnp.random.shuffle(index)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:17.166385Z","iopub.execute_input":"2021-07-04T17:29:17.166748Z","iopub.status.idle":"2021-07-04T17:29:17.172347Z","shell.execute_reply.started":"2021-07-04T17:29:17.166717Z","shell.execute_reply":"2021-07-04T17:29:17.17122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using above array with indices to get a shuffled dataframe\ncar_shuffled_df = car_df.iloc[index]\n\n#Split the shuffled datafram into train, validation and test\ncar_train_df = car_shuffled_df.iloc[:train_rows].copy()\ncar_val_df = car_shuffled_df.iloc[:val_rows].copy()\ncar_test_df = car_shuffled_df.iloc[:test_rows].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:18.382064Z","iopub.execute_input":"2021-07-04T17:29:18.382574Z","iopub.status.idle":"2021-07-04T17:29:18.397481Z","shell.execute_reply.started":"2021-07-04T17:29:18.382542Z","shell.execute_reply":"2021-07-04T17:29:18.396373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training DataSet: \\n ~> Rows: {car_train_df.shape[0]}\\n ~> Columns: {car_train_df.shape[1]}\")\nprint(f\"Validation DataSet: \\n ~> Rows: {car_val_df.shape[0]}\\n ~> Columns: {car_val_df.shape[1]}\")\nprint(f\"Testing DataSet: \\n ~> Rows: {car_test_df.shape[0]}\\n ~> Columns: {car_test_df.shape[1]}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:19.701527Z","iopub.execute_input":"2021-07-04T17:29:19.701881Z","iopub.status.idle":"2021-07-04T17:29:19.707983Z","shell.execute_reply.started":"2021-07-04T17:29:19.701852Z","shell.execute_reply":"2021-07-04T17:29:19.70659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from above analysis we have got long tail in distribution of price and to remove its effect, log transformation is used\ny_train = np.log1p(car_train_df['msrp'].values)\ny_val = np.log1p(car_val_df['msrp'].values)\ny_test = np.log1p(car_test_df['msrp'].values)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:20.994917Z","iopub.execute_input":"2021-07-04T17:29:20.995617Z","iopub.status.idle":"2021-07-04T17:29:21.002732Z","shell.execute_reply.started":"2021-07-04T17:29:20.995544Z","shell.execute_reply":"2021-07-04T17:29:21.001863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_train_df.drop(['msrp'], axis=1, inplace=True)\ncar_val_df.drop(['msrp'], axis=1, inplace=True)\ncar_test_df.drop(['msrp'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:22.2516Z","iopub.execute_input":"2021-07-04T17:29:22.252192Z","iopub.status.idle":"2021-07-04T17:29:22.265249Z","shell.execute_reply.started":"2021-07-04T17:29:22.252135Z","shell.execute_reply":"2021-07-04T17:29:22.264125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:23.572123Z","iopub.execute_input":"2021-07-04T17:29:23.572535Z","iopub.status.idle":"2021-07-04T17:29:23.59806Z","shell.execute_reply.started":"2021-07-04T17:29:23.572497Z","shell.execute_reply":"2021-07-04T17:29:23.596192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_val_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:24.691991Z","iopub.execute_input":"2021-07-04T17:29:24.692519Z","iopub.status.idle":"2021-07-04T17:29:24.716677Z","shell.execute_reply.started":"2021-07-04T17:29:24.692487Z","shell.execute_reply":"2021-07-04T17:29:24.71545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Regression:","metadata":{}},{"cell_type":"code","source":"#linear regression implemented with Numpy\ndef linear_regression(X, y):\n    \"\"\"\n    This function is for implementation of Linear regression.\n    X = it is matrix(features).\n    y = it is a vector(target).\n    \"\"\"\n    ones = np.ones(X.shape[0]) #creating an array that contains only 1s.\n    X = np.column_stack([ones, X]) #adding the array of 1's as the column of X\n    #normal equation formula\n    XTX = X.T.dot(X) \n    XTX_inv = np.linalg.inv(XTX) #inverse of XTX\n    w = XTX_inv.dot(X.T).dot(y) #computing the rest of the normal equation\n    \n    return w[0], w[1:] #spliting the weight vector into the bias and the rest of the weights ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:26.580879Z","iopub.execute_input":"2021-07-04T17:29:26.581247Z","iopub.status.idle":"2021-07-04T17:29:26.587453Z","shell.execute_reply.started":"2021-07-04T17:29:26.581203Z","shell.execute_reply":"2021-07-04T17:29:26.586552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Naive solution","metadata":{}},{"cell_type":"code","source":"naive_features = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:28.451425Z","iopub.execute_input":"2021-07-04T17:29:28.452074Z","iopub.status.idle":"2021-07-04T17:29:28.462124Z","shell.execute_reply.started":"2021-07-04T17:29:28.451998Z","shell.execute_reply":"2021-07-04T17:29:28.461075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preparing_X(df):\n    \"\"\"\n    This function is used to replace all Nan to 0 and assign the values to variable X.\n    \"\"\"\n    df_num = df[naive_features]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:29.251696Z","iopub.execute_input":"2021-07-04T17:29:29.252087Z","iopub.status.idle":"2021-07-04T17:29:29.257272Z","shell.execute_reply.started":"2021-07-04T17:29:29.252051Z","shell.execute_reply":"2021-07-04T17:29:29.256222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naive_X_train = preparing_X(car_train_df)\n\nw_0, w = linear_regression(naive_X_train, y_train) #training the model\ny_pred = w_0 + naive_X_train.dot(w) #predicting ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:29.691266Z","iopub.execute_input":"2021-07-04T17:29:29.691679Z","iopub.status.idle":"2021-07-04T17:29:29.707283Z","shell.execute_reply.started":"2021-07-04T17:29:29.691641Z","shell.execute_reply":"2021-07-04T17:29:29.705623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let see the how good was the prediction\nplt.figure(figsize=(5,4))\n\nsns.histplot(y_train, label='target', color='black',bins=30)\nsns.histplot(y_pred, label='prediction',color='red', bins=30)\nplt.legend()\nplt.xlabel('log(1+price)')\nplt.ylabel('Count')\nplt.title('Predictions vs Actual Distribution')\n\nplt.show();\n#from the graph it clear that the prediction aren't good enough.","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:30.026094Z","iopub.execute_input":"2021-07-04T17:29:30.02645Z","iopub.status.idle":"2021-07-04T17:29:30.412583Z","shell.execute_reply.started":"2021-07-04T17:29:30.026419Z","shell.execute_reply":"2021-07-04T17:29:30.41164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#perfomace metric RMSE(root mean square error)\ndef rmse(y, y_pred):\n    error = y_pred - y\n    mse = (error**2).mean()\n    return np.sqrt(mse)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:30.41414Z","iopub.execute_input":"2021-07-04T17:29:30.414441Z","iopub.status.idle":"2021-07-04T17:29:30.419459Z","shell.execute_reply.started":"2021-07-04T17:29:30.414412Z","shell.execute_reply":"2021-07-04T17:29:30.418166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"RSME for training is: {round(rmse(y_train, y_pred), 4)}\")\n\n# Validating the model\nX_val = preparing_X(car_val_df)\ny_val_pred = w_0 + X_val.dot(w)\n\nprint(f\"RSME for validation is: {round(rmse(y_val, y_val_pred), 4)}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:30.452453Z","iopub.execute_input":"2021-07-04T17:29:30.452806Z","iopub.status.idle":"2021-07-04T17:29:30.466736Z","shell.execute_reply.started":"2021-07-04T17:29:30.452776Z","shell.execute_reply":"2021-07-04T17:29:30.465271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preparing_X(df):\n    \"\"\"\n    trying some features engineering, here I'm adding age column which is:\n    age = 2017 - year(from main dataframe) \n    then appending this into features.\n    \"\"\"\n    df = df.copy()\n    features = naive_features.copy()\n    \n    df['age'] = 2017 - df['year']\n    features.append('age')\n    \n    df_num = df[features]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:30.616362Z","iopub.execute_input":"2021-07-04T17:29:30.616714Z","iopub.status.idle":"2021-07-04T17:29:30.62264Z","shell.execute_reply.started":"2021-07-04T17:29:30.616685Z","shell.execute_reply":"2021-07-04T17:29:30.62163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = preparing_X(car_train_df)\nw_0, w = linear_regression(X_train, y_train) #training the model\ny_pred = w_0 + X_train.dot(w) #predicting \n\nprint(f\"RSME for training is: {round(rmse(y_train, y_pred), 4)}\")\n\n# Validating the model\nX_val = preparing_X(car_val_df)\ny_val_pred = w_0 + X_val.dot(w)\nprint(f\"RSME for validation is: {round(rmse(y_val, y_val_pred), 4)}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:31.027367Z","iopub.execute_input":"2021-07-04T17:29:31.027849Z","iopub.status.idle":"2021-07-04T17:29:31.048088Z","shell.execute_reply.started":"2021-07-04T17:29:31.027819Z","shell.execute_reply":"2021-07-04T17:29:31.046913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let see the how good was the prediction\nplt.figure(figsize=(5,4))\n\nsns.histplot(y_train, label='target', color='black',bins=30)\nsns.histplot(y_pred, label='prediction',color='red', bins=30)\nplt.legend()\nplt.xlabel('log(1+price)')\nplt.ylabel('Count')\nplt.title('Predictions vs Actual Distribution')\n\nplt.show();\n#with new features, the model follows the orginial distribution closer than previously","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:31.216268Z","iopub.execute_input":"2021-07-04T17:29:31.21662Z","iopub.status.idle":"2021-07-04T17:29:31.602104Z","shell.execute_reply.started":"2021-07-04T17:29:31.216589Z","shell.execute_reply":"2021-07-04T17:29:31.601132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['number_of_doors'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:31.603881Z","iopub.execute_input":"2021-07-04T17:29:31.604177Z","iopub.status.idle":"2021-07-04T17:29:31.616192Z","shell.execute_reply.started":"2021-07-04T17:29:31.604147Z","shell.execute_reply":"2021-07-04T17:29:31.614903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['make'].value_counts().head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:31.618148Z","iopub.execute_input":"2021-07-04T17:29:31.618474Z","iopub.status.idle":"2021-07-04T17:29:31.629513Z","shell.execute_reply.started":"2021-07-04T17:29:31.618442Z","shell.execute_reply":"2021-07-04T17:29:31.628647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['engine_fuel_type'].value_counts().head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:31.856486Z","iopub.execute_input":"2021-07-04T17:29:31.856842Z","iopub.status.idle":"2021-07-04T17:29:31.867879Z","shell.execute_reply.started":"2021-07-04T17:29:31.856813Z","shell.execute_reply":"2021-07-04T17:29:31.867023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preparing_X(df):\n    \"\"\"\n    Trying some more simple feature engineering.\n    \"\"\"\n    df = df.copy()\n    features = naive_features.copy()\n    \n    df['age'] = 2017 - df['year']\n    features.append('age')\n    \n    for index in ['chevrolet', 'ford', 'volkswagen', 'toyota', 'dodge']:\n        feature = 'is_make_%s' % index #giving a meaning full name\n        #creating the one hot encoding feature and adding the feature back to dataframe\n        df[feature] = (df['make'] == index).astype(int)\n        features.append(feature)\n        \n    for index in ['regular_unleaded', 'premium_unleaded_(required)', \n              'premium_unleaded_(recommended)', 'flex-fuel_(unleaded/e85)', 'diesel']:\n        feature = 'is_type_%s' % index\n        df[feature] = (df['engine_fuel_type'] == index).astype(int)\n        features.append(feature)\n    \n    for index in [2, 3, 4]: \n        feature = 'num_doors_%s' % index \n        df[feature] = (df['number_of_doors'] == index).astype(int) \n        features.append(feature)\n\n    df_num = df[features]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:32.069764Z","iopub.execute_input":"2021-07-04T17:29:32.070136Z","iopub.status.idle":"2021-07-04T17:29:32.078872Z","shell.execute_reply.started":"2021-07-04T17:29:32.070099Z","shell.execute_reply":"2021-07-04T17:29:32.077902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = preparing_X(car_train_df)\nw_0, w = linear_regression(X_train, y_train) #training the model\ny_pred = w_0 + X_train.dot(w) #predicting \n\nprint(f\"RSME for training is: {round(rmse(y_train, y_pred), 4)}\")\n\n# Validating the model\nX_val = preparing_X(car_val_df)\ny_val_pred = w_0 + X_val.dot(w)\nprint(f\"RSME for validation is: {round(rmse(y_val, y_val_pred), 4)}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:32.251344Z","iopub.execute_input":"2021-07-04T17:29:32.251674Z","iopub.status.idle":"2021-07-04T17:29:32.348844Z","shell.execute_reply.started":"2021-07-04T17:29:32.251643Z","shell.execute_reply":"2021-07-04T17:29:32.347425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let see the how good was the prediction\nplt.figure(figsize=(5,4))\n\nsns.histplot(y_train, label='target', color='black',bins=30)\nsns.histplot(y_pred, label='prediction',color='red', bins=30)\nplt.legend()\nplt.xlabel('log(1+price)')\nplt.ylabel('Count')\nplt.title('Predictions vs Actual Distribution')\n\nplt.show();\n#with new features, the model follows the orginial distribution closer than previously","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:32.46202Z","iopub.execute_input":"2021-07-04T17:29:32.462475Z","iopub.status.idle":"2021-07-04T17:29:32.851683Z","shell.execute_reply.started":"2021-07-04T17:29:32.462417Z","shell.execute_reply":"2021-07-04T17:29:32.850636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:32.853378Z","iopub.execute_input":"2021-07-04T17:29:32.853938Z","iopub.status.idle":"2021-07-04T17:29:32.86064Z","shell.execute_reply.started":"2021-07-04T17:29:32.853895Z","shell.execute_reply":"2021-07-04T17:29:32.859765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"naive_features","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:32.971255Z","iopub.execute_input":"2021-07-04T17:29:32.971628Z","iopub.status.idle":"2021-07-04T17:29:32.97761Z","shell.execute_reply.started":"2021-07-04T17:29:32.971595Z","shell.execute_reply":"2021-07-04T17:29:32.976752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['transmission_type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:33.211123Z","iopub.execute_input":"2021-07-04T17:29:33.211507Z","iopub.status.idle":"2021-07-04T17:29:33.2234Z","shell.execute_reply.started":"2021-07-04T17:29:33.211473Z","shell.execute_reply":"2021-07-04T17:29:33.222302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['driven_wheels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:33.410999Z","iopub.execute_input":"2021-07-04T17:29:33.411361Z","iopub.status.idle":"2021-07-04T17:29:33.42178Z","shell.execute_reply.started":"2021-07-04T17:29:33.411312Z","shell.execute_reply":"2021-07-04T17:29:33.420968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['market_category'].value_counts().head(4)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:33.611161Z","iopub.execute_input":"2021-07-04T17:29:33.61167Z","iopub.status.idle":"2021-07-04T17:29:33.621961Z","shell.execute_reply.started":"2021-07-04T17:29:33.611637Z","shell.execute_reply":"2021-07-04T17:29:33.620819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['vehicle_size'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:33.861135Z","iopub.execute_input":"2021-07-04T17:29:33.861503Z","iopub.status.idle":"2021-07-04T17:29:33.87371Z","shell.execute_reply.started":"2021-07-04T17:29:33.861472Z","shell.execute_reply":"2021-07-04T17:29:33.872635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_df['vehicle_style'].value_counts().head(4)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:29:34.056561Z","iopub.execute_input":"2021-07-04T17:29:34.05691Z","iopub.status.idle":"2021-07-04T17:29:34.067965Z","shell.execute_reply.started":"2021-07-04T17:29:34.05688Z","shell.execute_reply":"2021-07-04T17:29:34.06692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preparing_X(df):\n    \"\"\"\n    Trying some more simple feature engineering.\n    \"\"\"\n    df = df.copy()\n    features = naive_features.copy()\n    \n    df['age'] = 2017 - df['year']\n    features.append('age')\n    \n    for index in ['chevrolet', 'ford', 'volkswagen', 'toyota']:\n        feature = 'is_make_%s' % index #giving a meaning full name\n        #creating the one hot encoding feature and adding the feature back to dataframe\n        df[feature] = (df['make'] == index).astype(int)\n        features.append(feature)\n        \n    for index in ['regular_unleaded', 'premium_unleaded_(required)',\n                  'premium_unleaded_(recommended)', 'flex-fuel_(unleaded/e85)']:\n        feature = 'is_type_%s' % index\n        df[feature] = (df['engine_fuel_type'] == index).astype(int)\n        features.append(feature)\n    \n    for index in ['automatic', 'manual', 'automated_manual', 'direct_drive']:\n        feature = 'is_tranmission_%s' % index\n        df[feature] = (df['transmission_type'] == index).astype(int)\n        features.append(feature)\n    \n#     for index in ['front_wheel_drive', 'rear_wheel_drive', 'all_wheel_drive', 'four_wheel_drive']:\n#         feature = 'is_driven_wheel_%s' % index\n#         df[feature] = (df['driven_wheels'] == index).astype(int)\n#         features.append(feature)\n    \n    for index in ['crossover', 'flex_fuel', 'luxury', 'luxury,performance']:\n        feature = 'is_market_category_%s' % index\n        df[feature] = (df['market_category'] == index).astype(int)\n        features.append(feature)\n    \n#     for index in ['compact', 'midsize', 'large']:\n#         feature = 'is_vehicle_size_%s' % index\n#         df[feature] = (df['vehicle_size'] == index).astype(int)\n#         features.append(feature)\n    \n    \n#     this features give LinAlgError which means it is not possible to find an inverse for this matrix.\n#     If we try to invert a singular matrix, Numpy will raise an error which is LinAlgError: Singular Matrix\n#     this also happens in features which are multiple of each other by some constant(imp) or prefect linear combination\n#     for index in ['sedan', 'dr_suv', 'coupe', 'convertible']:\n#         feature = 'is_vehicle_style_%s' % index\n#         df[feature] = (df['vehicle_style'] == index).astype(int)\n#         features.append(feature)\n\n    for index in [2, 3, 4]: \n        feature = 'num_doors_%s' % index \n        df[feature] = (df['number_of_doors'] == index).astype(int) \n        features.append(feature)\n\n    df_num = df[features]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X\n\n#all the commented features are not useful","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:33:17.823871Z","iopub.execute_input":"2021-07-04T17:33:17.824204Z","iopub.status.idle":"2021-07-04T17:33:17.834905Z","shell.execute_reply.started":"2021-07-04T17:33:17.824177Z","shell.execute_reply":"2021-07-04T17:33:17.834027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = preparing_X(car_train_df)\nw_0, w = linear_regression(X_train, y_train) #training the model\ny_pred = w_0 + X_train.dot(w) #predicting \n\nprint(f\"RSME for training is: {round(rmse(y_train, y_pred), 4)}\")\n\n# Validating the model\nX_val = preparing_X(car_val_df)\ny_val_pred = w_0 + X_val.dot(w)\nprint(f\"RSME for validation is: {round(rmse(y_val, y_val_pred), 4)}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:33:19.156453Z","iopub.execute_input":"2021-07-04T17:33:19.156967Z","iopub.status.idle":"2021-07-04T17:33:19.251106Z","shell.execute_reply.started":"2021-07-04T17:33:19.156924Z","shell.execute_reply":"2021-07-04T17:33:19.249744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let see the how good was the prediction\nplt.figure(figsize=(5,4))\n\nsns.histplot(y_train, label='target', color='black',bins=30)\nsns.histplot(y_pred, label='prediction',color='red', bins=30)\nplt.legend()\nplt.xlabel('log(1+price)')\nplt.ylabel('Count')\nplt.title('Predictions vs Actual Distribution')\n\nplt.show();\n#with new features, the model follows the orginial distribution closer than previously","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:33:31.256189Z","iopub.execute_input":"2021-07-04T17:33:31.256587Z","iopub.status.idle":"2021-07-04T17:33:31.649022Z","shell.execute_reply.started":"2021-07-04T17:33:31.256551Z","shell.execute_reply":"2021-07-04T17:33:31.647918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Regularization\n\n- `Regularized Linear Regression is often called Ridge Regression`.","metadata":{}},{"cell_type":"code","source":"def linear_regression_reg(X, y, r=0.0):\n    \"\"\"\n    This function is for implementation of Regularized Linear regression.\n    \"\"\"\n    ones = np.ones(X.shape[0])\n    X = np.column_stack([ones, X])\n    \n    XTX = X.T.dot(X)\n    reg = r*np.eye(XTX.shape[0]) \n    #adding r to the main diagonal of XTX\n    XTX = XTX + reg\n    \n    XTX_inv = np.linalg.inv(XTX)\n    w = XTX_inv.dot(X.T).dot(y)\n    \n    return w[0], w[1:]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:33:38.986899Z","iopub.execute_input":"2021-07-04T17:33:38.987245Z","iopub.status.idle":"2021-07-04T17:33:38.994203Z","shell.execute_reply.started":"2021-07-04T17:33:38.987215Z","shell.execute_reply":"2021-07-04T17:33:38.993144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = preparing_X(car_train_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:33:40.221597Z","iopub.execute_input":"2021-07-04T17:33:40.221945Z","iopub.status.idle":"2021-07-04T17:33:40.27126Z","shell.execute_reply.started":"2021-07-04T17:33:40.221914Z","shell.execute_reply":"2021-07-04T17:33:40.270425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for r in [0, 0.001, 0.01, 0.1, 1, 10]:\n    w_0, w = linear_regression_reg(X_train, y_train, r=r)\n    y_pred = w_0 + X_train.dot(w) #predicting \n    print(f\"RSME for training when r = {r} is: {round(rmse(y_train, y_pred), 6)}\")\n    # Validating the model\n    X_val = preparing_X(car_val_df)\n    y_val_pred = w_0 + X_val.dot(w)\n    print(f\"RSME for validation when r = {r} is: {round(rmse(y_val, y_val_pred), 6)}\")\n    print('-'*15)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:33:41.816172Z","iopub.execute_input":"2021-07-04T17:33:41.816534Z","iopub.status.idle":"2021-07-04T17:33:42.077646Z","shell.execute_reply.started":"2021-07-04T17:33:41.816502Z","shell.execute_reply":"2021-07-04T17:33:42.076516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for r in [0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]:\n    w_0, w = linear_regression_reg(X_train, y_train, r=r)\n    y_pred = w_0 + X_train.dot(w) #predicting \n    print(f\"RSME for training when r = {r} is: {round(rmse(y_train, y_pred), 6)}\")\n    # Validating the model\n    X_val = preparing_X(car_val_df)\n    y_val_pred = w_0 + X_val.dot(w)\n    print(f\"RSME for validation when r = {r} is: {round(rmse(y_val, y_val_pred), 6)}\")\n    print('-'*15)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:33:46.62736Z","iopub.execute_input":"2021-07-04T17:33:46.62771Z","iopub.status.idle":"2021-07-04T17:33:46.986821Z","shell.execute_reply.started":"2021-07-04T17:33:46.62768Z","shell.execute_reply":"2021-07-04T17:33:46.985514Z"},"trusted":true},"execution_count":null,"outputs":[]}]}