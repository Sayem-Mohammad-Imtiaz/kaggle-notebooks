{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py"}},"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{},"source":"# This notebook is an extention of a notebook below\n\nRNN implementation \n\nhttps://www.kaggle.com/kentata/rnn-for-predicting-closing-price-using-keras"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"66960760c7a4b1355d60edbc2e17a104bddd7702","_cell_guid":"5294b1c3-7370-4017-9d0b-e4270b16ded3"},"source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set()\n# Input data files are available in the \"../input/\" directory.\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"train = pd.read_csv(\"../input/bitcoin_price_Training - Training.csv\")\ntest = pd.read_csv(\"../input/bitcoin_price_1week_Test - Test.csv\")\n\ntrain = train[::-1]\ntest = test[::-1]\n\ntrain = train['Close'].values.astype('float32')\ntest = test['Close'].values.astype('float32')"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"from sklearn.preprocessing import StandardScaler\n\n# reshape data to scale the point\ntrain = train.reshape(-1, 1)\ntest = test.reshape(-1, 1)\n\nscaler = StandardScaler()\ntrain_n = scaler.fit_transform(train)\ntest_n = scaler.transform(test)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"def generator(data, lookback, delay, min_index, max_index, \n              shuffle=False, batch_size=128, step=1):\n    if max_index is None:\n        max_index = len(data) - delay - 1\n    i = min_index + lookback\n    while 1:\n        if shuffle:\n            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n        else:\n            if i + batch_size >= max_index:\n                i = min_index + lookback\n                \n            rows = np.arange(i, min(i + batch_size, max_index))\n            i += len(rows)\n        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n        targets = np.zeros((len(rows),))\n        for j, row in enumerate(rows):\n            indices = range(rows[j] - lookback, rows[j], step)\n            samples[j] = data[indices]\n            targets[j] = data[rows[j] + delay]\n        yield samples, targets"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"lookback = 24\nstep = 1\ndelay = 7\nbatch_size = 128\ntrain_gen = generator(train_n, lookback=lookback, delay=delay,\n    min_index=0, max_index=1000, shuffle=True, step=step,\nbatch_size=batch_size)\nval_gen = generator(train_n, lookback=lookback, delay=delay,\n    min_index=1001, max_index=None, step=step, batch_size=batch_size)\ntest_gen = generator(test_n, lookback=lookback, delay=delay,\n    min_index=0, max_index=None, step=step, batch_size=batch_size)\n# This is how many steps to draw from `val_gen` in order to see the whole validation set:\nval_steps = (len(train_n) - 1001 - lookback) // batch_size\n# This is how many steps to draw from `test_gen` in order to see the whole test set:\ntest_steps = (len(test_n) - lookback) // batch_size"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"scrolled":false},"source":"model = Sequential()\nmodel.add(layers.GRU(32,\n                     dropout=0.5,\n                     recurrent_dropout=0.5,\n                     return_sequences=True,\n                     input_shape=(None, train_n.shape[-1])))\nmodel.add(layers.GRU(64, activation='relu',\n                     dropout=0.5,\n                     recurrent_dropout=0.5))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nmodel.summary()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"history = model.fit_generator(train_gen,\n                              steps_per_epoch=500,\n                              epochs=40,\n                              validation_data=val_gen,\n                              validation_steps=val_steps)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":""},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(loss))\nplt.figure()\nplt.plot(epochs, loss, 'blue', label='train loss')\nplt.plot(epochs, val_loss, 'orange', label='validation loss')\nplt.title('Training and validation loss')\nplt.legend()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":"train_re = train_n.reshape(-1,1,1)\npred = model.predict(train_re)\npred = scaler.inverse_transform(pred)\n\nplt.plot(range(len(train_re)), train, label='train')\nplt.plot(range(len(train_re)), pred, label='prediction')\nplt.legend()\nplt.title(\"Prediction on training data\")\n"}],"nbformat_minor":1}