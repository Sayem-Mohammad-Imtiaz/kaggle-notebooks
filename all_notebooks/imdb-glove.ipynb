{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"imdb_dir = '../input/keras-imdb/aclImdb_v1/aclImdb'\ntrain_dir = os.path.join(imdb_dir,'train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showdir(path, depth):\n    if depth == 0:\n        print(\"root:[\" + path + \"]\")\n \n    for item in os.listdir(path):\n        if '.' not in item:\n            print(\"|      \" * depth + \"|--\" + item)\n \n            newitem = os.path.join(path,item)\n            if os.path.isdir(newitem):\n                showdir(newitem, depth +1)\nshowdir('../',0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\ntexts = []\n\nfor label_type in ['neg','pos']:\n    dir_name = os.path.join(train_dir, label_type)\n    for fname in os.listdir(dir_name):\n        if fname[-4:] == '.txt':\n            f = open(os.path.join(dir_name,fname),encoding='utf-8')\n            texts.append(f.read())\n            f.close\n        if label_type == 'neg':\n            labels.append(0)\n        else:\n            labels.append(1)\nprint(len(texts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nmaxlen = 100\ntrain_samples = 200\nvalidation_samples = 10000\nmax_words = 10000\n\ntokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\n\nprint('Use %s token words'% len(word_index))\n\ndata = pad_sequences(sequences,maxlen=maxlen)\nlabels = np.asarray(labels)\nindices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\n\nx_train = data[:train_samples]\ny_train = labels[:train_samples]\n\nx_val = data[train_samples:train_samples+validation_samples]\ny_val = labels[train_samples:train_samples+validation_samples]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_dir = '../input/glove6b'\n\nembeddings_index = {}\nf = open(os.path.join(glove_dir,'glove.6B.100d.txt'),encoding='UTF-8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:],dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('There are %s word-vector.' % len(embeddings_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 100\nembedding_matrix = np.zeros((max_words, embedding_dim))\nprint(embedding_matrix.shape)\nfor word, i in word_index.items():\n    if i < max_words:\n        embeddings_vector = embeddings_index.get(word)\n        if embeddings_vector is not None:\n            embedding_matrix[i] = embeddings_vector\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Embedding(max_words,embedding_dim,input_length=maxlen))\nmodel.add(Flatten())\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[0].set_weights([embedding_matrix])\nmodel.layers[0].trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\nhistory = model.fit(x_train,y_train,epochs = 10,batch_size = 32,validation_data=(x_val,y_val))\nmodel.save_weights('../working/pre_trained_glove_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef show_all(history):\n    def show(history,acc,val_acc,label):\n        epochs = range(1, len(history.history[acc])+1)\n        plt.plot(epochs,history.history[acc],label='Training '+label)\n        plt.plot(epochs,history.history[val_acc],label='Validation '+label)\n        plt.title('Training and Validation '+label)\n        plt.legend()\n    plt.figure(figsize=(15,5))\n    plt.subplot(121)\n    show(history,'acc','val_acc','acc')\n    plt.subplot(122)\n    show(history,'loss','val_loss','loss')\nshow_all(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Not use pre-trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2 = Sequential()\nmodel_2.add(Embedding(max_words,embedding_dim,input_length=maxlen))\nmodel_2.add(Flatten())\nmodel_2.add(Dense(32,activation='relu'))\nmodel_2.add(Dense(1,activation='sigmoid'))\nmodel_2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\nhistory_2 = model_2.fit(x_train,y_train,epochs=10,batch_size=32,validation_data=(x_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_all(history_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\ntexts = []\ntest_dir = os.path.join(imdb_dir,'test')\nfor label_type in ['neg','pos']:\n    dir_name = os.path.join(test_dir, label_type)\n    for fname in os.listdir(dir_name):\n        if fname[-4:] == '.txt':\n            f = open(os.path.join(dir_name,fname),encoding='utf-8')\n            texts.append(f.read())\n            f.close\n        if label_type == 'neg':\n            labels.append(0)\n        else:\n            labels.append(1)\nsequences = tokenizer.texts_to_sequences(texts)\nx_test = pad_sequences(sequences, maxlen=maxlen)\ny_test = np.asarray(labels)\n    \nmodel.load_weights('../working/pre_trained_glove_model.h5')\nprint(model.metrics_names)\nmodel.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy : 0.56"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}