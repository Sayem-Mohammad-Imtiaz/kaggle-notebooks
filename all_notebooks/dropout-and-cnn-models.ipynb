{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras import Sequential,Model\nfrom tensorflow.keras.layers import Flatten, Dense, MaxPooling2D,Dropout, Conv2D, BatchNormalization,Add,Activation,Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:03.247359Z","iopub.execute_input":"2021-08-11T10:31:03.247747Z","iopub.status.idle":"2021-08-11T10:31:03.253915Z","shell.execute_reply.started":"2021-08-11T10:31:03.247712Z","shell.execute_reply":"2021-08-11T10:31:03.252863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv('../input/minst-fashion-dataset/fashion-mnist_train.csv')\ntest_df=pd.read_csv('../input/minst-fashion-dataset/fashion-mnist_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:03.553385Z","iopub.execute_input":"2021-08-11T10:31:03.554043Z","iopub.status.idle":"2021-08-11T10:31:09.430167Z","shell.execute_reply.started":"2021-08-11T10:31:03.553993Z","shell.execute_reply":"2021-08-11T10:31:09.428802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:13:39.237817Z","iopub.execute_input":"2021-08-11T07:13:39.238246Z","iopub.status.idle":"2021-08-11T07:13:39.242432Z","shell.execute_reply.started":"2021-08-11T07:13:39.238217Z","shell.execute_reply":"2021-08-11T07:13:39.241742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:13:39.243694Z","iopub.execute_input":"2021-08-11T07:13:39.244106Z","iopub.status.idle":"2021-08-11T07:13:39.289192Z","shell.execute_reply.started":"2021-08-11T07:13:39.244069Z","shell.execute_reply":"2021-08-11T07:13:39.288176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One column for label. Rest of the columns should represent both height and width.","metadata":{}},{"cell_type":"code","source":"print('Image Pixels: ', 785-1)\nprint('Lenght of each dimension: ', np.sqrt(784))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:13:39.290576Z","iopub.execute_input":"2021-08-11T07:13:39.290866Z","iopub.status.idle":"2021-08-11T07:13:39.297413Z","shell.execute_reply.started":"2021-08-11T07:13:39.290839Z","shell.execute_reply":"2021-08-11T07:13:39.296438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore our dimensions should be (28,28,1).\n(1 represents grayscale)","metadata":{}},{"cell_type":"code","source":"X=train_df.iloc[:,1:]\ny=train_df.label\nX_test=test_df.iloc[:,1:]\ny_test=test_df.label","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:15.424707Z","iopub.execute_input":"2021-08-11T10:31:15.425098Z","iopub.status.idle":"2021-08-11T10:31:15.435408Z","shell.execute_reply.started":"2021-08-11T10:31:15.425063Z","shell.execute_reply":"2021-08-11T10:31:15.434059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:13:42.837719Z","iopub.execute_input":"2021-08-11T07:13:42.838131Z","iopub.status.idle":"2021-08-11T07:13:42.857335Z","shell.execute_reply.started":"2021-08-11T07:13:42.838093Z","shell.execute_reply":"2021-08-11T07:13:42.856484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image from pixels","metadata":{}},{"cell_type":"markdown","source":"### Procedure:\nSelect values of each row separately and reshape them as (28,28,1). ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef pic_show(df,row):\n    plt.figure()\n    plt.imshow(df.iloc[row].values.reshape(28,28,1))\n    plt.axis('off')\n    plt.show()\n\npic_show(X,2)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:13:46.127405Z","iopub.execute_input":"2021-08-11T07:13:46.127932Z","iopub.status.idle":"2021-08-11T07:13:46.213172Z","shell.execute_reply.started":"2021-08-11T07:13:46.1279Z","shell.execute_reply":"2021-08-11T07:13:46.212156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Reshaper Function","metadata":{}},{"cell_type":"markdown","source":"### Procedure:\nSelect values of each row separately by utilizing for loop and reshape them as (28,28,1). Finally collect modified data in a new list and return the data collection. ","metadata":{}},{"cell_type":"code","source":"def reshaper(df):\n    X=[]\n    for i in range(df.shape[0]):\n        pic=df.iloc[i].values.reshape(28,28,1)\n        X.append(pic)\n    return np.array(X)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:21.092797Z","iopub.execute_input":"2021-08-11T10:31:21.093175Z","iopub.status.idle":"2021-08-11T10:31:21.100138Z","shell.execute_reply.started":"2021-08-11T10:31:21.093144Z","shell.execute_reply":"2021-08-11T10:31:21.098964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:13:51.146748Z","iopub.execute_input":"2021-08-11T07:13:51.147269Z","iopub.status.idle":"2021-08-11T07:13:51.174887Z","shell.execute_reply.started":"2021-08-11T07:13:51.147236Z","shell.execute_reply":"2021-08-11T07:13:51.174169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=reshaper(X)\nX_test=reshaper(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:25.241745Z","iopub.execute_input":"2021-08-11T10:31:25.242219Z","iopub.status.idle":"2021-08-11T10:31:32.613178Z","shell.execute_reply.started":"2021-08-11T10:31:25.242181Z","shell.execute_reply":"2021-08-11T10:31:32.612234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalization","metadata":{}},{"cell_type":"markdown","source":"### Procedure:\nDivide data to 255.0 to both converting the result a float and reduce the complexity of data. Normalization is a process in which the ratio between data remains same but the magnitude is decreased (Between 0 and 1). This is done by dividing all data to max value in dataset.\n\nFor example: [20,10]\n\nNormalized version:[1,0.5]\n\nFor colorscale, the maximum value is 255. That's why we divide all data to 255.0 ","metadata":{}},{"cell_type":"code","source":"X=X/255.0\nX_test=X_test/255.0","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:32.614769Z","iopub.execute_input":"2021-08-11T10:31:32.615161Z","iopub.status.idle":"2021-08-11T10:31:32.795521Z","shell.execute_reply.started":"2021-08-11T10:31:32.61512Z","shell.execute_reply":"2021-08-11T10:31:32.794539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_val,y_train,y_val=train_test_split(X,y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:32.797558Z","iopub.execute_input":"2021-08-11T10:31:32.797975Z","iopub.status.idle":"2021-08-11T10:31:32.926164Z","shell.execute_reply.started":"2021-08-11T10:31:32.797933Z","shell.execute_reply":"2021-08-11T10:31:32.925177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:21:42.676405Z","iopub.execute_input":"2021-08-11T07:21:42.676812Z","iopub.status.idle":"2021-08-11T07:21:42.683624Z","shell.execute_reply.started":"2021-08-11T07:21:42.676773Z","shell.execute_reply":"2021-08-11T07:21:42.682256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny_train_one=to_categorical(y_train)\ny_val_one=to_categorical(y_val)\ny_test_one=to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:36.94851Z","iopub.execute_input":"2021-08-11T10:31:36.948894Z","iopub.status.idle":"2021-08-11T10:31:36.956597Z","shell.execute_reply.started":"2021-08-11T10:31:36.948859Z","shell.execute_reply":"2021-08-11T10:31:36.95532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Sequential Model\nImportant Notes:\n\nFor the starting point, 0.5 is generally good for  Dropout layer (True for Linear Neural Networks)(Claim). Although that's the case it's beneficial to try the other alternatives until finding the optimum value. \n\nLet's test it!\n\n### Precedure\nTry different dropout values in model with utilizg for loop.\n\nUse lower epoch for the convenience.\n\n\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:27:48.33969Z","iopub.execute_input":"2021-08-11T10:27:48.340321Z","iopub.status.idle":"2021-08-11T10:27:48.345035Z","shell.execute_reply.started":"2021-08-11T10:27:48.340285Z","shell.execute_reply":"2021-08-11T10:27:48.343984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n             \ncandidates=[0.1,0.3,0.5,0.7,0.9]\n\nfor i in candidates:\n    model=Sequential([\n        Conv2D(64,3,activation='relu', input_shape=(28,28,1)),\n        BatchNormalization(),\n        MaxPooling2D(2),\n        Dropout(i),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dense(10, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                 metrics=['accuracy'],\n                 optimizer=sgd)\n    history=model.fit(X_train,y_train_one, batch_size=128,epochs=5,validation_data=(X_val,y_val_one), verbose=0)\n    print('Test accuracy for dropout value: ', str(i), model.evaluate(X_test,y_test_one,verbose=0)[1])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:43:58.551408Z","iopub.execute_input":"2021-08-11T07:43:58.551801Z","iopub.status.idle":"2021-08-11T07:57:53.817588Z","shell.execute_reply.started":"2021-08-11T07:43:58.551767Z","shell.execute_reply":"2021-08-11T07:57:53.816454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.ylabel('Test Accuracy')\nplt.xlabel('Dropout Value')\nsns.barplot(x=[0.1,0.3,0.5,0.7,0.9],y=[0.915,0.912,0.912,0.90,0.87]);","metadata":{"execution":{"iopub.status.busy":"2021-08-11T08:01:59.34035Z","iopub.execute_input":"2021-08-11T08:01:59.340752Z","iopub.status.idle":"2021-08-11T08:01:59.501823Z","shell.execute_reply.started":"2021-08-11T08:01:59.340718Z","shell.execute_reply":"2021-08-11T08:01:59.500696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like except dropout value of 0.9, test accuracy doesn't change that much. \n\nLet's try higher epoch and compare it with a functional neural network.","metadata":{}},{"cell_type":"code","source":"model=Sequential([\n    Conv2D(64,3,activation='relu', input_shape=(28,28,1)),\n    BatchNormalization(),\n    MaxPooling2D(2),\n    Dropout(0.5),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(10, activation='softmax')\n])\nmodel.compile(loss='categorical_crossentropy',\n             metrics=['accuracy'],\n             optimizer=sgd)\nhistory=model.fit(X_train,y_train_one, batch_size=128,epochs=20,validation_data=(X_val,y_val_one), verbose=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T08:06:56.588958Z","iopub.execute_input":"2021-08-11T08:06:56.589515Z","iopub.status.idle":"2021-08-11T08:18:13.80289Z","shell.execute_reply.started":"2021-08-11T08:06:56.589465Z","shell.execute_reply":"2021-08-11T08:18:13.8018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df=pd.DataFrame(history.history)\nhistory_df[['loss','val_loss']].plot();","metadata":{"execution":{"iopub.status.busy":"2021-08-11T08:19:56.234004Z","iopub.execute_input":"2021-08-11T08:19:56.234385Z","iopub.status.idle":"2021-08-11T08:19:56.435846Z","shell.execute_reply.started":"2021-08-11T08:19:56.234355Z","shell.execute_reply":"2021-08-11T08:19:56.434761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test Accuracy for Sequential Neural Network:', model.evaluate(X_test,y_test_one,verbose=0)[1])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T08:23:18.453706Z","iopub.execute_input":"2021-08-11T08:23:18.454102Z","iopub.status.idle":"2021-08-11T08:23:20.451305Z","shell.execute_reply.started":"2021-08-11T08:23:18.454065Z","shell.execute_reply":"2021-08-11T08:23:20.449947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Functional Model\n\n### Procedure:\n\nAdd another Dense Layer after flatten layer, combine the outputs and run the functional model.\n\nFinally compare the accuracy between two!","metadata":{}},{"cell_type":"code","source":"input_tensor=Input(shape=(28,28,1))\nConv1=Conv2D(64,3, input_shape=(28,28,1))(input_tensor)\nA1=Activation('relu')(Conv1)\nBatchNor=BatchNormalization()(A1)\nPool1=MaxPooling2D(2)(BatchNor)\nPool1=Dropout(0.5)(Pool1)\nFlat=Flatten()(Pool1)\nD1=Dense(128, activation='relu')(Flat)\nD2=Dense(128, activation='relu')(Flat)\nD3=Add()([D2,D1])\noutput_tensor=Dense(10,activation='softmax')(D3)\nmodel=Model(inputs=input_tensor,outputs=output_tensor)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:27:01.440428Z","iopub.execute_input":"2021-08-11T10:27:01.4408Z","iopub.status.idle":"2021-08-11T10:27:01.610905Z","shell.execute_reply.started":"2021-08-11T10:27:01.440767Z","shell.execute_reply":"2021-08-11T10:27:01.609738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:27:05.630918Z","iopub.execute_input":"2021-08-11T10:27:05.631264Z","iopub.status.idle":"2021-08-11T10:27:05.635914Z","shell.execute_reply.started":"2021-08-11T10:27:05.631234Z","shell.execute_reply":"2021-08-11T10:27:05.634721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T08:41:55.276875Z","iopub.execute_input":"2021-08-11T08:41:55.277272Z","iopub.status.idle":"2021-08-11T08:41:55.464353Z","shell.execute_reply.started":"2021-08-11T08:41:55.277238Z","shell.execute_reply":"2021-08-11T08:41:55.462857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n             metrics=['accuracy'],\n             optimizer=sgd)\nhistory=model.fit(X_train,y_train_one, batch_size=128,epochs=20,validation_data=(X_val,y_val_one), verbose=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:31:49.04841Z","iopub.execute_input":"2021-08-11T10:31:49.048829Z","iopub.status.idle":"2021-08-11T10:44:27.174113Z","shell.execute_reply.started":"2021-08-11T10:31:49.048797Z","shell.execute_reply":"2021-08-11T10:44:27.172875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test Accuracy for Functional Neural Network:', model.evaluate(X_test,y_test_one,verbose=0)[1])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:50:01.809343Z","iopub.execute_input":"2021-08-11T10:50:01.809747Z","iopub.status.idle":"2021-08-11T10:50:04.15624Z","shell.execute_reply.started":"2021-08-11T10:50:01.809714Z","shell.execute_reply":"2021-08-11T10:50:04.15502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nMaking more complex neural network models may improve the performance of the model. This improvement depends on the complexity that is added.\n\nDropout values generally did not change the accuracy of the model that much. 0.5 can be a good starting point as mentioned in the claim.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}