{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional,Flatten, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def getUnreadableCount(df):\n    return (df['IDENTITY'] == 'UNREADABLE').sum();\n\ndef getLowercaseCount(df):\n    return (df['IDENTITY'].str.islower()).sum();\n\ndef getDigitCount(df):\n    return (df['IDENTITY'].str.isdigit()).sum();\n  \ndef removeUnreadableEntries(df):\n    is_unreadable = df['IDENTITY'] != 'UNREADABLE';\n    df = df[is_unreadable];\n    return df;\n\ndef removeDigitEntries(df):\n    is_digit = df['IDENTITY'].str.isdigit();\n    df = df[is_digit];\n    return df;\n\ndef cleanDataSet(df):\n    empty_count = df.isnull().sum().sum();      # 565 for train, 78 for validation\n    if(empty_count):\n        df.dropna(inplace=True);\n    unreadable_count = getUnreadableCount(df);  # 102 for train, 12 for validation\n    if(unreadable_count):\n        df = removeUnreadableEntries(df);\n    digit_count = getDigitCount(df);            # 0 for train, 0 for validation\n    if(digit_count):\n        df = removeDigitEntries(df);\n    lowercase_count = getLowercaseCount(df);    # 13 for train, 2 for validation\n    if(lowercase_count):\n        # Names in the pictures are all uppercase, we have to make our data uppercase\n        df.loc[:, 'IDENTITY'] = df['IDENTITY'].apply(lambda x: x.upper());\n    notpicture_count = df[~df[\"FILENAME\"].str.endswith('.jpg')].sum().sum().astype(int);\n    if(notpicture_count):                       # 0 for train, 0 for validation\n         df = df[df[\"FILENAME\"].str.contains('.jpg')];\n    return df;\n\ndef num_to_char(num): \n    label = \"\"\n    for ch in num:\n        if ch == -1:\n            break\n        label+=alphabet_characters[ch]        \n    return label\n\ndef ctc_loss_function(args):  \n    y_pred, y_true, input_length, label_length = args\n    return tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 50000\nvalid_size= 10000\nalphabet_characters = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\nnum_of_characters = len(alphabet_characters) + 1\nnum_of_timestamps = 64","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the training and validation written names"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"training_written_df = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\nvalidation_written_df = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_written_df = cleanDataSet(training_written_df);\nvalidation_written_df = cleanDataSet(validation_written_df);\n    \n# To make sure our indices are one behind the other\ntraining_written_df.reset_index(inplace = True, drop=True)\nvalidation_written_df.reset_index(inplace = True, drop=True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example of picture after resizing to 128x64 and 256x32 "},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 128;\nimg_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+training_written_df.loc[i, 'FILENAME']\nimage = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\nnew_img = cv2.resize(image, (128, 64))\nplt.imshow(new_img, cmap = 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 128;\nimg_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+training_written_df.loc[i, 'FILENAME']\nimage = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\nnew_img = cv2.resize(image, (256, 32))\nplt.imshow(new_img, cmap = 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_x = []\nfor i in range(valid_size):\n    img_dir = '/kaggle/input/handwriting-recognition/validation_v2/validation/'+validation_written_df.loc[i, 'FILENAME']   \n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    valid_x.append(image)\n    \ntrain_x = []\nfor j in range(train_size):\n    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+training_written_df.loc[j, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    train_x.append(image)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_x = np.array(valid_x).reshape(-1, 256, 32, 1)\ntrain_x = np.array(train_x).reshape(-1, 256, 32, 1)\n\nstr_len = training_written_df[\"IDENTITY\"].str.len().max()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = np.ones([train_size, str_len]) * -1\n\ntrain_label_len = np.zeros([train_size, 1])\ntrain_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([train_size])\n\nvalid_y = np.ones([valid_size, str_len]) * -1\n\nvalid_label_len = np.zeros([valid_size, 1])\nvalid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\nvalid_output = np.zeros([valid_size])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label preparation\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(train_size):\n    label = []\n    for ch in training_written_df['IDENTITY'][i]:\n        label.append(alphabet_characters.index(ch))\n    arr = np.array(label)\n    train_y[i, 0:len(training_written_df.loc[i, 'IDENTITY'])] = arr;\n    train_label_len[i] = len(training_written_df.loc[i, 'IDENTITY'])\n\n\nfor i in range(valid_size):\n    label = []\n    for ch in validation_written_df['IDENTITY'][i]:\n        label.append(alphabet_characters.index(ch))\n    arr = np.array(label)\n    valid_y[i, 0:len(validation_written_df.loc[i, 'IDENTITY'])] = arr;\n    valid_label_len[i] = len(validation_written_df.loc[i, 'IDENTITY'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_seq = Sequential()\n\nmodel_seq.add(Conv2D(32, (3, 3), padding='same', input_shape=(256, 32, 1)))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_seq.add(BatchNormalization())\n\nmodel_seq.add(Conv2D(64, (3, 3), padding='same'))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(MaxPooling2D(pool_size=(1, 2)))\nmodel_seq.add(Dropout(0.3))\nmodel_seq.add(BatchNormalization())\n\nmodel_seq.add(Flatten())\nmodel_seq.add(Dropout(0.3))\n\nmodel_seq.add(Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1'))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(Dropout(0.2))\n\nmodel_seq.add(Dense(34))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(Dropout(0.2))\nmodel_seq.add(Activation('softmax'))\n\ninput_data = Input(shape=(256, 32, 1), name='input')\ny_pred_seq = model_seq(input_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling the model"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"optimizer = 'adam'\nmodel_seq.compile(loss=tf.keras.losses.MeanAbsoluteError(), optimizer=optimizer, metrics=['accuracy'])\n\nmodel_seq.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=5, restore_best_weights=True\n)\nmy_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=10)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"seq_history = model_seq.fit(train_x, train_y, validation_data=(valid_x, valid_y), epochs=30, batch_size=64, callbacks=my_callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RCNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data = Input(shape=(256, 32, 1))\n\ncnn_layer = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(input_data)  \ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(2, 2))(cnn_layer)\n    \ncnn_layer = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(cnn_layer)\ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(1, 2))(cnn_layer)\ncnn_layer = Dropout(0.3)(cnn_layer)\n    \ncnn_layer = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(cnn_layer)\ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(1, 1))(cnn_layer)\ncnn_layer = Dropout(0.3)(cnn_layer)\n\ncnn_layer = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(cnn_layer)\ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(2, 2))(cnn_layer)\ncnn_layer = Dropout(0.3)(cnn_layer)\n    \n# CNN to RNN\nreshaped_layer = Reshape(target_shape=((64, 1024)))(cnn_layer)\ndense_layer = Dense(64, activation='relu', kernel_initializer='he_normal')(reshaped_layer)\n    \n## RNN\nrnn_layer = Bidirectional(LSTM(256, return_sequences=True))(dense_layer)\nrnn_layer = Bidirectional(LSTM(256, return_sequences=True))(rnn_layer)\n    \n## OUTPUT\nfinal_dense_layer = Dense(num_of_characters, kernel_initializer='he_normal')(rnn_layer)\ny_pred = Activation('softmax')(final_dense_layer)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Early stopping function"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=5, restore_best_weights=True\n)\nmy_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=10)\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculation of ctc loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"true_labels = Input(shape=[str_len], dtype='float32')\ninput_length = Input(shape=[1], dtype='int64')\nlabel_length = Input(shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_loss_function, output_shape=(1,), name='ctc_loss')([y_pred, true_labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, true_labels, input_length, label_length], outputs=ctc_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling of model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_final.compile(loss={'ctc_loss' : lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training of model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n                epochs=30, batch_size=64, callbacks=my_callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = np.array(history.history['loss'])\nloss_val = np.array(history.history['val_loss'])\nepochs = range(1,31)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using the decoding function from Keras (Example for reading Captchas)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search. For complex tasks, you can use beam search\n    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n\n    output_text = []\n    for i in range(valid_size):\n        output_text.append(num_to_char(K.get_value(results[i])))\n    return output_text\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_valid_prediction = model.predict(valid_x)\ndecoded_valid_prediction = decode_batch_predictions(model_valid_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_true_labels = validation_written_df.loc[0:valid_size, 'IDENTITY']\ncorrect = 0\n\nfor i in range(valid_size):\n    pr = decoded_valid_prediction[i]\n    tr = valid_true_labels[i]\n    \n    if pr == tr :\n        correct += 1 \n    \nprint('Correct words in validation predicted: %.2f%%' %(correct*100/valid_size))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading, cleaning and prediction on the test set (10 000 examples)[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_written_df = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_test_v2.csv')\ntest_size = 10000\ntest_written_df = cleanDataSet(test_written_df);\n    \n# To make sure our indices are one behind the other\ntest_written_df.reset_index(inplace = True, drop=True)\n\ntest_x = []\nfor i in range(valid_size):\n    img_dir = '/kaggle/input/handwriting-recognition/test_v2/test/'+test_written_df.loc[i, 'FILENAME']   \n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    test_x.append(image)\n    \ntest_x = np.array(test_x).reshape(-1, 256, 32, 1)\ntest_y = np.ones([test_size, str_len]) * -1\n\nfor i in range(test_size):\n    label_num = []\n    for ch in test_written_df['IDENTITY'][i]:\n        label_num.append(alphabet_characters.index(ch))\n    arr = np.array(label_num)\n    test_y[i, 0:len(test_written_df.loc[i, 'IDENTITY'])] = arr;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_test_prediction = model.predict(test_x)\ndecoded_test_prediction = decode_batch_predictions(model_test_prediction)\n\ntest_labels = test_written_df.loc[0:test_size, 'IDENTITY']\ncorrect = 0\n\nfor i in range(test_size):\n    pr = decoded_test_prediction[i]\n    tr = test_labels[i]\n    \n    if pr == tr :\n        correct += 1 \n    \nprint('Correct words in test predicted: %.2f%%' %(correct*100/test_size))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random image reconstruction, with the predicted labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5,14):\n    img_dir = '/kaggle/input/handwriting-recognition/test_v2/test/'+test_written_df.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap='gray')\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    prediction = model.predict(image.reshape(1, 256, 32, 1))\n    decoded_label = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],greedy=True)[0][0])\n    plt.title(num_to_char(decoded_label[0]))\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}