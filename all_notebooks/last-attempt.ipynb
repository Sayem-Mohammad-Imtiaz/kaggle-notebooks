{"cells":[{"metadata":{"_cell_guid":"65e502f9-fd3b-4b19-a844-cb718b0d25e7","_uuid":"cd3296c40587f51a36e1818ae4a310ad05b658b5"},"cell_type":"markdown","source":"# A simple linear baseline for the Walmart challenge\nThis notebook shows how you load the data, prepare it for usage with Keras and then create a submission file. The model is a simple linear regression.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7c399d8c-5531-44a8-a758-ef7785518f28","collapsed":true,"_uuid":"3f34f97043b07eb2c0cca8fdc317a199ace93a6c","trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9785050d-5a83-44e2-82e8-f5c0f8309da2","_uuid":"f668e5a9e6c7462e8050c97c298bef888a13f6aa"},"cell_type":"markdown","source":"## Loading the data\nIn Kaggle, data that can be accessed by a Kernel is saved under ``../inputs/``\nFrom there we can load it with pandas:","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ecb87ead-f34a-4449-95f9-2c9c0764247d","collapsed":true,"_uuid":"03a0a3ff6dfdb3d53a037d727f6260c0412990a8","trusted":false},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"693a46c8-6748-4c51-bb76-e08eb1ebcea7","_uuid":"cca3344c7d9c45a2c0dc41fe90e88083e15fb8de"},"cell_type":"markdown","source":"We are going to do some data preparation. It is easiest to do this for training and test set combined so we have to do all these steps only once. It is good to know where to split the set afterwards though!","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"c813405d-10a0-45ba-891e-e4e494ab34fc","_uuid":"e6c57c708a9db7fc01447b6b00908b67cb7f4b09","trusted":false,"collapsed":true},"cell_type":"code","source":"len(train) # Get number of training examples","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8bca733e-3ba3-4db2-bcc1-66b371f702ab","_uuid":"adac71f84a15958f3ec618c5c49f8f86acbb9d06","trusted":false,"collapsed":true},"cell_type":"code","source":"len(test) # Get number of test examples","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"21486f31-1a32-4471-ae71-d791097547eb","_uuid":"98271a862054ac1b445e38a613b7b500c12e55ba","trusted":false,"collapsed":true},"cell_type":"code","source":"df = pd.concat([train,test],axis=0) # Join train and test\na1 = df.iloc[:282451]\na2 = df.iloc[282451:]\nw = len(df)\np = [1]*282451\np = np.array(p)\nq = np.arange(282451)\na1 = a1.assign(p=p)\np = [0]*(w-282451)\np = np.array(p)\nq = np.arange(w-282451)\na2 = a2.assign(p = p)\ndf = pd.concat([a1,a2], axis= 0)\nq = np.arange(len(df))\ndf = df.assign(q=q)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3f4dc881-8584-449b-955f-caa156e66d54","_uuid":"9457a3f22c9934f3c96dc0c742b2345a86770d83","trusted":false,"collapsed":true},"cell_type":"code","source":"df.iloc[282451:]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7094d024-8782-4d1c-8b46-ddf7140f46ab","_uuid":"b2d03ef65c79c4144d743e6ab70f2de365a26c61","trusted":false,"collapsed":true},"cell_type":"code","source":"df.head() # Get an overview of the data","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1af8adf9-b554-4dd8-b58a-1b1d522a89fe","_uuid":"540ed3ffa79d92489943b96b0d40a9fdea4254d5","trusted":false,"collapsed":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd62f58a-4762-4012-ac3b-185243517990","_uuid":"ecc8a8f449625c1ab493d380c5ea8fbd06a3e89e"},"cell_type":"markdown","source":"There seem to be some missing values in the data. We have to make sure to deal with them before feeding anything into the network.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4c2f78ee-4bf8-4d90-9e61-611aed761c1b","_uuid":"69a906f1e30491b5e20eadc6a807862ee4c4a344","trusted":false,"collapsed":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ebbc0654-0a0d-467b-98a3-aef93009aa38","_uuid":"51e0995047f008d796329e30e1b8d38e8040c124"},"cell_type":"markdown","source":"We will do a bit of very basic feature engineering here by creating a feature which indicates whether a certain markdown was active at all.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"90dbdf5c-2de5-493b-a846-3db0e9a2641e","collapsed":true,"_uuid":"b9a1c793ded40b597f959abcaaf8cebec9ee0423","trusted":false},"cell_type":"code","source":"df = df.assign(md1_present = df.MarkDown1.notnull())\ndf = df.assign(md2_present = df.MarkDown2.notnull())\ndf = df.assign(md3_present = df.MarkDown3.notnull())\ndf = df.assign(md4_present = df.MarkDown4.notnull())\ndf = df.assign(md5_present = df.MarkDown5.notnull())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"050a7853-86d7-4713-b336-456e2e216926","_uuid":"74c6dce0279cc94fe4ea748e6c9676908c94b431","trusted":false,"collapsed":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8aa23968-7b58-4cb2-a57f-0bcd2cf988aa","_uuid":"9f8d42ccef4c37705e8dc64fafb64e3a45104473"},"cell_type":"markdown","source":"We can probably safely fill all missing values with zero. For the markdowns this means that there was no markdown. For the weekly sales, the missing values are the ones we have to predict, so it does not really matter what we fill in there.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"690b5760-b2c9-4471-8355-fc9b3b0e0d73","collapsed":true,"_uuid":"5868b63dfc643d6d8015267c10c8105357de18fc","trusted":false},"cell_type":"code","source":"df.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ac690137-bb19-46b8-b75a-b1354222a161","collapsed":true,"_uuid":"57faefa432d4cd9d3624f9b5d2cd83c7be7af048","trusted":false},"cell_type":"code","source":"C = df.sort_values(by = ['Store', 'Dept', 'Date'])\nz = C['Weekly_Sales'].values\nPrev = [df['Weekly_Sales'].mean()]\nfor i in range(1,len(z)):\n    Prev.append((z[i-1]))\nfor j in range(len(Prev)):\n    if Prev[j] == 0:\n        Prev[j] = Prev[j-1]\nC = C.assign(Prev = np.array(Prev))\ndf = C","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8f665f9f-946a-43f5-af19-a138332e119f","_uuid":"2401b7681253b94de41c9cbbda369591cc68918e"},"cell_type":"markdown","source":"Now we have to create some dummy variebles for categorical data.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"75c044d2-4552-4371-91ce-563e8f2f305d","collapsed":true,"_uuid":"98780a9a5fe53e4944b96cc6417b3c23331fa6ce","trusted":false},"cell_type":"code","source":"# Make sure we can later recognize what a dummy once belonged to\ndf['Type'] = 'Type_' + df['Type'].map(str)\ndf['Store'] = 'Store_' + df['Store'].map(str)\ndf['Dept'] = 'Dept_' + df['Dept'].map(str)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"141ad9c1-1b6c-40b3-9286-200455fda866","collapsed":true,"_uuid":"c891ff438b9531dbdae3b87f954d22c13126eea3","trusted":false},"cell_type":"code","source":"# Create dummies\ntype_dummies = pd.get_dummies(df['Type'])\nstore_dummies = pd.get_dummies(df['Store'])\ndept_dummies = pd.get_dummies(df['Dept'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6b9b33b5-6511-4069-a1e2-8058494e30b3","collapsed":true,"_uuid":"5824ea5127d26b5174cabf1c33942e008e3d12b4","trusted":false},"cell_type":"code","source":"# Add dummies\ndf = pd.concat([df,type_dummies,store_dummies,dept_dummies],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"976808b7-58ae-4260-85c9-d8e4ec60cc2f","collapsed":true,"_uuid":"7a229ea27c65ad24f8a69699bff78337d0f71ad2","trusted":false},"cell_type":"code","source":"# Remove originals\ndel df['Type']\ndel df['Store']\ndel df['Dept']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f6ef1d7-0665-4640-867a-f012dd31bbc9","collapsed":true,"_uuid":"0437c0d644e4fee0ed4f481d2a06917ce625f5fa","trusted":false},"cell_type":"code","source":"del df['Date']\ndel df['CPI']\ndel df['Temperature']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ebd0dd53-c536-41e6-8b0f-782f331a4436","_uuid":"6603f9237bc92a302424b04b705ac84b90215865","trusted":false,"collapsed":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"90365e13-4a4a-4b92-916d-812d9017b6cd","_uuid":"2880be4b30dad2cef5c6d92d0cbefe1cf8dde843"},"cell_type":"markdown","source":"Now we can split train test again.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e5843e97-a2f0-499f-bb5a-f76b5892cf67","collapsed":true,"_uuid":"a8b39cd5493a5d870050f7138f67564d8a39e223","trusted":false},"cell_type":"code","source":"train = df[df['p'] == 1]\ntest = df[df['p'] == 0]\ndel train['p']\ndel test['p']\ntrain = train.sort_values(by = ['q'])\ntest = test.sort_values(by = ['q'])\ndel train['q']\ndel test['q']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"414ba742-c913-4f3f-8e14-71ce7e6fd306","collapsed":true,"_uuid":"be7ce247dc836e58a262eaa65829e78a8bb6ac97","trusted":false},"cell_type":"code","source":"test = test.drop('Weekly_Sales',axis=1) # We should remove the nonsense values from test","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bb38b96d-f8e3-4a69-94fc-6b6a2c4f60ac","_uuid":"4ba90bd3dced7bfd9fc47b7d7d2b87ba7f72da4f"},"cell_type":"markdown","source":"To get numpy arrays out of the pandas data frame, we can ask for a columns, or dataframes values","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ee4bd27f-60f9-451a-8800-8834a129ba68","collapsed":true,"_uuid":"d718d37849a08665b1a649c342b27b0115105ae2","trusted":false},"cell_type":"code","source":"y = train['Weekly_Sales'].values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2e24d360-2654-4993-ad4c-6a62c2581002","collapsed":true,"_uuid":"06c17700a046b415745a37bbbc524d722c64190b","trusted":false},"cell_type":"code","source":"X = train.drop('Weekly_Sales',axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"524b055d-3de8-478f-a528-cc45b81e5045","_uuid":"26234cecce0fa55ae2ad226e9c29c3d75ac73337","trusted":false,"collapsed":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5f50f352-76d3-4124-9847-c87a23f0bcda","_uuid":"dd252e577ea69f0d9e2d187c00db6150388860e0"},"cell_type":"markdown","source":"Now we create the baseline model","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"2432e904-f354-4d14-97e8-fd51482daa3a","collapsed":true,"_uuid":"e7f30cbfb0fdadcd71966f0bd9a21cbf8e6d97af","trusted":false},"cell_type":"code","source":"from keras.layers import Dense, Activation\nfrom keras.models import Sequential\nfrom keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0eeff49e-68ad-434e-b06c-046df7aaf712","collapsed":true,"_uuid":"6752c61ed7d3ef84d91aebfe9a47c157ba175b51","trusted":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(1,input_dim=144,activation ='relu',kernel_regularizer= regularizers.l2(0.01)))\nmodel.compile(optimizer='adam', loss='mae')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"12e9ffab-c3dd-442c-888e-a5d7da982b9a","_uuid":"4280365479f6fc50e491543fc140356911e84679","trusted":false,"collapsed":true},"cell_type":"code","source":"y[10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6bab5892-4ace-458d-801b-2174f72591a8","_uuid":"e963c74b6fdd90468b2ae237f5b58b3c6c5a97ed","trusted":false,"collapsed":true},"cell_type":"code","source":"model.fit(X,y,batch_size=2048,epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4b1a389-4e1a-4ef5-aad3-55e0993e043d","_uuid":"e3c30e44178c49e849d2bc10931a3cce1492b55b"},"cell_type":"markdown","source":"After we have created our model, we can predict things with it on the test set","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e185b5a8-c918-4505-8d4f-e47c3a54d061","_uuid":"42538025e79660158d40883542dd9f2879d2a9d9","trusted":false,"collapsed":true},"cell_type":"code","source":"model.evaluate(X,y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c906f7b-7abe-434c-aa8d-6c04fc0ecc91","collapsed":true,"_uuid":"4793684a0911883fe7016f854041bed0cd7df4d5","trusted":false},"cell_type":"code","source":"X_test = test.values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eb04360a-923d-445b-9969-5e1150d23b26","_uuid":"fb4467f37df6bd905db111edc61c9e0377a9e067","trusted":false,"collapsed":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bb76c5be-176d-460c-877c-d8db04c00815","collapsed":true,"_uuid":"0c6f1f23a472e6ea928911d0aed5b15c55e14f47","trusted":false},"cell_type":"code","source":"y_pred = model.predict(X_test,batch_size=2048)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d28662c3-e19b-41da-a2f9-aa6411782087","_uuid":"a7fef7d3802a6d78d3d93daf9611df245c26c4e2","trusted":false,"collapsed":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"077c5cfe-5454-4d49-b711-e117dd5f27a7","_uuid":"def1162bf32a3f7ae4bb2ac095f563cd3aa2faf7"},"cell_type":"markdown","source":"To create the ids required for the submission we need the original test file one more time","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"c263f137-bde8-4613-a893-afc01e090b22","collapsed":true,"_uuid":"61f90e8fbc75fd2d62b0546d4a7772a25f2799c3","trusted":false},"cell_type":"code","source":"testfile = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d70003ec-f330-426a-975a-6f965975971e","_uuid":"7c8c55cc85f67e658a6ec5a9f1725bef665212ee"},"cell_type":"markdown","source":"Now we create the submission. Once you run the kernel you can download the submission from its outputs and upload it to the Kaggle InClass competition page.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"876fa8f1-7b0a-4136-b5ae-d5a7e43bb468","collapsed":true,"_uuid":"f74aaf3d356cbf771e6a1c701831ac96a3b8a4d5","trusted":false},"cell_type":"code","source":"submission = pd.DataFrame({'id':testfile['Store'].map(str) + '_' + testfile['Dept'].map(str) + '_' + testfile['Date'].map(str),\n                          'Weekly_Sales':y_pred.flatten()})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f01c48ee-a1ae-4d95-94c9-f3e4ee1fd908","collapsed":true,"_uuid":"a5549a653482844d45f3812edf87050c08b82cde","trusted":false},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"20ddead0-935b-46bc-9925-3171cba85cea","collapsed":true,"_uuid":"ed0064926ffecd2c12f5c6917ce99a2508ee3832","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}