{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport seaborn as sns\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,f1_score,recall_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import  RobustScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/lt-vehicle-loan-default-prediction/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr= train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.set_index('UniqueID', inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr['loan_default'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/lt-vehicle-loan-default-prediction/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = test.set_index('UniqueID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Train data showing the default proportions where 0 denotes as non-default and 1 denotes as default\ntr.loan_default.value_counts().plot.bar()\nplt.xlabel('Default Proportion')\nplt.ylabel('customers')\nplt.title('number of clients')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Test data showing the employment info of the customers\n\nts['Employment.Type'].value_counts().plot.bar()\nplt.xlabel('Default Proportion')\nplt.ylabel('customers')\nplt.title('number of clients')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts['MobileNo_Avl_Flag'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Employment.Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts['Employment.Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.fillna('NAN',inplace=True)\nts.fillna('NAN',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr['Employment.Type'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts['Employment.Type'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus the missing values in train data is 3.28% and missing values in test data is 3.06% for the employment data. The data reflects that the details of the customers are not updated for income source type and these people can be at a high risk of default if they don't have an actual employment. Since we don't have any info regarding the employment type of these people and they constitute only small dataset, we can update the missing values as NAN and drop them to do further analysis and check if still we can get significant results"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating function for checking the correlation between variables\ndef correlationplot(data,width):\n    corr = data.corr()\n    plt.figure(num=None,figsize=(width, width), dpi=80, facecolor='w', edgecolor='black')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title('Correlation Matrix')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating function for checking the relation between variables using histogram\n\ndef histogramplot(data, no_of_rows):\n    nrow,ncol = data.shape\n    for i in range (ncol,no_of_rows):\n        plt.subplot(ncol,no_of_rows)\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.show()\n        \nhistogramplot(tr,8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_all_values():\n    df1=tr.drop('disbursed_amount',axis=1)\n    cols=tr.columns\n    for col in cols:\n        if (tr[col].dtypes !='object'):\n\n            fig1=plt.figure()\n            ax1=plt.axes()\n            plt.scatter(tr.disbursed_amount,tr[[col]],alpha=1)\n            plt.title('Comparison of features with disbursed amount')\n            ax1 = ax1.set(xlabel='disbursed_amount', ylabel=col)\n            plt.show()\n            \n            \nprint_all_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graphs are scatterplot to check the impact on different features w.r.t disbusred amount for train data. This helps majorly to check the category of disbursed_amount range which are more prone to default and the LTV on their respective loans."},{"metadata":{},"cell_type":"markdown","source":"###### checking the pattern of differnet varibales w.r.t uniqueID"},{"metadata":{"trusted":true},"cell_type":"code","source":"def hist_all_values():\n    df1=tr.drop('UniqueID',axis=1)\n    cols=tr.columns\n    for col in cols:\n        if (tr[col].dtypes !='object'):\n\n            fig1=plt.figure()\n            tr.hist(column=col,grid=True, figsize=(12,8),bins=40)\n            plt.title(col)\n            plt.ylabel('counts')\n            plt.xticks(rotation = 90)\n            plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n            plt.show()\n            \nhist_all_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The histograms above are created to visualize the basics of all feature in train data to know customers general background like if they are from  same county,have same LTV or already have loan default history , etc.."},{"metadata":{},"cell_type":"markdown","source":"#### Visualizing the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def print_test_values():\n    df1=ts.drop('disbursed_amount',axis=1)\n    cols=ts.columns\n    for col in cols:\n        if (ts[col].dtypes !='object'):\n\n            fig1=plt.figure()\n            ax1=plt.axes()\n            plt.scatter(ts.disbursed_amount,ts[[col]],alpha=1)\n            plt.title('comparision of disbusred amount vs other features')\n            ax1 = ax1.set(xlabel='disbursed_amount', ylabel=col)\n            plt.show()\n            \n            \nprint_test_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graphs are scatterplot to check the impact on different features w.r.t disbusred amount for test data. This helps majorly to check the category of disbursed_amount range which are more prone to default and the LTV on their respective loans."},{"metadata":{"trusted":true},"cell_type":"code","source":"def hist_test_values():\n    df1=ts.drop('UniqueID',axis=1)\n    cols=ts.columns\n    for col in cols:\n        if (ts[col].dtypes !='object'):\n\n            fig1=plt.figure()\n            ts.hist(column=col,grid=True, figsize=(12,8),bins=40)\n            plt.title(col)\n            plt.ylabel('counts')\n            plt.xticks(rotation = 90)\n            plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n            plt.show()\n            \nhist_test_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The histograms above are created to visualize the basics of all feature in test data to know customers general background like if they are from  same county,have same LTV or already have loan default history , etc.."},{"metadata":{},"cell_type":"markdown","source":"From the scatter plot and histogram we can easiy interpret that mostly the accounts which wre provided loan were around the november month of the year 2018 and still there are some deliquents accounts which means some have already made loan defaults.\n\nThe anomalies would be that te risk of loan default increases as the age of the person increases, but as per the data provide there are loan default by people with almost age group as young as born in year 1993.\n"},{"metadata":{},"cell_type":"markdown","source":"There is no way to compare the relatred quatities as the probability of default doesnot only remains on one of the factor but it varies as per the many factors acting as features for the profile."},{"metadata":{"trusted":true},"cell_type":"code","source":"correlationplot(tr,8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlationplot(ts,8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values are shown by the white lines."},{"metadata":{},"cell_type":"markdown","source":"From the above correlation matrix we can observe that the loan default is highly correlated with number of inquiries and number of overdue accounts."},{"metadata":{},"cell_type":"markdown","source":"Other question can be asked as the disbursed amount should also be related highly with the chance of loan default. Though it affects the chances but the correlation matrix cleraly depicts that the account with previous default history are risky and the loan should be provided to them with more caution."},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(tr.shape)\nprint(ts.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.boxplot(column='disbursed_amount', by='loan_default')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above boxplot refelcts that the major loan default are reported in the loan disbursed amount under $2,00,000"},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.boxplot(column='disbursed_amount', by='NO.OF_INQUIRIES')\nts.boxplot(column='disbursed_amount', by='NO.OF_INQUIRIES')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above boxplot graph is made to check the no. of inquries of customers for both test and train dataset"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"tr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a function to split the credit risk into risk grade and risk type\ndef credit_risk(tr):\n    d1=[]\n    d2=[]\n    for i in tr:\n        a = i.split(\"-\")\n        if len(a) == 1:\n            d1.append(a[0])\n            d2.append('unknown')\n        else:\n            d1.append(a[1])\n            d2.append(a[0])\n\n    return d1,d2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_number_of_ids(row):\n#     print(type(row), row.size)\n    return sum(row[['Aadhar_flag', 'PAN_flag', 'VoterID_flag', 'Driving_flag',\n       'Passport_flag']])\ndef check_pri_installment(row):\n    if row['PRIMARY.INSTAL.AMT']<=1:\n        return 0\n    else:\n        return row['PRIMARY.INSTAL.AMT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now converting the Score description into number rating from 0 to -5\n\nrisk_map = {'No Bureau History Available':-1, \n              'Not Scored: No Activity seen on the customer (Inactive)':-1,\n              'Not Scored: Sufficient History Not Available':-1,\n              'Not Scored: No Updates available in last 36 months':-1,\n              'Not Scored: Only a Guarantor':-1,\n              'Not Scored: More than 50 active Accounts found':-1,\n              'Not Scored: Not Enough Info available on the customer':-1,\n              'Very Low Risk':4,\n              'Low Risk':3,\n              'Medium Risk':2, \n              'High Risk':1,\n              'Very High Risk':0}\n\n#Have used the grading system in descending order because A is least risky and going forward risk increases\nsub_risk = {'unknown':-1, 'I':5, 'L':2, 'A':13, 'D':10, 'M':1, 'B':12, 'C':11, 'E':9, 'H':6, 'F':8, 'K':3,\n       'G':7, 'J':4}\n\n#Firstly converting the employment type to numbers:\n\nemployment_map = {'Self employed':0, 'Salaried':1, 'NAN':-1}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_engineering(df):\n    \n\n# Now converting the Date of birth of customers into the age and creating a new feature age:\n\n    df['Date.of.Birth'] = pd.to_datetime(df['Date.of.Birth'], format = \"%d-%m-%y\")\n    now = pd.Timestamp('now')\n    df['Age'] = (now - df['Date.of.Birth']).astype('<m8[Y]').astype(int)\n    age_mean = int(df[df['Age']>0]['Age'].mean())\n    df.loc[:,'age'] = df['Age'].apply(lambda x: x if x>0 else age_mean)\n\n# Now converting the Disbursal date of loan into no. of month passed from disbural month.\n\n    df['DisbursalDate'] = pd.to_datetime(df['DisbursalDate'], format = \"%d-%m-%y\")\n    df['disbursal_months_passed'] = ((now - df['DisbursalDate'])/np.timedelta64(1,'M')).astype(int)\n\n#Now converting AVERAGE.ACCT.AGE into number of months :\n    df['average_act_age_in_months'] = df['AVERAGE.ACCT.AGE'].apply(lambda x : int(re.findall(r'\\d+',x)[0])*12 + int(re.findall(r'\\d+',x)[1]))\n\n# Now Converting CREDIT.HISTORY.LENGTH into number of months:\n\n    df['credit_history_length_in_months'] = df['CREDIT.HISTORY.LENGTH'].apply(lambda x : int(re.findall(r'\\d+',x)[0])*12 + int(re.findall(r'\\d+',x)[1]))\n\n#adding a feature of number of zeroes present in a row so that we can count how many zeroes on row has\n\n    df['number_of_0'] = (df == 0).astype(int).sum(axis=1)\n    \n#creating additional column to split the PERFORM_CNS.SCORE.DESCRIPTION using credit risk function defined above\n\n    df.loc[:,'credit_risk'],df.loc[:,'credit_risk_grade']  = credit_risk(df[\"PERFORM_CNS.SCORE.DESCRIPTION\"])\n\n#adding loan to asset ratio to check which if the clients with default had suufficient assets to repay loan at time of disbursement\n\n    df.loc[:, 'loan_to_asset_ratio'] = df['disbursed_amount'] /df['asset_cost']\n\n#adding total number of accounts feature:\n\n    df.loc[:,'no_of_accts'] = df['PRI.NO.OF.ACCTS'] + df['SEC.NO.OF.ACCTS']\n\n#Now adding columns carrying total number of  various accounts including the primary and secondary and combing them in one\n\n    df.loc[:,'pri_inactive_accts'] = df['PRI.NO.OF.ACCTS'] - df['PRI.ACTIVE.ACCTS']\n    df.loc[:,'sec_inactive_accts'] = df['SEC.NO.OF.ACCTS'] - df['SEC.ACTIVE.ACCTS']\n    df.loc[:,'tot_inactive_accts'] = df['pri_inactive_accts'] + df['sec_inactive_accts']\n    df.loc[:,'tot_overdue_accts'] = df['PRI.OVERDUE.ACCTS'] + df['SEC.OVERDUE.ACCTS']\n    df.loc[:,'tot_current_balance'] = df['PRI.CURRENT.BALANCE'] + df['SEC.CURRENT.BALANCE']\n    df.loc[:,'tot_sanctioned_amount'] = df['PRI.SANCTIONED.AMOUNT'] + df['SEC.SANCTIONED.AMOUNT']\n    df.loc[:,'tot_disbursed_amount'] = df['PRI.DISBURSED.AMOUNT'] + df['SEC.DISBURSED.AMOUNT']\n    df.loc[:,'tot_installment'] = df['PRIMARY.INSTAL.AMT'] + df['SEC.INSTAL.AMT']\n    df.loc[:,'bal_disburse_ratio'] = np.round((1+df['tot_disbursed_amount'])/(1+df['tot_current_balance']),2)\n    df.loc[:,'pri_tenure'] = (df['PRI.DISBURSED.AMOUNT']/( df['PRIMARY.INSTAL.AMT']+1)).astype(int)\n    df.loc[:,'sec_tenure'] = (df['SEC.DISBURSED.AMOUNT']/(df['SEC.INSTAL.AMT']+1)).astype(int)\n    df.loc[:,'disburse_to_sactioned_ratio'] =  np.round((df['tot_disbursed_amount']+1)/(1+df['tot_sanctioned_amount']),2)\n    df.loc[:,'active_to_inactive_act_ratio'] =  np.round((df['no_of_accts']+1)/(1+df['tot_inactive_accts']),2)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding features for the credit risk and sub risk for which we have described numbers and grades above  \ndef label_data(df):\n    df.loc[:,'credit_risk_label'] = df['credit_risk'].apply(lambda x: risk_map[x])\n    df.loc[:,'sub_risk_label'] = df['credit_risk_grade'].apply(lambda x: sub_risk[x])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_correction(df):\n    #Many customers have invalid date of birth, so immute invalid data with mean age\n    df.loc[:,'PRI.CURRENT.BALANCE'] = df['PRI.CURRENT.BALANCE'].apply(lambda x: 0 if x<0 else x)\n    df.loc[:,'SEC.CURRENT.BALANCE'] = df['SEC.CURRENT.BALANCE'].apply(lambda x: 0 if x<0 else x)\n    df.loc[:,'employment_label'] = df['Employment.Type'].apply(lambda x: employment_map[x])\n\n    #loan that do not have current pricipal outstanding should have 0 primary installment\n    df.loc[:,'new_pri_installment']= df.apply(lambda x : check_pri_installment(x),axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_data(df):\n    df = data_correction(df)\n    df = features_engineering(df)\n    df = label_data(df)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = new_data(tr)\ntrain_data = train_data[train_data['number_of_0']<=25]\ntest_data = new_data(ts)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data['number_of_0']>=20]['number_of_0'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['disbursed_amount', 'asset_cost',\n            'Aadhar_flag', 'PAN_flag',\n       'PERFORM_CNS.SCORE',\n             'PRI.ACTIVE.ACCTS',\n       'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT',\n       'PRI.DISBURSED.AMOUNT',  'SEC.ACTIVE.ACCTS',\n       'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE', 'SEC.SANCTIONED.AMOUNT',\n       'SEC.DISBURSED.AMOUNT',  'SEC.INSTAL.AMT',\n       'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',\n            'NO.OF_INQUIRIES','disbursal_months_passed',\n       'average_act_age_in_months', 'credit_history_length_in_months',\n       'number_of_0','loan_to_asset_ratio', 'no_of_accts', 'pri_inactive_accts',\n       'sec_inactive_accts', 'tot_inactive_accts', 'tot_overdue_accts',\n       'tot_current_balance', 'tot_sanctioned_amount', 'tot_disbursed_amount',\n       'tot_installment', 'bal_disburse_ratio', 'pri_tenure', 'sec_tenure',\n       'credit_risk_label',\n       'employment_label', 'age', 'new_pri_installment'\n           ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# std_scaler = StandardScaler()\n# RobustScaler is less prone to outliers.\nrob_scaler = RobustScaler()\n\nscaled_training = train_data.copy()\nscaled_testing = test_data.copy()\n\n\nscaled_training[features] = rob_scaler.fit_transform(scaled_training[features])\nscaled_testing[features] = rob_scaler.fit_transform(scaled_testing[features])\n\ny = scaled_training.loan_default\nX = scaled_training[features]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# setting up testing and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27,stratify=y)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape,y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Testing\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_pre= rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, rfc_pre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, rfc_pre))\nprint(classification_report(y_test, rfc_pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=21, stratify=y)\nprint(X_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing Logistic Regression\nlogreg= LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thus as per the rfc the accuracy of the model is coming as 86% which is better than the accurcy of 78% coming from Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nrfc_pre_prob = rfc.predict_proba(X_test)[:,1]\nfpr, tpr , thresholds = roc_curve(y_test, rfc_pre_prob)\n\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label= 'Logistic Regression')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('RFC ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trying to use K fold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verifying the result of RFC using GridCVsearch \nfrom sklearn.model_selection import cross_val_score\ncv_results = cross_val_score(rfc,X,y,cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(cv_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Knn method\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(2)\nknn.fit(X_train,y_train)\ny_pred_knn= knn.predict(X_test)\nprint(confusion_matrix(y_test, y_pred_knn))\nprint(classification_report(y_test,y_pred_knn))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Thus rfc is better model to predict  the accuracy of the model which is coming to 85.27%"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":4}