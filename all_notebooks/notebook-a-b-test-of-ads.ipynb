{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#A/B Testing of Site Conversion Metrics Run in Python\n#Camilla Meek - Data Analyst\n\n\n#Introduction \nBest practices for optimizing website design and marketing calls to action will require testing of all the aspects of a website design in order to judge whether it meets your business KPI's or usability standards. The first step in A/B testing is to decide what to test. \n\nFor instance, of all the elements that combine to make a website deliver results for your business objectives, which element(s) are most important to driving the sales funnel from your campaign page? Is it the account sign-up feature? Then you definitely will want to test any buttons, forms, or directional graphics that direct users to create an account.\n\n\"In real life there are lots of things that influence whether someone clicks. For example, it may be that those on a mobile device are more likely to click on a certain size button, while those on desktop are drawn to a different size. This is where randomization can help — and is critical. By randomizing which users are in which group, you minimize the chances that other factors, like mobile versus desktop, will drive your results on average.\" Kaiser Fung, A Refresher on A/B Testing. Harvard Business Review, June 28, 2017\n\n#Business Case\n\nThis business case uses data from Kaggle.com pulled from an ad agency database which tracked a set of website visitors to a client’s site. The data tracked visitors that were served two different type of ads. Link to raw data, https://www.kaggle.com/osuolaleemmanuel. \n\nThe best tests for campaign or site optimization take a simple approach to testing. This allows a clear objective to be realized and avoids a tendency many researchers have to test for too many variables. \n\nThe question we are testing is simply put, “Does the exposed group click the Bio button at a higher rate than the control group?”\n\nOur goal is to determine whether either ad is more effective in driving customers to click a button to register with personal information. In this case, conversion is whether the site visitor clicks on a BIO button to register personal information.  We will use the test results to choose if the experimental ad has a higher conversion rate and use the more effective ad going forward. \n\nThe visitor data was collected over a period of a few weeks and gathered enough data to divide into two visitor groups. The two ads were served or shown to visitors in a completely random pattern, ensuring a good test case of randomized groups.\n\n\n\n#Research Questions & Hypotheses\n\nThe data contains a control group that used a static ad. Our tests will be against a second, interactive ad with a separate set of users. In this case conversion is whether the site visitor served the experimental ad clicks on a button to register or offer personal information (called the bio button in the test).\n\n1) Is there a significant difference in the conversion rate of the control and test groups' response to the ads each was served?\n\n\n2) Is there a significant difference in the conversion rate of the control and test groups' total responses to the ads each was served? In this test we've added both the conversions and the choice of 'no' to the conversion, i.e. \"I do not wish to give my personal information/register.\"\n*   Ho: p1 - p2 = 0\n*   Ha: p1 - p2 ≠ \n\nHo = There is no significant difference between the two ad groups in the conversion rate (clicking yes to the bio button).\nHa = Alternative Hypothesis Hₐ: µ₁ - µ₂ ≠ 0  \"There is a significant difference between the conversion rate of the two groups\"\n\nFor this test we will use the z test rather than a t test. The z test is used for testing proportions of a sample, in this case the conversion rate. A t test is used for testing and comparing the means of two groups.\n","metadata":{"id":"b0MCsXszXmZw"}},{"cell_type":"code","source":"!pip install --upgrade -q gspread\n!pip install bokeh","metadata":{"id":"Wugm2pDe1YbK","outputId":"6a0a7b7c-a197-4686-a15e-fcf609eaedaf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the csv comes from kaggle, https://www.kaggle.com/osuolaleemmanuel/ad-ab-testing\nfrom google.colab import drive\ndrive.mount('/content/gdrive')","metadata":{"id":"LkgyUuYtzjTD","outputId":"0b45248f-a762-406b-f70c-5f425f74bb74"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sqlalchemy import create_engine\n\n!pip install sqlalchemy\n!pip install psycopg2\n!pip install psycopg2-binary\n\nfrom scipy import stats\nfrom scipy.stats import chi2_contingency\n\nimport seaborn as sns \nsns.set()","metadata":{"id":"If3Ti5qx58FG","outputId":"567cf784-0dd3-4a7d-c67a-5b46e200396b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"id":"0t3dCJ6L6Yfd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra","metadata":{"id":"cX76mFAU6coF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import the datafile from drive\n\nimport pandas as pd\n\ndf = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/ab_data.csv')","metadata":{"id":"5Qd_g4l46heU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Import, review, and clean data\n","metadata":{"id":"m76lqhJqXyG_"}},{"cell_type":"code","source":"#data comes from kaggle csv. get array info. There are no null values in the array. \ninfo_df = df.info()\nprint(info_df)","metadata":{"id":"a1lrH-YN6_rk","outputId":"5ac4b5ac-5010-4b3d-8908-9669024f6989"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The array is 8077 rows with 8 columns (see below for detail). That gives us a large enough sample for z testing to be conclusive. ","metadata":{"id":"B8K1MrhGXlQa"}},{"cell_type":"markdown","source":"# Data column descriptions \nOur array is includes information about each unique visit to the site and which group they are in, a control group or exposed group (experiment ad).\n\nauction_id: the unique id of the online user\n\n\nexperiment: which group the user belongs to - control or exposed.\ncontrol: users who have been shown a dummy ad\nexposed: users who have been shown an interactive ad with a SmartAd brand\n\ndate: the date in YYYY-MM-DD format\n\nhour: the hour of the day in HH format\n\ndevice_make: the name of the type of device used\n\nplatform_os : the id of the OS used\n\nbrowser: browser used\n\nyes: 1 if the user chooses the “Yes” radio button for the BIO questionnaire.\n\nno: 1 if the user chooses the “No” radio button for the BIO questionnaire.","metadata":{"id":"gCjGlY_JVcxr"}},{"cell_type":"code","source":"#View the top five rows of data and column names. \n\ndf.head()","metadata":{"id":"ANt-3Kym7Qu0","outputId":"e755a20c-632c-4279-8e80-0aceba250c28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Check for any null values and print it out. There are no nulls in the set.\nnull_df = df.isna().sum()\nprint(null_df)","metadata":{"id":"LH3BJljA7Wt-","outputId":"6d558193-d7e3-4de1-999b-2ac69d176e85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create the pandas DataFrame\ndf1 = df[['experiment','yes']]\n  \n# print\ndf1.head()","metadata":{"id":"J9zQoErN64Ur","outputId":"91c7b98c-a033-4066-862e-9002ebd6514f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating dfs for each group\ndf_control = df[df.experiment =='control']\ndf_exposed = df[df.experiment =='exposed']\n#now let's see how the two groups of users compare","metadata":{"id":"_nar08C39fT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run ds on the control group\ndf_control.describe()","metadata":{"id":"T2yryg8BvqrP","outputId":"196bc936-e64e-4522-a827-0ecc817685b7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run ds on the exposed group\ndf_exposed.describe()","metadata":{"id":"PYcWLq7EvyoB","outputId":"05abcedd-309d-4823-dfde-4e6deda0c11f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The two samples appear to be similar in size and distribution. The mean of the yes and no of each group is approx the same so it's fair to say that we have a good set of data for the z or t-test. But our test will be run on a proportion of a population rather than the mean so we'll use the z test for our two tests of response to web ads.\n","metadata":{"id":"qRwbXYeMEorc"}},{"cell_type":"markdown","source":"#Data Visualizations\n\nVisualizations are the best way to illustrate features of our data set. Here we compare the randomized control and exposed group of users.\n\nIn figure 1 the two groups' size are compared side by side. The size of the control and exposed group are approximately the same.\n\nIn figure 2 the exposed group total and its actual conversions are shown side by side.","metadata":{"id":"Y-MjjE5q6Cst"}},{"cell_type":"code","source":"#Figure 1 - visualize the control and exposed groups\nsns.set(rc={'figure.figsize':(10,5)})\nsns.countplot(x='experiment', data=df)\nplt.title('Count of Users per Group')\nplt.show()\nplt.close()\n#they are approx same size","metadata":{"id":"to5L_Nwb653d","outputId":"8399e5ab-059e-480a-b7e5-b666d3753caa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Figure 2\n#visualize the total exposed group (experimental ad) and the conversions (clicked yes)\nsns.set(rc={'figure.figsize':(10, 5)})\nsns.countplot(x='yes', data=df_exposed)\nplt.title('Total Exposed and Conversions')\nplt.show()\nplt.close()","metadata":{"id":"XWYI9fLPEX3t","outputId":"176937b0-74a9-42a1-b801-261b5c8cc6cd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A way to illustrate the responses in each group is by using a density distribution. In the two figures below we see the range of responses by group.\n\nResponses choosing yes or no to the BIO button count are counted as 1 response. No response = 0. \n\nBoth distributions show that the greatest majority of both the control and exposed groups did not respond. Both figure 2 above and the two plots below show that we're dealing with a very small proportion of visitors who chose either a yes or no button click on the site. Although our array of over 7000 site visits is large, the portion that we can run our test with is very small in comparison. That's important to keep in mind in case we to run future tests. We may need to run tests longer to accumulate a signficantly large conversion set.","metadata":{"id":"f1wyYt_UAiEG"}},{"cell_type":"code","source":"#let's plot the distribution of the total responses (yes and no) in the exposed group \nfig = plt.figure(figsize=(8, 6))\nsns.distplot(df2_exposed['total'], hist=False, kde_kws={\"shade\": True})\n\n","metadata":{"id":"K6JLI7rFY55f","outputId":"b74a518d-2423-43dd-f257-95225a62769b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's plot the distribution of the total responses (yes and no) in the control group \nfig = plt.figure(figsize=(8, 6))\nsns.distplot(df2_control['total'], hist=False, kde_kws={\"shade\": True})\n","metadata":{"id":"WFbw6YEO3RsU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's very little difference in the distribution of the two groups; although there are somewhat fewer responses (yes or no) in the exposed group. That's a rough visual confirmation that there isn't a big difference in our two groups' responses. Will our z test confirm this?","metadata":{"id":"3-mhpmntRqdj"}},{"cell_type":"markdown","source":"# Hypothesis Testing\n\n\nLet's run the z-test for the test between the control and exposed group that converted (clicked the Yes button) in response to two different ads.\n\n\n*   Ho: p1 - p2 = 0\n*   Ha: p1 - p2 ≠ \n\nThe null hypothesis is that there is no significant difference between the two ad groups in the conversion rate.\nAlternative Hypothesis Hₐ: µ₁ - µ₂ ≠ 0  \"There is a significant difference between the conversion rate of the two groups\"\n\nConfidence Level: (p=0.05)\n\nIf p-value significant result, reject null.\nIf p-value > .05 accept alternate.\n\np and pₒ stand for the difference in the control and exposed groups, we set the confidence level at 95%.\n\n","metadata":{"id":"LVt5mcWyc6oz"}},{"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsm.stats.ztest(x1=df_control['yes'], x2=df_exposed['yes'])","metadata":{"id":"rsLVszHmJwz3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The p value is 0.03, so we can reject the null. There is a significant difference in the two groups' reponse. \n\n\nFor the second z test, we're going to test the TOTAL response rate (or proportion) of the exposed to the control group. The response includes both yes and no repsonses in each group. Remember, there are three possible responses, clicking yes, clicking no, or no response at all. A click of the yes or no response button is counted as a 1 in the data set, and no response is recorded as a 0. This will tell us if there was any significant difference in the two ad groups in the sum of responses. \n\nThe new column for the sum of responses is below created is called 'total'.","metadata":{"id":"s5k69RpWUGQ4"}},{"cell_type":"code","source":"#create a new column called total, sum of yes and no columns\ndf['total']= df['yes'] + df['no']\ndf.head()\n","metadata":{"id":"9N5uk30J-n8L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2_control = df[df.experiment =='control'] \ndf2_exposed = df[df.experiment =='exposed']","metadata":{"id":"J3eeWoQhAS2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf\nsm.stats.ztest(x1=df2_control['total'], x2=df2_exposed['total'])","metadata":{"id":"Lf0wLIKSjKls"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, our test shows a p value of less than 0.05 so we can reject the null and accept the alternate. There is a significant difference in the percentage or proportion of the site visitor responses between the two groups.\n\n#Conclusion\nUsing this adequately large data array sorted into control and exposed groups, we find a significant difference in the two groups responses; both in the conversion rate and in the total responsiveness of the groups based on the ads they were served. The control and exposed groups appear to be randomly dispersed across all recorded metrics so the elements of our hypothesis testing had a solid basis for accurate testing. \n\nFurther, the second z test showed that the experimental ad made a significant difference in selecting the no button as compared to the control group.\n\nFollowing this analysis using independent sample z- tests, we must conclude that the experiment ad did affect the conversion rate or signficantly change the overall response (yes, no, or no response) to that of the control group.\n\nA future test of a new ad could be set up. Or, the current array could be tested in one of the other metrics, such as browser or device used when visiting the site to see whether another factor influenced conversion or response rates. A/B testing is an ongoing process in site and campaign optimization and this completed analysis provides a model for future testing.\n\nThank you for your interest.\n","metadata":{"id":"cZOhjKw5XATE"}}]}