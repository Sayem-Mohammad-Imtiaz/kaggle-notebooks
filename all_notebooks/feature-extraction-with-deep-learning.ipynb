{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31ca96ee-558e-bab3-6626-852ac24f2916"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\ndata = pd.read_csv(\"../input/data.csv\",header=0)\ndata.drop(\"Unnamed: 32\",axis=1,inplace=True)\ndata.drop(\"id\",axis=1,inplace=True)\n\ndata.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86ab7768-64a2-1981-4fe6-023ea68e080d"},"outputs":[],"source":"from sklearn.model_selection import train_test_split \ntrain, test = train_test_split(data, test_size = 0.3)\n\nprediction_var = list(data.columns[1:31])\noutcome_var = \"diagnosis\"\n\ntrain_X = train[prediction_var]# taking the training data input\ntrain_y = train.diagnosis# This is output of our training data\n# same we have to do for test\ntest_X = test[prediction_var] # taking test data inputs\ntest_y = test.diagnosis   #output value of test dat\n\ntrain_X.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ba144e5-c9f6-3efe-79d7-76db25503c4c"},"outputs":[],"source":"import matplotlib.pyplot as plt\nn_train = np.array(train_X)\nn_test = np.array(test_X)\n\nplt.plot(n_train)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7dc6983-a69f-e095-0952-d31b90563e68"},"outputs":[],"source":"from keras.layers import Input, Dense\nfrom keras.models import Model\nimport tensorflow as tf\n\ninput_dim = n_train.shape[1]\nfeature_dim = [25, 20, 15, 10]\nprint(input_dim)\ninputs = Input(shape=(input_dim,))\nencoded = inputs\nencoded = Dense(feature_dim[0], kernel_initializer=\"uniform\")(encoded)\nencoded = Dense(feature_dim[1], kernel_initializer=\"uniform\")(encoded)\nencoded = Dense(feature_dim[2], kernel_initializer=\"uniform\")(encoded)\nencoded = Dense(feature_dim[3], kernel_initializer=\"uniform\")(encoded)\n\ndecoded = encoded\ndecoded = Dense(feature_dim[2], kernel_initializer=\"uniform\")(decoded)\ndecoded = Dense(feature_dim[1], kernel_initializer=\"uniform\")(decoded)\ndecoded = Dense(feature_dim[0], kernel_initializer=\"uniform\")(decoded)\ndecoded = Dense(input_dim, kernel_initializer=\"uniform\")(decoded)\n\n\nautoencoder = Model(inputs, decoded)\nautoencoder.compile(optimizer='adadelta', loss='mse')\n\nautoencoder.fit(n_train, n_train,\n                verbose=0,\n                epochs=150,\n                batch_size=100,\n                shuffle=True,\n                validation_data=(n_test, n_test))\n\npredict_vals = autoencoder.predict(n_train)\nprint(predict_vals.shape)\nplt.plot(predict_vals)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fcb3f0f4-7e0f-6fb3-8c1b-07f8327a9c96"},"outputs":[],"source":"from keras.models import Sequential\n\nfeaturemodel = Sequential()\nfeaturemodel.add(Dense(feature_dim[0], input_shape=(input_dim,), weights=autoencoder.layers[1].get_weights()))\nfeaturemodel.add(Dense(feature_dim[1], weights=autoencoder.layers[2].get_weights()))\nfeaturemodel.add(Dense(feature_dim[2], weights=autoencoder.layers[3].get_weights()))\nfeaturemodel.add(Dense(feature_dim[3], weights=autoencoder.layers[4].get_weights()))\n\nfeaturemodel.compile(optimizer='adadelta', loss='mse')\n\nfrom sklearn import svm # for Support Vector Machine\nfrom sklearn import metrics # for the check the error and accuracy of the model\n\n# classic svm\nmodel = svm.SVC()\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint(\"Accuracy svm: %s\" % \"{0:.3%}\".format(metrics.accuracy_score(prediction, test_y)))\n\n# classic svm with deep autoencoder\ndeepmodel = svm.SVC()\ndeepmodel.fit(featuremodel.predict(n_train),train_y)\ndeepprediction=deepmodel.predict(featuremodel.predict(n_test))\nprint(\"Accuracy d-svm: %s\" % \"{0:.3%}\".format(metrics.accuracy_score(deepprediction, test_y)))\n\n# linear svm\nmodel = svm.SVC(kernel='linear')\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint(\"Accuracy lsvm: %s\" % \"{0:.3%}\".format(metrics.accuracy_score(prediction, test_y)))\n\n# linear svm with deep autoencoder\ndeepmodel = svm.SVC(kernel='linear')\ndeepmodel.fit(featuremodel.predict(n_train),train_y)\ndeepprediction=deepmodel.predict(featuremodel.predict(n_test))\nprint(\"Accuracy d-lsvm: %s\" % \"{0:.3%}\".format(metrics.accuracy_score(deepprediction, test_y)))\n\n\n########################\nfrom sklearn.neighbors import KNeighborsClassifier\nprint(\"----------\")\n\n# classic knn\nmodel = KNeighborsClassifier()\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint(\"Accuracy knn: %s\" % \"{0:.3%}\".format(metrics.accuracy_score(prediction, test_y)))\n\n# classic knn with deep autoencoder\ndeepmodel = KNeighborsClassifier()\ndeepmodel.fit(featuremodel.predict(n_train),train_y)\ndeepprediction=deepmodel.predict(featuremodel.predict(n_test))\nprint(\"Accuracy d-nn: %s\" % \"{0:.3%}\".format(metrics.accuracy_score(deepprediction, test_y)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3f861f9-51b8-481c-da41-5b424ef2662a"},"outputs":[],"source":"from sklearn.model_selection  import KFold\ndef classification_model(model,data,prediction_input,output):\n    model.fit(data[prediction_input],data[output])\n    predictions = model.predict(data[prediction_input])\n    accuracy = metrics.accuracy_score(predictions,data[output])\n    print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n    \n    kf = KFold(n_splits=5)\n    error = []\n    for train, test in kf.split(data):\n        train_X = (data[prediction_input].iloc[train,:])\n        train_y = data[output].iloc[train]\n        model.fit(train_X, train_y)\n        test_X=data[prediction_input].iloc[test,:]\n        test_y=data[output].iloc[test]\n        error.append(model.score(test_X,test_y))\n        print(\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8c9c9fa-d719-cc27-d928-225e10562963"},"outputs":[],"source":"model = svm.SVC()\nclassification_model(model,data,prediction_var,outcome_var)\n\n# all data\nnp_data = np.array(data[prediction_var])\nnp_out = np.array(data[outcome_var])\ndata_prediction = featuremodel.predict(np_data)\n\n\n# svm\nmodel = svm.SVC()\ndeepmodel.fit(data_prediction,np_out)\ndeepprediction=deepmodel.predict(data_prediction)\nprint(\"Accuracy : %s\" % \"{0:.3%}\".format(metrics.accuracy_score(deepprediction, np_out)))\n\n# kfold\nkf = KFold(n_splits=5)\nerror = []\nfor train, test in kf.split(data):\n    tr_X = (data_prediction[train,:])\n    tr_y = np_out[train]\n    model.fit(tr_X, tr_y)\n    te_x=data_prediction[test,:]\n    te_y=np_out[test]\n    error.append(model.score(te_x,te_y))\n    print(\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}