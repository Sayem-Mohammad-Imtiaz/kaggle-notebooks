{"cells":[{"metadata":{"_uuid":"433d4d6cbc0b69bc58812e3f48fc485e85dac7e9"},"cell_type":"markdown","source":"# References \n* [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n* [Matplotlib Gallery](https://matplotlib.org/gallery/index.html)"},{"metadata":{"_uuid":"335140ee2e31402a1cecd0466b7482533650ffea"},"cell_type":"markdown","source":"# Content\n* Compress the 4 features of Iris Dataset to 2 features using Autoencoder\n* Visualize training using TensorBoard\n* Plot the obtained 2 features and assign different colors to different species"},{"metadata":{"trusted":true,"_uuid":"e454fe84a2fe6707fdf1c0ad6a1fff778b6f8332"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b279869ee8f62abf45302ee5bc70843100ecd12"},"cell_type":"markdown","source":"## Importing Data"},{"metadata":{"trusted":true,"_uuid":"3dccc906b3643ffbbd169679c9601ab673c5ba33"},"cell_type":"code","source":"data = pd.read_csv(\"../input/Iris.csv\")\nx_train, x_test, y_train, y_test = train_test_split(data[['SepalLengthCm', 'SepalWidthCm',\n                                                          'PetalLengthCm', 'PetalWidthCm']],\n                                                    data['Species'],test_size=0.1, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81611a8e12dae66ddecdd76e2501a4a0fe4b0f87"},"cell_type":"markdown","source":"## Launching TensorBoard"},{"metadata":{"trusted":true,"_uuid":"164cf2d7edb504f490c0076318edab661edd2070"},"cell_type":"code","source":"!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = '/tmp/autoencoder' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 6006 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"259eb70c735aa726dc95259456eec00e53b1b189"},"cell_type":"markdown","source":"## Linear Encoder and Linear Decoder"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.callbacks import TensorBoard\n\n# this is the size of our encoded representations\nencoding_dim = 2\ninput_dim = 4\n\n# this is our input placeholder\ninput_img = Input(shape=(input_dim,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim)(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(input_dim)(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)\n\n# this model maps an input to its encoded representation\nencoder = Model(input_img, encoded)\n\n# create a placeholder for an encoded (2-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\n\nautoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n\nautoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=135,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\n# encode and decode some data points\n# note that we take them from the *test* set\nencoded_datapoints = encoder.predict(x_test)\ndecoded_datapoints = decoder.predict(encoded_datapoints)\n\nprint('Original Datapoints :')\nprint(x_test)\nprint('Reconstructed Datapoints :')\nprint(decoded_datapoints)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc7de62fc50a1225f87142beb03561fb47b1436a"},"cell_type":"markdown","source":"## Plotting Encoded Features"},{"metadata":{"trusted":true,"_uuid":"7398436f682db4ea45f63effb3b4a481d22cd588"},"cell_type":"code","source":"encoded_dataset = encoder.predict(data[['SepalLengthCm', 'SepalWidthCm','PetalLengthCm', 'PetalWidthCm']])\n\nplt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=data['Species'].astype('category').cat.codes)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}