{"nbformat_minor":1,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"file_extension":".py","name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","version":"3.6.3","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"}}},"cells":[{"metadata":{"_uuid":"089d93abd982fdb7d2bc86f1d6aa8424f455c6c8","_cell_guid":"d51b3d6c-7315-4233-a322-eff979552394"},"source":"# Improved Salary Accuracy Prediction with Smart Missing Value Filling\n\nPeople really like to talk about the things that we, as an intellectual tradition, have nailed down. Linear regressions on normally-distributed predictive and response variables? We can write entire textbooks on that. But there are many important topics that get far less attention, despite being far more common. Dealing with missing values is a perfect example, and I will try to remedy the sitaution below.\n\nProper handling of missing values is actually a huge competitive advantage. Most people just use Scikit-Learn's Imputer object (or 'MISSING' as a category)  and move on without a second thought. But when the margins of victory are razor thin, and 10-40% of your data is missing, it's worth stepping back from the obsessive parameter tweaking and see if you can address the root of the problem.\n\nInspiration for most of these approaches goes to [Andrew Gelman](http://www.stat.columbia.edu/~gelman/arm/missing.pdf)","cell_type":"markdown"},{"execution_count":null,"metadata":{"_uuid":"fb8252c4880bb0545e364ad7c3c96779be2a172b","collapsed":true,"scrolled":true,"_cell_guid":"d0b82584-f69c-447b-9b25-8fd8c96176cd"},"outputs":[],"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom sklearn.linear_model import LinearRegression\n\nraw_mcr = pd.read_csv('../input/multipleChoiceResponses.csv',encoding=\"ISO-8859-1\", low_memory=False)\nprint(raw_mcr.shape)\nraw_mcr.head().T"},{"execution_count":null,"metadata":{"_uuid":"aca674191d370af57a717045205cbf249447ee32","collapsed":true,"_cell_guid":"8ef25079-eb65-4f8b-b05e-5ff3e0fab775"},"outputs":[],"cell_type":"code","source":"print(\"CompensationAmount will be our target column (filtering to dollars for simplicity)\")\nraw_mcr.columns[raw_mcr.columns.str.contains('compensation', flags=re.IGNORECASE)]"},{"execution_count":null,"metadata":{"_uuid":"6e1e3779ed7aacbc2d1b323f96f330ed840aa83a","collapsed":true,"_cell_guid":"1c83d1f5-1dd3-4942-bb8d-aade698ea32b"},"outputs":[],"cell_type":"code","source":"print(\"If you filter for 70%+ non-null columns, you lose most of your data already\")\nmcr = raw_mcr[raw_mcr.CompensationCurrency == 'USD'].copy()\nprint(\"Shape before filter: {}\".format(mcr.shape))\nmcr = mcr.loc[:, mcr.isnull().mean() < .7]\nassert (mcr.columns == ('CompensationAmount')).any()\nmcr['CompensationAmount'] = pd.to_numeric(mcr['CompensationAmount'].str.replace(r'\\D',''))\nprint(\"Shape after filter: {}\".format(mcr.shape))"},{"execution_count":null,"metadata":{"_uuid":"ae744a2c48ac587e6a3df7002332567424829984","collapsed":true,"_cell_guid":"b130c5f2-d4d6-40a1-b9c2-84981ea1032a"},"outputs":[],"cell_type":"code","source":"print(\"Even for that small subset of columns,\"\n      \" if you drop rows with any nulls you are left with ZERO data\")\nprint(\"Original shape: {}\".format(mcr.shape))\nprint(\"Shape if nulls dropped across all columns: {}\".format(mcr.dropna(axis=0).shape))"},{"execution_count":null,"metadata":{"_uuid":"df30ee6b75308b6ed410f33bb51267c29b63f4fe","collapsed":true,"_cell_guid":"f2b364c6-a1a6-4a78-9849-9483757dbbb8"},"outputs":[],"cell_type":"code","source":"print(\"For simplicity, we'll focus on predictions using the 'Time Spent' columns,\"\n      \" like 'TimeGatheringData'. Using just this one variable won't give great\"\n      \" predictions, but it will be a good example of the topic\")"},{"metadata":{"_uuid":"f3c59828afb5e1ff0a7e913b086ba68f560bb06b","_cell_guid":"2bb25ab6-1306-45d4-9639-c4936482da06"},"source":"## Imputation Methods","cell_type":"markdown"},{"execution_count":null,"metadata":{"_uuid":"6092c19aff12ca8a7b2bce67a487d2bbfce709c1","collapsed":true,"_cell_guid":"b03d4fbb-51ae-4836-b268-b38f5168fd76"},"outputs":[],"cell_type":"code","source":"def simple_plot(y_pred, y_all):\n    plt.scatter(y_pred, y_all, s=.2, alpha=.2)\n    plt.plot([.75e5, 1.5e5], [.75e5, 1.5e5], linestyle='--', c='k', alpha=.25)\n    ax = plt.gca()\n    f = plt.gcf()\n    f.set_figheight(5)\n    f.set_figwidth(7)\n    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, pos: ('${:0,.0f}').format(y)))\n    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda y, pos: ('${:0,.0f}').format(y)))\n    ax.set_xlim(0, 2e5)\n    ax.set_ylim(0, 2e5)\n    ax.set_title(\"Relationship between Predicted and actual Salary (Full Data)\");\n    ax.set_xlabel(\"Salary (Predicted)\");\n    ax.set_ylabel(\"Salary (Actual)\");\n    return ax"},{"execution_count":null,"metadata":{"_uuid":"28a739a781df6874e63a85affde7fd559364e308","collapsed":true,"_cell_guid":"01b871b6-8fb0-47dc-9079-ef1a68ff79b5"},"outputs":[],"cell_type":"code","source":"print(\"Because none of the Time data is null, we can get a perfect picture of how good it should be\"\n      \" as a predictor of salary. It's pretty terrible, but works as an example.\")\nfiltered_data = mcr[['TimeGatheringData', 'TimeModelBuilding', 'TimeProduction', 'TimeVisualizing', 'CompensationAmount']].dropna(axis=0, how='any')\nlr_all = LinearRegression()\nX_all = filtered_data[['TimeGatheringData']].values\ny_all = filtered_data['CompensationAmount'].values\nlr_all.fit(X_all, y_all)\ny_pred = lr_all.predict(X_all)\n\nax = simple_plot(y_pred, y_all);"},{"execution_count":null,"metadata":{"_uuid":"e4bc78f1c127af931879d30833efefeffd89686d","collapsed":true,"_cell_guid":"83256721-e46a-4d0c-98e5-61cc43b322fb"},"outputs":[],"cell_type":"code","source":"print(\"Now let's introduce some missing values randomly, and try to fix them\")\nprint(\"If you just impute the mean like normal, you get a weird cluster of data\")\n\n# Creating the nulls\nwith_nulls = filtered_data.copy()\nwith_nulls.loc[np.random.choice(with_nulls.index, size=int(with_nulls.index.size/3)), \n              'TimeGatheringData'] = np.nan\n\n# Fixing the nulls\nwith_nulls['TimeGatheringData'] = with_nulls['TimeGatheringData'].fillna(\n                                  with_nulls['TimeGatheringData'].mean())\n\n\nax = with_nulls['TimeGatheringData'].hist()\nax.set_title(\"Histogram of Time Gathering Data Values\");\nax.set_xlabel(\"Time Gathering Data (Value)\");\nax.set_ylabel(\"Number of data points\");"},{"execution_count":null,"metadata":{"_uuid":"ce58f3c1ac7f9e3860438fbff80eb6e64230a83f","collapsed":true,"_cell_guid":"72023759-2341-4421-9fff-9cf63822eb13"},"outputs":[],"cell_type":"code","source":"print(\"The prediction is now even more wrong, and the tight range of predicted values could give\"\n      \" the impression of better accuracy than you have\")\nlr_all = LinearRegression()\nX_all = with_nulls[['TimeGatheringData']].values\ny_all = with_nulls['CompensationAmount'].values\nlr_all.fit(X_all, y_all)\ny_pred = lr_all.predict(X_all)\nsimple_plot(y_pred, y_all);"},{"metadata":{"_uuid":"c6249de17afe407cf4fb00f3b4135d8f8ad223d4","_cell_guid":"c4160591-80c7-4008-8540-fdb75a2a0305"},"source":"## Bootstrapping","cell_type":"markdown"},{"execution_count":null,"metadata":{"_uuid":"0c50d9a20ea84ffe728668b98eb21c1875dac171","collapsed":true,"_cell_guid":"4f15c54b-ef60-49bb-8ba3-b867fa27e7c9"},"outputs":[],"cell_type":"code","source":"print(\"If you just bootstrap, at least you don't get that same cluster\")\n\n# Creating the nulls\nwith_nulls = filtered_data.copy()\nwith_nulls.loc[np.random.choice(with_nulls.index, size=int(with_nulls.index.size/3)), \n              'TimeGatheringData'] = np.nan\n\n# Fixing the nulls\nnull_ix = with_nulls.loc[:, 'TimeGatheringData'][lambda x: np.isnan(x)].index\nnotnull_ix = with_nulls.index.difference(null_ix)\nwith_nulls.loc[null_ix, 'TimeGatheringData'] = np.random.choice(\n                                                with_nulls.loc[notnull_ix, 'TimeGatheringData'],\n                                                size = len(null_ix),\n                                                replace=True)\n\n\nwith_nulls['TimeGatheringData'].hist();"},{"execution_count":null,"metadata":{"_uuid":"990f6040dd3cb1c506153e151ca1156b3c17856c","collapsed":true,"_cell_guid":"4b35bbba-7254-467f-81d9-b923f6ed4368"},"outputs":[],"cell_type":"code","source":"print(\"Now the prediction looks roughly like the prediction with full data.\")\nlr_all = LinearRegression()\nX_all = with_nulls[['TimeGatheringData']].values\ny_all = with_nulls['CompensationAmount'].values\nlr_all.fit(X_all, y_all)\ny_pred = lr_all.predict(X_all)\nsimple_plot(y_pred, y_all)"},{"metadata":{"_uuid":"958a136362ed1ffd8dc6eef6bc0d7d99090b8ef7","collapsed":true,"_cell_guid":"21327d72-4691-4d46-b5eb-3108af678dec"},"source":"## Iterative Regression","cell_type":"markdown"},{"execution_count":null,"metadata":{"_uuid":"d3cf48a18bece2aac4c345d58e1e37e618107d68","collapsed":true,"_cell_guid":"95fdd362-fb50-4d9e-bc27-4b88ca8b93b6"},"outputs":[],"cell_type":"code","source":"\"\"\" Iterative regression imputation\"\"\"\nprint(\"A more advanced technique is to iteratively fit the data with linear regressions\"\n     \" The disadvantage here is that the values will be drawn towards the mean, as the\"\n     \" linear regression doesn't capture all of the variance of the original data.\")\n\n\n# Creating the nulls, now across all columns\nwith_nulls = filtered_data.copy()\nnullcnt = int(filtered_data.index.size/3)\nfor col in filtered_data.columns:\n    if col == 'CompensationAmount': continue\n    null_ix = np.random.choice(with_nulls.index, size=nullcnt)\n    with_nulls.loc[null_ix, col] = np.nan\n\n# Fix nulls\ndef fill_with_mean(col):\n    return col.fillna(col.mean())\n\ndef fill_with_resample(col):\n    col.loc[col.isnull()] = np.random.choice(col.loc[col.notnull()].values, size=col.isnull().sum())\n    return col\n\nnull_mask = with_nulls.isnull()\nwith_nulls.apply(fill_with_resample)\nall_x_cols = filtered_data.columns.difference(['CompensationAmount'])\nfor i in range(10):\n    for col in filtered_data.columns:\n        lr = LinearRegression()\n        y_col = filtered_data[col]\n        x_col = filtered_data[all_x_cols.difference([col])]\n        col_pred = lr.fit(x_col, y_col).predict(x_col)\n        filtered_data.loc[:, col] = filtered_data[col].where(null_mask[col], col_pred)\n\n\nfiltered_data['TimeGatheringData'].hist();"},{"execution_count":null,"metadata":{"_uuid":"5538c40cfe2462cb4efd03bf1181c49bb274dd99","collapsed":true,"_cell_guid":"d21e2151-dbe6-4fe5-a10a-8c225dbdd9cb"},"outputs":[],"cell_type":"code","source":"print(\"I'm not going to pretend that this is a great prediction,\"\n      \" but it avoids the artifacts from the other approaches.\")\nlr_all = LinearRegression()\nX_all = with_nulls[['TimeGatheringData']].values\ny_all = with_nulls['CompensationAmount'].values\nlr_all.fit(X_all, y_all)\ny_pred = lr_all.predict(X_all)\nsimple_plot(y_pred, y_all)"}],"nbformat":4}