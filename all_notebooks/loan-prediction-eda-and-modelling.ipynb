{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification of Loan Status\n#In this notebook, I shall try to show a few ways to create a classification model.\n\nKey Highlights will be :\n\n1. Data Preparation\n2. Visualization and Descriptive analytics (EDA)\n3. Data Imputation\n4. System of multiple models\n5. System of multiple Model quality measure (accuracy score, f1 score, precision, recall)\n6. Cross validation using K folds\n\nDont forget to upvote if you find the notebook useful. Your comments and support will definitely act as a motivator and I shall publish more of my work."},{"metadata":{"_uuid":"9f6cf2ce-cbb9-4730-bfa4-7ac859c3c29a","_cell_guid":"fc68f19f-1992-448b-91a2-cb4f038cff08","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"261c1e60-94b9-4dd8-8356-177b673ced3e","_cell_guid":"423e8885-eca2-47a4-ab37-a9b77b26bd92","trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fc93e50-31ef-4996-91f6-6314e1cf565a","_cell_guid":"6ce2d68d-3d25-440d-b027-20df5b0a3235","trusted":true},"cell_type":"code","source":"train = pd.read_csv(r'/kaggle/input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ntest = pd.read_csv(r'/kaggle/input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cee0065-2366-4b22-bca3-008e6704183d","_cell_guid":"d2272ece-6a48-4aac-a58c-6160b8fa5c4c","trusted":true},"cell_type":"code","source":"##checking the shape of both train and test dataset\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ba76d13-513c-4f44-b24f-2141cce5125c","_cell_guid":"5bd3938c-f0c6-4a39-b305-605f7dec3135","trusted":true},"cell_type":"code","source":"##get the column names in the data\n#although its quiet understood that the test data will not contain the label i.e. Loan Status , but still\n#we shall take a look\n\ncols_train = train.columns\ncols_test = test.columns\nprint(\"Train data Column names : \")\nprint(cols_train)\nprint('_____________________________')\nprint(\"Train data Column names : \")\nprint(cols_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad2682f4-f010-4b5d-bc14-82e5cb5621fa","_cell_guid":"dba7293a-d914-4877-acc8-cea774854653","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e630af68-fdf2-4e96-8c9d-9022131e1320","_cell_guid":"b279fc92-81a9-48fa-8e30-acb7b323ad00","trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d850ce7e-3e47-4467-ac17-d6b63c8e72bc","_cell_guid":"224f7076-1b82-45c3-9635-a09907405b96","trusted":true},"cell_type":"code","source":"## Info about the data using .info and .describe\ntrain.info()\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ec5822c-f287-49a6-9d2a-3c171503c6fe","_cell_guid":"fe5a74ea-d71f-4b65-be10-b8446644c9ed","trusted":true},"cell_type":"code","source":"##describe\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea3e841b-7a6b-44a2-95f1-6e5683dd23c6","_cell_guid":"2a17b135-89e5-40d2-83ab-2cfb5669406d","trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07e697a4-ed46-4e13-904a-188cdafa7b2e","_cell_guid":"48422aa1-373e-4fd3-8ce7-b5bfdb0707ca","trusted":true},"cell_type":"code","source":"#converting Credit History to Object datatype as its of for 0 and 1\ntrain['Credit_History'] = train['Credit_History'].astype('O')\ntest['Credit_History'] = test['Credit_History'].astype('O')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2ab1217-dedb-4e93-b268-feb5a030cc05","_cell_guid":"27978d94-5acf-4b29-a9d2-d7ad7ceae4a4","trusted":true},"cell_type":"code","source":"print(train.info())\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b86d602-2e95-437c-8567-267149462ef2","_cell_guid":"d66bf6d4-219f-43a9-b49c-cda75e82feb2","trusted":true},"cell_type":"code","source":"## describe object type columns\ntrain.describe(include = 'O')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6d77f29-6f6b-4f98-8db6-0f30e9ffaeae","_cell_guid":"e491e2ff-2cad-461b-932b-5c34ec1f72e4","trusted":true},"cell_type":"code","source":"# we will drop ID because it's not important for our model and it will just mislead the model\n\ntrain.drop('Loan_ID', axis=1, inplace=True)\ntest.drop('Loan_ID', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc23d623-a61c-4200-b7ef-7dac047e1cef","_cell_guid":"50c415e3-4577-463d-b638-5967e6667bfd","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20c47047-f0c5-48f3-be44-cee528a004c4","_cell_guid":"95b64c5c-c359-47cd-a785-21a5dbbe0a16","trusted":true},"cell_type":"code","source":"#check if we have any duplicate rows \nprint(train.duplicated().any())\nprint(test.duplicated().any())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf6373c6-a6ab-40e1-8b4f-2bb05f5e4711","_cell_guid":"7e323f55-637d-48ae-80de-00671f5fd396","trusted":true},"cell_type":"code","source":"len(test)-len(test.drop_duplicates())\n\n## dropping the duplicates in test data\ntest = test.drop_duplicates()\ntrain['Loan_Status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c429d7f4-272d-4bde-85c9-998d2c84adaf","_cell_guid":"78bd1dba-213e-4350-8b98-4e43ea487708","trusted":true},"cell_type":"code","source":"# let's look at the target percentage\n\nplt.figure(figsize=(8,6))\nsns.set(style=\"darkgrid\")\nsns.countplot(train['Loan_Status']);\n\nprint('The percentage of Y class : %.2f' % (train['Loan_Status'].value_counts()[0] / len(train)))\nprint('The percentage of N class : %.2f' % (train['Loan_Status'].value_counts()[1] / len(train)))\n\n# We can consider it as imbalanced data, we shall use F1 Score, Precision and Recall to evaluate the Prediction","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7daf9e17-884a-4545-8105-b959b3a1f90c","_cell_guid":"8d3f9bf0-7e56-42dc-9062-74031bd7796c","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b405ff8e-5719-448e-938a-1c3bdc81075c","_cell_guid":"828c7c94-c951-4935-b797-dfb8bf57fa23","trusted":true},"cell_type":"code","source":"## finding the null values and treating them\nheat = sns.heatmap(train.isnull(), cbar=False)\nplt.show()\nNull_percent = train.isna().mean().round(4)*100\n\nNull_percent = pd.DataFrame({'Null_percentage' : Null_percent})\nNull_percent.head()\nNull_percent = Null_percent[Null_percent.Null_percentage > 0].sort_values(by = 'Null_percentage', ascending = False)\nprint(\"Percentage of Null cells : \\n \\n \" , Null_percent)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e914303-6087-406c-9958-ae4ae13d8ec4","_cell_guid":"6c7dbb72-8b8a-4c55-8bf0-9c390fc1ad48","trusted":true},"cell_type":"code","source":"null_klmns = Null_percent.index\nnull_klmns = list(null_klmns)\ntrain[null_klmns].info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d125602-12bc-49ec-b2e0-212eb8d37206","_cell_guid":"f231cdcf-7789-4f75-952b-b5e4a4181b80","trusted":true},"cell_type":"code","source":"#we shall separate the categorical and numeric columns\ncat_data = []\nnum_data = []\n\nfor i,c in enumerate(train.dtypes):\n    if c == object:\n        cat_data.append(train.iloc[:, i])\n    else :\n        num_data.append(train.iloc[:, i])\n\ncat_data = pd.DataFrame(cat_data).transpose()\nnum_data = pd.DataFrame(num_data).transpose()\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53b71a5d-7147-4893-9e7f-e50552799b53","_cell_guid":"bf9236e5-e980-4498-9cf9-5af322c2ecdd","trusted":true},"cell_type":"code","source":"num_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1851abf-d5ee-4bed-a5db-0cc434f03e44","_cell_guid":"bd9d404c-0751-4ca8-ba8d-dad88c5ecf33","trusted":true},"cell_type":"code","source":"##EDA for numerical data\nfor i in num_data.columns:\n    print(i)\n    sns.set(style=\"whitegrid\")\n    sns.boxplot(num_data[i])\n    plt.show()\n    \n##EDA for categorical data\nfor i in cat_data.columns:\n    print(i)\n    total = float(len(cat_data))\n    plt.figure(figsize=(8,10))\n    sns.set(style=\"whitegrid\")\n    ax = sns.countplot(cat_data[i])\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:1.2f}'.format(height/total),ha=\"center\") \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7ee753d-c12b-49b3-a6a0-21c0e641d0cd","_cell_guid":"0b5597f4-00e0-40e0-a6fc-9c85c4a07a0b","trusted":true},"cell_type":"code","source":"## EDA on categorical data relative to Loan Status\n##EDA for categorical data\nfor i in cat_data.columns:\n    print(i)\n    total = float(len(cat_data))\n    plt.figure(figsize=(8,10))\n    sns.set(style=\"darkgrid\")\n    ax = sns.countplot(x = i, hue = 'Loan_Status', data = cat_data)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:1.2f}'.format(height/total),ha=\"center\") \n    plt.show()\n    \n#from the corresponding charts one can gain a lot of important info","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2cf4649-7397-4435-848d-1569d8bb9ac3","_cell_guid":"c6c1ddab-8332-4c00-9e08-c8ac7abd3222","trusted":true},"cell_type":"code","source":"##creating a pair plot\nsns.pairplot(train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"985cacf3-0fd9-4b10-8d34-5f3c68737293","_cell_guid":"e7c79a23-0dc1-4858-a56e-1198602c4a9f","trusted":true},"cell_type":"code","source":"## Data Imputation\n# for cat_data\n\n# If you want to fill every column with its own most frequent value you can use\n\ncat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\ncat_data.isnull().sum().any() # no more missing data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5151b409-b9db-4883-8764-c903fa3b7d33","_cell_guid":"b53b3603-77ab-47c4-b162-13361d36e37b","trusted":true},"cell_type":"code","source":"#num_data\n##as we have many outliers in columns with Numerical data, we shall impute the blank cells with the median of their respective columns\n\nnum_data.fillna(num_data.median(), inplace=True)\nnum_data.isnull().sum().any() # no more missing data \nnum_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a567e87d-d01b-484b-bc46-df6cb5105dc4","_cell_guid":"25238eb1-bdf0-45e7-bb4b-aaf09e749f72","trusted":true},"cell_type":"code","source":"## num_data has certain columns with some very high valued columns and some very low, thus we \n#should standardize the values of these columns\n\nfor col in num_data.columns:\n    num_data[col] = (num_data[col]-num_data[col].min())/(num_data[col].max() - num_data[col].min())\n    \nnum_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0585a0da-ff75-4578-819a-7d0ad578e83b","_cell_guid":"c6f0febb-a27d-46d3-8c40-fdf081dc32bb","trusted":true},"cell_type":"code","source":"##Label Encoding\nfrom sklearn.preprocessing import LabelEncoder  \nle = LabelEncoder()\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb1b5ef2-c109-40d0-bc8c-0b7f3fd89c2b","_cell_guid":"bb3e2f4a-3bca-49f6-b2c5-ea679491bee1","trusted":true},"cell_type":"code","source":"# transform the target column\n\ntarget_values = {'Y': 1 , 'N' : 0}\n\ntarget = cat_data['Loan_Status']\ncat_data.drop('Loan_Status', axis=1, inplace=True)\n\ntarget = target.map(target_values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"517d6c7b-9fc9-49e8-baff-19262fd0fa15","_cell_guid":"ac3a995a-8830-445c-bd69-9b859db0db88","trusted":true},"cell_type":"code","source":"# transform other columns\n\nfor i in cat_data:\n    cat_data[i] = le.fit_transform(cat_data[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f360702e-53ca-46cc-991f-f768d6cb2c4f","_cell_guid":"d69da06a-728e-4b68-aedb-2394a3c8ba85","trusted":true},"cell_type":"code","source":"cat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83760503-d6a7-4771-bfd5-70b95be57e46","_cell_guid":"3db2cbf5-483a-4257-9678-2a912761c653","trusted":true},"cell_type":"code","source":"df = pd.concat([cat_data, num_data, target], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61f1fc8a-b9e7-4e4d-ac03-96759929680f","_cell_guid":"556e2754-cda4-48b4-b8f8-a2e2775a74af","trusted":true},"cell_type":"code","source":"#confirming if we have any null values\n\ndf.isna().any()\n\n#so we are good to model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe544d7c-0746-4a53-80e1-c27787466be6","_cell_guid":"c2e9d986-8260-4184-acee-9f1fa7c40e6a","trusted":true},"cell_type":"code","source":"## Creating our variable and target dataset\nX = pd.concat([cat_data, num_data], axis=1)\ny = target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will use 4 different models for training\n\n## ---------------------------All in one modelling---------------------------\n\nfrom sklearn.model_selection import train_test_split  #to split the dataset for training and testing\nfrom sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\nfrom sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\nfrom sklearn import svm  #for Support Vector Machine (SVM) Algorithm\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier  # for K nearest neighbours\nfrom sklearn import metrics #for checking the model accuracy\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import StratifiedShuffleSplit\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will use StratifiedShuffleSplit to split the data Taking into consideration that we will get the same ratio on the target column\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train, test in sss.split(X, y):\n    X_train, X_test = X.iloc[train], X.iloc[test]\n    y_train, y_test = y.iloc[train], y.iloc[test]\n    \nprint('X_train shape', X_train.shape)\nprint('y_train shape', y_train.shape)\nprint('X_test shape', X_test.shape)\nprint('y_test shape', y_test.shape)\n\n# almost same ratio\nprint('\\nratio of target in y_train :',y_train.value_counts().values/ len(y_train))\nprint('ratio of target in y_test :',y_test.value_counts().values/ len(y_test))\nprint('ratio of target in original_data :',df['Loan_Status'].value_counts().values/ len(df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We shall use 4 different models"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n    'LogisticRegression': LogisticRegression(random_state=34),\n    'KNeighborsClassifier': KNeighborsClassifier(n_neighbors= 5),\n    'SVC': SVC(random_state=34),\n    'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=1, random_state=34)\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2219cd6d-bf40-4873-9944-e70b349dfcd4","_cell_guid":"a06c11b9-dbc1-45b8-a69c-42043943dd4f","trusted":true},"cell_type":"markdown","source":"Creating a function to calculate various accuracy measures"},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n\ndef loss(y_true, y_pred, retu=False):\n    pre = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    loss = log_loss(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    \n    if retu:\n        return pre, rec, f1, loss, acc\n    else:\n        print('  pre: %.3f\\n  rec: %.3f\\n  f1: %.3f\\n  loss: %.3f\\n  acc: %.3f' % (pre, rec, f1, loss, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_eval_train\n\ndef train_eval_train(models, X, y):\n    for name, model in models.items():\n        print(name,':')\n        model.fit(X, y)\n        loss(y, model.predict(X))\n        print('-'*30)\n        \ntrain_eval_train(models, X_train, y_train)\n\n# we can see that best model is LogisticRegression at least for now, SVC is just memorizing the data so it is overfitting .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train cross validation model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n\ndef train_eval_cross(models, X, y, folds):\n    # we will change X & y to dataframe because we will use iloc (iloc don't work on numpy array)\n    X = pd.DataFrame(X) \n    y = pd.DataFrame(y)\n    idx = [' pre', ' rec', ' f1', ' loss', ' acc']\n    for name, model in models.items():\n        ls = []\n        print(name,':')\n\n        for train, test in folds.split(X, y):\n            model.fit(X.iloc[train], y.iloc[train]) \n            y_pred = model.predict(X.iloc[test]) \n            ls.append(loss(y.iloc[test], y_pred, retu=True))\n        print(pd.DataFrame(np.array(ls).mean(axis=0), index=idx)[0])  #[0] because we don't want to show the name of the column\n        print('-'*30)\n        \ntrain_eval_cross(models, X, y, skf)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}