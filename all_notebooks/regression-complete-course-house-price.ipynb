{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv('../input/dataset/House_Price.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['waterbody'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe() # EDD","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(x = 'n_hot_rooms', y ='price', data =df) # variable n_hot_rooms looks like outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(x ='rainfall', y ='price', data= df) # outliers in rainfall","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical variables- airport & \nsns.countplot(x = 'airport', data =df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = 'waterbody', data =df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Observations\n1. missing values in n_hos_beds\n2. skewness or outliers in crime rate\n3. outliers in n_hot_rooms and rainfall\n4. bus-ter has only 'yes' values\n","metadata":{}},{"cell_type":"markdown","source":"#Outliers treatment\n#------- Outliers detection---------------------------------------------\niqr = df\nQ1 = df[['n_hot_rooms','rainfall']].quantile(0.25)\nQ3 = df[['n_hot_rooms','rainfall']].quantile(0.75)\n\n\nIQR = Q3 - Q1\nprint(IQR)\n\nlower_bound = Q1-IQR*1.5\nupper_bound = Q3+IQR*1.5\nprint(lower_bound,upper_bound)\n\n#print(df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))\n\n#Step3: Remove the outliers using the IQR score\ndf = df[~((df < (Q1 - 1.5 * IQR)) |(df  > (Q3 + 1.5 * IQR))).any(axis=1)]\n\nprint(\"The no. of rows before outlier filtering was: \", df.shape)\nprint(\"The no. of rows after outlier filtering is: \", df_out.shape)","metadata":{}},{"cell_type":"code","source":"np.percentile(df.n_hot_rooms,[99])[0]  #99 percentile of variable n_hot_rooms- [0] fetching 1st no\nuv = np.percentile(df.n_hot_rooms,[99])[0]  # upper limit or upper value\ndf[(df.n_hot_rooms > uv)]\ndf.n_hot_rooms[(df.n_hot_rooms > 3*uv)]= 3*uv\n\n\nlv = np.percentile(df.rainfall,[1])[0]\ndf[(df.rainfall< lv)]\ndf.rainfall[(df.rainfall < 0.3*lv)] = 0.3*lv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing value imputation with mean- variable \ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing value replace with mean for n_hos_beds variable\n\ndf.n_hos_beds = df.n_hos_beds.fillna(df.n_hos_beds.mean()) \n\n#df = df.fillna(df.mean()) in case we want to impute for all variables","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum() # Missing value replaced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transforming crime_rate variable\nsns.jointplot(x ='crime_rate', y ='price', data = df)  #curve looks like logarithmic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using log function to transform\ndf.crime_rate = np.log(1+ df.crime_rate)\nsns.jointplot(x ='crime_rate', y ='price', data = df) # here the relationship is somehow linear after transformation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These four variable gives the same information so we will create one var by taking avg  dist1, dist2, dist3, dist4 \n\ndf['avg_dist'] = (df.dist1 + df.dist2 + df.dist3 + df.dist4)/4\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing the varibles dist1, dist2, dist3, dist4, bus_ter\n\ndf = df.drop(['dist1','dist2','dist3', 'dist4','bus_ter'], axis = 1)\ndf.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating dummies variables for categorical variables\n\ndf = pd.get_dummies(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['airport_NO','waterbody_None'], axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CORRELATION MATRIX","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n#df.corr()\ndata_cor = df.corr()\nplt.figure(figsize =(15,6))\ng = sns.heatmap(data_cor, annot = True, cmap =\"RdYlGn\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= df.drop(['parks'], axis =1) # Parks and air_qual are highly correlated > 0.8 removed one to avoid multicollinearity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SIMPLE LINEAR REGRESSION - OLS METHOD","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sn\nX = sn.add_constant(df[\"room_num\"])\nlm = sn.OLS(df['price'],X).fit()\nlm.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Machine learning Method\n\nfrom sklearn.linear_model import LinearRegression\ny =df['price']\nX = df[['room_num']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm2 = LinearRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm2.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm2.intercept_, lm2.coef_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm2.predict(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.jointplot(x = df['room_num'], y = df['price'], data = df, kind = 'reg')  #help(sns.jointplot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multiple Linear Regression","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining X and Y\n\nX_multi = df.drop('price', axis =1) # axis= 1 for dropping column, axis = 0 for row\ny_multi = df['price']\nX_multi.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_multi_cons = sn.add_constant(X_multi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_multi_cons.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm_multi = sn.OLS(y_multi, X_multi_cons).fit()\nlm_multi.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm3 = LinearRegression()\nlm3.fit(X_multi, y_multi)\nprint(lm3.intercept_, lm3.coef_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SPLITTING TRAIN & TEST DATA","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_multi, y_multi, test_size = 0.2, random_state = 0)\nprint(X_train.shape, X_test.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call a model\nlm_a = LinearRegression()\n\n# fit the model\nlm_a.fit(X_train, y_train)\n\n# predict the model\n\ny_test_a = lm_a.predict(X_test)\n#print(y_test_a)\n\ny_train_a = lm_a.predict(X_train)\n#print(y_train_a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Performance metrics #--- Overfitting model\n\nfrom sklearn.metrics import r2_score\nprint(\"R squared value for test :\", r2_score(y_test, y_test_a))\nprint(\"R squared value for train:\", r2_score(y_train, y_train_a))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RIDGE & LASSO REGRESSION","metadata":{}},{"cell_type":"code","source":"# transform with standard scaler\nfrom sklearn import preprocessing\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train_s = scaler.transform(X_train)\nX_test_s = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm_r = Ridge(alpha = 0.5)\nlm_r.fit(X_train_s, y_train)\nlm_r.predict(X_test_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"R squared after Ridge:\", r2_score(y_test, lm_r.predict(X_test_s)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HYPER PARAMETER TUNING\n\nfrom sklearn.model_selection import validation_curve\n\nparam_range = np.logspace(-2,8,100)  # creating 100 values between 10*-2 and 10*8- trying to fit the best value of alpha\nparam_range","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation_curve? to see the criteria of validation curve\n\ntrain_scores, test_scores = validation_curve(Ridge(), X_train_s, y_train, \"alpha\", param_range, scoring = 'r2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_scores)\nprint(test_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mean = np.mean(train_scores, axis=1)  #taking mean of 5 results above of each value\ntrain_mean # 100 r squared value of 100 alpha or lambda","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mean = np.mean(test_scores, axis =1)\ntest_mean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# taking out the highest r squared value\nprint('highest R squared-train',max(train_mean))\nprint('highest R squared-test',max(test_mean))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the r square values v/s lambda(alpha)\n\nsns.jointplot(x = np.log(param_range), y = test_mean)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# locating where optimum value of r squared\n\nnp.where(test_mean == max(test_mean))\n\n# maximum R-squared value lies in 31 index of alpha","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_range[31]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since we get best lambda or alpha value, let's build the model with this\n\nlm_r_best = Ridge(alpha = param_range[31])\nlm_r_best.fit(X_train_s, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('R squared of test', r2_score(y_test, lm_r_best.predict(X_test_s)))\nprint('R squared of train', r2_score(y_train, lm_r_best.predict(X_train_s)))\n\n# there is no improvement in the R-squared value - since the dataset is very less.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\nlm_l = Lasso(alpha = 0.5)\nlm_l.fit(X_train_s, y_train)\nlm_l.predict(X_test_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"R squared after Lasso:\", r2_score(y_test, lm_l.predict(X_test_s)))\n# continue the same process like we did in Ridge but considering R squared is too less, not going through ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}