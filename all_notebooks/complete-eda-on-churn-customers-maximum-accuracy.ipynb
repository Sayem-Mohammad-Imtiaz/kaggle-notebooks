{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#importing useful libararies\nimport pandas as pd\nimport numpy as np\nimport seaborn as sea\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nimport scipy.stats as stats\nfrom sklearn.preprocessing import StandardScaler, normalize, MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_similarity","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(r'../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Have a look the data, how its looks like."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()\ndf.columns\ndf.isnull().sum()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This dataset contains no 'null' or 'na' values.\n### Shape is (7043, 21).\n### Have 21 different columns.\n### Have 3 Contineous varibales and 18 categorical variables.\n### Our Target varible is Churn, also a categorical variable."},{"metadata":{},"cell_type":"markdown","source":"* Dropping unnecessary column."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['customerID'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Easily see the number of categories each varible has."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n    print(df[i].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n* there are some \" \"(Blank Space) in Total  Charges Column. \n* So, we need to replace that values with null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isin([\" \"]).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalCharges'] = df['TotalCharges'].replace([\" \"], np.nan)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Replace the null values with Nan values.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"you can the count of nan values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Dropped NA Values.**[](http://)"},{"metadata":{},"cell_type":"markdown","source":"### Setting the correct data Types of colums, then its easy to manipulate."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalCharges']= df['TotalCharges'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SeniorCitizen'] = df['SeniorCitizen'].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SeniorCitizen'] = df['SeniorCitizen'].replace({1:'Yes', 0:'No'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seprating the categorical and Numerical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = [i for i in df.columns if df[i].dtypes == 'O']\nnum = [i for i in df.columns if df[i].dtypes != 'O']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replacing 'No Phone Service' or 'No Internet Service' with 'No'.\n*Because it does not make any sense out of it. Still we will do some EDA on this."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.replace(['No phone service'], ['No'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.replace({'No internet service':'No'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cat].nunique().plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The paymentMethod, Contract and Internet Service has 3 or more categories.\n- Most of the variables has only 2 categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2, figsize=(15,5))\nplt.figure(figsize=(5,5))\nsea.countplot(x ='StreamingTV', hue = 'Churn' ,data =df, ax= ax[0])\nsea.countplot(x ='PaymentMethod', hue = 'Churn' ,data =df, ax= ax[1])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- Those customer who have subscribe **Streaming TV** service are less likey to churn as compared to those have subscribed it.\n- Those customer who are using **Electronic check** payment method are more likey to churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2, figsize=(15,5))\nplt.figure(figsize=(5,5))\nsea.countplot(x ='PaperlessBilling', hue = 'Churn' ,data =df, ax= ax[0])\nsea.countplot(x ='Contract', hue = 'Churn' ,data =df ,ax = ax[1])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- Those customers who use paperless billing are more likely to churn.\n- Those cusotmers who are using Month- to Month Contract are more churning. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2, figsize=(15,5))\nplt.figure(figsize=(5,5))\nsea.countplot(x ='InternetService', hue = 'Churn' ,data =df, ax= ax[0])\nsea.countplot(x ='gender', hue = 'Churn' ,data =df, ax = ax[1])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- Fiber Optic Internet service users are more churning."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sea.countplot(x=\"Churn\", hue=\"Contract\", data=df);\nax.set_title('Contract Type vs Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some Analysis on Contineous varibles."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[num].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"have a look at numerical varible"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nplt.title(\"Monthly C,harges VS Total Charges\")\nplt.scatter(x = df.MonthlyCharges, y = df.TotalCharges)\nplt.xlabel('Monthly Charges')\nplt.ylabel('Total Charges')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The relationship Between the MontyCharges and TotalCharges is postive. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ndf[['MonthlyCharges','tenure']].head(35).plot(kind='line')\nplt.title(\"Monthly Charges VS Tenure\")\nplt.xlabel('Monthly Charges')\nplt.ylabel('Tenure')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- "},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.countplot(x= 'Churn' ,data=df, hue='SeniorCitizen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- Senior Citizen cutomers are less and they are very less likely to churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Contract.value_counts().plot(kind='pie', legend= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The Month-to-Month Contract customers are more in numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.distplot(df[\"tenure\"], color=\"b\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The tenure of maximum customer are belong to 0-20."},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.distplot(df[\"MonthlyCharges\"], color=\"r\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The variation between the MontlyCharges."},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.distplot(df[\"TotalCharges\"], color=\"g\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The maxmimum total charges is vary between 0 to 2000."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Count_OnlineServices'] = (df[['OnlineSecurity', 'DeviceProtection', 'StreamingMovies', 'TechSupport','StreamingTV', 'OnlineBackup']] == 'Yes').sum(axis=1)\nplt.figure(figsize=(10,5))\nsea.countplot(x= 'Count_OnlineServices', hue= 'Churn', data =df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- Those cutomers, who is subscribing various  services are less likely to churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sea.boxplot(x='Churn', y = 'tenure', data=df)\nax.set_title('Churn vs Tenure', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The less the tenure more likely to churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.violinplot(x=\"MultipleLines\", y=\"tenure\", hue=\"Churn\", kind=\"violin\",\n                 split=True, palette=\"pastel\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- Those who are not using Multiple lines Service tend to churn in first of their months."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"]\ndf1 = pd.melt(df[df[\"InternetService\"] != \"No\"][cols]).rename({'value': 'Has service'}, axis=1)\nplt.figure(figsize=(10, 5))\nax = sea.countplot(data=df1, x='variable', hue='Has service')\nax.set(xlabel='Additional service', ylabel='Num of customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observation:**\n- The Most used service is Streaming Movies and Streaming TV.\n- the OnlineSecurity and Techsupport serices are less acquired by customers."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,5))\nsea.countplot(x= 'Churn' ,data=df, hue='PaymentMethod')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,5))\nsea.boxplot(x=\"Contract\", y=\"MonthlyCharges\", hue=\"Churn\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing for Machine Learning Equations"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df.Churn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* seprate the target column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Churn', axis =1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* drop that target column from the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = pd.DataFrame(y)\ny['Churn'].replace(to_replace='Yes', value=1, inplace=True)\ny['Churn'].replace(to_replace='No',  value=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* replace their values from Yes to 1 and No to 0. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp =df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Creating Dummy variables for out all categorical columns and drop all other columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shape of our prepared data frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\ndf[num] = scaler.fit_transform(df[num])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Doing Min MAx scalling for numerical varibles. As they are high in values so, we need to take them at same page. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dividing the data into Training and Testing."},{"metadata":{},"cell_type":"markdown","source":"## LOgistic Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import plot_confusion_matrix, plot_roc_curve\nmodel_lr = LogisticRegression()\nresult = model_lr.fit(X_train, y_train)\nprediction_test = model_lr.predict(X_test)\nmetrics.accuracy_score(y_test, prediction_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_roc_curve(model_lr, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier with 1000 Decision Tress."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel_rf = RandomForestClassifier(n_estimators=1000)\nmodel_rf.fit(X_train, y_train)\nprediction_test = model_rf.predict(X_test)\nmetrics.accuracy_score(y_test, prediction_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_roc_curve(model_rf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = model_rf.feature_importances_\nweights = pd.Series(importances,\n                 index=df.columns.values)\nweights.sort_values()[-20:].plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**You can see the Important features for model prediction according to Random Forest algorithm. **"},{"metadata":{},"cell_type":"markdown","source":"## Support vector Machine Algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nmodel_svm = SVC(kernel='linear') \nmodel_svm.fit(X_train,y_train)\npreds = model_svm.predict(X_test)\nmetrics.accuracy_score(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_roc_curve(model_svm, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extream Boost Classifier with Learning rate is 0.25"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nmodel_gb=xgb.XGBClassifier(learning_rate=0.25,max_depth=4)\nmodel_gb.fit(X_train, y_train)\nmodel_gb.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],   \n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomizedSearch for tuning and finding the best parameters for Extream boosting algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nrandom_search=RandomizedSearchCV(model_gb,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)\nrandom_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We found out the best paramerter impleting again in Extream boosting. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nmodel_gb=xgb.XGBClassifier(learning_rate=0.05,max_depth=3)\nmodel_gb.fit(X_train, y_train)\nmodel_gb.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import StackingClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building ensemble learning model with Stacking Classifier\n* For stage one, I choose Logistic Regression, KNearestNeigbour, DecisionTreeCassifier, and NaiveBayes.\n* For stage two, default model is Logistic Regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"level0 = list()\nlevel0.append(('lr', LogisticRegression()))\nlevel0.append(('knn', KNeighborsClassifier()))\nlevel0.append(('cart', DecisionTreeClassifier()))\nlevel0.append(('svm', SVC()))\nlevel0.append(('bayes', GaussianNB()))\n# define meta learner model\nlevel1 = LogisticRegression()\n# define the stacking ensemble\nmodelx = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\nmodelx.fit(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = modelx.predict(X_test)\nmetrics.accuracy_score(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **If you like this Notebook, Do Upvote this**\n# Thanks"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}