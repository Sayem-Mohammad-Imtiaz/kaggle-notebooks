{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This is just a short notebook about the questionare. Have fun**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport warnings \nimport math\nimport sys\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Alright, let's get the data. Also I gonna remove countries with less than 5 entries, since they are very unnacurate. Sadly this takes a lot of time.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_raw = pd.read_csv(\"../input/big-five-personality-test/IPIP-FFM-data-8Nov2018/data-final.csv\", sep=\"\\t\")\n\ndata_raw.rename(columns={\"EXT1\":\"life of party\", \"EXT2\":\"don't talk a lot\", \"EXT3\": \"comfortable around people\",\n                    \"EXT4\":\"keep background\", \"EXT5\":\"start conversation\", \"EXT6\":\"little to say\", \"EXT7\":\"talk to party people\",\n                     \"EXT8\":\"don't like draw attention\", \"EXT9\":\"center of attention\", \"EXT10\":\"quite around strangers\"}, inplace = True)\n\n#filter all countries with less then 5 values. Sadly this one is reeeaaaaaally slow.\ndata=pd.DataFrame()\ncounter=1\nlast=len(pd.unique(data_raw[\"country\"]))\n#only use entries with more then 5 values\nfor country in pd.unique(data_raw[\"country\"]):\n    print('\\r', counter, \"of\", last, end=\"\")\n    counter=counter+1\n    if len(data_raw[data_raw[\"country\"]==country])>=5:\n        data=data.append(data_raw[data_raw[\"country\"]==country])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"A short overview over the questions and the amount of taken answers. Not really a usefull analysis, but it gives a nice overview. I hid the output since there are 10 Histograms.","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"with warnings.catch_warnings():\n    # there are some warnings about runtime, I gonna ignore those.\n    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n    for i in range(0,9):\n        pyplot.hist(data.iloc[:,i],  alpha=1, label=data.columns[i])\n        pyplot.legend(loc='upper right')\n        plt.title(data.columns.values[i])\n        plt.xlabel(\"Value of votes\")\n        plt.ylabel(\"Number of votes\")\n        pyplot.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since it's very interesting, if those questions are correlation, I gonna do a correlation analysis. Basically there are two kind of questions:\n    Are you a extrovertive person?\n    Are you a introvertive person?\nThis can be seen on the correlation matrix. Nearly every question is correlating with another one.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = data.iloc[:,1:10].corr()\n\nax = sns.heatmap(\n    correlations, \n    vmin=-1, vmax=1, center=0,\n    square=True,\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n)\nax.set_title(\"correlation matrix\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are two different kind of answers in this questionare, we gonna check those. I will do scatterplot with mean and standard deviation for checking how those values are behaving in every country. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_coun1 = pd.DataFrame()\n\nwith warnings.catch_warnings():\n    # there are some warnings about runtime, I gonna ignore those.\n    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n    \n    for coun in pd.unique(data[\"country\"]):\n        data_coun = data[data[\"country\"]==coun].iloc[:,0]\n        data_coun = data_coun.dropna(0)\n        mean_coun = data_coun.values.mean()\n        std_coun = data_coun.values.std(ddof=1)\n        df_coun1 = df_coun1.append([[coun, mean_coun, std_coun]])\n\n    df_coun1=df_coun1.dropna(0)\n    df_coun1.columns=[\"country code\", \"mean\", \"stdev\"]\n\n    pyplot.hist(df_coun1.iloc[:,1],  alpha=0.5)\n\n    plt.xlabel(\"Mean\")\n    plt.ylabel(\"Number\")\n    \n    plt.title(data.columns.values[0])\n    \n    pyplot.figure()\n    pyplot.scatter(df_coun1.iloc[:,1], df_coun1.iloc[:,2])\n    plt.xlabel(\"Mean\")\n    plt.ylabel(\"Stdev\")\n    \n    plt.title(data.columns.values[0])\n\n    for i in range(len(df_coun1.index)):\n        plt.annotate(df_coun1.iloc[i,0], (df_coun1.iloc[i,1], df_coun1.iloc[i,2]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's improve this scatterplot by adding some clusters, those are more for visualization then for other reasons. Therefore I'm not filtering for the cluster, but a threshold. In this question \"Do you live the live of a party\" I take those, who are above a 3.0. The lower the standard deviation, the more the people are approving the mean of their country.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#I want to cluster the results. \ndf_kmeans = df_coun1.iloc[:,1:3]\n\n\ncluster=KMeans(n_clusters=4).fit(df_kmeans)\ncentroids = cluster.cluster_centers_\nplt.scatter(df_kmeans.iloc[:,0], df_kmeans.iloc[:,1], c= cluster.labels_.astype(float), alpha=0.5)\nplt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\nplt.xlabel(\"Mean\")\nplt.ylabel(\"Stdev\")\nplt.title(data.columns.values[0])\n\n\nfor i in range(len(df_coun1.index)):\n    plt.annotate(df_coun1.iloc[i,0], (df_coun1.iloc[i,1], df_coun1.iloc[i,2]))\nplt.show()\n\nprint (df_coun1[df_coun1.iloc[:,1]>3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In total there exist 5 countrys which are living the live of a party with a mean of 3 or above. But only one country is certain about it, which is Samoa. The other countrys are definatly above average, but also got a high standard deviation. Though Liechtenstein seems kinda happy about their live.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's check the other kind of question: \"I don't talk a lot around people\", so let's see who is the most introverted country. I will not explain the following code, since it's identically. I chose a higher thresholdof 3.3.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_coun2 = pd.DataFrame()\n\nwith warnings.catch_warnings():\n    # there are some warnings about runtime, I gonna ignore those.\n    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n    \n    for coun in pd.unique(data[\"country\"]):\n        data_coun = data[data[\"country\"]==coun].iloc[:,1]\n        data_coun = data_coun.dropna(0)\n        mean_coun = data_coun.values.mean()\n        std_coun = data_coun.values.std(ddof=1)\n        df_coun2 = df_coun2.append([[coun, mean_coun, std_coun]])\n    print(df_coun2)\n    df_coun2=df_coun2.dropna(0)\n    df_coun2.columns=[\"country code\", \"mean\", \"stdev\"]\n\n    pyplot.hist(df_coun2.iloc[:,1],  alpha=0.5)\n\n    plt.xlabel(\"Mean\")\n    plt.ylabel(\"Number\")\n    \n    plt.title(data.columns.values[1])\n    \n    pyplot.figure()\n    pyplot.scatter(df_coun2.iloc[:,1], df_coun2.iloc[:,2])\n    plt.xlabel(\"Mean\")\n    plt.ylabel(\"Stdev\")\n    \n    plt.title(data.columns.values[1])\n\n    for i in range(len(df_coun2.index)):\n        plt.annotate(df_coun2.iloc[i,0], (df_coun2.iloc[i,1], df_coun2.iloc[i,2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I want to cluster the results. \ndf_kmeans = df_coun2.iloc[:,1:3]\n\n\ncluster=KMeans(n_clusters=4).fit(df_kmeans)\ncentroids = cluster.cluster_centers_\nplt.scatter(df_kmeans.iloc[:,0], df_kmeans.iloc[:,1], c= cluster.labels_.astype(float), alpha=0.5)\nplt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\nplt.xlabel(\"Mean\")\nplt.ylabel(\"Stdev\")\nplt.title(data.columns.values[1])\n\n\nfor i in range(len(df_coun2.index)):\n    plt.annotate(df_coun2.iloc[i,0], (df_coun2.iloc[i,1], df_coun2.iloc[i,2]))\nplt.show()\n\nprint (df_coun2[df_coun2.iloc[:,1]>3.3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a lot higher average. Most countrys seem to identify with this kind of question. On top of all Liberia and the Northern Mariana Islands seem to be very quiet people.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"If you want to check what your country is, you can use your country code here. Mine is germany, so i gonna use this one. We are appearently very average with a huge spread.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Your country lifes the live of a party:\\n\", df_coun2[df_coun2[\"country code\"]==\"DE\"])\nprint(\"Your country does not speak a lot around people:\\n\", df_coun1[df_coun1[\"country code\"]==\"DE\"] )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}