{"cells":[{"metadata":{"_cell_guid":"f9ea3d81-0e70-4c70-b473-83a4c3623c9f","_uuid":"47f2f7894152e115f6e62068b0cc9e945f1d1dc0"},"cell_type":"markdown","source":"This notebook focuses on using e-commerce review data and the [spacy](http://www.spacy.io) NLP libraries. \nThe focus on this notebook is not to go over at length on the exploratory part as there is [two](https://www.kaggle.com/ankkur13/prediction-based-on-bayes-algo-nlp-wordcloud) another excellent notebooks that cover those aspects already.\nOne thing that I will be delving in more details is to compare the different models utilized to perform text classification and product recommendation predictions. One of the notebook uses a naive bayes approach whereas I will be focussing solely on using the spacy library."},{"metadata":{"_cell_guid":"fb1776d5-6933-4fd8-83bb-e30c6c116b83","_uuid":"fcb71f7b48fa7fe37605542711a8b25e629f45cd"},"cell_type":"markdown","source":"Let's import all the dependencies. \nWe are using spacy v2.0x which now incorporates flexible pipeline and deep learning models for text classification."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import unicode_literals, print_function\nimport plac\nimport random\nfrom pathlib import Path\nimport thinc.extra.datasets\nimport spacy\nfrom spacy.util import minibatch, compounding\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"#Read the file\ndfRaw = pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\")","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"12b33359-d93b-4748-ad8d-97ae472d3972","_uuid":"de3ee6dd5f40b8e5a41f92c1fafcddee5ff197eb","scrolled":true,"trusted":true},"cell_type":"code","source":"#Basic introspection of the file\ndfRaw.info()\ndfRaw.head()","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"2839c3dd-6b19-4527-8997-f93782c46b0f","_uuid":"aa959a6b21756e3ae957980cb02bdefe3b49f40a"},"cell_type":"markdown","source":"In this segment, we will train a model to learn about which product is recommended by a reviewer. We will use the spacy text classifier which uses a convolutional neural network for its model. More info can be found here on the new features of spacy v2.0 https://spacy.io/usage/v2#features-models"},{"metadata":{"_cell_guid":"3d2c7fff-60f9-49f5-bac2-539ba5c69ae9","_uuid":"11a02a99bffa728d04c763f0f642b48973d369c5","collapsed":true,"trusted":true},"cell_type":"code","source":"#Create a new dataframe with the field of interests and drops any null values.\ndfRec = dfRaw[['Review Text', 'Recommended IND']].dropna()","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"59336abb-d04c-4540-91bd-824f8de255ce","_uuid":"9cde80a7ebbf474357216bed8f2d3f6c150a23d7","trusted":true},"cell_type":"code","source":"dfRec.info()\ndfRec.head()","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"fac57617-52e2-43ce-8a75-f0568b7973e6","_uuid":"3b070c6879b8b6dcba7757f489fd55a6e45084e8","collapsed":true,"trusted":true},"cell_type":"code","source":"#Format the dataset for use in spacy\ndfRec['dataset'] = dfRec.apply(lambda row: (row['Review Text'],row['Recommended IND']), axis=1)\necom = dfRec['dataset'].tolist()","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"b4a96ca1-e611-47c8-a7fd-7127c8eac9c5","_uuid":"b0c8fb1d467434c64fdf40ae25e0b8b331bfe934","scrolled":true,"trusted":true},"cell_type":"code","source":"ecom[5]","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"4549ee98-721e-43fc-b82b-4a2c26b91787","_uuid":"e8131dcbb76b9fb9af85598f2a2a495ed015f5a8","collapsed":true,"trusted":true},"cell_type":"code","source":"#helper functions\ndef load_data(limit=0, split=0.8):\n    \"\"\"Load data from the e-commerce dataset.\"\"\"\n    # Partition off part of the train data for evaluation\n    train_data = ecom\n    random.shuffle(train_data)\n    train_data = train_data[-limit:]\n    texts, labels = zip(*train_data)\n    cats = [{'POSITIVE': bool(y)} for y in labels]\n    split = int(len(train_data) * split)\n    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n\n\ndef evaluate(tokenizer, textcat, texts, cats):\n    docs = (tokenizer(text) for text in texts)\n    tp = 1e-8  # True positives\n    fp = 1e-8  # False positives\n    fn = 1e-8  # False negatives\n    tn = 1e-8  # True negatives\n    for i, doc in enumerate(textcat.pipe(docs)):\n        gold = cats[i]\n        for label, score in doc.cats.items():\n            if label not in gold:\n                continue\n            if score >= 0.5 and gold[label] >= 0.5:\n                tp += 1.\n            elif score >= 0.5 and gold[label] < 0.5:\n                fp += 1.\n            elif score < 0.5 and gold[label] < 0.5:\n                tn += 1\n            elif score < 0.5 and gold[label] >= 0.5:\n                fn += 1\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    f_score = 2 * (precision * recall) / (precision + recall)\n    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"0eb915e7-e2d9-452e-92df-0c6d4ae55723","_uuid":"910d6615c613ba63d0734c0be4703928f322ff98","collapsed":true,"trusted":true},"cell_type":"code","source":"#Initialize variable for the spacy model\nmodel=None\nn_iter=20 \nn_texts=2000","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"22e16448-44e5-4c0e-9db4-f12ec9692929","_uuid":"17b4c0ff506e51c9113aa8c87b662fef62aa03d5","trusted":true},"cell_type":"code","source":"#Create a new model\nnlp = spacy.load('en')  # create blank Language class\nprint(\"Created blank 'en' model\")","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"e051ce6d-3093-4da1-a16a-de9b5b04af62","_uuid":"14b7829c48b3062ac663147e391f25445c4218ba","trusted":true},"cell_type":"code","source":"#Create text classifier, add to the pipeline and create label\ntextcat = nlp.create_pipe('textcat')\nnlp.add_pipe(textcat, last=True)\n# add label to text classifier\ntextcat.add_label('POSITIVE')","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"cc046e4c-68ca-426b-862d-d41051d603b8","_uuid":"857ca5ae084da52b0c386c09dac90e472910aa2c","scrolled":true,"trusted":true},"cell_type":"code","source":"#Load the data and split the dataset into DEV and Train for evaluation\nprint(\"Loading ecom data...\")\n(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\nprint(\"Using {} examples ({} training, {} evaluation)\".format(n_texts, len(train_texts), len(dev_texts)))\ntrain_data = list(zip(train_texts,[{'cats': cats} for cats in train_cats]))","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"f90beed5-e6be-4fac-b434-f8788249892d","_uuid":"da6e02dd9d07ea7fa5381275091b8857db2bf7fc","trusted":true},"cell_type":"code","source":"#Run model\n# get names of other pipes to disable them during training\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\nwith nlp.disable_pipes(*other_pipes):  # only train textcat\n        optimizer = nlp.begin_training()\n        print(\"Training the model...\")\n        print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n        for i in range(n_iter):\n            losses = {}\n            # batch up the examples using spaCy's minibatch\n            batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n                           losses=losses)\n            with textcat.model.use_params(optimizer.averages):\n                # evaluate on the dev data split off in load_data()\n                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n            print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n                  .format(losses['textcat'], scores['textcat_p'],\n                          scores['textcat_r'], scores['textcat_f']))","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"e0095e33-15cf-4837-920e-f67765cdf329","_uuid":"660118365ca102b8575cb2f1f3bad7435165f398","collapsed":true,"trusted":true},"cell_type":"code","source":"output_dir = \"./ecom_product_rec\"","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"0a778e25-6fab-4491-8254-57f2633065b6","_uuid":"ecf898b932f5e3db46526b8fab36413f6894149e","collapsed":true,"trusted":true},"cell_type":"code","source":"nlp.to_disk(output_dir)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"cc8a9d17-3386-4741-a914-48ad91bfaf53","_uuid":"d558676c2cc8da226a3177b37878db8e1ad6a9a7","trusted":true},"cell_type":"code","source":"# Load saved model\nprint(\"Loading from\", output_dir)\nnlp2 = spacy.load(output_dir)","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"22a3e753-9658-4551-a2ac-05313b4e263c","_uuid":"6c2db9b5c73796b9c3e41050108c13861fcba973","collapsed":true,"trusted":true},"cell_type":"code","source":"test_pos = \"I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\"","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"b679e5b6-604c-48c0-808d-ad55fef66d2b","_uuid":"5daccd2685538394c566894cafc84cf9352e7411","trusted":true},"cell_type":"code","source":"doc2 = nlp2(test_pos)\nprint(test_pos, doc2.cats)","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"806d6b7b-76a4-4d70-aaa3-73d4392c935b","_uuid":"97e7468cbf4daadab9237d882735c6c5d5cf5a7e"},"cell_type":"markdown","source":"We can observe that the positive test is indeed very close to 1 (Positive)"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5c8717f6ee314ef98816753c6667bf835522e4c8"},"cell_type":"code","source":"test_neg = \"3 tags sewn in, 2 small (about 1'' long) and 1 huge (about 2'' x 3''). very itchy so i cut them out. then the thread left behind was plasticy and even more itchy! how can you make an intimates item with such itchy tags? not comfortable at all! also - i love bralettes and wear them all the time including to work. i am a b cup. however, this one is so thin and flimsy that it gives no support even to a b cup - so for me this would only be a lounging bralette - if it wasn't so itchy!\"","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"c7daec49-6943-454b-9533-5200f66869db","_uuid":"597a735991f9d6e8246dc6538ad1ec8c154e702e","trusted":true},"cell_type":"code","source":"doc3 = nlp2(test_neg)\nprint(test_neg, doc3.cats)","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"2039d6ab-9a99-4ee8-926c-c06d2d301eee","_uuid":"4139475ea4300c71b8f8dec50a8e4d941e6b7b6d"},"cell_type":"markdown","source":"We can observe that the negative test is not very close to 0 (Negative). \n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}