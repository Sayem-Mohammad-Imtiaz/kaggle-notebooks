{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Spam Classification\n"},{"metadata":{},"cell_type":"markdown","source":"Let's Get started, I have used datasets from\nUCI Spam dataset : https://www.kaggle.com/uciml/sms-spam-collection-dataset"},{"metadata":{},"cell_type":"markdown","source":"Now, here we start with spam classification so we will allotting binary values to labels so that Machine Learning model can work efficiently in predicting the results"},{"metadata":{},"cell_type":"markdown","source":"# Steps taken\n* Load the libraries\n* Data Cleaning\n* Assigning Binary Values to Labels\n* Data Visualization (Part-1)\n* LowerCasing, Punctuation removing and Vocabulary modifications\n* Counting The Occurence of Words\n* Training, Testing Part of the model\n* Data Visualization (Part-2)"},{"metadata":{},"cell_type":"markdown","source":"# Loading the libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filepath='../input/sms-spam-collection-dataset/spam.csv'\ndf=pd.read_csv(filepath, encoding='latin-1')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\nWe, start with dropping columns with missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1)\ndf=df.rename(columns={'v1':'labels','v2': 'sms'})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assigning Binary Values"},{"metadata":{},"cell_type":"markdown","source":"We fix our response values for spam and ham"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['labels']=df.labels.map({'spam':0, 'ham':1})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['length']=df['sms'].apply(len)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization (Part-1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nsns.distplot(a=df['length'],kde=False)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message=df[df['length']==910]['sms'].iloc[0]\nmessage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LowerCasing, Punctuations and Vocab. modifications"},{"metadata":{},"cell_type":"markdown","source":"Now we will implement Bag of Words which will count the number of words based on their frequency distribution and that binary number will be fed for Machine Learning model\n"},{"metadata":{},"cell_type":"markdown","source":"We start with using lowercase for all the words in the above sentence"},{"metadata":{"trusted":true},"cell_type":"code","source":"message={\"\"\"\nFor me the love should start \n         with attraction.i should feel that \n         I need her every time around me.she should be the first thing which comes in my thoughts.\n         I would start the day and end it with her.she should be there every time I dream.love will be \n         then when my every breath has her name.my life should happen around her.my life will be named to her.\n         I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.\n         I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that \n         my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when \n         I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.\n         will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later.\n\"\"\"}\nlower_case=[]\nfor i in message:\n    lower_case=[i.lower() for i in message]\n    print(lower_case)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will use punctutation for sorting out the sentences"},{"metadata":{"trusted":true},"cell_type":"code","source":"sans_punctuation = []\nimport string\n\nfor i in lower_case:\n    sans_punctuation.append(i.translate(str.maketrans('', '', string.punctuation)))\nprint(sans_punctuation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tokenization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_documents = []\nfor i in sans_punctuation:\n     preprocessed_documents=[[w for w in i.split()] for i in message]\nprint(preprocessed_documents)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we begin with counting the numbers as how much is their frequency"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pprint\nfrom collections import Counter\nfrequency_num=[]\n\nfor i in preprocessed_documents:\n    frequency_count=Counter(i)\n    frequency_num.append(frequency_count)\npprint.pprint(frequency_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Counting The Occurence of Words"},{"metadata":{},"cell_type":"markdown","source":"Let's try the above with CountVectorizer tool "},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vector=CountVectorizer()\nprint(count_vector)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, using count_vector i have converted the words to vocabulary as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vector.fit(message)\nvoc=count_vector.get_feature_names()\nvoc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nwe convert the message words to array form"},{"metadata":{"trusted":true},"cell_type":"code","source":"doc_to_array=count_vector.transform(voc).toarray()\ndoc_to_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Table created "},{"metadata":{"trusted":true},"cell_type":"code","source":"frequency_matrix = pd.DataFrame(doc_to_array, \n                                columns = count_vector.get_feature_names())\nfrequency_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and Testing the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['sms'],df['labels'],random_state=1)\nprint('Number of rows in the total set: {}'.format(df.shape[0]))\nprint('Number of rows in the training set: {}'.format(X_train.shape[0]))\nprint('Number of rows in the test set: {}'.format(X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data=count_vector.fit_transform(X_train)\ntesting_data=count_vector.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb=MultinomialNB()\nmnb.fit(training_data, y_train)\n\npredictions=mnb.predict(testing_data)\nmnb_accuracy = accuracy_score(y_test,predictions)\nprint('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n\nprint('precision score: ', format(precision_score(y_test,predictions)))\nprint('recall score: ', format(recall_score(y_test,predictions)))\nprint('f1 score: ', format(f1_score(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Decision Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc=DecisionTreeClassifier()\ndtc.fit(training_data,y_train)\n\npredictions=dtc.predict(testing_data)\ndtc_accuracy = accuracy_score(y_test,predictions)\nprint('Accuracy score: ', format(accuracy_score(y_test, predictions)))\nprint('precision score: ', format(precision_score(y_test,predictions)))\nprint('recall score: ', format(recall_score(y_test,predictions)))\nprint('f1 score: ', format(f1_score(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomForest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc=RandomForestClassifier()\nrfc.fit(training_data,y_train)\n\npredictions=rfc.predict(testing_data)\nrfc_accuracy = accuracy_score(y_test,predictions)\nprint('Accuracy score: ', format(accuracy_score(y_test,predictions)))\nprint('precision score: ', format(precision_score(y_test,predictions)))\nprint('recall score: ', format(recall_score(y_test,predictions)))\nprint('f1 score: ', format(f1_score(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn=KNeighborsClassifier()\nknn.fit(training_data, y_train)\n\npredictions=knn.predict(testing_data)\nknn_accuracy = accuracy_score(y_test,predictions)\nprint('Accuracy score: ', format(accuracy_score(y_test,predictions)))\nprint('precision score: ', format(precision_score(y_test,predictions)))\nprint('recall score: ', format(recall_score(y_test,predictions)))\nprint('f1 score: ', format(f1_score(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bagging Classifer and AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"bgc=BaggingClassifier()\nbgc.fit(training_data, y_train)\n\npredictions=bgc.predict(testing_data)\nbgc_accuracy = accuracy_score(y_test,predictions)\nprint('Accuracy score: ', format(accuracy_score(y_test,predictions)))\nprint('precision score: ', format(precision_score(y_test,predictions)))\nprint('recall score: ', format(recall_score(y_test,predictions)))\nprint('f1 score: ', format(f1_score(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#AdaBoost\nadb=AdaBoostClassifier()\nadb.fit(training_data, y_train)\npredictions=adb.predict(testing_data)\nadb_accuracy = accuracy_score(y_test,predictions)\nprint('Accuracy score: ', format(accuracy_score(y_test,predictions)))\nprint('precision score: ', format(precision_score(y_test,predictions)))\nprint('recall score: ', format(recall_score(y_test,predictions)))\nprint('f1 score: ', format(f1_score(y_test,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization (Part-2)"},{"metadata":{},"cell_type":"markdown","source":"**Accuracy Plots estimations **"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=(mnb_accuracy,dtc_accuracy,rfc_accuracy,knn_accuracy,bgc_accuracy,adb_accuracy)\nplt.figure(figsize=(16,6))\nsns.distplot(a=clf, hist=True)\nplt.xlabel('Accuracy scores')\nplt.title('Accuracy comparison')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bar plot for all model accuracies"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data=clf)\nplt.title('Accuracy estimates')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=true_positive, false_negative, false_positive, true_negative = confusion_matrix(y_test,predictions).ravel()\nprint('True positive : ',true_positive)\nprint('False negative : ',false_negative)\nprint('False positive : ',false_positive)\nprint('True negative : ',true_negative)\n\naccuracy = (true_positive + true_negative)/(true_positive + false_negative + false_positive + true_negative)\nprint('General accuracy : ',accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So our model has a very good predictions on messages that are spam or ham and using certain algorithms like AdaBoost can enhance the accuracy of the model."},{"metadata":{},"cell_type":"markdown","source":"Any suggestions feel free to comment"},{"metadata":{},"cell_type":"markdown","source":"Hope you enjoyed this!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}