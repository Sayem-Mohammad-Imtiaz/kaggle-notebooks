{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom mpl_toolkits.mplot3d import Axes3D ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Big Five Survey Data Exploratory analysis and Hypothesis Testing\n> This notebook contains some basic EDA for the big five dataset.\nIn the course of the analysis, we notice some trends and perform statistical tests to formalize our hypothesis.\nThis is still a work-in-progress, and a lot more can be added.\nI am making this public as there are many open questions and subject-matter based assumptions, and it would be great to get suggestions/insights from you on the work so far and what else can be done."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/big-five-personality-test/IPIP-FFM-data-8Nov2018/data-final.csv', sep='\\t')\n\n# adjusting scores for questions with negative/opposite measurement, list of negatives taken from:\n\nnegatives = [ \n    'EXT2','EXT4','EXT6','EXT8','EXT10', # 5\n    'EST2','EST4',                       # 2\n    'AGR1','AGR3','AGR5','AGR7',         # 4\n    'CSN2','CSN4','CSN6','CSN8',         # 4\n    'OPN2','OPN4','OPN6',                # 3\n]\n\ndf[negatives] = df[negatives].replace({1:5, 2:4, 3:3, 4:2, 5:1})\n\na=range(1,11)\next_cols = [('EXT'+str(i)) for i in a]\nest_cols = [('EST'+str(i)) for i in a]\nagr_cols = [('AGR'+str(i)) for i in a]\ncsn_cols = [('CSN'+str(i)) for i in a]\nopn_cols = [('OPN'+str(i)) for i in a]\n\ntraits = [ext_cols, est_cols, agr_cols, csn_cols, opn_cols]\n\ndf_scores = pd.DataFrame(index = df.index)\n\n# Sum scores to calculate scores for each trait\n\nfor trait in traits:\n    df_scores = pd.concat([df_scores,(df.loc[:,trait]).sum(axis=1)], axis = 1)\n    \ndf_scores.columns=['EXT', 'EST', 'AGR', 'CSN', 'OPN']\n\n\n\n\ndf_scores = pd.concat([df_scores, df.country], axis = 1)\n\ndf_scores.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create histogram to check distribution of scores, we would expect close to normal"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nhist_plots = plt.figure(figsize=(30,20))\n\nfor i in range(5):\n    plt.subplot(2,3,i+1)\n    plt.title(label=df_scores.columns[i],fontsize=30)\n    sns.distplot(df_scores.iloc[:,i], axlabel=False, kde=False)\n\nhist_plots.suptitle('Histograms for each trait', fontsize=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distributions are more or less normal for all traits, as expected.\nThere are few major ourliers, specially in the lower end of the distributions, but with very low frequencies. Nothing too surprisingly, but may need a closer look later."},{"metadata":{},"cell_type":"markdown","source":"We may also with to check distribution of means of scores by country.\nThis should also be generally close to normal"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_by_country = df_scores.groupby('country').mean()\nscores_by_country.head()\ncountry_distplots = plt.figure(figsize=(30,20))\nfor i in range(5):\n    plt.subplot(2,3,i+1)\n    colname = scores_by_country.columns[i]\n    plt.title(label=colname,fontsize=30)\n    sns.distplot(scores_by_country.iloc[:,i], axlabel=False, kde=False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some countries with very low / very high average score.\nThis would be strange, I expect this is because we have very few observations from some of the countries, but I am leaving the confirmation as a //todo for now :)\nList of countries with max/min scores per trait can be checked below."},{"metadata":{"trusted":true},"cell_type":"code","source":"for trait in scores_by_country:\n    print(\"countries with maximum average scores for \", trait)\n    print(scores_by_country.loc[:,trait].sort_values()[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We can now check for collinearity in the traits, and examine visually using scatterplots.\nI am not sure what to expect here, would need some SME for this. Are there traits generally considered independent, or is there some correlation?\nFor example people who are less extroverted are generally also less open, or something similar?\n\nWe can try to find any such pattern in this data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import pearsonr\n\nr, p = pearsonr(df_scores.EXT, df_scores.EST)\nprint(r,p)\n\ndf_scores.iloc[:,0:5].corr()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation values are quite low, but lets plot some scatter plots and see what it looks like:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_plots = plt.figure()\nsns.scatterplot(x=df_scores.AGR, y=df_scores.EXT)\nplt.show()\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(df_scores.EXT, df_scores.EST, df_scores.OPN)\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nax.set_zlabel('Z Label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While numerical correlation values maybe low, there is clearly something going on.\nThe values are more or less independent for higher scores, but there is a distinct cluster for lower values.\nThe data seems to suggest that people who score low on one trait, tend to score low on ALL traits! Any such relation breaks down as scores increase.\n(I have displayed only one set of scatter plots for brevity, but they look similar for all combinations)\nThis does not sound too intuitive, but I'm not a psychologist!\n\nThere could be other unaccounted reasons for this, like how the participants percieve the questions, but for now we can ignore that and focus on analytics."},{"metadata":{},"cell_type":"markdown","source":"So lets perform some statistical tests to see if the effects we infer from the scatterplots are statistically significant in any way.\n\nSince there is no correlation for larger values, it might be a good starting point to separate the traits into 'low', 'mid', and 'high' scores and perform ANOVA.\nArbitrarily, i choose zscores = 2 and -2 as thresholds.\n\nWE will also plot number of negative outliers per trait, to see if there is a particular trait with very large number ( though we can kind of see from the histograms that they are all close to the same distribution)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n#count outliers in each trait\n\n\nzscores = pd.DataFrame(index = df_scores.index)\n\n\nfor trait in list(df_scores.columns[0:5]):\n    \n    zscores[trait] = (df_scores[trait] - df_scores[trait].mean()) / df_scores[trait].std(ddof=0)\n    \n# zscores = pd.concat([zscores, df_scores.country], axis = 1)\n\n\nis_neg_outlier = (zscores < -2)\ncount_outliers = is_neg_outlier.apply(np.count_nonzero)\ncount_outliers.columns=['Trait','Negative_Outliers']\nprint(count_outliers)\n\n## Number of outliers per \ncount_outliers.plot.bar(x='Trait', y='Negative_Outliers')\n\nis_neg_outlier = pd.concat([is_neg_outlier, df_scores.country], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for anova, lets start with categorizing EXT\n\n\nconditions = [zscores['EXT']<-2, zscores['EXT']>2]\nchoices = ['low', 'high']\n\n\n\n\next_cat = pd.Series(np.select(conditions, choices, default = 'mid'))\n\n\next_anova = pd.DataFrame(index = zscores.index)\n \n\n# EXT_CAT.head()\n\next_anova = pd.concat([ext_cat, zscores[['EST','AGR','CSN','OPN']]], axis=1)\next_anova.columns = ['EXT_CAT','EST','AGR','CSN','OPN']\next_anova.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.formula.api import ols\n\nresults = ols('AGR ~ C(EXT_CAT)', data=ext_anova).fit()\nresults.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, quite a significant result.\nCan also do Multivariate ANOVA as it seems the effect exists across traits (//todo)\n\nFurther tests... :\n\nWe can convert all traits to categoricals in the same way ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_chisq = pd.DataFrame(index = zscores.index)\ntraits = ['EXT', 'EST', 'AGR', 'CSN', 'OPN']\nfor trait in traits:\n    colname = trait + '_CAT'\n    conditions = [zscores[trait]<-1.5, zscores[trait]>1.5]\n    choices = ['low', 'high']\n    df_chisq[colname] = pd.Series(np.select(conditions, choices, default = 'mid'), name = colname)\ndf_chisq.describe()\n\n# Then perform chi square, also \\\\todo for now :(","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}