{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What do we want?"},{"metadata":{},"cell_type":"markdown","source":"We want to predict the response of a customer. For that we have some features :\n\n* **id** :\tUnique ID for the customer\n* **Gender** :\tGender of the customer\n* **Age** :\tAge of the customer\n* **Driving_License** :\n   * 0 : Customer does not have DL \n   * 1 : Customer already has DL\n* **Region_Code** :\tUnique code for the region of the customer\n* **Previously_Insured** :\n   * 1 : Customer already has Vehicle Insurance \n   * 0 : Customer doesn't have Vehicle Insurance\n* **Vehicle_Age** :\tAge of the Vehicle\n* **Vehicle_Damage** :\n   * 1 : Customer got his/her vehicle damaged in the past. \n   * 0 : Customer didn't get his/her vehicle damaged in the past.\n* **Annual_Premium** :\tThe amount customer needs to pay as premium in the year\n* **PolicySalesChannel** :\tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\n* **Vintage** :\tNumber of Days, Customer has been associated with the company\n* **Response** :\n   * 1 : Customer is interested \n   * 0 : Customer is not interested"},{"metadata":{},"cell_type":"markdown","source":"## Import librairies üìö"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nplt.style.use('ggplot')\n\nimport cufflinks as cf\nimport plotly.express as px\nimport plotly.offline as py\nfrom plotly.offline import plot\nimport plotly.graph_objects as go\nimport plotly.graph_objs as go\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.utils.multiclass import type_of_target\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Data üìù"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/train.csv\")\ntest_df = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"We have :\", train_df.shape[0], \"Rows in the Train set\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"We have :\", test_df.shape[0], \"Rows in the Test set\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop([\"id\"], axis=1)\ntest_df = test_df.drop([\"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_train = train_df.isnull().sum().sum()\nnull_test = test_df.isnull().sum().sum()\n\nprint(\"There's\", null_train, \"null value in the Train set\")\nprint(\"There's\", null_test, \"null value in the Test set\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration üìä"},{"metadata":{},"cell_type":"markdown","source":"### Responses (Not interested / Interested)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Response\"].value_counts().plot.bar(colormap=\"autumn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_response = train_df[train_df[\"Response\"] == 0].value_counts().sum()\npositive_response = train_df[train_df[\"Response\"] == 1].value_counts().sum()\nprint(\"The percentage of positive response is :\", round(positive_response*100/negative_response), \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gender (Not interested / Interested)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train_df['Response'], train_df['Gender']).plot(kind=\"bar\", figsize=(8,6), colormap=\"autumn\")\n\nplt.title(\"Response by Gender\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Female\", \"Male\"])\n\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Previously Insured (Not interested / Interested)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train_df['Response'], train_df['Previously_Insured']).plot(kind=\"bar\", figsize=(8,6), colormap=\"autumn\")\n\nplt.title(\"Response by Previously Insured\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Client without Insurance\", \"Client with already Insurance\"])\n\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Driving license (Not Intersted / Interested)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train_df['Response'], train_df['Driving_License']).plot(kind=\"bar\", figsize=(8,6), colormap=\"autumn\")\n\nplt.title(\"Response by Driving License\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Client without Driving License\", \"Client with Driving License\"])\n\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Driving license is too messy.\nFor the moment, I prefer too drop this column."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop([\"Driving_License\"], axis=1)\ntest_df = test_df.drop([\"Driving_License\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vehicules age (Not interested / Interested)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train_df['Response'], train_df['Vehicle_Age']).plot(kind=\"bar\", figsize=(10,6), colormap=\"autumn\")\n\nplt.title(\"Response by Vehicle Age\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"1-2 Year\", \"< 1 Year\", \"> 2 Years\"])\n\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vehicules Damage (Not interested / Interested)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train_df['Response'], train_df['Vehicle_Damage']).plot(kind=\"bar\", figsize=(10,6), colormap=\"autumn\")\n\nplt.title(\"Response by Vehicle Damage\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Vehicle damage\", \"No vehicle damage\"])\n\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of ages"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Graph : Age by responses\nfig = px.bar(train_df[\"Age\"].value_counts(), orientation=\"v\", color=train_df[\"Age\"].value_counts(), color_continuous_scale=px.colors.sequential.Plasma, \n             log_x=False, labels={'value':'Count', \n                                'index':'Ages',\n                                 'color':'None'\n                                })\n\nfig.update_layout(\n    font_color=\"black\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_text=\"Age by number of responses\"\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering üè∑Ô∏è"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At first, we have to change our data into numerical data.\nFor that, i will encode some features."},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoding_gender(item):\n    if item == \"Male\":\n        return 0\n    else:\n        return 1\n    \ntrain_df[\"Gender\"] = train_df[\"Gender\"].apply(encoding_gender)\ntest_df[\"Gender\"] = test_df[\"Gender\"].apply(encoding_gender)\n\ntrain_df[\"Gender\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoding_vehicle_age(item):\n    if item == \"< 1 Year\":\n        return 0\n    elif item == \"1-2 Year\":\n        return 1\n    else:\n        return 2\n    \ntrain_df[\"Vehicle_Age\"] = train_df[\"Vehicle_Age\"].apply(encoding_vehicle_age)\ntest_df[\"Vehicle_Age\"] = test_df[\"Vehicle_Age\"].apply(encoding_vehicle_age)\n\ntrain_df[\"Vehicle_Age\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoding_vehicle_dmg(item):\n    if item == \"No\":\n        return 0\n    else:\n        return 1\n    \ntrain_df[\"Vehicle_Damage\"] = train_df[\"Vehicle_Damage\"].apply(encoding_vehicle_dmg)\ntest_df[\"Vehicle_Damage\"] = test_df[\"Vehicle_Damage\"].apply(encoding_vehicle_dmg)\n\ntrain_df[\"Vehicle_Damage\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ours datasets are now, completely clean. Before modeling a model, I want to see the correlation between features."},{"metadata":{},"cell_type":"markdown","source":"## Correlation üîÑ"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.heatmap(train_df.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, Previously Insured has the worst corr coef with ***-0.34*** and at the opposite, Vehicle Damage has the best corr coef with ***0.35***."},{"metadata":{},"cell_type":"markdown","source":"## Modelling üü©"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, KFold, GridSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score,recall_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler, Normalizer\nfrom sklearn.utils.multiclass import type_of_target\n\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standardization\n\nnumerical_cols = ['Age', 'Vintage', 'Policy_Sales_Channel', 'Region_Code']\n\nscaler = StandardScaler()\ntrain_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n\nscaler_2 = MinMaxScaler()\ntrain_df[[\"Annual_Premium\"]] = scaler_2.fit_transform(train_df[[\"Annual_Premium\"]])\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop([\"Response\"], axis=1)\ny = train_df['Response']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# r = 42\n\n# RFC = RandomForestClassifier(random_state = r)\n# LGR = LogisticRegression(max_iter=10000)\n# KNN = KNeighborsClassifier(n_neighbors = 10)\n# SGD = SGDClassifier()\n\n# classifiers = [RFC, ADA, KNN, XGB]\n# classifiers_names = ['Random Forest',\n#                      'Logistic Regreesion',\n#                      'KNeighborsClassifier',\n#                      'SGD Classifier']\n# acc_mean = []\n\n# for cl in classifiers:\n#     acc = cross_val_score(estimator = cl, X = X_train, y  = y_train, cv = 2)\n#     acc_mean.append(acc.mean()*100)\n    \n# acc_df = pd.DataFrame({'Classifiers': classifiers_names,\n#                        'Accuracies Mean': acc_mean})\n\n# acc_df.sort_values('Accuracies Mean',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = KNeighborsClassifier(n_neighbors = 11)\n\nfinal_model.fit(X_train, y_train)\ny_pred_final_model = final_model.predict(X_test)\naccuracy_score(y_test, y_pred_final_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#k_range = list(range(1,31))\n#weight_options = [\"uniform\", \"distance\"]\n\n#param_grid = dict(n_neighbors = k_range, weights = weight_options)\n#print (param_grid)\n#KNN = KNeighborsClassifier()\n\n#grid = GridSearchCV(KNN, param_grid, cv = 10, scoring = 'accuracy')\n#grid.fit(X,y)\n\n#print(grid.best_score_)\n#print(grid.best_params_)\n#print(grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best params are n_neighbors = 30 et weights = uniform."},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN = KNeighborsClassifier()\n\nfinal_model = KNeighborsClassifier(n_neighbors = 30, weights = \"uniform\")\n\nfinal_model.fit(X_train, y_train)\ny_pred_final_model = final_model.predict(X_test)\naccuracy_score(y_test, y_pred_final_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_test, y_pred_final_model, average = 'weighted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_test, y_pred_final_model, average='weighted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recall_score(y_test, y_pred_final_model, average='weighted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### If you have any suggestion or advice to improve my notebook, don't hesitate! If you liked it, don't hesitate to like it either! It will help me a lot. I'll improve my work as I go. Thanks again !"},{"metadata":{},"cell_type":"markdown","source":"### After to improve my work :\n\n**-- Confusion Matrix**\n\n**-- Roc plot**\n\n**-- Oversampling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}