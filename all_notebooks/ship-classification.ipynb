{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport cv2\nimport glob\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport keras.backend as B\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport pycuda.driver as cuda\nfrom keras.preprocessing.image import ImageDataGenerator ,img_to_array\nfrom keras.metrics import binary_crossentropy\nfrom keras.models import Sequential , Model\nfrom keras.layers import BatchNormalization , Conv2D , Dense , Activation , Flatten , MaxPool2D , Dropout\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"['train', 'test_ApKoW4T.csv', 'sample_submission_ns2btKE.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"if (torch.cuda.is_available()):\n    cuda.init()\n\n    #Get ID of CUDA device\n    ID= torch.cuda.current_device()\n    #Get CUDA device name\n    print(cuda.Device(ID).name())\n\n    #set the GPU\n    os.environ['CUDA_VISIBLE_DEVICES'] = str(ID)","execution_count":2,"outputs":[{"output_type":"stream","text":"Tesla P100-PCIE-16GB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcsv= pd.read_csv(\"../input/train/train.csv\")\ntestcvs = pd.read_csv(\"../input/test_ApKoW4T.csv\")\ndata_path = \"../input/train/images/\"\npath = os.path.join(data_path , \"*jpg\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = glob.glob(path)\ndata=[]\nfor file in files:\n    image = cv2.imread(file)\n    data.append(image)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = data[:6252]\ntest_images= data[6252:]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='category' , data=rcsv)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7fd05464b5f8>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"* Since the data is imbalanced a bit, we will use keras inbuilt function for real time Data Augmentation of images"},{"metadata":{"trusted":true},"cell_type":"code","source":"category = {'Cargo': 1, \n'Military': 2, \n'Carrier': 3, \n'Cruise': 4, \n'Tankers': 5}","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualising Images in Each Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_class(cat):\n    \n    fetch = rcsv.loc[rcsv['category']== category[cat]][:9]\n    fig = plt.figure(figsize=(20,15))\n    \n    for i , index in enumerate(fetch.index ,1):\n        plt.subplot(3,3 ,i)\n        plt.imshow(train_images[index])\n        plt.xlabel(cat + \" (Index:\" +str(index)+\")\" )\n    plt.show()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_class('Cargo')","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_class('Military')","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_class('Carrier')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_class('Cruise')","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_class('Tankers')","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImagePreprocessing:\n    \n    def __init__(self,train_images , test_imges , height , length , dataframe):\n        \n        self.train_images =train_images\n        self.test_images  =test_images\n        self.height = height\n        self.length = length\n        self.dataframe = dataframe\n    \n    def Resize(self,TAG):\n        processed_images =[]\n        if TAG == 'Train':\n            for i in range(len(self.train_images)):\n                im= cv2.resize(self.train_images[i] , dsize=(self.height , self.height))\n                processed_images.append(im)\n        elif TAG== 'Test':\n            for i in range(len(self.test_images)):\n                im= cv2.resize(self.test_images[i] , dsize=(self.height , self.height))\n                processed_images.append(im)\n        return processed_images\n    \n    def Reshape(self):\n        #resizing Images\n        self.rez_train_image = self.Resize('Train')\n        self.rez_test_image  = self.Resize('Test')\n        #fetching labels for training and testing\n        self.train_labels    = self.dataframe['category'][:self.length]\n        \n        #converting into array \n        self.label_array = self.toarray(self.train_labels)\n        \n        #reshaping label array\n        self.labels      = self.label_array.reshape(len(self.label_array) , 1)\n        \n        #reshaping images\n        self.pro_images = np.reshape(self.rez_train_image , (len(self.rez_train_image),self.height,self.height,3))\n        self.test_pro_images = np.reshape(self.rez_test_image , (len(self.rez_test_image) ,self.height,self.height,3))\n        \n        return  self.pro_images , self.labels , self.test_pro_images\n    \n    \n    def toarray(self,series):\n        return np.array(series)\n    \n    def splitdata(self,TRAIN_images, LABELS):\n        X_train , X_val , Y_train , Y_val = train_test_split(TRAIN_images , LABELS , test_size=0.2 , random_state=42)\n        return X_train , X_val , Y_train , Y_val\n    \n    def OneHot(self,x):\n        onehotencoder = OneHotEncoder(categorical_features = [0])\n        x = onehotencoder.fit_transform(x).toarray()\n        return x","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Augmentation\nI refer to the artilcle for the idea of Augmentation. **[Here](https://medium.com/@ksusorokina/image-classification-with-convolutional-neural-networks-496815db12a8)** For data generator I refered this [article](https://medium.com/@arindambaidya168/https-medium-com-arindambaidya168-using-keras-imagedatagenerator-b94a87cdefad)"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(featurewise_center=True,  \n                             featurewise_std_normalization =False ,\n                             rotation_range=20, \n                             horizontal_flip=True,\n                             width_shift_range=0.20 , fill_mode = 'nearest',\n                             height_shift_range=0.20  )","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess = ImagePreprocessing(train_images , test_images , height=150 , length= 6252 , dataframe=rcsv)\nrez_images , LABELS , test_rez_images = preprocess.Reshape()\nonehot_labels = preprocess.OneHot(LABELS)\nX_train , X_val , Y_train , Y_val = preprocess.splitdata(rez_images , onehot_labels )","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save_image_path = \"/kaggle/working/IMAGES\"\n# if not os.path.exists(save_image_path):\n#     os.mkdir(save_image_path)\n\n\n\n\n\n\n\n# T0 = time.time()\n# for image , label in zip(rez_images , LABELS):\n#     image =np.expand_dims(image ,0)\n#     datagen.fit(image)\n#     name = \"shiptype_{}\".format(label)\n#     for x , val in zip(datagen.flow(image,label,batch_size=1,save_to_dir=save_image_path,save_prefix=name,save_format='jpg'), range(5)):\n#         pass\n# print(\"Total time for training: {}\".format(time.time()-T0))\n\n\n\n\n\n# files = glob.glob(os.path.join(save_image_path,\"*jpg\"))\n# imagedata=[]\n# labeldata=[]\n# for file in files:\n#     label = file.split(\"/\")[-1][10]\n#     image = cv2.imread(file)\n#     image = cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX)\n#     imagedata.append(image)\n#     labeldata.append(int(label))\n\n\n\n# imagedata = np.reshape(imagedata , (len(imagedata) , 150,150,3))\n# labeldata = np.reshape(labeldata , (len(labeldata) ,1))\n# IMAGES = np.concatenate((rez_images , imagedata), axis=0)\n# LABELDATA = np.concatenate((LABELS , labeldata) , axis=0)\n\n\n\n\n# IMAGESlist =[]\n# for i in range(len(IMAGES)):\n#     IMAGESlist.append(IMAGES[i].reshape(1,-1).transpose())\n\n\n\n\n# IMAGES.tolist()\n\n\n\n# df = pd.DataFrame([IMAGESlist])\n\n\n\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = plt.figure(figsize=(20,15))\n    \n# for i in range(1,10,1):\n#     plt.subplot(3,3 ,i)\n#     plt.imshow(IMAGES[i])\n#     plt.xlabel(LABELDATA[i])\n# plt.show()","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train , X_val , Y_train , Y_val = preprocess.splitdata(imagedata , labeldata )\n# Y_train = np.reshape(preprocess.toarray(Y_train) , (len(Y_train),1))\n# Y_val = np.reshape(preprocess.toarray(Y_val) , (len(Y_val),1))\n# X_train = np.reshape(preprocess.toarray(X_train) , (len(X_train),150,150,3))\n# X_val = np.reshape(preprocess.toarray(X_val) , (len(X_val),150,150,3))\n# Y_val = preprocess.toarray(Y_val)\n# labels = preprocess.OneHot(Y_train)\n# val_labels = preprocess.OneHot(Y_val)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Mymodel(input_shape , L2):\n    \n    model = Sequential()\n    model.add(Conv2D(32,kernel_size=(3,3),activation='relu', kernel_regularizer=L2,padding='same',input_shape=input_shape))\n    model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    model.add(Conv2D(64 , kernel_size=(3,3),activation='relu', padding='same'))\n    model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    #model.add(Conv2D(64 , kernel_size=(3,3),activation='relu', padding='same', kernel_regularizer=L2))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    \n    #model.add(Conv2D(128 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    #model.add(Conv2D(128 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(Conv2D(128 , kernel_size=(3,3),activation='relu', padding='same',  kernel_regularizer=L2))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    \n    #model.add(Conv2D(256 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(Conv2D(256 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(Conv2D(256 , kernel_size=(3,3),activation='relu', padding='same', kernel_regularizer=L2))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    \n    model.add(Flatten())\n    #model.add(Dense(512 , activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    \n    #model.add(Dense(256 , activation='relu'))\n    #model.add(BatchNormalization())\n    \n    #model.add(Dense(128 , activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(64 , activation='relu'))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(32 , activation='relu', kernel_regularizer=None))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(16 , activation='relu', kernel_regularizer=None))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(8 , activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(5 , activation='softmax'))\n    \n    model.compile(optimizer=Adam(lr=0.001) , loss='categorical_crossentropy' , metrics=['accuracy'])\n    \n    return model","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train = datagen.fit(X_train)\n#X_val = datagen.fit(X_val)\ntrain_generator = datagen.flow(X_train , Y_train)\nval_generator = datagen.flow(X_val , Y_val)","execution_count":57,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-24b257585ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#X_train = datagen.fit(X_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#X_val = datagen.fit(X_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mx_misc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             raise ValueError('`x` (images tensor) and `y` (labels) '\n\u001b[1;32m     78\u001b[0m                              \u001b[0;34m'should have the same length. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Mymodel((150,150,3), None)\nmodel.summary()","execution_count":58,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_19 (Conv2D)           (None, 150, 150, 32)      896       \n_________________________________________________________________\nmax_pooling2d_19 (MaxPooling (None, 75, 75, 32)        0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 75, 75, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_20 (MaxPooling (None, 38, 38, 64)        0         \n_________________________________________________________________\nflatten_7 (Flatten)          (None, 92416)             0         \n_________________________________________________________________\ndense_40 (Dense)             (None, 64)                5914688   \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 64)                256       \n_________________________________________________________________\ndense_41 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_42 (Dense)             (None, 16)                528       \n_________________________________________________________________\ndense_43 (Dense)             (None, 8)                 136       \n_________________________________________________________________\ndense_44 (Dense)             (None, 5)                 45        \n=================================================================\nTotal params: 5,937,125\nTrainable params: 5,936,997\nNon-trainable params: 128\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# T0 = time.time()\n# history = model.fit_generator(train_generator , steps_per_epoch=300 , epochs=25 , validation_data=val_generator , validation_steps=300)\n# #history=model.fit(X_train,Y_train,validation_data=(X_val,Y_val),batch_size=512,epochs=20)\n# print(\"Total time for training: {}\".format(time.time()-T0))","execution_count":59,"outputs":[{"output_type":"stream","text":"Epoch 1/25\n300/300 [==============================] - 79s 264ms/step - loss: 1.5785 - acc: 0.3316 - val_loss: 1.5629 - val_acc: 0.3324\nEpoch 2/25\n299/300 [============================>.] - ETA: 0s - loss: 1.5525 - acc: 0.3405","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-83218c4fc0cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mT0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#history=model.fit(X_train,Y_train,validation_data=(X_val,Y_val),batch_size=512,epochs=20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time for training: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mT0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# acc = history.history['acc']\n# val_acc = history.history['val_acc']\n# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n \n# epochs = range(len(acc))\n \n# plt.plot(epochs, acc, 'b', label='Training acc')\n# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n# plt.title('Training and validation accuracy')\n# plt.legend()\n# plt.savefig(\"../working/Accuracy.png\") \n# plt.figure()\n \n# plt.plot(epochs, loss, 'b', label='Training loss')\n# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n# plt.title('Training and validation loss')\n# plt.legend()\n# plt.savefig(\"../working/Loss.png\")\n \n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}