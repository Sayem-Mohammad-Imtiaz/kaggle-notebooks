{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport random\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A\nimport cv2\nimport random\n\nfrom tqdm import tqdm\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_fn = A.Compose([\n    A.HorizontalFlip(),\n    A.RandomBrightnessContrast(),\n    A.Rotate(limit=20),\n])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class PairedDataset(Dataset):\n    def __init__(self, a_dir, b_dir, split='train'):\n        self.a_fps = os.listdir(a_dir)\n        self.a_fps = [os.path.join(a_dir, x) for x in self.a_fps]\n        self.b_fps = os.listdir(b_dir)\n        self.b_fps = [os.path.join(b_dir, x) for x in self.b_fps]\n        self.size = (256, 256)\n        self.split = split\n        \n    def __getitem__(self, index):\n        if self.split == 'train':\n            a_fp = random.sample(self.a_fps, 1)[0]\n        else:\n            a_fp = self.a_fps[index]\n        b_fp = random.sample(self.b_fps, 1)[0]\n        a_img = self.get_input(a_fp)\n        b_img = self.get_input(b_fp)\n        a_img = torch.from_numpy(a_img).float()\n        b_img = torch.from_numpy(b_img).float()\n        return a_img, b_img\n    \n    def get_input(self, fp):\n        img = cv2.imread(fp)\n        img = cv2.resize(img, self.size)\n        if self.split == 'train':\n            img = transform_fn(image=img)['image']\n        img = img / 255\n        img = (img - 0.5) / 0.5\n        img = np.transpose(img, (2, 0, 1))\n        return img\n    \n    def __len__(self):\n        return len(self.a_fps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = PairedDataset(\"/kaggle/input/facades-dataset/testB/\", \n                     \"/kaggle/input/facades-dataset/testA/\")\na, b = data[0]\nplt.subplot(121)\nplt.imshow(0.5 + 0.5 * a.detach().numpy().transpose(1, 2, 0))\nplt.subplot(122)\nplt.imshow(0.5 + 0.5 * b.detach().numpy().transpose(1, 2, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class UNetDown(nn.Module):\n    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n        super(UNetDown, self).__init__()\n        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n        if normalize:\n            layers.append(nn.InstanceNorm2d(out_size))\n        layers.append(nn.LeakyReLU(0.2))\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\n\nclass UNetUp(nn.Module):\n    def __init__(self, in_size, out_size, dropout=0.0):\n        super(UNetUp, self).__init__()\n        layers = [\n            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n            nn.InstanceNorm2d(out_size),\n            nn.ReLU(inplace=True),\n        ]\n#         if dropout:\n#             layers.append(nn.Dropout(dropout))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x, skip_input):\n        x = self.model(x)\n        x = torch.cat((x, skip_input), 1)\n        return x\n\nclass GeneratorUNet(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3):\n        super(GeneratorUNet, self).__init__()\n\n        self.down1 = UNetDown(in_channels, 64, normalize=False)\n        self.down2 = UNetDown(64, 128)\n        self.down3 = UNetDown(128, 256)\n        self.down4 = UNetDown(256, 512, dropout=0.5)\n        self.down5 = UNetDown(512, 512, dropout=0.5)\n        self.down6 = UNetDown(512, 512, dropout=0.5)\n        self.down7 = UNetDown(512, 512, dropout=0.5)\n        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n\n        self.up1 = UNetUp(512, 512, dropout=0.5)\n        self.up2 = UNetUp(1024, 512, dropout=0.5)\n        self.up3 = UNetUp(1024, 512, dropout=0.5)\n        self.up4 = UNetUp(1024, 512, dropout=0.5)\n        self.up5 = UNetUp(1024, 256)\n        self.up6 = UNetUp(512, 128)\n        self.up7 = UNetUp(256, 64)\n\n        self.final = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.ZeroPad2d((1, 0, 1, 0)),\n            nn.Conv2d(128, out_channels, 4, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        # U-Net generator with skip connections from encoder to decoder\n        d1 = self.down1(x)\n        d2 = self.down2(d1)\n        d3 = self.down3(d2)\n        d4 = self.down4(d3)\n        d5 = self.down5(d4)\n        d6 = self.down6(d5)\n        d7 = self.down7(d6)\n        d8 = self.down8(d7)\n        u1 = self.up1(d8, d7)\n        u2 = self.up2(u1, d6)\n        u3 = self.up3(u2, d5)\n        u4 = self.up4(u3, d4)\n        u5 = self.up5(u4, d3)\n        u6 = self.up6(u5, d2)\n        u7 = self.up7(u6, d1)\n        return self.final(u7)\n                      \n\n\ndef get_discriminator(in_ch=3, ndf=128):\n    model = nn.Sequential(\n        nn.Conv2d(in_ch, ndf, 4, 2, 1, bias=False),\n        nn.LeakyReLU(0.1, inplace=True),\n        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 2),\n        nn.LeakyReLU(0.1, inplace=True),\n        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 4),\n        nn.LeakyReLU(0.1, inplace=True),\n        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 8),\n        nn.LeakyReLU(0.1, inplace=True),\n        nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 16),\n        nn.LeakyReLU(0.1, inplace=True),\n        nn.Conv2d(ndf * 16, ndf * 32, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 32),\n        nn.LeakyReLU(0.1, inplace=True),\n        nn.Dropout(0.3),\n        nn.AvgPool2d(4),\n        nn.Flatten(1, 3),\n        nn.Linear(ndf * 32, 1),\n        nn.Sigmoid(),\n    )\n    return model    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_single_epoch(gen_ab, gen_ba, disc_a, disc_b,\n                       data_loader, b_size, epoch, \n                       l1_crit, l2_crit,\n                       optimizer_gen_ab, optimizer_gen_ba, optimizer_disc_a, optimizer_disc_b):\n    gen_ab.train()\n    gen_ba.train()\n    disc_a.train()\n    disc_b.train()\n    total_steps = len(data_loader)\n    postfix_dict = {}\n    tbar = tqdm(enumerate(data_loader), total=total_steps, position=0, leave=True)\n    \n    img_a, img_b = None, None\n    \n    gen_ab.zero_grad()\n    gen_ba.zero_grad()\n    disc_a.zero_grad()\n    disc_b.zero_grad()\n    \n    for i, (img_a, img_b) in tbar:\n        a = img_a.cuda()\n        b = img_b.cuda()\n        \n        a2b = gen_ab(a)\n        a2b2a = gen_ba(a2b)\n        b2a = gen_ba(b)\n        b2a2b = gen_ab(b2a)\n        b2b = gen_ab(b)\n        a2a = gen_ba(a)\n        \n        a2b_probas = disc_b(a2b)\n        b_probas = disc_b(b)\n        b2a_probas = disc_a(b2a)\n        a_probas = disc_a(a)\n        \n        real_label = torch.full((b_size, 1), 1, dtype=torch.float, device='cuda')\n        fake_label = torch.full((b_size, 1), 0, dtype=torch.float, device='cuda')\n        \n        # Identity loss\n        id_loss = l1_crit(a2a, a) + l1_crit(b2b, b)\n        # Cycle loss\n        cycle_loss = l1_crit(a2b2a, a) + l1_crit(b2a2b, b)\n        # GAN loss\n        a_d_loss = l2_crit(a_probas, real_label) + l2_crit(b2a_probas, fake_label)\n        b_d_loss = l2_crit(b_probas, real_label) + l2_crit(a2b_probas, fake_label)\n        a_g_loss = l2_crit(b2a_probas, real_label)\n        b_g_loss = l2_crit(a2b_probas, real_label)\n        d_loss = a_d_loss + b_d_loss\n        g_loss = a_g_loss + b_g_loss\n        gan_loss = d_loss + g_loss\n        \n        total_loss = id_loss + cycle_loss + gan_loss\n        total_loss.backward()\n        \n        postfix_dict[\"train/id_loss\"] = id_loss.item()\n        postfix_dict[\"train/cycle_loss\"] = cycle_loss.item()\n        postfix_dict[\"train/g_loss\"] = g_loss.item()\n        postfix_dict[\"train/d_loss\"] = d_loss.item()\n        \n        optimizer_gen_ab.step()\n        optimizer_gen_ba.step()\n        optimizer_disc_a.step()\n        optimizer_disc_b.step()\n        \n#         a2b = gen_ab(a)\n#         b2a = gen_ba(b)\n#         a2b_probas = disc_b(a2b)\n#         b_probas = disc_b(b)\n#         b2a_probas = disc_a(b2a)\n#         a_probas = disc_a(a)\n#         a_d_loss = l2_crit(a_probas, real_label) + l2_crit(b2a_probas, fake_label)\n#         b_d_loss = l2_crit(b_probas, real_label) + l2_crit(a2b_probas, fake_label)\n#         d_loss = a_d_loss + b_d_loss\n#         d_loss.backward()\n#         optimizer_disc_a.step()\n#         optimizer_disc_b.step()\n        \n        f_epoch = epoch + i / total_steps\n        desc = ', {:04d}/{:04d}, {:.2f} epoch'.format(i, total_steps, f_epoch)\n        tbar.set_description(desc)\n        tbar.set_postfix(**postfix_dict)\n\n    return a, b\n        \n\ndef display_results(img_a, img_b, gen_ab, gen_ba):\n    display.clear_output(True)\n    with torch.no_grad():\n        fake_a = gen_ba(img_b)\n        fake_b = gen_ab(img_a)\n    plt.figure(figsize=(12, 6))\n    plt.subplot(141)\n    t = img_a[0].detach().cpu().numpy().transpose(1, 2, 0)\n    t = 0.5 + 0.5 * t\n    plt.imshow(t)\n    plt.axis('off')\n    plt.subplot(142)\n    t = fake_b[0].detach().cpu().numpy().transpose(1, 2, 0)\n    t = 0.5 + 0.5 * t\n    plt.imshow(t)\n    plt.axis('off')\n    plt.subplot(143)\n    t = fake_a[0].detach().cpu().numpy().transpose(1, 2, 0)\n    t = 0.5 + 0.5 * t\n    plt.imshow(t)\n    plt.axis('off')\n    plt.subplot(144)\n    t = img_b[0].detach().cpu().numpy().transpose(1, 2, 0)\n    t = 0.5 + 0.5 * t\n    plt.imshow(t)\n    plt.axis('off')\n    plt.show()\n        \ndef save_model(model, epoch, name):\n    fp = os.path.join(\"../working/\", name + '.pth')\n    ckpt = {'state_dict': model.state_dict(),\n            'epoch': epoch}\n    torch.save(ckpt, fp)\n        \ndef train(dir_a, dir_b, epochs, b_size=8):\n    data = PairedDataset(dir_a, dir_b)\n    data_loader = DataLoader(data, batch_size=b_size, num_workers=8, \n                              drop_last=True, shuffle=True)\n    \n    gen_ab = GeneratorUNet().cuda()\n    gen_ba = GeneratorUNet().cuda()\n#     gen_ab.load_state_dict(torch.load(\"../working/gen_ab.pth\")['state_dict'])\n#     gen_ba.load_state_dict(torch.load(\"../working/gen_ba.pth\")['state_dict'])\n    disc_a = get_discriminator().cuda()\n    disc_b = get_discriminator().cuda()\n    \n    ecriterion = nn.BCELoss()\n    l2_criterion = nn.MSELoss()\n    l1_criterion = nn.L1Loss()\n    lr = 1e-4\n\n    optimizer_gen_ab = optim.Adam(gen_ab.parameters(), lr=lr,)\n    optimizer_gen_ba = optim.Adam(gen_ba.parameters(), lr=lr,)\n    optimizer_disc_a = optim.Adam(disc_a.parameters(), lr=lr,)\n    optimizer_disc_b = optim.Adam(disc_b.parameters(), lr=lr,)\n    \n    for epoch in range(epochs):\n        img_a, img_b = train_single_epoch(gen_ab, gen_ba, disc_a, disc_b,\n                                          data_loader, b_size, epoch, \n                                          l1_criterion, l2_criterion,\n                                          optimizer_gen_ab, optimizer_gen_ba, optimizer_disc_a, optimizer_disc_b)\n        display_results(img_a, img_b, gen_ab, gen_ba)\n        save_model(gen_ab, epoch, \"gen_ab\")\n        save_model(gen_ba, epoch, \"gen_ba\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython import display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train(\"/kaggle/input/facades-dataset/trainB/\", \n      \"/kaggle/input/facades-dataset/trainA/\", 10, b_size=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gen_ab = GeneratorUNet().cuda()\ngen_ab.load_state_dict(torch.load(\"../working/gen_ab.pth\")['state_dict'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = PairedDataset(\"/kaggle/input/facades-dataset/testB/\", \n                 \"/kaggle/input/facades-dataset/testA/\", 'val')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\n\nfor i in range(3):\n    img_a, img_b = data[i]\n\n    img_a = img_a[None].cuda()\n    fake_b = gen_ab(img_a)\n\n    plt.subplot(3, 2, 2 * i + 1)\n    t = img_a[0].detach().cpu().numpy().transpose(1, 2, 0)\n    t = 0.5 + 0.5 * t\n    plt.imshow(t[..., ::-1])\n    plt.axis('off')\n    plt.subplot(3, 2, 2 * i + 2)\n    t = fake_b[0].detach().cpu().numpy().transpose(1, 2, 0)\n    t = 0.5 + 0.5 * t\n    plt.imshow(t[..., ::-1])\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}