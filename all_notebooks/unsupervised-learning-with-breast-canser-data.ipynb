{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction \nHello people! Welcome to my kernel. In this kernel, I will apply some Unsupervised Learning Algorithms over Breast Canser dataset. In this kernel, I am going to use two different clustering algorithms:\n\n* K-Means Clustering\n* Hierarchial (Agglomerative) Clustering\n\nTherefore, I am going to use SKLearn library. Let's take a look at our schedule.\n\n# Schedule\n1. Importing Libraries and Data\n1. Having Idea About Data\n1. Preprocessing \n1. Unsupervised Learning\n    * K-Means Clustering\n    * Hierarchial (Agglomerative) Clustering\n1. Comparing Labels\n1. Conclusion\n"},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries and Data\n\nIn this section I am going to import libraries and data that I will use."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Having Idea About Data\n\nIn this section I am going to diagnose data, because I can not prepare my dataset for Machine Learning without any idea. In order to diagnose I am going to use head(),tail() and info() functions."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 33 Features in our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 569 rows in our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are not NaN values in our dataset. I am going to drop these features:\n\n* Id \n* Unnamed: 32\n* Diagnosis (Because it is our label)"},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n\nIn this section I am going to prepare data for machine learning. Therefore I am going to start with dropping the features that I have decided in previous section"},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data.copy() \ndata.drop([\"id\",\"Unnamed: 32\",\"diagnosis\"],axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unsupervised Learning\nIn this section I am going to apply clustering algorithms to our dataset. I am going to start with K-Means Algorithm\n\n## K-Means Clustering\n\nIn this sub-section I am going to cluster our dataset using K-Means Algorithm. In order to do this I am going to use SKLearn library. Let's do it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2) # I've chosen n_clusters=2 because there are two classes in our dataset.\nkmeans_labels = kmeans.fit_predict(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our clustering model is ready. I've saved clustering labels in a variable. In the future I am going to add them into our dataset."},{"metadata":{},"cell_type":"markdown","source":"## Hierarchial (Agglomerative) Clustering\n\nIn this sub-section I am going to cluster our dataset using Hierarchial Clustering Algorithm. In order to do this I am going to use SKLearn library again"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\nhier = AgglomerativeClustering(n_clusters=2,affinity=\"euclidean\",linkage=\"ward\")\nhier_labels = hier.fit_predict(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our labels are ready. We are ready to compare labels"},{"metadata":{},"cell_type":"markdown","source":"# Comparing Labels\nIn this section I am going to compare labels. At the start of this section I am going to add K-Means Label and Hier Label features."},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True)\ndata2[\"KMeansLabel\"] = kmeans_labels\ndata2[\"HierLabel\"] = hier_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now I am going to drop all columns except diagnosis and labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"data3 = data2.loc[:,[\"diagnosis\",\"KMeansLabel\",\"HierLabel\"]]\ndata3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Diagnosis = M and Cluster 0 Data Dots: \",len(data3[(data3[\"diagnosis\"]==\"M\") & (data3.KMeansLabel==0) & (data3.HierLabel==0)]))\nprint(\"Diagnosis = M and Cluster 1 Data Dots:\",len(data3[(data3[\"diagnosis\"]==\"M\") & (data3.KMeansLabel==1) & (data3.HierLabel==1)]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(11,7))\nplt.scatter(data2[\"radius_mean\"][data2.KMeansLabel==0],data2[\"texture_mean\"][data2.KMeansLabel==0],color=\"Red\")\nplt.scatter(data2[\"radius_mean\"][data2.KMeansLabel==1],data2[\"texture_mean\"][data2.KMeansLabel==1],color=\"Green\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As you can see, There is not a relation between Cluster and Class\nSo we can say, clustering is not equals classification"},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nI am a beginner in machine learning so I might have mistakes in this kernel. Please tell me my mistakes. But If there are not any mistakes, if you upvote this kernel I would be glad."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}