{"cells":[{"metadata":{"_uuid":"63264524-d408-4bee-ba86-d1fb2037ccf5","_cell_guid":"327d2729-ca0b-4396-acba-7093c268d8ac","trusted":true},"cell_type":"code","source":"#Import Libraries\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n#----------------------------------------------------\n#reading data\ndata = pd.read_csv('../input/diabites-dataset/diabetes.csv')\n\ndata.describe()\n\n#X Data\nX = data.drop(['Outcome'], axis=1, inplace=False)\nprint('X Data is \\n' , X.head())\nprint('X shape is ' , X.shape)\n\n#y Data\ny = data['Outcome']\nprint('y Data is \\n' , y.head())\nprint('y shape is ' , y.shape)\n\n#----------------------------------------------------\n# Cleaning data\n\n\n\n\nImputedModule = SimpleImputer(missing_values = np.nan, strategy ='mean')\nImputedX = ImputedModule.fit(X)\nX = ImputedX.transform(X)\n\n\n#X Data\nprint('X Data is \\n' , X[:10])\n\n#y Data\nprint('y Data is \\n' , y[:10])\n\n#----------------------------------------------------\n#Standard Scaler for Data\n\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(X)\n\n#showing data\nprint('X \\n' , X[:10])\nprint('y \\n' , y[:10])\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#Splitted Data\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)\n\n#----------------------------------------------------\n#Applying RandomForestClassifier Model \n\n\nRandomForestClassifierModel = RandomForestClassifier(criterion = 'gini',n_estimators=100,max_depth=2,random_state=33) #criterion can be also : entropy \nRandomForestClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(X_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(X_test, y_test))\nprint('RandomForestClassifierModel features importances are : ' , RandomForestClassifierModel.feature_importances_)\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(X_test)\ny_pred_prob = RandomForestClassifierModel.predict_proba(X_test)\nprint('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for RandomForestClassifierModel is : ' , y_pred_prob[:10])\n\n#----------------------------------------------------\n#Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))\nAccScore = accuracy_score(y_test, y_pred, normalize=False)\nprint('Accuracy Score is : ', AccScore)\n\n#----------------------------------------------------\n#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)\n#f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n\nF1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('F1 Score is : ', F1Score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}