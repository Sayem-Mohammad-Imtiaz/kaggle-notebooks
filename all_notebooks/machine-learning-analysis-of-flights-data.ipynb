{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","file_extension":".py","mimetype":"text/x-python"}},"nbformat_minor":2,"cells":[{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4afd00d8-9565-44df-af38-6b4943057ec2","_uuid":"cc0f22e755a07273b85f4d75fdeee3a6ba865ca6","collapsed":true},"source":"import pandas as pd\nimport numpy as np\nimport os\nimport random\nimport scipy as sp\nfrom sklearn.metrics import confusion_matrix\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"e96c65af-34da-4632-a7e9-ca641bb7d976","_uuid":"12fac826b0e83045ee458cc260dd45161e1c7385","collapsed":true},"source":"### Load flights data. Can't handle all the data together, so I'm loading a specific number of random lines.\n#I also load only specific columns sincs I think the other columns are not necessary for what I want to do.\nSpecifically, I want to predict whether a flight will be late or not. \n#note: I loaded \"DAY\" column, and later used it to calculate the # of week of the year. I next included this column in my calculations but removed the \"MONTH\" column since together with the \"WEEK\" column it became redundant."},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"7721bab7-1eb8-4bb9-a7a6-79910975e203","_uuid":"02b9708260cd6e1a126646bafef6d01e139d298a","collapsed":true},"source":"# total number of datapoints = 5819078 \n\nn = 5819078\n#skip = sorted(random.sample(range(1,n),n-2000))\nskip = random.sample(range(1,n),n-20000)\nflights = pd.read_csv('../input/flights.csv',skiprows=skip,usecols = ['MONTH','DAY','DAY_OF_WEEK','AIRLINE','ORIGIN_AIRPORT','DESTINATION_AIRPORT','SCHEDULED_DEPARTURE',\n                                                             'DEPARTURE_DELAY','ARRIVAL_DELAY','CANCELLED'],low_memory=False)\nairports = pd.read_csv('../input/airports.csv')\nairlines = pd.read_csv('../input/airlines.csv')\nflights = flights.sample(frac=1).reset_index(drop=True)  # here I randomize rows so that data is not chronologically sorted\n\nall_features = flights.columns.values","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"dd49d76a-edad-4606-b9c8-e361de037717","_uuid":"69676d517b51578a208eff19d1aa523109688c1f"},"source":"### fixing airport data\nSome of the airports were listed using 5 digit numbers instead of 3 letter code. The code below fixes that problem. I used code by Scott Cole as a template for this section (see the link below).\nhttps://www.kaggle.com/srcole/fix-inconsistent-airport-codes"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4def7589-bede-479f-ba3a-8b2c033849ab","_uuid":"8a21b33c80cc854622b3fdcf30663562cb76e917"},"source":"import io\nimport requests\n\nurl1 = \"https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT\"\ns1 = requests.get(url1).content\nurl2 = \"https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT_ID\"\ns2 = requests.get(url2).content\n\naircode1 = pd.read_csv(io.StringIO(s1.decode('utf-8')))\naircode2 = pd.read_csv(io.StringIO(s2.decode('utf-8')))\n\n#aircode1 = pd.DataFrame.from_csv('L_AIRPORT.csv')\n#aircode2 = pd.DataFrame.from_csv('L_AIRPORT_ID.csv')\n\n\n# Format the airport codes\naircode1 = aircode1.reset_index()\naircode2 = aircode2.reset_index()\naircodes = pd.merge(aircode1,aircode2,on='Description')\naircode_dict = dict(zip(aircodes['Code_y'].astype(str),aircodes['Code_x']))\n\n# Make sure all Origin and departing airports are strings\nflights['ORIGIN_AIRPORT'] = flights['ORIGIN_AIRPORT'].values.astype(str)\nflights['DESTINATION_AIRPORT'] = flights['DESTINATION_AIRPORT'].values.astype(str)\n\nfor i in range(len(flights)):\n    if len(flights['ORIGIN_AIRPORT'][i]) != 3:\n        to_replace = flights['ORIGIN_AIRPORT'][i]\n        value = aircode_dict[flights['ORIGIN_AIRPORT'][i]]\n        flights = flights.replace(to_replace, value)\nfor i in range(len(flights)):\n    if len(flights['DESTINATION_AIRPORT'][i]) != 3:\n        to_replace = flights['DESTINATION_AIRPORT'][i]\n        value = aircode_dict[flights['DESTINATION_AIRPORT'][i]]\n        flights = flights.replace(to_replace, value)","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"3dc3bc02-ac42-4c45-ab97-8e094aa390c6","_uuid":"6d6acbdcfc41378165e72dc15ecbbd3c6cd1f89c"},"source":"# Enter the name of the airport\nLimid the analysis to the specific airport to improve results and reduce processing time."},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"261fdc6f-ac0d-4628-a572-696e60244798","_uuid":"0bc58706e4ea55af8b0b17f65bb5d57a24ac3fe6","collapsed":true},"source":"Depart_airport = str(input(\"Specify the departure airport (three letters) or put ALL:  \")).upper()\nif Depart_airport in list(flights['ORIGIN_AIRPORT']):\n    flights = flights[flights['ORIGIN_AIRPORT']== Depart_airport]\nelif Depart_airport == 'ALL':\n    print('Analyzing all airports')\nelse:        \n    print(\"incorrect airport code\")\n#flights = flights[flights['ORIGIN_AIRPORT']=='LAS']","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"e1012191-e4b7-487c-93f2-226ce3e53d96","_uuid":"74c388690bf9c072110683c48ef29272f10c4a49"},"source":"## Creating a column describing whether the flight was late to arrivelate or got cancelled\nAgain, for simplicity, I decided to combine these two features. I also chose 60min threshhold arbitrarily"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"7c10cd6b-9727-4abe-a076-5107ead495e6","_uuid":"2c18995217afbced87c41515ab31ae0123d80c10","collapsed":true},"source":"def late_or_cancelled(x):\n#    if x['ARRIVAL_DELAY'] > 60:\n    if x['CANCELLED'] == 1 or x['ARRIVAL_DELAY'] > 60:\n        return 1\n    else:\n        return 0\n\nflights['late or cancelled'] = flights.apply(late_or_cancelled,axis = 1)\nflights = flights[flights['CANCELLED']==0]\n#predictions = flights.apply(late_or_cancelled,axis = 1)","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"807b6915-684d-4fc9-8f0c-68530b57b7ce","_uuid":"08f9d193a17f4b563719dc95de5faaeb72142796"},"source":"# A function to change column Day from 1-31 to 1-365\nLater I will change this into a week of year. The reason is that individual days will be too much to account for since they will give 365 columns in the end, while the week of year will give only 52. This could also be too much, but I'll see. Technically I could even remove the month since the week of a year will account for the month as well."},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"9428718c-ba11-4870-a565-969fcb796554","_uuid":"e13489ee4d08bb5037b8dcdffe6f890fead8f19c","collapsed":true},"source":"days_in_month = np.array([31,28,31,30,31,30,31,31,30,31,30,31])\ndef day_31_to_365(x):\n    days_365 = days_in_month[:x['MONTH']-1].sum() + x['DAY']\n    return days_365","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"4a8635f3-e024-49c3-9d3b-c46330ad4739","_uuid":"0f3ecbb7a9e650022db35b24ee17f59a125c8876"},"source":"# Calculate the number of week and use it instead of month\nMONTH column becomes redundant after adding the column for week"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"2706b299-b313-411f-af8f-58ea76b9c206","_uuid":"8252706529ea297e746a5df507e5bcd21e48377a","collapsed":true},"source":"flights['DAY'] = flights.apply(day_31_to_365,axis = 1)\nflights['WEEK'] = flights['DAY']//7\ndel flights['DAY']","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"1a6aa64a-9dfb-426c-b8c0-e4319c371e74","_uuid":"bcc6a4dbc4af1dc1d746252f1d52b49c88d021f3"},"source":"## Since departure time is a categorical feature, I will devide it into 4 different sections\nI will devide it into 6 hour sections stating with midnight"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"5c7162c6-b7c5-48b5-a8f4-5dc6fadedb42","_uuid":"e7d8c9d54b5378e2b481c5f496fbfb1afe8ef501","collapsed":true},"source":"flights['SCHEDULED_DEPARTURE'] = np.ceil(flights['SCHEDULED_DEPARTURE']/600).apply(int)","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"c9be2c18-40cd-4785-b986-0c4f658b25ba","_uuid":"d260d7433cba2600fd17ec740fc86d65bc42d0c3"},"source":"## Getting rid of unnecessary data"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"51b82e38-cd09-47af-b6ab-bd6f197c9d8e","_uuid":"0023a7d694fd2573564631fa63e371f34d5795d8","collapsed":true},"source":"del flights['ARRIVAL_DELAY']\ndel flights['DEPARTURE_DELAY']\ndel flights['CANCELLED']","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"af0461a8-e8cb-4a4d-973c-6e3925e7a1c3","_uuid":"0c2d9d14ccf1634496d7d18664f1ec6aab648c4f"},"source":"## Plotting being late or not vs different features"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"1f8eaac1-07d1-4026-a8d4-80035f290946","_uuid":"c83a1ad107fecc3644f4e3bb63d5b564efe0d2b3","collapsed":true},"source":"Delay_vs_Day_of_Week = pd.DataFrame({'delays' : flights.groupby(['DAY_OF_WEEK'])['late or cancelled'].mean()}).reset_index()\nDelay_vs_WEEK = pd.DataFrame({'delays' : flights.groupby(['WEEK'])['late or cancelled'].mean()}).reset_index()\nDelay_vs_AIRLINE = pd.DataFrame({'delays' : flights.groupby(['AIRLINE'])['late or cancelled'].mean()})#.reset_index()\nDelay_vs_SCHEDULED_DEPARTURE = pd.DataFrame({'delays' : flights.groupby(['SCHEDULED_DEPARTURE'])['late or cancelled'].mean()}).reset_index()\n\n#Delay_vs_Day_of_Week.plot(x='DAY_OF_WEEK', y='delays')\n#Delay_vs_Day_of_Week['delays'].hist(hold=None)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"5d4b718f-e5a6-4fdd-9c21-6748b76f8164","_uuid":"8f391b901b4bca9bec4933721285d7110b0c52b7","collapsed":true},"source":"fig = plt.figure(figsize=(18.5, 12.5))\n\nsub1 = fig.add_subplot(221) # instead of plt.subplot(2, 2, 1)\nsub1.set_title('Week of Year', fontsize=18, color=\"blue\")\nsns.barplot(x=\"WEEK\", y=\"delays\", data=Delay_vs_WEEK, palette=\"Blues_d\", ax = sub1)\nsub1.set_xticks(list(range(0,52,10)))\nsub1.set_xticklabels(list(range(0,52,10)))\n\nsub2 = fig.add_subplot(222)\nsub2.set_title('Day of Week', fontsize=18, color=\"blue\")\nsns.barplot(x=\"DAY_OF_WEEK\", y=\"delays\", data=Delay_vs_Day_of_Week, palette=\"Blues_d\", ax = sub2)\nsub2.set_xticklabels(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])\n\nsub3 = fig.add_subplot(223)\nsub3.set_title('Airline', fontsize=18, color=\"blue\")\nsns.barplot(y = list(range(len(Delay_vs_AIRLINE))), x=Delay_vs_AIRLINE['delays'], palette=\"Blues_d\", ax = sub3, orient=\"h\")\nsub3.set_yticks(range(len(Delay_vs_AIRLINE)))\nsub3.set_yticklabels(Delay_vs_AIRLINE.index)\n\nsub4 = fig.add_subplot(224)\nsns.barplot(x = list(range(len(Delay_vs_SCHEDULED_DEPARTURE))), y=Delay_vs_SCHEDULED_DEPARTURE['delays'], palette=\"Blues_d\", ax = sub4)\nsub4.set_title('Scheduled Departure Time', fontsize=18, color=\"blue\")\nsub4.set_xticks([0, 1, 2, 3])\nsub4.set_xticklabels(['00:00 - 06:00','06:00 - 12:00','12:00 - 18:00','18:00 - 00:00'])\n","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"96c14715-80cb-4ed6-a87d-9ccf4b205b5a","_uuid":"be3b90ea6829e04a1372077523cc8776cea3c71f"},"source":"# Removing flights from not major airports (Currently disabled)\nThis section allows to use the data from a specific number of airports, allowing to exclude for example airports with low number of flights which could mess with the statistics.\n\n## This section is not currently being used for my calculations"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd3f79fb-2ed5-47d1-ae6b-cdd641d6d579","_uuid":"6d34d2cd92fa658970fb7d4bb6a90ba8fb2a1e27"},"source":"max_Airports = 15  # max number of airports to be analyzed\nORIGIN_AIRPORTs = set(flights.groupby(['ORIGIN_AIRPORT'])['late or cancelled'].sum().sort_values(ascending=False)[0:max_Airports].index.tolist())\nDESTINATION_AIRPORT = set(flights.groupby(['DESTINATION_AIRPORT'])['late or cancelled'].sum().sort_values(ascending=False)[0:max_Airports].index.tolist())\nairports = ORIGIN_AIRPORTs | DESTINATION_AIRPORT\n\nprint(flights.shape)\n\n#flights = flights[(flights['ORIGIN_AIRPORT'].isin(airports))]# & (flights['DESTINATION_AIRPORT'].isin(airports))]"},{"cell_type":"markdown","metadata":{"_cell_guid":"f1109f56-78a7-474e-a7b6-96e7aa736cab","_uuid":"144a6ecfa561a14c01d3135a2ce35fed7978cfe6"},"source":"## Correcting for a bias in being late vs not being late\nTypically, there is much higher number of flights which were not late or cancelled than the ones that were. This creates an imbalance later when trying to classify or fit the data. So I'm getting rid of random rows where the plane was not late.\nThis way the number of rows where flights['late or cancelled']=1 or not is approximately the same. This should make predictions more accurate."},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"c87cec04-074c-42de-9a90-c0ce5fdd80d0","_uuid":"0d74d359cadc01805a90c62343feb97a76e1f577","collapsed":true},"source":"num_late = sum(flights['late or cancelled'])\n\nflights_on_time = flights[flights['late or cancelled']==0]\n\nflights_orig = flights.copy()\n\nflights_on_time = flights_on_time.sample(frac=num_late/flights.shape[0]).reset_index(drop=True)\nflights_on_time.shape\nflights = pd.concat([flights[flights['late or cancelled']==1],flights_on_time])\nflights = flights.sample(frac=1).reset_index(drop=True)","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"c142c7ba-d77c-472a-924a-1bf4ec5f2674","_uuid":"4947ba48767be4276fe80ddf69537ecd9f97052d","collapsed":true},"source":"## Converting categorical values to sparce matrixes\nAt this point, all of the features are categorical, so I need to convert them into sparce matrixes using LabelBinarizer.\nI tried to do this using pipelines, but it didn't quite work. Apparently, eventhough fit_transform was working just fine for the pipeline, just fit didn't work. I need just fit alone so that later I can apply it to data for which I'll want to make a prediction."},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"c4500a91-07b6-401e-9778-7c745438bf2c","_uuid":"2805a883d6742d8d4243b45f2fe359d25a5b8c67","collapsed":true},"source":"from sklearn.preprocessing import LabelBinarizer\n\nWEEK_LabBin = LabelBinarizer()\nWEEK_LabBin.fit(flights_orig['WEEK'])\nWEEK_binarized = np.array(WEEK_LabBin.transform(flights['WEEK']))\nWEEK_binarized_orig = np.array(WEEK_LabBin.transform(flights_orig['WEEK']))\n\n\nDAY_OF_WEEK_LabBin = LabelBinarizer()\nDAY_OF_WEEK_LabBin.fit(flights_orig['DAY_OF_WEEK'])\nDAY_OF_WEEK_binarized = np.array(DAY_OF_WEEK_LabBin.transform(flights['DAY_OF_WEEK']))\nDAY_OF_WEEK_binarized_orig = np.array(DAY_OF_WEEK_LabBin.transform(flights_orig['DAY_OF_WEEK']))\n\n\nAIRLINE_LabBin = LabelBinarizer()\nAIRLINE_LabBin.fit(flights_orig['AIRLINE'])\nAIRLINE_binarized = np.array(AIRLINE_LabBin.transform(flights['AIRLINE']))\nAIRLINE_binarized_orig = np.array(AIRLINE_LabBin.transform(flights_orig['AIRLINE']))\n\n\nORIGIN_AIRPORT_LabBin = LabelBinarizer()\nORIGIN_AIRPORT_LabBin.fit(flights_orig['ORIGIN_AIRPORT'])\nORIGIN_AIRPORT_binarized = np.array(DAY_OF_WEEK_LabBin.transform(flights['ORIGIN_AIRPORT']))\nORIGIN_AIRPORT_binarized_orig = np.array(DAY_OF_WEEK_LabBin.transform(flights_orig['ORIGIN_AIRPORT']))\n\n\nDESTINATION_AIRPORT_LabBin = LabelBinarizer()\nDESTINATION_AIRPORT_LabBin.fit(flights_orig['DESTINATION_AIRPORT'])\nDESTINATION_AIRPORT_binarized = np.array(DESTINATION_AIRPORT_LabBin.transform(flights['DESTINATION_AIRPORT']))\nDESTINATION_AIRPORT_binarized_orig = np.array(DESTINATION_AIRPORT_LabBin.transform(flights_orig['DESTINATION_AIRPORT']))\n\n\nSCHEDULED_DEPARTURE_LabBin = LabelBinarizer()\nSCHEDULED_DEPARTURE_LabBin.fit(flights_orig['SCHEDULED_DEPARTURE'])\nSCHEDULED_DEPARTURE_binarized = np.array(SCHEDULED_DEPARTURE_LabBin.transform(flights['SCHEDULED_DEPARTURE']))\nSCHEDULED_DEPARTURE_binarized_orig = np.array(SCHEDULED_DEPARTURE_LabBin.transform(flights_orig['SCHEDULED_DEPARTURE']))\n\n\n# flights_binarized will contain all data in sparce matrix form\nflights_binarized = np.concatenate((WEEK_binarized,DAY_OF_WEEK_binarized,AIRLINE_binarized,ORIGIN_AIRPORT_binarized,\n                                    DESTINATION_AIRPORT_binarized,SCHEDULED_DEPARTURE_binarized),axis=1)\nflights_binarized_orig = np.concatenate((WEEK_binarized_orig,DAY_OF_WEEK_binarized_orig,AIRLINE_binarized_orig,ORIGIN_AIRPORT_binarized_orig,\n                                    DESTINATION_AIRPORT_binarized_orig,SCHEDULED_DEPARTURE_binarized_orig),axis=1)\n\nprint(flights_binarized.shape)\nprint(flights_binarized_orig.shape)\n","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"3d473dcc-9a57-4177-a5cd-ec3311663335","_uuid":"6650ef226fdd37a8db1130b5783033dd07cad9f8"},"source":"# split into test and training set"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"9325708e-d356-4a50-9dc5-f41b03093956","_uuid":"7bd0e470a0827a0de642fdfb809d1c1f91f306c6","collapsed":true},"source":"# splitting data into test and training sets\nfrom sklearn.model_selection import train_test_split\n\ntrain_set, test_set, train_set_target, test_set_target = train_test_split(flights_binarized, flights['late or cancelled'], test_size = 0.4, random_state=42)","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"db0a6391-7e50-4268-8d1b-aa85ad23c2a7","_uuid":"e8fd97c4e765c9c1dd8e27de6e2263d56386890e"},"source":"# Random forest search"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"f2b7c16c-0204-4ac1-ad15-2b92ef7ce0da","_uuid":"cb2e475e0970f9cd8c5f071bb98d789c82aaad47","collapsed":true},"source":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor(n_jobs=-1)\nforest_reg.fit(train_set,train_set_target)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"f37c2b17-d793-48a3-ae16-9c7653ccc95b","_uuid":"3921c81e291bda658e409e0bd1706e6381c0a8fe","collapsed":true},"source":"confusion_matrix(train_set_target,(forest_reg.predict(train_set)).round())","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"a4f72c0a-ae0e-4787-8451-44263ff00767","_uuid":"ff99682b53c9e44ec5c8d8874a32197925af7cb1","collapsed":true},"source":"confusion_matrix(test_set_target,(forest_reg.predict(test_set)).round())","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"4bc39ac5-7f31-40a1-88b5-bc5220a87e70","_uuid":"3533050b8c0e348a7982c4db0554721d3d234471"},"source":"# GridSearch for RandomForest\nRandom Forest did the best so far, so I'll try gridsearch to get the best conditions for random forest model\n#if I use all of the data instead of a single airport, the best numbers were [{'n_estimators': [150],'max_features':[50],'max_depth':[30]}]"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"32bc7d02-129b-4143-abf2-2f2a3b50682d","_uuid":"8c460b7406b7b9993528424482625faaf21b5eba","collapsed":true},"source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [{'n_estimators': [75, 100],'max_features':[10, 20],'max_depth':[20, 30]}]\nforest_reg = RandomForestRegressor(n_jobs=-1)\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(train_set,train_set_target)","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"6710f768-36f7-4f7d-8491-17504b49a5b3","_uuid":"cf1203fb97382c04fd5057dc7b72a01f4eece5cd"},"source":"# Use PICKLE to save results of the grid search"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"0c8f0bf0-3eb4-4faf-86a9-a0494ae4b0c0","_uuid":"244d8571926a34fc879ede6b74e3d04168fa9b9d","collapsed":true},"source":"import pickle\n\nfilename = 'finalized_model.sav'\npickle.dump(grid_search, open(filename, 'wb'))\n\n#loaded_model = pickle.load(open(filename, 'rb'))\n#result = loaded_model.score(X_test, Y_test)","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"0e529f21-e6fe-4992-8502-e926ccdebdab","_uuid":"014478860197e2a22ba66e18eb4740040eeeb548"},"source":"# Confusion Matrix for Training set"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"175051d5-2dd4-42bd-8d2a-7331a5e0d99d","_uuid":"27575364074c5b78993ec8f63e350c2d0ec0726a","collapsed":true},"source":"# confusion matrix for training set\nconfusion_matrix(train_set_target,(grid_search.predict(train_set)).round())","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"412d1a01-8890-4d43-ab9e-c93075a15ae1","_uuid":"3801cb2702a7eaff6b2e4549f1ef288940fda54e","collapsed":true},"source":"grid_search.best_estimator_","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"541312c7-911a-4ba6-a94a-0d3a43b239e6","_uuid":"1aa95043a6ac5e111456cedc0dca6182ffa6571b"},"source":"# Confusion Matrix for Test set"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"89301052-995e-4f95-bf2f-60482be6b13e","_uuid":"97c2647a99deca5d7ec909fa1a0b4530a7d56e30","collapsed":true},"source":"# confusion matrix for test set\nconfusion_matrix(test_set_target,(grid_search.predict(test_set)).round())","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"44cf1efd-e416-4179-ad9b-ea70b2e0dad9","_uuid":"18258cb46f18b49177ee1172c5718c4775ace8a0","collapsed":true},"source":"predictions = grid_search.predict(train_set)\ngrid_reg_results = pd.DataFrame({'True':train_set_target, 'predict':predictions})"},{"cell_type":"markdown","metadata":{"_cell_guid":"eaad4f58-aa0b-42d4-a1b0-cc7c04cc6d7d","_uuid":"c610cdda58eead2252a283a35e26a61a025750d5"},"source":"grid_reg_results[grid_reg_results['predict']>0.8]['True'].sum()/grid_reg_results[grid_reg_results['predict']>0.8]['True'].shape[0]"},{"cell_type":"markdown","metadata":{"_cell_guid":"135436b9-b9d3-46a0-b2ee-6def8a803e7e","_uuid":"580853c497e3761295c9f7b89eaa60587525545c"},"source":"# Create column \"Comparison\" to show which results is true/false pos/neg\nTrue pos = 1, True neg = 2, False pos = 3, false neg = 4"},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"2cde0718-ea7b-4f0c-aa6b-541a86d77fe4","_uuid":"30772f41ddf2058f817df444e6b43ee7e8f8f0ff","collapsed":true},"source":"def comparison_col(x):\n    # True pos = 1, True neg = 2, False pos = 3, false neg = 4\n    if (x['True'] == 1) & (x['predict'] > 0.5):\n        return 1\n    elif (x['True'] == 0) & (x['predict'] < 0.5):\n        return 2\n    elif (x['True'] == 0) & (x['predict'] > 0.5):\n        return 3\n    elif (x['True'] == 1) & (x['predict'] < 0.5):\n        return 4","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"5261bcac-9530-495c-9fb0-3ade141dbafd","_uuid":"38848e3d282ac65316a1e7ec63017ec6e1eabffb","collapsed":true},"source":"predictions = grid_search.predict(train_set)\ngrid_reg_results = pd.DataFrame({'True':train_set_target, 'predict':predictions})\n\ngrid_reg_results['Comparison'] = grid_reg_results.apply(comparison_col, axis = 1)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"993b24b6-9c8f-4bc3-8714-d0bf7913a065","_uuid":"51b7efc74a9ffb351ae4ed90f252d5166772053f","collapsed":true},"source":"fig = plt.figure(figsize=(18.5, 10.5))\nsub1 = fig.add_subplot(211) # instead of plt.subplot(2, 2, 1)\nsub1.set_title('ALL True predictions (including incorrect ones)', fontsize=18, color=\"blue\")\nsub1.hist(grid_reg_results[grid_reg_results['True']==1]['predict'],alpha=0.7, bins=31)\nsub1.set_xlim([0, 1])\n\nsub2 = fig.add_subplot(212)\nsub2.set_title('ALL False predictions (including incorrect ones)', fontsize=18, color=\"blue\")\nsub2.hist(grid_reg_results[grid_reg_results['True']==0]['predict'],alpha=0.7, bins=31)\nsub2.set_xlim([0, 1])","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"adc3adf8-6fcf-4d21-8b9e-1f995b2c6891","_uuid":"e53939595dba02da60448ac0850e4a688f0d66d3"},"source":"# Plotting histograms of my results\nBlue color shows correctly predicted results, orange shows incorrect predictions."},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"7f3a915f-3bfa-40a6-ae7b-fb5be5116052","_uuid":"bc2a6439afea910dbf1d35e27edef4c57883283b","collapsed":true},"source":"plt.hist(grid_reg_results[grid_reg_results['Comparison'].isin([1,2])]['predict'],alpha=0.7, bins=30,label='Correct',color='c')\nplt.hist(grid_reg_results[grid_reg_results['Comparison'].isin([3,4])]['predict'],alpha=0.7, bins=30,label='Incorrect',color='m')\nplt.legend(loc='upper left')\nplt.title('Training Data')","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4719a756-d0b2-4759-af48-a6b736511e08","_uuid":"95e3f63f762613d0d8512c253ae46644919ecf22","collapsed":true},"source":"test_predictions = grid_search.predict(test_set)\ntest_grid_reg_results = pd.DataFrame({'True':test_set_target, 'predict':test_predictions})\ntest_grid_reg_results['Comparison'] = test_grid_reg_results.apply(comparison_col, axis = 1)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"27860421-76c8-4236-92ee-273e4f9bf3f8","_uuid":"2f3766aae46df30dfd00e1c762be9bd7404a750b","collapsed":true},"source":"plt.hist(test_grid_reg_results[test_grid_reg_results['Comparison'].isin([1,2])]['predict'],alpha=0.7, bins=30,label='Correct',color='c')\nplt.hist(test_grid_reg_results[test_grid_reg_results['Comparison'].isin([3,4])]['predict'],alpha=0.7, bins=30,label='Incorrect',color='m')\nplt.legend(loc='upper left')\nplt.title('Test Data')","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"3f652038-4622-418c-9a5c-36949a86d844","_uuid":"27b6803ed04824b1618d49b0e29b9d1a65e66692","collapsed":true},"source":"from sklearn.metrics import roc_curve, auc\n\nfpr_rf, tpr_rf, _ = roc_curve(test_set_target, test_predictions)\n\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_rf, tpr_rf, label='RF')\nplt.title('ROC Curve for Test Data')","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"79763e10-3ba0-4c24-9857-45a8d9766b1c","_uuid":"38e3392ed9c91aa2d84f335ebd3749e9e9559d30"},"source":"# modifying original flights data before balancing late vs. not_late\nEarlier I exluded big chunk of data to correct for bias, but now I want to see how my predictions look for all the data together. "},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"eadf54dd-dccf-4847-9113-2477820833bf","_uuid":"a9318cfb2249b3252655e1bcac35ed2810ebb84b","collapsed":true},"source":"orig_predictions = grid_search.predict(flights_binarized_orig)\norig_target = flights_orig['late or cancelled']\norig_grid_reg_results = pd.DataFrame({'True':orig_target, 'predict':orig_predictions})\norig_grid_reg_results['Comparison'] = orig_grid_reg_results.apply(comparison_col, axis = 1)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"a066ca96-19c4-4c67-8173-38cfeecf10c9","_uuid":"1df94c42b90ac6a8de86168170218bfe39d6ee9b","collapsed":true},"source":"fig = plt.figure(figsize=(18.5, 10.5))\nsub1 = fig.add_subplot(211) # instead of plt.subplot(2, 2, 1)\nsub1.set_title('Full Data - Positive predictions only', fontsize=18, color=\"blue\")\nsub1.hist(orig_grid_reg_results[orig_grid_reg_results['Comparison'].isin([1])]['predict'],alpha=0.7, bins=30,label='True Positive',color='c')\nsub1.hist(orig_grid_reg_results[orig_grid_reg_results['Comparison'].isin([3])]['predict'],alpha=0.7, bins=30,label='False Positive',color='m')\n#sub1.set_xlim([0, 1])\n\nsub2 = fig.add_subplot(212)\nsub2.set_title('Zoomed-in', fontsize=18, color=\"blue\")\nsub2.hist(orig_grid_reg_results[orig_grid_reg_results['Comparison'].isin([1])]['predict'],alpha=0.7, bins=30,label='True Positive',color='c')\nsub2.hist(orig_grid_reg_results[orig_grid_reg_results['Comparison'].isin([3])]['predict'],alpha=0.7, bins=30,label='False Positive',color='m')\nsub2.set_ylim([0, 200])\n#sub1.set_xlim([0, 1])","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"3bebfbc5-fc80-4b3d-b220-36d733e67fed","_uuid":"683f27495efae5a85197a6fa8c093849acb7a39a","collapsed":true},"source":"confusion_matrix(orig_target,(orig_predictions).round())","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"93e1952a-c556-4fae-867c-e83b7a1317b1","_uuid":"8d4de7e62b95b050b0851dbeda5e3b0f94e8c893","collapsed":true},"source":"from sklearn.metrics import roc_curve, auc\n\nfpr_rf, tpr_rf, _ = roc_curve(orig_target, orig_predictions)\n\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_rf, tpr_rf, label='RF')\nplt.title('ROC Curve for Full Data')","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"5157ab95-95a4-4aea-8631-953e727e26ca","_uuid":"a49f2fe154363e1cfcfc50dad6aac549f2012a6e","collapsed":true},"source":"# Short Summary\nWhile the ROC curve looks quite good, you can see from the histogram of the full data that the since there is much higher number of instances where the flights were neither delayed more than an hour, not cancelled (as expected), it is hard to make good predictions. It can also be seen in the confusion matrix.\n\nNevertheless, this script can be used to alert passengers regarding higher-than-usual chance of their flights being delayed to cancelled by using predictions with score higher than 0.85."},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"8952d1d6-e9c9-4b2a-ba3a-2b25f454fc6b","_uuid":"69c4b1a4a128dce32653a2b50d28337e90aa76df","collapsed":true},"source":"","outputs":[]}],"nbformat":4}