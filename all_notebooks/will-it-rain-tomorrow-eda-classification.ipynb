{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color:lightblue\">**Will it rain tomorrow?**</span>\n\n<iframe src=\"https://giphy.com/embed/KatjlSAMx0K9zdHMR4\" width=\"480\" height=\"347\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/tcm-vintage-turner-classic-movies-gene-kelly-KatjlSAMx0K9zdHMR4\">via GIPHY</a></p>\n\n#### Context\nPredict whether or not it will rain tomorrow by training a binary classification model \n\n#### Content\nThis dataset contains daily weather observations from numerous Australian weather stations such as Rainfall, Wind and Humidity."},{"metadata":{},"cell_type":"markdown","source":"### Variable Descriptions:\n\n* ** RainTomorrow: The target variable. Did it rain the following day? YES/NO**\n\n* Date: The date of observation\n* Location: The common name of the location of the weather station\n* MinTemp: The minimum temperature in degrees celsius\n* MaxTemp: The maximum temperature in degrees celsius\n* Rainfall: The amount of rainfall recorded for the day in mm\n* Evaporation: The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n* Sunshine: The number of hours of bright sunshine in the day.\n* WindGustDir: The direction of the strongest wind gust in the 24 hours to midnight\n* WindGustSpeed: The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n* WindDir9am: Direction of the wind at 9am\n* WindDir3p: Direction of the wind at 3pm\n* WindSpeed9am: Wind speed (km/hr) averaged over 10 minutes prior to 9am\n* WindSpeed3pm: Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n* Humidity9a: Humidity (percent) at 9am\n* Humidity3pm: Humidity (percent) at 3pm\n* Pressure9am: Atmospheric pressure (hpa) reduced to mean sea level at 9am\n* Pressure3pm: Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n* Cloud9am: Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast.\n* Cloud3pm: Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n* Temp9am: Temperature (degrees C) at 9am\n* Temp3pm: Temperature (degrees C) at 3pm\n* RainToday: Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n* RISK_MM: The amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the \"risk\". Will be left out in the model.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries and magic functions\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n%config InlineBackend.figure_format ='retina'\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read data\ndf = pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Cleaning & Manipulation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()\nprint(\"The size of the dataframe is:\",df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for null values\ndf_missing = df.isnull().sum()\ndf_missing\n\n# calculate the % of missing values\nperc_missing = round(100*(df_missing/len(df)),2)\nperc_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping columns with large % of missing values - also dropping RISK_MM based on instructions in the description\n\ndf_dropped = df.drop(['Evaporation','Sunshine','Cloud9am','Cloud3pm','RISK_MM'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dropped.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we are dropping the remaining rows with nan values\n\ndf_dropped = df_dropped.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dropped.head()\nprint(\"The new size of the dataframe is:\", df_dropped.shape)\nprint(\"We deleted\",df.shape[0]-df_dropped.shape[0],\"rows and\", df.shape[1]-df_dropped.shape[1],\"columns.\")\ndf_dropped.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change date type to datetime\n\ndf_dropped['Date'] = pd.to_datetime(df_dropped['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding columns Year and Month\n\ndf_dropped['Year'] = pd.to_datetime(df_dropped['Date']).dt.year\ndf_dropped['Month'] = pd.to_datetime(df_dropped['Date']).dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set Date as index\n\ndf_dropped.set_index('Date', inplace=True)\ndf_dropped.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting rainfall during time\nplt.figure(figsize=(20,5))\ndf_dropped['Rainfall'].plot()\nplt.box(False)\nplt.title ('Rainfall throughout the Years',fontweight=\"bold\", fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting Rainfall per Month\nplt.figure(figsize=(8,5))\nsns.barplot(x = 'Month', y='Rainfall', data=df_dropped, color = 'skyblue')\nplt.box(False)\nplt.title ('Rainfall throughout Months', fontweight=\"bold\",fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting average Rainfall by Location\ndf_loc = df_dropped.groupby('Location').agg({'Rainfall':'mean'}).sort_values(by='Rainfall', ascending=False) \n\ndf_loc.plot(kind='bar',figsize=(20,5))\nplt.box(False)\nplt.title ('Average Rainfall by Location', fontsize=15, fontweight=\"bold\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Temperature and Rainfall\n\nfig, (ax1,ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.despine(left=True)\nsns.scatterplot(x='MinTemp', y='Rainfall', data=df_dropped, ax=ax1)\nax1.set_title(\"Lowest Temperature and Amount of Rainfall\",fontweight=\"bold\")\nsns.scatterplot(x='MaxTemp', y='Rainfall', data=df_dropped, color=\"tomato\", ax=ax2)\nax2.set_title(\"Highest Temperature and Amount of Rainfall\",fontweight=\"bold\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation for ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming Dataframe for the Machine Learning Part\ndf_ML = df_dropped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping columns that we do not need for the model building part\ndf_ML = df_ML.drop(['Location','Year'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adjusting the Target Variables' values: Yes/No with 1/0\ndf_ML = df_ML.replace({'RainTomorrow':'Yes','RainToday':'Yes'},1)\ndf_ML = df_ML.replace({'RainTomorrow':'No','RainToday':'No'},0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dummies for categorical variables\ndf_ML = pd.get_dummies(df_ML, prefix = ['WindDir3pm','WindDir9am','WindDir3pm'])\n\ndf_ML.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation\n# Create Correlation mask >0.5:\ndf_ML_corr = df_ML.corr()\ncondition = abs(df_ML.corr()) > 0.5\n#df_ML_corr[condition]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# heatmap\n# correlation plot\nplt.figure(figsize=(20,20))\nsns.heatmap(df_ML.corr(), cmap = 'Wistia')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping highly correlated columns\n\ndf_ML = df_ML.drop(['WindGustSpeed','Humidity9am',], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardize our Data - Feature Scaling 0-1 scale \n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1)) \n\n#assign scaler to column:\ndf_scaled = pd.DataFrame(scaler.fit_transform(df_ML), columns=df_ML.columns)\n\ndf_scaled.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selection of the most important features using SelectKBest\nfrom sklearn.feature_selection import SelectKBest, chi2\n\nX = df_scaled.loc[:,df_scaled.columns!='RainTomorrow']\ny = df_scaled[['RainTomorrow']]\n\nselector = SelectKBest(chi2, k=5)\nselector.fit(X, y)\n\nX_new = selector.transform(X)\nprint(\"The 5 most important features are:\", X.columns[selector.get_support(indices=True)]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a new dataframe with the most important features\n\ndf_new = df_scaled[['Rainfall', 'Humidity3pm','WindDir9am_E', 'WindDir9am_N','RainToday','RainTomorrow']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the Target variables' distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['RainTomorrow'].value_counts()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Percentage_No = df_new['RainTomorrow'].value_counts()[0]/len(df_new['RainTomorrow'])*100\nPercentage_Yes = df_new['RainTomorrow'].value_counts()[1]/len(df_new['RainTomorrow'])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the distribution of our target variable \nprint(df_new['RainTomorrow'].value_counts())\n\nprint(\"Percentage Occurences of No Rain on the following day:\", round(Percentage_No,2),\"%\")\nprint(\"Percentage Occurences of Rain on the following day:\", round(Percentage_Yes,2),\"%\")\n\nsns.countplot(df_new['RainTomorrow'])\nplt.title('Balance target',fontsize=15, fontweight='bold')\nplt.box(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that the distribution between the two outcomes Rain on the following day and No Rain on the following day is unbalanced. This can lead to a biased result. Therefore we will balance the outcome variable in the next step while splitting the training ans testing data using the stratify argument.**\n"},{"metadata":{},"cell_type":"markdown","source":"### Train-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# clarify what is y and what is X\ny = df_new['RainTomorrow']\nX = df_new.drop(['RainTomorrow'], axis = 1)\n\n# Train-Test Split 80-20\n# Note: We use stratify = y here because we have an unbalanced Dataset and we want to sample equal occurences of the target variable outcomes\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,stratify = y)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Choosing the best Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Model Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport time\n\nclassifiers = [LogisticRegression(),DecisionTreeClassifier(),KNeighborsClassifier(2)]\n\nfor classifier in classifiers:\n    t0=time.time()\n    pipe = Pipeline(steps=[('classifier', classifier)])\n    pipe.fit(X_train, y_train)   \n    score = pipe.score(X_test, y_test)\n    print(f\"The accuracy score is: {round(score,2)*100}%\")\n    print('Time taken to execute:' , time.time()-t0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We get the best accuracy score with the Logistic Regression Model with 84%. The Decision Tree Algorithm is slightly faster but only scores 83%.KNN performs worse and is comparatable slow.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}