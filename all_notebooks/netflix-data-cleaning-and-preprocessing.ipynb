{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Netflix: Movies and TV Shows (preprocessing and cleaning)**\n \nThe purpose of this notebook is to cleanse the comma-separated values into tables for __unique actors, directors, countries, and genres__. Then we'll analyze the reshaped dataset in case to find any interesting patterns and try to satisfy the task's expectations. \n\n**Task Details:**\nAs mentioned above,  columns in this dataset have comma-separated values, which makes it difficult to find how many titles an actor or actress appeared in or how many titles a director has filmed.\n\n**Expected Submission:**\nCleanse the comma-separated values into tables for unique actors, directors, countries, and genres that can be linked back to the original dataset via the **\"show_id\"** field.","metadata":{}},{"cell_type":"code","source":"# Import packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.preprocessing import TransactionEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import dataset\ndf = pd.read_csv('../input/netflix-shows/netflix_titles.csv')\n\n# Observe dataset\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect dataset\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for null values\ndf.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Country Cleanse\n---\nLet's analyze the variable which has the least number of null values. In this case, it is a \"Country\" where the movie/show was produced. It has 507 null values. Let's observe the first 5 records. ","metadata":{}},{"cell_type":"code","source":"df[df.country.isna()].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Instead of drop these records with null countries, we can try to merge another dataset and restore the information. One of the famous and large movie/TV show datasets, which comes to mind, is IMDb.","metadata":{}},{"cell_type":"code","source":"imdb = pd.read_csv('../input/imdb-extensive-dataset/IMDb movies.csv', low_memory=False)\nimdb.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the IMDb dataset doesn't contain a key to merge with the Netflix data, we'll try to merge by title and production year. But before we need to clean the IMDb dataset. ","metadata":{}},{"cell_type":"code","source":"# one record in 'year' colummn in IMDB has inappropriate formatting \nimdb[imdb.year.str.contains(' ')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can replace it just by year\nimdb.loc[imdb.year.str.contains(' '), 'year'] = imdb.loc[imdb.year.str.contains(' '), 'year'].str.rsplit(' ', expand=True)[2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert release year to datetime format for the merging procedure\ndf.release_year = pd.to_datetime(df.release_year, format='%Y').dt.year\nimdb.year = pd.to_datetime(imdb.year, format='%Y').dt.year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop duplicates in subset\nimdb = imdb.drop_duplicates(subset=['original_title', 'year'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge 2 datasets by title and release year\ndf = df.merge(imdb.add_suffix('_imdb'), how='left', left_on=['title','release_year'], right_on=['original_title_imdb','year_imdb'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of counties\nlen(df[(df.country.isna()) & (df.country_imdb.notnull())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unfortunately, we can restore only **13** records. Anyway, it's better than nothing. The problem of small merged countries might be that the IMDb dataset is not big enough and doesn't contain information about some movies/TV shows in the Netflix dataset. The solution might be to merge a _larger movie/TV Show dataset_, which contains titles in a foreign language as well.","metadata":{}},{"cell_type":"code","source":"# replace these null country records \ndf.loc[df.country.isna(), 'country'] = df.loc[df.country.isna(), 'country_imdb']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's perform the same procedure for cast and director columns:","metadata":{}},{"cell_type":"code","source":"# number of replaceble cast records\nlen(df.loc[(df.cast.isna()) & (df.actors_imdb.notnull())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace null cast records by actors from IMDb\ndf.loc[(df.cast.isna()) & (df.actors_imdb.notnull()), 'cast'] = df.loc[(df.cast.isna()) & (df.actors_imdb.notnull()), 'actors_imdb']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of replaceble director\nlen(df.loc[(df.director.isna()) & (df.director_imdb.notnull())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace null director records by director from IMDb\ndf.loc[(df.director.isna()) & (df.director_imdb.notnull()), 'director'] = df.loc[(df.director.isna()) & (df.director_imdb.notnull()), 'director_imdb']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result, we can restore 11 records that have actors' information and 30 records that contain information about directors from IMDb. Now drop the IMDb columns because they are useless for further analysis.","metadata":{}},{"cell_type":"code","source":"# drop IMDb columns \ndf = df.drop(df.columns[12:], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check decreased null values\ndf.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Country Analysis\n---\nRather than show production countries with the highest value count and build a bar plot of that (if be honest, you can find this kind of information in other notebooks), I would like to analyze country interaction in the production process (such as with which country the US produce more movies/TV shows) and to create a new dataframe to satisfy task demand. \n\nOne-hot encoding can help to perform it. Basically, this approach is using for market basket analysis to create association rules, but I think it is suitable in our case. ","metadata":{}},{"cell_type":"code","source":"# subset dataset and split \ncountry = df.loc[df.country.notnull(), 'country'].astype('str').apply(lambda t: t.split(', '))\n\n# Convert DataFrame column into list of strings\ncountry = list(country)\n\n# number of movies/TV shows without null values\nlen(country)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate encoder and identify unique country\nencoder = TransactionEncoder().fit(country)\n\n# One-hot encode\nonehot_country = encoder.transform(country)\n\n# Convert one-hot encoded data to DataFrame and set show_id as index\nonehot_country = pd.DataFrame(onehot_country, columns = encoder.columns_, index=df.loc[df.country.notnull(), 'show_id'])\n\n# Print the one-hot encoded country dataset\nonehot_country.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To interpret this table is not too hard. For example, a movie/TV Show with __show_id__ _\"s1\"_ was made in Brazil. Thus Brazil column is _True_ for this row. The rest columns are _False_. Using this new table, we can calculate the share of the movie/TV show production of each country in the Netflix dataset. ","metadata":{}},{"cell_type":"code","source":"# Print the one-hot encoded country share dataset\ncountry_share = onehot_country.mean().sort_values(ascending=False).round(4) * 100\ncountry_share","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take countries that share more than 1%\ncountry_share = country_share[country_share > 1]\nlabels = country_share.round(3).astype('str') + ' %'\n\nfig1, ax1 = plt.subplots(figsize=(20,15), facecolor='white')\nax1.pie(country_share, labels=labels, labeldistance=1.05,\n        shadow=True)\nplt.title('Percent of produced Movies/TV Show by Country', fontsize=20)\nplt.legend(labels=country_share.index, loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the pie chart above, 45.2% of movies/TV Shows were produced by the United States and in collaboration of United States with other countries. Now, I am interested in what country collaborates more with the United States to produce movies/TV Shows.","metadata":{}},{"cell_type":"code","source":"# Compute frequency using the Apriori algorithm\nfrequency = apriori(onehot_country[onehot_country['United States'] == True], \n                    min_support = 0.0001, \n                    max_len = 4, \n                    use_colnames = True).rename({'support':'frequency', 'itemsets':'Countries'}, axis=1)\n\n# sort row which contain 'United States' and more than 1 country\nfrequency = frequency[(frequency.Countries.apply(lambda t: 'United States' in t)) & (frequency.Countries.apply(lambda t: len(t) >= 2))]\\\n                    .sort_values('frequency', ascending=False).round(3)\n\n# Print a preview of the frequency\nfrequency.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the table above, 7% of all movies/shows (where the US was participated in production) were made in collaboration with the United Kingdom. 6% with Canada and 3% with France.  \n\nReset index of the one-hot encoded country dataset so we can link back to the original dataset via the \"show_id\" field.","metadata":{}},{"cell_type":"code","source":"onehot_country = onehot_country.reset_index()\nonehot_country.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Genre Cleanse and Analysis\n---\nWe can use the same one-hot encode technique for genre variable to clean and analyze it.","metadata":{}},{"cell_type":"code","source":"# subset dataset and split \ngenre = df['listed_in'].apply(lambda t: t.split(', '))\n\n# Convert DataFrame column into list of strings\ngenre = list(genre)\n\n# number of movies/TV Shows\nlen(genre)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate transaction encoder and identify unique items\nencoder = TransactionEncoder().fit(genre)\n\n# One-hot encode transactions\nonehot = encoder.transform(genre)\n\n# Convert one-hot encoded data to DataFrame and set show_id as index\nonehot_genre = pd.DataFrame(onehot, columns = encoder.columns_, index=df['show_id'])\n\n# Print the one-hot encoded transaction dataset\nonehot_genre.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 42 different genres in out dataset for 7787 Movies/TV Shows. We can calculate the number of Movies/TV Shows for each genre and visualize it.","metadata":{}},{"cell_type":"code","source":"genre_count = onehot_genre.sum().sort_values(ascending=False)\ngenre_count.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('ggplot')\nplt.figure(figsize=(20, 10))\ngenre_count.plot(kind='bar')\nplt.xticks(rotation='90')\nplt.tick_params(axis='x', labelsize=15)\nplt.title('Number of Movies/TV Shows by genre', fontsize=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like that the most popular genre is \"International Movies\" but for me it doesn't make any sense in term of the genre. Hence, let's look at the most common combination of genres with \"International Movies.\"","metadata":{}},{"cell_type":"code","source":"# Compute frequent itemsets using the Apriori algorithm\nfrequency = apriori(onehot_genre[onehot_genre['International Movies'] == True], \n                    min_support = 0.0001, \n                    max_len = 2, \n                    use_colnames = True).rename({'support':'frequency', 'itemsets':'Genre'}, axis=1)\n\n# sort row which contain 'International Movies' and more than 1 country\nfrequency = frequency[(frequency.Genre.apply(lambda t: 'International Movies' in t)) & (frequency.Genre.apply(lambda t: len(t) >= 2))]\\\n                    .sort_values('frequency', ascending=False).round(3)\n\nfrequency.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the table above, 53% of all International Movies (2437) are dramas. 30% are comedies and 15% in the action & adventure genre. \n\nYou are probably questioned why the sum of the percent doesn't give a 100%. It is because that it might be a combination of genres, for example, drama and comedy. Apriori algorithms calculate any mentioned combination in all records and return its frequency.\n\nFor instance, suppose we have two international movies with genres \"dramas, crime, documentaries\" and \"dramas, comedies\". In this case, 100% of international movies are drama and 50% are crime. \n\nLet's look at the International TV Shows genres:","metadata":{}},{"cell_type":"code","source":"# Compute frequent itemsets using the Apriori algorithm\nfrequency = apriori(onehot_genre[onehot_genre['International TV Shows'] == True], \n                    min_support = 0.0001, \n                    max_len = 2, \n                    use_colnames = True).rename({'support':'frequency', 'itemsets':'Genre'}, axis=1)\n\n# sort row which contain 'International Movies' and more than 1 country\nfrequency = frequency[(frequency.Genre.apply(lambda t: 'International TV Shows' in t)) & (frequency.Genre.apply(lambda t: len(t) >= 2))]\\\n                    .sort_values('frequency', ascending=False).round(3)\n\nfrequency.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most popular genre of International TV Shows is also drama (40%). Nevertheless, romantic and crime are in the 2nd and 3rd places respectively, which is make sense for the TV Shows segment - people tend to watch detective and love dramas on TV).\n\nNow, again, reset indexes of the one-hot genre dataset in case if we want to merge it with initial dataset.","metadata":{}},{"cell_type":"code","source":"# reset index with show_id information\nonehot_genre = onehot_genre.reset_index()\nonehot_genre.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cast Cleanse and Analysis\n---\nThe same procedure fot the cast column.","metadata":{}},{"cell_type":"code","source":"# subset dataset and split \ncast = df.loc[df.cast.notnull(),'cast'].astype('str').apply(lambda t: t.split(', '))\n\n# Convert DataFrame column into list of strings\ncast = list(cast)\n\n# number of movies/TV Shows\nlen(cast)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate encoder and identify unique records\nencoder = TransactionEncoder().fit(cast)\n\n# One-hot encode\nonehot = encoder.transform(cast)\n\n# Convert one-hot encoded data to DataFrame and set show_id as index\nonehot_cast = pd.DataFrame(onehot, columns = encoder.columns_, index=df.loc[df.cast.notnull(),'show_id'])\n\n# Print the one-hot encoded dataset\nonehot_cast.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the one-hot encoded dataset, there are 32966 actors/actresses in a total of 7080 Movies/TV Shows. Let's look at the top 5 actors/actresses with the highest numbers of Movies/TV shows:","metadata":{}},{"cell_type":"code","source":"onehot_cast.sum().sort_values(ascending=False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unfortunately, these names don't tell me anything. Thus, I created a function which returns a dataset with all necessary information:","metadata":{}},{"cell_type":"code","source":"# function that returns information about cast's Movies/TV Shows\ndef cast(actor):\n    data = df[df.cast.astype('str').apply(lambda t: actor in t)]\n    return(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply a function to the top actor and look at the first 5 Movies/TV Shows\ncast('Anupam Kher').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now I am interested in the most filmed actor in any movie which the US has participated in the production. To do so, we need to reset indexes and merge the \"onehot_cast\" dataset with appropriate data. We could merge with initial Netflix data but the problem that we want to group all movies in which the US was involved in the production. The initial dataset cannot satisfy our desire, but the encoded country dataset can:)\n\nAdditionally, I'll show how created new datasets might be used.","metadata":{}},{"cell_type":"code","source":"# reset index\nonehot_cast = onehot_cast.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge show type first\ncast_country = onehot_cast.merge(df[['show_id', 'type']], how='left')\n\n# merge one-hot encoded country dataset\ncast_country = cast_country.merge(onehot_country, how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filter by movie type and the US country\ncast_us = cast_country.loc[(cast_country.type == 'Movie') & (cast_country['United States'] == True)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate the total number of American movies of actors/actresses\nus_cast_count = cast_us.loc[:,onehot_cast.columns].drop('show_id', axis=1)\\\n                       .sum().sort_values(ascending=False)\n\n# Top-5 actors/actresses\nus_cast_count.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like Adam Sandler acted more than others in movies that were produced by the US and other countries. There are 19 his movies in the Netflix dataset. Let's observe these movies using our function:","metadata":{}},{"cell_type":"code","source":"# First 5 movies with Adam Sandler\ncast('Adam Sandler').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of actors/actresses in American movies\nlen(us_cast_count[us_cast_count > 0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Director Cleanse\n---","metadata":{}},{"cell_type":"code","source":"# subset dataset and split \ndirector = df.loc[df.director.notnull(),'director'].astype('str').apply(lambda t: t.split(', '))\n\n# Convert DataFrame column into list of strings\ndirector = list(director)\n\n# number of movies/TV Shows\nlen(director)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate encoder and identify unique records\nencoder = TransactionEncoder().fit(director)\n\n# One-hot encode\nonehot = encoder.transform(director)\n\n# Convert one-hot encoded data to DataFrame and set show_id as index\nonehot_director = pd.DataFrame(onehot, columns = encoder.columns_, \n                               index=df.loc[df.director.notnull(),'show_id'])\n\n# Print the one-hot encoded dataset\nonehot_director.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 4501 directors of 5428 Movies/TV Shows according to the one-hot encoded dataset.","metadata":{}},{"cell_type":"code","source":"# number of Movies/TV Shows by director\nonehot_director.sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function defining the Movies/TV Shows by director\ndef director(name):\n    data = df[df.director.astype('str').apply(lambda t: name in t)]\n    return(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Countries where Jan Suter made his Movies/TV Shows\ndirector('Jan Suter').country.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next question is what is the director with made the most number of TV Shows in the US? ","metadata":{}},{"cell_type":"code","source":"# merge with Netflix dataset\nonehot_director_us = onehot_director.reset_index().merge(df, how='left')\n\n# Filter the data\nonehot_director_us = onehot_director_us.loc[(onehot_director_us.country == 'United States') & (onehot_director_us.type == 'TV Show')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top-5 TV Show directors with the highest number of movies\nonehot_director_us.loc[:,onehot_director.columns].sum().sort_values(ascending=False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, I would like to know what Movies and TV Shows of my favourite director Quentin Tarantino a Netflix dataset has:","metadata":{}},{"cell_type":"code","source":"# Quentin Tarantino's filmography\ndirector('Quentin Tarantino')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\nIn this work we cleaned, reshaped, and visualize the __actors, directors, countries, and genres__ columns of the Netflix dataset. It is not easy to analyze these columns because each contains several values. Thus, each variable has its own encoded dataset with the \"show_id\" primary key. So you can merge them with source data to answer to interested you questions about  actors, directors, countries, or genres. I performed basic visualization just to show how we can operate and use these tables. Feel free to use these tables and function to perform more complicated exploratory data analysis. I hope I accomplished all task's  requirements and my code would serve to the further sophisticated analysis work.","metadata":{}}]}