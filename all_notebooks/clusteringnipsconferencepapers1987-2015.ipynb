{"cells":[{"metadata":{"id":"view-in-github"},"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Nikunjbansal99/ClusteringNIPSConferencePapers1987-2015/blob/main/ClusteringNIPSConferencePapers1987_2015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"},{"metadata":{"id":"fiRD6YSSyNVD"},"cell_type":"markdown","source":"# **Methodology**"},{"metadata":{"id":"1NTQ1uMl6MCg"},"cell_type":"markdown","source":"\n*   **Import Some Basic Libraries**\n*   **Import Data**\n*   **Perform Descriptive Analysis on the dataset**\n    *   **Data Description**\n    *   **Check null/NAN values**\n*   **Plotting Dendograms for different number of clusters**\n*   **Train-Test Splitting**\n*   **Apply Dimensionality Reduction Using PCA**\n*   **Implementing different clustering algorithm's for different number of clusters and perform visualization**\n*   **Initialize Model Selected**\n    *   **Get labels of Training Data**\n    *   **Get labels of Testing Data**\n*   **On Training data, Evaluating Model based on Silhouette Score, Calinski Harabasz Score and Davies Bouldin Score**\n*   **On Testing data, Evaluating Model based on Silhouette Score, Calinski Harabasz Score and Davies Bouldin Score**"},{"metadata":{"id":"NsTeYKU1i8kn"},"cell_type":"markdown","source":"# **Importing Some Basic Libraries**"},{"metadata":{"id":"mhhG3SPhkr9t","outputId":"471011e5-a6fd-4c31-bb28-eac10ee3e24f","trusted":true},"cell_type":"code","source":"pip install scikit-learn-extra","execution_count":null,"outputs":[]},{"metadata":{"id":"FDrOlV9tlxiW","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.utils import check_random_state\nimport sys, os\nfrom sklearn.cluster import KMeans\nfrom sklearn_extra.cluster import KMedoids\nfrom sklearn.cluster import MeanShift\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.metrics import calinski_harabasz_score\nfrom sklearn.metrics import davies_bouldin_score","execution_count":null,"outputs":[]},{"metadata":{"id":"3yzClrp5jFWl"},"cell_type":"markdown","source":"# **Importing Data**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"mgD5zlZfyej6"},"cell_type":"code","source":"input_data_dir = \"../input/nips-conference-papers-19872015\"\nNIPS_full_df = pd.read_csv(os.path.join(input_data_dir, \"NIPS_1987-2015.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"id":"5I8rZpuTrle_"},"cell_type":"markdown","source":"# **Descriptive Analysis of the dataset**"},{"metadata":{"trusted":true,"id":"m7YFN-twSpsP","outputId":"68d7ab7a-8a8d-43e9-dfe2-ea1c01e7cbe8"},"cell_type":"code","source":"print(\"Size of NIPS DataFrame     : {}\".format(NIPS_full_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"id":"Ex0Pj2NVrlfN"},"cell_type":"markdown","source":"## **Data Description**"},{"metadata":{"id":"9JzU2s64UcL2","outputId":"30010ef7-9ca3-4535-bdf9-976624c0943d","trusted":true},"cell_type":"code","source":"print(\"Total Number of Papers included in NIPS DataFrame     : {}\".format(len(NIPS_full_df.columns)-1))","execution_count":null,"outputs":[]},{"metadata":{"id":"AOjBt6d-rlfP","outputId":"2085d39c-f655-4ad9-86b6-c7cd5b0b9b38","trusted":true},"cell_type":"code","source":"NIPS_full_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"wrC8TEXZyekb","outputId":"9fca85ce-77ee-47fa-c606-b57d8efaa58c"},"cell_type":"code","source":"NIPS_full_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"id":"nhuZ_NHuYvPC","trusted":true},"cell_type":"code","source":"NIPS_full_df = NIPS_full_df.transpose()","execution_count":null,"outputs":[]},{"metadata":{"id":"frwuAFGIY7G5","outputId":"9b15985c-6eb9-42fc-a141-2e7a10f03a04","trusted":true},"cell_type":"code","source":"NIPS_full_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"cYL3JX54aY4U","trusted":true},"cell_type":"code","source":"new_header = NIPS_full_df.iloc[0] #grab the first row for the header\nNIPS_full_df = NIPS_full_df[1:] #take the data less the header row\nNIPS_full_df.columns = new_header #set the header row as the df header","execution_count":null,"outputs":[]},{"metadata":{"id":"U7Gi7UvGa7-L","outputId":"71aa161c-02b0-486f-e91c-10ac6318ca77","trusted":true},"cell_type":"code","source":"NIPS_full_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"SGa5pGaAV8lI"},"cell_type":"markdown","source":"## **NULL VALUES:**"},{"metadata":{"id":"vy4wv6YYVwsx","outputId":"3218d92b-b441-44f8-9276-cbc696ddf471","trusted":true},"cell_type":"code","source":"NIPS_full_df.isna().sum() ","execution_count":null,"outputs":[]},{"metadata":{"id":"Nrt1kPlYUUFK","outputId":"153cfde9-2373-4098-9f31-6ce3e95c5296","trusted":true},"cell_type":"code","source":"print(\"Total Number of Missing Values in NIPS DataFrame     : {}\".format(NIPS_full_df.isna().sum().sum()))   ","execution_count":null,"outputs":[]},{"metadata":{"id":"pOWFvEkNkVL4"},"cell_type":"markdown","source":"# **Plotting Dendograms:**"},{"metadata":{"id":"MLHzj9MEkczX","trusted":true},"cell_type":"code","source":"def dendrogramPlot(model, **kwargs):                                            # Create linkage matrix and then plot the dendrogram\n    counts = np.zeros(model.children_.shape[0])                                 # Create the counts of samples under each node\n\n    n_samples = len(model.labels_)\n    for i, merge in enumerate(model.children_):\n        current_count = 0\n        for child_idx in merge:\n            if child_idx < n_samples:\n                current_count += 1  # leaf node\n            else:\n                current_count += counts[child_idx - n_samples]\n        counts[i] = current_count\n    linkage_matrix = np.column_stack([model.children_, model.distances_,counts]).astype(float)\n    dendrogram(linkage_matrix, **kwargs)                                        # Plot the corresponding dendrogram ","execution_count":null,"outputs":[]},{"metadata":{"id":"hyPxIwFmq45Y","trusted":true},"cell_type":"code","source":"ClusteringModel = AgglomerativeClustering(distance_threshold=0, n_clusters=None)# setting distance_threshold=0 ensures we compute the full tree.","execution_count":null,"outputs":[]},{"metadata":{"id":"1GPEI7ifwlPb","trusted":true},"cell_type":"code","source":"ClusteringModel = ClusteringModel.fit(NIPS_full_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"79ZquYhjrX5W","outputId":"4e844938-f602-46f0-9aa4-fca8d1a59e54","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 10 levels')\ndendrogramPlot(ClusteringModel, p=10, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"AFL6fjIztcgo"},"cell_type":"markdown","source":"**Too much dense. So, going for dendogram with levels 8.**"},{"metadata":{"id":"rSxZ6SdVxhvH","outputId":"453b032a-1f7d-4750-8c0c-2973bebed74b","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 8 levels')\ndendrogramPlot(ClusteringModel, p=8, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"bHyVgFOOtu_8"},"cell_type":"markdown","source":"**Too much dense. So, going for dendogram with levels 7.**"},{"metadata":{"id":"HDlD4ec5xnsD","outputId":"013d8135-6c4e-4193-f318-e2790eb5331e","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 7 levels')\ndendrogramPlot(ClusteringModel, p=7, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_-4F6duAtw_J"},"cell_type":"markdown","source":"**Too much dense. So, going for dendogram with levels 6.**"},{"metadata":{"id":"fNv_z4BVxsKz","outputId":"3d997341-08fb-4094-8ec4-56f75abdfc0f","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 6 levels')\ndendrogramPlot(ClusteringModel, p=6, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"RM58-u2CydNy","outputId":"e63be198-052a-4cef-e6f5-3f79b4cc1f97","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 5 levels')\ndendrogramPlot(ClusteringModel, p=5, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"-ehLHSYqx0Co","outputId":"c33d2d5d-033d-4993-dfe2-484235199d6e","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 4 levels')\ndendrogramPlot(ClusteringModel, p=4, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"shuexCIJz2Rk","outputId":"23961b79-8e02-4e63-c3c6-5159ab46eedb","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 3 levels')\ndendrogramPlot(ClusteringModel, p=3, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"DZuCbpin0HUO","outputId":"377b5763-ab05-450a-de7b-d20bb36ec8b9","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Clustering Dendrogram for 2 levels')\ndendrogramPlot(ClusteringModel, p=2, truncate_mode='level')                    \nplt.xlabel(\"Number of points in node\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Gyh5ekTBiPNE"},"cell_type":"markdown","source":"# **Train-Test Splitting:**"},{"metadata":{"id":"bN02MT6v0YiG","trusted":true},"cell_type":"code","source":"# Splitting NIPS_full_df into 70% and 30% to construct training dataframe and testing dataframe respectively.\ntraindf, testdf = train_test_split(NIPS_full_df, test_size=0.3, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"65rq-BSYrlfE","outputId":"8cb41096-b290-4f4f-c779-6b1eff41a472"},"cell_type":"code","source":"print(\"Size of Training Dataframe       : {}\".format(traindf.shape))\nprint(\"Size of Testing Dataframe      : {}\".format(testdf.shape))","execution_count":null,"outputs":[]},{"metadata":{"id":"ugwF1BWv09wz","outputId":"b390edda-90ad-4be8-f9b3-39d1c4b7510f","trusted":true},"cell_type":"code","source":"traindf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"QK_HHjed1FJV","outputId":"790f0e04-b094-40ce-a198-3ed98befeb46","trusted":true},"cell_type":"code","source":"testdf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"-vCees5fiuxx"},"cell_type":"markdown","source":"# **Applying Dimensionality Reduction:**"},{"metadata":{"id":"7H-2J7zQ07oE","trusted":true},"cell_type":"code","source":"# Initializing Principal Component Analysis(PCA)\nPCA_method = PCA(n_components=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"vtcBxizI4xEQ","trusted":true},"cell_type":"code","source":"# Fit And Transorm Data\ntraindf= PCA_method.fit_transform(traindf)\ntestdf = PCA_method.transform(testdf)","execution_count":null,"outputs":[]},{"metadata":{"id":"L5RnYRfyWroF"},"cell_type":"markdown","source":"# **Visualizing various Algorithm's:**"},{"metadata":{"id":"fzYfhy3X0u9N","trusted":true},"cell_type":"code","source":"np.random.seed(42)\n\n# Step size of the mesh. Decrease to increase the quality of the VQ.\nh = 0.02  # point in the mesh [x_min, m_max]x[y_min, y_max].\n\n# Plot the decision boundary. For that, we will assign a color to each\nx_min, x_max = traindf[:, 0].min() - 1, traindf[:, 0].max() + 1\ny_min, y_max = traindf[:, 1].min() - 1, traindf[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))","execution_count":null,"outputs":[]},{"metadata":{"id":"RssCN1O7n98a","outputId":"871d8e0f-8de6-467a-f95a-cb082f0f443e","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,30))\nplt.clf()\n\nplt.suptitle(\"Comparing Multiple Clustering Algorithms having no. of clusters as 8\",fontsize=15,)\n\nchoosed_models = [(KMedoids(metric=\"manhattan\", n_clusters=8),\"KMedoids (Manhattan)\",),\n                 (KMedoids(metric=\"euclidean\", n_clusters=8),\"KMedoids (Euclidean)\",),\n                 (KMedoids(metric=\"cosine\", n_clusters=8), \"KMedoids (Cosine)\"),\n                 (KMeans(n_clusters=8), \"KMeans\"),\n                 (KMeans(n_clusters=8, init='k-means++'),\"k-means++\")]\n\nplot_rows = 2\nplot_cols = 3\n\nfor i, (i_model, description) in enumerate(choosed_models):\n    i_model.fit(traindf)\n    Y = i_model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Y = Y.reshape(xx.shape)\n    plt.subplot(plot_cols, plot_rows, i + 1)                                    # Put the result into a color plot\n    plt.imshow(Y, interpolation=\"nearest\", extent=(xx.min(), xx.max(), yy.min(), yy.max()), cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\",)\n    plt.plot(traindf[:, 0], traindf[:, 1], \"k.\", markersize=2, alpha=0.3)\n\n\n    centroids = i_model.cluster_centers_\n    plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=169, linewidths=3, color=\"w\", zorder=10,)\n                                        # set centroids shape as a X        ; set centroids color as a white\n    plt.title(description)\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    plt.xticks(())\n    plt.yticks(())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"wsd-2t6luKo7","outputId":"7be07538-a6b4-477a-9a48-dda9ab125b6d","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,30))\nplt.clf()\n\nplt.suptitle(\"Comparing Multiple Clustering Algorithms having no. of clusters as 16\",fontsize=15,)\n\nchoosed_models = [(KMedoids(metric=\"manhattan\", n_clusters=16),\"KMedoids (Manhattan)\",),\n                 (KMedoids(metric=\"euclidean\", n_clusters=16),\"KMedoids (Euclidean)\",),\n                 (KMedoids(metric=\"cosine\", n_clusters=16), \"KMedoids (Cosine)\"),\n                 (KMeans(n_clusters=16), \"KMeans\"),\n                 (KMeans(n_clusters=16, init='k-means++'),\"k-means++\")]\n\nplot_rows = 2\nplot_cols = 3\n\nfor i, (i_model, description) in enumerate(choosed_models):\n    i_model.fit(traindf)\n    Y = i_model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Y = Y.reshape(xx.shape)\n    plt.subplot(plot_cols, plot_rows, i + 1)                                    # Put the result into a color plot\n    plt.imshow(Y, interpolation=\"nearest\", extent=(xx.min(), xx.max(), yy.min(), yy.max()), cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\",)\n    plt.plot(traindf[:, 0], traindf[:, 1], \"k.\", markersize=2, alpha=0.3)\n\n\n    centroids = i_model.cluster_centers_\n    plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=169, linewidths=3, color=\"w\", zorder=10,)\n                                        # set centroids shape as a X        ; set centroids color as a white\n    plt.title(description)\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    plt.xticks(())\n    plt.yticks(())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"l4KyBNolu8T3","outputId":"8de784fc-1940-44c3-9983-de9383474d32","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,30))\nplt.clf()\n\nplt.suptitle(\"Comparing Multiple Clustering Algorithms having no. of clusters as 32\",fontsize=15,)\n\nchoosed_models = [(KMedoids(metric=\"manhattan\", n_clusters=32),\"KMedoids (Manhattan)\",),\n                 (KMedoids(metric=\"euclidean\", n_clusters=32),\"KMedoids (Euclidean)\",),\n                 (KMedoids(metric=\"cosine\", n_clusters=32), \"KMedoids (Cosine)\"),\n                 (KMeans(n_clusters=32), \"KMeans\"),\n                 (KMeans(n_clusters=32, init='k-means++'),\"k-means++\")]\n\nplot_rows = 2\nplot_cols = 3\n\nfor i, (i_model, description) in enumerate(choosed_models):\n    i_model.fit(traindf)\n    Y = i_model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Y = Y.reshape(xx.shape)\n    plt.subplot(plot_cols, plot_rows, i + 1)                                    # Put the result into a color plot\n    plt.imshow(Y, interpolation=\"nearest\", extent=(xx.min(), xx.max(), yy.min(), yy.max()), cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\",)\n    plt.plot(traindf[:, 0], traindf[:, 1], \"k.\", markersize=2, alpha=0.3)\n\n\n    centroids = i_model.cluster_centers_\n    plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=169, linewidths=3, color=\"w\", zorder=10,)\n                                        # set centroids shape as a X        ; set centroids color as a white\n    plt.title(description)\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    plt.xticks(())\n    plt.yticks(())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"oN8zAFpg72HV","outputId":"ea4d5b9b-2b55-456a-c335-eea041162115","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,30))\nplt.clf()\n\nplt.suptitle(\"Comparing Multiple Clustering Algorithms having no. of clusters as 64\",fontsize=15,)\n\nchoosed_models = [(KMedoids(metric=\"manhattan\", n_clusters=64),\"KMedoids (Manhattan)\",),\n                 (KMedoids(metric=\"euclidean\", n_clusters=64),\"KMedoids (Euclidean)\",),\n                 (KMedoids(metric=\"cosine\", n_clusters=64), \"KMedoids (Cosine)\"),\n                 (KMeans(n_clusters=64), \"KMeans\"),\n                 (KMeans(n_clusters=64, init='k-means++'),\"k-means++\")]\n\nplot_rows = 2\nplot_cols = 3\n\nfor i, (i_model, description) in enumerate(choosed_models):\n    i_model.fit(traindf)\n    Y = i_model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Y = Y.reshape(xx.shape)\n    plt.subplot(plot_cols, plot_rows, i + 1)                                    # Put the result into a color plot\n    plt.imshow(Y, interpolation=\"nearest\", extent=(xx.min(), xx.max(), yy.min(), yy.max()), cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\",)\n    plt.plot(traindf[:, 0], traindf[:, 1], \"k.\", markersize=2, alpha=0.3)\n\n\n    centroids = i_model.cluster_centers_\n    plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=169, linewidths=3, color=\"w\", zorder=10,)\n                                        # set centroids shape as a X        ; set centroids color as a white\n    plt.title(description)\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    plt.xticks(())\n    plt.yticks(())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"AbVqpH2A253e"},"cell_type":"markdown","source":"# **Model Selected:**"},{"metadata":{"id":"tZF_EWwL3B0K","trusted":true},"cell_type":"code","source":"KMeansplusModel = KMeans(n_clusters=32, init='k-means++')               # Initialize KMeans++ Model","execution_count":null,"outputs":[]},{"metadata":{"id":"S5FzWvb-iqJ4","trusted":true},"cell_type":"code","source":"KMeansplusModel = KMeansplusModel.fit(traindf)                          # Fitting traindf to the Model","execution_count":null,"outputs":[]},{"metadata":{"id":"CDvyV4jFkuRQ","outputId":"f5ea8612-8e2c-40ef-a68a-73b412da0c09","trusted":true},"cell_type":"code","source":"CenterOfClusters = KMeansplusModel.cluster_centers_\nprint('Centers Of Clusters: ')\nprint(CenterOfClusters)","execution_count":null,"outputs":[]},{"metadata":{"id":"x4IFrQrBjgyW","outputId":"4ec3a1aa-93a9-4a99-b6f8-c58ed627bb41","trusted":true},"cell_type":"code","source":"traindf_labels = KMeansplusModel.labels_\nprint(\"traindf labels: \",traindf_labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"3th_tConzvFT"},"cell_type":"markdown","source":"### **Perform Prediction on Testing DataFrame:**"},{"metadata":{"id":"O4y91a6Sj51q","outputId":"78965e84-06e8-4b79-9355-c778f4ab56c6","trusted":true},"cell_type":"code","source":"testdf_labels = KMeansplusModel.predict(testdf)\nprint(\"testdf labels: \",testdf_labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"8jtDKdBm9ZOu"},"cell_type":"markdown","source":"# **Evaluation**"},{"metadata":{"id":"_s1DjSmvVqci"},"cell_type":"markdown","source":"## **On Training Data:**"},{"metadata":{"id":"2_4XrFN3mFW_","outputId":"5c643e0b-8a3d-4a64-e84c-5243b42799ed","trusted":true},"cell_type":"code","source":"print(\"Silhouette Score : \",silhouette_score(traindf, traindf_labels, metric='euclidean'))\nprint(\"Calinski Harabasz Score : \",calinski_harabasz_score(traindf, traindf_labels))\nprint(\"Davies Bouldin Score : \",davies_bouldin_score(traindf, traindf_labels))","execution_count":null,"outputs":[]},{"metadata":{"id":"p69GzxneVvTM"},"cell_type":"markdown","source":"## **On Testing Data:**"},{"metadata":{"id":"Si1GdDnYpp1h","outputId":"2c152e5b-fd08-4052-ade5-b0e909790249","trusted":true},"cell_type":"code","source":"print(\"Silhouette Score : \",silhouette_score(testdf, testdf_labels, metric='euclidean'))\nprint(\"Calinski Harabasz Score : \",calinski_harabasz_score(testdf, testdf_labels))\nprint(\"Davies Bouldin Score : \",davies_bouldin_score(testdf, testdf_labels))","execution_count":null,"outputs":[]},{"metadata":{"id":"M9pynMZ1uit2"},"cell_type":"markdown","source":"**We got a Silhouette Score of 0.332 on training data and 0.300 on testing data. It shows our algorithm is performing good but some cluster's are overlapping each other.**"},{"metadata":{"id":"Skwmnz8HuAw1"},"cell_type":"markdown","source":"**We got a Calinski Harabasz Score of 3078.58 on training data and 1192.73 on testing data. Which is quite good.**"},{"metadata":{"id":"wE_SgHjivg7P"},"cell_type":"markdown","source":"**We got a Davies Bouldin Score of 0.8173 on training data and 0.8689 on testing data. It shows that the separation between the clusters is low.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}