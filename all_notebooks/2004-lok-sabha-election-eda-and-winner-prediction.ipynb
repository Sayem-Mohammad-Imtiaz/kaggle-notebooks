{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font color='blue' size=6> 2004 Lok Sabha Candidate Winner Prediction</font>\n<hr/>\n<font size=2> - Durgesh Samariya | The ML PhD Student </font>\n"},{"metadata":{},"cell_type":"markdown","source":"<font color='red' size=5><center>Please Upvote my kernel if you like my work.</center></font>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:MediumSeaGreen; border:0' role=\"tab\" aria-controls=\"home\"><center>Table of Content</center></h1>\n\n- [1. Introduction](#introduction)\n- [2. Import Required Libraries](#library)"},{"metadata":{},"cell_type":"markdown","source":"<a id='introduction'></a>\n# Introduction\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>"},{"metadata":{},"cell_type":"markdown","source":"<a id='library'></a>\n# Import Required Libraries\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# wordcloud\nfrom wordcloud import WordCloud, STOPWORDS\n\n# machine learning\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn import preprocessing\n\n%matplotlib inline\n\nplt.style.use('seaborn-dark-palette')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset"},{"metadata":{},"cell_type":"markdown","source":"Let's load `LokSabha2004.csv` file."},{"metadata":{"trusted":true},"cell_type":"code","source":"%time data = pd.read_csv('../input/lok-sabha-election-candidate-list-2004-to-2019/LokSabha2004.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = (data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(missing[missing>0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data exploration"},{"metadata":{},"cell_type":"markdown","source":"## Check the data"},{"metadata":{},"cell_type":"markdown","source":"Let's glimpse at dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data contains:\n- **Candidate** - Name of the Candidate.\n- **Party** - Policatical Party.\n- **Criminal Cases** - Criminal Cases against candidate.\n- **Education** - Education of candidate.\n- **Age** - Age of candidate.\n- **Total Assets** - Total assets of candidate.\n- **Constituency** - Name of constituency from candidate stand in election.\n- **Liabilities** - Total Liabilities of candidate.\n- **Winner** - Does candidate won in election that year? (0 - No, 1- Yes)\n- **Gender** - Gender of candidate. (M-Male, F-Female)"},{"metadata":{},"cell_type":"markdown","source":"Let's check statistics of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We make few observation here:\n- In `age` feature we can see minimum value is `Zero (0)`, which is wrong we might have some wrong values. In data analysis part I will decide what to do with this candidates.\n- We have max 36 criminal cases value and lowest is zero. This feature probably help in prediction."},{"metadata":{},"cell_type":"markdown","source":"Let's check information of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check shape of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 3642 samples in dataset and 10 features."},{"metadata":{},"cell_type":"markdown","source":"Let's check if there is any missing value in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    missing_data['Types'] = types\n    return(np.transpose(missing_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmissing_data(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 260 missing/NaN values in Total Assest. I will decide what to do with this value after data analysis. "},{"metadata":{},"cell_type":"markdown","source":"# Exploring important features"},{"metadata":{},"cell_type":"markdown","source":"<font color='slateblue' size=+2.5> The Class Variable; Winner\n    </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Winner'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(10,6))\nsns.countplot('Winner', data=data, palette='Set3')\nplt.xticks(rotation=90)\nplt.title('Winner Count',fontsize=20)\nplt.ylabel('Count',fontsize=16)\nplt.xlabel('Winner?',fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 2004, total 3642 candidates participated in election. However 388 won the election and 3254 lose."},{"metadata":{},"cell_type":"markdown","source":"## Name wordcloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_wordcloud(df, title):\n    wordcloud = WordCloud(\n        background_color='black', \n        stopwords=set(STOPWORDS), \n        max_words=100, \n        max_font_size=40, \n        random_state=666\n    ).generate(str(df))\n\n    fig = plt.figure(1, figsize=(15,15))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=16)\n    fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"build_wordcloud(data['Candidate'], 'Prevalent words in Name for all dataset')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Party Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = data['Party'].value_counts().head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.barplot(x=temp.index, y=temp.values, palette='Set3')\nplt.xticks(rotation=90)\nplt.title('Number of Seats Contested by PARTIES (TOP 20)',fontsize=20)\nplt.ylabel('Number of Seats',fontsize=16)\nplt.xlabel('Political Parties',fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Candidate'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Mapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Party\"] = data[\"Party\"].astype(\"category\")\ndata = pd.get_dummies(data, columns = [\"Party\"],prefix=\"Party\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Education\"] = data[\"Education\"].astype(\"category\")\ndata = pd.get_dummies(data, columns = [\"Education\"],prefix=\"Education\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Constituency\"] = data[\"Constituency\"].astype(\"category\")\ndata = pd.get_dummies(data, columns = [\"Constituency\"],prefix=\"Constituency\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Gender'] = data['Gender'].map({'M':1, 'F':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.copy().drop('Winner', axis=1)\ny = data['Winner']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaled = preprocessing.scale(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.3)\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# k-nearest neighbor\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nknn_Y_pred = knn.predict(X_test)\nknn_accuracy = knn.score(X_test, Y_test)\nknn_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, knn_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, knn_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\ndecision_tree_Y_pred = decision_tree.predict(X_test)\ndecision_tree_accuracy = decision_tree.score(X_test, Y_test)\ndecision_tree_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, decision_tree_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, decision_tree_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nsvm_Y_pred = svc.predict(X_test)\nsvc_accuracy = svc.score(X_test, Y_test)\nsvc_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, svm_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, svm_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=1000)\nrandom_forest.fit(X_train, Y_train)\nrandom_forest_Y_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nrandom_forest_accuracy = random_forest.score(X_test, Y_test)\nrandom_forest_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, random_forest_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, random_forest_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gaussian Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\ngaussian_Y_pred = gaussian.predict(X_test)\ngaussian_accuracy = gaussian.score(X_test, Y_test)\ngaussian_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, gaussian_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, gaussian_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stochastic Gradient Descent Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nsgd_Y_pred = sgd.predict(X_test)\nsgd_accuracy = sgd.score(X_test, Y_test)\nsgd_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, sgd_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, sgd_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear SVM Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nlinear_svc_Y_pred = linear_svc.predict(X_test)\nlinear_svc_accuracy = linear_svc.score(X_test, Y_test)\nlinear_svc_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, linear_svc_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, linear_svc_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Linear SVC', 'Decision Tree','Random Forest', 'Stochastic Gradient Descent', 'Gaussian Naive Bayes'],\n    'Score': [svc_accuracy, knn_accuracy, linear_svc_accuracy, decision_tree_accuracy, random_forest_accuracy, sgd_accuracy, gaussian_accuracy]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}