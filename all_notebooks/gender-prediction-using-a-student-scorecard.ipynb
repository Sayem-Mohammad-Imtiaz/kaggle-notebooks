{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# turn off warnings for final notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)\n%matplotlib inline\nsns.set_context('notebook')\nsns.set_palette('Set2')\nsns.set_style('darkgrid')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0.Stablishing the goal\n\nIn this notebook, we will explore a dataset(https://www.kaggle.com/spscientist/students-performance-in-exams), which contains 1000 entries of students.  \nThe main goal will be to stablish a **gender prediction** with ML based on the available features and conclude about the most important features in this prediction. ","metadata":{}},{"cell_type":"markdown","source":"# 1.Importing","metadata":{}},{"cell_type":"code","source":"#Importing the dataset\ndf=pd.read_csv('../input/students-performance-in-exams/StudentsPerformance.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Exploring and Preparing","metadata":{}},{"cell_type":"code","source":"# general information about the dataset\ndf.info()\ndf.isnull().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see that there is apparently no absent data.  \nThe datatypes all seem to be right.","metadata":{}},{"cell_type":"markdown","source":"* **Numerical features**","metadata":{}},{"cell_type":"code","source":"\nnum = df.select_dtypes(include=np.number)\nnum.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(10,5))\nnum.boxplot(patch_artist=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At the boxplot, we see some outliers, but nothing unexpected considering a school exam.","metadata":{}},{"cell_type":"code","source":"# Frequency distribution\nfig, axs = plt.subplots(nrows=1,ncols=3, figsize=(20,5), sharey=True, tight_layout=True)\n\nbin_num=30\ncolors=['blue','red','green']\nfor i in range(0,3):\n    n, bins, patches = axs[i].hist(num[num.columns[i]],bins=bin_num,color=colors[i])\n    \n    axs[i].set_title(num.columns[i], size=20,fontweight='bold')\n    \naxs[0].set_ylabel('Frequency', size=20,fontweight='bold')\n\n#    mu    = num[num.columns[i]].mean()\n#    sigma = num[num.columns[i]].std()\n    \n#    y = ((1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 * (1 / sigma * (bins))**2))\n#    axs[i].plot(bins, y*100, '--')     ","metadata":{"_kg_hide-input":false,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The frequency distribution, also doesn't show anything unexpected, but there seems to be some bias towards the score of 70 in all exams.","metadata":{}},{"cell_type":"code","source":"\nfig, ax = plt.subplots(figsize=(10, 8))\nax.set_title(\"Correlation Matrix\\n\", size=20,fontweight='bold')\nsns.heatmap(num.corr(), annot=True,ax=ax,);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we see the correlation matrix of the numerical variables, namely the exams scores.  \nWe observe a very strong correlation between \"writing score\" and the \"reading score\".  \nWe also see a strong correlation between \"writing score\" and \"math score\".\nIt can be concluded that the performance of the stundents tend to be rather linear, if they have higher( or lower) score in one domain, it is expected the other domains to also be higher(or lower) and vice versa.","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(7, 7))\nsns.kdeplot(data=num, x=\"reading score\", y=\"writing score\", levels=50, color=\"b\",thresh=0,cmap=\"rocket\",fill=True)\nsns.kdeplot(data=num, x=\"math score\", y=\"writing score\", levels=50, color=\"b\",thresh=0,cmap=\"rocket\",fill=True)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with sns.axes_style(\"white\"):\n    g = sns.pairplot(df, diag_kind=\"kde\",height= 4,corner=True,diag_kws={\"linewidth\": 0, \"shade\": False})\n    g.map_lower(sns.kdeplot,  levels=50, color=\"b\",thresh=0,cmap=\"rocket\",fill=True)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.pairplot(df, diag_kind=\"kde\", height=4,hue='gender',corner=False)\ng.map_lower(sns.kdeplot,  levels=50,hue=None,thresh=0,cmap=\"rocket\",fill=True)\n#g.map_upper(stat_sig)\n\ng.fig.text(0.33, 1.02,'Distribution of Test Scores', fontsize=20)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see the distribution of the scores, now also in respect to the gender of the students.\n* There is overlap among the distributions, but we can see that the female students have a better mean performance in writing and reading, the male students in the other hand, have a slight edge in math\n* When combined, the writing and math scores, make distinct areas when it comes to gender. Those probably will be relevant predictors in the model.\n* Due to the overlap, it is important to check for the statistical relevance of the differences, especially in regard to math scores, where the distributions seems to be somewhat similar.","metadata":{}},{"cell_type":"code","source":"def stat_sig(x,y, **kwargs):\n    \n    # Calculate the value\n    print(x)\n    print(y)\n    print(kwargs)\n    '''\n    stat, p = ttest_ind(df[df['hue']=='female'], df[df['hue']=='male'])\n    \n    coef = p\n    # Make the label\n    label = r'$p$ = ' + str(round(coef, 2))\n    \n    # Add the label to the plot\n    ax = plt.gca()\n    ax.annotate(label, xy = (0.2, 0.95), size = 20, xycoords = ax.transAxes)\n    '''","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n'''\nFail to Reject H0: Sample distributions are equal.\nReject H0: Sample distributions are not equal.\n'''\nstat, p = ttest_ind(df['math score'][df['gender']=='female'], df['math score'][df['gender']=='male'])\nprint('Statistics=%.3f, p=%.3f \\n' % (stat, p))\n# interpret\nalpha = 0.05\nprint(\"Comparison between the math score of male and female students: \")\nif p > alpha:\n    print('Same distributions (fail to reject H0)')\nelse:\n    print('Different distributions (reject H0)')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Categorical varibles","metadata":{}},{"cell_type":"code","source":"cat = df.select_dtypes(exclude=np.number)\nprint(\"List of categorical variables:\")\ncat.columns","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_function(val):\n    return f'{val / 100 * len(df):.0f}\\n{val:.0f}%'\n\nfig, axs = plt.subplots(3,2, figsize=(15, 15))\nfor i in range(0,5):\n    cat.groupby(cat.columns[i]).size().plot(kind='pie', autopct=label_function, textprops={'fontsize': 13}, cmap='tab20c', ax=axs[int((i-i%2)/2),i%2])\n    axs[int((i-i%2)/2),i%2].set_title(cat.columns[i], size=20,fontweight='bold')\n    axs[int((i-i%2)/2),i%2].set_ylabel(None)\n\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see the distribution of the students among the categorical variables. No anomalities perceived.","metadata":{}},{"cell_type":"markdown","source":"* Categorical x Numerical","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Processing","metadata":{}},{"cell_type":"code","source":"# We are going to process data\n#First we have to give different treatment to three classes: ordinal Categorical features, non-ordinal Categorical features and Numerical features.\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\ncat = df.select_dtypes(exclude=np.number)\nnum = df.drop(columns=cat.columns) # Numerical features\nprint(\"Number of unique values per categorical feature:\\n\", cat.nunique())\n\ncat_ord = cat[['parental level of education','gender']] # ordinal categorical features\ncat.drop(columns=['parental level of education','gender'],inplace=True) #non-ordinal categorical features\n\n\n#Encoding ordinal categorical features\n\n# define order\norder_1 = ['high school', \n        'some high school',\n        'some college',\n        \"associate's degree\",\n        \"bachelor's degree\",  \n        \"master's degree\"]\norder_2 =['male','female']\n\n# define ordinal encoding\nencoder = OrdinalEncoder(categories=[order_1,order_2])\n# transform data\nencoder.fit(cat_ord[['parental level of education','gender']])\ncat_ord_encoded = pd.DataFrame(encoder.transform(cat_ord[['parental level of education','gender']]))\n\ncat_ord_encoded.columns = ['parental level of education','gender']\n\n\n#Encoding  non-ordinal categorical features\n\nenc = OneHotEncoder(sparse=False).fit(cat)\ncat_encoded = pd.DataFrame(enc.transform(cat))\ncat_encoded.columns = enc.get_feature_names(cat.columns)\n\n# Numerical features will be standardized\nfrom sklearn.preprocessing import StandardScaler\nnum.iloc[:, 0:3] = StandardScaler().fit_transform(num.iloc[:, 0:3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge numeric and categorical data\ndf2 = pd.concat([cat_encoded,cat_ord_encoded, num], axis=1)\ndf2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the dataset is ready to be inserted in a model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df2.drop(columns='gender')\ny = df2['gender']\n\n\nx_train , x_test , y_train, y_test = train_test_split(X,y,test_size = 0.2 , random_state = 23)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we split the dataset so we can test it for accuracy after modelling.","metadata":{}},{"cell_type":"markdown","source":"# 4.Prediction","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Random Forest","metadata":{}},{"cell_type":"code","source":"score_list = []\nfrom sklearn.ensemble import RandomForestClassifier\nfor each in range (1,100):\n    rf = RandomForestClassifier(n_estimators = each,random_state = 7,bootstrap = \"False\",criterion=\"gini\",\n                                min_samples_split = 10 , min_samples_leaf = 1)\n    rf.fit(x_train,y_train)\n    score_list.append(rf.score(x_test,y_test))\n    \nrf_max = np.max(score_list)\nprint(\"RF Max Score : \",rf_max)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(7, 7))\nplt.plot(score_list)\nplt.title(\"Accuracy x estimators\\n\", size=20,fontweight='bold')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can expect the random forest Classifier to have an accuracy around 85%.**","metadata":{}},{"cell_type":"code","source":"#Training with the best number of estimators\n\nbest = score_list.index(max(score_list)) + 1\n\nrf = RandomForestClassifier(n_estimators = best,random_state = 7,bootstrap = \"False\",criterion=\"gini\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf.fit(x_train,y_train)\n\n\nfrom sklearn.metrics import plot_confusion_matrix\n\nwith sns.axes_style(\"white\"):\n    titles_options = [(\"Confusion matrix, without normalization\", None),\n                      (\"Normalized confusion matrix\", 'true')]\n    class_names = ['Male','Female']\n    for title, normalize in titles_options:\n        fig, ax = plt.subplots(figsize=(7, 7))\n        disp = plot_confusion_matrix(rf, x_test, y_test,\n                                     display_labels=class_names,\n                                     cmap='rocket',\n                                     normalize=normalize,\n                                    ax=ax)\n        disp.ax_.set_title(title)\n\n        print(title)\n        print(disp.confusion_matrix)\n    \nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix show us that given the data available, it is easier to predict female students(90% accuracy). Male students incur in more false labelling as females(17%).","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Support Vector Machine","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvm1 = SVC(gamma = 0.01 , C = 500 , kernel = \"rbf\")\nsvm1.fit(x_train,y_train)\nsvm1_score = svm1.score(x_test,y_test)\nprint(\"SVM Max Score = : \", svm1_score)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with sns.axes_style(\"white\"):\n    titles_options = [(\"Confusion matrix, without normalization\", None),\n                      (\"Normalized confusion matrix\", 'true')]\n    class_names = ['Male','Female']\n    for title, normalize in titles_options:\n        fig, ax = plt.subplots(figsize=(7, 7))\n        disp = plot_confusion_matrix(svm1, x_test, y_test,\n                                     display_labels=class_names,\n                                     cmap='rocket',\n                                     normalize=normalize,\n                                    ax=ax)\n        disp.ax_.set_title(title)\n\n        print(title)\n        print(disp.confusion_matrix)\n    \nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**With the support vector machine model, we can expect a accuracy of 88,5%.**","metadata":{}},{"cell_type":"markdown","source":"# 5.Relative Relevance of features","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rf, random_state=1).fit(x_test, y_test)\neli5.show_weights(perm, feature_names = x_test.columns.tolist(), top=7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To establish the relative relevance of the features in predicting the gender of the student, we are going to model a Random Forest Regressor, so that the target variable become continuous. Afterward we are going to apply the **SHAP (SHapley Additive exPlanations)** to rank order the features. ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nbest = score_list.index(max(score_list)) + 1\n\nrf_reg = RandomForestRegressor(n_estimators = best,random_state = 7,bootstrap = \"False\",criterion=\"mse\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf_reg.fit(x_train,y_train)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n\n# calculate shap values \nex = shap.Explainer(rf_reg, x_train)\nshap_val = ex(x_test,check_additivity=False)\n\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.plots.bar(shap_val, show=False)\nplt.title('Mean SHAP value per feature\\n Gender Analysis',size=20,fontweight='bold')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see that the most important variables when predicting the target feature, namely \"gender\",are the writing, math and reading scores.  \nAll other variables are dispensable.","metadata":{}},{"cell_type":"code","source":"# plot\n\nplt.title('SHAP summary for Gender prediction', size=20)\nshap.plots.beeswarm(shap_val, max_display=5,show=False)\nfig = plt.gcf()\nfig.set_figheight(7)\nfig.set_figwidth(12)\nax = plt.gca()\nax.set_xlabel(r'Average SHAP values', fontsize=16)\nax.set_ylabel('Parameters', fontsize=16)\nleg = ax.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This beeswarp graph shows the dispersion of the SHAP values along the variables. As expected the three test scores contribute with higher absolute values, giving more certainty to the model prediction.","metadata":{}},{"cell_type":"code","source":"plt.title('SHAP Waterfall for individual number 280\\n', size=20)\nshap.plots.waterfall(shap_val[10])\n\nclass color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n\nprint(color.BOLD + \"Individual number 280\\n\" + color.END)\nprint(x_test.iloc[10])\nprint(color.BOLD + y_test.map({1:'female',0:\"male\"}).iloc[10] + color.END)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we apply the SHAP waterfall to a single individual. This allow us to follow the path the model takes and helps to understand why the top three variables are determinant in the assertion","metadata":{}},{"cell_type":"code","source":"explainer = shap.TreeExplainer(rf_reg)\nshap_values = explainer.shap_values(x_test)\nshap.dependence_plot(\"writing score\", shap_values, x_test,show=False)\nfig = plt.gcf()\nfig.set_figheight(7)\nfig.set_figwidth(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BONUS: Math Score prediction","metadata":{}},{"cell_type":"code","source":"X = df2.drop(columns='math score')\ny = df2['math score']\n\n\nx_train , x_test , y_train, y_test = train_test_split(X,y,test_size = 0.2 , random_state = 23)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nbest = score_list.index(max(score_list)) + 1\n\nrf_reg = RandomForestRegressor(n_estimators = best,random_state = 7,bootstrap = \"False\",criterion=\"mse\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf_reg.fit(x_train,y_train)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_list = []\nfor each in range (1,100):\n    rf = RandomForestRegressor(n_estimators = each,random_state = 7,bootstrap = \"False\",criterion=\"mse\",\n                                min_samples_split = 10 , min_samples_leaf = 1)\n    rf.fit(x_train,y_train)\n    score_list.append(rf.score(x_test,y_test))\n    \nrf_max = np.max(score_list)\nprint(\"RF Max Score : \",rf_max)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(7, 7))\nplt.plot(score_list)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best = score_list.index(max(score_list)) + 1\n\nrf = RandomForestRegressor(n_estimators = best,random_state = 7,bootstrap = \"False\",criterion=\"mse\",\n                            min_samples_split = 10 , min_samples_leaf = 1)\nrf.fit(x_train,y_train)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.plots.bar(shap_val)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n\n# calculate shap values \nex = shap.Explainer(rf_reg, x_train)\nshap_val = ex(x_test,check_additivity=False)\n\n# plot\n\nplt.title('SHAP summary for math score prediction', size=16)\nshap.plots.beeswarm(shap_val, max_display=5,show=False)\nfig = plt.gcf()\nfig.set_figheight(7)\nfig.set_figwidth(12)\nax = plt.gca()\nax.set_xlabel(r'Average SHAP values', fontsize=16)\nax.set_ylabel('Parameters', fontsize=16)\nleg = ax.legend()\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}