{"cells":[{"metadata":{"id":"Ziu0Kw9r9m_L","outputId":"1e466d28-33f4-4a8d-88b2-b1ca666d398e","trusted":true},"cell_type":"code","source":"#Importing Required Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import ttest_ind\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.stats.diagnostic import linear_rainbow\nimport scipy.stats as stats\nfrom mlxtend.feature_selection import SequentialFeatureSelector as sfs\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom statsmodels.tools.eval_measures import rmse\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom statsmodels.tsa.stattools import adfuller\n#from pandas.plotting import autocorrelation_plo\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nfrom statsmodels.tsa.arima.model import ARIMA\nimport statsmodels\nfrom pandas.tseries.offsets import DateOffset","execution_count":null,"outputs":[]},{"metadata":{"id":"gJzm40MB9m_k","trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (18,8) # Setting the size of the images used here.","execution_count":null,"outputs":[]},{"metadata":{"id":"osmUEdLF9m_m","outputId":"da79808e-9019-4a67-f3ed-11123aac71f8","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/walmart-sales-prediction/train.csv', parse_dates=['Date'])  # Training data\nfeatures = pd.read_csv('../input/walmart-sales-prediction/features.csv', parse_dates=['Date']) # Features\nstores = pd.read_csv('../input/walmart-sales-prediction/stores.csv')  # Store Details","execution_count":null,"outputs":[]},{"metadata":{"id":"YS2SFrEG9m_o","trusted":true},"cell_type":"code","source":"train_stores = pd.merge(left=train, right=stores, how='left', on='Store')  # Merging Train data and Stores Details","execution_count":null,"outputs":[]},{"metadata":{"id":"CcGQYRIs9m_r","outputId":"e84dd543-d569-4c91-d9f3-a2f4538cdcb3","scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.merge(left=train_stores, right=features, how='left', on=['Store','Date','IsHoliday'])  # Merging Train data, Stores and Features\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"k16qkVoL9m_x","outputId":"8b1550a4-4159-42fb-cf93-45fefe4a6866","trusted":true},"cell_type":"code","source":"print(f'Total number of rows --> {df.shape[0]}')\nprint(f'Total number of columns --> {df.shape[1]}')","execution_count":null,"outputs":[]},{"metadata":{"id":"RxIwXcDa9m_y","outputId":"b05ce0ed-6866-4d24-e92f-89d6922750d7","trusted":true},"cell_type":"code","source":"df.info()  # Information about the columns","execution_count":null,"outputs":[]},{"metadata":{"id":"ibniICTP9m_z","outputId":"a4a89df4-287c-40b7-8518-d1165d0d8586","scrolled":false,"trusted":true},"cell_type":"code","source":"df.describe().T  # Five Point Summary","execution_count":null,"outputs":[]},{"metadata":{"id":"GEguIlR39m_1","outputId":"00a4ee9e-05a7-48f3-a371-63fb719f1e37","trusted":true},"cell_type":"code","source":"df.columns   # Columns present in the dataset","execution_count":null,"outputs":[]},{"metadata":{"id":"REdaxrSZ9m_2","outputId":"55374aa0-2363-4084-9796-2cd82d1a938e","scrolled":false,"trusted":true},"cell_type":"code","source":"#Plotting a heatmap to check the missing values\nsns.heatmap(data = df.isna(), yticklabels=False, cbar=False, cmap='Wistia')\nplt.title('Missing Values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"RIlk0thV9m_4","outputId":"461c3c99-d1fa-4ca4-888d-318ff0b5d116","scrolled":true,"trusted":true},"cell_type":"code","source":"#Number of missing values\ndf.isna().sum().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"id":"FRdJ6TKH9m_7","outputId":"195e249c-27ea-478d-8fd0-d2bd6c7c2a0f","scrolled":true,"trusted":true},"cell_type":"code","source":"#Percentage of missing values\ndf.isna().sum().sort_values(ascending=False).head()/df.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{"id":"K7goOKT-9m_9","trusted":true},"cell_type":"code","source":"#Imputing the missing values with 0 as it means there is no discount available there\ndf.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"rZ9mmAUC9m_-","outputId":"077aeaee-f8ec-4bd7-a66f-46c3b3c3d4a7","scrolled":false,"trusted":true},"cell_type":"code","source":"#Plotting a heatmap again to confirm that there are no missing values\nsns.heatmap(data = df.isna(), yticklabels=False, cbar=False, cmap='Wistia')\nplt.title('Missing Values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"goEpc1Al9m__","trusted":true},"cell_type":"code","source":"df_markdown = df[['MarkDown1', 'MarkDown2', 'MarkDown3','MarkDown4', 'MarkDown5', 'Weekly_Sales']].copy()  # Creating a new dataframe with all MarkDowns and Weekly Sales.\ndf_markdown['Is_MarkDown'] = df_markdown.iloc[:,0:5].sum(axis=1).apply(lambda x: 0 if x == 0 else 1) # Add one new column is_MarkDown","execution_count":null,"outputs":[]},{"metadata":{"id":"Wvi4k2HO9nAA","trusted":true},"cell_type":"code","source":"df_is_markdown = df_markdown.loc[df_markdown['Is_MarkDown']==1, 'Weekly_Sales']  # Weekly Sales with MarkDown\ndf_no_markdown = df_markdown.loc[df_markdown['Is_MarkDown']==0, 'Weekly_Sales']  # Weekly Sales without MarkDown","execution_count":null,"outputs":[]},{"metadata":{"id":"AIvv7hWj9nAB","outputId":"d5d702e8-db68-476c-c33a-70ba7ef9f00a","trusted":true},"cell_type":"code","source":"df_is_markdown.shape, df_no_markdown.shape  # NUmber of records with and without MarkDown","execution_count":null,"outputs":[]},{"metadata":{"id":"Ff4eWyBw9nAC","outputId":"05a90122-f456-4298-ee18-c0bfa40160fe","trusted":true},"cell_type":"code","source":"print(f'Average Weekly Sales with Markdown --> {df_is_markdown.mean():.2f}\\nAverage Weekly Sales without Markdown --> {df_no_markdown.mean():.2f}')","execution_count":null,"outputs":[]},{"metadata":{"id":"mx_RDD2g9nAD","outputId":"52c9bd59-9197-4f70-9355-072b07b1068f","trusted":true},"cell_type":"code","source":"ttest_ind(df_is_markdown, df_no_markdown)  # Two Sample Independent T Test performed on weekly sales with MarkDown andd weekly sales without MarkDown","execution_count":null,"outputs":[]},{"metadata":{"id":"K7Ek2EJK9nAF"},"cell_type":"markdown","source":"**As we can see from the ttest, there is a significant difference between the Weekly Sales with Markdown and the Weekly Sales without Markdown.**"},{"metadata":{"id":"5Qunxd409nAF"},"cell_type":"markdown","source":"<h2 style='font-family:rockwell; color:#06917e'> Exploratory Data Analysis</h2>"},{"metadata":{"id":"453k4ZUI9nAG","outputId":"24d0cebd-3382-4ead-ed31-5ab7aa2f0f37","scrolled":false,"trusted":true},"cell_type":"code","source":"mask = np.triu(np.ones_like(df.corr(), dtype=bool))\nsns.heatmap(data=df.corr(), annot=True, cmap='afmhot_r', mask=mask)  # Heatmap for correlation\nplt.title('Correlation Matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"zmVUoaxy9nAH","outputId":"f7575427-0bc4-450d-dd8a-d499039fb987","scrolled":false,"trusted":true},"cell_type":"code","source":"cols_outlier = df[['Weekly_Sales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature','MarkDown1', 'MarkDown2', 'MarkDown3',\n       'MarkDown4', 'MarkDown5', 'Unemployment']]\nfig, axes = plt.subplots(4,3,figsize=(18,12))\nfig.suptitle('Outliers in the numerical features',fontsize=18, color = '#06917e', x = 0.5, y = 1.05)\nindex = [(i,j) for i in range(4) for j in range(3)]\nindex_count=0\nfor col in cols_outlier.columns:\n    sns.boxplot(x=col, ax=axes[index[index_count]], data=df, palette='afmhot_r')\n    index_count += 1\n    plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"gz0T-18R9nAK","outputId":"1ca742ce-256d-4a6c-d58b-1ea7c55689ea","scrolled":false,"trusted":true},"cell_type":"code","source":"sns.distplot(df['Weekly_Sales'], bins=30, kde=True)  # Distribution of Target Variable 'Weekly_Sales'\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"FMQ5oQ0-9nAL","outputId":"64d9c8c4-878c-4167-e4fa-01e33d47af21","trusted":true},"cell_type":"code","source":"sns.boxplot(x='Weekly_Sales', y='IsHoliday', data=df, orient='h', palette='afmhot_r')  # Effect of IsHoliday on Weekly Sales\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"pzeKRnEh9nAM","outputId":"01d99623-ec8d-4033-c8c1-9ef6ab566134","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3,2,figsize=(18,12))\nax_index = [(i,j) for i in range(3) for j in range(2)]\nindex_number = 0\nfig.suptitle('Effect of various factors on Weekly Sales',fontsize=18, color = '#06917e', y = 1.05)\nfor i in ['Unemployment','IsHoliday','Size','CPI','Temperature','Fuel_Price']:\n    sns.scatterplot(x=i, y='Weekly_Sales', data=df, ax=axes[ax_index[index_number]], palette='afmhot_r')\n    index_number += 1\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"id":"Fp56yyXM9nAN","outputId":"3724957e-85f9-4724-f3e0-49b9860af7a0","scrolled":false,"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Size', y='Type', data=df, palette='afmhot_r')\nplt.title('Size of the Store with respect to Type')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"IfhquRPf9nAO","outputId":"7a1f5e86-9a13-4e2a-bc91-ba1d0c3e2803","trusted":true},"cell_type":"code","source":"TypewiseSize = df.groupby(by='Type')['Size']\nprint(\"Median Size for Type A Stores --> \",TypewiseSize.get_group('A').median())\nprint(\"Median Size for Type B Stores --> \",TypewiseSize.get_group('B').median())\nprint(\"Median Size for Type C Stores --> \",TypewiseSize.get_group('C').median())","execution_count":null,"outputs":[]},{"metadata":{"id":"pOMNY7Y89nAP","outputId":"0072c9f8-c333-4428-fad4-41afaa82869b","scrolled":false,"trusted":true},"cell_type":"code","source":"sns.boxplot(y='Type',x='Weekly_Sales', data=df, orient='h', palette='afmhot_r')\nplt.title('Type wise Weekly Sales')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"sluAcg1b9nAQ","outputId":"1ada9751-49e9-40b3-d9a6-4dbb3fcc078d","scrolled":true,"trusted":true},"cell_type":"code","source":"TypewiseSales = df.groupby(by='Type')['Weekly_Sales']\nprint(\"Median Weekly Sales for Type A Stores --> \",TypewiseSales.get_group('A').median())\nprint(\"Median Weekly Sales for Type B Stores --> \",TypewiseSales.get_group('B').median())\nprint(\"Median Weekly Sales for Type C Stores --> \",TypewiseSales.get_group('C').median())","execution_count":null,"outputs":[]},{"metadata":{"id":"-v11_5zT9nAR"},"cell_type":"markdown","source":"**Average number of departments in each type**"},{"metadata":{"id":"ClArQlaB9nAS","outputId":"e2699463-4e94-4df8-a836-2e9d932e9d5d","trusted":true},"cell_type":"code","source":"#Average Sales per stores\navg_sales_per_store = df.groupby(by='Store')['Weekly_Sales'].mean()\nsns.barplot(x = avg_sales_per_store.index, y=avg_sales_per_store)\nplt.title('Average Sales per Store')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"kRwJ7c559nAT","outputId":"1de3ecc5-70dc-410d-cc2b-062f675960ca","trusted":true},"cell_type":"code","source":"avg_sales_per_store.sort_values(ascending = False).head()  # Top 5 most average weekly sales stores.","execution_count":null,"outputs":[]},{"metadata":{"id":"CHby_Kz29nAU","outputId":"cc5ec95f-bbaf-4c08-8bac-b829bc7ebd90","trusted":true},"cell_type":"code","source":"avg_sales_per_store.sort_values(ascending = False).tail()  # Bottom 5 less average weekly sales stores.","execution_count":null,"outputs":[]},{"metadata":{"id":"dmoudi8x9nAV","outputId":"d16fc837-6112-49a9-9043-3d979a6d7f90","scrolled":false,"trusted":true},"cell_type":"code","source":"#Average Sales per Department\navg_sales_per_dept = df.groupby(by='Dept')['Weekly_Sales'].mean()\nsns.barplot(x = avg_sales_per_dept.index, y=avg_sales_per_dept)\nplt.title('Average Sales per Department')\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"HAUV-_J29nAW","outputId":"91333eba-25bd-483e-998f-644741e43b8e","trusted":true},"cell_type":"code","source":"avg_sales_per_dept.sort_values().head(6)  # Bottom 6 departments with least average weekly sales. ","execution_count":null,"outputs":[]},{"metadata":{"id":"L5-cAa2s9nAX"},"cell_type":"markdown","source":"**As we can see from the above graph, few of the sales have almost no sales**"},{"metadata":{"id":"mUs2IKYt9nAX","outputId":"79ee1ba5-84c6-4f18-cd68-911c184a3a61","trusted":true},"cell_type":"code","source":"#Total Sales per stores\ntotal_sales_per_store = df.groupby(by='Store')['Weekly_Sales'].sum()\nsns.barplot(x = total_sales_per_store.index, y=total_sales_per_store)\nplt.title('Total Sales per Store')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Ug5hHfk89nAZ","outputId":"3a71529e-7f59-4eab-9309-002daec73b8b","scrolled":false,"trusted":true},"cell_type":"code","source":"total_sales_per_year = df.groupby(by=[df['Date'].dt.year, 'Type'])['Weekly_Sales'].sum()\ng = total_sales_per_year.unstack().plot(kind='bar')\nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.085, p.get_height()),ha='center', va='bottom',color= 'black')\nplt.title('Total Sales per Year - Type Wise')\nplt.xticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"0_75eVkp9nAc","outputId":"9b211c59-2403-4439-e06b-b4c6a64cf3d6","trusted":true},"cell_type":"code","source":"sns.barplot(x=df['Date'].dt.isocalendar().week, y=\"Weekly_Sales\", data=df, ci=None)\nplt.title('Week wise Total Sales')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"-sglGRfF9nAs","outputId":"c5a1aef1-024f-4fbe-9135-a180fa01b99d","scrolled":false,"trusted":true},"cell_type":"code","source":"df_2010 = df.loc[ (df['Date'].dt.year==2010), ['Date', 'Weekly_Sales'] ].groupby(by='Date').sum()\ndf_2011 = df.loc[ (df['Date'].dt.year==2011), ['Date', 'Weekly_Sales'] ].groupby(by='Date').sum()\ndf_2012 = df.loc[ (df['Date'].dt.year==2012), ['Date', 'Weekly_Sales'] ].groupby(by='Date').sum()\n\na10 = pd.DataFrame(data = {'Week_num':df_2010.index.isocalendar().week , 'Sales_2010':df_2010['Weekly_Sales']})\na11 = pd.DataFrame(data = {'Week_num':df_2011.index.isocalendar().week , 'Sales_2011':df_2011['Weekly_Sales']})\na12 = pd.DataFrame(data = {'Week_num':df_2012.index.isocalendar().week , 'Sales_2012':df_2012['Weekly_Sales']})\n\nx = pd.merge(a11, a10, how='outer', on='Week_num')\ny = pd.merge(a12, x, how='outer', on='Week_num')\n\nfor i in y.columns[1:]:\n    plt.plot(y['Week_num'], y[i], label=i)\nplt.ylabel(\"Sales in millions dollars\")\nplt.xlabel(\"Week of the Year\")\nplt.xticks(np.arange(1,53))\nplt.yticks(np.arange(20000000, 85000000, 5000000))\nplt.title('Weekly Sales over the Years')\nplt.legend()\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"oZ81vqtB9nAt","outputId":"d5c61ff1-4504-4800-9cc0-637be46d5ff1","scrolled":false,"trusted":true},"cell_type":"code","source":"df['Type'].value_counts(normalize=True).plot(kind='pie', autopct='%.2f', explode=[0.05,0.05,0.05])\nplt.legend(df['Type'].value_counts(normalize=True).index, loc = 'upper right')\nplt.title('Distribution of Store Types')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"UwURLG4V9nAu","outputId":"5ac48869-b9b1-4bf0-a12f-3257ab6a0d4d","scrolled":false,"trusted":true},"cell_type":"code","source":"month_wise_avg_sales=df.groupby(df['Date'].dt.month)['Weekly_Sales'].mean()\nplt.title('Month wise Average Sales')\ng = sns.barplot(x=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], y=month_wise_avg_sales)\nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),ha='center', va='bottom',color= 'black')","execution_count":null,"outputs":[]},{"metadata":{"id":"_r1RNn49FOEb"},"cell_type":"markdown","source":"<h2 style='font-family:rockwell; color:#06917e'> Linear Model:</h2>"},{"metadata":{"id":"NNen1kNGFHwn","trusted":true},"cell_type":"code","source":"df1 = df.drop(columns=['Date'])  # Dropping Date column as most of the values are unique","execution_count":null,"outputs":[]},{"metadata":{"id":"JqjUOAQ4FcpF","trusted":true},"cell_type":"code","source":"df1['IsHoliday'] = df1['IsHoliday'].apply(lambda x : 1 if x==True else 0)  # Label Encoding","execution_count":null,"outputs":[]},{"metadata":{"id":"0V5TlxA7Fcvc","trusted":true},"cell_type":"code","source":"df1 = pd.get_dummies(df1, drop_first=True)  # get_dummies for 'Type' column\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"JQ232IN1Fc06","trusted":true},"cell_type":"code","source":"inp = df1.drop('Weekly_Sales',1)  # Independent Features\nout = df1['Weekly_Sales']  # Dependent Features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc=StandardScaler()\ninp_sc=sc.fit_transform(inp.iloc[:,2:])\ninp_sc=pd.DataFrame(inp_sc,columns=inp.iloc[:,2:].columns)\ninp_sc = pd.concat((inp.iloc[:,0:2],inp_sc),axis=1)\ninp_sc.head(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"lJ2UGeB4Fc5X","trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(inp_sc,out,test_size = 0.3, random_state = 40)  # Splitting data into Train and Test","execution_count":null,"outputs":[]},{"metadata":{"id":"tx_KatG2FdBg","trusted":true},"cell_type":"code","source":"# Creating a base model using OLS\ninpc = sm.add_constant(inp_sc)\nols = sm.OLS(out,inpc)\nols_mod = ols.fit()\nols_mod.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Base Model using Scikit-learn\nlr=LinearRegression()\nlr.fit(xtrain,ytrain)\nypred=lr.predict(xtest)\nprint('R-Square Value:',r2_score(ytest,ypred))\nrmse=np.sqrt(mean_squared_error(ytest,ypred))\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for Assumptions:\n#Multi-collinearity\nvif = pd.DataFrame()\nvif['VIF'] = [variance_inflation_factor(inp_sc.values,i) for i in range(inp_sc.shape[1])]\nvif['Features'] = inp_sc.columns\nvif.sort_values('VIF', ascending= False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As all values are less than 5, There is no multi-colinearity present in the data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Auto Correlation\ninpc = sm.add_constant(xtrain)\nols = sm.OLS(ytrain,inpc)\nols_mod = ols.fit()\nols_mod.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As the value of Durbin-Watson test near 2, we can say there is no auto correlation present.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linearity\ninpc = sm.add_constant(inp_sc)\nols = sm.OLS(out,inpc)\nols_mod = ols.fit()\nstat,p_value = linear_rainbow(res = ols_mod, frac = 0.5)\nstat,p_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As the P-value greater than 0.05, It is following linearity.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Homoscedasticity\nsns.scatterplot(ols_mod.predict(),ols_mod.resid)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the graph, we can say that the model is homoscedastic.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Selection\nlr=LinearRegression()\nbackward=sfs(estimator=lr,k_features='best',forward=False,scoring='r2')\nsfs_backward=backward.fit(inp_sc,out)\nfeat_back=sfs_backward.k_feature_names_\nprint('Best Features using Backward Elimination:\\n',feat_back)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LinearRegression()\nforward=sfs(estimator=lr,k_features='best',forward=True,scoring='r2')\nsfs_forward=forward.fit(inp_sc,out)\nfeat_forw=sfs_forward.k_feature_names_\nprint('Best Features using Forward Selection:\\n',feat_forw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LinearRegression()\nrfe=RFECV(estimator=lr)\nrfe_mod=rfe.fit(inp_sc,out)\nrfe_mod.ranking_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rank=pd.DataFrame()\nrank['Features']=xtrain.columns\nrank['RANK']=rfe_mod.ranking_\nfeat_rfe=rank[rank['RANK']==1]['Features']\nrank.sort_values(by='RANK')\nprint('Best Features using Recursive Feature Elimination:\\n',feat_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_back =list(feat_back)\nfeat_forw =list(feat_forw)\nfeat_rfe=list(feat_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building Model using features got by Backward Elimination\nlr=LinearRegression()\nlr.fit(xtrain[feat_back],ytrain)\nypred=lr.predict(xtest[feat_back])\n\nr2=r2_score(ytest,ypred)\nrmse=np.sqrt(mean_squared_error(ytest,ypred))\n\nres_back=[r2,rmse]\nres_back","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building Model using features got by Forward Selection\nlr=LinearRegression()\nlr.fit(xtrain[feat_forw],ytrain)\nypred=lr.predict(xtest[feat_forw])\n\nr2=r2_score(ytest,ypred)\nrmse=np.sqrt(mean_squared_error(ytest,ypred))\n\nres_forw=[r2,rmse]\nres_forw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building Model using features got by Recursive Feature Elimination\nlr=LinearRegression()\nlr.fit(xtrain[feat_rfe],ytrain)\nypred=lr.predict(xtest[feat_rfe])\n\nr2=r2_score(ytest,ypred)\nrmse=np.sqrt(mean_squared_error(ytest,ypred))\n\nres_rfe=[r2,rmse]\nres_rfe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_card=pd.DataFrame()\nscore_card['Backward_Elmination']=res_back\nscore_card['Forward_Selection']=res_forw\nscore_card['RFE']=res_rfe\nscore_card.index=['Rsquare','RMSE']\nscore_card","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RFE is giving comparatively bettr result.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation Score using RFE\nlr=LinearRegression()\nres=cross_val_score(lr,inp_sc[feat_rfe],out,cv=3,scoring='neg_mean_squared_error')\nrmse=np.sqrt(abs(res))\nbe=np.mean(rmse)\nve=np.std(rmse)\ncvv=np.std(rmse)/np.mean(rmse)\nres_lr=[be,ve,cvv]\nres_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp_sc=inp_sc[feat_rfe]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Regularization\n# Ridge Model\nridge=Ridge()\nparam={'alpha':[0.0001,0.001,0.005,0.01,0.5,1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]}\ngrid=GridSearchCV(ridge,param_grid=param,cv=3,scoring='neg_mean_squared_error')\nmod_hyp=grid.fit(inp_sc,out) \nprint(mod_hyp.best_params_) \nprint(abs(mod_hyp.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge = Ridge(alpha = 100)\nres = cross_val_score(ridge,inp_sc,out,cv = 3,scoring = 'neg_mean_squared_error')\nrmse = np.sqrt(abs(res))\nbe = np.mean(rmse) #bias error\nve = np.std(rmse) #variance error\ncve = be/ve #coefficient of variance\nres_rid = [be,ve,cve]\nres_rid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lasso Model\nlasso=Lasso()\nparam={'alpha':[0.0001,0.001,0.005,0.01,0.5,1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]}\ngrid=GridSearchCV(lasso,param_grid=param,cv=3,scoring='neg_mean_squared_error')\nmod_hyp=grid.fit(inp_sc,out) \nprint(mod_hyp.best_params_) \nprint(abs(mod_hyp.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso = Lasso(alpha = 100)\nres = cross_val_score(lasso,inp_sc,out,cv = 3,scoring = 'neg_mean_squared_error')\nrmse = np.sqrt(abs(res))\nbe = np.mean(rmse) #bias error\nve = np.std(rmse) #variance error\ncve = be/ve #coefficient of variance\nres_las = [be,ve,cve]\nres_las","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ElasticNet Model\nenet=ElasticNet()\nparam={'alpha':[0.0001,0.001,0.005,0.01,0.5,1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]}\ngrid=GridSearchCV(enet,param_grid=param,cv=3,scoring='neg_mean_squared_error')\nmod_hyp=grid.fit(inp_sc,out) \nprint(mod_hyp.best_params_) \nprint(abs(mod_hyp.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enet = ElasticNet(alpha = 0.5)\nres = cross_val_score(enet,inp_sc,out,cv = 3,scoring = 'neg_mean_squared_error')\nrmse = np.sqrt(abs(res))\nbe = np.mean(rmse) #bias error\nve = np.std(rmse) #variance error\ncve = be/ve #coefficient of variance\nres_enet = [be,ve,cve]\nres_enet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_card=pd.DataFrame() \nscore_card['LR']=res_lr \nscore_card['Ridge']=res_rid \nscore_card['Lasso']=res_las \nscore_card['ElasticNet']=res_enet \nscore_card.index=['Bias Error','Variance Error', 'Coefficient of Variance'] \nscore_card","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the models, we can see that Linear Regression model is giving comparatively better result. But the r-square value is very less.**\n\n**So we will try Non-Linear Models.**"},{"metadata":{"id":"dFr0UbLAFd03"},"cell_type":"markdown","source":"<h2 style='font-family:rockwell; color:#06917e'> Non-Linear Models:</h2>"},{"metadata":{"id":"n950nqbTFh7C"},"cell_type":"markdown","source":"### Decision Tree Regressor\n#### Base Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = inp_sc\ny = out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tools.eval_measures import rmse","execution_count":null,"outputs":[]},{"metadata":{"id":"dngueFUHJRsv","trusted":true},"cell_type":"code","source":"dtree=  DecisionTreeRegressor()\ndtree.fit(xtrain,ytrain)\n\nytrain_pred = dtree.predict(xtrain)\nytest_pred = dtree.predict(xtest)\n\nprint('RMSE score of train data: ', rmse(ytrain, ytrain_pred) )\nprint('R^2 score of train data: ',r2_score(ytrain, ytrain_pred) )\n\nprint('RMSE score of test data: ', rmse(ytest, ytest_pred) )\nprint('R^2 score of test data: ', r2_score(ytest, ytest_pred) )","execution_count":null,"outputs":[]},{"metadata":{"id":"qe6VGtBoJFUv","outputId":"769996dc-a8ce-4017-a06c-735f1e118577","trusted":true},"cell_type":"code","source":"result_rmse_score = pd.DataFrame(index=['Training','Testing'])\nresult_r2_score = pd.DataFrame(index=['Training','Testing'])","execution_count":null,"outputs":[]},{"metadata":{"id":"8i9nu5n8Ogoc","trusted":true},"cell_type":"code","source":"result_rmse_score['DT Base Model'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['DT Base Model'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tuning with RandomizedCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeRegressor() # estimator\n\n\nparam_dist = {'max_depth' : np.arange(5,20),\n             'min_samples_leaf':[15,17,20,25,30,35,40],\n              'min_samples_split':[2,5,8,10,12,15],\n              'criterion':['mse']}\n\n\nrsearch  = RandomizedSearchCV(dtree, param_distributions = param_dist, cv=4) \n\nrsearch.fit(x,y)\nrsearch.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating tuned model with best params of RandomizedCV object"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_rand_tuned = DecisionTreeRegressor(**rsearch.best_params_)\ndtree_rand_tuned.fit(xtrain,ytrain)\n\n\nytrain_pred = dtree_rand_tuned.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred) )\nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\n\nytest_pred = dtree_rand_tuned.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred) )\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['DT Tuned Model'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['DT Tuned Model'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble Technique:\n### Bagging:"},{"metadata":{},"cell_type":"markdown","source":"### Random Forest\n#### Base Random Forest Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf1 = RandomForestRegressor()\nrf1.fit(xtrain, ytrain)\n\n\nytrain_pred =  rf1.predict(xtrain)\nprint('RMSE of Train Data: ', rmse(ytrain, ytrain_pred))\nprint('R^2 score of Train Data: ', r2_score(ytrain, ytrain_pred))\n\n\nytest_pred =  rf1.predict(xtest)\nprint('RMSE of Test Data: ', rmse(ytest, ytest_pred))\nprint('R^2 score of Test Data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['RF Base Model'] = [rmse(ytrain, ytrain_pred),rmse(ytest, ytest_pred) ]\nresult_r2_score['RF Base Model'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tuning Random forest model with RandomizedCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf2 = RandomForestRegressor()\n\n\nparam_dist = { 'n_estimators':sp_randint(50,100),\n              'max_features': sp_randint(1,14),\n              'max_depth' : sp_randint(5,20),\n             'min_samples_leaf':sp_randint(10,50),\n              'min_samples_split':sp_randint(2,50)}\n\n\nrsearch_rf  = RandomizedSearchCV(estimator=rf2, param_distributions = param_dist, cv=4, random_state=4) \n\nrsearch_rf.fit(x,y)\nrsearch_rf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsearch_rf.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating tuned model with best params of RandomizedCV object"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestRegressor(**rsearch_rf.best_params_)\n\nrf_tuned.fit(xtrain,ytrain)\n\nytrain_pred = rf_tuned.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = rf_tuned.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['RF Tuned Model'] = [rmse(ytrain, ytrain_pred),rmse(ytest, ytest_pred) ]\nresult_r2_score['RF Tuned Model'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned.fit(xtrain,ytrain)\npd.DataFrame(index=xtrain.columns, data=rf_tuned.feature_importances_, columns=['feat']).sort_values(by='feat',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extra Tree Regressor\n#### Base Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"et = ExtraTreesRegressor()\net.fit(xtrain, ytrain)\n\nytrain_pred =  et.predict(xtrain)\nprint('RMSE of Train Data: ', rmse(ytrain, ytrain_pred))\nprint('R^2 score of Train Data: ', r2_score(ytrain, ytrain_pred))\n\n\nytest_pred =  et.predict(xtest)\nprint('RMSE of Test Data: ', rmse(ytest, ytest_pred))\nprint('R^2 score of Test Data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['ETR Base Model'] = [rmse(ytrain, ytrain_pred),rmse(ytest, ytest_pred) ]\nresult_r2_score['ETR Base Model'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tuning the Extra Tree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"etr2 = ExtraTreesRegressor()\n\n\nparam_dist = { 'n_estimators':sp_randint(50,100),\n              'max_features': sp_randint(1,14),\n              'max_depth' : sp_randint(5,20),\n             'min_samples_leaf':sp_randint(10,50),\n              'min_samples_split':sp_randint(2,50)}\n\n\nrsearch_etr  = RandomizedSearchCV(estimator=etr2, param_distributions = param_dist, cv=4, random_state=4) \n\nrsearch_etr.fit(x,y)\nrsearch_etr.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating tuned model with best params of RandomizedCV object"},{"metadata":{"trusted":true},"cell_type":"code","source":"etr_tuned = ExtraTreesRegressor(**rsearch_etr.best_params_)\netr_tuned.fit(xtrain, ytrain)\n\nytrain_pred = etr_tuned.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = etr_tuned.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['ETR Tuned Model'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['ETR Tuned Model'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"result_r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"etr_tuned.fit(xtrain, ytrain)\netr_tuned.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(index=xtrain.columns, data=etr_tuned.feature_importances_, columns=['feat']).sort_values(by='feat',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Boosting:\n#### AdaBoost:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada = AdaBoostRegressor(random_state=48)\nada.fit(xtrain,ytrain)\n\nytrain_pred = ada.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = ada.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['AdaBoost'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['AdaBoost'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gradient Boost:"},{"metadata":{"trusted":true},"cell_type":"code","source":"grad = GradientBoostingRegressor(random_state=48)\ngrad.fit(xtrain,ytrain)\n\nytrain_pred = grad.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = grad.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['Gradient Boost'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['Gradient Boost'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LightGBM:"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbmr = LGBMRegressor(random_state=48)\nlgbmr.fit(xtrain,ytrain)\n\nytrain_pred = lgbmr.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = lgbmr.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['LightGBM'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['LightGBM'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbmr.fit(xtrain, ytrain)\nlgbmr.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(index=xtrain.columns, data=lgbmr.feature_importances_, columns=['feat']).sort_values(by='feat',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBoost:"},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = XGBRegressor(random_state=48)\nxg.fit(xtrain,ytrain)\n\nytrain_pred = xg.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = xg.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['XGBoost'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['XGBoost'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg.fit(xtrain, ytrain)\nxg.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(index=xtrain.columns, data=xg.feature_importances_, columns=['feat']).sort_values(by='feat',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbor Regressor:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsRegressor()\nknn.fit(xtrain,ytrain)\n\nytrain_pred = knn.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = knn.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score['KNN'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['KNN'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RMSE Scorecard:"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### R-square Scorecard:"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As we are getting best result for Random Forest Regressor and LightGBM, we will use these two ensemble methods in stacking to get best result.**"},{"metadata":{},"cell_type":"markdown","source":"## Stacking Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestRegressor(**rsearch_rf.best_params_)\netr_tuned = ExtraTreesRegressor(**rsearch_etr.best_params_)\nlgbmr = LGBMRegressor(random_state=48)\nxg = XGBRegressor(random_state=48)\n\nestimators = [('rf_tuned', rf_tuned),('etr_tuned',etr_tuned),('lgbmr', lgbmr), ('xg',xg)]\n\nstack1 = VotingRegressor(estimators=estimators)\n\nstack1.fit(xtrain, ytrain)\n\nytrain_pred = stack1.predict(xtrain)\nprint('RMSE on train data: ', rmse(ytrain, ytrain_pred)) \nprint('R^2 on train data: ', r2_score(ytrain, ytrain_pred))\n\nytest_pred = stack1.predict(xtest)\nprint('RMSE on test data: ', rmse(ytest, ytest_pred))\nprint('R^2 on test data: ', r2_score(ytest, ytest_pred))\n\nresult_rmse_score['Stacked Model'] = [rmse(ytrain, ytrain_pred), rmse(ytest, ytest_pred) ]\nresult_r2_score['Stacked Model'] = [r2_score(ytrain, ytrain_pred),r2_score(ytest, ytest_pred) ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RMSE Scorecard:"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### R-square Scorecard:"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_rmse_score.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_1 =  result_rmse_score.drop(columns=['AdaBoost']).T\nr2_1 =  result_r2_score.drop(columns=['AdaBoost']).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,5))\nplt.plot(rmse_1['Training'], label='Train')\nplt.plot(rmse_1['Testing'], label='Test')\nplt.title('RMSE score')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,5))\nplt.plot(r2_1['Training'], label='train')\nplt.plot(r2_1['Testing'], label='Test')\nplt.title('R2 score')\nplt.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}