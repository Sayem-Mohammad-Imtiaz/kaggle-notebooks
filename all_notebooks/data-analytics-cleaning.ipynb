{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as plt # graphs and plotting\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pulls in the CSV for the DataAnalyst"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/data-analyst-jobs/DataAnalyst.csv\") #Pull in the DataAnalyst CSV\ndf.rename(columns = {\"Unnamed: 0\":\"Index\"}, inplace = True) #Replace the weird name for the index column\ndf.head() #View the dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removes the salary listings that are -1 (Null)"},{"metadata":{"trusted":true},"cell_type":"code","source":"values = df[\"Salary Estimate\"] #Puts the salary estimate \n\n#For loop to check for null values\nfor i in range(0,len(df.index)):\n    if values[i] == \"-1\": #If the estimate is null\n        df.drop(df.index[i],inplace=True) #Drop the line with the null value\ndf.reset_index(drop=True, inplace=True) #Reset indecies so we can still loop through\ndf.head() #Opens up the dataframe to take a peek","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removes the fluff from the Salary Estimate Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimate = df[\"Salary Estimate\"].apply(lambda x: x.split(\"(\")[0]) #Lambda function to remove the (Glassdoor est.) from the row\nestimate = estimate.replace({\"\\$\" : \"\",\"K\" : \"\"},regex = True) #Takes out the dollar sign and k off of the numbers\ndf[\"Salary Estimate\"] = estimate #Puts the variable removing the fluff back into the dataframe\ndf.head() #Take a peek at the dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Divide the salary estimate into high and low for later math"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"low_estimate\"] = df[\"Salary Estimate\"].apply(lambda x: x.split(\"-\")[0]).astype(int) #Gets the low salary estimate as a new column\ndf[\"high_estimate\"] = df[\"Salary Estimate\"].apply(lambda x: x.split(\"-\")[1]).astype(int) #Gets the high salary estimate as a new column\ndf.head() #Take a peek at the dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pull the state out from the city, as a better metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"states = df[\"Location\"].apply(lambda x: x.split(\", \")[1]) #Pull the state from the location\ndf[\"State\"] = states.apply(lambda x: \"CO\" if \"Arapahoe\" in x else x) #Arapahoe comes from \"Greenwood Village, Arapahoe, CO\" in the data\ndf[\"State\"].value_counts() #Make sure there is no problems in the state data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fix easy apply and competitors to remove the -1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Easy Apply\"] = df[\"Easy Apply\"].apply(lambda x: False if x==\"-1\" else True) #Fixed Easy Apply to True/False\ndf[\"Competitors\"] = df[\"Competitors\"].apply(lambda x: \"None\" if x==\"-1\" else x) #Changed competitors from -1 to None\ndf.head() #Take a peek at the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Replace the newline \\n from Description and Company Name"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Company Name\"] = df[\"Company Name\"].astype(str).apply(lambda x: x.split(\"\\n\")[0]) #Removed the rating off the end of the company name\ndf[\"Job Description\"] = df[\"Job Description\"].replace({\"\\n\" : \" \"}, regex=True) #Turned the description into one long string, deleting \\n characters\ndf.head() #Take a peek at the dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get the length of the description"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Description Length\"] = df[\"Job Description\"].apply(lambda x: len(x)) #Get the length of the description using a lambda function\ndf.head() #Take a peek at the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make a column simply saying if there is a competitor or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Has_Competitor\"] = df[\"Competitors\"].apply(lambda x: False if x==\"None\" else True) #Created a new row to see if the company has any competitors\nprint(df[\"Has_Competitor\"].value_counts()) #Display the counts of the true or false","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Change the -1 null value to unknown in Industry"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Industry = df.Industry.apply(lambda x: \"Undefined\" if x==\"-1\" else x) #another cleaning aspect it seems I overlooked, but fixed here\nprint(df[\"Industry\"].value_counts()) #Display the counts of each industry","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Change the null values to Unknown in the Revenue column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Revenue\"] = df[\"Revenue\"].apply(lambda x: \"Unknown / Non-Applicable\" if x==\"-1\" else x) #Fixing the null values in the revenue column\nprint(df[\"Revenue\"].value_counts()) #Display the counts of each revenue class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fix the null values (-1) in the Company Size column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Size\"] = df[\"Size\"].apply(lambda x: \"Unknown\" if x==\"-1\" else x) #Update null values in the Size area\nprint(df[\"Size\"].value_counts()) #Display the counts of each size class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Drop the Index column, as it was only needed in cleanup"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop([\"Index\"], axis=1) #Drop the index column, as it is not really needed in analysis\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Send newly cleaned data to a new CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(r\"./DataAnalytics_clean.csv\", index = False) #Sends the data to a new csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}