{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Flight delay time exploratory data analysis\n\n**For this week's exercises, scroll down to \"Part 2\"**."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport seaborn as sns\nimport networkx as nx\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we read in the input files. We can use the `glob` package with `*` as a wildcard to make a list of all the csv files, and then open and concatenate all the files in the list to get a single dataframe."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.concat([pd.read_csv(f) for f in glob.glob(\"/kaggle/input/historical-flight-and-weather-data/*.csv\") ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, lets explore some basic characteristics of our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(20,20)); # Tip: put a semicolon at the end of the line to avoid printing a bunch of text output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So from the initial analysis above, we can see that we've got a database of 5.5 billion flights, with each record including information about the airline (\"carrier_code\"), origin and destination airport, date and time, and weather information. This dataset is not well documented, but we'll assume that `*_x` corresponds to weather at the origin airport and `*_y` corresponds to weather at the destination airport. There is also information about flight delays and cancellations.\n\nOur goal is always to do something useful. Some useful things we could do with this dataset could be to gain insight into what conditions are related to delayed and canceled flights, and potentially predict or avoid those delays in the future, so we will explore the dataset with that goal in mind.\n\nFirst, we'll look into the frequency of delays and cancellations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.arrival_delay > 0).sum() / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.arrival_delay > 30).sum() / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.arrival_delay > 60).sum() / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.departure_delay > 0).sum() / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"((df.arrival_delay > 0) & (df.departure_delay > 0)).sum() / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.cancelled_code.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.cancelled_code != \"N\").sum() / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above, we can see that 34% of flight arrivals are delayed, 12% are delayed by more than 30 minutes, and 7% are delayed by more than one hour. (We're assuming the times are in minutes. Hopefully the benefit of having a well-documented dataset is apparent here.)\n\nIf we assume that a cancelled code of \"N\" means not cancelled, and everything else is cancelled, then about 1.5% of flights are cancelled.\n\nWe can start out by looking at how conditions were different for flights that were canceled compared to other flights. One way to do this is to create two sets of histograms:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cancel = df[df.cancelled_code != \"N\"]\ndf_cancel.hist(figsize=(20,20)); ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nocancel = df[df.cancelled_code == \"N\"]\ndf_nocancel.hist(figsize=(20,20)); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One insight this gives us is that the max windspeed for non-canceled flights appears much higher than the max windspeed for flights that were canceled. TWe can investigate this further:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_cancel.HourlyWindSpeed_x.mean(), df_cancel.HourlyWindSpeed_x.median(), df_cancel.HourlyWindSpeed_x.max())\nprint(df_nocancel.HourlyWindSpeed_x.mean(), df_nocancel.HourlyWindSpeed_x.median(), df_nocancel.HourlyWindSpeed_x.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 2: Network analysis\n\nLast week, we started an exploratory analysis of this dataset, treating it as tabular data. However there is also a graph or network aspect of this datasetâ€”it's a \"transportation network'. This week, we will explore that aspect.\n\nFirst, let's calculate the number of flights on each \"route\", which is the number of flights that share an origin and destination airport:"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_flights = df.groupby(by=[\"origin_airport\", \"destination_airport\"]).size()\n\nnum_flights.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, let's create a directed graph of the different routes."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(num_flights.reset_index()).dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_flights = num_flights.reset_index()\n\nnum_flights.columns = ['origin_airport','destination_airport','num_flights']\n\ng = nx.DiGraph()\n\nfor _, edge in num_flights.iterrows():\n    g.add_edge(edge['origin_airport'], edge['destination_airport'], weight=edge['num_flights'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can make a plot of the graph:"},{"metadata":{"trusted":true},"cell_type":"code","source":"nx.draw(g)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, let's calculate the degree centrality and (weighted) betweenness centrality of each airport and create a data frame that includes the columns `airport`, `deg_cen`, and `bet_cen`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"deg_cen = nx.degree_centrality(g)\n\ndf_deg_cen = pd.DataFrame(deg_cen.items())\ndf_deg_cen.columns = [\"airport\", \"deg_cen\"]\n\ndf_deg_cen.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bet_cen = nx.betweenness_centrality(g, weight=\"weight\")\n\ndf_bet_cen = pd.DataFrame(bet_cen.items())\ndf_bet_cen.columns = [\"airport\", \"bet_cen\"]\n\ndf_bet_cen.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bet_cen.set_index(\"airport\", inplace=True)\ndf_deg_cen.set_index(\"airport\", inplace=True)\n\n\nnet_stats = df_bet_cen\nnet_stats[\"deg_cen\"] = df_deg_cen.deg_cen\n\nnet_stats.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nNow, let's add our network statistics for each airport to data frame of flights:"},{"metadata":{"trusted":true},"cell_type":"code","source":"net_stats.reset_index(inplace=True)\n\ndf_net_stats = df.merge(net_stats, left_on=\"origin_airport\", right_on=\"airport\")\n\ndf_net_stats[\"origin_bet_cen\"] = df_net_stats[\"bet_cen\"]\ndf_net_stats[\"origin_deg_cen\"] = df_net_stats[\"deg_cen\"]\ndf_net_stats.drop([\"airport\", \"deg_cen\", \"bet_cen\"], inplace=True, axis=1)\n\ndf_net_stats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_net_stats = df_net_stats.merge(net_stats, left_on=\"destination_airport\", right_on=\"airport\")\n\ndf_net_stats[\"destination_bet_cen\"] = df_net_stats[\"bet_cen\"]\ndf_net_stats[\"destination_deg_cen\"] = df_net_stats[\"deg_cen\"]\ndf_net_stats.drop([\"airport\", \"deg_cen\", \"bet_cen\"], inplace=True, axis=1)\n\ndf_net_stats.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, let's calculate the correlations of our network statistics with our \"departure delay\" dependent variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_net_stats[[\"arrival_delay\", \"destination_bet_cen\",\"destination_deg_cen\", \"origin_bet_cen\",\"origin_deg_cen\"]].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Can you conclude anything from these correlations?"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}