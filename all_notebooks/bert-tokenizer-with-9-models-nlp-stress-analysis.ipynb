{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://data.whicdn.com/images/266750169/original.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Acknowledgements\n\nTurcan, E., & McKeown, K. (2019). Dreaddit: A Reddit dataset for stress analysis in social media. arXiv preprint arXiv:1911.00133.\n\n# The relevant research paper link can be found here: -\nhttps://aclanthology.org/D19-6213.pdf","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv(\"../input/stress-analysis-in-social-media/dreaddit-train.csv\")\ntest = pd.read_csv(\"../input/stress-analysis-in-social-media/dreaddit-test.csv\")\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.516359Z","iopub.execute_input":"2021-07-03T16:48:46.516965Z","iopub.status.idle":"2021-07-03T16:48:46.693255Z","shell.execute_reply.started":"2021-07-03T16:48:46.51684Z","shell.execute_reply":"2021-07-03T16:48:46.691969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.695299Z","iopub.execute_input":"2021-07-03T16:48:46.695814Z","iopub.status.idle":"2021-07-03T16:48:46.73639Z","shell.execute_reply.started":"2021-07-03T16:48:46.695758Z","shell.execute_reply":"2021-07-03T16:48:46.735194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.columns)\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.738611Z","iopub.execute_input":"2021-07-03T16:48:46.73895Z","iopub.status.idle":"2021-07-03T16:48:46.750993Z","shell.execute_reply.started":"2021-07-03T16:48:46.738913Z","shell.execute_reply":"2021-07-03T16:48:46.749685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.columns)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.754574Z","iopub.execute_input":"2021-07-03T16:48:46.755249Z","iopub.status.idle":"2021-07-03T16:48:46.766396Z","shell.execute_reply.started":"2021-07-03T16:48:46.755198Z","shell.execute_reply":"2021-07-03T16:48:46.764881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#categorical columns\ntrain.select_dtypes(include=['object']).columns.tolist()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.768806Z","iopub.execute_input":"2021-07-03T16:48:46.769402Z","iopub.status.idle":"2021-07-03T16:48:46.783911Z","shell.execute_reply.started":"2021-07-03T16:48:46.769349Z","shell.execute_reply":"2021-07-03T16:48:46.782634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.select_dtypes(include=['object']).columns.tolist()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.78585Z","iopub.execute_input":"2021-07-03T16:48:46.786474Z","iopub.status.idle":"2021-07-03T16:48:46.801836Z","shell.execute_reply.started":"2021-07-03T16:48:46.786406Z","shell.execute_reply":"2021-07-03T16:48:46.80055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.subreddit.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.803554Z","iopub.execute_input":"2021-07-03T16:48:46.803898Z","iopub.status.idle":"2021-07-03T16:48:46.813546Z","shell.execute_reply.started":"2021-07-03T16:48:46.803864Z","shell.execute_reply":"2021-07-03T16:48:46.812697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.subreddit.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.816347Z","iopub.execute_input":"2021-07-03T16:48:46.81697Z","iopub.status.idle":"2021-07-03T16:48:46.832186Z","shell.execute_reply.started":"2021-07-03T16:48:46.816925Z","shell.execute_reply":"2021-07-03T16:48:46.830673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(['post_id', 'sentence_range', 'id'], axis = 1)\ntest = test.drop(['post_id', 'sentence_range', 'id'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.834384Z","iopub.execute_input":"2021-07-03T16:48:46.834755Z","iopub.status.idle":"2021-07-03T16:48:46.853198Z","shell.execute_reply.started":"2021-07-03T16:48:46.834719Z","shell.execute_reply":"2021-07-03T16:48:46.851647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train,test],axis=0,ignore_index=True)\ndf = df.sample(frac = 1).reset_index(drop = True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.855202Z","iopub.execute_input":"2021-07-03T16:48:46.855841Z","iopub.status.idle":"2021-07-03T16:48:46.927963Z","shell.execute_reply.started":"2021-07-03T16:48:46.855798Z","shell.execute_reply":"2021-07-03T16:48:46.92683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['subreddit'] = le.fit_transform(df['subreddit'])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:46.929753Z","iopub.execute_input":"2021-07-03T16:48:46.930112Z","iopub.status.idle":"2021-07-03T16:48:47.297822Z","shell.execute_reply.started":"2021-07-03T16:48:46.930077Z","shell.execute_reply":"2021-07-03T16:48:47.296598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:47.299483Z","iopub.execute_input":"2021-07-03T16:48:47.299822Z","iopub.status.idle":"2021-07-03T16:48:47.340009Z","shell.execute_reply.started":"2021-07-03T16:48:47.299785Z","shell.execute_reply":"2021-07-03T16:48:47.338727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label ---> 1 (Stress)\n\nLabel ---> 0 (Not stress)","metadata":{}},{"cell_type":"code","source":"df.corr().abs()['label'].sort_values(ascending = False)[:30]","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:47.341569Z","iopub.execute_input":"2021-07-03T16:48:47.341929Z","iopub.status.idle":"2021-07-03T16:48:47.484088Z","shell.execute_reply.started":"2021-07-03T16:48:47.341892Z","shell.execute_reply":"2021-07-03T16:48:47.482844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport transformers\nimport tqdm\nfrom keras.preprocessing import sequence\n\n#creating a function\ndef func_tokenizer(tokenizer_name, docs):\n    features = []\n    for doc in tqdm.tqdm(docs, desc = 'converting documents to features'):\n        tokens = tokenizer_name.tokenize(doc)\n        ids = tokenizer_name.convert_tokens_to_ids(tokens)\n        features.append(ids)\n    return features\nprint(\"The function is created successfully\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:47.485627Z","iopub.execute_input":"2021-07-03T16:48:47.485976Z","iopub.status.idle":"2021-07-03T16:48:49.622779Z","shell.execute_reply.started":"2021-07-03T16:48:47.485939Z","shell.execute_reply":"2021-07-03T16:48:49.621657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT tokenizer","metadata":{}},{"cell_type":"code","source":"#Initialize bert tokenizer\nbert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-large-uncased')\n\nX,y = df[['text', 'lex_liwc_Tone', 'lex_liwc_negemo', 'lex_liwc_Clout','lex_liwc_i', 'sentiment' ]], df['label']\nbert_features = func_tokenizer(bert_tokenizer, X['text'])","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:48:49.624046Z","iopub.execute_input":"2021-07-03T16:48:49.624354Z","iopub.status.idle":"2021-07-03T16:49:02.153325Z","shell.execute_reply.started":"2021-07-03T16:48:49.624323Z","shell.execute_reply":"2021-07-03T16:49:02.152281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_trg = sequence.pad_sequences(bert_features, maxlen = 500)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:49:02.154701Z","iopub.execute_input":"2021-07-03T16:49:02.155016Z","iopub.status.idle":"2021-07-03T16:49:02.303452Z","shell.execute_reply.started":"2021-07-03T16:49:02.15498Z","shell.execute_reply":"2021-07-03T16:49:02.30227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.DataFrame(bert_trg)\n\nX = X.assign(lex_liwc_negemo = df['lex_liwc_negemo'].values)\nX = X.assign(lex_liwc_Tone= df['lex_liwc_Tone'].values)\nX = X.assign(lex_liwc_Clout = df['lex_liwc_Clout'].values)\nX = X.assign(lex_liwc_i = df['lex_liwc_i'].values)\nX = X.assign(sentiment = df['sentiment'].values)\nX = X.assign(lex_dal_min_pleasantness = df['lex_dal_min_pleasantness'].values)\nX = X.assign(lex_liwc_posemo = df['lex_liwc_posemo'].values)\nX = X.assign(lex_liwc_anx = df['lex_liwc_anx'].values)\nX = X.assign(lex_liwc_Authentic = df['lex_liwc_Authentic'].values)\nX = X.assign(lex_liwc_social = df['lex_liwc_social'].values)\nX = X.assign(lex_liwc_Analytic = df['lex_liwc_Analytic'].values)\nX = X.assign(lex_liwc_function = df['lex_liwc_function'].values)\nX = X.assign(lex_liwc_Dic = df['lex_liwc_Dic'].values)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:49:02.304858Z","iopub.execute_input":"2021-07-03T16:49:02.305198Z","iopub.status.idle":"2021-07-03T16:49:02.389856Z","shell.execute_reply.started":"2021-07-03T16:49:02.305162Z","shell.execute_reply":"2021-07-03T16:49:02.388694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:49:02.391403Z","iopub.execute_input":"2021-07-03T16:49:02.391795Z","iopub.status.idle":"2021-07-03T16:49:02.712708Z","shell.execute_reply.started":"2021-07-03T16:49:02.391742Z","shell.execute_reply":"2021-07-03T16:49:02.711134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=UserWarning)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:49:02.714329Z","iopub.execute_input":"2021-07-03T16:49:02.714727Z","iopub.status.idle":"2021-07-03T16:49:02.821341Z","shell.execute_reply.started":"2021-07-03T16:49:02.714683Z","shell.execute_reply":"2021-07-03T16:49:02.820359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# All 9 models to be applied","metadata":{}},{"cell_type":"code","source":"def get_models():\n    \n    models = dict()\n    models['lr'] = make_pipeline(StandardScaler(),LogisticRegression(solver = 'saga', C = 70.0))\n    models['knn'] = make_pipeline(StandardScaler(),KNeighborsClassifier())\n    models['cart'] = DecisionTreeClassifier(max_depth = 1)\n    models['svm'] = make_pipeline(StandardScaler(),SVC())\n    models['bayes'] = make_pipeline(StandardScaler(), GaussianNB())\n    models['xgboost'] = XGBClassifier(n_estimators = 11, max_depth = 1)\n    models['GBM'] = GradientBoostingClassifier(n_estimators = 10)\n    models['rf'] = RandomForestClassifier(n_estimators = 10)\n    models['adaboost'] = AdaBoostClassifier(n_estimators= 12)\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:49:02.822794Z","iopub.execute_input":"2021-07-03T16:49:02.823467Z","iopub.status.idle":"2021-07-03T16:49:02.83265Z","shell.execute_reply.started":"2021-07-03T16:49:02.823394Z","shell.execute_reply":"2021-07-03T16:49:02.8316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models to be applied with 10 fold repeated stratified K fold cross validation","metadata":{}},{"cell_type":"code","source":"# evaluate a given model using cross-validation\ndef evaluate_model(model, X, y):\n\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=4, random_state=1)\n\tscores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n\treturn scores","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:49:02.834142Z","iopub.execute_input":"2021-07-03T16:49:02.834505Z","iopub.status.idle":"2021-07-03T16:49:02.855485Z","shell.execute_reply.started":"2021-07-03T16:49:02.834469Z","shell.execute_reply":"2021-07-03T16:49:02.854245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom numpy import mean\nfrom numpy import std\n\n# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n\tscores = evaluate_model(model, X, y)\n\tresults.append(scores)\n\tnames.append(name)\n\tprint('>%s %.2f (%.2f)' % (name, scores.mean(), std(scores)))\n# plot model performance for comparison\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:49:02.857437Z","iopub.execute_input":"2021-07-03T16:49:02.857968Z","iopub.status.idle":"2021-07-03T16:51:42.803113Z","shell.execute_reply.started":"2021-07-03T16:49:02.857921Z","shell.execute_reply":"2021-07-03T16:51:42.801666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic regression, XGBoost and SVM gave the highest accuracy!","metadata":{}},{"cell_type":"markdown","source":"# The relevant research paper link can be found here: -\nhttps://aclanthology.org/D19-6213.pdf","metadata":{}},{"cell_type":"markdown","source":"# According to the research paper too, logistic regression gave the highest accuracy.","metadata":{}},{"cell_type":"markdown","source":"# Upvote if you like it.","metadata":{}}]}