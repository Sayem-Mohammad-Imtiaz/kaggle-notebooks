{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tarea 1 - Fraschini, Rovira - Grupo 2\n\nCargar el dataset usando la libreria pandas y guardarlo en una variable llamada dataset.","metadata":{}},{"cell_type":"code","source":"import pandas\ndataset = pandas.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parte 1 \n\nAnálisis de los datos y correlación.","metadata":{}},{"cell_type":"markdown","source":"### Tipos\n\nPara comenzar con el análisis de los datos, obtendremos el tipo de cada una de las variables que lo conforman y la cantidad de valores no nulos ingresados en cada una de ellas.","metadata":{}},{"cell_type":"code","source":"dataset.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Con esto, se puede observar que el dataset tiene 12 columnas y 1599 filas. De las 12 columnas, 11 son de tipo float64 y una de tipo int64. Además se puede ver que no hay ningún dato nulo ya que todas las columnas tienen 1599 datos no nulos que es el total de datos del dataset.\n\n### Descripción del dataset\n\nLuego, usaremos la funcion describe() sobre el dataset para obtener: cantidad de entradas del dataset (count), promedio de cada una de las variables (mean), desviacion estandar (std). Además incluye los 5 percentiles mas importantes que son: valor minimo (min); valor del primer cuartil, es decir que el 25% de los datos estan por debajo de este valor (25%); valor del segundo cuartil, el 50% de los datos esta por debajo de este valor y el otro 50% por encima (50%); valor del tercer cuartil, el 75% de los datos esta por debajo de este valor (75%); y por último el valor máximo de la variable (max) ","metadata":{}},{"cell_type":"code","source":"dataset.describe(include='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlación entre todas las variables 2 a 2.\n\nLa correlación se expresa en un coeficiente de correlación que varía entre -1 y +1. La correlación negativa es cuando un incremento en una variable causa un decremento en la otra. La correlación cero es que no hay ninguna relación entre las variaciones de las dos variables. La correlación de una variable con ella misma siempre es +1. Cuanto más cerca de 1 este el valor absoluto de la correlación entre de 2 variables, más estrechamente ligados estan los cambios de una con los de la otra. La correlación no responde a una relación de causa y efecto.\nPara obtener la correlación entre todas las variabes 2 a 2, se invocará la funcion corr() sobre el dataset. ","metadata":{}},{"cell_type":"code","source":"dataset.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gráfica de Correlación \n\nSe usa la función heatmap de seaborn y matplotlib para renderizar los valores de correlación hallados anteriormente. \nLas celdas quedan coloreadas según su valor. \nPodemos ver como la diagonal es la parte más oscura del heatmap ya que es la correlación más alta porque es la de cada variable consigo misma.\nLuego hay diferentes matices pero se observa que ninguna de las correlaciones supera el 0.7 de valor absoluto. Más aún, la correlación entre la calidad del vino que es la variable de estudio, y las demás variables nunca alcanza el 0.5.","metadata":{}},{"cell_type":"code","source":"import seaborn\nimport matplotlib.pyplot as plot\n\ncm = seaborn.color_palette(\"Spectral\", as_cmap=True)\nplot.figure(figsize=(15, 8))\nseaborn.heatmap(dataset.corr(), annot = True, square=True, cmap=cm)\nplot.title('Correlación')\nplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parte 2\n\nSe aplicará el método de regresión lineal para predecir la calidad del vino teniendo en cuenta los valores del resto de las variables. Para esto se separa el dataset en un conjunto de datos de entrada que contiene todos los features salvo la calidad del vino y otro conjunto de datos que sería la salida que solo contiene los valores de calidad del vino.\nSe usará el 80% de los datos para entrenar el modelo y el otro 20% para testearlo.\nLa regresión lineal es un algoritmo de aprendizaje supervisado que estudia la mejor relación funcional para un conjunto de puntos. El mejor modelo es aquel que minimiza el error de Y = B0 + B1X. \n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.feature_selection import RFE\nimport numpy\n\nlinearReg = LinearRegression()\n\nx = dataset.drop(['quality'],axis=1)\ny = dataset['quality']\n\nspl = 0.8\nN = len(y)\nsample = int(spl*N)\n\nx_train, x_test, y_train, y_test = x[:sample], x[sample:], y[:sample], y[sample:]\n\nlinearReg.fit(x_train,y_train)\n\npredictionsLin = linearReg.predict(x_test)\nres = numpy.c_[predictionsLin, y_test]\n\n# print(res)\n\nplot.figure(figsize=(15,8))\nplot.ylabel('Predicciones')\nplot.xlabel('Valores de test')\nplot.scatter(y_test,predictionsLin, alpha=0.3)\n\nprint('Mean Squared Error:', mean_squared_error(y_test, predictionsLin))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aplicando regresión lineal al dataset obtenemos un error cuadrático medio de 0.43. Que es el promedio de los errores al cuadrado. Los errores son la diferencia entre las variables y de test y las predicciones realizadas por el algoritmo.","metadata":{}},{"cell_type":"markdown","source":"### Mecanismos de mejora\n\n#### Eliminacion de ouliers\n\nEn primer lugar, intentaremos determinar que variables en el dataset tienen outliers, es decir, valores numéricamente distantes del resto de los datos, que puedan afectar la predicción que se realiza. Luego de determinar los valores a partir de los cuales una entrada se consideraría un outlier, eliminaremos esas entradas y se realizará de nuevo la regresión lineal con el nuevo dataset sin outliers.\nA continuación se grafican todas las variables contra la calidad del vino para determinar los valores a partir de los cuales consideraremos que el dato es un oulier.","metadata":{}},{"cell_type":"code","source":"dataOut = dataset ## usamos este nuevo dataset llamado dataOut para sacarle los outliers al original\nseaborn.set(rc={'figure.figsize':(8,5)})\nseaborn.boxplot(x=dataOut['quality'], y=dataOut['fixed acidity'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 11 de fixed acidity es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['volatile acidity'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 1.1 de volatile acidity es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['citric acid'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 0.6 de citric acid es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['residual sugar'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 3.5 de residual sugar es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['chlorides'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 0.16 de chlorides es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['free sulfur dioxide'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 25 de free sulfur dioxide es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['total sulfur dioxide'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 90 de total sulfur dioxide es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['density'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 1000 o menor a 0.994 de density es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['pH'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 3.6 o menor a 3.0 de pH es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['sulphates'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 0.88 de sulphates es un outlier","metadata":{}},{"cell_type":"code","source":"seaborn.boxplot(x=dataOut['quality'], y=dataOut['alcohol'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos que cualquier valor mayor a 13 de alcohol es un outlier.\nEliminaremos todas las entradas con outliers y haremos de nuevo la predicción usando regresión lineal.","metadata":{}},{"cell_type":"code","source":"dataOut = dataOut.drop(dataOut[dataOut['fixed acidity'] > 11].index)\ndataOut = dataOut.drop(dataOut[dataOut['volatile acidity'] > 1.1].index)\ndataOut = dataOut.drop(dataOut[dataOut['citric acid'] > 0.6].index)\ndataOut = dataOut.drop(dataOut[dataOut['residual sugar'] > 3.5].index)\ndataOut = dataOut.drop(dataOut[dataOut['chlorides'] > 0.16].index)\ndataOut = dataOut.drop(dataOut[dataOut['free sulfur dioxide'] > 25].index)\ndataOut = dataOut.drop(dataOut[dataOut['total sulfur dioxide'] > 90].index)\ndataOut = dataOut.drop(dataOut[dataOut['density'] > 1000].index)\ndataOut = dataOut.drop(dataOut[dataOut['density'] < 0.994].index)\ndataOut = dataOut.drop(dataOut[dataOut['pH'] > 3.6].index)\ndataOut = dataOut.drop(dataOut[dataOut['pH'] < 3.0].index)\ndataOut = dataOut.drop(dataOut[dataOut['sulphates'] > 0.88].index)\ndataOut = dataOut.drop(dataOut[dataOut['alcohol'] > 13].index)\n\nx = dataOut.drop(['quality'],axis=1)\ny = dataOut['quality']\n\nspl = 0.8\nN = len(y)\nsample = int(spl*N)\n\nx_train, x_test, y_train, y_test = x[:sample], x[sample:], y[:sample], y[sample:]\n\nlinearReg.fit(x_train,y_train)\n\npredictionsOut = linearReg.predict(x_test)\nres = numpy.c_[predictionsOut, y_test]\n\n# print(res)\n\nplot.ylabel('Predicciones')\nplot.xlabel('Valores de test')\nplot.scatter(y_test,predictionsOut, alpha=0.3)\n\nprint('Mean Squared Error:', mean_squared_error(y_test, predictionsOut))\ndataOut.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se puede observar que el dataset ahora tiene solo 800 entradas y antes eran 1599.\nEl error, que antes era de 0.43, ahora es de 0.39","metadata":{}},{"cell_type":"markdown","source":"#### RFE\n\nOtro mecanismo de mejora es eliminar los features que no colaboran a la predicción. Para esto utilizaremos el RFE de sklearn que selecciona las columnas más relevantes en la predicción sobre el dataset original (es decir, el que tiene outliers).\nRealizando pruebas, pudimos ver que el numero optimo de features era 7. ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nx = dataset.drop(['quality'],axis=1)\ny = dataset['quality']\n\nspl = 0.8\nN = len(y)\nsample = int(spl*N)\n\nx_train, x_test, y_train, y_test = x[:sample], x[sample:], y[:sample], y[sample:]\n\nlinearReg = LinearRegression()\nrfe = RFE(linearReg, n_features_to_select=7)\n\nrfe.fit(x_train,y_train)\n\npredictionsRFE = rfe.predict(x_test)\nres = numpy.c_[predictionsRFE, y_test]\n\n# print(res)\n\nplot.ylabel('Predicciones')\nplot.xlabel('Valores de test')\nplot.scatter(y_test,predictionsRFE, alpha=0.3)\n\nprint('Mean Squared Error:', mean_squared_error(y_test, predictionsRFE))\n             \nisSelected = pandas.Series(rfe.support_,index = x_train.columns)\nselected_features_rfe = isSelected[isSelected==True].index\nselectedToShow = pandas.DataFrame(selected_features_rfe, \n             columns=['Varibales seleccionadas'])\ndisplay(selectedToShow)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Utilizando RFE sobre el dataset original el error es de 0.42.","metadata":{}},{"cell_type":"markdown","source":"#### RFE sobre el dataset sin outliers\n\nPor último aplicaremos la eliminación de features al dataset sin outliers.","metadata":{}},{"cell_type":"code","source":"x = dataOut.drop(['quality'],axis=1)\ny = dataOut['quality']\n\nspl = 0.8\nN = len(y)\nsample = int(spl*N)\n\nx_train, x_test, y_train, y_test = x[:sample], x[sample:], y[:sample], y[sample:]\n\nlinearReg = LinearRegression()\nrfe = RFE(linearReg, n_features_to_select=7)\n\nrfe.fit(x_train,y_train)\n\npredictionsOutRFE = rfe.predict(x_test)\nres = numpy.c_[predictionsOutRFE, y_test]\n\n# print(res)\n\nplot.ylabel('Predicciones')\nplot.xlabel('Valores de test')\nplot.scatter(y_test,predictionsOutRFE, alpha=0.3)\n\nprint('Mean Squared Error:', mean_squared_error(y_test, predictionsOutRFE))\n             \nisSelected = pandas.Series(rfe.support_,index = x_train.columns)\nselected_features_rfe = isSelected[isSelected==True].index\nselectedToShow = pandas.DataFrame(selected_features_rfe, \n             columns=['Varibales seleccionadas'])\ndisplay(selectedToShow)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En esta última predicción se obtiene un error menor a todos los anteriores que se obtuvieron usando regresión lineal. Aunque tanto eliminar los outliers como eliminar lso features que no colaboran a la predicción ayudan. Se observa que eliminar los outliers tiene un mayor impacto y que, si se aplican ambos mecanismos en simultáneo, el error es el menor obtenido","metadata":{}},{"cell_type":"markdown","source":"## Parte 3\n\nSe clasificará la calidad del vino como buena o mala. \nLuego se utilizará el método de regresión logística y el de Naive Bayes para realizar las predicciones y se compararán los resultados usando algunas métricas.","metadata":{}},{"cell_type":"code","source":"dataset['quality'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Umbral\n\nUtilizaremos como valor de corte para la clasificación el 6. \nTodas las entradas cuyo valor de calidad sea menor o igual a 6 serán etiquetadas como vino malo. Las que tengan una calidad mayor a 6 serán etiquetadas como vino bueno.\n\nAgregamos un 0 y un 1 delante de las categorias porque sino la grafica de roc se da vuelta por un tema de orden alfabético.","metadata":{}},{"cell_type":"code","source":"dataset['quality'] = pandas.cut(dataset['quality'], bins = (2, 6, 8), labels = ['0malo', '1bueno'])\n\ndataset.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Método de regresión logística\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nx = dataset.drop(['quality'],axis=1)\ny = dataset['quality']\n\nspl = 0.8\nN = len(y)\nsample = int(spl*N)\n\nx_train, x_test, y_train, y_test = x[:sample], x[sample:], y[:sample], y[sample:]\n\nlogRegression = LogisticRegression(solver='lbfgs', max_iter=10000)\nlogRegression.fit(x_train, y_train)\npredictionsLR = logRegression.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nx = dataset.drop(['quality'],axis=1)\ny = dataset['quality']\n\nspl = 0.8\nN = len(y)\nsample = int(spl*N)\n\nx_train, x_test, y_train, y_test = x[:sample], x[sample:], y[:sample], y[sample:]\n\nnaiveBayes=GaussianNB()\nnaiveBayes.fit(x_train,y_train)\npredictionsNB=naiveBayes.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn\nfrom sklearn.metrics import confusion_matrix\n\nmat = confusion_matrix(y_test, predictionsLR)\nseaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, cmap=cm)\nplot.xlabel('Test')\nplot.ylabel('Prediccion Regresion Logistica')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matNB = confusion_matrix(y_test, predictionsNB)\nseaborn.heatmap(matNB.T, square=True, annot=True, fmt='d', cbar=False, cmap=cm)\nplot.xlabel('Test')\nplot.ylabel('Prediccion Naive Bayes')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Matriz de confusión\n\nAnalizando las matrices de confusión que se desprenden de las predicciones de cada uno de los métodos, podemos ver que usando regresión logística los resultados son mejores ya que acierta 296 veces y no lo hace solo en 24 casos. \nPor otro lado, el algoritmo de Naive Bayes acierta 283 veces y no lo hace 37 veces.\n\n#### Curva ROC\n\nA continuacion graficaremos la ROC para ambos métodos. \nfpr es la razon de falsos positivos y tpr es la razon de verdaderos positivos.\nSi la ROC grafica un rectangulo, la prediccion es perfecta y el modelo es capaz de distinguir sin error entre un buen vino y un mal vino.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\n\nprobasLR = logRegression.predict_proba(x_test)\nfpr, tpr, thresholds = roc_curve(y_test, probasLR[:, 1], pos_label='1bueno')\n\nplot.plot([0,1], [0,1], 'k-.')\nplot.plot(fpr, tpr, label = 'LR')\nplot.xlabel('fpr')\nplot.ylabel('tpr')\nplot.title('ROC para regresion logistica')\nplot.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probasNB = naiveBayes.predict_proba(x_test)\nfpr, tpr, thresholds = roc_curve(y_test, probasNB[:, 1], pos_label='1bueno')\n\nplot.plot([0,1],[0,1],'k-.')\nplot.plot(fpr, tpr, label='NB') \nplot.xlabel('fpr')\nplot.ylabel('tpr')\nplot.title('Curva ROC para Naive Bayes')\nplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Area bajo la curva roc\n\nLo importante es el area bajo la curva que analizaremos a continuacion. \nEl modelo es perfecto si el area es 1. Y cuanto más cerca de 1 este ese numero, mejor es la predicción aunque no sea absolutamnete perfecta.","metadata":{}},{"cell_type":"code","source":"print(roc_auc_score(y_test, probasLR[:, 1]))\nprint(roc_auc_score(y_test, probasNB[:, 1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aqui se observa que el modelo de Naive Bayes arroja un resultado mejor que el de regresion logistica cuando se trata del area bajo la curva roc.\n\n#### Reporte de clasificacion","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\nprint (classification_report(y_test,predictionsLR))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (classification_report(y_test,predictionsNB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El report de clasificacion lanza varias metricas.\nEn primer lugar, la precision indica que tan preciso es el modelo para la prediccion de positivos y de negativos.\nEl recall calcula cuantos de los verdaderos positivos (o negativos) son efectivamente capturados por el modelo.\nEl f1 score es una media armonica entre la precision y el recall.\nEn el promedio ponderado de estas metricas, podemos ver que funciona mejor la regresion logistica ya que tiene mejores valores en recall y en f1 score que naive bayes y tiene la misma precision.\nEn el promedio sin ponderar, el modelo naive bayes parece ser mejor en recall y f1 score mientras que el de regresion logistica es mejor en la precision.","metadata":{}},{"cell_type":"markdown","source":"#### Accuracy","metadata":{}},{"cell_type":"code","source":"print (accuracy_score(y_test,predictionsLR))\nprint (accuracy_score(y_test,predictionsNB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El accuracy es la cantidad de resultados verdaderos (true positive and true negative) sobre el total de los casos examinados.\nEn esta métrica es bastante mejor e. modelo de regresion logistica ya que tiene un accuracy del 93% frente a un 88% que arroja el modelo de Naive Bayes\n\n#### Feature relevance\n\nTécnica que asigna un valor a los features de entrada en función a la utilidad que tienen para predecir la calidad del vino, en este caso.\nEl permutation importance permite ver cuanto cambian los resultados del modelo si se cambian aleatoriamente de posición los valores de una columna. Si el modelo cambia mucho, es porque esa columna era importante para la predicción.\nAdemás, el coef_ en la regresión logística es el coeficiente de cada uno de los features en la función de decisión.","metadata":{}},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\n\nimpsLR = permutation_importance(logRegression, x_test, y_test)\nimportancesLR = impsLR.importances_mean\nstdLR = impsLR.importances_std\nindicesLR = numpy.argsort(importancesLR)[::-1]\n\nimpsNB = permutation_importance(naiveBayes, x_test, y_test)\nimportancesNB = impsNB.importances_mean\nstdNB = impsNB.importances_std\nindicesNB = numpy.argsort(importancesNB)[::-1]\n\nimportanceLR = pandas.DataFrame(logRegression.coef_[0], \n             x.columns, \n             columns=['coeficiente LR'])\\\n            .sort_values(by='coeficiente LR', ascending=False)\n\nimportancePermLR = pandas.DataFrame(importancesLR[indicesLR], \n             x.columns[indicesLR], \n             columns=['coeficiente permutación LR'])\\\n            .sort_values(by='coeficiente permutación LR', ascending=False)\n\nimportanceNB = pandas.DataFrame(importancesNB[indicesNB], \n             x.columns[indicesNB], \n             columns=['coeficiente permutación NB'])\\\n            .sort_values(by='coeficiente permutación NB', ascending=False)\n\ndisplay(importanceLR)\ndisplay(importancePermLR)\ndisplay(importanceNB)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parte 4\n\nBases teóricas del algoritmo k-NN (k-nearest neighbors) y aplicacion al dataset.\n\n### Bases teóricas\n\nEl algoritmo del k-nearest neighbors es un algoritmo de clasificación que toma un montón de puntos marcados y los utiliza para aprender a etiquetar otros puntos. Este algoritmo clasifica los casos nuevos basados en su similitud con otros casos ya presentes en el conjunto de datos de entrenamiento. Los puntos de datos que están cerca entre sí se dice que son “vecinos”. El algoritmo se basa en este paradigma: Casos similares con las mismas etiquetas de clase están cerca el uno al otro.\nLa distancia entre dos casos es una medida de su disimilitud. Existen diferentes maneras de calcular la similitud, la distancia o la disimilitud de dos puntos de datos. El más común es la distancia de Euclidiana.\nEl k lo elige el investigador dependiendo del conjunto de datos e indica la cantidad de vecinos que se evaluarán. La exactitud del algoritmo depende del k elegido. Si se elige un k = 1 solo se considera el vecino más cercano de todos.","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nx = dataset.drop(['quality'],axis=1)\ny = dataset['quality']\n\nspl = 0.8\nN = len(y)\nsample = int(spl*N)\n\nx_train, x_test, y_train, y_test = x[:sample], x[sample:], y[:sample], y[sample:]\n\nknn = KNeighborsClassifier()\nknn.fit(x_train,y_train)\npredictionsKNN=knn.predict(x_test)\nprint(classification_report(y_test, predictionsKNN))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pandas.DataFrame({'models': [\"Logistic regression\",\"Naive Bayes\",\"KNN\"],\n                           'accuracies': [accuracy_score(y_test,predictionsLR),accuracy_score(y_test,predictionsNB),accuracy_score(y_test,predictionsKNN)]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparación con parte 3 \n\nSe puede observar que el algoritmo de knn tiene una mejor accuracy que el de naive bayes pero no que el de regresion logistica.","metadata":{}},{"cell_type":"markdown","source":"## Parte 5 \n\nLuego de realizar el trabajo, se pudieron sacar varias conclusiones.\nEn primer lugar, la importancia de contar con un buen dataset, con muchos datos para evaluar pero lo más libre de outliers presentes en sus muestras ya que se vio que estos valores atípicos afectan notoriamente las predicciones.\nAdemás, no siempre lo mejor es tener la mayor cantidad de features posibles, sino las que más colaboren con la predicción que se desea realizar. Algunas features del dataset es preferible dejarlas fuera del conjunto de datos que alimenta el modelo porque puede que lo perjudiquen.\nTambién se observó que la primera predicción puede no ser la más acertada y se debe intentar mejorar los datos de entrada del modelo para mejorar las predicciones y disminuir el error lo más posible.\nTambién se observo que no alcanza con evaluar los métodos con una sola métrica ya que muchas veces un método arroja mejores resultados en cierta métrica pero peores en otra y entonces la elección del método debe depender del objetivo que se persiga.\nSe aprecia, además, lo sencillo que es realizar predicciones sobre un conjunto de datos determinado si se cuenta con las herramientas adecuadas.\nEn conclusión, se analizaron los datos con éxito y se logró aprender a trabajar con cada uno de los modelos vistos en el curso de manera práctica.","metadata":{}}]}