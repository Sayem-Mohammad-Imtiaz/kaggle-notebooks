{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HackerEarth Machine Learning Challenge: Exhibit A(rt) "},{"metadata":{},"cell_type":"markdown","source":"**Points:**\n* Trying to learn Machine Learning by participating in the competitions.\n* Achieved accuracy of 94%, and trying to further improve it.\n* Beginner in Machine Leraning, so may be there will be naive mistake, **feedbacks are most welcome**.\n* Used feature_engine library. Install it on kaggle using `!pip install feature_engine`"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install feature_engine","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\npd.options.display.max_columns = None\n\nimport seaborn as sns\nimport feature_engine.transformation as vt #Please install #!pip install feature_engine\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train =  pd.read_csv('/kaggle/input/hackerearth-machine-learning-exhibit-art/dataset/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function Definitions"},{"metadata":{"trusted":true},"cell_type":"code","source":"float_var_list = ['Artist Reputation',\n 'Height',\n 'Width',\n 'Weight',\n 'Price Of Sculpture',\n 'Base Shipping Price']\n\nArtist_Reputation_mean = df_train['Artist Reputation'].mean()\nHeight_mean = df_train['Height'].mean()\nWidth_mean = df_train['Width'].mean()\nWeight_median = df_train['Weight'].mean()\n\ndf_train_copy = df_train.copy(deep=True)\ndf_train_copy['State_code'] = df_train_copy['Customer Location'].str.split(',', expand=True)[1].str.slice(0, 3)\n\n\ndef create_dummies_columns(df, column_name, prefix_str):\n    temp_df  =  pd.get_dummies(df[column_name], prefix=prefix_str, drop_first=True)\n    df.drop([column_name],  axis = 1, inplace=True)\n    df = pd.concat([df, temp_df], axis = 1)\n    return df\n\ndef prepare_data(df):\n    df.drop(['Customer Id', 'Artist Name'], axis = 1, inplace=True)\n    df['Artist Reputation_NA'] = np.where(df['Artist Reputation'].isnull(), 1, 0)\n    df['Artist Reputation'].fillna(Artist_Reputation_mean, inplace = True)\n    \n    df['Transport_NA'] = np.where(df['Transport'].isnull(), 1, 0)\n    df['Transport'].fillna(df['Transport'].mode()[0], inplace = True)\n    \n    df['Remote_Location_NA'] = np.where(df['Remote Location'].isnull(), 1, 0)\n    df['Remote Location'].fillna(df['Remote Location'].mode()[0], inplace = True)\n    \n    df['Height_NA'] = np.where(df['Height'].isnull(), 1, 0)\n    df['Height'].fillna(Height_mean, inplace = True)\n    df['Height'] = np.exp(df['Height'])\n    \n    \n    df['Width_NA'] = np.where(df['Width'].isnull(), 1, 0)\n    df['Width'].fillna(Width_mean, inplace = True)\n    df['Width'] = np.log(df['Width'])\n    \n    df['Weight_NA'] = np.where(df['Weight'].isnull(),1,0)\n    df['Weight'].fillna(Weight_median, inplace = True)\n    df['Weight'] = np.log(df['Weight'])\n    \n    df['Material_NA'] = np.where(df['Material'].isnull(), 1, 0)\n    df['Material'].fillna('NA', inplace = True)\n    #Below code is to fill Random in Material\n    #random_sample_Material = df_train_copy['Material'].dropna().sample(df['Material'].isnull().sum(),\n    #                                                                   random_state=\n    #                                                                   np.log(np.abs(df_train_copy['Cost'])).astype(int))\n    \n    #random_sample_Material.index = df[df['Material'].isnull()].index\n    #df.loc[df['Material'].isnull(), 'Material'] = random_sample_Material\n    \n    df['Price Of Sculpture'] = np.log(df['Price Of Sculpture'])\n\n    df['Delivery Date'] = pd.to_datetime(df['Delivery Date'], format='%m/%d/%y')\n    df['Scheduled Date'] = pd.to_datetime(df['Scheduled Date'], format='%m/%d/%y')\n    df['del_date_sch_date_diff'] = (df['Delivery Date'] - df['Scheduled Date']).dt.days\n    df['del_date_sch_date_diff'] = np.abs(df['del_date_sch_date_diff'])\n    \n    df.drop(['Delivery Date', 'Scheduled Date'], axis = 1, inplace=True)\n    \n    df['city'] = df['Customer Location'].str.split(',', expand=True)[0]\n    df['State_code'] = df['Customer Location'].str.split(',', expand=True)[1].str.slice(0, 3)\n    df['pin'] = df['Customer Location'].str.split(',', expand=True)[1].str.split(' ', expand=True)[2]\n    \n    city_others = df[df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[0]\n    city_others.index = df[df['State_code'].isnull()].index\n    \n    State_code_others = df[df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[1]\n    State_code_others.index = df[df['State_code'].isnull()].index\n    \n    pin_others = df[df['pin'].isna()]['Customer Location'].str.split(' ', expand=True)[2]\n    pin_others.index = df[df['pin'].isnull()].index\n    \n    \n    df.loc[df['State_code'].isnull(), 'city'] = city_others\n    df.loc[df['State_code'].isnull(), 'State_code'] = State_code_others\n    df.loc[df['pin'].isnull(), 'pin'] = pin_others\n    \n    #df['pin'] = df['pin'].astype(int)\n    \n    df.drop(['Customer Location'], axis = 1, inplace=True)\n    df.drop(['city', 'pin'], axis = 1, inplace=True)    \n    return df\n\n# function to create histogram, Q-Q plot and\n# boxplot\n\nimport scipy.stats as stats\n\n\ndef diagnostic_plots(df, variable):\n    # function takes a dataframe (df) and\n    # the variable of interest as arguments\n\n    # define figure size\n    plt.figure(figsize=(16, 4))\n\n    # histogram\n    plt.subplot(1, 3, 1)\n    sns.histplot(df[variable], bins=30)\n    plt.title('Histogram')\n\n    # Q-Q plot\n    plt.subplot(1, 3, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('RM quantiles')\n\n    # boxplot\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y=df[variable])\n    plt.title('Boxplot')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Float columns Graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in float_var_list:\n   diagnostic_plots(df_train, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = prepare_data(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Float columns graph after preparing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in float_var_list:\n    diagnostic_plots(df_train, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_X = df_train.drop(['Cost'], axis = 1)\ndf_train_y = np.log(np.abs(df_train['Cost']))\n\nfrom feature_engine.encoding import OrdinalEncoder\nordinal_enc = OrdinalEncoder(\n    # NOTE that we indicate ordered in the encoding_method, otherwise it assings numbers arbitrarily\n    #encoding_method='ordered',\n    encoding_method='arbitrary',\n    variables=['Material', 'State_code'])\n#ordinal_enc.fit(df_train_X, df_train_y)\nordinal_enc.fit(df_train_X)\ndf_train_X = ordinal_enc.transform(df_train_X)\n\nfrom feature_engine.encoding import OneHotEncoder\nohe_enc = OneHotEncoder(top_categories=None) \nohe_enc.fit(df_train_X)\ndf_train_X = ohe_enc.transform(df_train_X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_X.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_train_X, df_train_y, test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor \n\nfrom sklearn.ensemble import GradientBoostingRegressor\nreg = GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_depth=8, random_state=42\n                                ,loss='ls', min_samples_split=5\n                               )\n# train the model\nreg.fit(X_train, y_train)\n\nprint(reg.score(X_train, y_train))\nprint(reg.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = [\n{'n_estimators':  [x for x in range(50,500, 20)], \n 'learning_rate' : [0.1, 0.2, 0.3, 0.4, 0.5],\n 'max_depth': [x for x in range(5,20)], \n 'min_samples_split': [x for x in range(2,10)]}\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(df_train_X, df_train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test =  pd.read_csv('/kaggle/input/hackerearth-machine-learning-exhibit-art/dataset/test.csv')\nsample_submission = df_test[['Customer Id']]\ndf_test = prepare_data(df_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = ordinal_enc.transform(df_test)\ndf_test = ohe_enc.transform(df_test)\nprint(df_train_X.shape)\nprint(df_test.shape)\nX_test = df_test\ny_predicted = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Cost'] = np.exp(y_predicted)\nsample_submission.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}