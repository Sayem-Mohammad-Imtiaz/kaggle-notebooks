{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# ARIMA Forecasting using Statsmodel\n\nForecasting is a magic nowadays. Finance institution seeking for good forecasting model to ensure the \"uncertain future\". It also be a magic if you could done well forecasting for your financial activity :)"},{"metadata":{},"cell_type":"markdown","source":"## 1. Load the Data\n\nWe will drop first 5 row to make the data fully numerical. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/exchange-rates/exchange_rates.csv\")\ndf = df.drop(df.index[0:5]).dropna()\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Drop ND and NA values\n\nWe will use the numerical values only, so we will drop all the NaN and ND valued rows. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the format was not fixed, so we will fix it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.columns[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df != 'ND']\ndf.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\ndf[df.columns[0]] = pd.to_datetime(df[df.columns[0]]) \ndf[df.columns[1:len(df.columns)]] = df[df.columns[1:len(df.columns)]].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. See the trend\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint(len(df))\nprint(df.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nfor i in range(1,len(df.columns)):\n    plt.figure(figsize=(15,4))\n    sns.lineplot(x = df[df.columns[0]], y = df[df.columns[i]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We dont see the function as stationary, so we need to make it stationary. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,len(df.columns)):\n    plt.figure(figsize=(15,4))\n    sns.lineplot(x = df[df.columns[0]], y = np.log(df[df.columns[i]]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Make Stationary Data\n\nWe will use ADF (Augmented Dickey Fuller) for statistical test \n\n(Thanks to https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/ for the lesson!)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(timeseries):\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n       dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,len(df.columns)):\n    df[df.columns[i]] = df[df.columns[i]].fillna(method='ffill')\n    print('\\n',df.columns[i])\n    adf_test(df[df.columns[i]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will try to differentiate the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,len(df.columns)):\n    plt.figure(figsize=(15,4))\n    df[df.columns[i]] = df[df.columns[1]] - df[df.columns[i]].shift(1)\n    df[df.columns[i]].dropna().plot()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think the first was stationary, but the rest is works for later, so it needs different treatment. We will proceed to the first."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,4))\ndf[df.columns[1]].dropna().plot()\nadf_test(df[df.columns[1]].dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n# using 1,1,1 ARIMA Model\nmodel = ARIMA(df[df.columns[1]].dropna(), order=(1,1,0))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"yea the p-value was less than 0.05 so it should be significant. We can plot the residuals to ensure the mean is near-zero. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,4))\nresiduals = pd.DataFrame(model_fit.resid)\nresiduals.plot(title=\"Residuals\")\nresiduals.plot(kind='kde', title='Density')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Predicting Values\n\nWe will split the data into train and test set, with ratio of 7:3. \n\n(Thanks to https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/) "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df[df.columns[1]].dropna().values\n\nsize = int(len(data) * 0.7)\ntrain, test = data[0:size], data[size:len(data)]\nhistory = [x for x in train]\npredictions = list()\n\nfor t in range(len(test)):\n    model = ARIMA(history, order=(1,1,1))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)\n    print('predicted=%f, expected=%f' % (yhat, obs))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yea, too long to wait, so I decide to immediately plot it. Not even halfway but I am impatient for the graph. The graph took differential form. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\n#error = mean_squared_error(test, predictions)\n#print('Test MSE: %.3f' % error)\nplt.figure(figsize=(15,4))\nplt.plot(test, label = 'actual')\nplt.plot(predictions, color='red', label = 'predicted')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Optimization\n\nOptimization could be done from the stationary test of datas, or from the ARIMA models. The p, d, and q values could be varied. This work would be done later. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}