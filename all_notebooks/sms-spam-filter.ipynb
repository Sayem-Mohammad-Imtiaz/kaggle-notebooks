{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e20f80237f6afb30db48311184326d9208d778c5"},"cell_type":"code","source":"%config IPCompleter.greedy=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d11125a1218697f1a5b6e18add648fbf7bf5b058"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"166b526cf92782b54277e0d8d3c582be2297104b"},"cell_type":"code","source":"import pandas as pd\nimport re\ndataset = pd.read_csv('../input/spam.csv',encoding=\"ISO-8859-1\")\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19edc5619ee25635e3853e963df85f0848d88553"},"cell_type":"markdown","source":"Lets clean up the table!!\n1) Rename the features to give it more sense.\n2) Remove unwanted columns"},{"metadata":{"trusted":true,"_uuid":"3a5888aa058040322a1b270b1d2def585c8a9dde"},"cell_type":"code","source":"dataset = dataset.rename(columns={\"v1\":\"label\",\"v2\":\"message\"})\ndataset = dataset.drop([\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],axis=1)\ndataset['label'].replace(\"ham\",0,inplace=True)\ndataset['label'].replace(\"spam\",1,inplace=True)\n#clean up anything other than chars and nums\nfor msg in dataset['message']:\n    msg = re.sub('[^A-Za-z0-9 ]+','',msg)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"214486e52884c7760b61346b675e73c082e23a76"},"cell_type":"code","source":"#split to test and train data\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nX_train,X_test,y_train,y_test = train_test_split(dataset['message'],dataset['label'],random_state=42,test_size=0.33)\n#If you want to know the shape and stats of dataset. \n#print(\"-\"*20)\n# print(\"Training features shape: \",X_train.shape)\n# print(\"Training labels shape: \",y_train.shape)\n# print(\"Test feature shape: \",X_test.shape)\n# print(\"test label shape: \",y_test.shape)\n# print(\"Count:\")\n# unique, count = np.unique(y_train,return_counts=True)\n# spam_ham = dict(zip(unique,count))\n# print((spam_ham[1]/(spam_ham[0]+spam_ham[1])*100,\" were spam in training dataset\"))\n# print(\"In original dataset\")\n# unique, count = np.unique(dataset['label'],return_counts=True)\n# spam_ham = dict(zip(unique,count))\n# print((spam_ham[1]/(spam_ham[0]+spam_ham[1])*100,\" were spam in original dataset\"))\n# print(\"-\"*20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c20ee6478c2b222659ce8aebfc7ad2d322d471f"},"cell_type":"markdown","source":"Since this is my first kernel, would be running everything at basic config. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f5daa0ca87dfbd9269e109183b35ce25c9cb5c09"},"cell_type":"code","source":"count_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"76412aef945d03ad97ddb8d5916dd559c5bd2175"},"cell_type":"code","source":"\ntfidfTransformer = TfidfTransformer(use_idf=True,norm=\"l1\")\nX_train_tfIdf = tfidfTransformer.fit_transform(X_train_counts)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69aeac1182fe44c4b78be2ab639aa667895f5857"},"cell_type":"markdown","source":"I tried Multinomial and Gaussian Naive Bayes, gives ~92 percent accuracy. Whereas, BernoulliNB gives around ~98 percent accuracy."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"31ffe5c24c2396ff2d11c5ddc30ea49477933406"},"cell_type":"code","source":"clf = BernoulliNB().fit(X_train_tfIdf.toarray(),y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4752a4c7e1229fcff4c8c57c8098cc0b7cba879a"},"cell_type":"code","source":"log_reg_model = LogisticRegression()\nlog_reg_model.fit(X_train_tfIdf,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4d26dd5fbda8205f2506ca9ef512c9150734ee94"},"cell_type":"code","source":"# transform the test feature in the same form as for training feature\nX_test_counts = count_vect.transform(X_test)\nX_test_tfIdf = tfidfTransformer.transform(X_test_counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c8a620eaacdff088ef591af723e8301d0491464f"},"cell_type":"code","source":"predicted_BNB = clf.predict(X_test_tfIdf.toarray())\npredicted_LR = log_reg_model.predict(X_test_tfIdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6689a708746d46989f8ff68e67ef010728bd8b78"},"cell_type":"code","source":"# measure accuracy\nprint(\"Bernoulli NB: \",accuracy_score(y_test,predicted_BNB,normalize=True))\nprint(\"Logistic Regression: \",accuracy_score(y_test,predicted_LR,normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc6c982c4269476641213411629b359dc389dd9d"},"cell_type":"markdown","source":"Nay logistic regression not good enough (or most probably I am doing something wrong.). \n"},{"metadata":{"_uuid":"9e7b90a27dd2361698a50c3beef985697a418e81"},"cell_type":"markdown","source":"**Future Works:**\n1. Use pipeline and parameter. Use the likes of GridCV to try out the different combinations.\n2. Apply  CountVectorizer or TfIdfVectorizer() individually as features."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}