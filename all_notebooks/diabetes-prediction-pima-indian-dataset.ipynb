{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Diabetes prediction for the PIMA Indian Diabetes Database\n\n## Context\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n## Data Description\n\n- `Pregnancies` - Number of times pregnant\n- `Glucose` - Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n- `Blood pressure` - Diastolic blood pressure (mm Hg)\n- `SkinThickness` - Triceps skin fold thickness (mm)\n- `Insulin` - 2-Hour serum insulin (mu U/ml)\n- `BMI` - Body mass index (weight in kg/(height in m)^2)\n- `DiabetesPedigreeFunction` - Diabetes pedigree function\n- `Age` - Age (years)\n- `Outcome` - Class variable (0 or 1) 268 of 768 are 1, the others are 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic EDA"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Missing Values\n\nIn this dataset missing data are filled with 0. First, we are gonna change zeros with NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness',\n                                                                      'Insulin','BMI']].replace(0, np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Filling the missing values with median values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def median_target(var):   \n    temp = df[df[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above we are finding the median value the separate outcomes and then filling it in the missing values accordingly"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df.columns\ncols = cols.drop('Outcome')\n\nfor col in cols:\n    median_target(col)\n    \n    df.loc[(df['Outcome'] == 0) & (df[col].isnull()), col] = median_target(col)[col][0]\n    df.loc[(df['Outcome'] == 1) & (df[col].isnull()), col] = median_target(col)[col][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now as we can see all the missing values have been filled with their median values according to the target."},{"metadata":{},"cell_type":"markdown","source":"# Data visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df.hist(bins=15,figsize=(20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfor col in df.columns[:-1]:\n    df[col] = scaler.fit_transform(df[[col]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(bins=15,figsize=(20,20));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df.drop('Outcome',axis=1)\ny = df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plt_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0,1],[0,1],\"k--\")\n    plt.tight_layout()\n    plt.axis([0,1,0,1])\n    plt.legend()\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nmodel_rf = RandomForestClassifier(n_estimators=100)\nmodel_ext = ExtraTreesClassifier()\nmodel_ada = AdaBoostClassifier()\nmodel_grad = GradientBoostingClassifier()\nmodel_logis = LogisticRegression()\nmodel_dec = DecisionTreeClassifier()\n\nmodels = [model_rf, model_ext, model_ada, model_grad, model_logis, model_dec]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, classification_report, f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_train(model):\n    model.fit(X_train,y_train)\n    \n    y_pred = model.predict(X_test)\n    fpr, tpr, thresholds = roc_curve(y_test,y_pred)\n    print(f'model: {model}')\n    print(classification_report(y_test,y_pred))\n    plt_roc_curve(fpr,tpr,label=f'{model}')\n    \n    return f1_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = {'Random Forest':0,\n          'ExtraTress': 0,\n          'AdaBoost':0,\n          'Gradient Boosting':0,\n          'Logistic Regression':0,\n          'Decision Tree':0}\n\n\nscr = []\nfor i,model in enumerate(models):\n    score = model_train(model)\n    scr.append(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above we can see that Gradient Boosting algorithm is performing well"},{"metadata":{},"cell_type":"markdown","source":"Without any feature engineering we got higher ROC"},{"metadata":{},"cell_type":"markdown","source":"# K-Fold cross validated models with RandomSearchCV for best params"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV\nfrom sklearn.pipeline import make_pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ml_model(model, parameters):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\n    random_search = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1, verbose=2 )\n    #pipe = make_pipeline(StandardScaler(),random_search)\n    random_search.fit(X_train, y_train)\n    y_pred_proba = random_search.predict_proba(X_test)[:,1]\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n    print(\"ROC Score : \",roc_auc_score(y_test, y_pred_proba))\n    print(\"Accuracy for train: \", accuracy_score(y_train, random_search.predict(X_train)))\n    print(\"Accuracy for test: \" , accuracy_score(y_test, random_search.predict(X_test)))\n    print(\"Best params:\" + str(random_search.best_params_))\n    plt_roc_curve(fpr,tpr)\n    \n    return random_search\n    \nlog_reg_params = {\"C\" : [1,2,3,0.01,0.001, 2.5, 1.5],\n                  \"max_iter\" : range(100,800,100)}\nknn_params = {\"n_neighbors\" : np.arange(1,50),\n              \"leaf_size\" : np.arange(1,50)}\ndecTree_params = {\"max_depth\" : [5,10,15,20,25,30],\n                  \"min_samples_split\" : np.arange(2,50),\n                  \"min_samples_leaf\" : np.arange(1,50)}\nrandomForest_params = {\"n_estimators\" : [100,500, 1000],\n                       \"min_samples_split\" : np.arange(2,30),\n                       \"min_samples_leaf\" : np.arange(1,50),\n                       \"max_features\" : np.arange(1,7)}\ngrad_params = {\"n_estimators\" : [100,500,1000],\n               \"subsample\" : [0.6,0.8,1.0],\n               \"max_depth\" : [5,10,15,20,25,30],\n               \"learning_rate\" : [0.1, 0.01, 0.02, 0.5]\n               }\n\nsgd_params = {\"alpha\" : [0.0001, 0.1, 0.001, 0.01],\n              \"max_iter\" : [100,500,1000,2000],\n              \"loss\" : [\"log\",\"modified_huber\",\"perceptron\"]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model(LogisticRegression(), log_reg_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model(KNeighborsClassifier(), knn_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model(DecisionTreeClassifier(), decTree_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model(RandomForestClassifier(), randomForest_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model(SGDClassifier(), sgd_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model(GradientBoostingClassifier(), grad_params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We got highest roc_score of 95.4% for the `GradientBoosting Classifier`, we are storing the model with that best params and we are going to use that for the prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_final_gradboost = GradientBoostingClassifier(subsample = 0.6,\n                                                n_estimators = 500, \n                                                max_depth = 20,\n                                                learning_rate = 0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_final_gradboost.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = model_final_gradboost.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nprint(\"ROC Score : \",roc_auc_score(y_test, y_pred_proba))\nprint(\"Accuracy for train: \", accuracy_score(y_train, model_final_gradboost.predict(X_train)))\nprint(\"Accuracy for test: \" , accuracy_score(y_test, model_final_gradboost.predict(X_test)))\nplt_roc_curve(fpr,tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_final_gradboost.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Storing the Best Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\nwith open('model_gradboost.pkl','wb') as file:\n    pickle.dump(model_final_random,file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have successfully stored our model in our storage**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}