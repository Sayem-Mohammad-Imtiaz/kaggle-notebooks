{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Imports and loading training data\n\nMake some imports first"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport random\nimport os\nfrom queue import Queue\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras import Model\nfrom tensorflow.data import Dataset\nfrom IPython.display import display\nimport PIL","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is dataset folders"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_dataset_images_path = '/kaggle/input/car-object-detection/data/training_images'\ntesting_dataset_images_path = '/kaggle/input/car-object-detection/data/testing_images'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"boxes_df = pd.read_csv('/kaggle/input/car-object-detection/data/train_solution_bounding_boxes (1).csv')\nboxes_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Definitions\n\n`single_inputs` - convert tensor from image format to acceptable for Keras model - add new dimension for cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"def single_inputs(img_arr):\n    x,y,z = img_arr.shape\n    return img_arr.reshape((1,x,y,z))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`DetectionBox` - it is bounds for X,Y coordinates in training sets and notebook results for specify detected object position.\n\n`TrainingCase` holds data about detected boxes and image paths. Have some utilitary methods to get case inputs, outputs and draw images with boxes."},{"metadata":{"trusted":true},"cell_type":"code","source":"class DetectionBox:\n    def __init__(self,x_min,y_min,x_max,y_max):\n        self.x_min = x_min\n        self.y_min = y_min\n        self.x_max = x_max\n        self.y_max = y_max\n    \n    @staticmethod\n    def from_named_tuple(tup):\n        return DetectionBox(tup.xmin,tup.ymin,tup.xmax,tup.ymax)\n    \n    def scale(self,scale_mul):\n        return DetectionBox(\n            self.x_min * scale_mul,\n            self.y_min * scale_mul,\n            self.x_max * scale_mul,\n            self.y_max * scale_mul\n        )\n    \n    def resize_to_point(self,x,y):\n        if self.x_min > x:\n            self.x_min = x\n        if self.x_max < x:\n            self.x_max = x\n        if self.y_min > y:\n            self.y_min = y\n        if self.y_max < y:\n            self.y_max = y\n\nclass TrainingCase:\n    def __init__(self,img_path):\n        self.img_path = img_path\n        self.boxes = []\n    \n    def add_box(self,tup):\n        self.boxes.append(DetectionBox.from_named_tuple(tup))\n    \n    def get_image(self):\n        img = load_img(self.img_path)\n        img_arr = img_to_array(img)\n        return img_arr\n    \n    def draw_image_with_boxes(self):\n        img = load_img(self.img_path)\n        img_arr = img_to_array(img)\n        h,w = img_arr.shape[:2]\n        \n        def point(y,x,color):\n            x = int(x)\n            y = int(y)\n            if x >= 0 and x < w and y >= 0 and y < h:\n                img_arr[y,x,:] = color\n        \n        for box in self.boxes:\n            if box.x_min-1 >= 0:\n                for y in range(int(box.y_min),int(box.y_max)):\n                    point(y, box.x_min-1,(0,255,0))\n                    point(y, box.x_min  ,(0,255,0))\n                    point(y, box.x_min+1,(0,255,0))\n                    point(y, box.x_max-1,(0,255,0))\n                    point(y, box.x_max  ,(0,255,0))\n                    point(y, box.x_max+1,(0,255,0))\n                for x in range(int(box.x_min),int(box.x_max)):\n                    point(box.y_min-1, x,(0,255,0))\n                    point(box.y_min  , x,(0,255,0))\n                    point(box.y_min+1, x,(0,255,0))\n                    point(box.y_max-1, x,(0,255,0))\n                    point(box.y_max  , x,(0,255,0))\n                    point(box.y_max+1, x,(0,255,0))\n        \n        img = PIL.Image.fromarray(img_arr.astype(np.uint8),'RGB')\n        display(img)\n    \n    def get_answer(self):\n        img = load_img(self.img_path)\n        img_w, img_h = img.size\n        \n        h,w = int(img_h/32),int(img_w/32)\n        out_arr = np.concatenate((np.full((1,h,w,1),-1,dtype=np.float),np.ones((1,h,w,1),dtype=np.float)),axis=3)\n        \n        \n        for box in self.boxes:\n            x_min,y_min,x_max,y_max = int(box.x_min / 32),int(box.y_min / 32),int(box.x_max / 32),int(box.y_max / 32)\n            for y in range(y_min,y_max):\n                for x in range(x_min,x_max):\n                    if y < 0 or x < 0 or y >= h or x >= w:\n                        continue\n                    \n                    out_arr[0,y,x,0] = 1\n                    out_arr[0,y,x,1] = -1\n        \n        return out_arr\n    \n    def get_answer_as_outputs(self):\n        answer = self.get_answer()\n        return answer[0,:,:,0],answer[0,:,:,1]\n    \n    def get_inputs(self):\n        return single_inputs(self.get_image())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`KerasModelWrapper` define utility method for prediction which works with case inputs and get results in necessary format."},{"metadata":{"trusted":true},"cell_type":"code","source":"class KerasModelWrapper:\n    def __init__(self,model):\n        self._model = model\n    \n    @staticmethod\n    def _normalize(matrix,min_val,max_val):\n        return (matrix - min_val) / (max_val - min_val)\n    \n    def predict(self,case):\n        inputs = case.get_inputs()\n        results = self._model.predict(inputs)\n        \n        outs1 = results[0,:,:,0]\n        outs2 = results[0,:,:,1]\n        \n        min_val = min(outs1.min(),outs2.min())\n        max_val = min(outs1.max(),outs2.max())\n        \n        n_outs1 = KerasModelWrapper._normalize(outs1,min_val,max_val)\n        n_outs2 = KerasModelWrapper._normalize(outs2,min_val,max_val)\n        \n        return outs1,outs2,(n_outs1 > n_outs2)\n    \n    def __call__(self,case):\n        return self.predict(case)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`df_to_training_list` allow to convert dataframe loaded from boxes CSV to list with cases and boxes."},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_to_training_list(df):\n    trn_dict = dict()\n\n    for i in boxes_df.itertuples():\n        if not i.image in trn_dict:\n            trn_case = TrainingCase(training_dataset_images_path + '/' + i.image)\n            trn_dict[i.image] = trn_case\n        else:\n            trn_case = trn_dict[i.image]\n        trn_case.add_box(i)\n\n    trn_list = [val for (key,val) in trn_dict.items()]\n\n    return trn_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`draw_outputs` it is utility function to show neural network outputs."},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_outputs(outputs):\n    for out in outputs:\n        out = out * 1 # This operation should case boolean matrix to numeric.\n        min_val = out.min()\n        max_val = out.max()\n        out = (out - min_val) / (max_val - min_val)\n        img = PIL.Image.fromarray((out*255).astype(np.uint8),'L')\n        w,h = img.size\n        img = img.resize((w*4,h*4))\n        display(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preparation\n\nLet's prepare our training cases list first."},{"metadata":{"trusted":true},"cell_type":"code","source":"training_list = df_to_training_list(boxes_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below examples of images with boxes in training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    idx = random.randrange(len(training_list))\n    training_list[idx].draw_image_with_boxes()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have enough RAM just to put all inputs and outputs to tensors without any data loaders or generators. So, let's do it."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = np.concatenate([x.get_inputs() for x in training_list],axis=0)\ntrain_y = np.concatenate([x.get_answer() for x in training_list],axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model definition and training\n\nI will use pretrained MobileNet architecture with additional convolution layer which split data to 2 classes - car and background. Pretrained layers not locked because experiments show me better quality of fitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    mobilenet = MobileNetV2(weights='imagenet',include_top=False)\n    x = mobilenet.outputs[0]\n    x = Conv2D(2,1)(x)\n    model = Model(mobilenet.inputs,x)\n    model.compile('adam',loss = 'mse')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_X,train_y,epochs=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's export our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('car_detection')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -r car_detection.zip car_detection\n!rm -rv car_detection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_wrapper = KerasModelWrapper(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Case and neural network inputs and outputs\n\nBelow 2 output channels which should predict our neural network according to random case from training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"random_case = training_list[random.randrange(len(training_list))]\ndraw_outputs(random_case.get_answer_as_outputs())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is actual predictions and restored mask of detected objects"},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_outputs(model_wrapper.predict(random_case))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking on test data\n\n`load_test_images` - load test cases with empty boxes list."},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_test_images(path):\n    cases = []\n    for filename in os.listdir(path):\n        file_path = path + '/' + filename\n        case = TrainingCase(file_path)\n        cases.append(case)\n    \n    return cases","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`populate_boxes` have algorythm for walking over detected objects mask for draw predicted boxes. `walk_on_box` do breadth-first search on mask and fill visited points by False values."},{"metadata":{"trusted":true},"cell_type":"code","source":"def populate_boxes(model,case):\n    prediction = model.predict(case)\n    mask = prediction[2].copy()\n    h,w = mask.shape\n    boxes = []\n    \n    def walk_on_box(sx,sy):\n        box = DetectionBox(sx,sy,sx,sy)\n        q = Queue()\n        q.put((sx,sy))\n        while not q.empty():\n            x,y = q.get()\n            box.resize_to_point(x+1,y+1)\n            mask[y,x] = False\n            if y+1 < h and mask[y+1,x]:\n                q.put((x,y+1))\n            if y-1 >= 0 and mask[y-1,x]:\n                q.put((x,y-1))\n            if x+1 < w and mask[y,x+1]:\n                q.put((x+1,y))\n            if x-1 >= 0 and mask[y,x-1]:\n                q.put((x-1,y))\n        \n        return box.scale(32)\n    \n    for y in range(h):\n        for x in range(w):\n            if mask[y,x]:\n                boxes.append(walk_on_box(x,y))\n    \n    case.boxes = boxes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill boxes lists using prediction from neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_list = load_test_images(testing_dataset_images_path)\nfor case in testing_list:\n    populate_boxes(model_wrapper,case)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some random examples of testing images and predicted boxes."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    idx = random.randrange(len(testing_list))\n    while len(testing_list[idx].boxes) == 0:\n        idx = random.randrange(len(testing_list))\n    testing_list[idx].draw_image_with_boxes()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}