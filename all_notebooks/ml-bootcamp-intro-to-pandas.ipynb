{"cells":[{"metadata":{},"cell_type":"markdown","source":"(Don't let the length of this notebook intimidate you. Most of the length comes from the large amount of retrieved data and the code itself is short and easy to follow)\n\n# Table of Contents\n\n- Load CSV Data\n- A Word About Accessing Columns\n- Selecting Data\n  - Default Selection Mechanism\n  - Selecting Rows by Index and Columns By Name\n  - Selecting Rows and Columns By Position\n  - Extracting Head/Tail Rows\n- Filtering\n  - Basic Idea of Filtering: Masking\n  - Combining Multiple Conditions\n  - Selecting Columns While Filtering\n- Operating on Data\n  - Finding Unique Values\n  - View vs Copy\n  - Adding a Column to a Data Frame\n  - Finding Counts of Different Values\n- Grouping & Aggregation\n  - Mean/Standard Deviation/Count/Etc\n  - Grouping By Ranges of Values\n- Handling Missing Data\n  - Remove Rows With Missing Data\n  - Filling Empty Values\n- Plotting\n  - 2D Plot\n  - Bar Chart\n  - Pie Chart\n  - Multiple Graphs\n  - Other Plot Types\n- Summary\n\n\nFollowing up on [ML Bootcamp: Intro to NumPy](https://www.kaggle.com/rafidka/ml-bootcamp-intro-to-numpy), the next important step in preparing to embark on a machine learning task is data manipulation. Machine leraning deals with a huge amount of data and without proper methods for extracting knowledge from data. \n\nIn this notebook, I will be using the [Stack Overflow Developer Survey for 2019](https://www.kaggle.com/mchirico/stack-overflow-developer-survey-results-2019). This way, I hope, the reader will gain the additional benefit of getting some insight into Stack Overflow Developer Survey at the same time as learning pandas."},{"metadata":{},"cell_type":"markdown","source":"# Load CSV Data"},{"metadata":{},"cell_type":"markdown","source":"Obviously, the first step in processing data is to load them. Pandas support [multiple file formats](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html), including CSV which we will be using here."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ncomplete_survey = pd.read_csv(\"../input/stack-overflow-developer-survey-results-2019/survey_results_public.csv\")\ncomplete_survey_schema = pd.read_csv(\"../input/stack-overflow-developer-survey-results-2019/survey_results_schema.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":" # Let's get a feeling of what the data looks like.\nprint(f\"(rows x columns) = {complete_survey.shape}\")\ncomplete_survey","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the dataset has many columns and rows, the notebook only shows part of the columns and rows. First, let's print all the columns to see what data is available for us. We could use the pandas DataFrame's [columns](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html) field, but this will only shows the columns name and we have to guess what they mean. Luckily, the [survey](https://insights.stackoverflow.com/survey) also provides the schema of the table, which we loaded above into the `survey_schema` variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import HTML\n\npd.set_option('display.max_rows', 100) # Ensure that we see all results.\npd.set_option('display.max_colwidth', -1) # Ensure that we display the complete text description.\ncomplete_survey_schema","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the available columns, I am interested in studying the following columns:\n\n- MainBranch\n- Hobbyist\n- OpenSourcer\n- Employment\n- Country\n- Student\n- EdLevel\n- UndergradMajor\n- DevType\n- YearsCode\n- Age1stCode\n- YearsCodePro\n- ConvertedComp\n- LanguageWorkedWith\n- Age\n- Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey = complete_survey[[\n    'MainBranch',\n    'Hobbyist',\n    'OpenSourcer',\n    'Employment',\n    'Country',\n    'Student',\n    'EdLevel',\n    'UndergradMajor',\n    'DevType',\n    'YearsCode',\n    'Age1stCode',\n    'YearsCodePro',\n    'ConvertedComp',\n    'LanguageWorkedWith',\n    'Age',\n    'Gender'\n]]\nsurvey","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A Word About Accessing Columns\n\nThe syntax above for selecting some of the columns might be a little bit strange at first. What are the double square brackets `[[` and `]]`? This section will help understand this.\n\nTo access a single column in Pandas we simply use the column's name:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey['Hobbyist']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To access multiple columns, we need to pass an array containing the name of the columns we want, which explains the syntax above. To make it clearer, we could instead type:\n\n```python\nsurvey = survey[ [\n    'MainBranch',\n    'Hobbyist',\n    # ...\n] ]\n```\n\nWe could also assign the column names to a variable:\n\n```python\ncolumns = [\n    'MainBranch',\n    'Hobbyist',\n    # ...\n]\nsurvey = survey[columns]\n```\n\nIt is a personal preference, but I personally prefer to reduce the number of unnecessary variables and make my code as compact as possible."},{"metadata":{},"cell_type":"markdown","source":"# Selecting Data\n\nLet's see various ways we can select data from a Pandas data frame.\n"},{"metadata":{},"cell_type":"markdown","source":"## Default Selection Mechanism\n\nWe can use the square brackets operator `[` and `]` on a data frame to select data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select rows 0 to 4.\nsurvey[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select Country column\nsurvey['Country']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that the above code returns a [Series](https://pandas.pydata.org/pandas-docs/stable/reference/series.html) object instead of a DataFrame. The difference is that a series is a linear set of values, instead of two dimensional like a data frame. Essentially, a data frame is a set of multiple data series sharing the same index, each representing a different column.\n\nIf you want to return a data frame instead, you should pass the column(s) as an array:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey[ ['Country'] ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To select multiple rows and columns, you can apply the selectors above one after the other, for example:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract \nsurvey[0:10][ ['Country', 'Student', 'EdLevel' ] ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Selecting Rows by Index and Columns By Name\n\nTwo things distinguishes Pandas data frames form NumPy 2-dimesnional arrays:\n\n1. Pandas data frame has an index that distinguishes different rows. In NumPy, rows and columns are always specified by a numerical index between 0 and the length of dimension - 1.  With pandas, however, the index can be anything, numerical or non-numerical, without any strict order. The benefit of this is that rows are uniquely identified by an index so even after applying a filter that removes some of the columns, the same row is still uniquely identified by the same index.\n\n2. Pandas data frame has columns with specific names. For example, in the data frame above for Stack Overflow survey, we don't have to remember the numerical index of the column containing the country of the responder, we simply use the `Country` field.\n\nTo use indexes and column names for selecting data, we can use the `loc` field.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select individual rows by index.\nsurvey.loc[ [1, 2, 5] ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select inidivdual columns by name.\nsurvey.loc[ :, ['MainBranch', 'Country'] ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select all columns between MainBranch and Country.\nsurvey.loc[ [1, 3, 10], ['MainBranch', 'Country'] ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select all columns between MainBranch and Country\nsurvey.loc[:, 'MainBranch':'Country']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One thing to notice is that the indexes for rows happened to be numbers here, but they don't need to be so. For example, let's take the first 5 rows and change the index to use alphabetical letters."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_new_index = survey.head(5)\nsurvey_new_index.index = ['a', 'b', 'c', 'd', 'e']\nsurvey_new_index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having this new data frame, let's see how we can extract rows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_new_index.loc['b':'d']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting Rows and Columns By Position\n\nIf you want to select data from a data frame using the NumPy-style of specifying the numerical position of the row(s)/column(s), you can use the `iloc` field."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the first row\nsurvey.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the first column\nsurvey.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting the coll in the 4th row and 5th column\nsurvey.iloc[3, 4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extracting Head/Tail Rows\n\nIt is sometimes useful to extract the first or last few columns. For this we can use the `head` and `tail` methods:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filtering\n\nWe can filter down the data in a data frame by applying operators on the values of the columns. For example, we might want to extract all rows where the `Country` column is `Canada`, or the salary is less/higher than a certain value. \n\n## Basic Idea of Filtering: Masking\n\nLet's start with an example that explains the basic idea of how filtering works in pandas. Let's extract responses coming from Canada:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey[survey['Country'] == 'Canada']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At first, it might seem a bit hard to understand the syntax of the code above; why do we need to specify `survey['Country] < 1000` inside as operand to `survey[]` itself? To understand, let's evaluate what is inside the square brackets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey['Country'] == 'Canada'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, it is returning a series containing True/False values. Passing this series to `survey[ ]` acts as a mask, specifying which indexes to extract and which one to ignore."},{"metadata":{},"cell_type":"markdown","source":"## Combining Multiple Conditions\n\nWe can apply more than one condition at the same time. For example, to extract responses from full-time employees in Bulgaria, we can use the following code:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey[ (survey['Country'] == 'Bulgaria') & (survey['Employment'] == 'Employed full-time')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting Columns While Filtering\n\nWhile filtering rows according to certain criteria, we could select certain columns by using the `loc` field. Let's modify the code above to only return some columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.loc[ (survey['Country'] == 'Bulgaria') & (survey['Employment'] == 'Employed full-time'), [\"Country\", \"Employment\"] ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The use of `loc` is not much different than the examples above. The first parameter is always the row selector, only this time we are providing a criteria for what to retrieve instead of a range or specific indexes."},{"metadata":{},"cell_type":"markdown","source":"# Operating on Data\n\nThe rest of this notebook is dedicated to exploring different functionalities available in the pandas while at the same time trying to extract something meaningful from the survey data.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Finding Unique Values\n\nLet's start by inspecting the different possible values of some categorical fields to give us some insight into what we can do."},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML, display\nimport tabulate\n\ndef print_series(series):\n    \"\"\"\n    A helper function for displaying a series using HTML.\n    \"\"\"\n    series_as_table = map(lambda x: [x], series)\n    display(HTML(tabulate.tabulate(series_as_table, tablefmt='html')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_series(survey['MainBranch'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_series(survey['OpenSourcer'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_series(survey['Employment'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## View vs Copy\n\nWhen we created the `survey` data frame, we executed the following code:\n\n```python\nsurvey = complete_survey[ [\n    # columns\n] ]\n```\n\nThis allowed us to have another data frame containing only the colunms we selected. One important note to mention about this is that the `survey` data frame doesn't actually contain a copy of the data, but instead a [view](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy). This is a similar to the concept of reference and pointer in programming languages.\n\nCare must be taken when trying to operate on a view. For example, let's try to add another column to the `survey` data frame. The `ConvertedComp` column contains the salary per year. What if we want to find the monthly compensation, as is commonly the case in many countries around the world? Let's try to add this column to the `survey` data frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey['MonthlyConvertedComp'] = survey['ConvertedComp']/12","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, this call failed and the reason is that we were trying to add a new column to a view of a data frame, which is not possible. The following section will explain how to solve this problem."},{"metadata":{},"cell_type":"markdown","source":"## Adding a Column to a Data Frame\n\nAdding a column to a data frame as is easy as executing a call like the following:\n\n```\nsurvey[<new column>] = survey[<column>]\n```\n\nThe new column will contain the same values in the given column. Obviously, this is dull and will only result in duplicated data, so it is worth mentioning that you can execute operation on the column before assigning it to the new column, just like [ufunc](https://docs.scipy.org/doc/numpy/reference/ufuncs.html) in NumPy. For example:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_ext = survey.copy()\nsurvey_ext['MonthlyConvertedComp'] = survey_ext['ConvertedComp']/12\nsurvey_ext[ ['ConvertedComp', 'MonthlyConvertedComp'] ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that we had to make a copy of `survey` as it is a view and cannot be modified in this way as explained in the previous section."},{"metadata":{},"cell_type":"markdown","source":"## Finding Counts of Different Values\n\nHow do we find the occurrence count of different values? For example, how many respondents are coming from different countries? Or how many respondants are hobbyist? We can use the `value_counts()` method for this:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey['Country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Or let's find how many are hobbyist. Notice that we used `normalize=True` in the code below to show percentages instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey['Hobbyist'].value_counts(normalize=True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find a breakdown of the education levels of the respondants."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey['EdLevel'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grouping & Aggregation\n\nIt is common to group data by a certain field. For example, we might want to split the survey by the country of residence (grouping). Then, we could generate the same statistics for different countries (aggregation). Pandas make this possibly via the `groupby` method, which generates a special kind of data frame or series. For example, calling the `groupby` method on a DataFrame will return an object of type [DataFrameGroupBy](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html):\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_by_country = survey.groupby('Country')\ntype(survey_by_country)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can think of this object as multiple data frames combined together in one object, each data frame is distinguishable by the value of the grouping. For example, in our code above, the result is a `DataFrameGroupBy` object whose keys are the different countries and values are a DataFrame per country. To understand this more, let's inspect the [indices](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.indices.html#pandas.core.groupby.GroupBy.indices) field of the grouping. This field returns a dictionary whose keys are the different values of the column we grouped by (let's call it the group-by column) and values are the indices of the rows from the original data frame whose value of the group-by column matches the key.\n\nSince printing the complete dictionary will be huge, let's print the keys only and then the value of one of the keys."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_by_country.indices.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_by_country.indices['Afghanistan']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that for `Afghanistan` we have the following indices: 719, 6391, ... etc. Let's display the `Country` column of the row with index `719` to verify that it is indeed `Afghanistan`."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.loc[719, 'Country']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"As expected, it is `Afghanistan`. With this introduction on grouping in pandas, let's see some examples of grouping and aggregation."},{"metadata":{},"cell_type":"markdown","source":"## Mean/Standard Deviation/Count/Etc\n\n"},{"metadata":{},"cell_type":"markdown","source":"Let's find the average salary by country:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.groupby('Country')['ConvertedComp'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's also find the standard deviation for each country:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.groupby('Country')['ConvertedComp'].std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is easier to read if we have both aggregations in one table. For this, we can use the [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.groupby('Country')['ConvertedComp'].agg([\"mean\", \"std\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Grouping By Ranges of Values\n\nIn the previous section, we see how we can group by specific values, e.g. a specific country. What if we want to group by a range of values? For example, group by ages between 0 - 10, 11 -20, and so on. For this, we can use the [pandas.cut](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html) method for this. For example, let's find the number of respondants per different each groups."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.groupby(pd.cut(survey['Age'], np.arange(0, 101, 10)))['Age'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Missing Data\n\nYou might noticed in many of the results above that we occasionally see the value `NaN`. This happens when there is no value in a certain cell, or a certain operation cannot be carried out like when we try to calculate the standard deviation with only one sample. This is usually undesirable in machine learning as we don't know what to do with those values. There are multiple ways to handle missing data in pandas.\n\n## Remove Rows With Missing Data\n\nThe simpliest scenario is removing any row containing missing data, which we can do using the [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey['ConvertedComp'].dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As simple as that! As you can see now, every retrieved result is not empty. However, we are only seeing the salary. What if we want to see other columns? "},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.dropna(subset=['ConvertedComp'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filling Empty Values\n\nThe other option for handling empty values is to fill them with some value. For example, for those respondants who haven't provided the salary, one option might be to assume they are getting the average salary. (Obviously, this is a wrong assumption, but it is used here for the sake of explanation.) We can achieve this by using the [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's first find rows containing no salary information\nsurvey_index_no_salary = survey['ConvertedComp'].isnull()\nsurvey[survey_index_no_salary]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_mean = survey['ConvertedComp'].mean()\nsurvey.fillna({'ConvertedComp': salary_mean})[survey_index_no_salary] # Display the rows which didn't contain salary.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting\n\nThe main method for plotting in pandas is the `plot` method of Series and DataFrame. For Series, the index is the x-axis and the y-axis represent the values of the series. DataFrame is plot the same way, except that each column has its own graph in the y-axis; essentially, think of plotting a data frame is plotting multiple series sharing the same index.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## 2D Plot\n\nTo demonstrate 2D-plots, let's plot the average salary per age.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_by_age = survey[ ['Age', 'ConvertedComp'] ].dropna().groupby('Age')\nsalary_by_age.mean()\nsalary_by_age.mean().dropna().plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph is distorted by a few points which seem (at least to me) to be unrealistic; it is hard to justify the spike in the mean salary near the age 30. Let's use the [quantile](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html) method of the DataFrame to leave entries below 5% percentile and above 95% percentile."},{"metadata":{"trusted":true},"cell_type":"code","source":"p5, p95 = survey['ConvertedComp'].quantile(0.05), survey['ConvertedComp'].quantile(0.95)\nsalary_by_age = survey[ (survey['ConvertedComp'] >= p5) & (survey['ConvertedComp'] <= p95) ] [ ['Age', 'ConvertedComp'] ].dropna().groupby('Age')\nsalary_by_age.mean().dropna().plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph is better now, we don't see a 1 million spike in average which is hard to explain, but it is still a bit strange. I wonder whether this is caused by the different pay scale among different countries. Let's repeat the same operation above, but limiting the result to one country, e.g. United Kingdom."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_uk = survey[survey['Country'] == 'United Kingdom']\np5, p95 = survey_uk['ConvertedComp'].quantile(0.05), survey_uk['ConvertedComp'].quantile(0.95)\nsalary_by_age = survey_uk[ (survey_uk['ConvertedComp'] >= p5) & (survey_uk['ConvertedComp'] <= p95) ] [ ['Age', 'ConvertedComp'] ].dropna().groupby('Age')\nsalary_by_age.mean().dropna().plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data seems to be more reasonable now, though still spiky and not smooth, which I don't find an explanation for! I leave it to the reader to decide whether to play with this data more to understand what is going on!"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Bar Chart\n\nPlotting bar charts is no different than normal 2D plot; we simple use the `plot` method but pass `kind=bar` to the arguments. For example, let's see inspect the `OpenSourcer` column via bar chart.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.groupby('OpenSourcer')['OpenSourcer'].count().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pie Chart\n\nPie chart is very useful when we have a limited number of categories. Let's convert the bar chart above into a pie chart."},{"metadata":{},"cell_type":"markdown","source":"As expected, the vast majority of respondants are not actively contributing to open source."},{"metadata":{"trusted":true},"cell_type":"code","source":"survey.groupby('OpenSourcer')['OpenSourcer'].count().plot(kind='pie')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multiple Graphs\n\nCalling the `plot` method on a DataFrame will generate multiple graphs, one per column. Let's expand the 2D graph above to multiple countries. To be more accurate, I should say break down the graph by country. "},{"metadata":{"trusted":true},"cell_type":"code","source":"series = []\ncountries = ['United States', 'Japan', 'United Kingdom', 'Canada', 'Germany', 'Italy', 'Russia']\n# For each of the countries above, generate an aggregation for the mean of compensation by age.\nfor country in countries:\n    survey_by_country = survey[survey['Country'] == country]\n    salary_by_age = survey_by_country[ ['ConvertedComp'] ].groupby(pd.cut(survey_by_country['Age'], np.arange(0, 101, 5)))\n    series.append(salary_by_age.mean())\n# Concatate the result into a data frame and plot.\nc = pd.concat(series, axis=1)\nc.columns = countries\nc.plot()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Other Plot Types\n\nThere are multiple other plot types that can be generated using pandas. The basic idea is the same, so I will leave the reader with the [visualization page](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) of pandas documentation to learn about and experiment with different plot types."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary\n\nPandas is a huge library and it is hard to cover all its functionality in one notebook. However, I tried to cover multiple different aspect of this library to set the reader up to speed with using this amazing library. More information about the library can be found on the [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html) of pandas.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}