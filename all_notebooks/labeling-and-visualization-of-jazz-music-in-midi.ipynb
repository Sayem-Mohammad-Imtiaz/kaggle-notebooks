{"cells":[{"metadata":{"_uuid":"faf7a79af04c7e1d49268ffec73024afd5164b20"},"cell_type":"markdown","source":"# Labeling and Visualization of Jazz Music in MIDI\n\n## 0. Setup and Pre-Process"},{"metadata":{"trusted":true,"_uuid":"cb2cc408be858c0125e264e81beaec10365690ab"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# read file\ndf = pd.read_csv('../input/Jazz-midi.csv', index_col=0)\nunique_notes = df.Unique_notes\nfile_name = df.Name\nlen_uni_notes = df.len_Uni_Notes\n\n# drop Notes columns.\ndf = df.drop(columns=['Notes'])\n# drop songs which has less than 32 notes.\ndf = df.drop(df[df.Len_Sequence <= 32].index)\n\ndef get_name(fn):\n    words = []\n    first = 0 \n    for i in range(1, len(fn)-4):     \n        if fn[i].isupper() and first<i:\n            words.append(fn[first:i])\n            first = i  \n    words.append(fn[first:len(fn)-4])\n    return ' '.join(words)\n\ndef filter_numbers(notes):\n    ret = []\n    notes = notes[1:-1].split(',')\n    for note in notes: \n        note = note.strip()\n        if not note[1].isdigit():\n            ret.append(note[1:-1])\n    return ret\n    \n# insert name column.\nname = file_name.apply(get_name)\ndf.insert(0, 'Song', name)\n# update unique_notes column.\nunique_notes = unique_notes.apply(filter_numbers)\ndf.update(unique_notes)\n# update len_uni_notes column.\ndf.update(pd.Series(name='len_Uni_Notes', data=unique_notes.apply(lambda x: len(x))))\n# drop songs with invalid notes.\ndf = df.drop(df[df.len_Uni_Notes <= 1].index)\n# rename names.\ndf = df.rename(columns={'Name':'file_name', 'Song':'Name', 'Len_Sequence':'len_sequence',\n                        'Unique_notes':'unique_notes' ,'len_Uni_Notes':'len_uni_notes'})\n\nprint('Setup Complete!\\n')\n# df.to_csv('/Users/todd/Downloads/jazz_notes.csv',)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41977e51d195577ac23ac09e7cb32fcbe72dde15"},"cell_type":"markdown","source":"## 1. Define Features\n\n**Based on the data field after data-washing,  I've made some attmpts to define some features to describe the music.**\n\n$\\mathbb{Depth} = \\mathcal{Min}(notes)\\rightarrow \\mathcal{Max}(notes)$\n\n$\\mathbb{Length} = \\mathcal{Count}(all~notes) $\n\n$\\mathbb{Chromaticity} = \\mathcal{Count}(unique~notes)$\n\n$\\mathbb{Major} = \\mathcal{Argmax}(scales~notes) $"},{"metadata":{"trusted":true,"_uuid":"deff147f653f2e46c99e61f609caf85167de7cf1"},"cell_type":"code","source":"# calculate depth\nlevel = lambda x: (ord(x[0]) - ord('A')) * int(x[-1]) \ndepth = pd.Series(data=[level(max(notes))-level(min(notes)) for notes in df['unique_notes']], dtype=int, name='Depth')\n# calculate length\nlength = pd.Series(data=df['len_sequence'], dtype=int, name='Length')\n# calculate chromaticity\nchromaticity = pd.Series(data=df['len_uni_notes'], dtype=int, name='Chromaticity').dropna()\n# calculate major\nmajor = []\nfor notes in df['unique_notes']:\n    scale = {}\n    for note in notes:\n        scale[note[-1]] = scale[note[-1]] + 1 if scale.__contains__(note[-1]) else 1\n    major.append(max(scale, key=scale.get))\n   \nmajor = pd.Series(data=major, dtype=int, name='Major')\n\n# define features\nfeatures = pd.concat([depth, length, chromaticity, major], axis=1)\nfeatures = features.dropna()\nfeatures.index = range(len(features))\ndepth, length, chromaticity, major = features['Depth'], features['Length'], features['Chromaticity'], features['Major']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be1d7dd6a61018aead13562dc0450c49db19dd68"},"cell_type":"markdown","source":"# 2. Matplotlib Viz\n###  Features Distribution Histogram"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"92b87ab640b4a59524922f95d454414e25da4606"},"cell_type":"code","source":"def distplot(idx, data, name):\n    plt.subplot(2, 2, idx)\n    plt.title(name+' Distribution')\n    sns.distplot(data, norm_hist=True)\n\nplt.figure(figsize=(12,6))\ndistplot(1, depth, 'Depth')   \ndistplot(2, length, 'Length')  \ndistplot(3, chromaticity, 'Chromaticity')  \ndistplot(4, major, 'Major')  \nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bb1e7d343a4718ef7a77481f65e9a9aeff29bd0"},"cell_type":"markdown","source":"### Person-Correlation Heatmap"},{"metadata":{"trusted":true,"_uuid":"7ff745d0f6327a6e45631ba967050e083ac2ea43"},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(features.corr(), annot=True, linewidths=.5, fmt= '.3f', ax=ax)\nplt.title(\"Person-Correlation Heatmap\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"445c9fb82b82b4450628ce1a8f9c5ad153fbc4f0"},"cell_type":"markdown","source":"Note: we can find out that there are 2 **highly relative pairs** of features, which is: \n\n* *(depth, major)         \n* *(length, chromaticity)*\n\nThe results showed that the **depth** is a **key influencing factor** to major, and the **length** is a **key influencing factor** to chromaticity, which is quite intuitive and reasonable.\n"},{"metadata":{"_uuid":"e016bcceef453cb169b6d617fddd5d32a252b314"},"cell_type":"markdown","source":"## 3. Define Music Tags\nBased on the features and observations above, I've made some attempts to define some tags. \n\nIn order to **reduce the correlation impacts** of features, we use several combinations with the 2 highly relative pairs excluded to define some interesting tags.\n\n$\\mathbb{Classic} = \\{\\mathcal{Depth}\\in [16, 32] \\},~~\\mathbb{Exotic} = \\{\\mathcal{Depth}\\in (0, 16)\\cup (32, \\infty]\\}$\n\n$\\mathbb{Ceased} = \\{\\mathcal{Length}\\in (0, 300)\\},~~\\mathbb{Epic} = \\{\\mathcal{Length}\\in (3500, \\infty]\\}$\n\n$\\mathbb{Peaceful} = \\{\\mathcal{Chromaticity}\\in (0, 32]\\},~~\\mathbb{Vivid} = \\{\\mathcal{Chromaticity}\\in (32, \\infty)\\}$\n\n$\\mathbb{Bassy} = \\{\\mathcal{Major}\\in [0, 2]\\},~~\\mathbb{Harmony} = \\{\\mathcal{Major}\\in [3, 5]\\},~~\\mathbb{Trebly} = \\{\\mathcal{Major}\\in [6, \\infty]\\}$"},{"metadata":{"trusted":true,"_uuid":"12a430aa2b903a8086046bca1dec42fa5992b12a"},"cell_type":"code","source":"TAGS = [['Classic','Exotic'], ['Ceased', 'Progressive', 'Epic'], ['Peaceful','Vivid'], ['Bassy','Harmony','Trebly']]\n    \nget_conds = lambda idx: [[depth[idx]>=16 and depth[idx]<=32],\\\n            [length[idx]<300, length[idx]>3500],\\\n            [chromaticity[idx]<=32],\\\n            [major[idx]<=2, major[idx]>=6]]\n\ndef get_tags(idx):\n    conds = get_conds(idx)\n    tags = []\n    if conds[0][0]:\n        tags.append(TAGS[0][0])\n    else:\n        tags.append(TAGS[0][1])\n        \n    if conds[1][0]:\n        tags.append(TAGS[1][0])\n    elif conds[1][1]:\n        tags.append(TAGS[1][2])\n    else:\n        tags.append(TAGS[1][1])\n    \n    if conds[2][0]:\n        tags.append(TAGS[2][0])\n    else:\n        tags.append(TAGS[2][1])\n    \n    if conds[3][0]:\n        tags.append(TAGS[3][0])\n    elif conds[3][1]:\n        tags.append(TAGS[3][2])\n    else:\n        tags.append(TAGS[3][1])\n            \n    return tags\n\ntags = pd.Series(data=[' '.join(get_tags(idx)) for idx in features.index], name='Tags')\n\nc_total   = len(tags)\nc_classic = sum(tags.str.count('Classic'))\nc_ceased  = sum(tags.str.count('Ceased'))\nc_epic    = sum(tags.str.count('Epic'))\nc_peaceful= sum(tags.str.count('Peaceful'))\nc_bassy   = sum(tags.str.count('Bassy'))\nc_trebly  = sum(tags.str.count('Trebly'))\n\ndata = [[c_classic, c_total-c_classic], \n        [c_ceased, c_total-c_ceased-c_epic, c_epic],\n        [c_peaceful, c_total-c_peaceful], \n        [c_bassy, c_total-c_bassy-c_trebly, c_trebly]]\n\nexplode = [(0, 0.1), (0.1, 0, 0.2), (0, 0.1), (0.1, 0, 0.2)]\n    \ndef pie(idx):\n    plt.subplot(2, 2, idx)\n    plt.pie(data[idx-1], shadow=True, startangle=90, explode=explode[idx-1])\n    plt.legend(labels=TAGS[idx-1])\n    plt.axis('equal')\n    \n\nplt.figure(figsize=(10,6))\nfor i in range(1, 5):\n    pie(i)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cf7fe7891ab0fb3a8153dc21fcf542853e55147"},"cell_type":"markdown","source":"## 4. Define How Jazzy a song is\nSince it is a jazz music midi dataset, I made a naive definition to described how jazzy a song is.\n\n$\\mathbb{S_{Jazzy}} = 5 - \\sum_i{\\dfrac{\\sqrt{(f_i-\\overline{f_i})^2}}{\\overline{f_i}}}$"},{"metadata":{"trusted":true,"_uuid":"58a11d2a8af08f507b4f67e904973baeec7b837e"},"cell_type":"code","source":"from sklearn.preprocessing import normalize\n\njazzy = []\nfor i in features.index:\n    jazzy.append(5 - np.sqrt((depth[i] - np.mean(depth))**2)/np.mean(depth) - \n                 np.sqrt((length[i] - np.mean(length))**2)/np.mean(length) -\n                 np.sqrt((chromaticity[i] - np.mean(chromaticity))**2)/np.mean(chromaticity) -\n                 np.sqrt((major[i] - np.mean(major))**2)/np.mean(major))\n\nfilter_zero = lambda x: x if x>0 else 0\nfilter_five = lambda x: x if x<5 else 5\njazzy = pd.Series(data=jazzy, name='Jazzy').apply(filter_zero).apply(filter_five)\n\nplt.title('Jazzy Distribution')\n\nsns.distplot(jazzy, norm_hist=True)\nmost_jazzy = np.argmax(jazzy)\nplt.annotate('<Rise> is the most jazzy song!', xy=(5, 0.1), xytext=(5,0.3), arrowprops=dict(width=0.2, facecolor='black', shrink=0.05)) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03a3d0d7a09d3d9b1b3973780b02c7a068ea499d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}