{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Objective:\n\nDevelop an algorithm which will identify the artist when provided with a painting, with state of the art precision."},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset: https://www.kaggle.com/ikarus777/best-artworks-of-all-time"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport cv2\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport shutil\nfrom glob import glob\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization\nfrom keras.models import Model\nfrom keras.optimizers import Adam \nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n\nfrom keras.preprocessing.image import ImageDataGenerator\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display some paintaings by **Vincent van Gogh**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotImages(\"Vincent van Gogh\",\"../input/best-artworks-of-all-time/images/images/Vincent_van_Gogh/**\")      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display some paintaings by **Leonardo da Vinci**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotImages(\"Leonardo da Vinci\",\"../input/best-artworks-of-all-time/images/images/Leonardo_da_Vinci/**\")      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display some paintaings by **Andy Warhol**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotImages(\"Andy Warhol\",\"../input/best-artworks-of-all-time/images/images/Andy_Warhol/**\")      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the CSV data"},{"metadata":{"trusted":true},"cell_type":"code","source":"artists = pd.read_csv('../input/best-artworks-of-all-time/artists.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"artists","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"artists.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us do some data exploration\n### Plot paintings by nationality of the painter. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nnationalityPlot = sns.countplot(y='nationality',data=artists)\nnationalityPlot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot artists and count of paintings"},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize=(15, 5)\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol1 = \"name\"\ncol2 = \"paintings\"\n\nsns.barplot(x=col1, y=col2, data=artists)\nplt.title(\"Painting Count by Artist\")\nplt.xlabel(\"Artist\")\nplt.ylabel(\"Painting Count\")\nplt.xticks(rotation=90)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create dataframe with artists having min of 200 paintings."},{"metadata":{},"cell_type":"markdown","source":"Here I have first sorted data according to feature painting so that all my data in sorted manner and according to their painting name. I have taken paintings >200 for our analysis just taken sample data.\n"},{"metadata":{},"cell_type":"markdown","source":"I have also added one more feature in this called ‘class_weight’ which put weight on paintings why we want weight actually simple putting weight on something it tells us the importance of that particular thing right."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort artists by number of paintings\nartists = artists.sort_values(by=['paintings'], ascending=False)\n\n# Create a dataframe with artists having more than 200 paintings\nartists_top = artists[artists['paintings'] >= 200].reset_index()\nartists_top = artists_top[['name', 'paintings']]\n\nartists_top['class_weight'] = artists_top.paintings.sum() / (artists_top.shape[0] * artists_top.paintings)\nartists_top","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a key value pairs of class index and weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set class weights - assign higher weights to underrepresented classes\nclass_weights = artists_top['class_weight'].to_dict()\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There is some problem recognizing 'Albrecht_Dürer' (don't know why, worth exploring)\n# So I'll update this string as directory name to df's\nupdated_name = \"Albrecht_Dürer\".replace(\"_\", \" \")\nartists_top.iloc[4, 0] = updated_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore images of top artists\nimages_dir = '../input/best-artworks-of-all-time/images/images/'\nartists_dirs = os.listdir(images_dir)\nartists_top_name = artists_top['name'].str.replace(' ', '_').values\n\n# See if all directories exist\nfor name in artists_top_name:\n    if os.path.exists(os.path.join(images_dir, name)):\n        print(\"Found -->\", os.path.join(images_dir, name))\n    else:\n        print(\"Did not find -->\", os.path.join(images_dir, name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Print few random paintings along with artists name"},{"metadata":{},"cell_type":"markdown","source":"Lets display some random paintings for clear visualization whats happening right."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print few random paintings\nimport random\nn = 5\nfig, axes = plt.subplots(1, n, figsize=(20,10))\n\nfor i in range(n):\n    random_artist = random.choice(artists_top_name)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n    image = plt.imread(random_image_file)\n    axes[i].imshow(image)\n    axes[i].set_title(\"Artist: \" + random_artist.replace('_', ' '))\n    axes[i].axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation\n"},{"metadata":{},"cell_type":"markdown","source":"Data Augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. This technique like padding , cropping , shifting , flipping etc."},{"metadata":{},"cell_type":"markdown","source":"**ImageDataGenerator()** the ImageDataGenerator accepts the original data, randomly transforms it, and returns only the new, transformed data."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\ntrain_input_shape = (224, 224, 3)\nn_classes = artists_top.shape[0]\n\ntrain_datagen = ImageDataGenerator(validation_split=0.2,\n                                   rescale=1./255.,\n                                   #rotation_range=45,\n                                   #width_shift_range=0.5,\n                                   #height_shift_range=0.5,\n                                   shear_range=5,\n                                   #zoom_range=0.7,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                  )\n\ntrain_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"training\",\n                                                    shuffle=True,\n                                                    classes=artists_top_name.tolist()\n                                                   )\n\nvalid_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"validation\",\n                                                    shuffle=True,\n                                                    classes=artists_top_name.tolist()\n                                                   )\n\nSTEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\nprint(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build Model\n"},{"metadata":{},"cell_type":"markdown","source":"So here in this part we are going to build model which train our data as previously I have mentioned that I will use state of the art technique like **ResNet50** model. I can use CNN(Convolutional Neural Network) but when I read the research paper that **ResNet50** network does a tremendous job on image data so let’s begin this section."},{"metadata":{},"cell_type":"markdown","source":"**ResNet50** model is also called identity layer why because the sole purpose of identity layer is skip-connection that means skip one layer in ResNet model which helps reducing vanishing gradient problem "},{"metadata":{},"cell_type":"markdown","source":"The ResNet model is adapted to the 1000 categories of ImageNet. Our task, however, is to classify some artists.\n\nWhat can we do? With keras, it's easy to import only the convolutional part of VGG16, by setting the include_top parameter to False :"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load pre-trained model\nfrom keras.applications import *\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n\nfor layer in base_model.layers:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ImageNet is an image database organized according to the WordNet hierarchy this is freely available for researcher and data scientist for research purposes."},{"metadata":{},"cell_type":"markdown","source":"### Create your Convolutional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Flatten()(base_model.output)\n\n#Initialize the CNN\nclassifier = Dense(512, activation='relu')(classifier)\nclassifier = BatchNormalization()(classifier)\n\nclassifier= Dense(16, activation='relu')(classifier)\nclassifier = BatchNormalization()(classifier)\n\noutput = Dense(n_classes, activation = 'softmax')(classifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs=base_model.input, outputs=output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compile the CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compile the CNN\nmodel.compile(optimizer = Adam(lr =0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epoch = 10\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n                           mode='auto', restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              verbose=1, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr],\n                              use_multiprocessing=True,\n                              workers=16,nlp\n                              class_weight=class_weights\n                             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the result after training the model for first time accuracy touched by my model is 0.98 or (98%) and loss reduce from 1.07 to 0.21 means model doing good now we freeze layers and re-train again."},{"metadata":{},"cell_type":"markdown","source":"### Fine tuning the model"},{"metadata":{},"cell_type":"markdown","source":"Freezing a layer prevents its weights from being modified. This technique is often used in transfer learning, where the base model(trained on some other dataset)is frozen indicating that this layer should not be trained"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Freeze core ResNet layers and train again \nfor layer in model.layers:\n    layer.trainable = False\n\nfor layer in model.layers[:50]:\n    layer.trainable = True\n\noptimizer = Adam(lr=0.0001)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])\n\nn_epoch = 50\nhistory2 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr, early_stop],\n                              use_multiprocessing=True,\n                              workers=16,\n                              class_weight=class_weights\n                             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction accuracy on train data\nscore = model.evaluate_generator(train_generator, verbose=1)\nprint(\"Prediction accuracy on train data =\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate_generator(valid_generator, verbose=1)\nprint(\"Prediction accuracy on test data =\", score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### print classification report"},{"metadata":{},"cell_type":"markdown","source":"### Test Model\n\nHere taking randomly 5 images and giving this random images to model to predict the artist by giving 5 random images that belong to particular artist or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\nfrom keras.preprocessing import *\n\nn = 4\nfig, axes = plt.subplots(1, n, figsize=(25,10))\n\nfor i in range(n):\n    random_artist = random.choice(artists_top_name)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n\n    # Original image\n\n    test_image = image.load_img(random_image_file, target_size=(train_input_shape[0:2]))\n\n    # Predict artist\n    test_image = image.img_to_array(test_image)\n    test_image /= 255.\n    test_image = np.expand_dims(test_image, axis=0)\n\n    prediction = model.predict(test_image)\n    prediction_probability = np.amax(prediction)\n    prediction_idx = np.argmax(prediction)\n\n    labels = train_generator.class_indices\n    labels = dict((v,k) for k,v in labels.items())\n\n    title = \"Actual artist = {}\\nPredicted artist = {}\\nPrediction probability = {:.2f} %\" \\\n                .format(random_artist.replace('_', ' '), labels[prediction_idx].replace('_', ' '),\n                        prediction_probability*100)\n\n    # Print image\n    axes[i].imshow(plt.imread(random_image_file))\n    axes[i].set_title(title)\n    axes[i].axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, from above we could see that given 4 random images our model predicted right artist name with given image on average probability of around 87% and above."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}