{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nd_fake = pd.read_csv('../input/fake-news-net/dataset/politifact_fake.csv')\nheadlines_fake = d_fake.drop(['id', 'news_url', 'tweet_ids'], axis=1).rename(columns={'title': 'headline'})\nheadlines_fake['fake'] = 1\n\nd_real = pd.read_csv('../input/fake-news-net/dataset/politifact_real.csv')\nheadlines_real = d_real.drop(['id', 'news_url', 'tweet_ids'], axis=1).rename(columns={'title': 'headline'})\nheadlines_real['fake'] = 0\n\neval_data = pd.concat([headlines_fake, headlines_real])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"headlines_fake.info()\nheadlines_real.info()\neval_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\ndef read_data(d):\n    \"\"\"Each file has a headline as the first line, followed by some white space and then the article content.\n    We need to exract the headline and the content of each file and store them in lists.\"\"\"\n    files = os.listdir(d)\n    headlines, contents = [], []\n    for fname in files:\n        if fname[:5] != 'polit':\n            continue\n        \n        f = open(d + '/' + fname)\n        text = f.readlines()\n        f.close()\n\n        if len(text) == 2:\n            # One of the lines is missing\n            if len(text[1]) <= 1:\n                # There is no article content or headline\n                continue\n        elif len(text) >= 3:\n            # More than one empty line encountered\n            text[1] = text[-1]\n        else:\n            # Only one or zero lines is file\n            continue\n        \n        headline, content = text[0][:-1].strip().rstrip(), text[1][:-1]\n        headlines.append(headline)\n        contents.append(content)\n    \n    return headlines, contents\n\n\nfake_dir = '../input/fake-news-dataset/fakeNewsDatasets/fakeNewsDataset/fake'\nfake_headlines, fake_content = read_data(fake_dir)\nfake_headlines = pd.DataFrame(fake_headlines, columns=['headline'])\nfake_headlines['fake'] = 1\n\nreal_dir = '../input/fake-news-dataset/fakeNewsDatasets/fakeNewsDataset/legit'\nreal_headlines, real_content = read_data(real_dir)\nreal_headlines = pd.DataFrame(real_headlines, columns=['headline'])\nreal_headlines['fake'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_data = pd.concat([eval_data, fake_headlines, real_headlines])\neval_data['fake'].value_counts()\neval_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_news = pd.read_csv('../input/all-the-news/articles3.csv', nrows=300000)\nall_news = all_news.rename(columns={'title': 'headline'})\nall_news['fake'] = 0\ndata = all_news[['headline', 'fake']]\n\n#data = pd.concat([data, all_news])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport numpy as np\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef format_data(data, max_features, maxlen, tokenizer=None, shuffle=False):\n    if shuffle:\n        data = data.sample(frac=1).reset_index(drop=True)\n    \n    data['headline'] = data['headline'].apply(lambda x: str(x).lower())\n\n    X = data['headline']\n    Y = data['fake'].values # 0: Real; 1: Fake\n\n    if not tokenizer:\n        filters = \"\\\"#$%&()*+./<=>@[\\\\]^_`{|}~\\t\\n\"\n        tokenizer = Tokenizer(num_words=max_features, filters=filters)\n        tokenizer.fit_on_texts(list(X))\n\n    X = tokenizer.texts_to_sequences(X)\n    X = pad_sequences(X, maxlen=maxlen)\n\n    return X, Y, tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features, max_len = 5000, 25\nX, Y, tokenizer = format_data(data, max_features, max_len, shuffle=True)\nX_eval, Y_eval, tokenizer = format_data(eval_data, max_features, max_len, tokenizer=tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\npickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Bidirectional, GRU, Embedding, Dropout, LSTM\nfrom keras.layers import concatenate, SpatialDropout1D, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras import regularizers\n\nepochs=20\n\n# Input shape\ninp = Input(shape=(max_len,))\n\nencoder = Embedding(max_features, 50)(inp)\nencoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\nencoder = Bidirectional(LSTM(25, return_sequences=True,\n                        activity_regularizer=regularizers.l1(10e-5)))(encoder)\n\ndecoder = Bidirectional(LSTM(75, return_sequences=True))(encoder)\ndecoder = GlobalMaxPooling1D()(decoder)\ndecoder = Dense(50, activation='relu')(decoder)\ndecoder = Dense(max_len)(decoder)\n\nmodel = Model(inputs=inp, outputs=decoder)\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, X, epochs=epochs, batch_size=64, verbose=1)\n\nmodel.save_weights('model{}.h5'.format(epochs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.predict(X_eval, batch_size=1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = np.mean(np.power(X_eval - results, 2), axis=1)\nerror_df = pd.DataFrame({'reconstruction_error': mse,\n                         'true_class': Y_eval})\nerror_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LABELS = ['REAL', 'FAKE']\nbest, threshold = -1, -1\n\n# General Search\nfor t in range(0, 3500000, 10000):\n    y_pred = [1 if e > t else 0 for e in error_df.reconstruction_error.values]\n    score = f1_score(y_pred, error_df.true_class, average='micro', labels=[0, 1])\n    if score > best:\n        best, threshold = score, t\n\n# Specialized Search around general best\nfor t in range(threshold-10000, threshold+10000):\n    y_pred = [1 if e > t else 0 for e in error_df.reconstruction_error.values]\n    score = f1_score(y_pred, error_df.true_class, average='micro', labels=[0, 1])\n    if score > best:\n        best, threshold = score, t\n\nprint(threshold, best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ngroups = error_df.groupby('true_class')\nfig, ax = plt.subplots()\n\nfor name, group in groups:\n    ax.plot(group.index, group.reconstruction_error, marker='o', ms=3.5, linestyle='',\n            label=\"Fake\" if name == 1 else \"Real\")\n\nax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\nax.legend()\nplt.title(\"Reconstruction error for different classes\")\nplt.ylabel(\"Reconstruction error\")\nplt.xlabel(\"Data point index\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LABELS = ['FAKE', 'REAL']\nerrors = error_df.reconstruction_error.values\ny_pred = [1 if e > threshold else 0 for e in errors] # final predictions\nconf_matrix = confusion_matrix(error_df.true_class, y_pred)\nplt.figure(figsize=(12, 12))\nsns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef accuracy_f1(preds, correct):\n    \"\"\"Returns F1-Score for predictions\"\"\"\n    return f1_score(preds, correct, average='micro', labels=[0, 1])\n\naccuracy_f1(y_pred, error_df.true_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nminmax_0_05 = MinMaxScaler(feature_range=(0, 0.5))\nminmax_05_1 = MinMaxScaler(feature_range=(0.5, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors_below = np.array([i for i, e in enumerate(errors) if e <= threshold])\nerrors_above = np.array([i for i, e in enumerate(errors) if e > threshold])\n\nminmax_0_05.fit(errors[errors_below].reshape(-1, 1))\nminmax_05_1.fit(errors[errors_above].reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors_mm = np.array([minmax_0_05.transform(e.reshape(1, -1)) if i in errors_below\n                      else minmax_05_1.transform(e.reshape(1, -1))\n                      for i, e in enumerate(errors)]).flatten()\n\ny_pred2 = [1 if e > 0.5 else 0 for e in errors_mm]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_percentile(preds, Y_validate):\n    \"\"\"Return the percentage of correct predictions for each class and in total\"\"\"\n    real_correct, fake_correct, total_correct = 0, 0, 0\n    _, (fake_count, real_count) = np.unique(Y_validate, return_counts=True)\n\n    for i, r in enumerate(preds):\n        if r == Y_validate[i]:\n            total_correct += 1\n            if r == 0:\n                fake_correct += 1\n            else:\n                real_correct += 1\n\n    print('Real Accuracy:', real_correct/real_count * 100, '%')\n    print('Fake Accuracy:', fake_correct/fake_count * 100, '%')\n    print('Total Accuracy:', total_correct/(real_count + fake_count) * 100, '%')\n\n\naccuracy_percentile(y_pred2, error_df.true_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef accuracy_f1(preds, correct):\n    \"\"\"Returns F1-Score for predictions\"\"\"\n    return f1_score(preds, correct, average='micro', labels=[0, 1])\n\naccuracy_f1(y_pred2, error_df.true_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(errors_mm).to_csv('autoencoder.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}