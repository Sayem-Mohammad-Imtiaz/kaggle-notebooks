{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-27T13:42:49.982772Z","iopub.execute_input":"2021-06-27T13:42:49.983322Z","iopub.status.idle":"2021-06-27T13:42:50.003983Z","shell.execute_reply.started":"2021-06-27T13:42:49.983197Z","shell.execute_reply":"2021-06-27T13:42:50.002886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In the Kaggle course, only a few columns were chosen so I will start with choosing all the columns (except sales price ofcourse) to train models. Let's see what happens ðŸ˜‰","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/home-data-for-ml-course/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:50.005442Z","iopub.execute_input":"2021-06-27T13:42:50.005822Z","iopub.status.idle":"2021-06-27T13:42:50.091561Z","shell.execute_reply.started":"2021-06-27T13:42:50.005791Z","shell.execute_reply":"2021-06-27T13:42:50.090816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:50.09347Z","iopub.execute_input":"2021-06-27T13:42:50.093724Z","iopub.status.idle":"2021-06-27T13:42:50.126166Z","shell.execute_reply.started":"2021-06-27T13:42:50.093698Z","shell.execute_reply":"2021-06-27T13:42:50.125155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.columns:\n    if df[col].count()<1350:\n        df.drop(col,axis=1,inplace=True)\n\ndf = df.select_dtypes(exclude=['object'])\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:50.127809Z","iopub.execute_input":"2021-06-27T13:42:50.128384Z","iopub.status.idle":"2021-06-27T13:42:50.173453Z","shell.execute_reply.started":"2021-06-27T13:42:50.128339Z","shell.execute_reply":"2021-06-27T13:42:50.172442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:50.174873Z","iopub.execute_input":"2021-06-27T13:42:50.175274Z","iopub.status.idle":"2021-06-27T13:42:50.197624Z","shell.execute_reply.started":"2021-06-27T13:42:50.175229Z","shell.execute_reply":"2021-06-27T13:42:50.196452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let me first define a function to simply get the mean squared error between the predicted values of the models that I will use and the actual values in the validation set","metadata":{"execution":{"iopub.status.busy":"2021-06-13T20:53:21.266367Z","iopub.execute_input":"2021-06-13T20:53:21.266736Z","iopub.status.idle":"2021-06-13T20:53:21.282927Z","shell.execute_reply.started":"2021-06-13T20:53:21.266705Z","shell.execute_reply":"2021-06-13T20:53:21.281592Z"}}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error \n\ndef get_mae(actual,predicted):\n    return mean_absolute_error(actual,predicted)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:50.19896Z","iopub.execute_input":"2021-06-27T13:42:50.199308Z","iopub.status.idle":"2021-06-27T13:42:51.105453Z","shell.execute_reply.started":"2021-06-27T13:42:50.199276Z","shell.execute_reply":"2021-06-27T13:42:51.104671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now I will get some things ready that I will be using for every variation of models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:51.106799Z","iopub.execute_input":"2021-06-27T13:42:51.10723Z","iopub.status.idle":"2021-06-27T13:42:51.349332Z","shell.execute_reply.started":"2021-06-27T13:42:51.107179Z","shell.execute_reply":"2021-06-27T13:42:51.34856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.loc[:,'Id':'YrSold']\ny = df['SalePrice']","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:51.352274Z","iopub.execute_input":"2021-06-27T13:42:51.352864Z","iopub.status.idle":"2021-06-27T13:42:51.360201Z","shell.execute_reply.started":"2021-06-27T13:42:51.352817Z","shell.execute_reply":"2021-06-27T13:42:51.359488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - mean","metadata":{}},{"cell_type":"code","source":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\nimputer = SimpleImputer(strategy='mean')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X))\n\nimputed_train_X.columns = train_X.columns\nimputed_valid_X.columns = valid_X.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:51.36236Z","iopub.execute_input":"2021-06-27T13:42:51.362924Z","iopub.status.idle":"2021-06-27T13:42:51.38952Z","shell.execute_reply.started":"2021-06-27T13:42:51.362877Z","shell.execute_reply":"2021-06-27T13:42:51.388647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:42:51.393016Z","iopub.execute_input":"2021-06-27T13:42:51.393323Z","iopub.status.idle":"2021-06-27T13:44:37.853483Z","shell.execute_reply.started":"2021-06-27T13:42:51.393295Z","shell.execute_reply":"2021-06-27T13:44:37.850649Z"},"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So I see that around 750 trees is where the MAE went the lowest. I will see how the MAE changes from 500 trees to 1000 trees by plotting it","metadata":{}},{"cell_type":"code","source":"plot_list = []","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.854597Z","iopub.status.idle":"2021-06-27T13:44:37.855016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-27T13:44:37.85583Z","iopub.status.idle":"2021-06-27T13:44:37.856236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.857035Z","iopub.status.idle":"2021-06-27T13:44:37.857456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - median","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:00:47.445126Z","iopub.execute_input":"2021-06-14T12:00:47.445505Z","iopub.status.idle":"2021-06-14T12:00:47.449314Z","shell.execute_reply.started":"2021-06-14T12:00:47.445418Z","shell.execute_reply":"2021-06-14T12:00:47.448629Z"}}},{"cell_type":"code","source":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\nimputer = SimpleImputer(strategy='median')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X))\n\nimputed_train_X.columns = train_X.columns\nimputed_valid_X.columns = valid_X.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.858277Z","iopub.status.idle":"2021-06-27T13:44:37.858676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.859719Z","iopub.status.idle":"2021-06-27T13:44:37.860145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Again, I see that around 750 trees is where the MAE went the lowest. I will see how the MAE changes from 500 trees to 1000 trees by plotting it","metadata":{}},{"cell_type":"code","source":"plot_list = []","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.860934Z","iopub.status.idle":"2021-06-27T13:44:37.861385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-27T13:44:37.862311Z","iopub.status.idle":"2021-06-27T13:44:37.862741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.863545Z","iopub.status.idle":"2021-06-27T13:44:37.863952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ### 3. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - most_frequent","metadata":{}},{"cell_type":"code","source":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\nimputer = SimpleImputer(strategy='most_frequent')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X))\n\nimputed_train_X.columns = train_X.columns\nimputed_valid_X.columns = valid_X.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.864783Z","iopub.status.idle":"2021-06-27T13:44:37.865228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.865999Z","iopub.status.idle":"2021-06-27T13:44:37.866454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_list = []","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.86731Z","iopub.status.idle":"2021-06-27T13:44:37.867733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-27T13:44:37.868526Z","iopub.status.idle":"2021-06-27T13:44:37.868924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.869808Z","iopub.status.idle":"2021-06-27T13:44:37.870269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ### 3. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - mean (adding a column indicating which column was imputed)","metadata":{}},{"cell_type":"code","source":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\ncols_with_missing = [col for col in train_X.columns\n                     if train_X[col].isnull().any()]\n\ntrain_X_m3 = train_X.copy()\nvalid_X_m3 = valid_X.copy()\n\nfor col in cols_with_missing:\n    train_X_m3[col + '_was_missing'] = train_X_m3[col].isnull()\n    valid_X_m3[col + '_was_missing'] = valid_X_m3[col].isnull()\n\n#Let's go with the mean as the strategy this time.\nimputer = SimpleImputer(strategy='mean')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X_m3))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X_m3))\n\nimputed_train_X.columns = train_X_m3.columns\nimputed_valid_X.columns = valid_X_m3.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.893508Z","iopub.status.idle":"2021-06-27T13:44:37.893909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.895129Z","iopub.status.idle":"2021-06-27T13:44:37.895532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_list = []","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.896617Z","iopub.status.idle":"2021-06-27T13:44:37.897028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-27T13:44:37.897821Z","iopub.status.idle":"2021-06-27T13:44:37.898223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T13:44:37.899322Z","iopub.status.idle":"2021-06-27T13:44:37.899752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### That's all for now folks!","metadata":{}}]}