{"cells":[{"metadata":{"id":"Baodtjso1U6W","outputId":"36b095a7-0d56-4f43-c0a0-f4b4a94a860c","trusted":false},"cell_type":"code","source":"try:\n    import torch_geometric\nexcept:\n    import torch\n    \n    CUDA = \"cu102\"\n    TORCH = \"1.4.0\"\n    \n    ! pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n    ! pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n    ! pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n    ! pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n    ! pip install torch-geometric","execution_count":null,"outputs":[]},{"metadata":{"id":"57DpXDnG1s3Y","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.nn import Linear, LayerNorm, ReLU, Dropout\nimport torch.nn.functional as F\nfrom torch_geometric.nn import ChebConv, NNConv, DeepGCNLayer, GATConv, DenseGCNConv, GCNConv, GraphConv\nfrom torch_geometric.data import Data, DataLoader\n\nfrom sklearn.metrics import roc_auc_score\nimport scipy.sparse as sp\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"id":"Z_FW_uxL2Dag","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf_features = pd.read_csv('../input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_txs_features.csv', header=None)\ndf_edges = pd.read_csv(\"../input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\ndf_classes =  pd.read_csv(\"../input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\ndf_classes['class'] = df_classes['class'].map({'unknown': 2, '1':1, '2':0})","execution_count":null,"outputs":[]},{"metadata":{"id":"iBYoyWM32JFQ","trusted":true},"cell_type":"code","source":"# merging dataframes\ndf_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\ndf_merge = df_merge.sort_values(0).reset_index(drop=True)\nclassified = df_merge.loc[df_merge['class'].loc[df_merge['class']!=2].index].drop('txId', axis=1)\nunclassified = df_merge.loc[df_merge['class'].loc[df_merge['class']==2].index].drop('txId', axis=1)\n\n# storing classified unclassified nodes seperatly for training and testing purpose\nclassified_edges = df_edges.loc[df_edges['txId1'].isin(classified[0]) & df_edges['txId2'].isin(classified[0])]\nunclassifed_edges = df_edges.loc[df_edges['txId1'].isin(unclassified[0]) | df_edges['txId2'].isin(unclassified[0])]\ndel df_features, df_classes","execution_count":null,"outputs":[]},{"metadata":{"id":"LMM7lBiU2I6F","outputId":"b50b50b2-4410-4a14-f9f8-35ed45679691","trusted":true},"cell_type":"code","source":"# all nodes in data\nnodes = df_merge[0].values\nmap_id = {j:i for i,j in enumerate(nodes)} # mapping nodes to indexes\n\nedges = df_edges.copy()\nedges.txId1 = edges.txId1.map(map_id)\nedges.txId2 = edges.txId2.map(map_id)\nedges = edges.astype(int)\n\nedge_index = np.array(edges.values).T\n\n# for undirected graph\n# edge_index_ = np.array([edge_index[1,:], edge_index[0, :]])\n# edge_index = np.concatenate((edge_index, edge_index_), axis=1)\n\nedge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\nweights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.double)\nprint(edge_index.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"4M4CJKwpvNtP","trusted":true},"cell_type":"code","source":"# maping txIds to corresponding indexes, to pass node features to the model\nnode_features = df_merge.drop(['txId'], axis=1).copy()\nnode_features[0] = node_features[0].map(map_id)\nclassified_idx = node_features['class'].loc[node_features['class']!=2].index\nunclassified_idx = node_features['class'].loc[node_features['class']==2].index\n# replace unkown class with 0, to avoid having 3 classes, this data/labels never used in training\nnode_features['class'] = node_features['class'].replace(2, 0) ","execution_count":null,"outputs":[]},{"metadata":{"id":"hGx0LmwS2Ilv","trusted":false},"cell_type":"code","source":"labels = node_features['class'].values\nnode_features = torch.tensor(np.array(node_features.drop([0, 'class', 1], axis=1).values, dtype=np.double), dtype=torch.double)\n\n# converting data to PyGeometric graph data format\ndata_train = Data(x=node_features, edge_index=edge_index, edge_attr=weights,\n                               y=torch.tensor(labels, dtype=torch.double)) #, adj= torch.from_numpy(np.array(adj))","execution_count":null,"outputs":[]},{"metadata":{"id":"Wv747ZYxhabw","trusted":false},"cell_type":"code","source":"y_train = labels[classified_idx]\n\n# spliting train set and validation set\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid, train_idx, valid_idx = train_test_split(node_features[classified_idx], y_train, classified_idx, test_size=0.15, random_state=42, stratify=y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"ocbBkKk3hcOI","outputId":"f0b90aae-3ad9-4c2d-d9c5-c8212084f8ff","trusted":false},"cell_type":"code","source":"data_train.y[classified_idx].sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"3wdIHRUm2RZk","trusted":false},"cell_type":"code","source":"# data_train.y = data_train.y.double()\n# data_train.x = data_train.x.double()","execution_count":null,"outputs":[]},{"metadata":{"id":"ey_zVTCC2Ttn","outputId":"feac5ff9-ebe0-469d-fc22-2b5484fc8034","trusted":false},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"Rjr_1PQf2TmI","trusted":false},"cell_type":"code","source":"import torch.nn.functional as F\nfrom sklearn.metrics import roc_auc_score\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv1 = GCNConv(165, 128)\n        self.conv2 = GCNConv(128, 128)\n        self.conv3 = GCNConv(64, 64)\n        self.conv4 = GCNConv(128, 1) \n\n    def forward(self, data, adj=None):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, p=0.1, training=self.training)\n        x = self.conv4(x, edge_index)\n\n        return F.sigmoid(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"_41H9jZyvRMK","outputId":"7b4cb5f4-3c87-4230-aeab-156c7fd734a7","trusted":false},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Net().to(device)\nmodel.double()\ndata_train = data_train.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\ncriterion = torch.nn.BCELoss()\n\nmodel.train()\nfor epoch in range(70):\n    optimizer.zero_grad()\n    out = model(data_train)\n    # data_train.y.unsqueeze(1)\n    out = out.reshape((data_train.x.shape[0]))\n    loss = criterion(out[train_idx], data_train.y[train_idx])\n    auc = roc_auc_score(data_train.y.detach().cpu().numpy()[train_idx], out.detach().cpu().numpy()[train_idx]) #[train_idx]\n    loss.backward()\n    optimizer.step()\n    if epoch%5 == 0:\n      print(\"epoch: {} - loss: {} - roc: {}\".format(epoch, loss.item(), auc))","execution_count":null,"outputs":[]},{"metadata":{"id":"lYxjqP4U2f0S","trusted":false},"cell_type":"code","source":"preds = model(data_train)\npreds = preds.detach().cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"id":"VuFVOba1Sp9A","outputId":"3492f545-0177-4b93-c8da-b25da812d46a","trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nout_labels = preds > 0.6\ntrain_acc = accuracy_score(data_train.y.detach().cpu().numpy()[train_idx], out_labels[train_idx])\ntrain_auc = roc_auc_score(data_train.y.detach().cpu().numpy()[train_idx], preds[train_idx])\nprint(\"train accuracy: \", train_acc)\nprint(\"train AUC: \", train_auc)","execution_count":null,"outputs":[]},{"metadata":{"id":"gYkbMHzKBkop","outputId":"1bdcaaa4-6394-4986-c98d-5883a2c200ec","trusted":false},"cell_type":"code","source":"valid_auc = roc_auc_score(data_train.y.detach().cpu().numpy()[valid_idx], preds[valid_idx])\nout_labels = out.detach().cpu().numpy() > 0.6\nvalid_acc = accuracy_score(data_train.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx])\nprint(\"valid accuracy: \", valid_acc)\nprint(\"valid AUC: \", valid_auc)","execution_count":null,"outputs":[]},{"metadata":{"id":"yIytiwE4DmUT","outputId":"0f88d217-18e9-48a8-ae93-bf5235f11a78","trusted":false},"cell_type":"code","source":"# total predicted illicit (positives) in test set\nout_labels[unclassified_idx].sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"HswFvuso71N1","outputId":"e08c8b6f-ba11-4428-f0a0-d1e70aa96b83","trusted":false},"cell_type":"code","source":"# total predicted positives in validation set\nout_labels[valid_idx].sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"p0RO7CM72h8e","outputId":"402aae83-9666-4d1d-81d5-7382e034e0b0","trusted":false},"cell_type":"code","source":"from sklearn.metrics import roc_curve, confusion_matrix\n# confusion matrix for validation data\ncm = confusion_matrix(data_train.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx])\ncm","execution_count":null,"outputs":[]},{"metadata":{"id":"T8Le8GUuB4nM","outputId":"4d12722c-522d-44d5-e40a-fa887f865af6","trusted":false},"cell_type":"code","source":"# confusion matrix for train data\ncm = confusion_matrix(data_train.y.detach().cpu().numpy()[train_idx], out_labels[train_idx])\ncm","execution_count":null,"outputs":[]},{"metadata":{"id":"sES35_kMX95G","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}