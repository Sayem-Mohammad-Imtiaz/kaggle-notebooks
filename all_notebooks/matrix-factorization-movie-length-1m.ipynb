{"cells":[{"metadata":{"_uuid":"4308205b065c7e6684592ec42e475e5bcbe9b773"},"cell_type":"markdown","source":"## 1. Giới thiệu về phương pháp Recommendation system\n### 1. 1. Tầm quan trọng của recommendation system\nTrong cuộc sống hàng ngày chúng ta thường thấy những tình huống khá tình cờ khi các hệ thống lớn có khả năng đọc và hiểu sở thích của người dùng và hiện thị những thông tin mà người dùng quan tâm rất chuẩn xác. Chẳng hạn như:\n\n* Facebook có khả năng hiển thị trên newfeed những trạng thái của những người mà bạn quan tâm.\n* Youtube có thể tự động nhảy sang những video mà bạn có khả năng yêu thích dựa trên những gì mà bạn đang xem.\n* Amazon có thể đưa ra những cuốn sách cùng loại với những cuốn sách mà bạn đã mua hoặc rating cao.\n* Google có thể đưa quảng cáo về một đồ vật phù hợp với những gì bạn tìm kiếm gần đây.\n\nNếu không có các thuật toán recommendation, trải nghiệm người dùng sẽ kém hơn vì thông tin mà họ thực sự quan tâm không được đưa ra đúng thời điểm trong khi thông tin không cần thiết được đưa ra nhiều hơn. Hậu quả là người dùng cảm thấy bị làm phiền và nhiễu loạn thông tin. Trong lĩnh vực marketing hệ thống recommendation lại càng trở nên quan trọng. Mỗi sản phẩm được đưa đến đúng người tiêu dùng có nhu cầu sẽ làm tăng doanh thu, giảm chi phí thời gian, chi phí quảng cáo và giúp người tiêu dùng sở hữu được thứ mình cần. Trong lĩnh vực giải trí như video, game, truyện online,... người dùng sẽ đạt độ hài lòng cao khi tìm được đúng loại hình giải trí yêu thích dễ dàng. Dù chỉ ra đời trong 10 năm trở lại đây, song hành cùng thời kì bùng nổ internet nhưng có thể nói `recommendation system` là một lĩnh vực nghiên cứu sôi động. Nó đã tạo ra một cuộc cách mạng thay đổi hành vi mua sắm, hành vi giải trí, chiến lược kinh doanh,... trên toàn cầu. Hàng trăm triệu các hộ kinh doanh nhỏ lẻ đang hưởng lợi từ nó thông qua khai thác nguồn khách hàng vô tận từ tài nguyên mạng và biến kênh bán hàng này thay thế các kênh truyền thống. Lĩnh vực này đồng thời là chìa khóa mấu chốt giúp các công ty công nghệ Google, Facebook, Amazon, Microsoft,... trở thành những tập đoành hàng đầu thể giới. Chính vì thế `recommendation system` luôn được các công ty kinh doanh trên nền tảng online đầu tư nghiên cứu và phát triển để tạo ra một hệ thống thông minh nhằm nâng cao trải nghiệm khách hàng và tối ưu hóa nguồn tài nguyên.\n\n### 1.2. Phương pháp recommendation\n\nBên trên chúng ta đã biết vai trò của `recommendation system` đối với việc phát triển của lĩnh vực internet và kinh doanh online. Tuy nhiên thực sự bài toán `recommendation system` là gì? Cơ sở của phương pháp `recommendation system` ra sao chúng ta vẫn chưa thực sự hiểu rõ. Theo định nghĩa từ wikipedia thì `recommendation system` là một nhánh nhỏ của lĩnh vực *hệ thống chiết lọc thông tin* (information filtering system) được sử dụng để dự báo mức độ yêu thích thông qua rating của một người dùng (user) cho một sản phẩm (item). Để đưa ra được sản phẩm phù hợp nhất đến người dùng đòi hỏi các hệ thống phải dựa trên thông tin đã rating của sản phẩm, thông tin người dùng, thông tin về sản phẩm để xây dựng thuật toán tối ưu. Dựa trên hàm loss function để tính ra sai số dự báo của thuật toán và tìm ra một phương pháp có mức độ dự báo chuẩn xác nhất. Có rất nhiều các thuật toán khác nhau được sử dụng trong `recommendation system` nhưng về cơ bản chúng bao gồm 2 phương pháp chính: `Collaborative filtering` và `Content based filtering`. Điểm khác biệt cơ bản giữa 2 phương pháp này là:\n\n* Collaborative filtering: Dựa trên mối quan hệ tương quan về mặt hành vi tiêu dùng hoặc đặc trưng sản phẩm để tìm ra các users hoặc items có chung đặc tính, sở thích. Từ đó dựa trên những thông tin mà nhóm người dùng hoặc sản phẩm liên quan gần nhất đã rating để đánh giá sản phẩm mà một người dùng cụ thể chưa rating. Tuy nhiên nhược điểm của thuật toán này là đưa ra dự báo về rating mà không hoàn toàn hiểu về user, item mà hoàn toàn dựa trên quan sát về mức độ tương đương giữa các nhóm users, items để dự báo. Thuật toán được sử dụng trong các bài toán này chủ yếu là k-nearest neighbor để tìm ra nhóm tương đương và ma trận hệ số tương quan được sử dụng để đo lường mức độ gần gũi về mặt hành vi hay đặc tính để phân nhóm.\n\n* Content based filtering: Dựa trên những thông tin và nội dung liên quan đến sản phẩm như nhà sản xuất, thể loại, năm sản xuất, công dụng, đặc tính,... hoặc dựa trên thông tin của người dùng như giới tính, độ tuối, ngành nghề,... để đưa ra dự báo về rating của người đối với sản phẩm đó. Thuật toán này chỉ đơn thuần là các phương trình hồi qui giữa các chiều đặc tính của sản phẩm hoặc người dùng đối với điểm rating mà không tận dụng được tương quan về mặt hành vi giữa những nhóm người dùng hay đặc trưng sản phẩm như `Collaborative filtering`. Trong thực tế hành vi của người dùng lại cho thấy rất giống nhau nếu thuộc cùng một nhóm chẳng hạn như các nhóm nhạc thiền, nhạc vàng, nhạc trẻ, nhạc thiếu nhi sẽ phù hợp với người già, người trung niên, người trẻ, thiếu nhi. Không xem xét được các yếu tố tương quan theo nhóm là một hạn chế lớn của content based filtering.\n\n\nMỗi thuật toán đều có ưu, nhược điểm khác nhau và mức độ hiệu quả trong dự báo mức độ yêu thích các cặp (user, item) (*người dùng, sản phẩm*) cũng khác nhau tùy thuộc vào tập dữ liệu. Nhưng các thuật toán đều có điểm chung đó là sử dụng dữ liệu mà người dùng đã rating đối với các sản phẩm để làm cơ sở dự báo rating cho các sản phẩm chưa được đánh giá. Việc này cũng giống như chúng ta chơi trò chơi điền số vào *ma trận tiện ích* (utility matrix). Một chiều của ma trận ứng với users và chiều còn lại ứng với items. Các ô trên ma trận thể hiện giá trị rating của user tương ứng lên item. Như vậy sẽ có những ô đã được rating bởi người dùng và các ô còn lại chưa được rating. Quá trình giải bài toán cũng giống như việc chúng ta đi giải ma trận tại những ô còn thiếu sao cho sai số cuối cùng giữa dự báo và thực tế là nhỏ nhất. \n\n### 1.3. Giới thiệu thuật toán matrix factorization\n\n\nTrong thuật toán matrix factorization chúng ta giả định đặc trưng của item được thể hiện qua ma trận $\\mathbf{I}$ và hành vi của người dùng được thể hiện qua ma trận $\\mathbf{U}$. Với mỗi dòng của ma trận $\\mathbf{I}$ là một đặc trưng ẩn (*latent feature*) của sản phẩm và mỗi cột của $\\mathbf{U}$ là mức độ yêu thích của một người dùng đối với đặc trưng ẩn tương ứng. Các đặc trưng ẩn này có thể coi như những nhân tố chính được tổng hợp từ nhiều thông tin liên quan đến sản phẩm tương tự như thành phần chính trong phép phân tích thành phần chính `PCA`. Đặc trưng của sản phẩm thứ m được thể hiện qua vector dòng $\\mathbf{i_m}$ và hành vi của người dùng thứ n được thể hiện qua vector cột $\\mathbf{u_n}$. Khi đó giá trị dự báo mức độ yêu thích của một người dùng n lên một sản phẩm m sẽ là tích của 2 vector $\\mathbf{i_m}$ và $\\mathbf{u_n}$:\n\\begin{equation*}\ny_{mn} = \\mathbf{i_m} \\mathbf{u_n}\n\\end{equation*}\n\nước lượng của ma trận tiện ích $\\mathbf{\\hat{Y}}$ sẽ được biểu diễn theo các ma trận hành vi $\\mathbf{I}$ và ma trận người dùng $\\mathbf{U}$ như sau:\n\n\\begin{equation*}\n\\mathbf{\\hat{Y}} \\approx \\left[ \\begin{matrix}\n\\mathbf{i}_1\\mathbf{u}_1 & \\mathbf{i}_1\\mathbf{u}_2 & \\dots & \\mathbf{i}_1 \\mathbf{u}_N\\\\\n\\mathbf{i}_2\\mathbf{u}_1 & \\mathbf{i}_2\\mathbf{u}_2 & \\dots & \\mathbf{i}_2 \\mathbf{u}_N\\\\\n\\dots & \\dots & \\ddots & \\dots \\\\\n\\mathbf{i}_M\\mathbf{u}_1 & \\mathbf{i}_M\\mathbf{u}_2 & \\dots & \\mathbf{i}_M \\mathbf{u}_N\\\\\n\\end{matrix} \\right]\n = \\left[ \\begin{matrix}\n\\mathbf{i}_1 \\\\\n\\mathbf{i}_2 \\\\\n\\dots \\\\\n\\mathbf{i}_M \\\\\n\\end{matrix} \\right]\n\\left[ \\begin{matrix}\n\\mathbf{u}_1 & \\mathbf{u}_2 & \\dots & \\mathbf{u}_N\n\\end{matrix} \\right] = \\mathbf{IU}\n\\end{equation*}\n\n\n### 1.4. Thuật toán gradient descent\n\nGiả sử rằng chúng ta đã có thông tin về các ma trận $\\mathbf{U}$ và $\\mathbf{I}$ điều chúng ta cần thực hiện bây giờ là coi các dòng của mỗi $\\mathbf{I}$ là một item profile và mỗi cột của $\\mathbf{U}$ là một user profile. Giả sử $\\mathbf{I} \\in \\mathbb{R}^{M \\times K}$, $\\mathbf{U} \\in \\mathbb{R}^{K \\times N}$, $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$. Thông thường ta sẽ chọn số đặc trưng ẩn nhỏ hơn số lượng sản phẩm và người dùng. Khi đó Y sẽ được biểu diễn dưới dạng tích của 2 ma trận có rank nhỏ hơn (*Low-rank Matrix factorization*):\n\n\\begin{aligned}\\hat{\\mathbf{Y}} = \\mathbf{I}\\mathbf{U}\\end{aligned}\n\nHàm loss function của thuật toán chính là chuẩn [Frobenius norm](http://mathworld.wolfram.com/FrobeniusNorm.html) về độ lệch giữa $\\mathbf{Y}$ và $\\mathbf{\\hat{Y}}$ như sau:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{I},\\mathbf{U})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2\n\\end{aligned}\n\nĐể tránh hiện tượng overfiting [hệ số hiệu chỉnh bậc 2](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c) (*l2 - reguralization*) được đưa thêm vào:\n\n\\begin{equation*}\n\\mathcal{L(\\mathbf{I},\\mathbf{U})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2 + \\frac{\\lambda_1}{2}||\\mathbf{I}||_{F}^2 + \\frac{\\lambda_2}{2}||\\mathbf{U}||_{F}^2             \\tag{1.4.1}\n\\end{equation*}\n\nNếu coi $\\mathbf{U}$ cố định và cần tối ưu $\\mathbf{I}$. Bài toán `Matrix factorization` sẽ tương đương với tối ưu hàm loss function:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{I})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2 + \\frac{\\lambda_1}{2}||\\mathbf{I}||_{F}^2\n\\end{aligned}\n\nNếu coi $\\mathbf{I}$ cố định và cần tối ưu $\\mathbf{U}$. Hàm loss function sẽ có dạng:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{U})} = \\frac{1}{2s}||\\mathbf{Y}-\\mathbf{\\hat{Y}}||_{F}^2 + \\frac{\\lambda_2}{2}||\\mathbf{U}||_{F}^2\n\\end{aligned}\n\nTa nhận thấy hàm loss function đều là những hàm lồi. Việc tìm nghiệm tối ưu có thể dựa trên bài toán tối ưu lồi bậc 2 (*Quadratic Programming*) hoặc cách đơn giản hơn là thông qua thuật toán `gradient descent`. Chúng ta sẽ sử dụng thuật toán `Stochastic gradient descent` để cập nhật lần lượt từng điểm dữ liệu trên toàn bộ dữ liệu, sau đó lặp lại quá trình này. Đối với trường hợp ma trận sản phẩm ($\\mathbf{I}$) cố định, ta sẽ cần cập nhật ma trận người dùng ($\\mathbf{U}$) theo phương gradient descent. Mỗi một lượt cập nhật, một người dùng u được lựa chọn. Dựa trên thông tin về những sản phẩm mà người dùng u đã rating. Vector gradient descent được tính toán để cập nhật giá trị của vector $\\mathbf{u}$ tương ứng. Quá trình này tiếp tục cho đến khi toàn bộ các vector users được cập nhật. Tương tự như vậy đối với trường hợp cố định ma trận người dùng cố định và cập nhật ma trận sản phẩm. \n\n**Tối ưu ma trận người dùng:**\n\nĐể đơn giản hóa quá trình tính toán, ta có thể biểu diễn hàm loss function theo tổng loss function của từng user như sau:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{U})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n)^2+\\frac{\\lambda_1}{2} ||\\mathbf{U}||_{F}^2\n\\end{aligned}\n\nTrong đó $r_{mn}$ là phần tử thuộc ma trận rating $R \\in \\mathbb{R}^{M \\times N}$ có giá trị 0 hoặc 1. $r_{mn} = 1$ đánh dấu sản phẩm m đã được rating bởi user n và bằng 0 trong trường hợp chưa được rating. Điều kiện $r_{mn} = 1$ trong hàm loss function là để lọc ra những sản phẩm đã được rating bởi user n. Khi đó nếu coi $\\hat{\\mathbf{I}}_n$ là ma trận các sản phẩm đã được rating của user n và $\\hat{y}_n$ là vector kết quả rating tương ứng thì hàm loss function đối với user n được viết gọn như sau:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{U}| user = n)} = \\frac{1}{2s}\\sum_{m: r_{mn} = 1}(y_{mn} - \\mathbf{i_m} . \\mathbf{u_n})^2 + \\frac{\\lambda_1}{2}||\\mathbf{u_n}||^2 = \\frac{1}{2s}||\\mathbf{\\hat{y}_n}-\\hat{\\mathbf{I}}_n. \\mathbf{u_n}||^2 + \\frac{\\lambda_1}{2}||\\mathbf{u_n}||^2\n\\end{aligned}\n\nĐạo hàm của nó tương ứng:\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L(\\mathbf{U}| user = n)}}{\\partial \\mathbf{u_n}} = -\\frac{1}{s}\\hat{\\mathbf{I}}_n^{T}\\space (\\mathbf{\\hat{y}_n}-\\hat{\\mathbf{I}}_n. \\mathbf{u_n}) + \\lambda_1\\mathbf{u_n}\n\\end{aligned}\n\nCông thức cập nhật nghiệm cho mỗi cột của ma trận người dùng:\n\n\\begin{aligned}\n\\mathbf{u'_n} = \\mathbf{u_n} - \\theta (-\\frac{1}{s}\\hat{\\mathbf{I}}_m^{T}\\space (\\mathbf{\\hat{y}_n}-\\hat{\\mathbf{I}}_n. \\mathbf{u_n}) + \\lambda_1\\mathbf{u_n})\n\\end{aligned}\n\n**Tối ưu ma trận sản phẩm:**\n\nHoàn toàn tương tự ta cũng có đối với ma trận sản phẩm, hàm loss function đối với item = m:\n\n\\begin{aligned}\n\\mathcal{L(\\mathbf{I}| item = m)} = \\frac{1}{2s}\\sum_{n: r_{mn} = 1}(y_{mn} - \\mathbf{i_m} . \\mathbf{u_n})^2 + \\frac{\\lambda_1}{2}||\\mathbf{i_m}||^2 = \\frac{1}{2s}||\\mathbf{\\hat{y}_m}-\\mathbf{i_m}.\\hat{\\mathbf{U}}_m||^2 + \\frac{\\lambda_1}{2}||\\mathbf{i_m}||^2\n\\end{aligned}\n\nĐạo hàm tương ứng đối với mỗi item sẽ là:\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L(\\mathbf{I}| item = m)}}{\\partial \\mathbf{i_m}} = -\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_m}. \\hat{\\mathbf{U}}_m)\\hat{\\mathbf{U}}_m^{T} + \\lambda_1\\mathbf{i_m}\n\\end{aligned}\n\nCông thức cập nhật nghiệm cho mỗi dòng của ma trận sản phẩm:\n\n\\begin{aligned}\n\\mathbf{i'_m} = \\mathbf{i_m} - \\theta (-\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_m}. \\hat{\\mathbf{U}}_m)\\hat{\\mathbf{U}}_m^{T} + \\lambda_1\\mathbf{i_m})\n\\end{aligned}\n\n## 2. Xây dựng code thuật toán\n\n### 2.1. Thực hành trên bộ dữ liệu movie length 1M\n\nChúng ta sẽ thực hiện phương pháp `matrix factorization` trên bộ dữ liệu [Movie length 1M](http://files.grouplens.org/datasets/movielens/ml-1m.zip) gồm 1 triệu các lượt ratings cho khoảng 4000 bộ phim được thu thập từ 6000 người dùng. Để tiện phù hợp với thuật toán đã xây dựng, các xử lý dữ liệu sẽ được thực hiện trên ma trận. Load dữ liệu đầu vào như sau:"},{"metadata":{"trusted":true,"_uuid":"75921cc9eeeb8a254be0f53c590f91911f755eba","_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ncolumns = ['user_id', 'item_id', 'rating', 'timestamp']\nmovie_length = pd.read_csv('../input/ratings.dat', header = 0, \\\n                           names = columns, sep = '::', engine = 'python')\nmovie_length = movie_length.sort_values(['user_id', 'item_id'])\nmovie_length.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e93ea4ee0079bbb43581888a5f27652884cfb1f"},"cell_type":"markdown","source":"Kích thước các dữ liệu và số lượng users, items"},{"metadata":{"trusted":true,"_uuid":"c0d5eda977a1b49630b92453ddce67895034afb5"},"cell_type":"code","source":"print('Data movie length shape: %s'%str(movie_length.shape))\nprint('No customers: %s'%str(np.unique(movie_length.iloc[:, 0]).shape[0]))\nprint('No movies: %s'%str(np.unique(movie_length.iloc[:, 1]).shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"885ac3a9ba3dcb7150cdcda80a8ffefaab052c86"},"cell_type":"markdown","source":"Thống kê mô tả số tần suất rating của các users:"},{"metadata":{"trusted":true,"_uuid":"ac953acef011c01c50a1ac9aef9a2ee1cac2730f"},"cell_type":"code","source":"movie_length['user_id'].value_counts().describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d527f28e23916ff8f4628fe2937578234828e2a"},"cell_type":"markdown","source":"* Bình quân một user rate tổng cộng 165 bộ phim. \n* User thấp nhất rate 20 bộ phim và user nhiều nhất rate 2314 bộ phim. \n* Khoảng số lượng bộ phim rating phổ biến của một user là từ 44 bộ tới 208 bộ phim (chiếm 50%)."},{"metadata":{"trusted":true,"_uuid":"76d03c224285779b0288471bf356b364a1569a9d"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nmovie_length[['user_id', 'item_id']].groupby(['user_id']).count().\\\nhist(bins = 20, figsize = (12, 8))\nplt.title('Distribution of no ratings by each customer')\nplt.xlabel('No ratings')\nplt.ylabel('No customers')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35a508056fb88a02419d6af847e1d28257e39d66"},"cell_type":"markdown","source":"Nhìn vào phân bố của số lượng user theo mức độ rating ta có thể thấy mẫu của chúng ta có hiện tượng không cân bằng khi có nhiều user rating rất ít và nhiều user rating nhiều hơn. Tuy nhiên đây không phải là bài toán classification nên việc mẫu có kích thước mất cân bằng cũng không ảnh hưởng tới mức độ chính xác của thuật toán. Hơn nữa thuật toán `matrix factorization` xây dựng hàm loss function riêng lẻ cho từng user nêu việc user này rating bao nhiêu sản phẩm không ảnh hưởng đến kết quả dự báo rating của user khác. Hoàn toàn tương tự ta cũng thống kê được số lượng các user rating đối với từng bộ phim."},{"metadata":{"trusted":true,"_uuid":"a06ceb5c3faf499214a775e260b5a6f99c28e019"},"cell_type":"code","source":"movie_length['item_id'].value_counts().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf2bac8083738a8d13097e7ee5a9f8d933071876"},"cell_type":"code","source":"movie_length[['user_id', 'item_id']].groupby(['item_id']).count().\\\nhist(bins = 20, figsize = (12, 8))\nplt.title('Distribution of no ratings per each movie')\nplt.xlabel('No ratings')\nplt.ylabel('No movies')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ceeadb9c4ad2f7ed00e5d5258af2abfbf35ba833"},"cell_type":"markdown","source":"Một vài đánh giá:\n* Số lần 1 bộ phim được rating ít nhất là 1 lần.\n* Số lần 1 bộ phim được rating nhiều nhất là 3428 lần.\n* Mức độ rating phổ biến của một bộ phim là từ 33 đến 123 lần.\n\n## 2.2. Thuật toán matrix factorization\n\n### 2.2.1. Các hàm trong thuật toán\n\nĐầu tiên ta sẽ tiến hành chia mẫu train và test theo tỷ lệ sao cho số lượng rating trong tập train chiếm 2/3 số lượng các lượt rating. Cách chia mẫu hợp lý nhất là đảm bảo tỷ lệ số lượng ratings xuất hiện trong tập train đối với số lượng ratings xuất hiện trong tập test của cùng một user là bằng nhau. Cách chia này đảm bảo sự công bằng đối với các user khi không có user nào có quá nhiều dữ liệu train và dữ liệu test ít hoặc dữ liệu train quá ít nhưng dữ liệu test lại quá nhiều. Giá trị được dự báo từ mô hình mà dữ liệu train quá ít sẽ thường không chuẩn xác và làm sai lệch kết quả kiểm tra sai số trên test. "},{"metadata":{"trusted":true,"_uuid":"a31e9751b6eb95dc8a0cca52b59b4c5e1ae2b7ff","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"#declare split_rate for train/total ratings\nsplit_rate = 2/3\n\ndef split_train_test(dataset):\n    gb = dataset.groupby('user_id')\n    ls = [gb.get_group(x) for x in gb.groups]\n    items = [x for x in gb.groups]\n    index_size = [{'i': i, 'index':gb.groups[i], 'size':len(gb.groups[i])} for i in items]\n    index_train = pd.Int64Index([])\n    index_test = pd.Int64Index([])\n    for x in index_size:\n        np.random.shuffle(x['index'].values)\n        le = int(x['size']*split_rate)\n        index_train = index_train.append(x['index'][:le])\n        index_test = index_test.append(x['index'][le:])\n    train = dataset.iloc[index_train].values\n    test = dataset.iloc[index_test].values\n    #minus id to 1 to index start from 0\n    train[:, 0] -= 1\n    train[:, 1] -= 1\n    test[:, 0] -= 1\n    test[:, 1] -= 1\n    return train, test\n\ntrain, test = split_train_test(movie_length)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b9845f4338cc598ade78720a84f13d238c5fb7f"},"cell_type":"markdown","source":"**Tiến hành xây dựng thuật toán:**\n\nCác biến chính cho thuật toán dữ báo bao gồm:\n* n_users: Số lượng user (chính là $N$ trong thuật toán).\n* n_items: Số lượng item (chính là $M$ trong thuật toán).\n* K: Số lượng nhân tố ẩn được sử dụng (giá trị $K$ trong thuật toán). \n* theta: Tham số $\\theta$ để cập nhật hệ số trong thuật toán gradient descent.\n* split_rate: Tỷ lệ chia mẫu train/test.\n* lamda: Tham số hiệu chỉnh của thành phần hiệu chỉnh `l2 - regularization` (Để đơn giản thiết lập $\\lambda_1 = \\lambda_2$).\n* I: Ma trận sản phẩm.\n* U: Ma trận người dùng.\n\nLưu ý rằng các ma trận $\\mathbf{I}, \\mathbf{U}$ được xây dựng dựa trên các *nhân tố ẩn* (latent feature) nên ban đầu ta chưa xác định được các nhân tố này và phải khởi tạo giá trị ngẫu nhiên cho chúng. Số lượng nhân tố ẩn $K$ là một giá trị tùy ý ta có thể lựa chọn. Theo [Matrix Factorization For Recommendation System](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf) thì khi số lượng nhân tố ẩn càng nhiều thuật toán càng chính xác hơn nhưng cũng làm gia tăng chi phí tính toán.  Đồng thời những mô hình được xây dựng dựa trên nhân tố ẩn đã được tinh luyện để có mức độ khác biệt lớn cũng đưa ra kết quả chính xác hơn các việc tạo ra các nhân tố ẩn ngẫu nhiên. "},{"metadata":{"trusted":true,"_uuid":"2f66f994447184ed436aa39e6dc03a59dd453617"},"cell_type":"code","source":"n_users = np.max(train[:, 0] + 1) #plus one because index start from 0\nn_items = np.max(train[:, 1] + 1)\nn_ratings = train.shape[0]\nprint('N user dimesion: %s'%n_users)\nprint('M item dimesion: %s'%n_items)\nprint('S Number of rating: %s'%n_ratings)\nK = 2\ntheta = 0.75\nlamda = 0.2\n#Inititalize random matrix according to Gauss distribution\nI = np.random.randn(n_items, K)\nU = np.random.randn(K, n_users)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a15ba1fcd16770a85d7ffd123268889d098c484e"},"cell_type":"code","source":"import scipy.sparse as sparse\n#Rating matrix\nY = np.zeros(shape = (n_items, n_users))\nprint('Y utility matrix shape: %s'%str(Y.shape))\nY = sparse.coo_matrix((train[:, 2], (train[:, 1], train[:, 0])),\\\n                      shape = (n_items, n_users), dtype = np.float).toarray()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b22a47980d6fcdc27fdf4c96a281d1aba5f02abb"},"cell_type":"markdown","source":"Không phải hoàn toàn các giá trị trên ma trận $\\mathbf{Y}$ đều được rating. Vì vậy ma trận $\\mathbf{R}$ được tạo ra nhằm đánh dấu các vị trí được rating của $\\mathbf{Y}$ bằng giá trị 1 và chưa được rating bằng 0."},{"metadata":{"trusted":true,"_uuid":"fa4d5d61e0956f8694065d4030b58dd55123f7c1"},"cell_type":"code","source":"R = sparse.coo_matrix((np.ones((n_ratings,)), (train[:, 1], train[:, 0])),\\\n                      shape = (n_items, n_users)).toarray()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94487acb57ab4b68bf3c3e1e9f2222b90724002b"},"cell_type":"markdown","source":"Để thuật toán `gradient descent` hội tụ nhanh hơn chúng ta cần chuẩn hóa ma trận $\\mathbf{Y}$ về giá trị kì vọng bằng 0 bằng cách trừ đi mỗi giá trị rating trong vector rating của một user với trung bình của vector rating đó."},{"metadata":{"trusted":true,"_uuid":"9ceb8b4521a168218eb0cafd99f2285b87f9d2a9"},"cell_type":"code","source":"def standardize_Y(Y):\n    sum_rating = Y.sum(axis = 0)\n    u_rating = np.count_nonzero(Y, axis = 0)\n    u_mean = sum_rating/u_rating\n    for n in range(n_users):\n        for m in range(n_items):\n            if Y[m, n] != 0:\n                Y[m, n] -= u_mean[n]\n    return Y, u_mean\n\nY_stad, u_mean = standardize_Y(Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92f444fb7af7d1731b5a3908ed3b6a48537d4125"},"cell_type":"markdown","source":"Sau khi chuẩn hóa ma trận $\\mathbf{Y}$ thì phần quan trọng nhất là áp dụng thuật toán `gradient descent` để tối ưu hóa các hệ số của ma trận $\\mathbf{U}, \\mathbf{I}$. Dựa trên lý thuyết về thuật toán đã xây dựng ở mục **1.4** để xây dựng các hàm số update ma trận:\n\n**Thuật toán gradient descent cho ma trận người dùng:**"},{"metadata":{"trusted":true,"_uuid":"fefd8dd0084de36ca676fb02099604243867ab84"},"cell_type":"code","source":"def updateU(U):\n    for n in range(n_users):\n    # Matrix items include all items is rated by user n\n        i_rated = np.where(Y_stad[:, n] != 0)[0] #item's index rated by n\n        In = I[i_rated, :]\n        if In.shape[0] == 0:\n            U[:, n] = 0\n        else: \n            s = In.shape[0]\n            u_n = U[:, n]\n            y_n = Y_stad[i_rated, n]\n            grad = -1/s * np.dot(In.T,(y_n-np.dot(In, u_n))) + lamda*u_n\n            U[:, n] -= theta*grad\n    return U","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da1071749f9d1561b2f6bfdce57739ab17d8f3a2"},"cell_type":"markdown","source":"**Thuật toán gradient descent cho ma trận sản phẩm:**"},{"metadata":{"trusted":true,"_uuid":"85620140574c17047702680a097034e510a2aca7"},"cell_type":"code","source":"def updateI(I):\n    for m in range(n_items):\n    # Matrix users who rated into item m\n        i_rated = np.where(Y_stad[m, :] != 0)[0] #user's index rated into m\n        Um = U[:, i_rated]\n        if Um.shape[1] == 0: \n            I[m, :] = 0\n        else:\n            s = Um.shape[1]\n            i_m = I[m, :]\n            y_m = Y_stad[m, i_rated]\n            grad = -1/s * np.dot(y_m - np.dot(i_m, Um), Um.T) + lamda*i_m\n            I[m, :] -= theta*grad\n    return I","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d9e2239925583b9c42f35041aaf7efb182a459b"},"cell_type":"markdown","source":"**Xây dựng hàm dự báo ma trận $\\mathbf{Y}$:**\n\nDựa trên ma trận $\\mathbf{U}$ và $\\mathbf{I}$ ta có thể tính toán ma trận dự báo của $\\mathbf{Y}$ là $\\mathbf{\\hat{Y}}$ theo công thức *(1.4.0)* và xây dựng được hàm *pred()*. Các kết quả dự báo cần được chuyển hóa ngược lại rating bằng cách cộng thêm trung bình rating của mỗi user vào các giá trị ratings thuộc cùng 1 user. Một số kết quả sẽ vượt quá miền giá trị của rating là [1, 5] và khi đó sẽ được gán lại về 2 đầu mút 1 hoặc 5. Ma trận thu được sẽ thỏa mãn tại một ô của $\\mathbf{\\hat{Y}}$ là kết quả dự báo rating của người dùng đối với sản phẩm tương ứng. Do ta chỉ cần đánh giá trận $\\mathbf{Y}$ trên những cặp (user,item) đã được rating nên trong hàm *pred_train_test()* ta cần dựa vào ma trận rating $\\mathbf{R}$ để thay thế những vị trí chưa được rating bằng 0. Lý do hàm số này được đặt tên là *pred_train_test()* đó là chúng ta cũng có thể thực hiện tương tự cho tập test khi thay thế giá trị chưa rating bằng 0."},{"metadata":{"trusted":true,"_uuid":"60b827e6f6a5806eef8d42e10ec7ed77c8109d78"},"cell_type":"code","source":"def pred(U, I):\n    #predict utility matrix base on formula Y_hat = I.U\n    Y_hat = np.dot(I, U)\n    #invert to forecast values by plus user's mean ratings\n    for n in range(n_users):\n        Y_hat[:, n] += u_mean[n]\n    #convert to interger values because of rating is integer\n    Y_hat = Y_hat.astype(np.int32) \n    #replace values > 5 by 5 and values < 1 by 1\n    Y_hat[Y_hat > 5] = 5\n    Y_hat[Y_hat < 1] = 1\n    return Y_hat\n\ndef pred_train_test(Y_hat, R):\n    #replace values have not yet rated by 0 \n    Y_pred = Y_hat.copy()\n    Y_pred[R == 0] = 0\n    return Y_pred","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d69b96bda47e4da8427d7f1cd2695845470f4993"},"cell_type":"markdown","source":"**Xây dựng hàm loss function:**\n\nHàm loss function được xây dựng dựa trên công thức *(1.4.1)* như sau:"},{"metadata":{"trusted":true,"_uuid":"136a291e708b9fee48f322bc6d106895141fddd4"},"cell_type":"code","source":"def loss(Y, Y_hat):\n    error = Y-Y_hat\n    loss_value = 1/(2*n_ratings)*np.linalg.norm(error, 'fro')**2 + \\\n    lamda/2*(np.linalg.norm(I, 'fro')**2 + np.linalg.norm(U, 'fro')**2)\n    return loss_value","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8ac847205c7397611e3d953bce389684c15ff52"},"cell_type":"markdown","source":"Sử dụng ma trận $\\mathbf{\\hat{Y}}$ để dự báo trên tập test"},{"metadata":{"trusted":true,"_uuid":"c2cbc416570fbcf8e1b19a8bd3d628a805e42c7c"},"cell_type":"code","source":"Y_test = sparse.coo_matrix((test[:, 2], (test[:, 1], test[:, 0])), \\\n                           shape = (n_items, n_users), dtype = np.float).toarray()\nR_test = sparse.coo_matrix((np.ones(test.shape[0]), (test[:, 1], test[:, 0])), \\\n                           shape = (n_items, n_users), dtype = np.float).toarray()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81c5ba76e546323ad0aae9b5c481fc96d3bc4e7e"},"cell_type":"markdown","source":"**Xây dựng hàm tính RMSE:**\n\nSau khi tính được ma trận dự báo $\\mathbf{\\hat{Y}}$ trên tập test kết hợp với ma trận tiện ích $\\mathbf{Y}$ của tập test đã biết ta sẽ tính được *RMSE* trên tập test như sau:"},{"metadata":{"trusted":true,"_uuid":"3ad158b177d7ffe17d75156b1fff63a2064bc770"},"cell_type":"code","source":"import math\ndef RMSE(Y_test, Y_pred):\n    error = Y_test - Y_pred\n    n_ratings = test.shape[0]\n    rmse = math.sqrt(np.linalg.norm(error, 'fro')**2/n_ratings)\n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3619b57a607c44c915a363ca781cbdcb7c3be230"},"cell_type":"markdown","source":"**Xây dựng vòng lặp tối ưu chính:**\n    \nSau khi đã thiết kế được các hàm tính toán *loss function, RMSE* và các hàm tối ưu *gradient descent* ta sẽ tiến hành xây dựng vòng lặp tối ưu để cập nhật các ma trận $\\mathbf{U}$ và $\\mathbf{I}$ và đánh giá hiệu quả của mỗi bước lặp thông qua giá trị của *loss function* và *RMSE*."},{"metadata":{"trusted":true,"_uuid":"89b371ae82e3e3b2a0b0060a26c3ebd12d0eff97"},"cell_type":"code","source":"def fit(Umatrix, Imatrix, Ytrain, Ytest, n_iter, log_iter):\n    for i in range(n_iter):\n        #update U and I\n        Umatrix = updateU(Umatrix)\n        Imatrix = updateI(Imatrix)\n        #calculate Y_hat\n        Y_hat = pred(Umatrix, Imatrix)\n        #calculate Y_hat_train by replace non ratings by 0\n        Y_pred_train = pred_train_test(Y_hat, R)\n        #calculate loss function\n        loss_value = loss(Ytrain, Y_pred_train)\n        #calculate Y_pred on test dataset\n        Y_pred_test = pred_train_test(Y_hat, R_test)\n        #calculate RMSE\n        rmse = RMSE(Ytest, Y_pred_test)\n        if i % log_iter == 0:\n            print('Iteration: {}; RMSE: {}; Loss value: {}'.format(i, rmse, loss_value))\n    return Y_hat, Y_pred_test   \n# Y_hat, Y_pred = fit(Umatrix = U, Imatrix = I, Ytrain = Y, Ytest = Y_test, n_iter = 100, log_iter = 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2346294dd2ab7dfa178a7754ad82b8d073953d2"},"cell_type":"markdown","source":"### 2.2.2. Xây dựng class MF\n\nDựa trên các hàm đã xử lý ở *(2.2.1)* ta sẽ thiết kế class MF có chức năng xử lý dữ liệu, fiting model, đánh giá kết quả model và đưa ra các recommend cho khách hàng về sản phẩm như sau:\n\n**Class Data xử lý dữ liệu:**"},{"metadata":{"trusted":true,"_uuid":"e2e7295c7fe6fd120dfaeb3c7b294b5256f5e38c"},"cell_type":"code","source":"class Data(object):\n    \"\"\"\n    This class used to manage data.\n    Two arguments:\n    dataset: pandas data frame include user_id, item_id and rating\n    split_rate: number train ratings/ total ratings\n    \"\"\"\n    def __init__(self, dataset, split_rate):\n        self.dataset = dataset\n        self.split_rate = split_rate\n        self.train, self.test = self.split_train_test(self.dataset)\n        self.n_users = np.max(self.train[:, 0] + 1) #plus one because index start from 0\n        self.n_items = np.max(self.train[:, 1] + 1)\n        self.Ytrain, self.Rtrain = self.utility_matrix(self.train)\n        self.Ytest , self.Rtest  = self.utility_matrix(self.test)\n        self.Ystad,  self.u_mean = self.standardize_Y(self.Ytrain)\n        self.n_ratings = self.train.shape[0]\n        \n    def split_train_test(self, dataset):\n        \"split train and test\"\n        gb = dataset.groupby('user_id')\n        ls = [gb.get_group(x) for x in gb.groups]\n        items = [x for x in gb.groups]\n        index_size = [{'i': i, 'index':gb.groups[i], 'size':len(gb.groups[i])} for i in items]\n        index_train = pd.Int64Index([])\n        index_test = pd.Int64Index([])\n        for x in index_size:\n            np.random.shuffle(x['index'].values)\n            le = int(x['size']*self.split_rate)\n            index_train = index_train.append(x['index'][:le])\n            index_test = index_test.append(x['index'][le:])\n        train = dataset.iloc[index_train].values\n        test = dataset.iloc[index_test].values\n        #minus id to 1 to index start from 0\n        train[:, 0] -= 1\n        train[:, 1] -= 1\n        test[:, 0] -= 1\n        test[:, 1] -= 1\n        return train, test\n    \n    def utility_matrix(self, data_mtx):\n        \"create Y and R matrix\"\n        Y = np.zeros(shape = (self.n_items, self.n_users))\n        Y = sparse.coo_matrix((data_mtx[:, 2], (data_mtx[:, 1], data_mtx[:, 0])), \\\n                              shape = (self.n_items, self.n_users), dtype = np.float).toarray()\n        R = sparse.coo_matrix((np.ones((data_mtx.shape[0],)), (data_mtx[:, 1], data_mtx[:, 0])), \\\n                              shape = (self.n_items, self.n_users)).toarray()\n        return Y, R\n    \n    def standardize_Y(self, Y):\n        \"standard data to mean ratings of each user = 0\"\n        sum_rating = Y.sum(axis = 0)\n        u_rating = np.count_nonzero(Y, axis = 0)\n        u_mean = sum_rating/u_rating\n        for n in range(self.n_users):\n            for m in range(self.n_items):\n                if Y[m, n] != 0:\n                    Y[m, n] -= u_mean[n]\n        return Y, u_mean","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e0c58d10623d4111494e33fd38fd28c8a213056"},"cell_type":"markdown","source":"**Class model xây dựng và đánh giá model:**"},{"metadata":{"trusted":true,"_uuid":"2072581668d18c4cbbb8f4a5939c30c9c1ddcee5"},"cell_type":"code","source":"class Model():\n    \"\"\"\n    This class manage update U and I matrix, predict and evaluate error\n    Four arguments:\n    data: instance from Data class which supplies the data for model\n    theta: learning rate\n    lamda: regularization parameter\n    K: number of latent factors\n    \"\"\"\n    def __init__(self, data, theta, lamda, K):\n        self.data = data\n        self.theta = theta\n        self.lamda = lamda\n        self.K = K\n        self.I = np.random.randn(data.n_items, K)\n        self.U = np.random.randn(K, data.n_users)\n        \n               \n    def updateU(self):\n        for n in range(self.data.n_users):\n        # Matrix items include all items is rated by user n\n            i_rated = np.where(self.data.Ystad[:, n] != 0)[0] #item's index rated by n\n            In = self.I[i_rated, :]\n            if In.shape[0] == 0:\n                self.U[:, n] = 0\n            else: \n                s = In.shape[0]\n                u_n = self.U[:, n]\n                y_n = self.data.Ystad[i_rated, n]\n                grad = -1/s * np.dot(In.T,(y_n-np.dot(In, u_n))) + self.lamda*u_n\n                self.U[:, n] -= self.theta*grad\n         \n    def updateI(self):\n        for m in range(self.data.n_items):\n        # Matrix users who rated into item m\n            i_rated = np.where(self.data.Ystad[m, :] != 0)[0] #user's index rated into m\n            Um = self.U[:, i_rated]\n            if Um.shape[1] == 0: \n                self.I[m, :] = 0\n            else:\n                s = Um.shape[1]\n                i_m = self.I[m, :]\n                y_m = self.data.Ystad[m, i_rated]\n                grad = -1/s * np.dot(y_m - np.dot(i_m, Um), Um.T) + self.lamda*i_m\n                self.I[m, :] -= self.theta*grad\n    \n    def pred(self, I, U):\n        #predict utility matrix base on formula Yhat = I.U\n        Yhat = np.dot(I, U)\n        #invert to forecast values by plus user's mean ratings\n        for n in range(self.data.n_users):\n            Yhat[:, n] += self.data.u_mean[n]\n        #convert to interger values because of rating is integer\n        Yhat = Yhat.astype(np.int32) \n        #replace values > 5 by 5 and values < 1 by 1\n        Yhat[Yhat > 5] = 5\n        Yhat[Yhat < 1] = 1\n        return Yhat\n\n    def pred_train_test(self, Yhat, R):\n        #replace values have not yet rated by 0 \n        Y_pred = Yhat.copy()\n        Y_pred[R == 0] = 0\n        return Y_pred\n    \n    def loss(self, Y, Yhat):\n        error = Y-Yhat\n        n_ratings = np.sum(Y != 0)\n        loss_value = 1/(2*n_ratings)*np.linalg.norm(error, 'fro')**2 +\\\n        self.lamda/2*(np.linalg.norm(self.I, 'fro')**2 + \\\n                 np.linalg.norm(self.U, 'fro')**2)\n        return loss_value\n    \n    def RMSE(self, Y, Yhat):\n        error = Y - Yhat\n        n_ratings = np.sum(Y != 0)\n        rmse = math.sqrt(np.linalg.norm(error, 'fro')**2/n_ratings)\n        return rmse","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ef8ce8bee68b51be161f573d766b5e0ce00c541"},"cell_type":"markdown","source":"**Xây dựng class MF quản lý model và data:**"},{"metadata":{"trusted":true,"_uuid":"aa9db1a1a40d0f0579b7b6d803539bef71336f42"},"cell_type":"code","source":"class MF():\n    \"\"\"\n    This class used to manage model and data\n    Two main arguments:\n    data: control the data\n    model: control the functions which execute model\n    \"\"\"\n    def __init__(self, data, model, n_iter, print_log_iter):\n        self.data = data\n        self.model = model\n        self.n_iter = n_iter\n        self.print_log_iter = print_log_iter\n        self.Y_pred_train = None\n        self.Y_pred_test = None\n        self.Yhat = None\n        \n    def fit(self):\n        for i in range(self.n_iter):\n            #update U and I\n            self.model.updateU()\n            self.model.updateI()\n            #calculate Y_hat\n            self.Yhat = self.model.pred(self.model.I, self.model.U)\n            #calculate Y_pred_train by replace non ratings by 0\n            self.Y_pred_train = self.model.pred_train_test(self.Yhat, self.data.Rtrain)\n            self.Y_pred_test  = self.model.pred_train_test(self.Yhat, self.data.Rtest)\n            if i % self.print_log_iter == 0:\n                print('Iteration: {}; RMSE: {}; Loss value: {}'.\\\n                      format(i, self.model.RMSE(self.data.Ytest, self.Y_pred_test),\\\n                             self.model.loss(self.data.Ytrain, self.Y_pred_train)))\n                \n    def recommend_for_user(self, user_id, k_neighbors):\n        recm = np.concatenate((np.arange(1, self.Y_pred_test.shape[0]+1).reshape(-1, 1), \\\n                               self.Y_pred_test[:, user_id - 1].reshape(-1, 1)), axis = 1)\n        recm.sort(axis = 0)\n        print('Top %s item_id recommended to user_id %s: %s'%\\\n              (k_neighbors, user_id, str(recm[-k_neighbors:, 0])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eebcd873f7d5a129fbc41b13b16452d3e60c4690"},"cell_type":"code","source":"data = Data(dataset = movie_length, split_rate = 2/3)\nmodel = Model(data = data, theta = 0.75, lamda = 0.1, K = 3)\nmf = MF(data = data, model = model, n_iter = 100, print_log_iter = 10)\nmf.fit()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c07c0e0f3d3ab59aac63473cf94a7fa1f44feacc"},"cell_type":"markdown","source":"Ta nhận thấy kết quả của hàm `loss function` và `RMSE` giảm dần sau các vòng lặp. Điều đó cho thấy thuật toán `gradient descent` đã phát huy tác dụng trong việc làm giảm sai số dự báo. Tuy nhiên đôi khi chúng ta sẽ gặp tình huống `loss function` và `RMSE` tăng dần. Có nhiều nguyên nhân dẫn tới điều này chẳng hạn như hệ số `learning rate` và `regularization` được thiết lập quá cao làm thuật toán nhảy ra khỏi cực trị toàn cục hoặc cũng có thể các `loss function` chỉ tăng tạm thời và giảm sau đó để nghiệm di chuyển qua điểm cực trị địa phương. Đối với khả năng 1 chúng ta cần điều chỉnh lại các hệ số `learning rate` và `regularization` để thuật toán di chuyển đúng hướng tới nghiệm tối ưu. Khả năng thứ 2 không quá nghiêm trọng bởi thuật toán có thể di chuyển tới nghiệm tối ưu ngay sau đó.\n\nRecommend 10 sản phẩm tiềm năng nhất cho user_id = 200:"},{"metadata":{"trusted":true,"_uuid":"064cc8f6c7fb91e083bbdeaf442a544dca5681d9"},"cell_type":"code","source":"mf.recommend_for_user(user_id = 200, k_neighbors = 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d48f9ee5938292ccbcf314dc4c75330743fe7e1"},"cell_type":"markdown","source":"### 2.2.3. Xây dựng hàm loss function với bias\n\nChúng ta nhận thấy rằng trong mô hình ước lượng luôn luôn tồn tại sai số không được giải thích bởi các nhân tố ẩn. Chẳng hạn như trong tình huống một user khá khó tính đã rating cao một bộ phim chỉ bởi vì cảm thấy những user khác cũng đã rating cao bộ phim đó hoặc chỉ ở user quan tâm đến một khía cạnh rất nhỏ của phim như có diễn viên yêu thích, câu nói yêu thích hay bài hát ấn tượng,... Và một điều hiển nhiên là những yếu tố này không thể đưa vào mô hình được. Do đó nếu ta đưa thêm một *nhân tố chệch* (bias) đối với mỗi một dự đoán của người dùng lên một bộ phim sẽ làm cho mô hình dự báo sát hơn. Nhân tố chệch có thể xuất phát từ cả 2 phía user hoặc item. Ta coi $b_m$ là nhân tố chệch xuất phát từ item thứ m đại diện cho những ảnh hưởng lên rating mà các features của item m không giải thích được và $d_n$ là nhân tố chệch xuất phát từ user thứ n đại diện cho những ảnh hưởng không giải thích được từ các features của user n. $\\mathbf{b} \\in \\mathbb{R}^{m \\times 1}$ và $\\mathbf{d} \\in \\mathbb{R}^{1 \\times n}$ lần lượt là các vector cột và dòng của nhân tố chệch xuất phát từ item và user. Khi đó hàm `loss function` sẽ có dạng:\n\n$$\\mathcal{L(\\mathbf{I}, \\mathbf{U}, \\mathbf{b}, \\mathbf{d})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{I}||_{F}^2+||\\mathbf{U}||_{F}^2+|\\mathbf{b}||^2+||\\mathbf{d}||^2)$$ \n\nNếu coi ma trận $\\mathbf{I}$ cố định bài toán tương đương với tối ưu hàm `loss function` có dạng:\n\n$$\\mathcal{L(\\mathbf{U},\\mathbf{b},\\mathbf{d})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{U}||_{F}^2+||\\mathbf{b}||^2+||\\mathbf{d}||^2)$$ \n\nXét tại user n giá trị của hàm loss function là:\n$$\\begin{eqnarray}\\mathcal{L}(\\mathbf{u_n}, \\mathbf{\\hat{b}_n}) & = & \\frac{1}{2s}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{u_n}||^2+||\\mathbf{\\hat{b}_n}||^2) \\\\\n& = & \\frac{1}{2s}||\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n)||_F^2+\\frac{\\lambda}{2}(||\\mathbf{u_n}||^2+||\\mathbf{\\hat{b}_n}||^2)\n\\end{eqnarray}$$ \n\nỞ đây ta sử dụng kí hiệu $\\mathbb{1}(d_n)$ để biểu diễn cho vector cột gồm toàn bộ các giá trị cột đều bằng nhau và bằng $d_n$\n\nĐạo hàm tại user n theo vector $\\mathbf{u_n}$:\n\n$$\\frac{\\partial \\mathcal{L}(\\mathbf{u_n}, \\mathbf{\\hat{b}_n})}{\\partial \\mathbf{u_n}} = \\frac{-1}{s} \\mathbf{\\hat{I}_n}^{T}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{u_n}\n$$ \n\nĐạo hàm tại user n theo vector $\\mathbf{\\hat{b}_n}$:\n\n$$\\frac{\\partial \\mathcal{L}(\\mathbf{u_n}, \\mathbf{\\hat{b}_n})}{\\partial \\mathbf{\\hat{b}_n}} = \\frac{-1}{s}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{\\hat{b}_n}\n$$ \n\nCông thức cập nhật *gradient descent* đối với:\n\n* vector $\\mathbf{u}_n$:\n\n$$\\mathbf{u_n}' = \\mathbf{u_n} - \\theta(-\\frac{1}{s}\\mathbf{\\hat{I}_n}^{T}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{u_n})$$\n\n* vector $\\mathbf{\\hat{b}_n}$:\n\n$$\\mathbf{\\hat{b}_n}' = \\mathbf{\\hat{b}_n} - \\theta(-\\frac{1}{s}(\\mathbf{\\hat{y}_n}-\\mathbf{\\hat{I}_n}.\\mathbf{u_n}-\\mathbf{\\hat{b}_n}-\\mathbb{1}(d_n))+\\lambda \\mathbf{\\hat{b}_n})$$\n\nTương tự cho trường hợp ma trận $\\mathbf{U}$ cố định:\n\n$$\\mathcal{L(\\mathbf{I},\\mathbf{b}, \\mathbf{d})} = \\frac{1}{2s}\\sum_{n = 1}^{N}\\sum_{m: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{I}||_{F}^2+||\\mathbf{b}||^2+||\\mathbf{d}||^2)$$ \n\nXét tại item m giá trị của hàm loss function là:\n$$\\begin{eqnarray}\\mathcal{L}(\\mathbf{i_m}, \\mathbf{\\hat{d}_m}) & = & \\frac{1}{2s}\\sum_{n: r_{mn} = 1} (y_{mn} - i_m . u_n - b_m - d_n)^2+\\frac{\\lambda}{2}(||\\mathbf{i_m}||^2+||\\mathbf{\\hat{d}_m}||^2) \\\\\n& = & \\frac{1}{2s}||\\mathbf{\\hat{y}_m}-\\mathbf{i_n}.\\mathbf{\\hat{U}_m}-\\mathbb{1}(b_m)-\\mathbf{\\hat{d}_m}||_F^2+\\frac{\\lambda}{2}(||\\mathbf{i_m}||^2+||\\mathbf{\\hat{d}_m}||^2)\n\\end{eqnarray}$$ \n\nCông thức cập nhật *gradient descent* đối với:\n\n* vector $\\mathbf{i}_m$:\n\n$$\\mathbf{i_m}' = \\mathbf{i_m} - \\theta(-\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_n}.\\mathbf{\\hat{U}_m}-\\mathbb{1}(b_m)-\\mathbf{\\hat{d}_m})\\mathbf{\\hat{U}_m}^T+\\lambda \\mathbf{i_m})$$\n\n* vector $\\mathbf{\\hat{d}_m}$:\n\n$$\\mathbf{\\hat{d}_m}' = \\mathbf{\\hat{d}_m} - \\theta(-\\frac{1}{s}(\\mathbf{\\hat{y}_m}-\\mathbf{i_n}.\\mathbf{\\hat{U}_m}-\\mathbb{1}(b_m)-\\mathbf{\\hat{d}_m})+\\lambda \\mathbf{\\hat{d}_m})$$\n\nNhư vậy trong trường hợp hàm số loss function có thêm nhân tố chệch ta cũng sử dụng phương trình `gradient descent` để cập nhật nghiệm tối ưu. Tuy nhiên ta sẽ có thêm cập nhật nghiệm cho các nhân tố chệch và giá trị hàm loss function sẽ chịu ảnh hưởng từ các nhân tố chệch. Bạn đọc quan tâm đến kết quả của thuật toán này có thể tham khảo [code](https://www.kaggle.com/phamdinhkhanh/matrix-factorization-movie-len-1m-with-bias?scriptVersionId=6262032) được tôi viết sẵn."},{"metadata":{"_uuid":"905d687cc80cf2e0fbd331207f50f67fbc5b0830"},"cell_type":"markdown","source":"## 2.3. Tài liệu tham khảo\n\n1. [Recommendation System - Stanford](http://infolab.stanford.edu/~ullman/mmds/ch9.pdf)\n2. [Collaborative Filtering Youtube - Stanford](https://www.youtube.com/watch?v=h9gpufJFF-0&t=436s)\n3. [Recommendation System - Machine Learning - Andrew Ng](https://www.youtube.com/watch?v=YW2b8La2ICo)\n4. [Matrix Factorization - Machine Learning Cơ Bản - Tiep Huu Vu](https://machinelearningcoban.com/2017/05/31/matrixfactorization/)\n5. [Matrix Factorization techniques for recommender systems](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf)\n6. [Learning from Incomplete Ratings Using Non-negative Matrix Factorization](https://archive.siam.org/meetings/sdm06/proceedings/059zhangs2.pdf)\n7. [Matrix Factorization - Albert Au Yeung](http://www.albertauyeung.com/post/python-matrix-factorization/)\n8. [Algorithms for Non-negative Matrix Factorization - Daniel D.Lee and H. Sebastian Seung](http://hebb.mit.edu/people/seung/papers/nmfconverge.pdf)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":1}