{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport  matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import  AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.gaussian_process import GaussianProcessClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Starting the analysis\n1. We start taking a look at the the data trying to see some insights ?\n2. At second we see wich model will perform with a better score ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parsing and showing data\n\ndf=pd.read_csv('../input/heart-disease-uci/heart.csv')\n\ny=df.pop('target')\n\ncorrelation=df.corr()\nplt.figure(figsize=(12,12))\nsns.heatmap(correlation,annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After reading the data let's see what are the number of individuals that are male and female in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#showing the gender in the data\nval=[]\nmal=0\nfem=0\n\nsex=df['sex']\nclasses=np.unique(sex)\n\nfor c in classes:\n    val.append(np.count_nonzero(sex==c))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"done this we are going to show the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Genders in the dataset')\nplt.bar(['female','male'],val,label='individuals')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This data brings another question: What are the distribution between males and females with heart diseases ? Does it follows the same distribution as in the dataset?"},{"metadata":{"trusted":true},"cell_type":"code","source":"for r in range(len(y)):\n    if y[r]==1:\n        if sex[r]==1:\n            mal+=1\n        else:\n            fem+=1\nplt.bar(['female','male'],[fem,mal])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are going to look at age. Does age has a relation with heart disease. if yes how much? if not why?"},{"metadata":{"trusted":true},"cell_type":"code","source":"age_with=[]\nage_without=[]\nfor r in range(len(y)):\n    if y[r]==1:\n        age_with.append(df['age'][r])\n    else:\n        age_without.append(df['age'][r])\n\nprint('The oldest person to have a heart disease has the age of '+str(max(age_with)))\nprint('The youngest person to have a heart disease has the age of '+str(min(age_with))) \n\nprint('The oldest person to do not have a heart disease has the age of '+str(max(age_without)))\nprint('The youngest person to do not have a heart disease has the age of '+str(min(age_without))) \nplt.figure(figsize=(12,6))\nplt.bar(['Avg age with heart disease','Avg age without heart disease'],[np.mean(age_with),np.mean(age_without)])\nplt.bar(['Median age with heart disease','Median age  without heart disease'],[np.median(age_with),np.median(age_without)])\nplt.xticks(rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now analysing the models \n\n* We are going to use Diferent regressor models including:\n    \n    * Gradient Boosting \n    * Multi Layer Perceptron\n    * Random Forest Classifier \n    * Naive Bayes\n    * KNeighboards\n    * AdaBoost \n    * Gaussian Process\n    * Random Forest "},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.values\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.20)\n\nmodel=GradientBoostingClassifier()\nmodel.fit(X_train,y_train)\n\nprint(str(model.score(X_test,y_test))+' Score of Gradient Boosting')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=AdaBoostClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of AdaBoost')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=MLPClassifier(activation='logistic',max_iter=10000)\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Multi Layer Perceptron')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=KNeighborsClassifier(n_neighbors=15)\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of KNeighbors')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=RandomForestClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Random Forest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Decision Tree')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=GaussianNB()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Naive Bayes using gaussian')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=GaussianProcessClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Gaussian Process')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now with Normalized data.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nX_train=preprocessing.normalize(X_train)\nX_test=preprocessing.normalize(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=GradientBoostingClassifier()\nmodel.fit(X_train,y_train)\n\nprint(str(model.score(X_test,y_test))+'Score of Gradient Boosting (Normalized)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=AdaBoostClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of AdaBoost(Normalized)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=MLPClassifier(activation='logistic',max_iter=10000)\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Multi Layer Perceptron(Normalized)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=KNeighborsClassifier(n_neighbors=15)\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+'Score of KNeighbors (Normalized)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=RandomForestClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+'Score of Random Forest (Normalized)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Decision Tree (Normalized)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=GaussianNB()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Naive Bayes using gaussian(Normalized)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=GaussianProcessClassifier()\nmodel.fit(X_train,y_train)\nprint(str(model.score(X_test,y_test))+' Score of Gaussian Process (Normalized)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions \n* The greatest results came from the following algorithms :\n    * Naive Bayes\n    * Random Forest \n    * MLP (Multi Layer Perceptron)\n \nAs we could see the average age of the individuals in the dataset is around 55.\nThe youngest person with the disease has 29 years old and the oldest 77\nWe can see that with this dataset a lot of assumptions can be made but more data is nedded to make better classification models. Maybe weight and height of the person could improve the models, such as other health personal information. A lot of work still can be made and this is an starter notebook feel free to leave a comment on mistakes or improvements that can be made. If you enjoyed the notebook please give it an UP and Thank you for your attention."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}