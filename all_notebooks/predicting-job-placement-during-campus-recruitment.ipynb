{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Introduction**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The objective of this project is to determine what variables can increase the chances of securing a job placement in a college recruitment event. You can find the dataset at the end of this project. Once again,we want to determine if grades have an effect on securing a job placement, we will be studying visualization and predictive model to classify if a given student can get a placement or not.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Contents","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. Performing explorartory data analysis.\n2. Visualising which factor influenced a candidate in getting placed.\n3. Performing data preprocessing.\n4. Performing model building.\n5. Performing feature scaling for maintaining imbalanced of our dataset.\n6. Applying different types of classification model for predicting best accuracy.\n7. Performing different types of method and curve for calculating and visualising accuracy of our different classification model.\n\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First we are going to import best trio...","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we are importing warnings so that we will not get any warning msg...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we are importing seaborn library for making graphs...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set(style=\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we are going to read our dataset which we are using in this project...","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/placement-data-full-class/Placement_data_full_class.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then printing first 5 lines of our dataset....","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EXPLORATORY DATA ANALYSIS**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Then we are chceking if there is any missing value in our dataset...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1 st graph is of salary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset.salary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we are going to fill misisng salaries with 0 as they represent students who have not got placement offer...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are doing gender based analysis...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = dataset['gender'],y = dataset['salary'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"ssc_p\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"hsc_p\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"degree_p\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=dataset[\"gender\"],y=dataset[\"mba_p\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1st observation = in this visualisation we saw that man are given more salary even though women are scoring better the man.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we are doing Placement based analysis...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"mba_p\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"degree_p\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"hsc_p\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=dataset[\"status\"],y=dataset[\"ssc_p\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2nd observation - student with higher percentage better acedmic result are able to perfrom better during placement compared to those who are not getting higher percentage...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we are doing Salary VS Academic rasult analysis...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=dataset[dataset.salary<600000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=dataset[\"ssc_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=dataset[\"hsc_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=dataset[\"degree_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=dataset[\"mba_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=dataset[\"etest_p\"],y=dataset[\"salary\"],kind=\"reg\",color=\"g\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3rd observation = student with average percent of 60 to 70 percent are getting salary around 250000 INR anually. Higher percentage does not neccesarily corresponds to higher salary package...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we are analysing that does type of specalisation affect placement or not...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rc(\"axes\",labelsize=13)\nplt.rc(\"xtick\",labelsize=13)\nplt.rc(\"ytick\",labelsize=13)\nsns.countplot(x=dataset[\"specialisation\"],hue=dataset[\"status\"],palette=\"muted\").set_title(\"Barplot showing placement among specalisation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From here we see that, it seems like business related specialisation tend to have a higher chance of getting a job placement...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we are analysing that work experience affect placement or not...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rc(\"axes\",labelsize=13)\nplt.rc(\"xtick\",labelsize=13)\nplt.rc(\"ytick\",labelsize=13)\nsns.countplot(x=dataset[\"workex\"],hue=dataset[\"status\"],palette=\"muted\").set_title(\"Barplot showing placement acocording work experiences\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From here we see that,It seems like work experience has no effect on job placement...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**DATA PRE-PROCESSING**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data= dataset.select_dtypes(include=[np.number])\ncategorical_data = dataset.select_dtypes(exclude=[np.number])\nprint (\"There are {} numeric and {} categorical columns in dataset\"\n.format(numeric_data.shape[1],categorical_data.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using label Encoder to change categorical data to numerical\nfrom sklearn.preprocessing import LabelEncoder\nle =  LabelEncoder()\n# implementing le on gender\nle.fit(dataset.gender.drop_duplicates())\ndataset.gender = le.transform(dataset.gender)\n# implementing le on ssc_b\nle.fit(dataset.ssc_b.drop_duplicates())\ndataset.ssc_b = le.transform(dataset.ssc_b)\n# implementing le on hsc_b\nle.fit(dataset.hsc_b.drop_duplicates())\ndataset.hsc_b = le.transform(dataset.hsc_b)\n# implementing le on hsc_b\nle.fit(dataset.hsc_b.drop_duplicates())\ndataset.hsc_b = le.transform(dataset.hsc_b)\n# implementing le on hsc_s\nle.fit(dataset.hsc_s.drop_duplicates())\ndataset.hsc_s = le.transform(dataset.hsc_s)\n# implementing le on degree_t\nle.fit(dataset.degree_t.drop_duplicates())\ndataset.degree_t = le.transform(dataset.degree_t)\n# implementing le on workex\nle.fit(dataset.workex.drop_duplicates())\ndataset.workex = le.transform(dataset.workex)\n# implementing le on specialisation\t\nle.fit(dataset.specialisation.drop_duplicates())\ndataset.specialisation = le.transform(dataset.specialisation)\n# implementing le on status\nle.fit(dataset.status.drop_duplicates())\ndataset.status = le.transform(dataset.status)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now dataset is converted into numerical value\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are making correlation matrix...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\ncorrMatrix=dataset.corr()\nsns.heatmap(corrMatrix,annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BUILDING MODEL**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will exclude salary column beacuse people that get placement will get a salary...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dataset.iloc[:, 1:13].values\ny = dataset.iloc[:, -2].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spliting dataset into training and testing data...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nDoing featrue scaling on dataset for handling imbalanced values...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek\nsmk = SMOTETomek(random_state = 42)\nx,y = smk.fit_sample(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are doing classification on our dataset...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"LOGISTIC REGRESSION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression (solver='liblinear', random_state=0)\nclassifier.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are doing prediction...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying confusion matrix for knowing true positive,true neagtive,false postive,false neagtive... and calculating accuracy of our classifiaction model...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are calculating precision,recall,accuracy,f1 scores...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\naccuracy = accuracy_score(y_test,y_pred)\nprecision =  precision_score(y_test,y_pred,average=\"weighted\")\nrecall = recall_score(y_test,y_pred,average=\"weighted\")\nf1 = f1_score(y_test,y_pred,average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall- {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are plotting curve for of precision_recall...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\ndisp = plot_precision_recall_curve(classifier,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are importing roc and auc curve for visualising accuracy...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are predicting probability of our x_test...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score2 = classifier.predict_proba(x_test)[:,1]\nfalse_positive_rate2, true_positive_rate2, threshold2 = roc_curve(y_test, y_score2)\nprint('roc_auc_score for Logistic Regression: ', roc_auc_score(y_test, y_score2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are plotting receiver operating characteristic curve(roc)...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Logistic regression')\nplt.plot(false_positive_rate2, true_positive_rate2)\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of model logistic regression is 0.87,roc_auc_score:0.90","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**K NEAREST NEIGHBORS**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifierr = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n                     weights='uniform')\nclassifierr.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifierr.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_precision_recall_curve(classifierr,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score1 = classifierr.predict_proba(x_test)[:,1]\nfalse_positive_rate1, true_positive_rate1, threshold2 = roc_curve(y_test, y_score1)\nprint('roc_auc_score for k_nearest_neibour: ', roc_auc_score(y_test, y_score1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - k_nearest_neibour')\nplt.plot(false_positive_rate1, true_positive_rate1)\n\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of model K nearest Neighbors is 0.84,roc_auc_score:0.90","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**SUPPORT VECTOR MACHINE**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier1 = SVC(kernel=\"linear\",random_state=0,C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='scale',\n    max_iter=-1, probability=True,shrinking=True, tol=0.001,\n    verbose=False)\nclassifier1.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier1.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_precision_recall_curve(classifier1,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score3 = classifier1.predict_proba(x_test)[:,1]\nfalse_positive_rate3, true_positive_rate3, threshold3 = roc_curve(y_test, y_score3)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Support vector machine')\nplt.plot(false_positive_rate3, true_positive_rate3)\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of model support vector machine is 0.84,roc_auc_score:0.92","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**KERNEL SVM**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier2 = SVC(kernel=\"rbf\",random_state=0,probability=True)\nclassifier2.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier2.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_precision_recall_curve(classifier2,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score4 = classifier2.predict_proba(x_test)[:,1]\nfalse_positive_rate4, true_positive_rate4, threshold4 = roc_curve(y_test, y_score4)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Kernel SVM')\nplt.plot(false_positive_rate4, true_positive_rate4)\n\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of model Kernel SVM is 0.74,roc_auc_score:0.89","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**NAIVE BAYES**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclassifier3 = GaussianNB()\nclassifier3.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier3.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_precision_recall_curve(classifier3,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score5 = classifier3.predict_proba(x_test)[:,1]\nfalse_positive_rate5, true_positive_rate5, threshold5 = roc_curve(y_test, y_score5)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - Naive Bayes')\nplt.plot(false_positive_rate5, true_positive_rate5)\n\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of model naive bayes machine is 0.76,roc_auc_score:0.89","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**DECISION TREE**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier4 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier4.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier4.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_precision_recall_curve(classifier4,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score6 = classifier4.predict_proba(x_test)[:,1]\nfalse_positive_rate6, true_positive_rate6, threshold6 = roc_curve(y_test, y_score6)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(1, figsize=(8,6))\nplt.title('Receiver Operating Characteristic - decision tree')\nplt.plot(false_positive_rate6, true_positive_rate6)\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of model decision tree is 0.83,roc_auc_score:0.83","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**RANDOM FOREST**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier5 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier5.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier5.predict(x_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred, average=\"weighted\")\nrecall = recall_score(y_test,y_pred, average=\"weighted\")\nf1 = f1_score(y_test,y_pred, average=\"weighted\")\nprint(\"Accuracy - {}\".format(accuracy))\nprint(\"Precision - {}\".format(precision))\nprint(\"Recall - {}\".format(recall))\nprint(\"f1 - {}\".format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_precision = average_precision_score(y_test,y_pred)\nprint(average_precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_precision_recall_curve(classifier5,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score7 = classifier5.predict_proba(x_test)[:,1]\nfalse_positive_rate7, true_positive_rate7, threshold6 = roc_curve(y_test, y_score7)\nprint('roc_auc_score for support vector machine ', roc_auc_score(y_test, y_score7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(1, figsize=(8,8))\nplt.title('Receiver Operating Characteristic - Random forest')\nplt.plot(false_positive_rate7, true_positive_rate7)\n\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of model random forest is 0.90,roc_auc_score:0.93","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For comparing true positive and false positive class...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [LogisticRegression(random_state=0),\n               KNeighborsClassifier(),\n               SVC(random_state=0,probability=True), \n               GaussianNB(), \n               DecisionTreeClassifier(random_state=0),\n               RandomForestClassifier(random_state=0)]\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\nfor cls in classifiers:\n    model = cls.fit(x_train, y_train)\n    yproba = model.predict_proba(x_test)[:,1]\n    \n    fpr, tpr, _ = roc_curve(y_test,  yproba)\n    auc = roc_auc_score(y_test, yproba)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\nresult_table.set_index('classifiers', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comparing ROC curve for all classifier that which model is best...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Here we are comparing roc  of all calssification model and we get to know here that RandomForestClassifier is best...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Finally conclusion is that it seems like academic results have limited effect on securing a job placement. Specialisation seems to play a much more important role.\nMales have a better chance of getting chosen for the job placement. Males also have a better chance of getting higher pay.\nAnd RandomForestClassifier is predicting best among all classification model with 90 percent.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}