{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from yellowbrick.regressor import PredictionError\nfrom yellowbrick.regressor import ResidualsPlot\nfrom yellowbrick.regressor import CooksDistance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_boston\nfrom sklearn.tree  import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.ensemble import GradientBoostingRegressor,ExtraTreesRegressor,AdaBoostRegressor,BaggingRegressor,RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 14,6\nplt.style.use('seaborn-talk')\n#plt.style.available","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston = pd.DataFrame(load_boston().data,columns=load_boston().feature_names)\nboston[\"DESCR\"] = load_boston().target\nboston.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.heatmap(boston.corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.scatterplot(x=\"LSTAT\",y=\"RM\",data=boston,hue=\"DESCR\",palette=\"coolwarm\")\nplt.title(\"LSTAT vs RM\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.countplot(x=\"RAD\",data=boston,palette=\"prism\")\nplt.title(\"Countplot for RAD\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nplt.subplot(2,2,1)\nsns.boxplot(y=\"DIS\",x=\"CHAS\",data=boston,palette=\"inferno\")\n\nplt.subplot(2,2,2)\nsns.boxplot(y=\"NOX\",x=\"CHAS\",data=boston,palette=\"inferno\")\n\nplt.subplot(2,2,(3,4))\nsns.scatterplot(x=\"DIS\",y=\"NOX\",data=boston,palette=\"inferno\",hue=\"CHAS\")\nplt.title(\"Scatterplot for DIS vs NOX\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.hist(boston[\"CRIM\"],alpha=0.5,density=True,bins=30)\nplt.title(\"Histogram for CRIM\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nplt.hist(boston.loc[boston[\"CHAS\"]==1][\"AGE\"],alpha=0.5,density=True,label=\"CHAS:1\")\nplt.hist(boston.loc[boston[\"CHAS\"]==0][\"AGE\"],alpha=0.6,density=True,label=\"CHAS:0\")\nplt.title(\"Histogram for AGE\")\nplt.legend(loc=\"best\")\n\nplt.subplot(1,2,2)\nplt.hist(boston.loc[boston[\"CHAS\"]==1][\"TAX\"],alpha=0.5,density=True,label=\"CHAS:1\")\nplt.hist(boston.loc[boston[\"CHAS\"]==0][\"TAX\"],alpha=0.6,density=True,label=\"CHAS:0\")\nplt.title(\"Histogram for TAX\")\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nplt.hist(boston.loc[boston[\"CHAS\"]==1][\"RM\"],alpha=0.5,density=True,label=\"CHAS:1\")\nplt.hist(boston.loc[boston[\"CHAS\"]==0][\"RM\"],alpha=0.6,density=True,label=\"CHAS:0\")\nplt.title(\"Histogram for RM\")\nplt.legend(loc=\"best\")\n\nplt.subplot(1,2,2)\nplt.hist(boston.loc[boston[\"CHAS\"]==1][\"PTRATIO\"],alpha=0.5,density=True,label=\"CHAS:1\")\nplt.hist(boston.loc[boston[\"CHAS\"]==0][\"PTRATIO\"],alpha=0.6,density=True,label=\"CHAS:0\")\nplt.title(\"Histogram for PTRATIO\")\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nplt.hist(boston.loc[boston[\"CHAS\"]==1][\"INDUS\"],alpha=0.5,density=True,label=\"CHAS:1\")\nplt.hist(boston.loc[boston[\"CHAS\"]==0][\"INDUS\"],alpha=0.6,density=True,label=\"CHAS:0\")\nplt.title(\"Histogram for INDUS\")\nplt.legend(loc=\"best\")\n\nplt.subplot(1,2,2)\nplt.hist(boston.loc[boston[\"CHAS\"]==1][\"B\"],alpha=0.5,density=True,label=\"CHAS:1\")\nplt.hist(boston.loc[boston[\"CHAS\"]==0][\"B\"],alpha=0.6,density=True,label=\"CHAS:0\")\nplt.title(\"Histogram for B\")\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = load_boston(return_X_y=True)\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.35,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualizer = CooksDistance()\nvisualizer.fit(X, y)\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train,y_train)\nprint(\"=====LinearRegression=====\")\nprint(\"Score Test:\",lr.score(X_test,y_test))\npred_lr = lr.predict(X_test)\n\nprint(\"MAE:\",mean_absolute_error(y_test,pred_lr))\nprint(\"MSE:\",mean_squared_error(y_test,pred_lr))\n\n\nvisualizer = PredictionError(lr)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();   \n\nvisualizer = ResidualsPlot(lr)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = MLPRegressor(hidden_layer_sizes=(100,),max_iter=800,activation=\"relu\",alpha=0.0192,random_state=42)\nnet.fit(X_train,y_train)\nprint(\"=====MLPRegressor=====\")\nprint(\"Score Test:\",net.score(X_test,y_test))\npred_net = net.predict(X_test)\nprint(\"MAE:\",mean_absolute_error(y_test,pred_net))\nprint(\"MSE:\",mean_squared_error(y_test,pred_net))\n\nvisualizer = PredictionError(net)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();  \n\nvisualizer = ResidualsPlot(net)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeRegressor()\ndt.fit(X_train,y_train)\nprint(\"=====DecisionTreeRegressor=====\")\nprint(\"Score Test:\",dt.score(X_test,y_test))\npred_dt = dt.predict(X_test)\nprint(\"MAE:\",mean_absolute_error(y_test,pred_dt))\nprint(\"MSE:\",mean_squared_error(y_test,pred_dt))\n\nvisualizer = PredictionError(dt)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();  \n\nvisualizer = ResidualsPlot(dt)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingRegressor()\ngb.fit(X_train,y_train)\nprint(\"=====GradientBoostingRegressor=====\")\nprint(\"Score Test:\",gb.score(X_test,y_test))\npred_gb = gb.predict(X_test)\nprint(\"MAE:\",mean_absolute_error(y_test,pred_gb))\nprint(\"MSE:\",mean_squared_error(y_test,pred_gb))\n\nvisualizer = PredictionError(gb)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show(); \n\nvisualizer = ResidualsPlot(gb)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"et = ExtraTreesRegressor(n_estimators=50)\net.fit(X_train,y_train)\nprint(\"=====ExtraTreesRegressor=====\")\nprint(\"Score Test:\",et.score(X_test,y_test))\npred_et = et.predict(X_test)\nprint(\"MAE:\",mean_absolute_error(y_test,pred_et))\nprint(\"MSE:\",mean_squared_error(y_test,pred_et))\n\nvisualizer = PredictionError(et)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show(); \n\nvisualizer = ResidualsPlot(et)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ab = AdaBoostRegressor()\nab.fit(X_train,y_train)\nprint(\"=====AdaBoostRegressor=====\")\nprint(\"Score Test:\",ab.score(X_test,y_test))\npred_ab = ab.predict(X_test)\nprint(\"MAE:\",mean_absolute_error(y_test,pred_ab))\nprint(\"MSE:\",mean_squared_error(y_test,pred_ab))\n\nvisualizer = PredictionError(ab)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show(); \n\nvisualizer = ResidualsPlot(ab)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"br = BaggingRegressor()\nbr.fit(X_train,y_train)\nprint(\"=====BaggingRegressor=====\")\nprint(\"Score Test:\",br.score(X_test,y_test))\npred_br = br.predict(X_test)\nprint(\"MAE:\",mean_absolute_error(y_test,pred_br))\nprint(\"MSE:\",mean_squared_error(y_test,pred_br))\n\nvisualizer = PredictionError(br)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show(); \n\nvisualizer = ResidualsPlot(br)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=100)\nrf.fit(X_train,y_train)\nprint(\"=====RandomForestRegressor=====\")\nprint(\"Score Test:\",rf.score(X_test,y_test))\npred_rf = rf.predict(X_test)\nprint(\"MAE:\",mean_absolute_error(y_test,pred_rf))\nprint(\"MSE:\",mean_squared_error(y_test,pred_rf))\n\nvisualizer = PredictionError(rf)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show(); \n\nvisualizer = ResidualsPlot(rf)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = xgboost.XGBRFRegressor().fit(X_train,y_train)\nprint(\"=====XGBRFRegressor=====\")\nprint(\"Score Test:\",xg.score(X_test,y_test))\npred_xg = xg.predict(X_test)\nprint(\"R2 :\",r2_score(y_test,pred_xg))\nprint(\"MAE:\",mean_absolute_error(y_test,pred_xg))\nprint(\"MSE:\",mean_squared_error(y_test,pred_xg))\n\nvisualizer = PredictionError(xg)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();     \n\nvisualizer = ResidualsPlot(xg)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = {\n    \"LinearRegression\":[mean_squared_error(y_test,pred_lr)],\n    \"MLPRegressor\":[mean_squared_error(y_test,pred_net)],\n    \"DecisionTreeRegressor\":[mean_squared_error(y_test,pred_dt)],\n    \"GradientBoostingRegressor\":[mean_squared_error(y_test,pred_gb)],\n    \"ExtraTreesRegressor\":[mean_squared_error(y_test,pred_et)],\n    \"AdaBoostRegressor\":[mean_squared_error(y_test,pred_ab)],\n    \"BaggingRegressor\":[mean_squared_error(y_test,pred_br)],\n    \"RandomForestRegressor\":[mean_squared_error(y_test,pred_rf)],\n    \"XGBRFRegressor\":[mean_squared_error(y_test,pred_xg)]\n      }\nmse = pd.DataFrame(mse).T\nmse.columns=[\"Value\"]\n\nplt.figure(figsize=(14,6))\nsns.barplot(y=mse.sort_values(\"Value\").index,x=\"Value\",palette=\"coolwarm\",data=mse.sort_values(\"Value\"))\nplt.title(\"MSE\")\nplt.draw()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}