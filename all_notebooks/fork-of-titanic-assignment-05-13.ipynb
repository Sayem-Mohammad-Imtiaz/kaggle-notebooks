{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SIT307 T1 2021\n# Assignment 3 - Machine Learning Challenge\n***Group 5*** - Rhys McMillan (218335964), Brenton Fleming (217603898), Neb Miletic (218489118), Sean Pain (218137385), Oliver Bennett (218143462), Muhammad Sibtain (219345654), Asim Arshad (219337467)  \n  \n***Data*** - Titanic: Machine Learning From Disaster (https://www.kaggle.com/c/titanic/data)","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n\n* [1. Preparation](#1)\n    * [1.1 Import Relevant Libraries](#1_1)\n    * [1.2 Load Data from File](#1_2)\n* [2. Data Overview](#2)\n    * [2.1 Data Dictionary](#2_1)\n    * [2.2 Data Preparation Summary](#2_2)\n        * [2.2.1 Feature Engineering](#2_2_1)\n        * [2.2.2 Data Cleaning](#2_2_2)\n        * [2.2.3 Dimensionality Reduction](#2_2_3)\n* [3. Machine Learning Experimentation](#3)\n    * [3.1 Support Vector Machine](#3_1)\n    * [3.2 Classifier 2](#3_2)\n    * [3.3 Classifier 3](#3_3)\n    * [3.4 Classifier 4](#3_4)\n    * [3.5 Classifier 5](#3_5)\n    * [3.6 Classifier 6](#3_6)\n    * [3.7 Classifier 7](#3_7)","metadata":{}},{"cell_type":"markdown","source":"# 1. Preparation <a class=\"anchor\" id=\"1\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Import Relevant Libraries <a class=\"anchor\" id=\"1_1\"></a>","metadata":{}},{"cell_type":"code","source":"# data analysis\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\n# visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Load Data from File <a class=\"anchor\" id=\"1_2\"></a>\nThe source data for this machine learning experimentation (titanic_train_clean.csv) has been previously cleaned and pruned during the data preparation and feature selection stages completed in assignment 2. The original source data can be found at https://www.kaggle.com/c/titanic/data.\n\nA summary of the data preparation and updated data dictionary can be found in [Data Overview](#2) below.","metadata":{}},{"cell_type":"code","source":"# load train.csv to pandas data frame, using 'PassengerId' as the index\ntitanic_df = pd.read_csv('../input/titanic-train-clean/titanic_train_clean.csv' , index_col='PassengerId')\n\n# Preview the data\ntitanic_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Overview <a class=\"anchor\" id=\"2\"></a>\nA brief overview of the dataset features.\n## 2.1 Data Dictionary <a class=\"anchor\" id=\"2_1\"></a>\nThe following data dictionary has been updated to reflect the cleaned dataset:\n<table>\n    <tr>\n        <th>Variable</th>\n        <th>Definition</th>\n        <th>Key</th>\n    </tr>\n    <tr>\n        <td>Survived</td>\n        <td>Did the passenger survive?</td>\n        <td>1 = Yes, 0 = No</td>\n    </tr>\n    <tr>\n        <td>Pclass</td>\n        <td>Ticket class</td>\n        <td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n    </tr>\n    <tr>\n        <td>sex</td>\n        <td>Sex</td>\n        <td>1 = Female, 0 = Male</td>\n    </tr>\n    <tr>\n        <td>Age</td>\n        <td>Age in years</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>Fare</td>\n        <td>Passenger fare</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>Embarked</td>\n        <td>Port of Embarkation</td>\n        <td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n    </tr>\n    <tr>\n        <td>Title</td>\n        <td>Title of the passenger (extracted from name)</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>UniqueTicket</td>\n        <td>Was the passenger ticket number unique?</td>\n        <td>1 = Yes, 0 = No</td>\n    </tr>\n    <tr>\n        <td>IsChild</td>\n        <td>Is the passenger a child (15 years or younger)?</td>\n        <td>1 = Yes, 0 = No</td>\n    </tr>\n</table>","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Data Preparation Summary <a class=\"anchor\" id=\"2_2\"></a>\nA brief summary of the data clearning, feature engineering and feature selection performed during assignment 2.","metadata":{}},{"cell_type":"markdown","source":"### 2.2.1 Feature Engineering <a class=\"anchor\" id=\"2_2_1\"></a>\nThree of the features contained in this dataset were engineered from the original dataset:\n* Title\n* UniqueTicket\n* IsChild","metadata":{}},{"cell_type":"markdown","source":"***Title*** - The original data included the passenger name which contained the title, first name and last name of the passenger. As each passenger name was unique the field offered very little information gain. The title of each passenger was extracted and then normalised to a defined list.","metadata":{}},{"cell_type":"markdown","source":"***UniqueTicket*** - The original data set included the ticket number of each passenger. This field contained a significant percentage of unique values and offered little information gain. A new field was calculated to represent if the passengers ticket is unique within the dataset, or a duplicate.","metadata":{}},{"cell_type":"markdown","source":"***IsChild*** - Analysis of survival across different age brackets found that children had a much higher survival rate than adults. A new feature was created to represent if the passenger is a child (i.e. 15 years or younger).","metadata":{}},{"cell_type":"markdown","source":"### 2.2.2 Data Cleaning <a class=\"anchor\" id=\"2_2_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"Two of the features in this dataset required cleaning:\n* Age\n* Embarked","metadata":{}},{"cell_type":"markdown","source":"***Age*** - Missing values were imputed using multivariate linear regression based on Title and Pclass.","metadata":{}},{"cell_type":"markdown","source":"***Embarked*** - As only 2 of 891 values were missing, these were simply filled using the most common embarked value.","metadata":{}},{"cell_type":"markdown","source":"### 2.2.3 Dimensionality Reduction <a class=\"anchor\" id=\"2_2_3\"></a>\nFive features were removed from the original data set as analysis determined they offered little or no information gain:\n* Name\n* SibSp (# of siblings or spouses also onboard)\n* Parch (# parents of children also onboard)\n* Ticket\n* Cabin","metadata":{}},{"cell_type":"markdown","source":"# 3. Machine Learning Experimentation <a class=\"anchor\" id=\"3\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Support Vector Machine <a class=\"anchor\" id=\"3_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Data Preparation**  \nThere are two issues to be addressed in our data set before we can use the SVM classifier:  \n* The SVM classifier does not support labelled input data. Out dataset contains 2 labelled features - Embarked and Title.  \n * Previous examination of the data (assignment 2) found embarked's correlation to be a derivative of Pclass and Sex. This feature will be dropped as Pclass and Sex are retained.  \n * Title will initially be remapped to numeric values. As this implies an ordinal relationship between the values, we should test the performance of the classifier using mapping vs dropping the feature to ensure we are not degrading our prediction.\n* As support vector machines are not scale invarient, we can improve the accuracy of our model by preprocessing the dataset SciKit Learn's StandardScaler.  \n(Ref: https://scikit-learn.org/stable/modules/svm.html#tips-on-practical-use)","metadata":{}},{"cell_type":"code","source":"# import libraries\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n\n# create pipeline using standardScaler and SVM classifier\nsvm_clf = make_pipeline(StandardScaler(), SVC())\n\n# create X and y\nX = titanic_df.drop(columns=['Survived', 'Embarked'])\ny = titanic_df.Survived\n\n# map title to numeric values\nX.Title = X.Title.map({'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Officer': 5, 'Royalty': 6})\n\n# split data in to training and testing subsets\nX_train , X_test , y_train, y_test = train_test_split(X, y, random_state=1)\n\n# fit the data to the model\nsvm_clf.fit(X_train, y_train)\n\n# predict our test data\ny_pred = svm_clf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evalulation**  \nPerformance of an SVM classifier is normally done using the classification rate or error rate. We will use SciLearn's accuracy_score to evaluate the basic performance of our model.","metadata":{}},{"cell_type":"code","source":"# import libraries\nfrom sklearn.metrics import accuracy_score\n\n# check the accuracy of our prediction\nprint('Accuracy: {0}%'.format((accuracy_score(y_pred, y_test)*100).round(2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Retest with Dropping Title**","metadata":{}},{"cell_type":"code","source":"# drop title from our X data sets\nX_train = X_train.drop(columns=['Title'])\nX_test = X_test.drop(columns=['Title'])\n\n# fit the data to the model\nsvm_clf.fit(X_train, y_train)\n\n# predict our test data\ny_pred = svm_clf.predict(X_test)\n\n# check the accuracy of our prediction\nprint('Accuracy: {0}%'.format((accuracy_score(y_pred, y_test)*100).round(2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dropping Title improves the accuracy of our SVM classifier.","metadata":{}},{"cell_type":"markdown","source":"**Further Evaluation**  \nWe can further evaluate the performance of our SVM classifier using SciLearn's classification_report to see the precision, recall and f1-score for our model.","metadata":{}},{"cell_type":"code","source":"# import libraries\nfrom sklearn.metrics import classification_report\n\n# generate classification report\nprint(classification_report(y_test, y_pred, target_names=['Died', 'Survived']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 <Classifier 2> <a class=\"anchor\" id=\"3_2\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create X and y\nXO = titanic_df.drop(columns=[\n    'Survived',                           \n    'Embarked',\n#        'Pclass',\n#     'Sex',\n#     'Age',\n#     'Fare',\n#     'Title',\n#     'UniqueTicket',\n#     'IsChild'\n])\nyo = titanic_df.Survived\n\n# map title to numeric values\nXO.Title = XO.Title.map({'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Officer': 5, 'Royalty': 6})\n\n# split data in to training and testing subsets\nXO_train , XO_test , yo_train, yo_test = train_test_split(XO, yo, random_state=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view data\n# yo_train\n# XO_train\n# XO_test\n# yo_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest = RandomForestClassifier(criterion='gini',\n    n_estimators=700,\n#     n_estimators=350,\n    min_samples_split=10, \n    min_samples_leaf=1, \n    max_features='auto', \n    oob_score=True, \n    random_state=1,\n    n_jobs=-1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest.fit(XO_train, yo_train)\nyo_pred = random_forest.predict(XO_test) \nresult = round(random_forest.score(XO_train, yo_train) * 100, 2) \nresult ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(yo_test, yo_pred, target_names=['Died', 'Survived']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the accuracy of our prediction\nprint('Accuracy: {0}%'.format((accuracy_score(yo_pred, yo_test)*100).round(2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\nlabels = ['Yes','No']\nplot_confusion_matrix(random_forest, XO, yo, display_labels=labels, normalize=None)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 <Classifier 3> <a class=\"anchor\" id=\"3_3\"></a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 <Classifier 4> <a class=\"anchor\" id=\"3_4\"></a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 <Classifier 5> <a class=\"anchor\" id=\"3_5\"></a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.6 <Classifier 6> <a class=\"anchor\" id=\"3_6\"></a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.7 <Classifier 7> <a class=\"anchor\" id=\"3_7\"></a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}