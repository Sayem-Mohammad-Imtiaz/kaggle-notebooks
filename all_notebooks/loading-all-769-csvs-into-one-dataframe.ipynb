{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python"}},"cells":[{"metadata":{"_uuid":"269b716ae7146c55f5c359879a14cce5fcb48621","_cell_guid":"a4ed825f-35ee-4b27-bee1-e7496437d06e","collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport os"},{"metadata":{"_uuid":"e5e3e37df7a2ce2362b49928da9e2da5644c1cf8","_cell_guid":"9042b508-5264-4b2d-a31d-2db5c2e3cf94"},"source":"I got a little overwhlemed with the number of CSV files in this dataset. This kernel is going to show you how to load all the CSV files into one dataframe. The tricky part is that the filenames are the stock tickers, so I will also addadding that as a new column.","cell_type":"markdown"},{"metadata":{"_kg_hide-output":true,"_cell_guid":"32ec16fe-e270-407e-bb99-65d32450d1a5","_uuid":"4f50f36ca944cab2163919b489320d36467125d9"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# See how many files there are in the directory. \n# \"!\" commands are called \"magic commands\" and allow you to use bash\nfile_dir = '../input/kospi'\n!ls $file_dir"},{"metadata":{"_uuid":"09c1aa57b63c3facc7353513ec8c38721ac6fa3e","_cell_guid":"7ef1ca34-71c9-4fd2-9d3d-11303fa8128f"},"source":"Holy crap there are a lot of files...","cell_type":"markdown"},{"metadata":{"_uuid":"28172d254a967ef6c11d0fc335c77352473fdba8","_cell_guid":"ec53c3d4-fa5f-4734-9366-3e96f3fa1cfb"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# Number of files we are dealing with\n!ls $file_dir | wc -l"},{"metadata":{"_uuid":"e3460d2e2ada453b8a1e4cb956943f69e341d8d9","_cell_guid":"f07a870d-a1ce-4182-a412-35891b28883c","collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"# Get a python list of csv files\nfiles = glob.glob(os.path.join(file_dir, \"*.csv\"))"},{"metadata":{"_uuid":"2696c0a14ebd5bd1f27e240964dac149a73d2803","_cell_guid":"8ccd2a79-e412-462b-ba51-9e6ad8b01ee9"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# Look at a few to see how we can merge them\ndf1 = pd.read_csv(files[0])\ndf2 = pd.read_csv(files[1])\ndf3 = pd.read_csv(files[2])\n\nprint(df1.head(), \"\\n\")\nprint(df2.head(), \"\\n\")\nprint(df3.head(), \"\\n\")"},{"metadata":{"_uuid":"8972a3e6a95b0c40eb88937cc89fa42391995ca2","_cell_guid":"82009f34-3759-417a-b424-3f33a65e50fb"},"source":"These files have the same columns so it seems reasonable to concatenate everything into one dataframe. However, I want to keep track of the file names because that's the only reference to the stock tickers. \n<br><BR>\n\n- First, create a list of dataframes with the filenames in a \"stock_ticker\" column \n- Then concatenate them all into one **big ass dataframe**","cell_type":"markdown"},{"metadata":{"_uuid":"92bd070096deb59127b191f96f779fddf192671b","_cell_guid":"23a96034-fc01-4daf-8605-0ea138f776d2","collapsed":true},"execution_count":null,"outputs":[],"cell_type":"code","source":"# Make a list of dataframes while adding a stick_ticker column\ndataframes = [pd.read_csv(file).assign(stock_ticker=os.path.basename(file).strip(\".csv\")) for file in files]\n# Concatenate all the dataframes into one\ndf = pd.concat(dataframes, ignore_index=True)"},{"metadata":{"_uuid":"da3a9c50a88f559861aa03bc5d0aa3e3d9319639","_cell_guid":"56d38ee7-c422-4e89-a4df-3b2d0bcf9edb"},"execution_count":null,"outputs":[],"cell_type":"code","source":"df.head()"},{"metadata":{"_uuid":"00b5f0461a96be32e6ff3ee85e9f945816671c04","_cell_guid":"09acbc08-f609-4b0f-93c9-cf51cf951a73"},"execution_count":null,"outputs":[],"cell_type":"code","source":"df.shape"}],"nbformat_minor":1,"nbformat":4}