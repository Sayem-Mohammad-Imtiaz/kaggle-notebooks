{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Science for Good - Text classification using PySpark ML\n"},{"metadata":{},"cell_type":"markdown","source":"This Notebook utilizes Machine Learning with <code>PySpark</code> to categorize disaster tweets. This is created for the [Kaggle competition](https://www.kaggle.com/c/nlp-getting-started)."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\nfrom pyspark.sql.functions import col, udf,regexp_replace,isnull\nfrom pyspark.sql.types import StringType,IntegerType\nfrom pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, GBTClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create a Spark session"},{"metadata":{"trusted":true},"cell_type":"code","source":"spark = SparkSession.builder.appName('nlp').getOrCreate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring Data Analysis\n### Load the data files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filepath = '/kaggle/input/nlp-getting-started'\nsdf_train = spark.read.csv(f'{filepath}/train.csv', header = True, inferSchema = True)\nsdf_test = spark.read.csv(f'{filepath}/test.csv', inferSchema=True, header=True)\n\nsdf_sample_submission = spark.read.csv(f'{filepath}/sample_submission.csv', \n                                       inferSchema=True, header=True)\nsdf_train.printSchema()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predictor variables:** id, keyword, location, text\n\n**Outcome variable:** target"},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at how the data looks.  \nPandas data frame is better than Spark DataFrame show() function."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\npd.DataFrame(sdf_train.take(5), columns=sdf_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Data Record Count:\",sdf_train.count())\nprint(\"Test Data Record Count:\",sdf_test.count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sdf_train.toPandas().groupby(['target']).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is well balanced."},{"metadata":{},"cell_type":"markdown","source":"## Data Pre-processing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_df = sdf_train.select(\"id\",\"text\",\"target\")\nml_df.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning the dataset\n#### Drop null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_df = ml_df.dropna()\nml_df.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing numbers from the tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_df = ml_df.withColumn(\"only_str\",regexp_replace(col('text'), '\\d+', ''))\nml_df.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Segregating the words from the tweet"},{"metadata":{"trusted":true},"cell_type":"code","source":"regex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")\nraw_words = regex_tokenizer.transform(ml_df)\nraw_words.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing the stop words from raw words"},{"metadata":{"trusted":true},"cell_type":"code","source":"remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\nwords_df = remover.transform(raw_words)\nwords_df.select(\"id\",\"words\",\"target\",\"filtered\").show(5, truncate=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create a features column from the words"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\nmodel = cv.fit(words_df)\ncountVectorizer_train = model.transform(words_df)\ncountVectorizer_train = countVectorizer_train.withColumn(\"label\",col('target'))\ncountVectorizer_train.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countVectorizer_train.select('text','words','filtered','features','target').show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Separate the Train and Validation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"(train, validate) = countVectorizer_train.randomSplit([0.8, 0.2],seed = 97435)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData = countVectorizer_train\n\n#cleaning and preparing the test data\ntestData = sdf_test.select(\"id\",\"text\")#.dropna()\ntestData = testData.withColumn(\"only_str\",regexp_replace(col('text'), '\\d+', ''))\nregex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")  #Extracting raw words\ntestData = regex_tokenizer.transform(testData)\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\") #Removing stop words\ntestData = remover.transform(testData)\ncv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\nmodel = cv.fit(testData)\ncountVectorizer_test = model.transform(testData)\ntestData = countVectorizer_test\ntestData.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Prediction Models\n## Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"label\", featuresCol=\"features\")\nnbModel = nb.fit(train)\nnb_predictions = nbModel.transform(validate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nbEval = BinaryClassificationEvaluator()\nprint('Test Area Under ROC', nbEval.evaluate(nb_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nnb_accuracy = evaluator.evaluate(nb_predictions)\nprint(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(featuresCol = 'features', labelCol = 'target', maxIter=10)\nlrModel = lr.fit(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can obtain the coefficients by using <code>LogisticRegressionModel</code>â€™s attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nbeta = np.sort(lrModel.coefficients)\nplt.plot(beta)\nplt.ylabel('Beta Coefficients')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Summarize the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainingSummary = lrModel.summary\nlrROC = trainingSummary.roc.toPandas()\n\nplt.plot(lrROC['FPR'],lrROC['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n\nprint('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision and recall"},{"metadata":{"trusted":true},"cell_type":"code","source":"pr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lrPreds = lrModel.transform(validate)\nlrPreds.select('id','prediction').show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate the Logistic Regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lrEval = BinaryClassificationEvaluator()\nprint('Test Area Under ROC', lrEval.evaluate(lrPreds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nlr_accuracy = evaluator.evaluate(lrPreds)\nprint(\"Accuracy of Logistic Regression is = %g\"% (lr_accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'target', maxDepth = 3)\ndtModel = dt.fit(train)\ndtPreds = dtModel.transform(validate)\ndtPreds.show(5)\n#dtPreds.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate the Decision Tree model\n\nOne simple decision tree performed poorly because it is too weak given the range of different features. The prediction accuracy of decision trees can be improved by Ensemble methods, such as Random Forest and Gradient-Boosted Tree."},{"metadata":{"trusted":true},"cell_type":"code","source":"dtEval = BinaryClassificationEvaluator()\ndtROC = dtEval.evaluate(dtPreds, {dtEval.metricName: \"areaUnderROC\"})\nprint(\"Test Area Under ROC: \" + str(dtROC))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\ndt_accuracy = evaluator.evaluate(dtPreds)\nprint(\"Accuracy of Decision Trees is = %g\"% (dt_accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make Predictions based on Decision Tree Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'target', maxDepth = 3)\ndtModel = dt.fit(trainData)\ndtPreds = dtModel.transform(testData)\ndtPreds.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtPreds.select('id','prediction').withColumnRenamed('prediction','target').toPandas().to_csv('dt_Pred.csv',index=False,header=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'target')\nrfModel = rf.fit(train)\nrfPreds = rfModel.transform(validate)\nrfPreds.select('id', 'rawPrediction', 'prediction', 'probability').show(10)"},{"metadata":{},"cell_type":"markdown","source":"### Evaluate the Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"rfEval = BinaryClassificationEvaluator()\nrfROC = rfEval.evaluate(rfPreds, {rfEval.metricName: \"areaUnderROC\"})\nprint(\"Test Area Under ROC: \" + str(rfROC))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nrf_accuracy = evaluator.evaluate(rfPreds)\nprint(\"Accuracy of Random Forests is = %g\"% (rf_accuracy))"},{"metadata":{},"cell_type":"markdown","source":"### Make Predictions using the Model"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\nrfModel = rf.fit(trainData)\nrfPreds = rfModel.transform(testData)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#rfPreds.select('id', 'prediction').withColumnRenamed('prediction','target').toPandas()#.to_csv('rf_Preds.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Classifier"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from pyspark.ml.classification import GBTClassifier\n\ngbt = GBTClassifier(maxIter=10)\ngbtModel = gbt.fit(train)\ngbtPreds = gbtModel.transform(validate)\ngbtPreds.show(5)"},{"metadata":{},"cell_type":"markdown","source":"### Evaluate the Gradient-Boosted Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"gbtEval = BinaryClassificationEvaluator()\ngbtROC = gbtEval.evaluate(gbtPreds, {gbtEval.metricName: \"areaUnderROC\"})\nprint(\"Test Area Under ROC: \" + str(gbtROC))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\ngb_accuracy = evaluator.evaluate(gbtPreds)\nprint(\"Accuracy of GBT is = %g\"% (gb_accuracy))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"gbt = GBTClassifier(maxIter=10)\ngbtModel = gbt.fit(trainData)\ngbtPreds = gbtModel.transform(testData)\ngbtPreds.select('id','prediction').show(5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#gbtPreds.select('id', 'prediction').withColumnRenamed('prediction','target').toPandas().to_csv('gbt_Preds.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thanks you for reading. I appreciate your time! I hope you find this useful.  \nIf you have any suggestions, please add them in the comments section or reach out to me on [LinkedIn.](https://www.linkedin.com/in/suraj-malpani/)**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}