{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport codecs, json\nimport tempfile\nimport requests\nimport base64\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our file is under /kaggle/input. In this case we are going to use an old version of a Kaggle public dataset that has all the English Premiership matches from the 2000-2001 season to March of the 2019-2020 season.\n\nWe are going to load this file into a panda dataframe and we will take a look at the first few rows of the file to see the content","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = \"/kaggle/input/epl-results-up-to-march-2020/EPLresults.csv\"\nmy_df = pd.read_csv(file_path)\n\nprint('The shape of our dataset is ', my_df.shape)\n\nmy_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Excellent, we have 7,386 rows, each one with 22 columns and we can see a few samples below.\n\nWe can see some of the columns are numeric and some are strings so let's print all the column types to see what types we have","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"my_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's plot a few of our data dimensions to get familiar with our dataset.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, chart = plt.subplots() \ndata = my_df['FTR'].value_counts() \n\npoints = data.index \nfrequency = data.values \n\nchart.bar(points, frequency) \n\nchart.set_title('Frequency of different results in the English Permiership (2001-2020) ') \nchart.set_xlabel('Result Type') \nchart.set_ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see home team wins are way more prevalent than away team wins or draws. This makes sense as the crowd plays an important role in soccer. OK, what else can we plot?\n\nHow about what team has played the most home games?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a figure and axis \nfig, ax = plt.subplots() \n\n# count the occurrence of each class \ndata = my_df['HomeTeam'].value_counts() \n# get x and y data \npoints = data.index \nfrequency = data.values \n# create bar chart \nax.bar(points, frequency) \nplt.setp(ax.get_xticklabels(), rotation=90)\n# set title and labels \nax.set_title('Number of home games for all the English Premiership teams, 2001-2020') \nax.set_xlabel('Home Teams')\nax.set_ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kind of hard to see but we can see the teams with the most home games are Everton, Chelsea, Arsenal,Tottenham, Man United & Liverpool. Are they more likely to win the league then? We'll see\n\nThere are other things we could plot but let's say that's it for now. We can move on to the next step.\n\nNow that the file is in dataframe we assign some columns to x and the label to y. In our case the label is the full time result (\"FTR\"). Let's make sure we can print a label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"For row 149 the teams playing are \" + str(my_df[\"HomeTeam\"][149]) + \" and \" + str(my_df[\"AwayTeam\"][149]) + \" and the label is \"  + str(my_df[\"FTR\"][149]) + \" and the day is \" + str(my_df[\"Date\"][149]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before assigning the features to X and y we need to convert strings and text to something else since you cannot input strings to a neural network\n\nWhat features to use? Well, a theory is we need the teams that are playing and their statistics throughout the match: assists, corners and so on. Date? For now we are going to use just the day ofthe week so we will start with the following features in x:\n\n* Day of the week when the match was played (i.e Saturday)\n* HomeTeam\n* AwayTeam\n* HTHG (Half Time Home Goals)\n* HTAG (Half Time Away Goals)\n* HTR (Half Time Result)\n* HS (Home Team Shots)\n* AS (Away Team Shots)\n* HC (Home Team Corners)\n* AC (Away Team Corners)\n* HF (Home Team Fouls)\n* AF (Away Team Fouls)\n* HY (Homw Team Yellow Cards)\n* AY (Away Team Yellow Cards)\n* HR (Home Team Red Cards)\n* AR (Away Team Red Cards)\n\nNow we need to convert the object columns to numbers. First we create a new dataframe with the object columns.\n\nWe also drop the referee column since we are not going to use it and then we print a few rows","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epl_df_objects = my_df.copy()\nepl_df_objects.drop('Referee', axis=1, inplace=True)\n\n\nepl_df_objects.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are going to see if there are any null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(epl_df_objects.isnull().values.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hooray! No null values so we don't have to fix our data. We can move on to the next step: fixing some of the features we want to keep.\n\nSince we only want the day the match was played we convert the date to day of the week in a new column and drop the original date column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting match date to epoch and day of the week\n\nepl_df_objects[\"matchDate\"] = pd.to_datetime(epl_df_objects[\"Date\"], infer_datetime_format=True)\nepl_df_objects['matchDay'] = epl_df_objects['matchDate'].dt.day_name()\n\nprint(epl_df_objects[\"matchDate\"][0])\nprint(epl_df_objects['matchDay'][149])\n\nepl_df_objects.drop('Date', axis=1, inplace=True)\nepl_df_objects.drop('matchDate', axis=1, inplace=True)\n\n\nepl_df_objects.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we convert all the object columns to numbers because a neural network does not accept text\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epl_df_objects = pd.get_dummies(epl_df_objects, columns=['HomeTeam'], prefix = ['HomeTeam'])\nepl_df_objects = pd.get_dummies(epl_df_objects, columns=['AwayTeam'], prefix = ['AwayTeam'])\nepl_df_objects = pd.get_dummies(epl_df_objects, columns=['HTR'], prefix = ['HTR'])\nepl_df_objects = pd.get_dummies(epl_df_objects, columns=['matchDay'], prefix = ['matchDay'])\n\nepl_df_objects.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before assigning features to X and the label to y we need to convert the label to numeric values. We also assign all the relevant features to an intermediate variable\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\n\n\nepl_df_objects['FTR']= label_encoder.fit_transform(epl_df_objects['FTR']) \n  \nprint('Unique values for our label are: ', epl_df_objects['FTR'].unique())\nprint('if the home team wins the label is ', epl_df_objects['FTR'][0])\nprint('if the away team wins the label is ', epl_df_objects['FTR'][2])\nprint('if there is a tie the label is ', epl_df_objects['FTR'][3])\n\nlabel = epl_df_objects['FTR']\nprint('the result for the match in row 149 is ', label[149])\n\nprint(epl_df_objects.iloc[:,3:113])\n\nfeatures = epl_df_objects.iloc[:,3:113]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can create X and y and divide the dataset in a training set and a test set. We will use the test set to check and see if we are overfitting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny=np.ravel(label)\nX = features\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n\nprint(\"The shape of X_train is \" + str(X_train.shape))\nprint(\"The size of y_train is \" + str(y_train.shape))\nprint(\"The size of X_test set is \" + str(X_test.shape))\nprint(\"The size of y_test is \" + str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's print a few rows of y_train to make sure they are one hot-encoded","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#one hot-encoding y_train and y_test\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=3)\n\nprint(\"The size of y_train is \" + str(y_train.shape))\nprint(\"The size of y_test is \" + str(y_test.shape))\n\nprint(y_train[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now create our models. We will start with a neural network using tensorflow and keras.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n      tf.keras.layers.Dense(330, input_dim=110, activation='relu'), \n      tf.keras.layers.Dense(10, input_dim=330, activation='relu'),                               \n      tf.keras.layers.Dense(3,activation='softmax')\n])\n\nmodel.summary()\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model is now ready to be fitted.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=65)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before evaluating our model let's plot our loss and accuracy to see how they changed while the model was trained.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy history\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\n#loss history\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great accuracy, perhaps too good? Could we be overfitting to our training set. Now we can evaluate our model on the test set to see if that is the case.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nscore = model.evaluate(X_test, y_test, verbose=1)\n\nprint(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we suspected we are overfitting to the training set. \n\nNow let's try to make a prediction with data from a  premiership match from this current season:\n\nArsenal at home vs Norwich on Wednesday 07/01/2020","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Xnew = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\nprint('the shape of our input data is ', Xnew.shape)\n\n # make a prediction\nynew = np.argmax(model.predict(Xnew), axis=-1)\n# show the inputs and predicted outputs\nprint(\"X = %s \" % Xnew)\nprint(\"Prediction = %s\" % ynew[0])\n\nif ynew[0] == 2:\n  print(\"Home team is going to win\")\nelif ynew[0] == 0:\n  print(\"Away team is going to win\")\nelse:\n  print(\"It is going to be a draw\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's try to serve the model as an api so people can call it and get predictions for the games they want to know about.\n\nWe will use tensorflow serving to create our api\n\nFirst we save our model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_DIR = tempfile.gettempdir()\n\nversion = 1\n\nexport_path = os.path.join(MODEL_DIR, str(version))\n\nif os.path.isdir(export_path):\n    print('\\nAlready saved a model, cleaning up\\n')\n    !rm -r {export_path}\n\nmodel.save(export_path, save_format=\"tf\")\n\nprint('\\nexport_path = {}'.format(export_path))\n!ls -l {export_path}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we download the tensorflow model server code","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\ncurl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n!apt update","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we install tensorflow model server","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt-get install tensorflow-model-server","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can run our api server.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ[\"MODEL_DIR\"] = MODEL_DIR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash --bg \nnohup tensorflow_model_server \\\n  --rest_api_port=8501 \\\n  --model_name=epl_predictions \\\n  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can create the a json object to send as request to the api. We are going to send all the remaining Arsenal games and see what are the predictions so we can finally figure out if Arsenal is going to reach the Champions League.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"entry = np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1], \n                  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0],\n                  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0], \n                  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0],\n                  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],\n                  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0],\n                  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0],\n                  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0]\n                ])\n                  \nprint(type(entry))\nprint(entry.shape)\n\nthe_list = entry.tolist()\nprint(type(the_list))\n\n\ndata = json.dumps({\"signature_name\": \"serving_default\", \"instances\": the_list})\nprint('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have our object we can send it to the api and we can receive the prediction from our model\n\nSince we sent 8 games we should receive back an array of 8 x 3 shape. We print the shape to be sure. We then We then print the index of the highest probability to see what are our results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q requests\n\n\nheaders = {\"content-type\": \"application/json\"}\njson_response = requests.post('http://localhost:8501/v1/models/epl_predictions:predict', data=data, headers=headers)\n\nresponse = json.loads(json_response.text)\npredictions = response['predictions']\n\nprint(json_response)\nprint(json_response.text)\nprint(response['predictions'])\n\nmy_predictions = np.array(predictions)\nprint(\"The predictions are: \",np.argmax(my_predictions,axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK, we got all our results back. The model says that for the 8 games we sent the home team is going to win 4, the away team is going to win 1 and the rest are draws.\n\nDo we believe it? Kinda, usually, a home team has the advantage of the crowd but during in this Covid-19 era there is no crowd anymore. Our model doesn't know that though so that's a good feature to add for a future iteration of the model.\n\nFor now let's assume we believe it. If this is the case then we have the following record for Arsenal:\n\nBefore playing Norwich (the first of the 8 games we sent to our api) Arsenal had 43 points. 43 + 6 points (2 wins) + 2 points (2 times) = 51 so, according to our model, the Gunners will end the season with 51 points.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}