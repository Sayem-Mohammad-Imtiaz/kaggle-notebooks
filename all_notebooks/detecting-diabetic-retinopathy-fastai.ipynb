{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"## Introduction\n* In this kernel we use a pretrained ResNet34 model to train the retina images.\n* **The main purpose of this kernel is to:**\n    * **Show how to use fastai library correctly to train models in Kaggle kernels, save models, plots and also create an export pickle file. Many starters find it cofusing to use Fastai library in Kaggle kernels and how to save the models and download them correctly. I hope this kernel helps.**\n    * **To create a baseline for getting started, further this can be extended.**\n    * **How to PyTorch pretrained models without turning the internet on.**\n\n    \n<h3 style=\"color:green\">If you find this kernel helpful,then please upvote.</h3>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from fastai.vision import *\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is where we will copy our pretrained models\nos.makedirs('/root/.cache/torch/checkpoints')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/resnet34/resnet34.pth /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to save the models\nmodel_path = 'models'\n# to save the plots\nplot_path = 'plots'\n\nif not os.path.exists(model_path):\n    os.makedirs(model_path)\n    os.makedirs(os.path.join(model_path, plot_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nSeverity Levels\n\n0 - 'No_DR',\n1 - 'Mild',\n2 - 'Moderate',\n3 - 'Severe',\n4 - 'Proliferate_DR'\n'''\n\nclasses = ['No_DR', 'Mild', 'Moderate', 'Severe', 'Proliferate_DR']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/diabetic-retinopathy-2015-data-colored-resized/colored_images/colored_images/')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nRemove the images that we cannot open. \nExecute this only once per kernel run.\n'''\nfor c in classes:\n    print(c)\n    verify_images(path/c, delete=True, max_size=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train='.', valid_pct=0.2, \n                                  ds_tfms=get_transforms(), size=224, \n                                  num_workers=4, bs=32).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(10, 7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet34, \n                    metrics=error_rate, \n                    model_dir='/kaggle/working/models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()\nplt.savefig('models/plots/loss.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('colored_stage1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.recorder.plot()\nplt.savefig('models/plots/learning_rate.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.fit_one_cycle(3, max_lr=slice(1e-5, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.save('colored_stage2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.load('colored_stage2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"interp.plot_confusion_matrix()\nplt.savefig('models/plots/interp.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}