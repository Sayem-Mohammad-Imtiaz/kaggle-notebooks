{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom pprint import pprint\nimport re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndf = pd.read_csv('/kaggle/input/sentenced-to-death-last-words/deathrow_text.csv')\nprint(df.columns)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CLEANING THE DATAFRAME\n#drop unnecessary columns\ndf1 = df.drop(columns=['Unnamed: 0','inmate_info_link','lastwords_info_link'])\n\n#fill empty rows in lastwords with word blank\ndf1['lastwords'] = df1['lastwords'].fillna('blank')\n\n#clean race column by removing extra spaces\ndf1['race'] = df['race'].str.replace(' ','')\n\n#create a new column for category and populate it as \"Not Blank\" by default\ndf1['category'] = 'Statement Given'\n\n#In column category if no statement given, mark them as blank. For rest, mark as non-blank\n#source: https://kanoki.org/2019/07/17/pandas-how-to-replace-values-based-on-conditions/\ndf1['category'] = np.where((df1.lastwords == 'No statement given.'), \"No Statement\", df1.category )\ndf1['category'] = np.where((df1.lastwords == 'blank'), \"No Statement\", df1.category)\ndf1['category'] = np.where((df1.lastwords == 'This inmate declined to make a last statement.'), \"No Statement\", df1.category)\n\n#frequency of words\nfreq = pd.DataFrame(columns=[\"Word\",\"Freq\"])\nfreq = pd.Series(' '.join(df1['lastwords']).split()).value_counts()[:]\nfreq = pd.Series.to_frame(freq)\nprint(freq)\nfreq.to_csv('word_frequency.csv')\n\n#Based on word frequency, we will need to remove common words to see a meaningful output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEXT CLEANING\n#Convert to lowercase\ndef Remove_uppercase(df, column_name):\n    df[column_name+'_lower'] = df[column_name].str.lower()\n    return df\n#Remove special characters\ndef Remove_special_characters(df, column_name):\n    df[column_name+'_nospecialchar'] = df[column_name].map(str).map(lambda x: re.sub(r'\\W+', ' ', x))\n    return  df\n\n#Remove commonly occuring words + specific words that may not be generic enough\n#source: adding custom stop words: https://stackoverflow.com/questions/5511708/adding-words-to-nltk-stoplist\ndef Remove_commonwords(df, column_name):\n    stop = nltk.corpus.stopwords.words('english')\n    newStopWords = ['irene', 'okay', 'know']\n    stop.extend(newStopWords)\n    df[column_name+'_NoCommonWords'] = df[column_name].apply(lambda x: \" \".join([word for word in x.split() if word not in stop]))\n    return df\n\n\nRemove_special_characters(df1, 'lastwords')\nRemove_uppercase(df1,'lastwords_nospecialchar')\nRemove_commonwords(df1,'lastwords_nospecialchar_lower')\nprint(df1.columns)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create wordcloud on lastwords. Remove rows where \"statement not given\"\ntemp = df1[df1['category'] != 'No Statement']\nwordcloud2 = WordCloud().generate(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']))\nplt.imshow(wordcloud2)\nplt.axis(\"off\")\nplt.show()\n\n#Top 5 words\nfreq = pd.DataFrame(columns=[\"Word\",\"Freq\"])\nfreq = pd.Series(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']).split()).value_counts()[:5]\nfreq = pd.Series.to_frame(freq)\nprint(freq)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create wordcloud on lastwords. Remove rows where \"statement not given\" and race = Black\ntemp = df1[df1['category'] != 'No Statement']\ntemp = df1[df1['race'] == 'Black']\n\nwordcloud2 = WordCloud().generate(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']))\nplt.imshow(wordcloud2)\nplt.axis(\"off\")\nplt.show()\n\n#Top 5 words\nfreq = pd.DataFrame(columns=[\"Word\",\"Freq\"])\nfreq = pd.Series(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']).split()).value_counts()[:5]\nfreq = pd.Series.to_frame(freq)\nprint(freq)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create wordcloud on lastwords. Remove rows where \"statement not given\" and race = Black\ntemp = df1[df1['category'] != 'No Statement']\ntemp = df1[df1['race'] == 'White']\n\nwordcloud2 = WordCloud().generate(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']))\nplt.imshow(wordcloud2)\nplt.axis(\"off\")\nplt.show()\n\n#Top 5 words\nfreq = pd.DataFrame(columns=[\"Word\",\"Freq\"])\nfreq = pd.Series(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']).split()).value_counts()[:5]\nfreq = pd.Series.to_frame(freq)\nprint(freq)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create wordcloud on lastwords. Remove rows where \"statement not given\" and race = Black\ntemp = df1[df1['category'] != 'No Statement']\ntemp = df1[df1['race'] == 'Hispanic']\n\nwordcloud2 = WordCloud().generate(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']))\nplt.imshow(wordcloud2)\nplt.axis(\"off\")\nplt.show()\n\n#Top 5 words\nfreq = pd.DataFrame(columns=[\"Word\",\"Freq\"])\nfreq = pd.Series(' '.join(temp['lastwords_nospecialchar_lower_NoCommonWords']).split()).value_counts()[:5]\nfreq = pd.Series.to_frame(freq)\nprint(freq)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#No statements by race\n#source: https://stackoverflow.com/questions/41119623/pandas-pivot-table-sort-values-by-columns\ntemp=pd.pivot_table(df1, index=['race'], columns= ['category'], values=['id'], aggfunc='count' )\ntemp = temp.reindex(temp['id'].sort_values(by='Statement Given', ascending=False).index)\nprint(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#descriptive stats by age\n#source: https://pbpython.com/pandas-qcut-cut.html\nlabels = ['1_21 to 30', '2_31 to 40', '3_41 to 50', '4_51 to 60', '5_61 to 70', '6_71 and more' ]\nbins = [0,30, 40,50,60,70,100]\ndf1['age_bins'] = pd.cut(df1['age'], bins=bins, labels=labels)\n\n#Pivot by age bins and statement. Ignoring race = Other as number is very low. Showing percentage of rows\ntemp = pd.crosstab(df1.age_bins, df1.category, values=df1.id, aggfunc = sum, normalize='index')\nprint(\"View by age bins Vs Statement given/Not Given \\n\")\nprint(temp)\nprint('\\n')\n\n\n#Pivot by age bins, race and statement. Ignoring race = Other as number is very low. Showing percentage of rows\ntemp = pd.crosstab([df1.age_bins, df1.race], df1.category, values=df1.id, aggfunc = sum, normalize='index')\nprint(\"View by age bins, race Vs Statement given/Not given \\n\")\nprint(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}