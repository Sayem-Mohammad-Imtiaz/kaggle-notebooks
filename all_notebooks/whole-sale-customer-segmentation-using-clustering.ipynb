{"cells":[{"metadata":{},"cell_type":"markdown","source":"# INTRODUCTION"},{"metadata":{},"cell_type":"markdown","source":"The data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units on diverse product categories.\n\n### Attribute Information:\n- 1)\tFRESH: annual spending (m.u.) on fresh products (Continuous); \n- 2)\tMILK: annual spending (m.u.) on milk products (Continuous); \n- 3)\tGROCERY: annual spending (m.u.)on grocery products (Continuous); \n- 4)\tFROZEN: annual spending (m.u.)on frozen products (Continuous) \n- 5)\tDETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous) \n- 6)\tDELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous); \n- 7)\tCHANNEL: customers Channel - Horeca (Hotel/Restaurant/Cafe) or Retail channel (Nominal) \n- 8)\tREGION: customers Region - Lisbon, Oporto or Other (Nominal) \n\n### Region\tFrequency \nLisbon\t77 \nOporto\t47 \nOther Region\t316 \nTotal\t440 \n\n### Channel\tFrequency \nHoreca\t298 \nRetail\t142 \nTotal\t440 \n\nOur project goal is to use various clustering techniques to segment customers. Clustering is an unsupervised learning algorithm that tries to cluster data based on their similarity. Thus, there is no outcome to be predicted, and the algorithm just tries to find patterns in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing required numerical and data manipulation libraries\nimport numpy as np \nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#plotting libraries\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/Wholesale customers data.csv\")\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis(EDA)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Descriptive Statastics of our Data:')\ndata.describe().T","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Showing Meta Data :')\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Checking for missing values\npd.isnull(data).sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.Region.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Channel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Now,lets convert the channel and Region to categorical variable for only EDA purpose \nmapping channels as 1:Horeca 2:Retail and \nalso regions 1:lisbon 2:oporto 3:other"},{"metadata":{},"cell_type":"markdown","source":"### Univarient Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Channel'] = dataset['Channel'].map({1:'Horeca', 2:'Retail'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Region'].replace([1,2,3],['Lisbon','Oporto','other'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def continous_data(i):\n    if dataset[i].dtype!='object':\n        print('--'*60)\n        sns.boxplot(dataset[i])\n        plt.title(\"Boxplot of \"+str(i))\n        plt.show()\n        plt.title(\"histogram of \"+str(i))        \n        dataset[i].plot.hist(bins = 20)\n        plt.show()\n        plt.clf()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.set() #Sets the default seaborn style\nj=['Fresh','Milk','Grocery','Frozen','Detergents_Paper','Delicassen']\nfor k in j:\n    continous_data(i=k)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the data using the natural logarithm\nlog_data = np.log(dataset[['Fresh','Milk','Grocery','Frozen','Detergents_Paper','Delicassen']].copy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_data(i):\n    dataset[i].value_counts().plot(kind='bar')\n\nj_1 = ['Channel','Region']\n\nfor k in j_1:\n    categorical_data(i=k)\n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Correlation Heat map of the data')\nplt.figure(figsize=(10,6))\nsns.heatmap(dataset.corr(),annot=True,fmt='.2f',vmin=-1,vmax=1,cmap='Spectral')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatterplot(i,j):\n    sns.regplot(data=log_data,x=i,y=j)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatterplot(i='Milk',j='Grocery')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatterplot(i='Milk',j='Detergents_Paper')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatterplot(i='Detergents_Paper',j='Grocery')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def categorical_multi(i,j):\n    pd.crosstab(dataset[i],dataset[j]).plot(kind='bar')\n    plt.show()\n    print(pd.crosstab(dataset[i],dataset[j]))\n\ncategorical_multi(i='Channel',j='Region')    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treatment of Outliers"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"list(log_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing the outliers with their Inner fences\nfor k in list(log_data.columns):\n    IQR = np.percentile(log_data[k],75) - np.percentile(log_data[k],25)\n    \n    Outlier_top = np.percentile(log_data[k],75) + 1.5*IQR\n    Outlier_bottom = np.percentile(log_data[k],25) - 1.5*IQR\n    \n    log_data[k] = np.where(log_data[k] > Outlier_top,Outlier_top,log_data[k])\n    log_data[k] = np.where(log_data[k] < Outlier_bottom,Outlier_bottom,log_data[k])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def continous_data(i):\n    if log_data[i].dtype!='object':\n        print('--'*60)\n        sns.boxplot(log_data[i])\n        plt.title(\"Boxplot of \"+str(i))\n        plt.show()\n        plt.title(\"histogram of \"+str(i))\n        log_data[i].plot.kde()\n        plt.show()\n        plt.clf()\n\nfor k in j:\n    continous_data(i=k)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(log_data,diag_kind = 'kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset1 = log_data.copy()\nlist(dataset1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## replacing with median to treat the outliers\nfor k in list(dataset1.columns):\n    IQR=np.percentile(dataset1[k],75) - np.percentile(dataset1[k],25)\n    \n    Outlier_top=np.percentile(dataset1[k],75)+1.5*IQR\n    Outlier_bottom=np.percentile(dataset1[k],25)-1.5*IQR\n    \n    dataset1[k]=np.where(dataset1[k] > Outlier_top,np.percentile(dataset1[k],50),dataset1[k])\n    dataset1[k]=np.where(dataset1[k] < Outlier_bottom,np.percentile(dataset1[k],50),dataset1[k])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(dataset1,diag_kind = 'kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating dummies for categorical varibles"},{"metadata":{"trusted":true},"cell_type":"code","source":"df  =  pd.concat([dataset[['Channel','Region']],log_data],axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df,columns=['Channel','Region'],drop_first=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Scaling"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndf_std = scaler.fit_transform(df)\ndf_std = pd.DataFrame(df_std,columns=df.columns)\ndf_std.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import pdist,squareform\nfrom scipy.cluster.hierarchy import linkage,dendrogram,cut_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eu_d = pdist(df_std,metric='euclidean')\nclus = linkage(eu_d,method='average')\nnames = np.arange(0,df_std.shape[0]).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[14,8])\ndendrogram(clus,labels=names)\nplt.xlabel('hclust')\nplt.ylabel('distance')\nplt.title('cluster dendogram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_hier = data.copy()\ndata_hier.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_hier['clusters'] = cut_tree(clus,6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clust_profile = data_hier.groupby(['clusters'],as_index=False).mean()\nclust_profile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kmeans Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_std.copy()\n\nfrom sklearn.cluster import KMeans\ncluster_range = range(1,20)\ncluster_wss=[] \nfor cluster in cluster_range:\n    model = KMeans(cluster)\n    model.fit(X)\n    cluster_wss.append(model.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PLotting Elbow curve for finding Optimal K value\nplt.figure(figsize=[10,6])\nplt.title('WSS curve for finding Optimul K value')\nplt.xlabel('No. of clusters')\nplt.ylabel('Inertia or WSS')\nplt.plot(list(cluster_range),cluster_wss,marker='o')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clustering Using K-means with K=6"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nmodel = KMeans(n_clusters=6,random_state=0)\nmodel.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_final = data.copy()\ndataset_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_final['clusters']=model.predict(X)\ndataset_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cluster profiles\nclust_prof = dataset_final.groupby(['clusters'],as_index=False).mean()\nclust_prof","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA for getting the first 2 Principle components"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca2 = PCA(n_components=2)\npc = pca2.fit_transform(df_std)\npc_df = pd.DataFrame(pc)\npc_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = pd.concat([pc_df,dataset_final['clusters']],axis=1)\npca.columns = ['pc1','pc2','clusters']\nprint(pca.shape)\npca.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"pca.clusters.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[16,8])\nsns.scatterplot(x='pc1', y='pc2', hue= 'clusters', data=pca,palette='Set1')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explain what you have done and how this segments customers"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset_final.groupby('clusters').Fresh.mean().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_final.groupby('clusters').Milk.mean().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_final.groupby('clusters').Grocery.mean().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_final.groupby('clusters').Frozen.mean().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset_final.groupby('clusters').Detergents_Paper.mean().plot(kind='bar')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}