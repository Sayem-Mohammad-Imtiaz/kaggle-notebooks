{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#main libraries\nimport os\nimport re\nimport pickle\nimport numpy as np\nimport pandas as pd\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly \nimport plotly.graph_objs as go\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks as cf\nimport plotly.figure_factory as ff \nfrom plotly.offline import iplot\nfrom plotly import tools\n\n#importing machine learning libraries\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, KFold, cross_val_score\nfrom sklearn.preprocessing  import StandardScaler, LabelEncoder, MinMaxScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestRegressor\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom sklearn.linear_model import LinearRegression, ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import (BaggingRegressor, AdaBoostRegressor,GradientBoostingRegressor, \n                              RandomForestRegressor,  GradientBoostingRegressor)\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score\nfrom mlxtend.regressor import StackingCVRegressor\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import the data\nfull_df = pd.read_csv('/kaggle/input/bengaluru-house-price-data/Bengaluru_House_Data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df = full_df.drop(columns =['availability','balcony','area_type','society'])\nfull_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df['size'].fillna('0 BHK', inplace=True)\nfull_df['bath'].fillna(0, inplace=True)\nfull_df['location'].fillna('NA', inplace=True) \nfull_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df['size'] = full_df['size'].apply(lambda x: int(x.split(' ')[0]))\nfull_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return (float(tokens[0])+float(tokens[1]))/2\n    try:\n        return float(x)\n    except:\n        return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df.total_sqft = full_df.total_sqft.apply(convert_sqft_to_num)\nfull_df.total_sqft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#descriptive statistics summary\nfull_df['price'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#histogram\nsns.distplot(full_df['price']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#skewness and kurtosis\nprint(\"Skewness: %f\" % full_df['price'].skew())\nprint(\"Kurtosis: %f\" % full_df['price'].kurt())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatter plot size/price\nvar = 'size'\ndata = pd.concat([full_df['price'], full_df[var]], axis=1)\ndata.plot.scatter(x=var, y='price');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatter plot total_sqft/price\nvar = 'total_sqft'\ndata = pd.concat([full_df['price'], full_df[var]], axis=1)\ndata.plot.scatter(x=var, y='price');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatter plot bath/price\nvar = 'bath'\ndata = pd.concat([full_df['price'], full_df[var]], axis=1)\ndata.plot.scatter(x=var, y='price');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scatter plot balcony/price\nvar = 'location'\ndata = pd.concat([full_df['price'], full_df[var]], axis=1)\ndata.plot.scatter(x=var, y='price');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation matrix\ncorrmat = full_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using z_scores to remove outliers\n\n\ncols = ['size', 'total_sqft', 'bath']\n\n\ndef z_score(full_df):\n    full_df.columns = [x + \"_zscore\" for x in full_df.columns.tolist()]\n    return ((full_df - full_df.mean())/full_df.std(ddof=0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z_scores = z_score(full_df[cols])\nz_scores['ID'] = z_scores.index\nz_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df['ID'] = full_df.index\nfull_df = pd.merge(full_df, z_scores)\nfull_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df = full_df.loc[full_df['size_zscore'].abs()<=3]\nfull_df = full_df.loc[full_df['total_sqft_zscore'].abs()<=3]\nfull_df = full_df.loc[full_df['bath_zscore'].abs()<=3]\nfull_df = full_df.drop(columns =['size_zscore','total_sqft_zscore','bath_zscore','ID'])\nfull_df.reset_index(drop=True, inplace=True)\nfull_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train = full_df['price']\ndel full_df['price']\n\n#Converting the saleprice with Logarithms to over come the high skewness and the outliers\nY_train = np.log1p(Y_train) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert categorical variable into dummy\nfull_df = pd.get_dummies(full_df)\nfull_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df.fillna(0, inplace=True)\ntrain_set = full_df\ntrain_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define models to test:\n\nbase_models = {\"Elastic Net\":make_pipeline(RobustScaler(),                    #Elastic Net model(Regularized model)\n                                            ElasticNet(alpha=0.0005,\n                                                       l1_ratio=0.9)),\n               \"Kernel Ridge\" :KernelRidge(),                                 #Kernel Ridge model(Regularized model)\n               \"Lasso\" : make_pipeline(RobustScaler(), Lasso(alpha =0.0005,   #Lasso model(Regularized model)\n                                                             random_state=1)),\n               \"Linear Regression\" : LinearRegression(),                      #Linear Regression model\n               \"Random Forest\": RandomForestRegressor(n_estimators=300),      #Random Forest model\n               \"SVM\": SVR(),                                                  #Support Vector Machines\n               \"XGBoost\": XGBRegressor(),                                     #XGBoost model                                              \n               \"Gradient Boosting\":make_pipeline(StandardScaler(),\n                                                 GradientBoostingRegressor(n_estimators=3000, #GradientBoosting model\n                                                                           learning_rate=0.005,     \n                                                                           max_depth=4, max_features='sqrt',\n                                                                           min_samples_leaf=15, min_samples_split=10, \n                                                                           loss='huber', random_state =5))}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing, fitting, making predictions and scoring for every model:\nmodels_data = {'R^2':{'Training':{},'Testing':{}},\n               'Adjusted R^2':{'Training':{},'Testing':{}},\n               'MAE':{'Training':{},'Testing':{}},\n               'MSE':{'Training':{},'Testing':{}},\n               'RMSE':{'Training':{},'Testing':{}}}\n\nX_train, X_test, y_train, y_test = train_test_split(train_set, Y_train, test_size=0.2, random_state=42)\np = train_set.shape[1]\ntrain_n = X_train.shape[0]\ntest_n = X_test.shape[0]\n\nfor name in base_models:\n    #fitting the model\n    model = base_models[name].fit(X_train, y_train)\n    #make predictions with train and test datasets\n    y_pred_train = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n    \n    #calculate the R-Squared for training and testing\n    r2_train,r2_test = model.score(X_train, y_train), model.score(X_test, y_test)\n    models_data['R^2']['Training'][name], models_data['R^2']['Testing'][name] = r2_train, r2_test\n            \n    #calculate the Adjusted R-Squared for training and testing\n    adj_train, adj_test = (1-(1-r2_train)*(train_n-1)/(train_n-p-1)) ,(1-(1-r2_test)*(train_n-1)/(train_n-p-1))\n    models_data['Adjusted R^2']['Training'][name], models_data['Adjusted R^2']['Testing'][name] = adj_train, adj_test\n               \n    #calculate the Mean absolute error for training and testing\n    mae_train, mae_test = mean_absolute_error(y_train, y_pred_train), mean_squared_error(y_test, y_pred_test)         \n    models_data['MAE']['Training'][name], models_data['MAE']['Testing'][name] = mae_train, mae_test\n               \n    #calculate Mean square error for training and testing\n    mse_train, mse_test = mean_squared_error(y_train, y_pred_train), mean_squared_error(y_test, y_pred_test)\n    models_data['MSE']['Training'][name], models_data['MSE']['Testing'][name] = mse_train, mse_test\n\n    #calculate Root mean error for training and testing    \n    rmse_train, rmse_test = np.sqrt(mse_train), np.sqrt(mse_test)\n    models_data['RMSE']['Training'][name], models_data['RMSE']['Testing'][name] = rmse_train, rmse_test\n    \n    print('\\n========================={}========================='.format(name))\n    print('**********Training**********************Testing********')\n    print('R^2    : ',r2_train,' '*(25-len(str(r2_train))),r2_test) \n    print('Adj R^2: ',adj_train,' '*(25-len(str(adj_train))),adj_test) \n    print('MAE    : ',mae_train,' '*(25-len(str(mae_train))),mae_test) \n    print('MSE    : ',mse_train,' '*(25-len(str(mse_train))),mse_test) \n    print('RMSE   : ',rmse_train,' '*(25-len(str(rmse_train))),rmse_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"R_2 = pd.DataFrame(models_data['R^2']).sort_values(by='Testing',ascending=False)\nAdjusted_R_2 = pd.DataFrame(models_data['Adjusted R^2']).sort_values(by='Testing',ascending=False)\nMAE = pd.DataFrame(models_data['MAE']).sort_values(by='Testing',ascending=True)\nMSE = pd.DataFrame(models_data['MSE']).sort_values(by='Testing',ascending=True)\nRMSE = pd.DataFrame(models_data['RMSE']).sort_values(by='Testing',ascending=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#order the results by testing values\n\nfig1 = px.line(data_frame=R_2.reset_index(),\n        x='index',y=['Training','Testing'],\n        title='R-Squared for training and testing')\nfig1.update_yaxes(range=[-0.4, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#order the results by testing values\n\nfig2 = px.line(data_frame=Adjusted_R_2.reset_index(),\n        x='index',y=['Training','Testing'],\n        title='Adjusted R-Squared for training and testing')\nfig2.update_yaxes(range=[-0.4, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#order the results by testing values\n\nfig3 = px.line(data_frame=MAE.reset_index(),\n        x='index',y=['Training','Testing'],\n        title='Mean absolute error for training and testing')\nfig3.update_yaxes(range=[-0.4, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#order the results by testing values\n\nfig4 = px.line(data_frame=MSE.reset_index(),\n        x='index',y=['Training','Testing'],\n        title='Mean square error for training and testing')\nfig4.update_yaxes(range=[-0.4, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#order the results by testing values\n\nfig5 = px.line(data_frame=RMSE.reset_index(),\n        x='index',y=['Training','Testing'],\n        title='Root mean square error for training and testing')\nfig5.update_yaxes(range=[-0.4, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using XG Boost as it has maximum accuracy for the test dataset\npredictor = XGBRegressor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fitting the model to our data\npredictor.fit(train_set,Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#see the results of the model for training\n\npredictor_score = round(predictor.score(train_set, Y_train)*100, 3)\npredictions = predictor.predict(train_set)\npredictor_rmse = round(np.sqrt(mean_squared_error(Y_train, predictions).mean())*100, 3)\nprint(' _'*15)\nprint('\\nStacking Results for trining test : \\n')\nprint(f'Score : {predictor_score}%')\nprint(f'RMSE  : {predictor_rmse}%')\nprint(' _'*15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame({'Actual': Y_train,'Predicted': predictions })\ndf1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}