{"cells":[{"metadata":{},"cell_type":"markdown","source":"Read Bollywood (Indian Movie in Hindi Language) Dataset containing Cast and crew with Box office Gross.  \nFirst we need to load full datasets from CSV file. Later we can choose some Gross value field as target for prediction.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfull_dataframe = pd.read_csv(\"../input/bollywood-movie-dataset/Movie.csv\", index_col=0)\n\nfull_dataframe.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make data preparation:\n1. Drop column 'Title'. In this task I didn't account this column using text processing algorithms.\n2. Correct currency columns and convert them to numeric data type\n3. Fix 'Release Date' column and split it into Year, Month and Day features.\n4. Use One Hot encoding to encode all comma-separated columns, like 'Director', into thousands of feature columns.\n5. Use One Hot encoding to encode all 'Actors' columns. Seven 'Actors' columns have the same meaning and should be encoded in one operation.\n6. Use One Hot encoding (pd.get_dummies) to encode simple string columns as 'Genre', 'Production Banner'."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_object_cols(df):\n    return [cname for cname in df.columns if df[cname].dtype == \"object\"]\n\ndef encode_comma_separated_cols(df, max_cols=10000):\n    comma_separated_cols = ['Dialogue', 'Director', 'Directors', 'Lyrics', 'Music', 'Producer', 'Screenplay', 'Story']\n    for col in comma_separated_cols:\n        oh_cols = (df[col].str.split(pat=\",\", expand=True)\n            .apply(pd.Series.value_counts, 1)\n            .iloc[:, 1:]\n            .fillna(0, downcast='infer')\n            .add_prefix(col + ' '))\n        \n        oh_cols_count = min(oh_cols.shape[1], max_cols)\n        oh_cols = oh_cols.sample(oh_cols_count, axis=1)\n        \n        print(\"Count of %s features: %d\" % (col, oh_cols_count))\n\n        if oh_cols_count > 1:\n            df = df.drop(col, axis=1)\n            df = pd.concat([df, oh_cols], axis=1)\n\n    return df\n\ndef encode_actors_cols(df, max_cols=10000):\n    actors_cols = ['Actors ' + str(x) for x in range(1, 8)]\n    \n    oh_actors = (df[actors_cols]\n        .apply(pd.Series.value_counts, 1)\n        .iloc[:, 1:]\n        .fillna(0, downcast='infer')\n        .add_prefix('Actor '))\n\n    oh_cols_count = min(oh_actors.shape[1], max_cols)\n    oh_actors = oh_actors.sample(oh_cols_count, axis=1)\n\n    print(\"Count of %s features: %d\" % ('Actors', oh_cols_count))\n\n    df = df.drop(actors_cols, axis=1)\n    df = pd.concat([df, oh_actors], axis=1)\n\n    return df\n\ndef encode_object_cols(df):\n    object_cols = get_object_cols(df)\n\n    oh_cols = pd.get_dummies(df[object_cols])\n\n    df = df.drop(object_cols, axis=1)\n    df = pd.concat([df, oh_cols], axis=1)\n    \n    return df\n\ndef pre_processing(df):\n    # Drop useless column\n    df = df.drop('Title', axis=1)\n\n    # Fixing currency columns\n    currency_cols = ['Budget', 'First Day', 'First Week', 'First Weekend', 'India Gross', \"Overseas Gross\", 'Worldwide Gross']\n\n    for col in currency_cols:\n        df[col] = pd.to_numeric(df[col].str.lstrip('$').str.replace(',', '').str.replace('-', '').replace(\"\", np.nan))\n\n    df.Budget.fillna(df.Budget.mean(), inplace=True)\n        \n    # Fixing time and date columns\n    df['Runtime'] = pd.to_numeric(df['Runtime'].str.rstrip(' min'))\n    df['Release Year'] = pd.DatetimeIndex(df['Release Date']).year\n    df['Release Month'] = pd.DatetimeIndex(df['Release Date']).month\n    df['Release Day'] = pd.DatetimeIndex(df['Release Date']).day\n    df = df.drop('Release Date', axis=1)\n\n    for col in get_object_cols(df):\n        df[col] = df[col].str.strip()\n    \n    df = encode_comma_separated_cols(df)    \n    df = encode_actors_cols(df)\n    df = encode_object_cols(df)\n\n    return df\n\ndf = pre_processing(full_dataframe.copy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's choose 'India Gross' as prediction target and split prepared data to train and validation datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntarget_cols = ['First Day', 'First Week', 'First Weekend', 'India Gross', \"Overseas Gross\", 'Worldwide Gross']\n\n# Remove rows with missing target, separate target from predictors\ni_gross_df = df.dropna(axis=0, subset=['India Gross'])\n\nX_full = i_gross_df.drop(target_cols, axis=1)\ny_full = i_gross_df['India Gross']\n\nX_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some preparation has beed made here for feature selection using LinearSVC. But I disabled feature selection because it didn't bring significant results."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n#from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import SelectFromModel\n\ndef select_features_l1(X, y):\n    \"\"\"Return selected features using logistic regression with an L1 penalty.\"\"\"\n    #logistic = LogisticRegression(C=0.5, penalty=\"l1\", solver='liblinear', random_state=7).fit(X, y)\n    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n    selector = SelectFromModel(logistic, prefit=True)\n\n    X_new = selector.transform(X) \n\n    # Get back the kept features as a DataFrame with dropped columns as all 0s\n    selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                     index=X.index, \n                                     columns=X.columns)\n\n    selected_columns = selected_features.columns[selected_features.var() != 0]\n    return selected_columns\n\nis_select_features = False\nif is_select_features:\n    print(\"Feature selection\")\n\n    #n_samples = 300\n    #X, y = p_train[feature_cols][:n_samples], p_train[\"SalePrice\"][:n_samples]\n    selected = select_features_l1(X_train, y_train)\n\n    dropped_columns = feature_cols.drop(selected)\n\n    selected_features_train = p_train.drop(dropped_columns, axis=1)\n    selected_features_valid = p_valid.drop(dropped_columns, axis=1)\n\n    print('Selected features:', list(selected_features_train.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This code allows to find best parameters for RandomForestRegressor using GridSearchCV. Skip this code to speed up notebook execution."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nfind_best_params  = False\nif find_best_params:\n    n_samples = 1000\n\n    parameter_grid = {\n                'max_depth': [10, 15, 20],\n                'n_estimators': [50, 100, 200]\n            }\n    \n    rf_reg = RandomForestRegressor()\n    grid_searcher = GridSearchCV(rf_reg, parameter_grid, verbose=2)\n    grid_searcher.fit(X_train[:n_samples], y_train[:n_samples])\n    rf_reg_best = grid_searcher.best_estimator_\n\n    print('Best params = ', rf_reg_best.get_params())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Used best hyperparameters for regressor I've found on previous step."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Using best parameters\nrf_reg_params = {'n_estimators': 100,\n                 'max_depth': 15}\n\nrf_reg = RandomForestRegressor(**rf_reg_params)\n\nrf_reg.fit(X_train, y_train)\n\nscore = rf_reg.score(X_train, y_train)  \nprint(\"Training score: \", score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\ntest_pred = rf_reg.predict(X_test)\ntest_score = mean_absolute_error(y_test, test_pred)\nprint(\"Test MAE score:\", test_score)\n\ntest_score = mean_squared_error(y_test, test_pred, squared=False)\nprint(\"Test MSE score:\", test_score)\n\ntest_score = r2_score(y_test, test_pred)\nprint(\"Test R2 score:\", test_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We've got R2 score 0.68. This is greather than 0.5 and means that **our model is not perfect but acceptable for solving task**.  \nLet's try another GradientBoostingRegressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngb_reg_params = {'n_estimators': 500}\n\ngb_reg = GradientBoostingRegressor(**gb_reg_params)\ngb_reg.fit(X_train, y_train)\n\nscore = gb_reg.score(X_train, y_train)  \nprint(\"Training score: \", score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = gb_reg.predict(X_test)\ntest_score = mean_absolute_error(y_test, test_pred)\nprint(\"Test MAE score:\", test_score)\n\ntest_score = mean_squared_error(y_test, test_pred, squared=False)\nprint(\"Test MSE score:\", test_score)\n\ntest_score = r2_score(y_test, test_pred)\nprint(\"Test R2 score:\", test_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We've got R2 score 0.78! This result much closer to 0.8 and means that our **model performs well for this task**.  \nAfter that we will visualize the results for GradientBoostingRegressor. To do that we will first compute the test set deviance and then plot it against boosting iterations."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntest_score = np.zeros((gb_reg_params['n_estimators'],), dtype=np.float64)\nfor i, y_pred in enumerate(gb_reg.staged_predict(X_test)):\n    test_score[i] = gb_reg.loss_(y_test, y_pred)\n\nfig = plt.figure(figsize=(6, 6))\nplt.subplot(1, 1, 1)\nplt.title('Deviance')\nplt.plot(np.arange(gb_reg_params['n_estimators']) + 1, gb_reg.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(gb_reg_params['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try using XGBRegressor instead of GradientBoostingRegressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\n# Trying XGBRegressor\nxgb_reg = XGBRegressor()\n\nxgb_reg.fit(X_train, y_train)\n\nscore = xgb_reg.score(X_train, y_train)  \nprint(\"Training score: \", score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = xgb_reg.predict(X_test)\ntest_score = mean_absolute_error(y_test, test_pred)\nprint(\"Test MAE score:\", test_score)\n\ntest_score = mean_squared_error(y_test, test_pred, squared=False)\nprint(\"Test MSE score:\", test_score)\n\ntest_score = r2_score(y_test, test_pred)\nprint(\"Test R2 score:\", test_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obviously GradientBoostingRegressor is better suited for this task."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}