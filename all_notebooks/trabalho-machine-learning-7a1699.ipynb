{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introdução"},{"metadata":{},"cell_type":"markdown","source":"As instituições financeiras estão sujeitas à perdas significativas em decorrência de inadimplência nas operações de financiamento de veículos. A elevação dos índices de inadimplemento resulta em maior taxa de rejeição de pedidos de financiamento e no aumento das taxas de juros - que encarece o produto para consumidores finais e dessestimula muitos compradores.\n\nDiante deste cenário, torna-se cada vez mais relevante a aplicação de modelos estatísticos adequados para prever os riscos envolvidos nos contratos celebrados e permitir a concessão para clientes com menor risco de crédito.\n\nO presente estudo procura estimar as características determinantes para inadimplência em contratos de veículos. Para isto serão utilizadas características históricas de clientes e empréstimos realizados por uma instituição financeira.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Importação dos dados"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport pandas_profiling\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nsns.set(rc = {'figure.figsize':(15, 10)})\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom IPython.core.interactiveshell import InteractiveShell \nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Carregando os dados\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análise dos dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"pandas_profiling.ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De acordo com o relatório apresentado pela função *ProfileReport()*, há 233.154 linhas e 41 variáveis no dataset, sendo elas 25 númericas, 6 categóricas, 6 do tipo boolean e 4 do tipo constante (*rejected*).\n\nObserva-se que há alguns *warning* registrados para algumas variáveis do dataset que apontam alguns potenciais problemas para o modelo. São eles: alta cardinalidade, grande quantidade de valores zero na coluna, valores faltantes e um desequilíbrio na distribuição dos valores da variáveis (*y1*).\n\nEssas observações serão tratadas ao longo da análise."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Avaliando o shape do dataset de treino e teste\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Avaliando os típos das variáveis\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aval\ntrain.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A partir da observação dos tipos de cada variável, algumas decisões serão executadas:\n- Transformar as variáveis do tipo object em tipo inteiro ou dummy\n- Transformar as datas em tipo datetime e criar colunar para contabilizar a idade da observação (em ano ou dia)\n- Popular os dados faltantes com um valor \"desconhecido\" pela coluna como, por exemplo, o um valor \"-1\" em uma coluna de inteiros não-negativos\n\n\nNeste trabalho, a variável dependente (*target*) será o campo **LOAN_DEFAULT**."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analisando a quantidade de inadimplencias através da variável target LOAN_DEFAULT\ntrain['LOAN_DEFAULT'].value_counts(normalize=True)\ntrain['LOAN_DEFAULT'].value_counts(normalize=True).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observa-se que a variável target possui um volume de valores 0 (\"Inadimplente\") muito maior que valores 1 (\"Adimplente\"). Essa será uma obervação importante para a análise do modelo."},{"metadata":{},"cell_type":"markdown","source":"# Tratamento dos dados"},{"metadata":{},"cell_type":"markdown","source":"Nesta fase do trabalho os dados serão tratados de forma a permitir a aplicação de algoritmos de machine learning. \n* serão criadas novas colunas no dataframe a partir de colunas já existentes (feature engineering);\n* dummerização de variáveis; "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criação de cópia do dataframe de treino\ntrain_copy = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, train_copy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Os dataframes de teste e treino serão unidos afim de facilitar o processo de transformação e de feature engineering\ntrain = train.append(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando como estão os dados da coluna AVERAGE_ACCT_AGE\ntrain['AVERAGE_ACCT_AGE'].value_counts(normalize=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos criar nova coluna (AVERAGE_ACCT_AGE_EM_MESES), que vai contabilizar a quantidade de meses que estão dispostas na coluna AVERAGE_ACCT_AGE\ntrain['AVERAGE_ACCT_AGE_EM_MESES'] = train['AVERAGE_ACCT_AGE'].str.split('y').str.get(0).astype(int)*12 + train['AVERAGE_ACCT_AGE'].str.split(' ').str.get(1).str.split('m').str.get(0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando como estão os dados da coluna CREDIT_HISTORY_LENGTH\ntrain['CREDIT_HISTORY_LENGTH'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos criar nova coluna (CREDIT_HISTORY_LENGTH_EM_MESES), que vai contabilizar a quantidade de meses que estão dispostas na coluna CREDIT_HISTORY_LENGTH\ntrain['CREDIT_HISTORY_LENGTH_EM_MESES'] = train['CREDIT_HISTORY_LENGTH'].str.split('y').str.get(0).astype(int)*12 + train['CREDIT_HISTORY_LENGTH'].str.split(' ').str.get(1).str.split('m').str.get(0).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verifica-se que a data de nascimento está na coluna DATE_OF_BIRTH\n# Iremos transformar a data de nascimento em idade\ntrain['DATE_OF_BIRTH'] = train['DATE_OF_BIRTH'].astype('datetime64[ns]')\nnow = pd.Timestamp('now')\ntrain['DATE_OF_BIRTH'] = pd.to_datetime(train['DATE_OF_BIRTH'], format='%m%d%y')\ntrain['DATE_OF_BIRTH'] = train['DATE_OF_BIRTH'].where(train['DATE_OF_BIRTH'] < now, train['DATE_OF_BIRTH'] -  np.timedelta64(100, 'Y'))\ntrain['Idade'] = (now - train['DATE_OF_BIRTH']).astype('<m8[Y]').astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a nova coluna Idade\ntrain['Idade']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DISBURSAL_DATE - data do desembolso\n# Esta coluna será tranformada em dias afim de verificar se o tempo decorrido a partir da concessão do crédito é\n# determinante do inadimplemento dos clientes\n\ntrain['DISBURSAL_DATE'] = train['DISBURSAL_DATE'].astype('datetime64[ns]')\nnow = pd.Timestamp('now')\ntrain['DISBURSAL_DATE'] = pd.to_datetime(train['DISBURSAL_DATE'], format='%m%d%y')\ntrain['DISBURSAL_DATE'] = train['DISBURSAL_DATE'].where(train['DISBURSAL_DATE'] < now, train['DISBURSAL_DATE'] -  np.timedelta64(100, 'Y'))\ntrain['DIAS_DESEMBOLSO'] = (now - train['DISBURSAL_DATE']).dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verificando a quantidade de dias de desembolso\ntrain['DIAS_DESEMBOLSO']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando como estão os dados da coluna EMPLOYMENT_TYPE\ntrain['EMPLOYMENT_TYPE'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorizando os dados, inclusive os valores nulos\nle_employment_type = LabelEncoder()\ntrain['EMPLOYMENT_TYPE'] = le_employment_type.fit_transform(list(train['EMPLOYMENT_TYPE']))\ntrain['EMPLOYMENT_TYPE'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a quantidade de valores nulos em todo a base\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando como estão os dados da coluna PERFORM_CNS_SCORE_DESCRIPTION\ntrain['PERFORM_CNS_SCORE_DESCRIPTION'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transformando em dummies\ntrain = pd.get_dummies(train, columns=['PERFORM_CNS_SCORE_DESCRIPTION'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iniciando o treinamento do modelo"},{"metadata":{},"cell_type":"markdown","source":"De forma preliminar ao treinamento, os dados já tratados serão dividos novamente em treino e teste. Além disso, uma base de validação, para avaliar o modelo, também será gerada. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#dividindo os data sets\ntest = train[train['LOAN_DEFAULT'].isnull()]\ntrain = train[~train['LOAN_DEFAULT'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando uma base de validação\ntrain, validation = train_test_split(train, test_size = 0.30, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando as dimensões dos dataset\ntrain.shape, validation.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecionar as colunas para uso no treinamento e validação\n\n# lista das colunas não usadas\nremoved_cols = ['LOAN_DEFAULT','UNIQUEID', 'AVERAGE_ACCT_AGE','CREDIT_HISTORY_LENGTH','DISBURSAL_DATE','DATE_OF_BIRTH']\n\n# lista das features (colunas usadas no modelo)\nfeats = [c for c in train.columns if c not in removed_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definição dos hiperparâmetros dos modelos\nn_arvores = 300\noob_score = True\nn_jobs = -1\nn_cortes = 5\nmax_profundidade = 7\nrandom_state = 42\nlearning_rate = 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definição do modelo de arvoré\nrf = RandomForestClassifier(n_estimators = n_arvores,\n                            oob_score = oob_score,\n                            n_jobs = n_jobs,\n                            min_samples_split = n_cortes,\n                            max_depth = max_profundidade,\n                            random_state = random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realização do treino do modelo\nrf.fit(train[feats], train['LOAN_DEFAULT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exibindo o score do out-of-bag do modelo\nrf.oob_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realizando as predições no modelo criado a partir do dataset de validação\npredictions = rf.predict(validation[feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exibindo o score da validação\naccuracy_score(validation['LOAN_DEFAULT'], predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Método para gerar um gráfico da matrix de confusão\n# Fonte: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\ndef plot_confusion_matrix(y_true, y_pred, \n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    #classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           #xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusão com valores absolutos para \nplot_confusion_matrix(validation['LOAN_DEFAULT'], predictions, \n                      title='Matriz de Confusão [Valores Absolutos], Modelo RF')\n\n# Plotando a matriz de confusão com valores normalizados \nplot_confusion_matrix(validation['LOAN_DEFAULT'], predictions, normalize=True,\n                      title='Matriz de Confusão [Valores Normalizados], Modelo RF')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definição do modelo GCM\ngbm = GradientBoostingClassifier(n_estimators = n_arvores, learning_rate = learning_rate, max_depth = max_profundidade, random_state = random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realização do treino do modelo\ngbm.fit(train[feats], train['LOAN_DEFAULT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realizando as predições no modelo criado a partir do dataset de validação\npredictions = gbm.predict(validation[feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exibindo o score da validação\naccuracy_score(validation['LOAN_DEFAULT'], predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusão com valores absolutos para \nplot_confusion_matrix(validation['LOAN_DEFAULT'], predictions, \n                      title='Matriz de Confusão [Valores Absolutos], Modelo GBM')\n\n# Plotando a matriz de confusão com valores normalizados \nplot_confusion_matrix(validation['LOAN_DEFAULT'], predictions, normalize=True,\n                      title='Matriz de Confusão [Valores Normalizados], Modelo GBM')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definição do modelo XGBoost\nxgb = XGBClassifier(n_estimators = n_arvores, learning_rate = learning_rate, random_state = random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realização do treino do modelo\nxgb.fit(train[feats], train['LOAN_DEFAULT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realizando as predições no modelo criado a partir do dataset de validação\npredictions = xgb.predict(validation[feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exibindo o score da validação\naccuracy_score(validation['LOAN_DEFAULT'], predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusão com valores absolutos para \nplot_confusion_matrix(validation['LOAN_DEFAULT'], predictions, \n                      title='Matriz de Confusão [Valores Absolutos], Modelo XGB')\n\n# Plotando a matriz de confusão com valores normalizados \nplot_confusion_matrix(validation['LOAN_DEFAULT'], predictions, normalize=True,\n                      title='Matriz de Confusão [Valores Normalizados], Modelo XGB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função para criação de um DF de features importantes para o modelo\ndef create_df_feature_importance(column_names, importances):\n    df = pd.DataFrame({'feature': column_names,\n                       'feature_importance': importances}) \\\n           .sort_values('feature_importance', ascending = False) \\\n           .reset_index(drop = True)\n    return df\n\n# Função para plotar o features importance do modelo\ndef plot_feature_importance(imp_df, title):\n    imp_df.columns = ['feature', 'feature_importance']\n    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n       .set_title(title, fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o DF das principais features do modelo de RandomFlorest\nbase_imp = create_df_feature_importance(feats, rf.feature_importances_)\n\n# Imprimindo as principais features utilizadas no modelo RandonFlorest\nplot_feature_importance(base_imp, 'Feature Importances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o DF das principais features do modelo GBM\nbase_imp = create_df_feature_importance(feats, gbm.feature_importances_)\n\n# Imprimindo as principais features utilizadas no modelo GBM\nplot_feature_importance(base_imp, 'Feature Importances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o DF das principais features do modelo XGB\nbase_imp = create_df_feature_importance(feats, xgb.feature_importances_)\n\n# Imprimindo as principais features utilizadas no modelo XGB\nplot_feature_importance(base_imp, 'Feature Importances')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nota-se que os modelos têm acurácia muito próximas, embora o modelo ??? tenha tido a maior acurácia dentre os três. Outra informação importante está relacionada aos falsos positivos gerados a partir do modelo. Acredita-se que a principal causa dessa anomalida seja a proporção desbalanceada dos valores presentes na variável target. Como há um percentual maior de inadimplentes, logo o modelo tende a taxar a maioria dos novos valores como inadimplentes também. Há diversas soluções para esse problema, a principal delas é normalizar a base de dados de modo que a proporção entre as classes seja o mais igualitário possível."},{"metadata":{},"cell_type":"markdown","source":"# Proposta de aplicação do problema ao negócio"},{"metadata":{},"cell_type":"markdown","source":"Em relação aos dados obtidos pela aplicação do modelo de Random Forest, foi possível perceber que os principais fatores são:"},{"metadata":{},"cell_type":"markdown","source":"LTV (Loan to value of the asset) \n* é um indicador usado para definir qual o percentual máximo do valor do bem que pode ser emprestado para o cliente. Conforme abaixo, vemos que em média até 74% do valor do bem é concedido para empréstimos para os clientes. Quando se observa os clientes com inadimplência, este percentual chega próximo de 77%, desta forma é recomendável que os empréstimos sejam menores em relação ao valor do veículo financiado\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['LTV'].mean()\ntrain['LTV'].groupby(train['LOAN_DEFAULT']).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DISBURSED AMOUNT\n* É o valor concedido de empréstimo. Aqui podemos observar que os empréstimos com inadiplência possuem, em média, valor mais altos de desembolso."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['DISBURSED_AMOUNT'].mean()\ntrain['DISBURSED_AMOUNT'].groupby(train['LOAN_DEFAULT']).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RISCO DE CRÉDITO\n* Este é o risco atribuído pela instituição no momento do crédito do veículo\n* Póssível perceber inadiplência maior em clientes com maior risco, isso sugere que a instituição financeira já detém expertise ao atribuir risco para os clientes que pode ser melhorada através deste modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"riscoA = train_copy[train_copy['PERFORM_CNS_SCORE_DESCRIPTION'] == 'A-Very Low Risk']\nriscoA['LOAN_DEFAULT'].value_counts(normalize=True)\n\nriscoE = train_copy[train_copy['PERFORM_CNS_SCORE_DESCRIPTION'] == 'E-Low Risk']\nriscoE['LOAN_DEFAULT'].value_counts(normalize=True)\n\nriscoH = train_copy[train_copy['PERFORM_CNS_SCORE_DESCRIPTION'] == 'H-Medium Risk']\nriscoH['LOAN_DEFAULT'].value_counts(normalize=True)\n\nriscoL = train_copy[train_copy['PERFORM_CNS_SCORE_DESCRIPTION'] == 'L-Very High Risk']\nriscoL['LOAN_DEFAULT'].value_counts(normalize=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}