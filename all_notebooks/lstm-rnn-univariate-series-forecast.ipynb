{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nfrom matplotlib import pyplot\nimport numpy\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n#from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nfrom matplotlib import pyplot\nimport numpy\nimport os\n\n\n# date-time parsing function for loading the dataset\ndef parser(x):\n    return datetime.strptime('190'+x, '%Y-%m')\n \n# frame a sequence as a supervised learning problem\ndef timeseries_to_supervised(data, lag=1):\n    df = DataFrame(data)\n    columns = [df.shift(i) for i in range(1, lag+1)]\n    columns.append(df)\n    df = concat(columns, axis=1)\n    df.fillna(0, inplace=True)\n    return df\n \n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n \n# invert differenced value\ndef inverse_difference(history, yhat, interval=1):\n    return yhat + history[-interval]\n \n# scale train and test data to [-1, 1]\ndef scale(train, test):\n    # fit scaler\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler = scaler.fit(train)\n    # transform train\n    train = train.reshape(train.shape[0], train.shape[1])\n    train_scaled = scaler.transform(train)\n    # transform test\n    test = test.reshape(test.shape[0], test.shape[1])\n    test_scaled = scaler.transform(test)\n    return scaler, train_scaled, test_scaled\n \n# inverse scaling for a forecasted value\ndef invert_scale(scaler, X, value):\n    new_row = [x for x in X] + [value]\n    array = numpy.array(new_row)\n    array = array.reshape(1, len(array))\n    inverted = scaler.inverse_transform(array)\n    return inverted[0, -1]\n \n# fit an LSTM network to training data\ndef fit_lstm(train, batch_size, nb_epoch, neurons):\n    X, y = train[:, 0:-1], train[:, -1]\n    X = X.reshape(X.shape[0], 1, X.shape[1])\n    model = Sequential()\n    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    history = model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n    model.reset_states()\n    return model\n \n# make a one-step forecast\ndef forecast_lstm(model, batch_size, X):\n    X = X.reshape(1, 1, len(X))\n    yhat = model.predict(X, batch_size=batch_size)\n    return yhat[0,0]\n \n# load dataset\nseries = pd.read_csv('../input/sales-of-shampoo-over-a-three-ye.csv',date_parser=parser)\n\nmonth =  series['Month']\ndata = series['Sales of shampoo over a three year period']\ndata = data[:-1]\n \n# transform data to be stationary\nraw_values = data.values\n#diff_values = difference(raw_values, 1)\n \n# transform data to be supervised learning\n#supervised = timeseries_to_supervised(diff_values, 1)\nsupervised = timeseries_to_supervised(raw_values, 1)\nsupervised_values = supervised.values\n \n# split data into train and test-sets\ntrain, test = supervised_values[0:-12], supervised_values[-12:]\n \n# transform the scale of the data\nscaler, train_scaled, test_scaled = scale(train, test)\n \n# repeat experiment\n#repeats = 10\n#error_scores = list()\n#for r in range(repeats):\n    # fit the model\nlstm_model = fit_lstm(train_scaled, 1, 500, 4)\n# forecast the entire training dataset to build up state for forecasting\ntrain_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\nlstm_model.predict(train_reshaped, batch_size=1)\n# walk-forward validation on the test data\npredictions = list()\nfor i in range(len(test_scaled)):\n    # make one-step forecast\n    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n    yhat = forecast_lstm(lstm_model, 1, X)\n    # invert scaling\n    yhat = invert_scale(scaler, X, yhat)\n    # invert differencing\n    #yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n    # store forecast\n    predictions.append(yhat)\n    # report performance\nrmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\nprint('Test RMSE: ',rmse)\n#error_scores.append(rmse)\n\n#Forecasting into 1st ,2nd ,3rd Month of 4th Year\ntest_df = supervised.iloc[:,1]\ntest_new = test_df[-13:,]\nfor fv in range(0,3):    \n    test_new = np.array(test_new)\n    test_new = test_new.reshape(-1,1)\n    test_new_scaled =  scaler.fit_transform(test_new)\n\n    forecast = list()\n    for i in range(len(test_new_scaled)):\n        # make one-step forecast\n        X = test_new_scaled[i]\n        yhat = forecast_lstm(lstm_model, 1, X)\n        # invert scaling\n        yhat = invert_scale(scaler, X, yhat)\n        # invert differencing\n        #yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n        # store forecast\n        forecast.append(yhat)\n\n    print(\"forecast\",forecast)\n    forecast_df = pd.DataFrame(forecast)\n    value = forecast_df.iloc[-1:]\n    test_new = pd.DataFrame(test_new)\n    test_new = test_new.append(value)\n    test_new = test_new.reset_index()\n    test_new.drop(\"index\",axis =1, inplace = True)\n\nprint(\"Forecasting completed !!!\")\nprint(\"Future month forecast == \",test_new.iloc[-3:,])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}