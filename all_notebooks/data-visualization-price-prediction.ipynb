{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Welcome! This notebook is divided into the following sections:\n\n1. Data importation, cleaning and preparation.\n2. Data visualization/exploratory data analysis.\n3. Machine Learning/Price Prediction using a Random forest model.\n\n### The goal is to create a model that can predict Airbnb listing prices in the San Francisco market."},{"metadata":{"id":"4ldLweKZBKfL","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport re\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\n\nfrom sklearn import set_config\nset_config(display='diagram')\n\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"id":"fYObr5NOBKfV","trusted":true},"cell_type":"code","source":"# # Import the CSV file as a dataframe:\n\ndf = pd.read_csv('/kaggle/input/san-francisco-airbnb-listings/listings.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning and Preparation"},{"metadata":{"id":"KPcJtX2CBKfV","trusted":true},"cell_type":"code","source":"# # Display basic dataframe info (number of columns/rows & data types):\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Take a look at the first 5 rows:\n\npd.set_option('display.max_columns', None)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The dataframe contains 106 columns. For price prediction, we're going to utilize only these 4 features:\n* Property type\n* Room type\n* Amenities\n* Neighborhood"},{"metadata":{"id":"ySyR-oRmBKfW","trusted":true},"cell_type":"code","source":"# # Create a new dataframe that omits all the unneeded columns:\n\nmldf = df[['city', 'neighbourhood_cleansed', 'property_type', 'room_type', 'price', 'amenities']]","execution_count":null,"outputs":[]},{"metadata":{"id":"YMh1SORwBKfW","outputId":"c93dfc82-8668-4caf-812d-cae2d3d10e8e","trusted":true},"cell_type":"code","source":"# # Show the number of null values in each column:\n\nmldf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* #### 10 of the 8111 records contain null values for ***city***. \n* #### City is a non-numerical value and cannot be imputed. \n* #### Therefore, we will drop the affected records."},{"metadata":{"id":"SAODzvmqBKfX","outputId":"205b8523-ede2-40ae-b945-3055d9ab0623","trusted":true},"cell_type":"code","source":"# # Drop null values; check what datatype each column contains:\n\nmldf.dropna(inplace = True)\n\nmldf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Show summary stats for the dataframe:\n\nmldf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### There are 8 unique values for ***city***. Let's see what they are."},{"metadata":{"id":"F1DnFgpZBKfX","outputId":"08a4e915-fa00-4f69-df6f-60e339256a47","trusted":true},"cell_type":"code","source":"mldf['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We want only listings located in San Francisco. \n\n#### Consolidate the SF name-variant classes into the 'San Francisco' class, and eliminate the non-SF entries:"},{"metadata":{"id":"XlKS_wN5BKfY","outputId":"3c264dea-a866-43ef-f987-bbfec01ed3ad","trusted":true},"cell_type":"code","source":"# # Check whether the 'San Francisco' class with only 3 records contains an extra space in its name:\n\nmldf.loc[mldf['city'].str.contains('San Francisco ')]","execution_count":null,"outputs":[]},{"metadata":{"id":"ffHTmYCjBKfY","outputId":"65800f1f-cbb0-41d0-9d35-994b81ce5e2a","trusted":true},"cell_type":"code","source":"# # Correct the 'San Francisco' name variants to read only 'San Francisco':\n\nmldf.loc[mldf['city'] == 'Noe Valley - San Francisco', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == 'San Francisco, Hayes Valley', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == '旧金山', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == 'San Francisco ', 'city'] = 'San Francisco'","execution_count":null,"outputs":[]},{"metadata":{"id":"r9yW8KBaBKfZ","outputId":"088aa416-2b6b-4e97-df07-383b9009b4a1","trusted":true},"cell_type":"code","source":"# # Confirm the corrections using value_counts method:\n\nmldf['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"wga3YvMzBKfZ","outputId":"818d6d1a-c835-4c93-ee18-1b6a4e4a8d2f","trusted":true},"cell_type":"code","source":"# # Get the index names for non-SF records and compute the sum:\n\nindex_names = mldf[(mldf['city'] == 'Daly City') | (mldf['city'] == 'San Jose') | (mldf['city'] == 'Brisbane')].index \nlen(index_names)","execution_count":null,"outputs":[]},{"metadata":{"id":"kyDcjWQ-BKfa","outputId":"f83e020b-4f95-47cb-c879-78edd85e428b","trusted":true},"cell_type":"code","source":"# # drop non-SF row indices from dataFrame and confirm their removal:\n\nmldf.drop(index_names, inplace = True)\n\nmldf['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"AkiCAb5WBKfa","outputId":"317bfa9d-2cf9-43b2-ebf3-ddf219a08086","trusted":true},"cell_type":"code","source":"# # Convert the values in price column to floats:\n\nmldf['price'] = mldf['price'].replace('[\\$,]', '', regex=True).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Show summary stats for price column:\nmldf['price'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The min price value is zero. This make no sense. Let's check for prices < 1:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mldf[mldf['price'] < 1]","execution_count":null,"outputs":[]},{"metadata":{"id":"EvLA0XSkBKfa","outputId":"569d3b3a-18de-49b8-ce07-03cbe7add0b1","trusted":true},"cell_type":"code","source":"# # Drop the row with index 3752 and confirm its removal:\n\nmldf.drop([3752], inplace = True)\nmldf[mldf['price'] <= 1]","execution_count":null,"outputs":[]},{"metadata":{"id":"wGl91cJ9BKfb","trusted":true},"cell_type":"code","source":"# # We can now drop the city column from the dataframe:\n\nmldf = mldf[['neighbourhood_cleansed', 'property_type', 'room_type', 'amenities', 'price']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### With that done, let's check the proportion of listings that belong to each room type class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mldf['room_type'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The room_type variable specifies four classes:\n* 'Entire home/apt' and 'Private room', which account for ~ 59% and ~ 36% of observations respectively. \n* 'Shared room' and 'Hotel room', which individually account for 3% or less.\n\nTo help simplify and optimize our model, we will discard the small number of records that correspond to the 'shared room' and 'hotel room' classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Drop 'shared room' and 'hotel room' listings from the data frame:\n\nmldf = mldf[(mldf['room_type'] == 'Entire home/apt') | (mldf['room_type'] == 'Private room')]\nmldf['room_type'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The amenities text must be *tokenized* before being fed into the ML model. This will occur later, at the pre-processing step.\n\nSpaces between words might be (incorrectly) interpreted as token separators by the vectorizer. We must remove these spaces so that words describing individual amenities are counted as single tokens:"},{"metadata":{"id":"r_WTvUAbBKfb","trusted":true},"cell_type":"code","source":"mldf['amenities'] = mldf['amenities'].str.replace(' *', flags=re.I, repl='')","execution_count":null,"outputs":[]},{"metadata":{"id":"2xGveUb2BKfd","outputId":"f140db83-8306-4cfb-b75f-3f02a771ca63","trusted":true},"cell_type":"code","source":"# # Compute the proportion of listings that belong to each property type category:\n\nprint(mldf['property_type'].value_counts(normalize=True))\nprint(mldf['property_type'].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The property_type variable specifies 26 unique values. Most of these occur with low frequency and are of little business interest or predictive value because they are so rare or peculiar e.g., 'Earth house' and 'Dome house.'\n\nMoreover, all these classes will have to be one-hot encoded for use in our predictive model. One-hot encoding is computationally demanding.\n\nTo simplify our model and improve its predictive utility, we will discard property types with freq < 5%."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Add a column that shows the proportion of listings represented by each property type:\n\nmldf[\"property_type_freq\"] = 1\nmldf[\"property_type_freq\"] = mldf.groupby('property_type').transform('count').div(len(mldf))\nmldf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Drop property types with normalized frequencies less than 5% and confirm the change:\n\nmldf = mldf[(mldf['property_type_freq'] >= 0.05)]\n\nprint(mldf['property_type'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['property_type'].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The change leaves us with 4 property types."},{"metadata":{"id":"ZAD0WeaxBKff","outputId":"9f693e7a-467f-467e-b280-78da67018201","trusted":true},"cell_type":"code","source":"# drop property_type_freq from dataframe and confirm its removal:\n\nmldf.drop('property_type_freq', axis=1, inplace=True)\nmldf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Compute the normalized frequency of each neighborhood in the dataframe:\n\nprint(mldf['neighbourhood_cleansed'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['neighbourhood_cleansed'].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 36 unique neighborhoods. This is a categorical variable, so all the values in this column will have to be one-hot encoded for the predictive model. This raises the same issue as was noted for the property type variable. \n\nTo help our model's performance and predictive utility, we will use freq = 2% as a cut-off."},{"metadata":{"trusted":true},"cell_type":"code","source":"mldf[\"neigh_freq\"] = 1\nmldf[\"neigh_freq\"] = mldf.groupby('neighbourhood_cleansed').transform('count').div(len(mldf))\nmldf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mldf = mldf[(mldf['neigh_freq'] >= 0.02)]\nprint(mldf['neighbourhood_cleansed'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['neighbourhood_cleansed'].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The change leaves us with 20 neighborhoods."},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop neigh_freq from dataframe and confirm its removal:\n\nmldf.drop('neigh_freq', axis=1, inplace=True)\nmldf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization\n\nGenerate a strip plot representation of the prices for each room type:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(11,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(2,1,1)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Entire home/apt\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Entire home/apt\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Entire home prices')\nplt.xticks(rotation=45, size=8, ha='right')\nplt.xlabel(\"\")\n\nplt.subplot(2,1,2)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Private room\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Private room prices')\nplt.xticks(rotation=45, size=8, ha='right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In each plot, most of the data points are clustered toward the bottom; ***a few extreme values make the overall price range higher than it would otherwise be.***\n\nPlot the distribution of prices with and without log transformation to examine the skewness:"},{"metadata":{"trusted":true},"cell_type":"code","source":"price_skew = mldf['price'].skew(axis = 0, skipna = True)\nlogprice_skew = (np.log(mldf.price)).skew(axis = 0, skipna = True)\n\nfig, ax =plt.subplots(1, 2, figsize=(16,4))\nchart1 = sns.distplot(mldf.price, ax=ax[0], color='b')\nchart1.set_xlabel('Price',fontsize=12)\nchart1.annotate(s=f'skew: {price_skew:.2f}', xy=(300, 200), xycoords='axes points')\nchart2 = sns.distplot(np.log(mldf.price), ax=ax[1], color='g')\nchart2.set_xlabel('log Price',fontsize=12)\nchart2.annotate(s=f'log price skew: {logprice_skew:.2f}', xy=(300, 200), xycoords='axes points')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Left panel**: The prices are very positively skewed, with skewness = 12.02. Normally distributed data have skewness = 0.\n\n**Right panel**: Log transformation helps lower the skew value. But it's still considerably greater than 0.\n\nLet's see the price ranges for the bottom 98% and top 2% for each room class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Top: price range of the bottom 98% of listings.')\nprint('Bottom: price range of the top 2% of listings.')\nprint('\\n')\n      \n# print(pd.qcut(cleandf['price'], q=[0, .98, 1]).value_counts(normalize=False))\n\nprint('Private room:')\nprint('\\n')\nprint(pd.qcut(mldf[mldf[\"room_type\"] == \"Private room\"]['price'], q=[0, .98, 1]).value_counts(normalize=False))\nprint('\\n')\nprint('Entire home:')\nprint('\\n')\nprint(pd.qcut(mldf[mldf[\"room_type\"] == \"Entire home/apt\"]['price'], q=[0, .98, 1]).value_counts(normalize=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extremely high price values are skewing the distribution. These rare/extraordinary prices are of little predictive value. \n\nTrim away the top 2% to eliminate the high-price extremes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mldf = mldf[((mldf['price'] <= 350) & (mldf[\"room_type\"] == \"Private room\")) | ((mldf['price'] <= 1000) & (mldf[\"room_type\"] == \"Entire home/apt\"))]\nmldf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regenerate the strip plots:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(11,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(2,1,1)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Entire home/apt\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Entire home/apt\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Entire home prices')\nplt.xticks(rotation=45, size=8, ha='right')\nplt.xlabel(\"\")\n\nplt.subplot(2,1,2)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Private room\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Private room prices')\nplt.xticks(rotation=45, size=8, ha='right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data points are now more spread out along the price axis and cover it more evenly.\n\nRe-plot the distributions and re-calculate the skew values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"price_skew = mldf['price'].skew(axis = 0, skipna = True)\nlogprice_skew = (np.log(mldf.price)).skew(axis = 0, skipna = True)\n\nfig, ax =plt.subplots(1, 2, figsize=(16,4))\nchart1 = sns.distplot(mldf.price, ax=ax[0], color='b')\nchart1.set_xlabel('Price',fontsize=12)\nchart1.annotate(s=f'skew: {price_skew:.2f}', xy=(300, 200), xycoords='axes points')\nchart2 = sns.distplot(np.log(mldf.price), ax=ax[1], color='g')\nchart2.set_xlabel('log Price',fontsize=12)\nchart2.annotate(s=f'log price skew: {logprice_skew:.2f}', xy=(300, 200), xycoords='axes points')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eliminating extreme prices from the data set lowered the skew values considerably. \n\nThe log skew value is below 0.5, so we will apply a log transformation to the prices before running our ML algorithm."},{"metadata":{},"cell_type":"markdown","source":"With the extreme high prices eliminated, let's graph the median prices by room type and neighborhood:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y1 = mldf[mldf[\"room_type\"] == \"Entire home/apt\"].groupby(['neighbourhood_cleansed']).median(['price'])\ny2 = mldf[mldf[\"room_type\"] == \"Private room\"].groupby(['neighbourhood_cleansed']).median(['price'])\n\n# get the counts as a dataframe\ny_df=pd.concat([y1,y2],axis=1)\ny_df.columns=['Entire Hm','Pvt Rm']\n\n\ny_df.index.name = 'index'\n\n# # melt the data frame so it has a \"tidy\" data format\ny_df=y_df.reset_index().melt(id_vars=['index'], var_name=\"room_type\",value_name=\"Median Price (US$)\")\ny_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_df_rm = y_df[y_df['room_type'] == 'Pvt Rm']\n\nf, ax = plt.subplots(figsize=(12, 3))\nplt.xticks(rotation=50, size=10, ha='right')\n\nplt.bar(height=\"Median Price (US$)\", x=\"index\", data=y_df, label=\"Total\", alpha = 0.5, color=\"darkorange\")\nplt.bar(height=\"Median Price (US$)\", x=\"index\", data=y_df_rm, label=\"Total\", alpha = 0.5, color=\"deepskyblue\")\n\nsns.despine(left=True, bottom=True)\nplt.legend(['Entire Home/Apt', 'Private Room'], loc=1)\nplt.title(label='Median Listing Price x Neighborhood')\nplt.xlabel(\"Neighborhood\")\nplt.ylabel(\"Median Price in US$\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we would expect, the median listing price for a private room is lower than for an entire home, regardless of neighbhorhood.\n\n\nNeighborhoods with high median listing prices include: Pacific Heights, Marina, Portrero Hill, Castro, South of Market, Western Addition, and Russian Hill."},{"metadata":{},"cell_type":"markdown","source":"Let's graph the data a different way to show the rank of each neighborhood by median listing price:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(1,2,1)\nmldf[mldf[\"room_type\"] == \"Entire home/apt\"].groupby([\"neighbourhood_cleansed\"])['price'].median().sort_values(ascending=True).plot.barh(color=\"skyblue\")\nplt.xticks(rotation=50, size=10, ha='right')\nplt.xlabel(\"Median Price in US$\")\nplt.title(label='Entire home/apt Median Prices')\n\nplt.subplot(1,2,2)\nmldf[mldf[\"room_type\"] == \"Private room\"].groupby([\"neighbourhood_cleansed\"])['price'].median().sort_values(ascending=True).plot.barh()\nplt.xticks(rotation=50, size=10, ha='right')\nplt.xlabel(\"Median Price in US$\")\nplt.ylabel(\"\")\nplt.title(label='Private room Median Prices')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For both room types, the Marina district commands the highest median price."},{"metadata":{},"cell_type":"markdown","source":"Next, graph number of listings per neighborhood, per room type:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\nax = sns.countplot(x=mldf[mldf[\"room_type\"] == \"Entire home/apt\"]['neighbourhood_cleansed'],\n             order = mldf['neighbourhood_cleansed'].value_counts().index, \n                   alpha=0.4, \n                   color='blue')\nplt.xticks(rotation=50, size=10, ha='right')\n\nsns.countplot(x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              ax=ax, \n              alpha=0.3, \n              color='green')\n\nplt.legend(['Entire Home/Apt', 'Private Room'], loc=1)\nplt.title(label='Number of listings per neighborhood')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see sharp disparities/imbalances in terms of the number of listings per room type: \n* Inner Sunset has the highest number of entire home listings but comparatively few private room listings.\n* Mission has the third highest number of entire home listings but the highest number of private room listings."},{"metadata":{},"cell_type":"markdown","source":"## ML/Prediction - Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Log transform the price data to reduce skew:\n\nmldf['price'] = np.log(mldf['price'])\ndisplay(mldf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's try to predict price:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = mldf.drop('price', axis=1)\ny = mldf['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The predictors must be preprocessed before they can be fed into the ML model:\n* The categorical features must be one-hot encoded.\n* The amenities text must be vectorized.\n\n#### To accomplish this, we will use two transformers:\n* #### One-hot encoder\n* #### Term-frequency times inverse document-frequency (Tfid) vectorizer\n\n#### **These will convert the categorical and text data to numerical representations that can be used by the algorithm.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = ['neighbourhood_cleansed', 'property_type', 'room_type']\ntext_features = ['amenities']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('text', TfidfVectorizer(), 'amenities'), \n        ('category', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n\nrfr = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regressor', RandomForestRegressor())])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=0)\n\nrfr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare the first 10 predictions from the model to the first 10 observations in the test data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rfr.predict(X_test)\n\nprint('First 10 predictions vs first 10 observations:')\n\nPrediction_Vs_Observation = {'pred': y_pred[0:10],\n                            'obs': y_test[0:10]}\n\nPvOdf = pd.DataFrame(Prediction_Vs_Observation).reset_index(drop=True)\ndisplay(PvOdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Compute the accuracy scores the model achieved for the training and test data sets:\n\nprint(f'The accuracy score of our Random Forest model on the training data: {rfr.score(X_train, y_train)}.')\nprint('\\n')\nprint(f'The accuracy score of our Random Forest model on the test data: {rfr.score(X_test, y_test)}.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remarks\n#### The prediction accuracy for the test data is considerably lower than for the training data. This suggests the model overfit the training data.\n\n#### However, it's important to keep in mind that this model is attempting to make numerical price predictions based on numerous combinations of categorical variables:\n* 20 neighborhoods\n* 4 property types\n* 2 room types\n* many different amenities\n\n#### This makes for a very challenging prediction task. \n#### One possible strategy for improving the accuracy and usefulness of the model would be to make the target, price, a categorical variable. \n#### This could be accomplished by binning the price data into bands/ranges. There would be a loss of resolution but a gain of accuracy."},{"metadata":{},"cell_type":"markdown","source":"### Did you find this notebook instructive or helpful? Please upvote below."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}