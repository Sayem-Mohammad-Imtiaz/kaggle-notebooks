{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Modelling motor insurance claim frequency\nUsing the French Motor Claims dataset as an example to work through predictive modelling considerations. It is designed to be run on a Kaggle Kernel here: <https://www.kaggle.com/btw78jt/models-of-french-motor-claims>"},{"metadata":{},"cell_type":"markdown","source":"<!-- This table of contents is updated *manually* -->\n# Contents\n1. [Setup](#Setup)\n1. [Modelling data](#Modelling-data): Load data, Pre-processing, Split for modelling\n1. [Modelling setup](#Model:-GLM): Setup modelling, Modelling notes, Useful functions, Mean model\n1. [Simple features model](#Simple-features-model): Fit and score, Visualise fit (Lift plot, Individual factors)\n1. [Feature selection](#Feature-selection): Simple factors, Engineered features\n1. [Proposed model](#Proposed-model): Fit and score, Visualise fit\n1. [Output results](#Output-results) Fit on all train, Score on all validation, Save\n1. [Rough work only](#Rough-work-only)"},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set warning messages\nimport warnings\n# Show all warnings in IPython\nwarnings.filterwarnings('always')\n# Ignore specific numpy warnings (as per <https://github.com/numpy/numpy/issues/11788#issuecomment-422846396>)\nwarnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\nwarnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n# Other warnings that sometimes come up\nwarnings.filterwarnings(\"ignore\", message=\"unclosed file <_io.TextIOWrapper\")\nwarnings.filterwarnings(\"ignore\", message=\"Anscombe residuals currently unscaled\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import built-in modules\nimport sys\nimport platform\nimport os\nfrom pathlib import Path\nimport string\n\n# Import external modules\nfrom IPython import __version__ as IPy_version\nimport IPython.display as ipyd\nimport numpy as np\nimport pandas as pd\nfrom sklearn import __version__ as skl_version\nfrom sklearn.model_selection import train_test_split\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom bokeh import __version__ as bk_version\nfrom scipy import __version__ as scipy_version\nfrom statsmodels import __version__ as sm_version\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom patsy import __version__ as patsy_version\n\n# Check they have loaded and the versions are as expected\nassert platform.python_version_tuple() == ('3', '6', '6')\nprint(f\"Python version:\\t\\t{sys.version}\")\nassert IPy_version == '7.13.0'\nprint(f'IPython version:\\t{IPy_version}')\nassert np.__version__ == '1.18.2'\nprint(f'numpy version:\\t\\t{np.__version__}')\nassert pd.__version__ == '0.25.3'\nprint(f'pandas version:\\t\\t{pd.__version__}')\nassert skl_version == '0.22.2.post1'\nprint(f'sklearn version:\\t{skl_version}')\nassert mpl.__version__ == '3.2.1'\nprint(f'matplotlib version:\\t{mpl.__version__}')\nassert bk_version == '2.0.1'\nprint(f'bokeh version:\\t\\t{bk_version}')\nassert scipy_version == '1.4.1'\nprint(f'scipy version:\\t\\t{scipy_version}')\nassert sm_version == '0.11.0'\nprint(f'statsmodels version:\\t{sm_version}')\nassert patsy_version == '0.5.1'\nprint(f'patsy version:\\t\\t{patsy_version}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bokeh imports\nfrom bokeh.layouts import gridplot\nfrom bokeh.plotting import figure, output_file, show, output_notebook\nfrom bokeh.models.ranges import Range1d\nfrom bokeh.models.axes import LinearAxis\n\n# Load Bokeh for use in a notebook\nfrom bokeh.io import output_notebook\noutput_notebook()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configuration variables\nclaims_data_filepath = Path('/kaggle/input/french-motor-claims-datasets-fremtpl2freq/freMTPL2freq.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output exact environment specification, in case it is needed later\nprint(\"Capturing full package environment spec\")\nprint(\"(But note that not all these packages are required)\")\n!pip freeze > requirements_Kaggle.txt\n!jupyter --version > jupyter_versions.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Modelling data"},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load full data set\nexpected_dtypes = {\n    **{col: np.dtype('int64') for col in [\n        'IDpol', 'ClaimNb', 'VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']},\n    **{col: np.dtype('float64') for col in ['Exposure']},\n    **{col: np.dtype('O') for col in ['Area', 'VehBrand', 'VehGas', 'Region']},\n}\ndf_raw = pd.read_csv(claims_data_filepath, delimiter=',', dtype=expected_dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check it has loaded OK\nnRows, nCols = (678013, 12)\nassert df_raw.shape == (nRows, nCols)\nprint(f\"Correct: Shape of DataFrame is as expected: {nRows} rows, {nCols} cols\")\nassert df_raw.dtypes.equals(pd.Series(expected_dtypes)[df_raw.columns])\nprint(\"Correct: Data types are as expected\")\nassert df_raw.isna().sum().sum() == 0\nprint(\"Correct: There are no missing values in the raw dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n## Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_df_extra(df):\n    \"\"\"\n    Given a DataFrame of that contains the raw data columns (and possibly additional columns), \n    return the DataFrame with additional pre-processed columns\n    \"\"\"\n    df_extra = df.copy()\n    \n    # Calculate frequency per year on each row\n    df_extra['Frequency'] = df_extra['ClaimNb'] / df_extra['Exposure']\n    \n    # Feature engineering (the results of the analysis below)\n    VehBrand_map_sers = pd.Series({\n        'B12': 'X', 'B14': 'X', 'B13': 'X',\n        'B3': 'X', 'B11': 'X','B4': 'X', 'B5': 'X',\n        'B1': 'Y', 'B6': 'Y',\n        'B2': 'Z', 'B10': 'Z'\n    })\n\n    Region_map_sers = pd.Series({\n        **{reg: 'W' for reg in ['R21', 'R94', 'R11', 'R42', 'R22', 'R74']},\n        **{reg: 'X' for reg in ['R91', 'R82']},\n        **{reg: 'Y' for reg in ['R93', 'R53']},\n        **{reg: 'Z' for reg in ['R26', 'R25', 'R52', 'R31', 'R54', 'R73', \n                                'R23', 'R72', 'R83', 'R41', 'R43']},\n        **{reg: 'A' for reg in ['R24']},\n    })\n\n    df_extra = df_extra.assign(\n        DrivAge_capped=lambda x: np.clip(x.DrivAge, None, 80),\n        DrivAge_pow2=lambda x: np.power(x.DrivAge_capped, 2),\n        BonusMalus_over_50=lambda x: np.select([x.BonusMalus > 50], [\"Y\"], default=\"N\"),\n        BonusMalus_mod3=lambda x: np.floor((np.clip(x.BonusMalus, None, 90) - 48)/3)*3 + 50,\n        VehAge_new=lambda x: np.select([x.VehAge == 0], [\"Y\"], default=\"N\"),\n        VehAge_capped=lambda x: np.clip(x.VehAge, None, 18),\n        VehBrand_grd=lambda x: VehBrand_map_sers.loc[x.VehBrand].values,\n        Density_log=lambda x: np.log10(np.clip(x.Density, 10, np.power(10, 4))),\n        Region_grd=lambda x: Region_map_sers.loc[x.Region].values,\n    )\n    \n    return(df_extra)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run pre-processing to get a new DataFrame\ndf_extra = get_df_extra(df_raw)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split for modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get index sorted with ascending IDpol, just in case it is out or order\ndf_all = df_extra.sort_values('IDpol').reset_index(drop=True)\n\n# Proportions we want to split in (must sum to 1)\nsplit_props = pd.Series({\n    'train': 0.7,\n    'validation': 0.15,\n    'holdout': 0.15\n})\n\n# Split out training data\ndf_train, df_not_train = train_test_split(\n    df_all, test_size=(1 - split_props['train']), random_state=51, shuffle=True\n)\n# Split remaining data between validation and holdout\ndf_validation, df_holdout = train_test_split(\n    df_not_train, test_size=split_props['holdout'] / (1 - split_props['train']), random_state=13, shuffle=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check all rows have been accounted for\npd.concat([df_train, df_validation, df_holdout]).sort_index().equals(df_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Modelling setup"},{"metadata":{},"cell_type":"markdown","source":"## Setup modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split training into train and test\ndf_train_mod, df_test_mod = train_test_split(\n    df_train, test_size=0.3, random_state=34, shuffle=True\n)\nprint(\"Train sample size: \" + str(df_train_mod.shape))\n\n# For testing code, we'll only use a small sample.\n# The object has the *same name*, so that *omitting* to run\n# this line will allow the same code to run on the full sample.\n# small_samp_size = int(1e4)\n# _, df_train_mod = train_test_split(\n#     df_train_mod, test_size=small_samp_size, random_state=90, shuffle=True\n# )\n# print(\"Small sample size: \" + str(df_train_mod.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View first few rows\ndf_train_mod.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expl_var_names = [\n    col_name for col_name in df_train_mod.columns.to_list() \n     if col_name not in ['IDpol', 'ClaimNb', 'Exposure', 'Frequency']\n]\nprint(\"Explanatory variables\\n\" + '\\t'.join(expl_var_names))\nsimple_features = expl_var_names[:9]\nprint(\"\\nOf which the following are simple features\\n\" + '\\t'.join(simple_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialise DataFrame for holding model info\nmods_df = pd.DataFrame(np.empty(0, dtype=np.dtype([\n    ('mod_name', np.dtype('O')),\n    ('descr', np.dtype('O')),\n    ('GLMResults', np.dtype('O')),\n])))\n\n# Dictionary of scores on the data\nscored_dfs = dict()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling notes\n\n#### Model specification\nWe want to use a Poisson GLM (with log link) to model expected number of claims per year, taking account of the fact that observations have variable exposure. The relevant `statsmodels` [documentation](https://www.statsmodels.org/devel/examples/notebooks/generated/glm_weights.html#aggregated-or-averaged-data-(unique-values-of-explanatory-variables)), shows that the following are equivalent ways of specifying such a model in `sm.GLM()`:\n\n1. With the response as the *sum* of claim counts (i.e. `ClaimNb`), and passing `exposure=data['Exposure']` (which is possible because we are using a log link).\n1. With response as the *mean* (i.e. frequency) of the claims per exposure (i.e. `freq_pyr`), and passing `var_weights=data['Exposure']`. \n\nFurther notes showing that these are equivalent are here: <https://www.kaggle.com/btw78jt/explaining-glms>\n\nWe'll use the first option here."},{"metadata":{},"cell_type":"markdown","source":"## Useful functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_data(data_df, GLMRes_obj):\n    raw_exog_names = pd.Series(GLMRes_obj.model.exog_names[1:]).str.split(\n        '[', expand=True, n=1).iloc[:,0].drop_duplicates().to_list()\n    scored_df = data_df.assign(\n        wgt=lambda x: x.Exposure,\n        act_freq=lambda x: x[GLMRes_obj.model.endog_names] / x.wgt,\n        pred_freq=lambda x: GLMRes_obj.predict(x[raw_exog_names]),\n        act_Nb=lambda x: x[GLMRes_obj.model.endog_names],\n        pred_Nb=lambda x: x.pred_freq * x.wgt,\n    )\n    return(scored_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cut_grps(df, cut_by, n_bins):\n    if isinstance(n_bins, int):\n        return(pd.cut(df[cut_by], bins=n_bins))\n    if n_bins == 'cat':\n        return(df[cut_by])\n    if n_bins == 'all':\n        bins = np.sort(df[cut_by].unique())\n        offset = np.min(np.diff(bins)) / 2\n        bins = np.insert(bins, 0, 2*bins[0] - bins[1]) + offset\n        return(pd.cut(df[cut_by], bins=bins))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_agg_plot_data(\n    data_df,\n    order_by = None,\n    cut_by = None,\n    x_axis_var = None,\n    n_bins = None,\n    set_config = None\n):\n    # Set defaults\n    if set_config == \"lift\":\n        if order_by is None:\n            order_by = 'pred_freq'\n        if cut_by is None:\n            cut_by = 'cum_wgt'\n        if x_axis_var is None:\n            x_axis_var = cut_by\n        if n_bins is None:\n            n_bins = 10\n    if cut_by is None:\n        cut_by = order_by\n    if x_axis_var is None:\n        x_axis_var = cut_by\n\n    plt_data_df = data_df\\\n    .rename_axis(index='index').sort_values([order_by, 'index']).assign(\n        cum_wgt_raw=lambda x: x.wgt.cumsum(),\n        cum_wgt=lambda x: x.groupby(order_by).cum_wgt_raw.transform('max'),\n        grp=lambda df: get_cut_grps(df, cut_by, n_bins)\n    ).groupby('grp', sort=False).agg(\n        n_obs=('grp', 'size'), \n        wgt_sum=('wgt', 'sum'),\n        act_Nb=('act_Nb', 'sum'),\n        pred_Nb=('pred_Nb', 'sum'),\n        x_min=(x_axis_var, 'min'),\n        x_max=(x_axis_var, 'max'),\n    ).pipe(lambda x: (\n        x.reset_index(drop=True).pipe(lambda x: (\n            x.set_index(pd.interval_range(start=-0.5, periods=x.shape[0], freq=1.))\n        )) if n_bins == 'cat' \n        else x.set_index(x.index.categories)\n    )).assign(\n        act_av=lambda x: x.act_Nb / x.wgt_sum,\n        pred_av=lambda x: x.pred_Nb / x.wgt_sum,\n        x_left=lambda x: np.select(\n            [x.x_min == x.x_max],\n            [x.index.left], \n            default=x.x_min\n        ),\n        x_right=lambda x: np.select(\n            [x.x_min == x.x_max],\n            [x.index.right],\n            default=x.x_max\n        ),\n        x_mid=lambda x: (x.x_right + x.x_left) / 2,\n    )\n    return(plt_data_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_plot(plt_data_df, n_bins = None):\n    bkplt = figure(\n        title=\"Predicted vs Actual chart\", x_axis_label='Pred val', y_axis_label=\"Exposure\", \n        tools=\"reset,box_zoom,pan,wheel_zoom,save\", background_fill_color=\"#fafafa\",\n        plot_width=800, plot_height=500\n    )\n    bkplt.quad(\n        top=plt_data_df.wgt_sum, bottom=0, left=plt_data_df.x_left, right=plt_data_df.x_right,\n        fill_color=\"khaki\", line_color=\"white\", legend_label=\"Exposure\"\n    )\n    bkplt.y_range=Range1d(0, plt_data_df.wgt_sum.max() / 0.5)\n\n    y_range2_name = 'y_range2_name'\n    bkplt.extra_y_ranges[y_range2_name] = Range1d(\n        plt_data_df[['act_av', 'pred_av']].min().min(), \n        plt_data_df[['act_av', 'pred_av']].max().max() / 0.9\n    )\n    ax_new = LinearAxis(y_range_name=y_range2_name, axis_label=\"Average response\")\n    bkplt.add_layout(ax_new, 'right')\n\n    for col_name, color in [('pred_av', 'purple'), ('act_av', 'green')]:\n        bkplt.circle(\n            plt_data_df.x_mid, plt_data_df[col_name], \n            color=color, size=4,\n            y_range_name=y_range2_name,\n            legend_label=col_name\n        )\n        bkplt.line(\n            plt_data_df.x_mid, plt_data_df[col_name], \n            color=color, # size=4,\n            y_range_name=y_range2_name,\n            legend_label=col_name\n        )\n\n    bkplt.grid.grid_line_color = \"white\"\n    bkplt.legend.location = \"top_left\"\n    bkplt.legend.click_policy=\"hide\"\n\n    if n_bins == \"cat\":\n        x_tick_labs = plt_data_df.x_min.astype(str).reset_index(drop=True).to_dict()\n        bkplt.xaxis.ticker = list(x_tick_labs.keys())\n        bkplt.xaxis.major_label_overrides = x_tick_labs\n    \n    return(bkplt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cat_map_ordered(df, cat_col_name, order_by='act_av_freq'):\n    res = df.groupby(cat_col_name).agg(\n        n_obs=(cat_col_name, 'size'),\n        wgt_sum=('Exposure', 'sum'),\n        act_Nb=('ClaimNb', 'sum'),\n    ).assign(\n        act_av_freq=lambda x: x.act_Nb / x.wgt_sum\n    ).sort_values(\n        [order_by], ascending=False\n    ).assign(\n        all_levels=lambda x: x.reset_index().index\n    )\n    return(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mean model\nJust for checking that the code is working for the simplest case."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nGLMRes_obj = smf.glm(\n    \"ClaimNb ~ 1\",\n    data=df_train_mod, exposure=np.asarray(df_train_mod['Exposure']),\n    family=sm.families.Poisson(sm.genmod.families.links.log()),\n).fit()\nprint(GLMRes_obj.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check that this is the mean model\nmean_mod_pred = np.exp(GLMRes_obj.params[0])\nassert np.abs(\n    GLMRes_obj.family.link.inverse(GLMRes_obj.params[0]) - \n    GLMRes_obj.predict(pd.DataFrame([1]))[0]\n) < 1e-10\nassert np.abs(\n    df_train_mod.ClaimNb.sum() / df_train_mod.Exposure.sum() - \n    mean_mod_pred\n) < 1e-10\nprint(\"Correct: Reasonableness tests have passed\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Simple features model"},{"metadata":{},"cell_type":"markdown","source":"## Fit and score"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Takes approx 20 secs\nmods_df.loc[0, ['mod_name', 'descr']] = [\n    'All_simple_features', \n    'All simple features'\n]\nmods_df.GLMResults[0] = smf.glm(\n    \"ClaimNb ~ \" +  ' + '.join(simple_features),\n    data=df_train_mod, exposure=np.asarray(df_train_mod['Exposure']),\n    family=sm.families.Poisson(sm.genmod.families.links.log()),\n).fit()\nprint(mods_df.GLMResults[0].summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Score all the training data for analysis\n# Takes under 10 secs\nscored_dfs[0] = score_data(df_train, mods_df.GLMResults[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reasonableness checks\nassert np.abs(scored_dfs[0].act_Nb.sum() - df_train.ClaimNb.sum()) < 1e-7\nassert np.abs(scored_dfs[0].wgt.sum() - df_train.Exposure.sum()) < 1e-7\nprint(\"Correct: Reasonableness checks pass\\n\")\nprint(f\"Predicted number of claims:\\t{scored_dfs[0].pred_Nb.sum():,.1f}\")\nprint(f\"Actual number of claims:\\t{scored_dfs[0].ClaimNb.sum():,.1f}\")\nprint(f\"Difference:\\t\\t\\t{scored_dfs[0].pred_Nb.sum() - scored_dfs[0].ClaimNb.sum():,.1f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualise fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample data for visualisations\ndf_extra_for_plt = scored_dfs[0].loc[\n    # Data not used for training\n    ~scored_dfs[0].index.isin(df_train_mod.index), :\n#].iloc[:int(1e5), :  # Limit the number of rows for the plot\n].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checks\nprint(\"Number of rows\")\nprint(\n    \"Scored minus train_mod size:\\t\" + \n    str(scored_dfs[0].shape[0] - df_train_mod.shape[0])\n)\nprint(\"Test_mod size:\\t\\t\\t\" + str(df_test_mod.shape[0]))\nprint(\"Data for plots size:\\t\\t\" + str(df_extra_for_plt.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lift plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_plt_data_df = get_agg_plot_data(df_extra_for_plt, set_config = \"lift\")\nlift_plt = create_plot(lift_plt_data_df)\nshow(lift_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_actuals = lift_plt_data_df.act_av.iloc[-1] / lift_plt_data_df.act_av.iloc[0]\nlift_pred = lift_plt_data_df.pred_av.iloc[-1] / lift_plt_data_df.pred_av.iloc[0]\nprint(f'Lift on actuals:\\t{lift_actuals:.3f}')\nprint(f'Lift on predicted:\\t{lift_pred:.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Individual factors\nIn the following, I interactively examined each factor. Only the final plot is shown, and I've recorded some decisions to refine the feature engineering."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ordering and bucketing categorical variables\nArea_map_df = get_cat_map_ordered(df_extra_for_plt, 'Area')\nRegion_map_df = get_cat_map_ordered(df_extra_for_plt, 'Region')\nVehBrand_map_df = get_cat_map_ordered(df_extra_for_plt, 'VehBrand')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Policy holder factors"},{"metadata":{},"cell_type":"markdown","source":"#### DrivAge\n- Cap at high values due to low exposure.\n- Not doing a good job at low ages (under 25). Try adding a quadratic term to the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"indiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt.assign(\n        DrivAge_capped=lambda x: np.clip(x.DrivAge, None, 80)\n    ),\n    order_by = 'DrivAge_capped', #cut_by = 'cum_wgt', x_axis_var = 'DrivAge',\n    n_bins = 'all'\n)\nindiv_plt = create_plot(indiv_plt_data_df)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### BonusMalus\n- Majority of weight is on one value (50). And predictions are not extreme enough on this split. Add a binary variable. \n- Long tail - cap at around 90.\n- Other than that, values of multiple of 3 seem to be more popular. Possibly an increasing trend in that section."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_bins = 'all'\nindiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt.query(\"BonusMalus > 50\").assign(\n        BonusMalus_over_50=lambda x: np.select([x.BonusMalus > 50], [\"Y\"], default=\"N\"),\n        BonusMalus_capped=lambda x: np.clip(x.BonusMalus, None, 90),\n        BonusMalus_mod3=lambda x: np.floor((x.BonusMalus_capped - 48)/3)*3 + 50,\n    ),\n    order_by = 'BonusMalus_mod3', #cut_by = 'cum_wgt', x_axis_var = 'BonusMalus',\n    n_bins = n_bins\n)\nindiv_plt = create_plot(indiv_plt_data_df, n_bins=n_bins)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vehicle factors"},{"metadata":{},"cell_type":"markdown","source":"#### VehAge\n- Cap at high values due to low exposure.\n- Not doing a good job for the lowest age. Arguably flat after this value. Add a binary factor (although there isn't much exposure here)."},{"metadata":{"trusted":true},"cell_type":"code","source":"indiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt.assign(\n        VehAge_new=lambda x: np.select([x.VehAge == 0], [\"Y\"], default=\"N\"),\n        VehAge_capped=lambda x: np.clip(x.VehAge, None, 18),\n    ),\n    order_by = 'VehAge_capped', #cut_by = 'cum_wgt', x_axis_var = 'DrivAge',\n    n_bins = 'all'\n)\nindiv_plt = create_plot(indiv_plt_data_df)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VehBrand\nSome levels with low exposure. It is, however, difficult to group into levels with that are reasonably equally weighted, in a specified order (e.g. with actual frequency). Ended up going for 3 levels."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_grps = 3\nVehBrand_map_df = VehBrand_map_df.assign(\n    cum_wgt=lambda x: x.wgt_sum.cumsum(),\n    grps=lambda x: pd.cut(\n        x.cum_wgt, bins=n_grps, \n        labels=[letter for letter in string.ascii_uppercase[(-n_grps):]]\n    ).astype(str)\n)\n\nn_bins = 'cat'\nindiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt.assign(\n        VehBrand_ord=lambda x: VehBrand_map_df.all_levels.loc[x.VehBrand].values,\n        VehBrand_grd=lambda x: VehBrand_map_df.grps.loc[x.VehBrand].values,\n    ),\n    order_by = 'VehBrand_grd', #cut_by = 'VehBrand_grd', #x_axis_var = 'BonusMalus',\n    n_bins = n_bins\n)\nindiv_plt = create_plot(indiv_plt_data_df, n_bins=n_bins)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print out groups to use\nprint(\"{\" + \", \".join([\n    f\"'{grp}': '{grp_code}'\" for grp, grp_code \n    in VehBrand_map_df.grps.to_dict().items()\n]) + \"}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check against the hard-coded feature\n# Any difference should be small (e.g. in the smallest levels by wgt)\nVehBrand_map_df.merge(\n    df_extra_for_plt[[\n        'VehBrand', 'VehBrand_grd']].drop_duplicates(\n        ).set_index('VehBrand'),\n    how=\"outer\", left_index=True, right_index=True\n).assign(\n    same_allocation=lambda x: x.VehBrand_grd == x.grps\n).sort_values('all_levels')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VehGas\nThe factor only has two levels, but the model is not matching well (although the range is small). Suggests trying interaction with `VehBrand`, but I'm not going to try interactions at this stage."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_bins = 'cat'\nindiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt,\n    order_by = 'VehGas', #cut_by = 'VehBrand_grd', #x_axis_var = 'BonusMalus',\n    n_bins = n_bins\n)\nindiv_plt = create_plot(indiv_plt_data_df, n_bins=n_bins)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Location factors"},{"metadata":{},"cell_type":"markdown","source":"#### Area\nSeems to be a trend in the actuals, and the buckets are reasonably well spread. Leave it as is."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_bins = 'cat'\nindiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt.assign(\n        Area_ord=lambda x: Area_map_df.all_levels.loc[x.Area].values,\n    ),\n    order_by = 'Area_ord', #cut_by = 'VehBrand_grd', #x_axis_var = 'BonusMalus',\n    n_bins = n_bins\n)\nindiv_plt = create_plot(indiv_plt_data_df, n_bins=n_bins)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Density\nA very wide range of values with a long tail. Try logging and clipping the extremes. Although the predicted values follow the actuals pretty well."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_bins = 20\nindiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt.assign(\n        Density_log=lambda x: np.log10(np.clip(x.Density, 10, np.power(10, 4))),\n    ),\n    order_by = 'Density_log', #cut_by = 'cum_wgt', x_axis_var = 'Density_log',\n    n_bins = n_bins\n)\nindiv_plt = create_plot(indiv_plt_data_df, n_bins=n_bins)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Region\nUneven distribution over regions suggests some grouping. This seems to be easier than for `VehBrand` - settled on 4 groups as a reasonable number."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_grps = 4\nRegion_map_df = Region_map_df.assign(\n    cum_wgt=lambda x: x.wgt_sum.cumsum(),\n    grps=lambda x: pd.cut(\n        x.cum_wgt, bins=n_grps, \n        labels=[letter for letter in string.ascii_uppercase[(-n_grps):]]\n    ).astype(str),\n    manual_grps=pd.Series({\n        **{reg: 'W' for reg in ['R21', 'R94', 'R11', 'R42', 'R22', 'R74']},\n        **{reg: 'X' for reg in ['R91', 'R82']},\n        **{reg: 'Y' for reg in ['R93', 'R53']},\n        **{reg: 'Z' for reg in ['R26', 'R25', 'R52', 'R31', 'R54', 'R73', \n                                'R23', 'R72', 'R83', 'R41', 'R43']},\n        **{reg: 'A' for reg in ['R24']},\n    })\n)\n\nn_bins = 'cat'\nindiv_plt_data_df = get_agg_plot_data(\n    df_extra_for_plt.assign(\n        Region_ord=lambda x: Region_map_df.all_levels.loc[x.Region].values,\n        Region_grd=lambda x: Region_map_df.manual_grps.loc[x.Region].values,\n    ),\n    order_by = 'Region_grd', #cut_by = 'VehBrand_grd', #x_axis_var = 'BonusMalus',\n    n_bins = n_bins\n)\nindiv_plt = create_plot(indiv_plt_data_df, n_bins=n_bins)\nshow(indiv_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print out groups to use\nprint('\\n'.join([\n    f\"**{{reg: '{code}' for reg in {grps}}},\" for\n    code, grps in Region_map_df.reset_index().groupby('grps').agg({\n        'Region': lambda x: [reg for reg in x]\n    }).Region.to_dict().items()\n]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check against the hard-coded feature\n# Any difference should be small (e.g. in the smallest levels by wgt)\nRegion_map_df.merge(\n    df_extra_for_plt[[\n        'Region', 'Region_grd']].drop_duplicates(\n        ).set_index('Region'),\n    how=\"outer\", left_index=True, right_index=True\n).assign(\n    same_allocation=lambda x: x.Region_grd == x.manual_grps\n).sort_values('all_levels').style.bar(subset=['wgt_sum', 'act_av_freq'], color='#d65f5f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Feature selection\nTry selecting simple factors in stepwise regression using AIC. We want to *minimise* the AIC."},{"metadata":{"trusted":true},"cell_type":"code","source":"# The modelling is quite intensive on memory,\n# so we need to limit the amount of data used\n_, data_swreg_df = train_test_split(\n    df_train_mod, test_size=0.5, random_state=98, shuffle=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_candidate(\n    selected, candidate, \n    n_step, n_iter, # Adds these values to the model list\n    mods_swreg_df, # Add results to this model list\n    data_swreg_df, # Use this data set\n    direction = None, verbose = True\n):\n    \"\"\"Fit a model with an additional 'candidate' factor\"\"\"\n    if direction is None:\n        direction = 'fwd'\n    \n    if direction == 'fwd':\n        if candidate is \"None\":\n            factors_ls = selected\n        else:\n            factors_ls = selected + [candidate]\n    else:\n        factors_ls = selected.copy()\n        if candidate is not \"None\":\n            factors_ls.remove(candidate)\n    \n    mods_swreg_df.loc[n_iter, ['step', 'candidate', 'rhs_str']] = [\n        n_step,\n        candidate,\n        ' + '.join(['1'] + factors_ls)\n    ]\n\n    GLMRes_tmp = smf.glm(\n        \"ClaimNb ~ \" + mods_swreg_df.loc[n_iter, 'rhs_str'],\n        data=data_swreg_df,\n        exposure=np.asarray(data_swreg_df['Exposure']),\n        family=sm.families.Poisson(sm.genmod.families.links.log()),\n    ).fit()\n\n    mods_swreg_df.loc[n_iter, 'aic'] = GLMRes_tmp.aic\n    mods_swreg_df.loc[n_iter, 'df_model'] = GLMRes_tmp.df_model\n    GLMRes_tmp.remove_data() # Clear up to save RAM\n    mods_swreg_df.loc[n_iter, 'GLMResults'] = GLMRes_tmp\n    \n    if verbose:\n        print(\n            f\"Iter: {n_iter:<2}\\t\"\n            f\"Candidate: {candidate:<10}\\t\"\n            f\"AIC: {mods_swreg_df.loc[n_iter, 'aic']:.1f}\"\n        )\n\n    return(mods_swreg_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialise DataFrame for holding model info\nmods_swreg_df = pd.DataFrame(np.empty(int(0), dtype=np.dtype([\n    ('step', np.dtype('int64')),\n    ('candidate', np.dtype('O')),\n    ('rhs_str', np.dtype('O')),\n    ('GLMResults', np.dtype('O')),\n    ('df_model', np.dtype('int64')),\n    ('aic', np.dtype('float64')),\n])))\n\nn_iter = 0\nn_step = 0\nremaining = simple_features.copy()\ndirection = 'fwd'\nif direction == 'fwd':\n    selected = []\nelse:\n    selected = remaining.copy()\ngo_to_next_step = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nrun_this_chunk = True\nif run_this_chunk:\n\n    # The below loop does not cover the initial model\n    # Takes approx 4 mins\n    mods_swreg_df = fit_candidate(\n        selected=selected, candidate=\"None\", n_step=n_step, n_iter=n_iter,\n        mods_swreg_df=mods_swreg_df, data_swreg_df=data_swreg_df,\n        direction=direction, verbose=True\n    )\n\n    while remaining and go_to_next_step:\n        n_step += 1\n        go_to_next_step = False\n        print(\n            f\"==== Step {n_step:02} ====\\n\"\n            f\"Already selected: {', '.join(selected)}\\n\"\n            f\"Remaining: {', '.join(remaining)}\"\n        )\n\n        for candidate in remaining:\n            n_iter += 1\n            mods_swreg_df = fit_candidate(\n                selected, candidate, n_step, n_iter,\n                mods_swreg_df, data_swreg_df,\n                direction=direction, verbose=True\n            )\n\n        mods_swreg_df = mods_swreg_df.sort_values(\n            ['step', 'aic', 'rhs_str']).reset_index(drop=True)\n        best_aic_so_far = mods_swreg_df.aic.min()\n        best_in_step = mods_swreg_df.query(f\"step == {n_step}\")[['candidate', 'aic']].iloc[0]\n\n        if best_in_step.aic == best_aic_so_far:\n            if direction == 'fwd':\n                selected.append(best_in_step.candidate)\n            else:\n                selected.remove(best_in_step.candidate)\n            remaining.remove(best_in_step.candidate)\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: {best_in_step.candidate:<10} \"\n                f\"(AIC: {best_in_step.aic:.1f})\"\n            )\n            go_to_next_step = True\n        else:\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: None\\n\"\n                f\"==== Stepwise regression complete ====\"\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save and view results\nif run_this_chunk:\n    mods_fw_swreg_df = mods_swreg_df.copy()\n    best_mod = mods_fw_swreg_df.query(\"aic == @mods_fw_swreg_df.aic.min()\").iloc[0]\n    print(\"Best model for forward regression:\")\n    print(\"-\" * 40)\n    print(\n        \"Formula:\\t\" + best_mod.rhs_str + \"\\n\"\n        f\"aic:\\t\\t{best_mod.aic:.2f}\\n\"\n        f\"df_model:\\t{int(best_mod.df_model)}\"\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialise DataFrame for holding model info\nmods_swreg_df = pd.DataFrame(np.empty(int(0), dtype=np.dtype([\n    ('step', np.dtype('int64')),\n    ('candidate', np.dtype('O')),\n    ('rhs_str', np.dtype('O')),\n    ('GLMResults', np.dtype('O')),\n    ('df_model', np.dtype('int64')),\n    ('aic', np.dtype('float64')),\n])))\n\nn_iter = 0\nn_step = 0\nremaining = simple_features.copy()\ndirection = 'bwd'\nif direction == 'fwd':\n    selected = []\nelse:\n    selected = remaining.copy()\ngo_to_next_step = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nrun_this_chunk = True\nif run_this_chunk:\n\n    # The below loop does not cover the initial model\n    # Takes approx 5 mins\n    mods_swreg_df = fit_candidate(\n        selected=selected, candidate=\"None\", n_step=n_step, n_iter=n_iter,\n        mods_swreg_df=mods_swreg_df, data_swreg_df=data_swreg_df,\n        direction=direction, verbose=True\n    )\n\n    while remaining and go_to_next_step:\n        n_step += 1\n        go_to_next_step = False\n        print(\n            f\"==== Step {n_step:02} ====\\n\"\n            f\"Already selected: {', '.join(selected)}\\n\"\n            f\"Remaining: {', '.join(remaining)}\"\n        )\n\n        for candidate in remaining:\n            n_iter += 1\n            mods_swreg_df = fit_candidate(\n                selected, candidate, n_step, n_iter,\n                mods_swreg_df, data_swreg_df,\n                direction=direction, verbose=True\n            )\n\n        mods_swreg_df = mods_swreg_df.sort_values(\n            ['step', 'aic', 'rhs_str']).reset_index(drop=True)\n        best_aic_so_far = mods_swreg_df.aic.min()\n        best_in_step = mods_swreg_df.query(f\"step == {n_step}\")[['candidate', 'aic']].iloc[0]\n\n        if best_in_step.aic == best_aic_so_far:\n            if direction == 'fwd':\n                selected.append(best_in_step.candidate)\n            else:\n                selected.remove(best_in_step.candidate)\n            remaining.remove(best_in_step.candidate)\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: {best_in_step.candidate:<10} \"\n                f\"(AIC: {best_in_step.aic:.1f})\"\n            )\n            go_to_next_step = True\n        else:\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: None\\n\"\n                f\"==== Stepwise regression complete ====\"\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save results\nif run_this_chunk:\n    mods_bw_swreg_df = mods_swreg_df.copy()\n    best_mod = mods_bw_swreg_df.query(\"aic == @mods_bw_swreg_df.aic.min()\").iloc[0]\n    print(\"Best model for backward regression:\")\n    print(\"-\" * 40)\n    print(\n        \"Formula:\\t\" + best_mod.rhs_str + \"\\n\"\n        f\"aic:\\t\\t{best_mod.aic:.2f}\\n\"\n        f\"df_model:\\t{int(best_mod.df_model)}\"\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add selected model to list"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Takes approx 20 secs\nmods_df.loc[1, ['mod_name', 'descr']] = [\n    'Selected simple features', \n    'Following forward and backward stepwise regression'\n]\nmods_df.GLMResults[1] = smf.glm(\n    \"ClaimNb ~ 1 + \" + \" + \".join(  # <<< Manually specify the factors\n        [fac for fac in simple_features if not fac in [\"Density\", \"VehGas\"]]),\n    data=df_train_mod, exposure=np.asarray(df_train_mod['Exposure']),\n    family=sm.families.Poisson(sm.genmod.families.links.log()),\n).fit()\nprint(mods_df.GLMResults[1].summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clear memory of unrequired objects\nmods_bw_swreg_df = None\nmods_fw_swreg_df = None\nmods_swreg_df = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Score data for analysis\n# Takes under 10 secs\nscored_dfs[1] = score_data(df_train, mods_df.GLMResults[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reasonableness checks\nassert np.abs(scored_dfs[1].act_Nb.sum() - df_train.ClaimNb.sum()) < 1e-7\nassert np.abs(scored_dfs[1].wgt.sum() - df_train.Exposure.sum()) < 1e-7\nprint(\"Correct: Reasonableness checks pass\\n\")\nprint(f\"Predicted number of claims:\\t{scored_dfs[1].pred_Nb.sum():,.1f}\")\nprint(f\"Actual number of claims:\\t{scored_dfs[1].ClaimNb.sum():,.1f}\")\nprint(f\"Difference:\\t\\t\\t{scored_dfs[1].pred_Nb.sum() - scored_dfs[1].ClaimNb.sum():,.1f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Engineered features\nConsider adding these in one at a time. Can we improve AIC?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# These are the engineered features\ndf_train_mod.loc[:,'Frequency':].iloc[:,1:].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose between the simple and engineered features\nremaining = [\n    'DrivAge_capped', 'DrivAge_pow2', \n    'BonusMalus_over_50', 'BonusMalus_mod3', \n    'VehAge_new', 'VehAge_capped', \n    'VehBrand_grd',\n    'Density_log', \n    'Region_grd'\n] + [fac for fac in simple_features if not fac in [\n    # These factors are superseded by their engineered versions\n    \"DrivAge\", \"BonusMalus\", \"VehAge\",\n    \"VehBrand\", \"Region\", \"Density\", \n    # And not including these factors\n    \"VehGas\"\n]]\n\n# Initialise DataFrame for holding model info\nmods_swreg_df = pd.DataFrame(np.empty(int(0), dtype=np.dtype([\n    ('step', np.dtype('int64')),\n    ('candidate', np.dtype('O')),\n    ('rhs_str', np.dtype('O')),\n    ('GLMResults', np.dtype('O')),\n    ('df_model', np.dtype('int64')),\n    ('aic', np.dtype('float64')),\n])))\n\nn_iter = 0\nn_step = 0\ndirection = 'fwd'\nif direction == 'fwd':\n    selected = []\nelse:\n    selected = remaining.copy()\ngo_to_next_step = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nrun_this_chunk = True\nif run_this_chunk:\n    # Takes approx 4 mins\n    # The below loop does not cover the initial model\n    mods_swreg_df = fit_candidate(\n        selected=selected, \n        candidate=\"None\", n_step=n_step, n_iter=n_iter,\n        mods_swreg_df=mods_swreg_df, data_swreg_df=data_swreg_df,\n        direction=direction, verbose=True\n    )\n\n    while remaining and go_to_next_step:\n        n_step += 1\n        go_to_next_step = False\n        print(\n            f\"==== Step {n_step:02} ====\\n\"\n            f\"Already selected: {', '.join(selected)}\\n\"\n            f\"Remaining: {', '.join(remaining)}\"\n        )\n\n        for candidate in remaining:\n            n_iter += 1\n            mods_swreg_df = fit_candidate(\n                selected, candidate, n_step, n_iter,\n                mods_swreg_df, data_swreg_df,\n                direction=direction, verbose=True\n            )\n\n        mods_swreg_df = mods_swreg_df.sort_values(\n            ['step', 'aic', 'rhs_str']).reset_index(drop=True)\n        best_aic_so_far = mods_swreg_df.aic.min()\n        best_in_step = mods_swreg_df.query(f\"step == {n_step}\")[['candidate', 'aic']].iloc[0]\n\n        if best_in_step.aic == best_aic_so_far:\n            if direction == 'fwd':\n                selected.append(best_in_step.candidate)\n            else:\n                selected.remove(best_in_step.candidate)\n            remaining.remove(best_in_step.candidate)\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: {best_in_step.candidate:<10} \"\n                f\"(AIC: {best_in_step.aic:.1f})\"\n            )\n            go_to_next_step = True\n        else:\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: None\\n\"\n                f\"==== Stepwise regression complete ====\"\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save and view results\nif run_this_chunk:\n    mods_fw_swreg_extra_df = mods_swreg_df.copy()\n    best_mod = mods_fw_swreg_extra_df.query(\"aic == @mods_fw_swreg_extra_df.aic.min()\").iloc[0]\n    print(\"Best model for forward regression:\")\n    print(\"-\" * 40)\n    print(\n        \"Formula:\\t\" + best_mod.rhs_str + \"\\n\"\n        f\"aic:\\t\\t{best_mod.aic:.2f}\\n\"\n        f\"df_model:\\t{int(best_mod.df_model)}\"\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The same but backward from all factors\nremaining = [\n    'DrivAge_capped', 'DrivAge_pow2', \n    'BonusMalus_over_50', 'BonusMalus_mod3', \n    'VehAge_new', 'VehAge_capped', \n    'VehBrand_grd',\n    'Density_log', \n    'Region_grd'\n] + [fac for fac in simple_features if not fac in [\n    # These factors are superseded by their engineered versions\n    \"DrivAge\", \"BonusMalus\", \"VehAge\",\n    \"VehBrand\", \"Region\", \"Density\", \n    # And not including these factors\n    \"VehGas\"\n]]\n\n# Initialise DataFrame for holding model info\nmods_swreg_df = pd.DataFrame(np.empty(int(0), dtype=np.dtype([\n    ('step', np.dtype('int64')),\n    ('candidate', np.dtype('O')),\n    ('rhs_str', np.dtype('O')),\n    ('GLMResults', np.dtype('O')),\n    ('df_model', np.dtype('int64')),\n    ('aic', np.dtype('float64')),\n])))\n\nn_iter = 0\nn_step = 0\ndirection = 'bwd' # <<<<<<<<< Direction of stepwise regression\nif direction == 'fwd':\n    selected = []\nelse:\n    selected = remaining.copy()\ngo_to_next_step = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nrun_this_chunk = True\nif run_this_chunk:\n    # The below loop does not cover the initial model\n    # Takes approx 2 mins\n    mods_swreg_df = fit_candidate(\n        selected=selected, \n        candidate=\"None\", n_step=n_step, n_iter=n_iter,\n        mods_swreg_df=mods_swreg_df, data_swreg_df=data_swreg_df,\n        direction=direction, verbose=True\n    )\n\n    while remaining and go_to_next_step:\n        n_step += 1\n        go_to_next_step = False\n        print(\n            f\"==== Step {n_step:02} ====\\n\"\n            f\"Already selected: {', '.join(selected)}\\n\"\n            f\"Remaining: {', '.join(remaining)}\"\n        )\n\n        for candidate in remaining:\n            n_iter += 1\n            mods_swreg_df = fit_candidate(\n                selected, candidate, n_step, n_iter,\n                mods_swreg_df, data_swreg_df,\n                direction=direction, verbose=True\n            )\n\n        mods_swreg_df = mods_swreg_df.sort_values(\n            ['step', 'aic', 'rhs_str']).reset_index(drop=True)\n        best_aic_so_far = mods_swreg_df.aic.min()\n        best_in_step = mods_swreg_df.query(f\"step == {n_step}\")[['candidate', 'aic']].iloc[0]\n\n        if best_in_step.aic == best_aic_so_far:\n            if direction == 'fwd':\n                selected.append(best_in_step.candidate)\n            else:\n                selected.remove(best_in_step.candidate)\n            remaining.remove(best_in_step.candidate)\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: {best_in_step.candidate:<10} \"\n                f\"(AIC: {best_in_step.aic:.1f})\"\n            )\n            go_to_next_step = True\n        else:\n            print(\n                f\"Step {n_step:02} \"\n                f\"selected: None\\n\"\n                f\"==== Stepwise regression complete ====\"\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save and view results\nif run_this_chunk:\n    mods_bw_swreg_extra_df = mods_swreg_df.copy()\n    best_mod = mods_bw_swreg_extra_df.query(\"aic == @mods_bw_swreg_extra_df.aic.min()\").iloc[0]\n    print(\"Best model for backward regression:\")\n    print(\"-\" * 40)\n    print(\n        \"Formula:\\t\" + best_mod.rhs_str + \"\\n\"\n        f\"aic:\\t\\t{best_mod.aic:.2f}\\n\"\n        f\"df_model:\\t{int(best_mod.df_model)}\"\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again the selected models are the same, this time containing *all* the factors. We'll need to apply some judgement to choose the factors that go into the proposed model."},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Proposed model"},{"metadata":{},"cell_type":"markdown","source":"## Fit and score"},{"metadata":{"trusted":true},"cell_type":"code","source":"chosen_factors = [\n    'DrivAge_capped', 'DrivAge_pow2', \n    'BonusMalus_over_50', 'BonusMalus_mod3', \n    'VehAge_new', 'VehAge_capped', \n    'VehBrand_grd',\n    'Density_log', \n    'Region_grd'\n] + [fac for fac in simple_features if not fac in [\n    # These factors are superseded by their engineered versions\n    \"DrivAge\", \"BonusMalus\", \"VehAge\",\n    \"VehBrand\", \"Region\", \"Density\", \n    # And not including these factors\n    \"VehGas\"\n]]\nchosen_factors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Takes approx 20 secs\nmods_df.loc[2, ['mod_name', 'descr']] = [\n    'Proposed model', \n    'Following assessment of engineered features'\n]\nmods_df.GLMResults[2] = smf.glm(\n    \"ClaimNb ~ 1 + \" + \" + \".join(  # <<< Manually specify the factors\n        chosen_factors\n    ),\n    data=df_train_mod, exposure=np.asarray(df_train_mod['Exposure']),\n    family=sm.families.Poisson(sm.genmod.families.links.log()),\n).fit()\nprint(mods_df.GLMResults[2].summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clear memory of unrequired objects\nmods_fw_swreg_extra_df = None\nmods_bw_swreg_extra_df = None\nmods_swreg_df = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Score data for analysis\n# Takes under 10 secs\nscored_dfs[2] = score_data(df_train, mods_df.GLMResults[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reasonableness checks\nassert np.abs(scored_dfs[2].act_Nb.sum() - df_train.ClaimNb.sum()) < 1e-7\nassert np.abs(scored_dfs[2].wgt.sum() - df_train.Exposure.sum()) < 1e-7\nprint(\"Correct: Reasonableness checks pass\\n\")\nprint(f\"Predicted number of claims:\\t{scored_dfs[2].pred_Nb.sum():,.1f}\")\nprint(f\"Actual number of claims:\\t{scored_dfs[2].ClaimNb.sum():,.1f}\")\nprint(f\"Difference:\\t\\t\\t{scored_dfs[2].pred_Nb.sum() - scored_dfs[2].ClaimNb.sum():,.1f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualise fit\nThe model with selected simple features, and then the proposed model."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_for_plt1 = scored_dfs[1].loc[\n    scored_dfs[1].index.isin(df_test_mod.index), :\n]\nassert df_for_plt1.shape[0] == df_test_mod.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_plt_data_df = get_agg_plot_data(df_for_plt1, set_config = \"lift\")\nlift_plt = create_plot(lift_plt_data_df)\nshow(lift_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_actuals = lift_plt_data_df.act_av.iloc[-1] / lift_plt_data_df.act_av.iloc[0]\nlift_pred = lift_plt_data_df.pred_av.iloc[-1] / lift_plt_data_df.pred_av.iloc[0]\nprint(f'Lift on actuals:\\t{lift_actuals:.3f}')\nprint(f'Lift on predicted:\\t{lift_pred:.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_for_plt2 = scored_dfs[2].loc[\n    scored_dfs[2].index.isin(df_test_mod.index), :\n]\nassert df_for_plt2.shape[0] == df_test_mod.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_plt_data_df = get_agg_plot_data(df_for_plt2, set_config = \"lift\")\nlift_plt = create_plot(lift_plt_data_df)\nshow(lift_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_actuals = lift_plt_data_df.act_av.iloc[-1] / lift_plt_data_df.act_av.iloc[0]\nlift_pred = lift_plt_data_df.pred_av.iloc[-1] / lift_plt_data_df.pred_av.iloc[0]\nprint(f'Lift on actuals:\\t{lift_actuals:.3f}')\nprint(f'Lift on predicted:\\t{lift_pred:.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both models have similar results. In the absence of any other more siginificant consideration, we choose the model with the engineered features as it more simple (i.e. has lower degrees of freedom), so will possibly generalise better to unseen data."},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Output results\nThis involves:\n- Fitting the model on all the training data\n- Scoring the validation data\n- Plotting lift on the validation data\n- Saving the output"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Takes approx 20 secs\nmods_df.loc[3, ['mod_name', 'descr']] = [\n    'Output model', \n    'Same as proposed but on all the training data'\n]\nmods_df.GLMResults[3] = smf.glm(\n    \"ClaimNb ~ 1 + \" + \" + \".join(\n        chosen_factors\n    ),\n    # Use all of the training data\n    data=df_train, exposure=np.asarray(df_train['Exposure']),\n    family=sm.families.Poisson(sm.genmod.families.links.log()),\n).fit()\nprint(mods_df.GLMResults[3].summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Score *validation* data for reporting\n# Takes under 10 secs\nscored_dfs[3] = score_data(df_validation, mods_df.GLMResults[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reasonableness checks\nassert np.abs(scored_dfs[3].act_Nb.sum() - df_validation.ClaimNb.sum()) < 1e-7\nassert np.abs(scored_dfs[3].wgt.sum() - df_validation.Exposure.sum()) < 1e-7\nprint(\"Correct: Reasonableness checks pass\\n\")\nprint(f\"Predicted number of claims:\\t{scored_dfs[3].pred_Nb.sum():,.1f}\")\nprint(f\"Actual number of claims:\\t{scored_dfs[3].ClaimNb.sum():,.1f}\")\nprint(f\"Difference:\\t\\t\\t{scored_dfs[3].pred_Nb.sum() - scored_dfs[3].ClaimNb.sum():,.1f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_plt_data_df = get_agg_plot_data(scored_dfs[3], set_config = \"lift\")\nlift_plt = create_plot(lift_plt_data_df)\nshow(lift_plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift_actuals = lift_plt_data_df.act_av.iloc[-1] / lift_plt_data_df.act_av.iloc[0]\nlift_pred = lift_plt_data_df.pred_av.iloc[-1] / lift_plt_data_df.pred_av.iloc[0]\nprint(f'Lift on actuals:\\t{lift_actuals:.3f}')\nprint(f'Lift on predicted:\\t{lift_pred:.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output scored validation data\nscored_dfs[3].to_pickle(\"df_validation_GLM_preds.gzip\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output model\nmods_df.GLMResults[3].save(\"GLMResults_obj.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check they have saved\n!ls -lh","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>\n\n# Rough work only"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To score data manually, we need to an object for \n# converting data into design matrix fields\n\n# import patsy\n# _, des_mx_obj = patsy.dmatrices(\n#     mods_df.GLMResults[0].model.formula, \n#     df_train_mod, # Needs to be the data used for fitting the model\n#     return_type='dataframe'\n# )\n# patsy.build_design_matrices(\n#     [des_mx_obj.design_info],\n#     scored_df.loc[4554,:],\n#     return_type='dataframe'\n# )[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Partial residuals\nIt seems we need to calculate these manually for features that account for multiple columns in the design matrix.\n\n#### Definitions\n$$\n\\textrm{Working residuals: } r_i^W = \\frac{y_i - \\hat{y}_i}{g'(\\eta_i)} = \n\\frac{y_i - \\hat{y}_i}{\\hat{y}_i} \\textrm{ for Poisson}\\\\\n\\textrm{Partial residuals for covariate }k\\textrm{: } r_i^{[k]} = r_i^W + x_{ik}\\hat{\\beta}_k\n$$\n\nPresumably, if there are multiple $\\beta_k$ for a term, we need to add all the associated $x_{ik}\\hat{\\beta}_k$. Consider whether they should be weighted (by exposure). Consider what we expect these to show - do we need to have centred the $x_i$ first?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOT COMPLETE\n\n# import patsy\n\n# def score_data(data_df, GLMRes_obj):\n#     raw_exog_names = pd.Series(GLMRes_obj.model.exog_names[1:]).str.split(\n#         '[', expand=True, n=1).iloc[:,0].drop_duplicates().to_list()\n#     scored_df = data_df.assign(\n#         wgt=lambda x: x.Exposure,\n#         act_freq=lambda x: x[GLMRes_obj.model.endog_names] / x.wgt,\n#         pred_freq=lambda x: GLMRes_obj.predict(x[raw_exog_names]),\n#         act_Nb=lambda x: x[GLMRes_obj.model.endog_names],\n#         pred_Nb=lambda x: x.pred_freq * x.wgt,\n#         resid_Nb=lambda x: x.act_Nb - x.pred_Nb,\n#     )\n#     return(scored_df)\n\n# GLMRes_obj = mods_df.GLMResults[0]\n# training_data_df = df_train_mod\n# scored_data_df = scored_dfs[0].copy()\n\n# raw_exog_names = pd.Series(GLMRes_obj.model.exog_names[1:]).str.split(\n#         '[', expand=True, n=1).iloc[:,0].drop_duplicates().to_list()\n\n# data_df = df_train.iloc[:1000,:]\n# GLMRes_obj = mods_df.GLMResults[0]\n# _, des_mx_obj = patsy.dmatrices(\n#     GLMRes_obj.model.formula, \n#     df_train_mod,\n#     return_type='matrix'\n# )\n\n# data_df = score_data(data_df, GLMRes_obj)\n\n# data_dmx = patsy.build_design_matrices(\n#     [des_mx_obj.design_info],\n#     data_df,\n#     return_type='matrix'\n# )[0]\n\n# data_df = pd.concat([\n#     data_df,\n#     pd.DataFrame(np.array([\n#         np.matmul(\n#             data_dmx[:, term_slice],\n#             GLMRes_obj.params[term_slice]\n#         )\n#         for _, term_slice \n#         in des_mx_obj.design_info.term_name_slices.items()\n#     ]).T, columns=[\n#         'clp_' + term_name for term_name \n#         in data_dmx.design_info.term_names\n#     ], index=data_df.index)\n# ], sort=False, axis=1).assign(**{\n#     ('cpr_' + exog_name): lambda x: np.log(x.act_freq) - np.log(x.pred_freq) + x['clp_' + exog_name]\n#     for exog_name in raw_exog_names\n# })\n\n# data_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div align=\"right\" style=\"text-align: right\"><a href=\"#Contents\">Back to Contents</a></div>"}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}