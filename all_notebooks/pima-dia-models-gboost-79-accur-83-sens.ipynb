{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##Importing Packages for Data Manipulation and Analysis##\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport sklearn as sk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score\nfrom sklearn.feature_selection import RFE, RFECV\nfrom sklearn.feature_selection import SelectFromModel\nimport statsmodels.api as sm\nimport statsmodels.stats.api as sms\n\n##Importing Packages for Data Visualization##\nimport seaborn as sns\nsns.set()\nsns.set_style('whitegrid')\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:09.564946Z","iopub.execute_input":"2021-07-18T21:51:09.565361Z","iopub.status.idle":"2021-07-18T21:51:10.332913Z","shell.execute_reply.started":"2021-07-18T21:51:09.565303Z","shell.execute_reply":"2021-07-18T21:51:10.331951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-- Data Project Goal: Predict the onset of diabetes based on diagnostic measures --","metadata":{}},{"cell_type":"code","source":"##Importing PIMA Population Diabetes Dataset - obtained from from https://www.kaggle.com/uciml/pima-indians-diabetes-database##\npima_diabetes_data = pd.read_csv(r'../input/pima-indians-diabetes-database/diabetes.csv')\n\n##General Overview of Data Column Characteristics##\npima_diabetes_data.info() #9 Columns (8 predictors, 1 response (Outcome)); 768 non-null observations for all columns.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.337037Z","iopub.execute_input":"2021-07-18T21:51:10.337497Z","iopub.status.idle":"2021-07-18T21:51:10.475667Z","shell.execute_reply.started":"2021-07-18T21:51:10.337468Z","shell.execute_reply":"2021-07-18T21:51:10.474369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Applying train-test split before proceeding with exploratory data analysis segment##\n\n##Splitting y (response) from X variables (predictors)\ny = pima_diabetes_data.loc[:,['Outcome']]\n\nX = pima_diabetes_data\nX = X.drop(['Outcome'], axis=1)\n\n##Splitting data into training (80%) and test (20%) sets (while keeping balanced)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, train_size = 0.80, random_state = 2021, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.477506Z","iopub.execute_input":"2021-07-18T21:51:10.477819Z","iopub.status.idle":"2021-07-18T21:51:10.4972Z","shell.execute_reply.started":"2021-07-18T21:51:10.477779Z","shell.execute_reply":"2021-07-18T21:51:10.49621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Step 1: Reviewing Training Dataset and Applying Cleaning if Necessary","metadata":{}},{"cell_type":"code","source":"##Overview of Columns of Training Dataset##\n##X_train Column Characteristics\nX_train.info() #614 Observations, 7 columns.\n\n##y_train Column Characteristics\ny_train.info() #614 Observations, 1 columns.\n\n#Therefore, the test data portion comprises of 154 observations.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.498394Z","iopub.execute_input":"2021-07-18T21:51:10.498702Z","iopub.status.idle":"2021-07-18T21:51:10.521073Z","shell.execute_reply.started":"2021-07-18T21:51:10.498671Z","shell.execute_reply":"2021-07-18T21:51:10.520059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-checking for any null values (double checking##\nprint(X_train.isnull().sum()) #No null values in training predictor set.\nprint(y_train.isnull().sum()) #No null values in training target set.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.524366Z","iopub.execute_input":"2021-07-18T21:51:10.524659Z","iopub.status.idle":"2021-07-18T21:51:10.534674Z","shell.execute_reply.started":"2021-07-18T21:51:10.524632Z","shell.execute_reply":"2021-07-18T21:51:10.533639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Step 2. Performing Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"##Determining Descriptive Statistics for Training Predictor Set##\nX_train.describe().round(1) ##Rounding descriptive statistics to 1 decimal place.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.53698Z","iopub.execute_input":"2021-07-18T21:51:10.537406Z","iopub.status.idle":"2021-07-18T21:51:10.586419Z","shell.execute_reply.started":"2021-07-18T21:51:10.537364Z","shell.execute_reply":"2021-07-18T21:51:10.585475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining Descriptive Statistics for Training Target Set##\ny_train_cat = y_train.astype('category') #Creating a variable within which y_train is converted to a categorical datatype.\n\ny_train_cat.describe() #Describing count split; The top occurence is 0, which corresponds to patients with no onset of diabetes. 400 out of 614 patients (65%) had no indicated onset of diabetes in this dataset.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.587627Z","iopub.execute_input":"2021-07-18T21:51:10.587988Z","iopub.status.idle":"2021-07-18T21:51:10.608732Z","shell.execute_reply.started":"2021-07-18T21:51:10.587949Z","shell.execute_reply":"2021-07-18T21:51:10.607698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating distribution plots for all predictor variables (all are continuous numerical variables)##\nprint(X_train.columns) #Printing column names for reference.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.61393Z","iopub.execute_input":"2021-07-18T21:51:10.614311Z","iopub.status.idle":"2021-07-18T21:51:10.623553Z","shell.execute_reply.started":"2021-07-18T21:51:10.614244Z","shell.execute_reply":"2021-07-18T21:51:10.622399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'Pregnancies' Predictor Variable.\nplt.hist(X_train['Pregnancies'], color='green');\nplt.xlabel('Number of Times Pregnant')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'Pregnancies' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.625734Z","iopub.execute_input":"2021-07-18T21:51:10.626063Z","iopub.status.idle":"2021-07-18T21:51:10.930072Z","shell.execute_reply.started":"2021-07-18T21:51:10.626031Z","shell.execute_reply":"2021-07-18T21:51:10.929076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'Glucose' Predictor Variable.\nplt.hist(X_train['Glucose'], color='green');\nplt.xlabel('Plasma glucose concentration after tolerance test')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'Glucose' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:10.931572Z","iopub.execute_input":"2021-07-18T21:51:10.931923Z","iopub.status.idle":"2021-07-18T21:51:11.229195Z","shell.execute_reply.started":"2021-07-18T21:51:10.931891Z","shell.execute_reply":"2021-07-18T21:51:11.227997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'BloodPressure' Predictor Variable.\nplt.hist(X_train['BloodPressure'], color='green');\nplt.xlabel('Diastolic blood pressure (mm Hg)')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'BloodPressure' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:11.230811Z","iopub.execute_input":"2021-07-18T21:51:11.23115Z","iopub.status.idle":"2021-07-18T21:51:11.503858Z","shell.execute_reply.started":"2021-07-18T21:51:11.231117Z","shell.execute_reply":"2021-07-18T21:51:11.502905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'SkinThickness' Predictor Variable.\nplt.hist(X_train['SkinThickness'], color='green');\nplt.xlabel('Triceps skin fold thickness (mm)')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'SkinThickness' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:11.505255Z","iopub.execute_input":"2021-07-18T21:51:11.505575Z","iopub.status.idle":"2021-07-18T21:51:11.780017Z","shell.execute_reply.started":"2021-07-18T21:51:11.505543Z","shell.execute_reply":"2021-07-18T21:51:11.778985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'Insulin' Predictor Variable.\nplt.hist(X_train['Insulin'], color='green');\nplt.xlabel('2-Hour serum insulin (mu U/ml)')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'Insulin' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:11.783358Z","iopub.execute_input":"2021-07-18T21:51:11.783688Z","iopub.status.idle":"2021-07-18T21:51:12.037094Z","shell.execute_reply.started":"2021-07-18T21:51:11.783654Z","shell.execute_reply":"2021-07-18T21:51:12.03605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'BMI' Predictor Variable.\nplt.hist(X_train['BMI'], color='green');\nplt.xlabel('Body mass index (weight in kg/(height in m)^2)')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'BMI' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:12.03842Z","iopub.execute_input":"2021-07-18T21:51:12.038725Z","iopub.status.idle":"2021-07-18T21:51:12.328069Z","shell.execute_reply.started":"2021-07-18T21:51:12.038695Z","shell.execute_reply":"2021-07-18T21:51:12.326737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'Diabetes pedigree function' Predictor Variable.\nplt.hist(X_train['DiabetesPedigreeFunction'], color='green');\nplt.xlabel('Diabetes pedigree function')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'Diabetespedigreefunction' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:12.329736Z","iopub.execute_input":"2021-07-18T21:51:12.330223Z","iopub.status.idle":"2021-07-18T21:51:12.589243Z","shell.execute_reply.started":"2021-07-18T21:51:12.330179Z","shell.execute_reply":"2021-07-18T21:51:12.588193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histogram for 'Age' Predictor Variable.\nplt.hist(X_train['Age'], color='green');\nplt.xlabel('Age(years)')\nplt.ylabel('Patient Count')\nplt.title(\"Distribution of 'Age' Predictor Variable\");","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:12.590568Z","iopub.execute_input":"2021-07-18T21:51:12.590948Z","iopub.status.idle":"2021-07-18T21:51:12.848313Z","shell.execute_reply.started":"2021-07-18T21:51:12.590918Z","shell.execute_reply":"2021-07-18T21:51:12.847465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating Boxplots to display relative difference in means of each variable between the Occurrence (1) group and Non-Ocurrence (0) groups\n\n##Creating a combined training dataframe dedicated to making these subplots.\ncombined_training_data = pd.concat([X_train, y_train], axis=1)\ncombined_training_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:12.849437Z","iopub.execute_input":"2021-07-18T21:51:12.849903Z","iopub.status.idle":"2021-07-18T21:51:12.865848Z","shell.execute_reply.started":"2021-07-18T21:51:12.849838Z","shell.execute_reply":"2021-07-18T21:51:12.864633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating Series of Subplots\nf, axes = plt.subplots(4,2,figsize=(20,15))\n\nsns.boxplot(x='Outcome', y='Pregnancies', data=combined_training_data, orient='v', ax=axes[0,0])\nsns.boxplot(x='Outcome', y='Glucose', data=combined_training_data, orient='v', ax=axes[0,1])\nsns.boxplot(x='Outcome', y='BloodPressure', data=combined_training_data, orient='v', ax=axes[1,0])\nsns.boxplot(x='Outcome', y='SkinThickness', data=combined_training_data, orient='v', ax=axes[1,1])\nsns.boxplot(x='Outcome', y='Insulin', data=combined_training_data, orient='v', ax=axes[2,0])\nsns.boxplot(x='Outcome', y='BMI', data=combined_training_data, orient='v', ax=axes[2,1])\nsns.boxplot(x='Outcome', y='DiabetesPedigreeFunction', data=combined_training_data, orient='v', ax=axes[3,0])\nsns.boxplot(x='Outcome', y='Age', data=combined_training_data, orient='v', ax=axes[3,1]);","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:12.867232Z","iopub.execute_input":"2021-07-18T21:51:12.867534Z","iopub.status.idle":"2021-07-18T21:51:14.166409Z","shell.execute_reply.started":"2021-07-18T21:51:12.867504Z","shell.execute_reply":"2021-07-18T21:51:14.165139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building A Pearson/Point Biserial Correlation Matrix for Training Data##\ncorr_combined = combined_training_data\nact_corr = corr_combined.corr()\nmatrix = np.tril(act_corr)\nf, ax = plt.subplots(figsize=(15,12))\nsns.heatmap(act_corr, vmax=0.8, annot=True, mask=matrix)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:14.167725Z","iopub.execute_input":"2021-07-18T21:51:14.168066Z","iopub.status.idle":"2021-07-18T21:51:14.998632Z","shell.execute_reply.started":"2021-07-18T21:51:14.168033Z","shell.execute_reply":"2021-07-18T21:51:14.997572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Step 3: Performing Data Modelling. \n    \n    The following models will be attempted: Random Forest Classification, Gradient Boost Classification, Extreme Gradient Boost Classification.","metadata":{}},{"cell_type":"markdown","source":"Step 3a: Random Forest Classification Modelling","metadata":{}},{"cell_type":"code","source":"##Importing Random Forest Classifier##\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:15.00008Z","iopub.execute_input":"2021-07-18T21:51:15.000413Z","iopub.status.idle":"2021-07-18T21:51:15.020649Z","shell.execute_reply.started":"2021-07-18T21:51:15.000381Z","shell.execute_reply":"2021-07-18T21:51:15.019451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Applying Recursive Feature Elimination (RFE) with cross-validation for Random Forest Classification feature selection.##\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=2021)\n\n##Identification of optimal number of features to select with RFECV approach. Selecting 3 folds in attempt to avoid overfitting.\nopt_feat_num_rfecv = RFECV(estimator = rf_classifier, step=1, cv=StratifiedKFold(3), scoring='balanced_accuracy', min_features_to_select=1)\n\nopt_feat_num_rfecv.fit(X_train, np.ravel(y_train))\nprint(\"Optimal number of features selected using RFECV: %d\"%opt_feat_num_rfecv.n_features_) #6 out of 8 selected as important.\n\n#Plot reference cited from: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (# of correct classifications)\")\nplt.plot(range(1,\n               len(opt_feat_num_rfecv.grid_scores_) + 1),\n         opt_feat_num_rfecv.grid_scores_)\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:15.021985Z","iopub.execute_input":"2021-07-18T21:51:15.022362Z","iopub.status.idle":"2021-07-18T21:51:21.84663Z","shell.execute_reply.started":"2021-07-18T21:51:15.02233Z","shell.execute_reply":"2021-07-18T21:51:21.845627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Training the random forest classifier with optimal number of features already identified.\nrfe_classifier = RFE(estimator=rf_classifier, n_features_to_select=6, step=1)\nrfe_classifier.fit(X_train, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:21.84796Z","iopub.execute_input":"2021-07-18T21:51:21.848311Z","iopub.status.idle":"2021-07-18T21:51:22.592904Z","shell.execute_reply.started":"2021-07-18T21:51:21.848278Z","shell.execute_reply":"2021-07-18T21:51:22.591862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining features of highest importance for the random forest model.\nrf_feat = pd.DataFrame()\nrf_feat['feature_name'] = X_train.columns\nrf_feat['importance'] = rfe_classifier.support_\nprint(rfe_classifier.ranking_)\nrf_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:22.593974Z","iopub.execute_input":"2021-07-18T21:51:22.594266Z","iopub.status.idle":"2021-07-18T21:51:22.608744Z","shell.execute_reply.started":"2021-07-18T21:51:22.594238Z","shell.execute_reply":"2021-07-18T21:51:22.607722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Only columns found to have  importance to the random forest model via RFECV.\nX_train_reduced = X_train.filter(['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\nX_test_reduced = X_test.filter(['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age'])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:22.610089Z","iopub.execute_input":"2021-07-18T21:51:22.610409Z","iopub.status.idle":"2021-07-18T21:51:22.625216Z","shell.execute_reply.started":"2021-07-18T21:51:22.610368Z","shell.execute_reply":"2021-07-18T21:51:22.623973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building Random Forest Classification Model with Selected Variables\nmodel1_varimp = RandomForestClassifier(n_estimators=100, random_state=2021).fit(X_train_reduced, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:22.626493Z","iopub.execute_input":"2021-07-18T21:51:22.626808Z","iopub.status.idle":"2021-07-18T21:51:22.877491Z","shell.execute_reply.started":"2021-07-18T21:51:22.626778Z","shell.execute_reply":"2021-07-18T21:51:22.876501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score\nmodel1_cvs= cross_val_score(model1_varimp, X_train_reduced, np.ravel(y_train), cv=StratifiedKFold(3))\nmodel1_cvs.mean() #0.7622588872947552","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:22.882642Z","iopub.execute_input":"2021-07-18T21:51:22.882997Z","iopub.status.idle":"2021-07-18T21:51:23.59124Z","shell.execute_reply.started":"2021-07-18T21:51:22.882967Z","shell.execute_reply":"2021-07-18T21:51:23.590366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Response Prediction\ny_pred = model1_varimp.predict(X_test_reduced)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.595083Z","iopub.execute_input":"2021-07-18T21:51:23.595388Z","iopub.status.idle":"2021-07-18T21:51:23.615091Z","shell.execute_reply.started":"2021-07-18T21:51:23.59536Z","shell.execute_reply":"2021-07-18T21:51:23.614168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating classification report for random forest.\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.616241Z","iopub.execute_input":"2021-07-18T21:51:23.616523Z","iopub.status.idle":"2021-07-18T21:51:23.627515Z","shell.execute_reply.started":"2021-07-18T21:51:23.616496Z","shell.execute_reply":"2021-07-18T21:51:23.626267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating confusion matrix for logistic regression model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.\nconfusion_matrix(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.628936Z","iopub.execute_input":"2021-07-18T21:51:23.629232Z","iopub.status.idle":"2021-07-18T21:51:23.637531Z","shell.execute_reply.started":"2021-07-18T21:51:23.629202Z","shell.execute_reply":"2021-07-18T21:51:23.636463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining AUC score for random forest model.\nroc_auc_score(y_test, y_pred) #0.7077777777777777","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.638907Z","iopub.execute_input":"2021-07-18T21:51:23.639272Z","iopub.status.idle":"2021-07-18T21:51:23.652304Z","shell.execute_reply.started":"2021-07-18T21:51:23.639242Z","shell.execute_reply":"2021-07-18T21:51:23.651222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining F1 score for the random forest model\nf1_score(y_test, y_pred,average='binary') #0.6122448979591836; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.6542Z","iopub.execute_input":"2021-07-18T21:51:23.654718Z","iopub.status.idle":"2021-07-18T21:51:23.666214Z","shell.execute_reply.started":"2021-07-18T21:51:23.654673Z","shell.execute_reply":"2021-07-18T21:51:23.66505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Checking for multicollinearity\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nX_train_constant_vif = sm.add_constant(X_train_reduced) #For evaluating VIF only.\n\nvif= [variance_inflation_factor(X_train_constant_vif.values,i) for i in range(X_train_constant_vif.shape[1])]\n\npd.DataFrame({'vif': vif[1:]}, index=X_train_reduced.columns).T #Multicollinearity interpretted as high when VIF > 5. All found to be below 5 (no multicollinearity issues indicated)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.66797Z","iopub.execute_input":"2021-07-18T21:51:23.66862Z","iopub.status.idle":"2021-07-18T21:51:23.699665Z","shell.execute_reply.started":"2021-07-18T21:51:23.668571Z","shell.execute_reply":"2021-07-18T21:51:23.698894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Generating values for feature importance plot.\nreduced_list_rf = list(['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\n\n#Numerical Importance of Predictors\nrfr_importance_rf = list(model1_varimp.feature_importances_)\n\n#Merged and Sorted with Predictors of importance\nvar_importance_merge_rf = [(predictor,round(importance,2)) for predictor, importance in zip(reduced_list_rf,rfr_importance_rf)]\n\nvar_importance_merge_rf = sorted(var_importance_merge_rf, key = lambda x: x[1], reverse = True)\n\nprint(var_importance_merge_rf)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.700945Z","iopub.execute_input":"2021-07-18T21:51:23.701442Z","iopub.status.idle":"2021-07-18T21:51:23.72206Z","shell.execute_reply.started":"2021-07-18T21:51:23.701409Z","shell.execute_reply":"2021-07-18T21:51:23.720945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plotting feature importance.\ndf_importance_rf = pd.DataFrame(var_importance_merge_rf, columns = ['PREDICTOR','IMPORTANCE_LEVEL'])\n\n#Predictor Rank Plot\nsns.catplot(x=\"IMPORTANCE_LEVEL\", y='PREDICTOR', data = df_importance_rf, kind = \"bar\", height =14)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:23.723773Z","iopub.execute_input":"2021-07-18T21:51:23.724141Z","iopub.status.idle":"2021-07-18T21:51:24.187655Z","shell.execute_reply.started":"2021-07-18T21:51:23.724106Z","shell.execute_reply":"2021-07-18T21:51:24.186731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Hypertuning with GridSearchCV\nparam_grid = {\n    'max_depth':[6,9,12],\n    'min_samples_split':[5,10,15],\n    'n_estimators':[80,100,120]\n}\n\nrf_gscv = GridSearchCV(estimator = rf_classifier, param_grid = param_grid, cv=StratifiedKFold(3), n_jobs=-1, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:24.189018Z","iopub.execute_input":"2021-07-18T21:51:24.189307Z","iopub.status.idle":"2021-07-18T21:51:24.194617Z","shell.execute_reply.started":"2021-07-18T21:51:24.189279Z","shell.execute_reply":"2021-07-18T21:51:24.193721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Fitting GSCV with training data \nrf_gscv.fit(X_train_reduced, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:24.196119Z","iopub.execute_input":"2021-07-18T21:51:24.196447Z","iopub.status.idle":"2021-07-18T21:51:34.092546Z","shell.execute_reply.started":"2021-07-18T21:51:24.196416Z","shell.execute_reply":"2021-07-18T21:51:34.091528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Extracting best params from GSCV\nrf_gscv.best_params_ #{'max_depth': 6, 'min_samples_split': 5, 'n_estimators': 80}","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.094302Z","iopub.execute_input":"2021-07-18T21:51:34.094671Z","iopub.status.idle":"2021-07-18T21:51:34.101242Z","shell.execute_reply.started":"2021-07-18T21:51:34.094634Z","shell.execute_reply":"2021-07-18T21:51:34.100186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Re-fitting a second random forest classification model with hypertuned parameters\nmodel_rf_final= RandomForestClassifier(n_estimators=80, max_depth=6, min_samples_split=5, random_state=2021).fit(X_train_reduced, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.103008Z","iopub.execute_input":"2021-07-18T21:51:34.10343Z","iopub.status.idle":"2021-07-18T21:51:34.294894Z","shell.execute_reply.started":"2021-07-18T21:51:34.103388Z","shell.execute_reply":"2021-07-18T21:51:34.293917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score\nmodel_rf_final_cvs = cross_val_score(model_rf_final, X_train_reduced, np.ravel(y_train), cv=StratifiedKFold(3))\nmodel_rf_final_cvs.mean() #0.7720149848557308","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.296184Z","iopub.execute_input":"2021-07-18T21:51:34.296487Z","iopub.status.idle":"2021-07-18T21:51:34.837623Z","shell.execute_reply.started":"2021-07-18T21:51:34.296457Z","shell.execute_reply":"2021-07-18T21:51:34.836648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Response Prediction\ny_pred_rf_final = model_rf_final.predict(X_test_reduced)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.839085Z","iopub.execute_input":"2021-07-18T21:51:34.839383Z","iopub.status.idle":"2021-07-18T21:51:34.858292Z","shell.execute_reply.started":"2021-07-18T21:51:34.839354Z","shell.execute_reply":"2021-07-18T21:51:34.857215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining Test Accuracy Score\naccuracy_score(y_test, y_pred_rf_final)#0.7857142857142857","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.859856Z","iopub.execute_input":"2021-07-18T21:51:34.860323Z","iopub.status.idle":"2021-07-18T21:51:34.867601Z","shell.execute_reply.started":"2021-07-18T21:51:34.860273Z","shell.execute_reply":"2021-07-18T21:51:34.866671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating classification report for random forest classification.\nprint(classification_report(y_test, y_pred_rf_final))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.869114Z","iopub.execute_input":"2021-07-18T21:51:34.869431Z","iopub.status.idle":"2021-07-18T21:51:34.884739Z","shell.execute_reply.started":"2021-07-18T21:51:34.8694Z","shell.execute_reply":"2021-07-18T21:51:34.88356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating confusion matrix for random forest classification model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.\nconfusion_matrix(y_test, y_pred_rf_final)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.886343Z","iopub.execute_input":"2021-07-18T21:51:34.886706Z","iopub.status.idle":"2021-07-18T21:51:34.895437Z","shell.execute_reply.started":"2021-07-18T21:51:34.886671Z","shell.execute_reply":"2021-07-18T21:51:34.894359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining AUC score for random forest classification model.\nroc_auc_score(y_test, y_pred_rf_final) #0.7370370370370369","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.896967Z","iopub.execute_input":"2021-07-18T21:51:34.897346Z","iopub.status.idle":"2021-07-18T21:51:34.909746Z","shell.execute_reply.started":"2021-07-18T21:51:34.897283Z","shell.execute_reply":"2021-07-18T21:51:34.908796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining F1 score for the for random forest classification model.\nf1_score(y_test, y_pred_rf_final,average='binary') #0.6526315789473683; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.911284Z","iopub.execute_input":"2021-07-18T21:51:34.911653Z","iopub.status.idle":"2021-07-18T21:51:34.925894Z","shell.execute_reply.started":"2021-07-18T21:51:34.911617Z","shell.execute_reply":"2021-07-18T21:51:34.924759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Generating values for feature importance plot.\nreduced_list_rf_final = list(['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\n\n#Numerical Importance of Predictors\nrfr_importance_rf_final = list(model_rf_final.feature_importances_)\n\n#Merged and Sorted with Predictors of importance\nvar_importance_merge_rf_final= [(predictor,round(importance,2)) for predictor, importance in zip(reduced_list_rf_final,rfr_importance_rf_final)]\n\nvar_importance_merge_rf_final = sorted(var_importance_merge_rf_final, key = lambda x: x[1], reverse = True)\n\nprint(var_importance_merge_rf_final)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.927495Z","iopub.execute_input":"2021-07-18T21:51:34.927923Z","iopub.status.idle":"2021-07-18T21:51:34.957899Z","shell.execute_reply.started":"2021-07-18T21:51:34.92788Z","shell.execute_reply":"2021-07-18T21:51:34.956779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plotting feature importance.\ndf_importance_rf_final = pd.DataFrame(var_importance_merge_rf_final, columns = ['PREDICTOR','IMPORTANCE_LEVEL'])\n\n#Predictor Rank Plot\nsns.catplot(x=\"IMPORTANCE_LEVEL\", y='PREDICTOR', data = df_importance_rf_final, kind = \"bar\", height =14)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:34.959416Z","iopub.execute_input":"2021-07-18T21:51:34.959804Z","iopub.status.idle":"2021-07-18T21:51:35.432058Z","shell.execute_reply.started":"2021-07-18T21:51:34.959765Z","shell.execute_reply":"2021-07-18T21:51:35.431006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The final metrics obtained for this Random Forest Classification Model were:\n    1. Final Test Score: 0.78;\n    2. Sensitivity: TP/(TP+FN) = (90/(90+23)) = 0.80;\n    3. Specificity: TN/(TN+FP) = (31/(31+10)) = 0.76;\n    4. AUC Score: 0.7;\n    5. F1 Score: 0.7;**","metadata":{}},{"cell_type":"markdown","source":"Step 3b:Gradient Boost Classification Modelling","metadata":{}},{"cell_type":"code","source":"##Importing Gradient Boosting Classifier##\nfrom sklearn.ensemble import GradientBoostingClassifier","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:35.433464Z","iopub.execute_input":"2021-07-18T21:51:35.433747Z","iopub.status.idle":"2021-07-18T21:51:35.43696Z","shell.execute_reply.started":"2021-07-18T21:51:35.433719Z","shell.execute_reply":"2021-07-18T21:51:35.436331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building GB Classification Model for Sklearn Prediction\ngb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=2021).fit(X_train, np.ravel(y_train))\n\n##Identification of optimal number of features to select with RFECV approach. Selecting 3 folds in attempt to avoid overfitting.\nopt_gb_rfecv = RFECV(estimator = gb_classifier, step=1, cv=StratifiedKFold(3), scoring='balanced_accuracy', min_features_to_select=1)\n\nopt_gb_rfecv.fit(X_train, np.ravel(y_train))\nprint(\"Optimal number of features selected using RFECV: %d\"%opt_gb_rfecv.n_features_) #6 out of 8 selected as important.\n\n#Plot reference cited from: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (# of correct classifications)\")\nplt.plot(range(1,\n               len(opt_gb_rfecv.grid_scores_) + 1),\n         opt_gb_rfecv.grid_scores_)\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:35.437896Z","iopub.execute_input":"2021-07-18T21:51:35.438301Z","iopub.status.idle":"2021-07-18T21:51:39.040176Z","shell.execute_reply.started":"2021-07-18T21:51:35.438264Z","shell.execute_reply":"2021-07-18T21:51:39.039151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Training the gradient boost classifier with optimal number of features already identified.\ngb_rfe_classifier = RFE(estimator=gb_classifier, n_features_to_select=6, step=1)\ngb_rfe_classifier.fit(X_train, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:39.041452Z","iopub.execute_input":"2021-07-18T21:51:39.04175Z","iopub.status.idle":"2021-07-18T21:51:39.515992Z","shell.execute_reply.started":"2021-07-18T21:51:39.04172Z","shell.execute_reply":"2021-07-18T21:51:39.514955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining features of highest importance for the gradient boost model.\ngb_feat = pd.DataFrame()\ngb_feat['feature_name'] = X_train.columns\ngb_feat['importance'] = gb_rfe_classifier.support_\nprint(gb_rfe_classifier.ranking_)\ngb_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:39.517302Z","iopub.execute_input":"2021-07-18T21:51:39.517602Z","iopub.status.idle":"2021-07-18T21:51:39.53235Z","shell.execute_reply.started":"2021-07-18T21:51:39.517573Z","shell.execute_reply":"2021-07-18T21:51:39.53149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Only columns found to have  importance to the gradient boost model via RFECV.\nX_train_reduced_gb = X_train.filter(['Pregnancies', 'Glucose','Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\nX_test_reduced_gb = X_test.filter(['Pregnancies', 'Glucose','Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:39.533546Z","iopub.execute_input":"2021-07-18T21:51:39.534056Z","iopub.status.idle":"2021-07-18T21:51:39.548375Z","shell.execute_reply.started":"2021-07-18T21:51:39.534015Z","shell.execute_reply":"2021-07-18T21:51:39.547344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building Gradient Boost Classification Model with Selected Variables\nmodel2_varimp = GradientBoostingClassifier(n_estimators=100, random_state=2021).fit(X_train_reduced_gb, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:39.549636Z","iopub.execute_input":"2021-07-18T21:51:39.550216Z","iopub.status.idle":"2021-07-18T21:51:39.708183Z","shell.execute_reply.started":"2021-07-18T21:51:39.550179Z","shell.execute_reply":"2021-07-18T21:51:39.707213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score\ngb_model_cvs = cross_val_score(model2_varimp, X_train_reduced_gb, np.ravel(y_train), cv=StratifiedKFold(3))\ngb_model_cvs.mean() #0.7704128805993943","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:39.709383Z","iopub.execute_input":"2021-07-18T21:51:39.709846Z","iopub.status.idle":"2021-07-18T21:51:40.086075Z","shell.execute_reply.started":"2021-07-18T21:51:39.709796Z","shell.execute_reply":"2021-07-18T21:51:40.084975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Response Prediction\ny_pred_gb = model2_varimp.predict(X_test_reduced_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.08775Z","iopub.execute_input":"2021-07-18T21:51:40.088242Z","iopub.status.idle":"2021-07-18T21:51:40.096587Z","shell.execute_reply.started":"2021-07-18T21:51:40.088194Z","shell.execute_reply":"2021-07-18T21:51:40.095615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining test accuracy score\naccuracy_score(y_test, y_pred_gb) #0.7857142857142857","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.098007Z","iopub.execute_input":"2021-07-18T21:51:40.098315Z","iopub.status.idle":"2021-07-18T21:51:40.114128Z","shell.execute_reply.started":"2021-07-18T21:51:40.098286Z","shell.execute_reply":"2021-07-18T21:51:40.11332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating classification report for GB Classification Model \nprint(classification_report(y_test, y_pred_gb))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.116093Z","iopub.execute_input":"2021-07-18T21:51:40.116883Z","iopub.status.idle":"2021-07-18T21:51:40.1335Z","shell.execute_reply.started":"2021-07-18T21:51:40.11682Z","shell.execute_reply":"2021-07-18T21:51:40.132243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating confusion matrix for GB Classification Model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.\nconfusion_matrix(y_test, y_pred_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.135321Z","iopub.execute_input":"2021-07-18T21:51:40.135822Z","iopub.status.idle":"2021-07-18T21:51:40.144608Z","shell.execute_reply.started":"2021-07-18T21:51:40.135775Z","shell.execute_reply":"2021-07-18T21:51:40.14359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining AUC score for the GB Classification Model.\nroc_auc_score(y_test, y_pred_gb) #0.7412962962962963","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.145953Z","iopub.execute_input":"2021-07-18T21:51:40.146277Z","iopub.status.idle":"2021-07-18T21:51:40.163519Z","shell.execute_reply.started":"2021-07-18T21:51:40.146247Z","shell.execute_reply":"2021-07-18T21:51:40.162604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining F1 score for the GB Classification Model.\nf1_score(y_test, y_pred_gb,average='binary') #0.6597938144329897; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.16474Z","iopub.execute_input":"2021-07-18T21:51:40.165048Z","iopub.status.idle":"2021-07-18T21:51:40.176468Z","shell.execute_reply.started":"2021-07-18T21:51:40.165019Z","shell.execute_reply":"2021-07-18T21:51:40.175187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Checking for multicollinearity\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nX_train_constant_vif = sm.add_constant(X_train_reduced_gb) #For evaluating VIF only.\n\nvif= [variance_inflation_factor(X_train_constant_vif.values,i) for i in range(X_train_constant_vif.shape[1])]\n\npd.DataFrame({'vif': vif[1:]}, index=X_train_reduced_gb.columns).T #Multicollinearity interpretted as high when VIF > 5. All found to be below 5 (no multicollinearity issues indicated)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.177553Z","iopub.execute_input":"2021-07-18T21:51:40.177999Z","iopub.status.idle":"2021-07-18T21:51:40.207573Z","shell.execute_reply.started":"2021-07-18T21:51:40.177969Z","shell.execute_reply":"2021-07-18T21:51:40.206433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Generating values for feature importance plot.\nreduced_list_gb = list(['Pregnancies', 'Glucose','Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\n\n#Numerical Importance of Predictors\nimportance_gb = list(model2_varimp.feature_importances_)\n\n#Merged and Sorted with Predictors of importance\nvar_importance_merge_gb = [(predictor,round(importance,2)) for predictor, importance in zip(reduced_list_gb,importance_gb)]\n\nvar_importance_merge_gb = sorted(var_importance_merge_gb, key = lambda x: x[1], reverse = True)\n\nprint(var_importance_merge_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.208814Z","iopub.execute_input":"2021-07-18T21:51:40.209207Z","iopub.status.idle":"2021-07-18T21:51:40.218039Z","shell.execute_reply.started":"2021-07-18T21:51:40.209172Z","shell.execute_reply":"2021-07-18T21:51:40.216837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plotting feature importance.\ndf_importance_gb = pd.DataFrame(var_importance_merge_gb, columns = ['PREDICTOR','IMPORTANCE_LEVEL'])\n\n#Predictor Rank Plot\nsns.catplot(x=\"IMPORTANCE_LEVEL\", y='PREDICTOR', data = df_importance_gb, kind = \"bar\", height =14)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.220055Z","iopub.execute_input":"2021-07-18T21:51:40.220725Z","iopub.status.idle":"2021-07-18T21:51:40.705816Z","shell.execute_reply.started":"2021-07-18T21:51:40.220445Z","shell.execute_reply":"2021-07-18T21:51:40.704872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Hypertuning with GridSearchCV\nparam_grid = {\n    'max_depth':[6,9,12],\n    'min_samples_split':[5,10,15],\n    'n_estimators':[80,100,120]\n}\n\ngb_gscv = GridSearchCV(estimator = gb_classifier, param_grid = param_grid, cv=StratifiedKFold(3), n_jobs=-1, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.707192Z","iopub.execute_input":"2021-07-18T21:51:40.707477Z","iopub.status.idle":"2021-07-18T21:51:40.712389Z","shell.execute_reply.started":"2021-07-18T21:51:40.707449Z","shell.execute_reply":"2021-07-18T21:51:40.711501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Fitting GSCV with training data \ngb_gscv.fit(X_train_reduced_gb, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:40.71354Z","iopub.execute_input":"2021-07-18T21:51:40.713818Z","iopub.status.idle":"2021-07-18T21:51:52.690652Z","shell.execute_reply.started":"2021-07-18T21:51:40.713792Z","shell.execute_reply":"2021-07-18T21:51:52.689655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Extracting best params from GSCV\ngb_gscv.best_params_ #{'max_depth': 6, 'min_samples_split': 10, 'n_estimators': 120}","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:52.691883Z","iopub.execute_input":"2021-07-18T21:51:52.692214Z","iopub.status.idle":"2021-07-18T21:51:52.69843Z","shell.execute_reply.started":"2021-07-18T21:51:52.692185Z","shell.execute_reply":"2021-07-18T21:51:52.69735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Re-fitting a second gradient boosting classification model with hypertuned parameters\nmodel_gb_final= GradientBoostingClassifier(n_estimators=120, max_depth=6, min_samples_split=10, random_state=2021).fit(X_train_reduced_gb, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:52.699895Z","iopub.execute_input":"2021-07-18T21:51:52.700214Z","iopub.status.idle":"2021-07-18T21:51:53.053374Z","shell.execute_reply.started":"2021-07-18T21:51:52.700183Z","shell.execute_reply":"2021-07-18T21:51:53.052373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score\nmodel_gb_final_cvs = cross_val_score(model_gb_final, X_train_reduced_gb, np.ravel(y_train), cv=StratifiedKFold(3))\nmodel_gb_final_cvs.mean() #0.7573489558424996","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.054588Z","iopub.execute_input":"2021-07-18T21:51:53.054889Z","iopub.status.idle":"2021-07-18T21:51:53.863658Z","shell.execute_reply.started":"2021-07-18T21:51:53.054846Z","shell.execute_reply":"2021-07-18T21:51:53.862674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Response Prediction\ny_pred_gb_final = model_gb_final.predict(X_test_reduced_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.864976Z","iopub.execute_input":"2021-07-18T21:51:53.865278Z","iopub.status.idle":"2021-07-18T21:51:53.873033Z","shell.execute_reply.started":"2021-07-18T21:51:53.865248Z","shell.execute_reply":"2021-07-18T21:51:53.872007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining Test Score\naccuracy_score(y_test, y_pred_gb_final)#0.7922077922077922","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.8744Z","iopub.execute_input":"2021-07-18T21:51:53.874696Z","iopub.status.idle":"2021-07-18T21:51:53.889999Z","shell.execute_reply.started":"2021-07-18T21:51:53.874667Z","shell.execute_reply":"2021-07-18T21:51:53.888944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating classification report for gradient boosting classification.\nprint(classification_report(y_test, y_pred_gb_final))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.891453Z","iopub.execute_input":"2021-07-18T21:51:53.891798Z","iopub.status.idle":"2021-07-18T21:51:53.906258Z","shell.execute_reply.started":"2021-07-18T21:51:53.891753Z","shell.execute_reply":"2021-07-18T21:51:53.905218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating confusion matrix for gradient boosting model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.\nconfusion_matrix(y_test, y_pred_gb_final)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.907282Z","iopub.execute_input":"2021-07-18T21:51:53.907553Z","iopub.status.idle":"2021-07-18T21:51:53.920942Z","shell.execute_reply.started":"2021-07-18T21:51:53.907526Z","shell.execute_reply":"2021-07-18T21:51:53.91972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining AUC score for gradient boosting classification model.\nroc_auc_score(y_test, y_pred_gb_final) #0.7633333333333332","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.922283Z","iopub.execute_input":"2021-07-18T21:51:53.922801Z","iopub.status.idle":"2021-07-18T21:51:53.937184Z","shell.execute_reply.started":"2021-07-18T21:51:53.922743Z","shell.execute_reply":"2021-07-18T21:51:53.936341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining F1 score for the for random forest classification model.\nf1_score(y_test, y_pred_gb_final,average='binary') #0.6923076923076923; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.938602Z","iopub.execute_input":"2021-07-18T21:51:53.93918Z","iopub.status.idle":"2021-07-18T21:51:53.951054Z","shell.execute_reply.started":"2021-07-18T21:51:53.939133Z","shell.execute_reply":"2021-07-18T21:51:53.950116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Generating values for feature importance plot.\nreduced_list_gb_final = list(['Pregnancies', 'Glucose','Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\n\n#Numerical Importance of Predictors\nimportance_gb_final = list(model_gb_final.feature_importances_)\n\n#Merged and Sorted with Predictors of importance\nvar_importance_merge_gb_final = [(predictor,round(importance,2)) for predictor, importance in zip(reduced_list_gb_final,importance_gb_final)]\n\nvar_importance_merge_gb_final = sorted(var_importance_merge_gb_final, key = lambda x: x[1], reverse = True)\n\nprint(var_importance_merge_gb_final)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.952415Z","iopub.execute_input":"2021-07-18T21:51:53.952937Z","iopub.status.idle":"2021-07-18T21:51:53.965507Z","shell.execute_reply.started":"2021-07-18T21:51:53.952904Z","shell.execute_reply":"2021-07-18T21:51:53.964211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plotting feature importance.\ndf_importance_gb_final= pd.DataFrame(var_importance_merge_gb_final, columns = ['PREDICTOR','IMPORTANCE_LEVEL'])\n\n#Predictor Rank Plot\nsns.catplot(x=\"IMPORTANCE_LEVEL\", y='PREDICTOR', data = df_importance_gb_final, kind = \"bar\", height =14)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:53.96761Z","iopub.execute_input":"2021-07-18T21:51:53.968136Z","iopub.status.idle":"2021-07-18T21:51:54.440141Z","shell.execute_reply.started":"2021-07-18T21:51:53.968053Z","shell.execute_reply":"2021-07-18T21:51:54.439062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The final metrics obtained for this Gradient Boosting Classification Model were: 1. Final Test Score: 0.79; 2. Sensitivity: TP/(TP+FN) = (86/(86+18)) = 0.83; 3. Specificity: TN/(TN+FP) = (36/(36+14)) = 0.72; 4. AUC Score: 0.7; 5. F1 Score: 0.7**","metadata":{}},{"cell_type":"markdown","source":"3c. Extreme Gradient Boost Classification (Similar to Gradient Boosting but with higher computation power and more regularization to combat overfitting while aiming to reduce bias reduction)","metadata":{}},{"cell_type":"code","source":"##Importing xgboost Classifier##\nimport xgboost as xgb\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:54.441692Z","iopub.execute_input":"2021-07-18T21:51:54.442139Z","iopub.status.idle":"2021-07-18T21:51:54.466518Z","shell.execute_reply.started":"2021-07-18T21:51:54.442093Z","shell.execute_reply":"2021-07-18T21:51:54.465351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building XGB Classification Model for Sklearn Prediction\nxgb_classifier = XGBClassifier(objective='binary:logistic',  eval_metric='logloss', use_label_encoder=False, n_estimators=100, random_state=2021).fit(X_train, np.ravel(y_train))\n\n##Identification of optimal number of features to select with RFECV approach. Selecting 3 folds in attempt to avoid overfitting.\nopt_xgb_rfecv = RFECV(estimator = xgb_classifier, step=1, cv=StratifiedKFold(3), scoring='balanced_accuracy', min_features_to_select=1)\n\nopt_xgb_rfecv.fit(X_train, np.ravel(y_train))\nprint(\"Optimal number of features selected using RFECV: %d\"%opt_xgb_rfecv.n_features_) #All 8 selected as important.\n\n#Plot reference cited from: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (# of correct classifications)\")\nplt.plot(range(1,\n               len(opt_xgb_rfecv.grid_scores_) + 1),\n         opt_xgb_rfecv.grid_scores_)\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:54.469936Z","iopub.execute_input":"2021-07-18T21:51:54.47027Z","iopub.status.idle":"2021-07-18T21:51:57.113419Z","shell.execute_reply.started":"2021-07-18T21:51:54.470241Z","shell.execute_reply":"2021-07-18T21:51:57.112449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Training the gradient boost classifier with optimal number of features already identified.\nxgb_rfe_classifier = RFE(estimator=xgb_classifier, n_features_to_select=8, step=1)\nxgb_rfe_classifier.fit(X_train, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.114598Z","iopub.execute_input":"2021-07-18T21:51:57.11489Z","iopub.status.idle":"2021-07-18T21:51:57.230272Z","shell.execute_reply.started":"2021-07-18T21:51:57.114848Z","shell.execute_reply":"2021-07-18T21:51:57.229206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining features of highest importance for the extreme gradient boost model.\nxgb_feat = pd.DataFrame()\nxgb_feat['feature_name'] = X_train.columns\nxgb_feat['importance'] = xgb_rfe_classifier.support_\nprint(xgb_rfe_classifier.ranking_)\nxgb_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.237506Z","iopub.execute_input":"2021-07-18T21:51:57.237857Z","iopub.status.idle":"2021-07-18T21:51:57.253905Z","shell.execute_reply.started":"2021-07-18T21:51:57.237813Z","shell.execute_reply":"2021-07-18T21:51:57.252829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building Extreme Gradient Boost Classification Model with all Variables\nmodel3_varimp = XGBClassifier(objective='binary:logistic',  eval_metric='logloss', use_label_encoder=False, n_estimators=100, random_state=2021).fit(X_train, np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.256153Z","iopub.execute_input":"2021-07-18T21:51:57.256457Z","iopub.status.idle":"2021-07-18T21:51:57.348256Z","shell.execute_reply.started":"2021-07-18T21:51:57.256428Z","shell.execute_reply":"2021-07-18T21:51:57.347298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score\nxgb_model_cvs = cross_val_score(model3_varimp, X_train, np.ravel(y_train), cv=StratifiedKFold(3))\nxgb_model_cvs.mean() #0.7736170891120676","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.34958Z","iopub.execute_input":"2021-07-18T21:51:57.349912Z","iopub.status.idle":"2021-07-18T21:51:57.580914Z","shell.execute_reply.started":"2021-07-18T21:51:57.349861Z","shell.execute_reply":"2021-07-18T21:51:57.579812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Response Prediction\ny_pred_xgb = model3_varimp.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.582355Z","iopub.execute_input":"2021-07-18T21:51:57.582679Z","iopub.status.idle":"2021-07-18T21:51:57.590231Z","shell.execute_reply.started":"2021-07-18T21:51:57.582647Z","shell.execute_reply":"2021-07-18T21:51:57.589405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining test accuracy score\naccuracy_score(y_test, y_pred_xgb) #0.7987012987012987","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.591575Z","iopub.execute_input":"2021-07-18T21:51:57.592102Z","iopub.status.idle":"2021-07-18T21:51:57.601907Z","shell.execute_reply.started":"2021-07-18T21:51:57.592064Z","shell.execute_reply":"2021-07-18T21:51:57.601124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating classification report for XGB classification model.\nprint(classification_report(y_test, y_pred_xgb))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.603246Z","iopub.execute_input":"2021-07-18T21:51:57.603775Z","iopub.status.idle":"2021-07-18T21:51:57.62246Z","shell.execute_reply.started":"2021-07-18T21:51:57.603737Z","shell.execute_reply":"2021-07-18T21:51:57.621573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating confusion matrix for XGB classification model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.\nconfusion_matrix(y_test, y_pred_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.623639Z","iopub.execute_input":"2021-07-18T21:51:57.624153Z","iopub.status.idle":"2021-07-18T21:51:57.633455Z","shell.execute_reply.started":"2021-07-18T21:51:57.624102Z","shell.execute_reply":"2021-07-18T21:51:57.632669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining AUC score for the XGB classification model.\nroc_auc_score(y_test, y_pred_xgb) #0.764074074074074","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.634759Z","iopub.execute_input":"2021-07-18T21:51:57.635067Z","iopub.status.idle":"2021-07-18T21:51:57.649345Z","shell.execute_reply.started":"2021-07-18T21:51:57.635038Z","shell.execute_reply":"2021-07-18T21:51:57.6486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining F1 score for the XGB classification model\nf1_score(y_test, y_pred_xgb,average='binary') #0.6930693069306931; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.65036Z","iopub.execute_input":"2021-07-18T21:51:57.650837Z","iopub.status.idle":"2021-07-18T21:51:57.661736Z","shell.execute_reply.started":"2021-07-18T21:51:57.650808Z","shell.execute_reply":"2021-07-18T21:51:57.660977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Hypertuning parameters: max_depth, min_child_weight, eta.\n#Code referenced as guide for tuning procedure: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\nparam_grid = {\n    'max_depth':[6,8,10],\n    'n_estimators':range(80,120,20),\n    'learning_rate': [0.10,0.15,0.20]\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:51:57.662841Z","iopub.execute_input":"2021-07-18T21:51:57.663323Z","iopub.status.idle":"2021-07-18T21:51:57.671433Z","shell.execute_reply.started":"2021-07-18T21:51:57.663293Z","shell.execute_reply":"2021-07-18T21:51:57.670345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Employing GridSearchCV to identify optimal parameters based on specified range.\nxgb_optmodel = xgb.XGBClassifier(random_state=2021)\noptimal_params = GridSearchCV(xgb_optmodel, param_grid, verbose=0,n_jobs=-1, cv=StratifiedKFold(3))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:10:00.764812Z","iopub.execute_input":"2021-07-18T22:10:00.765233Z","iopub.status.idle":"2021-07-18T22:10:00.770114Z","shell.execute_reply.started":"2021-07-18T22:10:00.765198Z","shell.execute_reply":"2021-07-18T22:10:00.769332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determing optimal parameters\noptimal_params.fit(X_train,np.ravel(y_train))\nprint(optimal_params.best_params_) #{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 80}","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:10:58.25566Z","iopub.execute_input":"2021-07-18T22:10:58.256209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Final Optimized Gradient Boosting Model Object\nxgb_final = xgb.XGBClassifier(objective='binary:logistic',  eval_metric='logloss', use_label_encoder=False, n_estimators=80, max_depth=10,learning_rate=0.1, n_jobs=-1, random_state=2021)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.475884Z","iopub.execute_input":"2021-07-18T22:04:27.476269Z","iopub.status.idle":"2021-07-18T22:04:27.48081Z","shell.execute_reply.started":"2021-07-18T22:04:27.476239Z","shell.execute_reply":"2021-07-18T22:04:27.479772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Fitting xgb_final on training data and predicting on test data\nxgb_final.fit(X_train,np.ravel(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.482319Z","iopub.execute_input":"2021-07-18T22:04:27.482616Z","iopub.status.idle":"2021-07-18T22:04:27.61017Z","shell.execute_reply.started":"2021-07-18T22:04:27.482585Z","shell.execute_reply":"2021-07-18T22:04:27.609106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cross-Validation Accuracy Score\nxgb_cvs = cross_val_score(xgb_final, X_train, np.ravel(y_train), cv=StratifiedKFold(3))\nxgb_cvs.mean() #0.7524868483978957","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.611355Z","iopub.execute_input":"2021-07-18T22:04:27.611652Z","iopub.status.idle":"2021-07-18T22:04:27.902178Z","shell.execute_reply.started":"2021-07-18T22:04:27.611623Z","shell.execute_reply":"2021-07-18T22:04:27.90134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Response Prediction\nxgb_pred_final = xgb_final.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.903449Z","iopub.execute_input":"2021-07-18T22:04:27.903939Z","iopub.status.idle":"2021-07-18T22:04:27.91238Z","shell.execute_reply.started":"2021-07-18T22:04:27.903904Z","shell.execute_reply":"2021-07-18T22:04:27.911106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining accuracy scores\naccuracy_score(y_test, xgb_pred_final) #0.7597402597402597","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.913909Z","iopub.execute_input":"2021-07-18T22:04:27.914377Z","iopub.status.idle":"2021-07-18T22:04:27.92915Z","shell.execute_reply.started":"2021-07-18T22:04:27.914341Z","shell.execute_reply":"2021-07-18T22:04:27.928273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating classification report for XGB classification.\nprint(classification_report(y_test, xgb_pred_final))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.93049Z","iopub.execute_input":"2021-07-18T22:04:27.930985Z","iopub.status.idle":"2021-07-18T22:04:27.948385Z","shell.execute_reply.started":"2021-07-18T22:04:27.930953Z","shell.execute_reply":"2021-07-18T22:04:27.947309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating confusion matrix for XGB classification model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.\nconfusion_matrix(y_test, xgb_pred_final)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.949838Z","iopub.execute_input":"2021-07-18T22:04:27.950193Z","iopub.status.idle":"2021-07-18T22:04:27.958484Z","shell.execute_reply.started":"2021-07-18T22:04:27.950161Z","shell.execute_reply":"2021-07-18T22:04:27.957599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining AUC score for XGB classification model.\nroc_auc_score(y_test, xgb_pred_final) #0.7383333333333333","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.959791Z","iopub.execute_input":"2021-07-18T22:04:27.960113Z","iopub.status.idle":"2021-07-18T22:04:27.976112Z","shell.execute_reply.started":"2021-07-18T22:04:27.96008Z","shell.execute_reply":"2021-07-18T22:04:27.974954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determining F1 score for the for XGB classification model.\nf1_score(y_test, xgb_pred_final,average='binary') #0.6605504587155963; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.977754Z","iopub.execute_input":"2021-07-18T22:04:27.978076Z","iopub.status.idle":"2021-07-18T22:04:27.989783Z","shell.execute_reply.started":"2021-07-18T22:04:27.978047Z","shell.execute_reply":"2021-07-18T22:04:27.988461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Checking for multicollinearity\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nX_train_constant_vif = sm.add_constant(X_train) #For evaluating VIF only.\n\nvif= [variance_inflation_factor(X_train_constant_vif.values,i) for i in range(X_train_constant_vif.shape[1])]\n\npd.DataFrame({'vif': vif[1:]}, index=X_train.columns).T #Multicollinearity interpretted as high when VIF > 5. All found to be below 5 (no multicollinearity issues indicated)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:27.991591Z","iopub.execute_input":"2021-07-18T22:04:27.992116Z","iopub.status.idle":"2021-07-18T22:04:28.026487Z","shell.execute_reply.started":"2021-07-18T22:04:27.992073Z","shell.execute_reply":"2021-07-18T22:04:28.024939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plotting features by ranked importance (Training Data) (Importance_type=Weight is default)\n\n#Converting dataframes to Dmatrix optimized structure\nxgb_trainmatrix = xgb.DMatrix(X_train, label = y_train)\nxgb_testmatrix = xgb.DMatrix(X_test, label = y_test)\n\nparams={'learning_rate': 0.1, 'max_depth': 10}\n\nxgb_finalimportance = xgb.train(params=params, dtrain=xgb_trainmatrix, num_boost_round=80)\n\nxgb.plot_importance(xgb_finalimportance, importance_type='gain')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:04:28.028012Z","iopub.execute_input":"2021-07-18T22:04:28.028347Z","iopub.status.idle":"2021-07-18T22:04:28.723386Z","shell.execute_reply.started":"2021-07-18T22:04:28.028315Z","shell.execute_reply":"2021-07-18T22:04:28.722337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The final metrics obtained for this Extreme Gradient Boosting Classification Model were: 1. Final Test Score: 0.76; 2. Sensitivity: TP/(TP+FN) = (81/(81+18)) = 0.82; 3. Specificity: TN/(TN+FP) = (36/(36+19)) = 0.75; 4. AUC Score: 0.7; 5. F1 Score: 0.7**","metadata":{}},{"cell_type":"markdown","source":"**Ultimately, Gradient Boosting (not extreme) seems to have the strongest performance, in terms of sensitivity (ability to detect true positive occurences (onset of diabetes) ~0.80), whereas the random forest model had the strongest performance in terms of being able to determine a true negative occurence (when onset of diabetes would not occur) ~0.76). Gradient boosting also had the highest test accuracy score (0.79).**","metadata":{}}]}