{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Seyedsaman Emami\n### 02.Jul.2021\n\n# Table of contents\n* About the Notebook\n* Hypothesis\n* Importing Libraries\n* Overview of dataset\n    * Exploring the Data\n    * Data sampling\n    * Visualizing\n    * Outlier treatment\n    * Correlation\n* Conclusion","metadata":{}},{"cell_type":"markdown","source":"# About this notebook\nIn the following notebook, I reviewed the demographic dataset and investigated different aspects of this simple dataset. \nIn the first part, I imported the libraries which I needed for my experiments.\nTo import the dataset, I considered the Panda's library and read the *CSV file by calling the Pandas's method. And to have an overview of our data frame, I called the five top rows of the dataset by the Head method. For the description, I studied the five features of the dataset (In terms of min, max, std, mean, and quartile). Also, one can find the size, type, and dimensions of the dataset in the related cell. \n\nTo have a clean dataset, I had to check the null or missing values, and if I find any, there are different approaches to deal with them. Hence, I checked the missing values and used another function to remove the null value in the case that we have any.\n\nSo it is time to dive into the details by exploring more. For this matter, I visualized the data by plotting the histogram of each feature, scatter plot to see the relationship between pair columns, and box plot to have a summary of quantile, max, min, median, and mean of each attribute.\n\nRegarding the outlier, I reviewed the box plot and scatter plot, and defined the lower and upper bound to drop the outliers.\n\nFinally, I checked the correlation by applying the Pearson method and print out the covariance.","metadata":{}},{"cell_type":"markdown","source":"# Hypothesis","metadata":{}},{"cell_type":"markdown","source":"* There would be a relationship between different features of the dataset.\n* There is a high correlation between one pair of columns.\n* There are duplicated values.\n* Do customers in different regions spend more per transaction? Which regions spend the most/least?\n* Is there a relationship between number of items purchased and amount spent?","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T17:38:17.265287Z","iopub.execute_input":"2021-07-15T17:38:17.266101Z","iopub.status.idle":"2021-07-15T17:38:18.244903Z","shell.execute_reply.started":"2021-07-15T17:38:17.265949Z","shell.execute_reply":"2021-07-15T17:38:18.243522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the sake of sampling and other experiments, I added a random seed to generate a different seed for functions.","metadata":{}},{"cell_type":"code","source":"Random_seed = random.randint(1, 1000)\nprint(Random_seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:20.740333Z","iopub.execute_input":"2021-07-15T17:38:20.741029Z","iopub.status.idle":"2021-07-15T17:38:20.746491Z","shell.execute_reply.started":"2021-07-15T17:38:20.740989Z","shell.execute_reply":"2021-07-15T17:38:20.745704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Obtaining Data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/demographic-data/Demographic_Data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:21.50016Z","iopub.execute_input":"2021-07-15T17:38:21.500784Z","iopub.status.idle":"2021-07-15T17:38:21.577072Z","shell.execute_reply.started":"2021-07-15T17:38:21.500708Z","shell.execute_reply":"2021-07-15T17:38:21.575854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## An overview of dataset","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:22.005613Z","iopub.execute_input":"2021-07-15T17:38:22.006189Z","iopub.status.idle":"2021-07-15T17:38:22.044342Z","shell.execute_reply.started":"2021-07-15T17:38:22.006145Z","shell.execute_reply":"2021-07-15T17:38:22.042899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check Data description ","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:22.634396Z","iopub.execute_input":"2021-07-15T17:38:22.634847Z","iopub.status.idle":"2021-07-15T17:38:22.691932Z","shell.execute_reply.started":"2021-07-15T17:38:22.634804Z","shell.execute_reply":"2021-07-15T17:38:22.690749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the data types","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:23.074146Z","iopub.execute_input":"2021-07-15T17:38:23.074601Z","iopub.status.idle":"2021-07-15T17:38:23.096232Z","shell.execute_reply.started":"2021-07-15T17:38:23.074553Z","shell.execute_reply":"2021-07-15T17:38:23.095085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data cleaning","metadata":{}},{"cell_type":"markdown","source":"### Check missing values","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:23.615099Z","iopub.execute_input":"2021-07-15T17:38:23.61551Z","iopub.status.idle":"2021-07-15T17:38:23.627156Z","shell.execute_reply.started":"2021-07-15T17:38:23.615475Z","shell.execute_reply":"2021-07-15T17:38:23.626034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop missing value\n> We do not have any","metadata":{}},{"cell_type":"code","source":"data = data.drop_duplicates()\ndata.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:23.989038Z","iopub.execute_input":"2021-07-15T17:38:23.98946Z","iopub.status.idle":"2021-07-15T17:38:24.020005Z","shell.execute_reply.started":"2021-07-15T17:38:23.989425Z","shell.execute_reply":"2021-07-15T17:38:24.018822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check our data type","metadata":{}},{"cell_type":"code","source":"data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:24.364028Z","iopub.execute_input":"2021-07-15T17:38:24.364453Z","iopub.status.idle":"2021-07-15T17:38:24.373094Z","shell.execute_reply.started":"2021-07-15T17:38:24.36442Z","shell.execute_reply":"2021-07-15T17:38:24.371908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore the Data","metadata":{}},{"cell_type":"code","source":"print(data.columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:24.778553Z","iopub.execute_input":"2021-07-15T17:38:24.778993Z","iopub.status.idle":"2021-07-15T17:38:24.785636Z","shell.execute_reply.started":"2021-07-15T17:38:24.778956Z","shell.execute_reply":"2021-07-15T17:38:24.784166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The number of purchases","metadata":{}},{"cell_type":"markdown","source":"I tried to group by the dataset to check different features in contrast to the rest.","metadata":{}},{"cell_type":"code","source":"data.groupby('in-store')['in-store'].count()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:25.279198Z","iopub.execute_input":"2021-07-15T17:38:25.279618Z","iopub.status.idle":"2021-07-15T17:38:25.290151Z","shell.execute_reply.started":"2021-07-15T17:38:25.279584Z","shell.execute_reply":"2021-07-15T17:38:25.289124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can find the average of in-store shopping regarding the sale zone","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(data.groupby(data['region'])['in-store'].mean())","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:25.684527Z","iopub.execute_input":"2021-07-15T17:38:25.684979Z","iopub.status.idle":"2021-07-15T17:38:25.701909Z","shell.execute_reply.started":"2021-07-15T17:38:25.684941Z","shell.execute_reply":"2021-07-15T17:38:25.700289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Many libraries in python during the implementation, print out the logs. To have a clear output, I ignore the printing of the outputs.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\")\nsns.factorplot('in-store', data=data, kind='count', aspect=1)\nplt.title(\"Number of in store purchases\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:26.021055Z","iopub.execute_input":"2021-07-15T17:38:26.021506Z","iopub.status.idle":"2021-07-15T17:38:26.297337Z","shell.execute_reply.started":"2021-07-15T17:38:26.021461Z","shell.execute_reply":"2021-07-15T17:38:26.296252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same as previous without duplicated purchased amount","metadata":{}},{"cell_type":"code","source":"subset = data.drop_duplicates(subset='amount')\nsns.factorplot('in-store', data = subset, kind='count', aspect=1)\nplt.title(\"Number of in store purchases\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:26.402521Z","iopub.execute_input":"2021-07-15T17:38:26.402996Z","iopub.status.idle":"2021-07-15T17:38:26.636874Z","shell.execute_reply.started":"2021-07-15T17:38:26.402956Z","shell.execute_reply":"2021-07-15T17:38:26.635891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the description of only two features","metadata":{}},{"cell_type":"code","source":"data[['amount','items']].describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:26.840513Z","iopub.execute_input":"2021-07-15T17:38:26.84099Z","iopub.status.idle":"2021-07-15T17:38:26.874037Z","shell.execute_reply.started":"2021-07-15T17:38:26.840943Z","shell.execute_reply":"2021-07-15T17:38:26.873005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dropping duplicates values by subsetting the amount\nFrom the previous cell, I understand that the plots do not make a sense so, I thought about duplicated values in a specific column.\n\nFirst of all, I sorted my data frame to have the ideal form of table which I was looking for.\n\nI stored the modified dataset in a *Sorted* DataFrame","metadata":{}},{"cell_type":"code","source":"Sorted = data.sort_values('items', inplace=False)\nSorted.drop_duplicates(subset='amount', inplace=True)\nSorted.tail()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:27.170641Z","iopub.execute_input":"2021-07-15T17:38:27.171127Z","iopub.status.idle":"2021-07-15T17:38:27.207154Z","shell.execute_reply.started":"2021-07-15T17:38:27.171087Z","shell.execute_reply":"2021-07-15T17:38:27.206328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the data ","metadata":{}},{"cell_type":"code","source":"Sorted = data.groupby(data['items']).count()\nit = Sorted.iloc[:, 0:3]\nplt.hist(Sorted)\nplt.legend(Sorted.columns)\nplt.title('Counting items')\nprint(Sorted)\nprint(it)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:27.587523Z","iopub.execute_input":"2021-07-15T17:38:27.588163Z","iopub.status.idle":"2021-07-15T17:38:27.879002Z","shell.execute_reply.started":"2021-07-15T17:38:27.588124Z","shell.execute_reply":"2021-07-15T17:38:27.877956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Sorted = data.sort_values('items', inplace=False)\nSorted.drop_duplicates(subset='amount', inplace=True)\n\nage = Sorted.groupby(Sorted['age']).count()\nplt.hist(age)\nplt.legend(age.columns)\nplt.title('Counting items')\nplt.xlabel('Values')\nplt.ylabel('age')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:27.880349Z","iopub.execute_input":"2021-07-15T17:38:27.880812Z","iopub.status.idle":"2021-07-15T17:38:28.182939Z","shell.execute_reply.started":"2021-07-15T17:38:27.880777Z","shell.execute_reply":"2021-07-15T17:38:28.182066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the columns' names","metadata":{}},{"cell_type":"markdown","source":"### Plotting\n>  a histogram on the features","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i, j in enumerate(data.columns):\n    plt.subplot(3, 2, i+1)\n    plt.hist(Sorted[j], color='teal', histtype='bar')\n    plt.title(str(data.columns[i]))\n    plt.ylabel(\"Values\") ","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:28.367541Z","iopub.execute_input":"2021-07-15T17:38:28.368141Z","iopub.status.idle":"2021-07-15T17:38:29.353391Z","shell.execute_reply.started":"2021-07-15T17:38:28.3681Z","shell.execute_reply":"2021-07-15T17:38:29.352136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data sampling","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:44:12.686659Z","iopub.execute_input":"2021-06-28T11:44:12.687085Z","iopub.status.idle":"2021-06-28T11:44:13.16246Z","shell.execute_reply.started":"2021-06-28T11:44:12.68702Z","shell.execute_reply":"2021-06-28T11:44:13.16128Z"}}},{"cell_type":"markdown","source":"I generated a random sample from the main dataset to explore the dataset in a small dimension.","metadata":{}},{"cell_type":"code","source":"sample = Sorted.sample(frac=0.005, random_state=Random_seed)\nprint(sample.shape)\nsample.tail()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:29.366886Z","iopub.execute_input":"2021-07-15T17:38:29.367299Z","iopub.status.idle":"2021-07-15T17:38:29.384813Z","shell.execute_reply.started":"2021-07-15T17:38:29.367266Z","shell.execute_reply":"2021-07-15T17:38:29.383678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = sample['age']\ny = sample['amount']\nprint(\"Age sample:\", X, '\\n',\n      \"Amount sample:\", y)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:29.59234Z","iopub.execute_input":"2021-07-15T17:38:29.59279Z","iopub.status.idle":"2021-07-15T17:38:29.603543Z","shell.execute_reply.started":"2021-07-15T17:38:29.592729Z","shell.execute_reply":"2021-07-15T17:38:29.602262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing \n> Let's compare the simple samples of two different features of our dataset","metadata":{}},{"cell_type":"code","source":"plt.scatter(X, y, marker='o', c='lawngreen')\nplt.title(\"Scatter plot\")\nplt.xlabel(\"age\")\nplt.ylabel(\"amount\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:30.059408Z","iopub.execute_input":"2021-07-15T17:38:30.059886Z","iopub.status.idle":"2021-07-15T17:38:30.244086Z","shell.execute_reply.started":"2021-07-15T17:38:30.05984Z","shell.execute_reply":"2021-07-15T17:38:30.242982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scatter","metadata":{}},{"cell_type":"markdown","source":"We have the same scatter as the previous with this difference that I defined a python method here to return the scatter plot for the user.","metadata":{}},{"cell_type":"code","source":"X = sample['region']\ny = sample['amount']\n\ndef sct(X, y, Xlabel=None, ylabel=None):\n    plt.scatter(X, y, marker='o', c='lawngreen')\n    plt.title(\"Scatter plot\")\n    plt.xlabel(Xlabel)\n    plt.ylabel(ylabel)\n    return plt.show()\nsct(X, y, 'age', 'amount')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:30.696477Z","iopub.execute_input":"2021-07-15T17:38:30.69695Z","iopub.status.idle":"2021-07-15T17:38:30.863526Z","shell.execute_reply.started":"2021-07-15T17:38:30.696909Z","shell.execute_reply":"2021-07-15T17:38:30.862423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = sample['items']\ny = sample['amount']\n\ndef sct(X, y, Xlabel=None, ylabel=None):\n    plt.scatter(X, y, marker='o', c='lawngreen')\n    plt.title(\"Scatter plot\")\n    plt.xlabel(Xlabel)\n    plt.ylabel(ylabel)\n    return plt.show()\nsct(X, y, 'items', 'amount')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:30.903348Z","iopub.execute_input":"2021-07-15T17:38:30.903809Z","iopub.status.idle":"2021-07-15T17:38:31.089034Z","shell.execute_reply.started":"2021-07-15T17:38:30.903743Z","shell.execute_reply":"2021-07-15T17:38:31.087748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### feature dentification ","metadata":{}},{"cell_type":"markdown","source":"Instead of printing plots one-by-one, we can print them out in one loop in the range of features of the dataset.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 15))\nfor i, j in enumerate(data.columns):\n    plt.subplot(3, 2, i+1)\n    plt.boxplot(Sorted[j], 0, 'gD', showmeans=True,\n                meanline=True, autorange=True)\n    plt.title('Box plt - ' + str(data.columns[i]))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:31.496212Z","iopub.execute_input":"2021-07-15T17:38:31.49663Z","iopub.status.idle":"2021-07-15T17:38:32.091914Z","shell.execute_reply.started":"2021-07-15T17:38:31.496597Z","shell.execute_reply":"2021-07-15T17:38:32.09079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outlier treatment","metadata":{}},{"cell_type":"markdown","source":"As we can see in the amount, we have outliers values.\n\nAfter seeing the box plot, I curious about the \"amount\" feature, so I decided to have a subsample of it and compare it with its median. ","metadata":{}},{"cell_type":"code","source":"outliers = np.where(Sorted['amount']>2000)\nprint('outliers indes:', outliers)\n(Sorted['amount']>2000).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:32.209441Z","iopub.execute_input":"2021-07-15T17:38:32.209897Z","iopub.status.idle":"2021-07-15T17:38:32.237624Z","shell.execute_reply.started":"2021-07-15T17:38:32.209858Z","shell.execute_reply":"2021-07-15T17:38:32.236857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sct(Sorted['region'], Sorted['amount'], 'region', 'amount')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:32.385811Z","iopub.execute_input":"2021-07-15T17:38:32.386431Z","iopub.status.idle":"2021-07-15T17:38:32.647386Z","shell.execute_reply.started":"2021-07-15T17:38:32.386394Z","shell.execute_reply":"2021-07-15T17:38:32.646486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amount = (sample.amount).values\nm = []\nfor i in range(amount.shape[0]):\n    m.append(np.mean(amount))\nplt.plot(amount, label='Amount of purchase')\nplt.plot(m, linewidth=3, color='r', label='Median')\nplt.legend()\nplt.title(\"Checking amount outliers\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:32.648723Z","iopub.execute_input":"2021-07-15T17:38:32.649172Z","iopub.status.idle":"2021-07-15T17:38:32.854978Z","shell.execute_reply.started":"2021-07-15T17:38:32.649138Z","shell.execute_reply":"2021-07-15T17:38:32.854074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ","metadata":{}},{"cell_type":"code","source":"z = np.abs(stats.zscore(amount))\nplt.plot(z, c='g', alpha=0.3)\nplt.ylabel('Distance')\nplt.xlabel('index')\nplt.title('Distance of the amount value from the mean')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:32.97886Z","iopub.execute_input":"2021-07-15T17:38:32.979926Z","iopub.status.idle":"2021-07-15T17:38:33.177594Z","shell.execute_reply.started":"2021-07-15T17:38:32.979846Z","shell.execute_reply":"2021-07-15T17:38:33.176454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Defining the bounds to remove the outliers","metadata":{}},{"cell_type":"code","source":"\nQ1 = np.percentile(amount, 25, interpolation='midpoint')\nQ3 = np.percentile(amount, 65, interpolation='midpoint')\nIQR = Q3 - Q1\namount.shape\nupper = np.where(amount>=(Q3+1.5*IQR))\nlower = np.where(amount<=(Q1-1.5*IQR))\nnew = pd.DataFrame(amount)\nnew.drop(upper[0], inplace=True)\nnew.drop(lower[0], inplace=True)\nprint(new.shape)\nnew.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:33.483403Z","iopub.execute_input":"2021-07-15T17:38:33.483896Z","iopub.status.idle":"2021-07-15T17:38:33.502352Z","shell.execute_reply.started":"2021-07-15T17:38:33.483854Z","shell.execute_reply":"2021-07-15T17:38:33.501127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(amount, label='Amount of purchase')\nplt.plot(new, label='Clean amount', c='g', alpha=0.7)\nplt.plot(m, linewidth=3, color='r', label='Median')\nplt.legend()\nplt.title(\"Comparing the amount with and without outliers\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:33.683292Z","iopub.execute_input":"2021-07-15T17:38:33.68373Z","iopub.status.idle":"2021-07-15T17:38:33.907019Z","shell.execute_reply.started":"2021-07-15T17:38:33.68369Z","shell.execute_reply":"2021-07-15T17:38:33.905914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.boxplot(new, 0, 'gD', showmeans=True,\n                meanline=True, autorange=True)\nplt.title('Cleaned amount without outliers')\nplt.subplot(2,2,2)\nplt.boxplot(amount, 0, 'gD', showmeans=True,\n                meanline=True, autorange=True)\nplt.title('Real values of amount')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:33.966473Z","iopub.execute_input":"2021-07-15T17:38:33.966953Z","iopub.status.idle":"2021-07-15T17:38:34.222095Z","shell.execute_reply.started":"2021-07-15T17:38:33.96691Z","shell.execute_reply":"2021-07-15T17:38:34.220958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the Correlation","metadata":{}},{"cell_type":"markdown","source":"I chose the pearson method to return the Correlation Coefficient matrix","metadata":{}},{"cell_type":"code","source":"Sorted.corr(\"pearson\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:34.878449Z","iopub.execute_input":"2021-07-15T17:38:34.878921Z","iopub.status.idle":"2021-07-15T17:38:34.902211Z","shell.execute_reply.started":"2021-07-15T17:38:34.878877Z","shell.execute_reply":"2021-07-15T17:38:34.901078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualize the correlation","metadata":{}},{"cell_type":"markdown","source":"As we only have four attributes, it is easier to check the correlation over a heatmap","metadata":{}},{"cell_type":"code","source":"sns.heatmap(data.corr(\"pearson\"), annot=True, cmap='GnBu')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:36.03546Z","iopub.execute_input":"2021-07-15T17:38:36.035919Z","iopub.status.idle":"2021-07-15T17:38:36.334861Z","shell.execute_reply.started":"2021-07-15T17:38:36.035875Z","shell.execute_reply":"2021-07-15T17:38:36.333742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## Joint variability","metadata":{}},{"cell_type":"markdown","source":"### Measure of the joint variability by using the Covariance","metadata":{}},{"cell_type":"code","source":"Sorted.cov()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:37.517737Z","iopub.execute_input":"2021-07-15T17:38:37.518197Z","iopub.status.idle":"2021-07-15T17:38:37.541327Z","shell.execute_reply.started":"2021-07-15T17:38:37.51816Z","shell.execute_reply":"2021-07-15T17:38:37.54013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(Sorted.cov(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T17:38:38.0186Z","iopub.execute_input":"2021-07-15T17:38:38.019109Z","iopub.status.idle":"2021-07-15T17:38:38.526617Z","shell.execute_reply.started":"2021-07-15T17:38:38.019067Z","shell.execute_reply":"2021-07-15T17:38:38.525572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"I imported the libraries which were useful to my proposal of EDA the dataset. After entering the dataset, and have an overview of the data frame, I looked for missing values and I did not find any.\n\nTo have a summary of our features, I grouped the dataset into different parts and studied them separately. My studies included sorting, histogram, scatter plots, box plots, data frame, correlations, covariance size of the data, and shape of the arrays.\n\nFrom the previous studies, I found that we have duplicate values in one of our features which were \"amount\" so I removed them and continue with the new dataset.\n\nAlso, from different plots such as the box plot, I noted the outliers values, So I defined the various percentile of the relevant axis to drop them. After removing outliers, I compared the shape, size, and behavior of the removed outliers and the principal dataset.\n\nRegarding the questions and hypothesizes, I should say that;\n-\tI found a relationship and correlation between different features of the dataset.\n-\tThere were duplicate values in the dataset.\n- Customers in regions one and four, spent more money to buy their items. And region two has the lowers amount of purchase.\n-\tYes, there is a relationship between number of items purchased and amount spent.","metadata":{}}]}