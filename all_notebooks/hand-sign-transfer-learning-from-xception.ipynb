{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook I will build a model to detect and recognize American Manual Alphabet (AMA). A model that can understand sign language can help improve the lives of many people and recognizing the Alphabet is a good start for it.\nI will use the Xception model that trained on ImageNet dataset and it will demonstrate the power of Transfer Learning. Xception is a deep convolutional neural network architecture developed by Google researchers. It's an efficient architecture that relies on two main points:\n- Depthwise Separable Convolution.\n- Shortcuts between Convolution blocks as in ResNet.\n\nXception model got an extraordinary results on ImageNet dataset with less then 20% parameters than VGG16. With my Xception based model I got an accuracy result of allmost 100% on the validation data!\n"},{"metadata":{"_uuid":"6b4ea5a7-578f-4969-8a3f-b7a12b6a5d28","_cell_guid":"37adc7ce-0aca-418c-acd8-0313d9ef3b04","trusted":true},"cell_type":"code","source":"import os\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing:\nThe dataset contains 41 different signs represented as folders, with 1600 images for each sign - 26 alphabets, 10 digits and 5 extra symbols which are used to perform ancillary operations. For this work, I didn't use the digits because some of them are identical to letters (for example 0 and o, 5 and z) and the only way to distinguish them is by context (not in scope of this work)."},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = r'../input/hand-sign-recognition/original_images/original_images'\n\nclasses_wo_digits = os.listdir(PATH)\n\nclasses_wo_digits.sort()\n\nclasses_wo_digits = classes_wo_digits[10:]\n\nprint(classes_wo_digits)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I split the data to \"train\" (80%) and \"validation\" (20%) using Keras's ImageDataGenerator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = keras.preprocessing.image.ImageDataGenerator(\n                                            rescale=1./255, \n                                            validation_split=0.2\n                                                       )\n\ntrain_generator = datagen.flow_from_directory(\n                                        PATH,\n                                        target_size=(256, 256),\n                                        seed=51,\n                                        subset='training', \n                                        classes=classes_wo_digits\n                                              )\n\nvalidation_generator = datagen.flow_from_directory(\n                                        PATH,\n                                        target_size=(256, 256), \n                                        seed=51,\n                                        subset='validation', \n                                        shuffle=False, \n                                        classes=classes_wo_digits\n                                                   )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is an example of the first batch:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(4, 8, sharex=True, figsize=(10, 10))\n\nplt.subplots_adjust(bottom=0.1, left=0.01, right=0.99,\n                    top=0.9, hspace=0.35)\n\nfor i in range(4):\n    for j in range(8):\n        plt.gray()\n        axes[i, j].imshow(train_generator[0][0][8*i + j])\n        axes[i, j].set_title(\n          classes_wo_digits[\n              train_generator[0][1][8*i + j].argmax()\n                            ],\n          weight='bold', size=16)\n        axes[i, j].set_xticks([])\n        axes[i, j].set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building The Model:\nI imported the Xception model from keras with weights pre-trained on ImageNet. I didn't use the original top of the model and instead added 3 fully connected (FC) layers (the last one with units as the number of classes). The only trainable weights are the ones of the FC layers."},{"metadata":{"trusted":true},"cell_type":"code","source":"xception = Xception(include_top=False, input_shape=(256, 256, 3))\n\nx = xception.output\nx = layers.GlobalMaxPooling2D()(x)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dense(512, activation='relu')(x)\noutput = layers.Dense(31, activation='softmax')(x)\n\nmodel = Model(xception.input, output)\n\n# Freezing all the Imported Layers\nfor layers in xception.layers:\n    layers.trainable = False\n    \nmodel.compile(optimizer='adam', loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\"])\n\nearlystop = EarlyStopping(monitor='val_accuracy', patience=20,\n                          verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training:"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(train_generator, \n                 validation_data=validation_generator,\n                 steps_per_epoch=100, validation_steps=10,\n                 epochs=50, callbacks=[earlystop])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The model finished training after only half of the epochs!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.plot(hist.history[\"accuracy\"])\nplt.plot(hist.history['val_accuracy'])\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title(\"Model Metrics\", weight='bold', size=18)\nplt.ylabel(\"Accuracy / Loss\", size=14)\nplt.xlabel(\"Epoch\", size=14)\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\",\n            \"Training Loss\", \"Validation Loss\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating:"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.evaluate(validation_generator, steps=280)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The model predict correctly allmost 100% of the valdiation data!**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}