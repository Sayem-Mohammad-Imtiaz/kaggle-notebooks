{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Few take aways from this exercise:\n\n1) Catboost works really fast on GPU(use param task_type). Ligth GBM runs slow.\n\n2) Although we generally aim for model not to overfit, but this exercise wants as high accuracy on test data as it can. So one can keep on making model overfit on train data with marginal increase of accuracy on test set. But it eventually increases rank on LB, so many participants use this tactic. For this one can keep n_iterations very high.\n\n3) Features created using crosstab(prob_of_facility_to_stay, prob_of_age_to_stay) gave good improvement to score.\n\n4) I didn't remove feature which have low feature importance as it might marginally decrease accuracy.\n\n5) Models tried--> Cat Boost, Light GBM, XGBoost\n\n6) Since I wanted to use large number of iterations and Catboost was fast using GPU so I used it as final model(train time <10min). Although Light GBM was better in accuracy if both models are compared for less number of iterations. XGboost didn't perform that well.\n\n7) While doing CV, some folds give lower accuracy and some higher so one clever tactic some participants used was to sum up predictions of only those folds which are giving accuracy score on test set above your desired threshold and then used argmax function on that only instead of on all folds. This might help since we are aiming only for 'Accuracy' but in general it is not good practice.\n\n8) I also tried undersampling of those categories of target variable which have higher percentage. But I affected accuracy really hard. Parameter tuning also didn't gave noticeable improvement in performance.\n\n9) It is important to do Stratified K fold in classification if class imbalance is high.\n\n\n**Did this exercise after the competition ended. Got rank of 51 on private LB.**\n\nhttps://datahack.analyticsvidhya.com/contest/janatahack-healthcare-analytics-ii/#About"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom catboost import CatBoostClassifier\nimport catboost\nfrom catboost import *\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom lightgbm import LGBMModel,LGBMClassifier\nfrom sklearn.model_selection import train_test_split,StratifiedShuffleSplit,StratifiedKFold\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\n'''\nhttps://datahack.analyticsvidhya.com/contest/janatahack-healthcare-analytics-ii/#ProblemStatement\n'''\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data import, Visualization, Pre-processing"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/janatahack-healthcare-analytics-part-2/train.csv\")\ntest = pd.read_csv(\"../input/janatahack-healthcare-analytics-part-2/test.csv\")\ntrain_data_dict = pd.read_csv(\"../input/janatahack-healthcare-analytics-part-2/train_data_dict.csv\")\nsample_sub = pd.read_csv(\"../input/janatahack-healthcare-analytics-part-2/sample_submission.csv\")\nprint('Shape of raw train data: ',train.shape)\nprint('Shape of raw test data: ',test.shape)\nprint(train.columns)\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check = train.drop(['case_id','patientid'],axis=1)\n\ndup_index_list = check[check.duplicated()].index   # duplicaet rows after removing case ID, patient ID, 152 such observations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(train.index[dup_index_list],inplace=True)\ntrain.reset_index(drop=True, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Num unique in Hospital_code: ',train.Hospital_code.nunique())\nprint('Num unique in Hospital_type_code: ',train.Hospital_type_code.nunique())\nprint('Num unique in City_Code_Hospital: ',train.City_Code_Hospital.nunique())\nprint('Num unique in Hospital_region_code: ',train.Hospital_region_code.nunique())\nprint('Num unique in Department: ',train.Department.nunique())\nprint('Num unique in Ward_Type: ',train.Ward_Type.nunique())\n\nprint('Num unique in Ward_Facility_Code: ',train.Ward_Facility_Code.nunique())\nprint('Num unique in Bed Grade: ',train['Bed Grade'].nunique())\nprint('Num unique in City_Code_Patient: ',train.City_Code_Patient.nunique())\nprint('Num unique in patientid: ',train.patientid.nunique())\n\nprint('Num unique in Type of Admission: ',train['Type of Admission'].nunique())\nprint('Num unique in Available Extra Rooms in Hospital: ',train['Available Extra Rooms in Hospital'].nunique())\nprint('Num unique in Severity of Illness: ',train['Severity of Illness'].nunique())\n\nprint('Num unique in Age: ',train['Age'].nunique())\nprint('Num unique in Visitors with Patient: ',train['Visitors with Patient'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Stay'] = 'test_data'\ntotal = train.append(test)\ntotal.reset_index(inplace=True,drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['patientid'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total['Bed Grade'] = total.groupby(['Department','Hospital_code','Ward_Type'])[\"Bed Grade\"].apply(lambda x: x.fillna(x.value_counts().index[0]))\n\nidx = total['City_Code_Patient'].isnull( )\ntotal['City_Code_Patient'][ idx ] = 17 #Taking distinct values of this variable you will see all values from 1 to 37 but 17 would be missing. SO I am imputing it with 17","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total['Bed Grade']=total['Bed Grade'].astype(int)\ntotal['City_Code_Patient']=total['City_Code_Patient'].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train['Type of Admission'],train['Severity of Illness'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(y='Ward_Facility_Code', x='Admission_Deposit', data=total)    # to plot scatter graph between two continuous variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = total.Admission_Deposit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Stay\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_treatment(data,p1,p99):\n    data_X = data.copy()\n    col = \"Admission_Deposit\"\n    data_X[col][data_X[col] <= p1] = p1\n    data_X[col][data_X[col] >= p99] = p99\n    \n  \n    return data_X\n\na = train[\"Admission_Deposit\"].quantile([0.25,0.75]).values\np_cap = a[1] + 1.5*(a[1]-a[0])\np_clip = a[0] - 1.5*(a[1]-a[0])\n\ntotal = outlier_treatment(total,p_clip,p_cap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"total.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# varibale to check if a patient is from same city as that of hospital\ndef row_same_city(a,b):\n    if a ==b:\n        return 1\n    \n    return 0\n\ntotal['in_same_city'] = total.apply(lambda row: row_same_city(row['City_Code_Hospital'],row['City_Code_Patient']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total['Avg_deposit_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('mean')\ntotal['Avg_deposit_2'] = total.groupby(['Hospital_code'])['Admission_Deposit'].transform('mean')\ntotal['Avg_deposit_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('mean')\ntotal['Avg_deposit_4'] = total.groupby(['Ward_Type'])['Admission_Deposit'].transform('mean')\ntotal['Avg_deposit_5'] = total.groupby(['Ward_Type','Bed Grade'])['Admission_Deposit'].transform('mean')\ntotal['Avg_deposit_8'] = total.groupby(['Age'])['Admission_Deposit'].transform('mean')\ntotal['Avg_deposit_9'] = total.groupby(['Ward_Type','Ward_Facility_Code'])['Admission_Deposit'].transform('mean')\n\n'''\ntotal['Median_deposit_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_2'] = total.groupby(['Hospital_code'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_4'] = total.groupby(['Ward_Type'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_5'] = total.groupby(['Ward_Type','Bed Grade'])['Admission_Deposit'].transform('median')\n\ntotal['Median_deposit_6'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_7'] = total.groupby(['Hospital_code'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_8'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_9'] = total.groupby(['Ward_Type'])['Admission_Deposit'].transform('median')\ntotal['Median_deposit_10'] = total.groupby(['Ward_Type','Bed Grade'])['Admission_Deposit'].transform('median')\n\ntotal['max_deposit_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_2'] = total.groupby(['Hospital_code'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_4'] = total.groupby(['Ward_Type'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_5'] = total.groupby(['Ward_Type','Bed Grade'])['Admission_Deposit'].transform('max')\n\ntotal['max_deposit_6'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_7'] = total.groupby(['Hospital_code'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_8'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_9'] = total.groupby(['Ward_Type'])['Admission_Deposit'].transform('max')\ntotal['max_deposit_10'] = total.groupby(['Ward_Type','Bed Grade'])['Admission_Deposit'].transform('max')\n\n'''\n\ntotal['min_deposit_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('min')\ntotal['min_deposit_2'] = total.groupby(['Hospital_code'])['Admission_Deposit'].transform('min')\ntotal['min_deposit_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('min')\ntotal['min_deposit_4'] = total.groupby(['Ward_Type'])['Admission_Deposit'].transform('min')\ntotal['min_deposit_5'] = total.groupby(['Ward_Type','Bed Grade'])['Admission_Deposit'].transform('min')\n\ntotal['min_deposit_6'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('min')\n\n'''\ntotal['min_deposit_7'] = total.groupby(['Hospital_code'])['Admission_Deposit'].transform('min')\n'''\n\ntotal['min_deposit_8'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Admission_Deposit'].transform('min')\ntotal['min_deposit_9'] = total.groupby(['Ward_Type'])['Admission_Deposit'].transform('min')\ntotal['min_deposit_10'] = total.groupby(['Ward_Type','Bed Grade'])['Admission_Deposit'].transform('min')\n\n\n\ntotal['num_visit_emergency_gp_PDA'] = (total[total['Type of Admission']=='Emergency'].groupby(['patientid','Department','Type of Admission'])['patientid'].transform('count'))\ntotal['num_visit_emergency_gp_PDA'].fillna(0,inplace=True)\n\ntotal['num_visit_Trauma_gp_PDA'] = (total[total['Type of Admission']=='Trauma'].groupby(['patientid','Department','Type of Admission'])['patientid'].transform('count'))\ntotal['num_visit_Trauma_gp_PDA'].fillna(0,inplace=True)\n\ntotal['num_visit_Urgent_gp_PDA'] = (total[total['Type of Admission']=='Urgent'].groupby(['patientid','Department','Type of Admission'])['patientid'].transform('count'))\ntotal['num_visit_Urgent_gp_PDA'].fillna(0,inplace=True)\n\ntotal['num_visit_emergency_gp_H'] = (total[total['Type of Admission']=='Emergency'].groupby(['Hospital_code'])['patientid'].transform('count'))\ntotal['num_visit_emergency_gp_H'].fillna(0,inplace=True)\n\ntotal['num_visit_Trauma_gp_H'] = (total[total['Type of Admission']=='Trauma'].groupby(['Hospital_code'])['patientid'].transform('count'))\ntotal['num_visit_Trauma_gp_H'].fillna(0,inplace=True)\n\ntotal['num_visit_Urgent_gp_H'] = (total[total['Type of Admission']=='Urgent'].groupby(['Hospital_code'])['patientid'].transform('count'))\ntotal['num_visit_Urgent_gp_H'].fillna(0,inplace=True)\n\ntotal['Avg_visitors_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('mean')\ntotal['Avg_visitors_2'] = total.groupby(['Hospital_code'])['Visitors with Patient'].transform('mean')\ntotal['Avg_visitors_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('mean')\ntotal['Avg_visitors_4'] = total.groupby(['Ward_Type'])['Visitors with Patient'].transform('mean')\ntotal['Avg_visitors_5'] = total.groupby(['Ward_Type','Bed Grade'])['Visitors with Patient'].transform('mean')\n\ntotal['Avg_visitors_6'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('mean')\ntotal['Avg_visitors_8'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('mean')\n\ntotal['Median_visitors_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_2'] = total.groupby(['Hospital_code'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_4'] = total.groupby(['Ward_Type'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_5'] = total.groupby(['Ward_Type','Bed Grade'])['Visitors with Patient'].transform('median')\n\ntotal['Median_visitors_6'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_7'] = total.groupby(['Hospital_code'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_8'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_9'] = total.groupby(['Ward_Type'])['Visitors with Patient'].transform('median')\ntotal['Median_visitors_10'] = total.groupby(['Ward_Type','Bed Grade'])['Visitors with Patient'].transform('median')\n\ntotal['max_visitors_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_2'] = total.groupby(['Hospital_code'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_4'] = total.groupby(['Ward_Type'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_5'] = total.groupby(['Ward_Type','Bed Grade'])['Visitors with Patient'].transform('max')\n\ntotal['max_visitors_6'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_7'] = total.groupby(['Hospital_code'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_8'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_9'] = total.groupby(['Ward_Type'])['Visitors with Patient'].transform('max')\ntotal['max_visitors_10'] = total.groupby(['Ward_Type','Bed Grade'])['Visitors with Patient'].transform('max')\n\ntotal['min_visitors_1'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('min')\ntotal['min_visitors_2'] = total.groupby(['Hospital_code'])['Visitors with Patient'].transform('min')\ntotal['min_visitors_3'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('min')\ntotal['min_visitors_4'] = total.groupby(['Ward_Type'])['Visitors with Patient'].transform('min')\ntotal['min_visitors_5'] = total.groupby(['Ward_Type','Bed Grade'])['Visitors with Patient'].transform('min')\n\ntotal['min_visitors_6'] = total.groupby(['Hospital_code','Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('min')\ntotal['min_visitors_7'] = total.groupby(['Hospital_code'])['Visitors with Patient'].transform('min')\ntotal['min_visitors_8'] = total.groupby(['Department', 'Ward_Type','Ward_Facility_Code','Bed Grade'])['Visitors with Patient'].transform('min')\n\n\ntotal['type_of_ad_cnt_1'] = total.groupby(['Ward_Type','Ward_Facility_Code'])['Type of Admission'].transform('count')\ntotal['type_of_ad_cnt_2'] = total.groupby(['Ward_Type'])['Type of Admission'].transform('count')\ntotal['type_of_ad_cnt_3'] = total.groupby(['Ward_Facility_Code'])['Type of Admission'].transform('count')\ntotal['type_of_ad_cnt_4'] = total.groupby(['Age'])['Type of Admission'].transform('count')\ntotal['type_of_ad_cnt_5'] = total.groupby(['Age'])['Ward_Facility_Code'].transform('count')\ntotal['type_of_ad_cnt_6'] = total.groupby(['Hospital_code'])['Age'].transform('count')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mapping few variables w.r.t their relative intuitive magnitude"},{"metadata":{"trusted":true},"cell_type":"code","source":"m1 = {'Minor':1, 'Moderate':2, 'Extreme':3}\nm2 = {'Trauma':1, 'Urgent':2, 'Emergency':3}\nm3 = {'0-10':1, '11-20':2, '21-30':3, '31-40':4, '41-50':5, '51-60':6, '61-70':7,\n       '71-80':8, '81-90':9, '91-100':10}\n\n\n\ntotal['Type of Admission'] = total['Type of Admission'].map(m2)\ntotal['Severity of Illness'] = total['Severity of Illness'].map(m1)\ntotal['Age'] = total['Age'].map(m3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following kind of varibales are good as they represent probability of patient from a city w.r.t differnet Stay categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = pd.crosstab(total.in_same_city,total.Stay).drop(['test_data'],axis=1)\nprob_of_same_city_to_stay = abc.iloc[:, :].apply(lambda x: x / x.sum(),axis=1)\nprob_of_same_city_to_stay.columns = [str(col) + '_same_city_prob' for col in prob_of_same_city_to_stay.columns]\nprob_of_same_city_to_stay.reset_index(inplace=True)\nprob_of_same_city_to_stay.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = pd.crosstab(total.Ward_Facility_Code,total.Stay).drop(['test_data'],axis=1) #dropping test_data column will get us values only for train set\nprob_of_facility_to_stay = abc.iloc[:, :].apply(lambda x: x / x.sum(),axis=1)\nprob_of_facility_to_stay.columns = [str(col) + '_facility_prob' for col in prob_of_facility_to_stay.columns]\nprob_of_facility_to_stay.reset_index(inplace=True)\nprob_of_facility_to_stay.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = pd.crosstab(total.Age,total.Stay).drop(['test_data'],axis=1) #dropping test_data column will get us values only for train set\nprob_of_age_to_stay = abc.iloc[:, :].apply(lambda x: x / x.sum(),axis=1)\nprob_of_age_to_stay.columns = [str(col) + '_age_prob' for col in prob_of_age_to_stay.columns]\nprob_of_age_to_stay.reset_index(inplace=True)\nprob_of_age_to_stay.head(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = pd.crosstab(total['Severity of Illness'],total.Stay).drop(['test_data'],axis=1) #dropping test_data column will get us values only for train set*/\n\nprob_of_sev_ill_to_stay = abc.iloc[:, :].apply(lambda x: x / x.sum(),axis=1)\nprob_of_sev_ill_to_stay.columns = [str(col) + '_sever_prob' for col in prob_of_sev_ill_to_stay.columns]\nprob_of_sev_ill_to_stay.reset_index(inplace=True)\nprob_of_sev_ill_to_stay.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = pd.crosstab(total['Type of Admission'],total.Stay).drop(['test_data'],axis=1) #dropping test_data column will get us values only for train set*/\n\nprob_of_type_of_ad_to_stay = abc.iloc[:, :].apply(lambda x: x / x.sum(),axis=1)\nprob_of_type_of_ad_to_stay.columns = [str(col) + '_type_ad_prob' for col in prob_of_type_of_ad_to_stay.columns]\nprob_of_type_of_ad_to_stay.reset_index(inplace=True)\nprob_of_type_of_ad_to_stay.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc2 = total.groupby(['Age','Severity of Illness']).agg({'Age': 'count'})\n\nabc2 = abc2.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\nabc2.rename(columns={'Age':'perc'},inplace=True)\nabc2.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = total.merge(prob_of_age_to_stay, on='Age',how='left')\n\n#total = total.merge(prob_of_sev_ill_to_stay, on='Severity of Illness',how='left')  #decreasing perf\n\n#total = total.merge(prob_of_type_of_ad_to_stay, on='Type of Admission',how='left')  #decreasing perf\n\ntotal = total.merge(prob_of_same_city_to_stay, on='in_same_city',how='left')\n\ntotal = total.merge(prob_of_facility_to_stay, on='Ward_Facility_Code',how='left')\n\ntotal = total.merge(abc2, on=['Age','Severity of Illness'],how='left') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_hot = ['Ward_Type', 'Ward_Facility_Code']\n\ntotal = pd.get_dummies(total,columns=col_hot)  # creating one hot encoding varibales for only these two.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_to_drop = ['City_Code_Hospital',\n 'is_outlier',\n 'Avg_deposit_1',\n 'Avg_deposit_3',\n 'Avg_deposit_4',\n 'Avg_deposit_10',\n 'min_deposit_1',\n 'min_deposit_2',\n 'min_deposit_4',\n 'min_deposit_5',\n 'min_deposit_8',\n 'min_deposit_9',\n 'min_deposit_10',\n 'num_visit_emergency_gp_H',\n 'num_visit_Urgent_gp_H',\n 'Avg_visitors_1',\n 'Avg_visitors_3',\n 'Avg_visitors_8',\n 'Median_visitors_1',\n 'Median_visitors_6',\n 'Median_visitors_7',\n 'Median_visitors_9',\n 'Median_visitors_10',\n 'max_visitors_3',\n 'max_visitors_4',\n 'max_visitors_6',\n 'max_visitors_8',\n 'max_visitors_9',\n 'min_visitors_1',\n 'min_visitors_2',\n 'min_visitors_4',\n 'min_visitors_5',\n 'min_visitors_6',\n 'min_visitors_7',\n 'min_visitors_8','Median_visitors_8', 'max_visitors_7', 'max_visitors_10','Ward_Type_T', 'Ward_Type_U', 'Median_visitors_2','61-70_age_prob', \n                '71-80_age_prob', '91-100_age_prob',\n       'More than 100 Days_age_prob', '11-20_sever_prob', '31-40_sever_prob',\n       '41-50_sever_prob', '51-60_sever_prob', '61-70_sever_prob',\n       '71-80_sever_prob', '81-90_sever_prob', '91-100_sever_prob',\n       'More than 100 Days_sever_prob', 'Ward_Type_P', 'Ward_Type_R',\n       'Ward_Type_U', 'Ward_Facility_Code_F',\n       'Ward_Facility_Code_A','bin_separater', '11-20_same_city_prob', '21-30_same_city_prob',\n       '31-40_same_city_prob', '41-50_same_city_prob', '51-60_same_city_prob',\n       '61-70_same_city_prob', '71-80_same_city_prob', '81-90_same_city_prob',\n       '91-100_same_city_prob', 'More than 100 Days_same_city_prob',\n       '61-70_facility_prob', '71-80_facility_prob', '91-100_facility_prob',\n       'More than 100 Days_facility_prob', 'Ward_Facility_Code_B',\n       'Ward_Facility_Code_C', 'Ward_Facility_Code_D', 'Ward_Facility_Code_E']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfor i in feat_to_drop:\n    if i in total.columns:\n        total.drop(i,axis=1,inplace=True)\n        \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nobj = (total.dtypes=='object') + (total.dtypes=='category')\ncol = list(total.dtypes[obj].index)\n\ncol.remove('Stay')\nfor i in range(0,len(col)):\n    l = col[i]\n    total[l] = le.fit_transform(total[l])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking intra correlation of features(Now all are numeric)"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = total[~(total['Stay']=='test_data')].drop(['Stay'],axis=1).corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);    #without exact values\n\n# Threshold for removing correlated variables\nthreshold = 0.8\n\n# Absolute value correlation matrix\ncorr_matrix = corrmat.abs()\ncorr_matrix.head()\n\n# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()\n\n# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not dropping variables as it is marginally decreasing performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop correlated features\n#total.drop(columns = to_drop,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percentages of target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# percentage of target counts in the train set\n\n(train['Stay'].value_counts())*100/train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = total[~(total['Stay']=='test_data')].drop(['Stay'],axis=1)\nX.drop(['case_id','patientid'],axis=1,inplace=True)\ny = total[~(total['Stay']=='test_data')]['Stay']\n\nfinal_test = total[(total['Stay']=='test_data')].drop(['Stay'],axis=1)\nfinal_test.drop(['patientid'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=.30, random_state=150,stratify=y,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical column \ncat_col=['Hospital_code','Hospital_type_code', 'Hospital_region_code', 'Department'\n            ,'Bed Grade','City_Code_Patient','Type of Admission','Severity of Illness','Age']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Catboost Classifier without CV\n\nwith task type=GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\ncatb = CatBoostClassifier(\n    iterations=10000,\n   cat_features=cat_col,\n    random_seed=4,\n    learning_rate=0.05,\n    #subsample=0.7,\n    early_stopping_rounds=150,\n    eval_metric='Accuracy',\n    task_type='GPU'\n)\ncatb.fit(\n    X_train, y_train,\n    eval_set=(X_validation, y_validation),verbose=200\n)\nprint('Model is fitted: ' + str(catb.is_fitted()))\nprint('Model params:')\nprint(catb.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances = pd.Series(catb.feature_importances_, index=X_train.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\n\n\np_train_catb_val = catb.predict(X_validation)\nprint(accuracy_score(y_validation, p_train_catb_val))\n\np_train_catb = catb.predict(X_train)\nprint(accuracy_score(y_train, p_train_catb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"               \ncase_ids=final_test['case_id'].reset_index(drop=True)\n\nfinal_test_pred = catb.predict(final_test.drop(['case_id'],axis=1))\n\nak = pd.DataFrame(case_ids).reset_index(drop=True).merge(pd.DataFrame(final_test_pred,columns=[\"Stay\"]).reset_index(drop=True), left_index=True, right_index=True)\n\nak = ak[['case_id','Stay']]\nak.reset_index(drop=True,inplace=True)\nak.to_csv('test_pred_catboost_wo_CV.csv', index=False)\nak.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('test_pred_catboost_wo_CV.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Catboost Classifier with CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n##LightGBM\n\nprobs_final_test = np.zeros(shape=(len(final_test),11))\n\nn_fold = 6\nscores_cv_train = []\nscores_cv_test = []\n\navg_loss = []\n\nclass_list = []\n\n\nsssf = StratifiedShuffleSplit(n_splits=n_fold, test_size = 0.25 ,random_state=14)\n\nfor i, (idxT, idxV) in enumerate(sssf.split(X, y)):\n\n    print('Fold',i)\n\n    print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n\n    clf = CatBoostClassifier(\n    iterations=10000,\n   cat_features=cat_col,\n    random_seed=4,\n    learning_rate=0.05,\n    #subsample=0.7,\n    early_stopping_rounds=150,\n    eval_metric='Accuracy',\n    task_type='GPU'\n)    \n\n    clf.fit(X.iloc[idxT], y.iloc[idxT], \n                eval_set=[(X.iloc[idxV],y.iloc[idxV])],\n                verbose=100)\n    \n    class_list = list(clf.classes_)\n\n\n    probs_cv_train = clf.predict(X.iloc[idxT])\n    score_train = accuracy_score( y.iloc[idxT], probs_cv_train)\n    scores_cv_train.append(score_train)\n    \n    \n    probs_cv_test = clf.predict(X.iloc[idxV])\n    score_test = accuracy_score( y.iloc[idxV], probs_cv_test)\n    scores_cv_test.append(score_test)\n    \n\n    probs_final_test  += clf.predict_proba(final_test.drop(['case_id'],axis=1))\n\n    print('#'*100)\n\n    if i==0:\n        feat_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\n        feat_importances.nlargest(20).plot(kind='barh')\n        \nprint(scores_cv_train)\nprint(scores_cv_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncase_ids=final_test['case_id'].reset_index(drop=True)\nmaxInrows= np.argmax(probs_final_test/n_fold, axis=1)\na = class_list\nfinal_test_pred = [a[idx] for idx in maxInrows]\n\nak = pd.DataFrame(case_ids).reset_index(drop=True).merge(pd.DataFrame(final_test_pred,columns=[\"Stay\"]).reset_index(drop=True), left_index=True, right_index=True)\n\nak = ak[['case_id','Stay']]\nak.reset_index(drop=True,inplace=True)\nak.to_csv('test_pred_catboost_with_CV.csv', index=False)\nak.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('test_pred_catboost_with_CV.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Light GBM without CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LGBMClassifier( n_estimators=1000,\n                         #objective ='multiclass',\n                         feature_name =cat_col,max_depth=20,\n                     eval_metric='multiclass',\n                     \n            )        \n\nclf.fit(X_train, y_train, \n            eval_set=[(X_validation,y_validation)],\n            verbose=100,early_stopping_rounds=50\n           )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_train_lgbm = clf.predict(X_train)\nprint(\"train score :\",accuracy_score(y_train, p_train_lgbm))\n\np_train_lgbm_val = clf.predict(X_validation)\nprint(\"Validation score :\",accuracy_score(y_validation, p_train_lgbm_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"               \ncase_ids=final_test['case_id'].reset_index(drop=True)\n\nfinal_test_pred = clf.predict(final_test.drop(['case_id'],axis=1))\n\nak = pd.DataFrame(case_ids).reset_index(drop=True).merge(pd.DataFrame(final_test_pred,columns=[\"Stay\"]).reset_index(drop=True), left_index=True, right_index=True)\n\nak = ak[['case_id','Stay']]\nak.reset_index(drop=True,inplace=True)\nak.to_csv('test_pred_lgb_wo_CV.csv', index=False)\nak.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Light GBM with CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n##LightGBM\n\nprobs_final_test = np.zeros(shape=(len(final_test),11))\n\nn_fold = 8\nscores_cv_train = []\nscores_cv_test = []\n\navg_loss = []\n\nclass_list = []\n\n\nsssf = StratifiedShuffleSplit(n_splits=n_fold, test_size = 0.25 ,random_state=14)\n\nfor i, (idxT, idxV) in enumerate(sssf.split(X, y)):\n\n    print('Fold',i)\n\n    print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n\n    clf = LGBMClassifier(colsample_bytree=0.7, n_estimators=700,\n                             objective ='multiclass',\n                             feature_name =cat_col,\n                max_depth=15,learning_rate=0.05\n                )        \n\n    clf.fit(X.iloc[idxT], y.iloc[idxT], \n                eval_set=[(X.iloc[idxV],y.iloc[idxV])],\n                verbose=100,eval_metric=['multiclass'],\n                early_stopping_rounds=30)\n    \n    class_list = list(clf.classes_)\n\n\n    probs_cv_train = clf.predict(X.iloc[idxT])\n    score_train = accuracy_score( y.iloc[idxT], probs_cv_train)\n    scores_cv_train.append(score_train)\n    \n    \n    probs_cv_test = clf.predict(X.iloc[idxV])\n    score_test = accuracy_score( y.iloc[idxV], probs_cv_test)\n    scores_cv_test.append(score_test)\n    \n\n    probs_final_test  += clf.predict_proba(final_test.drop(['case_id'],axis=1))\n\n    print('#'*100)\n\n    if i==0:\n        feat_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\n        feat_importances.nlargest(20).plot(kind='barh')\n        \nprint(scores_cv_train)\nprint(scores_cv_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncase_ids=final_test['case_id'].reset_index(drop=True)\nmaxInrows= np.argmax(probs_final_test/n_fold, axis=1)\na = class_list\nfinal_test_pred = [a[idx] for idx in maxInrows]\n\nak = pd.DataFrame(case_ids).reset_index(drop=True).merge(pd.DataFrame(final_test_pred,columns=[\"Stay\"]).reset_index(drop=True), left_index=True, right_index=True)\n\nak = ak[['case_id','Stay']]\nak.reset_index(drop=True,inplace=True)\nak.to_csv('test_pred_lgb_with_CV.csv', index=False)\nak.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}