{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n        print(dirname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport random\nimport shutil\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining Base directory"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_dir = os.path.join(\"/kaggle/input/multiclass-weather-dataset/dataset/\")\nos.listdir(base_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"/train/\"\ntest_dir = base_dir + \"alien_test/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the image folders are not in structure to feed the generator. In order to structurize it, we copy the whole tree and remove the unnecessary folders."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code to replicate the whole directory\n\ndef copytree(src, dst, symlinks=False, ignore=None):\n    for item in os.listdir(src):\n        s = os.path.join(src, item)\n        d = os.path.join(dst, item)\n        if os.path.isdir(s):\n            shutil.copytree(s, d, symlinks, ignore)\n        else:\n            shutil.copy2(s, d)\n            \ncopytree(base_dir, train_dir) # Define source directory and destination directory\n\n# Here we remove the unwanted folders by condition\n            \nfor i in os.listdir(train_dir):\n    if i not in ['sunrise', 'shine', 'cloudy', 'rainy', 'foggy']:\n        try:\n            os.remove(train_dir + i)\n        except:\n            shutil.rmtree(train_dir + i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train directory -->\", os.listdir(train_dir))\nprint(\"Test directory -->\", os.listdir(test_dir)[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random image generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying random image from the dataset\n\nfig, ax = plt.subplots(1, 5, figsize=(15, 10))\n\nsample_paper = random.choice(os.listdir(train_dir + \"rainy\"))\nimage = load_img(train_dir + \"rainy/\" + sample_paper)\nax[0].imshow(image)\nax[0].set_title(\"Rainy\")\nax[0].axis(\"Off\")\n\nsample_rock = random.choice(os.listdir(train_dir + \"foggy\"))\nimage = load_img(train_dir + \"foggy/\" + sample_rock)\nax[1].imshow(image)\nax[1].set_title(\"Foggy\")\nax[1].axis(\"Off\")\n\nsample_scissor = random.choice(os.listdir(train_dir + \"shine\"))\nimage = load_img(train_dir + \"shine/\" + sample_scissor)\nax[2].imshow(image)\nax[2].set_title(\"Shine\")\nax[2].axis(\"Off\")\n\nsample_scissor = random.choice(os.listdir(train_dir + \"sunrise\"))\nimage = load_img(train_dir + \"sunrise/\" + sample_scissor)\nax[3].imshow(image)\nax[3].set_title(\"Sunrise\")\nax[3].axis(\"Off\")\n\nsample_scissor = random.choice(os.listdir(train_dir + \"cloudy\"))\nimage = load_img(train_dir + \"cloudy/\" + sample_scissor)\nax[4].imshow(image)\nax[4].set_title(\"Cloudy\")\nax[4].axis(\"Off\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    \n    tf.keras.layers.Dense(256, activation='relu'),\n    \n    tf.keras.layers.Dense(5, activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy',\n              optimizer = 'SGD',\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callback function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.85):\n            print(\"\\nReached >85% accuracy so cancelling training!\")\n            self.model.stop_training = True\n        \ncallbacks = myCallback()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.4, # Shifting image width by 40%\n      height_shift_range=0.4,# Shifting image height by 40%\n      shear_range=0.2,       # Rotation across X-axis by 20%\n      zoom_range=0.3,        # Image zooming by 30%\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = (150, 150),\n    class_mode = 'categorical',\n    batch_size = 20\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This dataset doesn't have any validation data. So, there is no need to define Validation generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n      train_generator,\n      steps_per_epoch = np.ceil(1500/20),  # 1500 images = batch_size * steps\n      epochs = 50,\n      callbacks=[callbacks],\n      verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of the model on train data is {:.2f}%\".format(history.history[\"accuracy\"][-1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = os.listdir(os.path.join(test_dir))\n\ntest_df = pd.DataFrame({'Image': test_img})\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    test_dir, \n    x_col = 'Image',\n    y_col = None,\n    class_mode = None,\n    target_size = (150, 150),\n    batch_size = 20,\n    shuffle = False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict_generator(test_generator, steps = int(np.ceil(30/20)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Label Mapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identifying the classes\n\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\nlabel_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Label'] = np.argmax(predict, axis = -1) # axis = -1 --> To compute the max element index within list of lists\n\ntest_df['Label'] = test_df['Label'].replace(label_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.Label.value_counts().plot.bar(color = ['red','blue','green','yellow','orange'])\nplt.xticks(rotation = 0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v = random.randint(0, 12)\n\nsample_test = test_df.iloc[v:(v+18)].reset_index(drop = True)\nsample_test.head()\n\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['Image']\n    category = row['Label']\n    img = load_img(test_dir + filename, target_size = (150, 150))\n    plt.subplot(6, 3, index + 1)\n    plt.imshow(img)\n    plt.xlabel(filename + ' ( ' + \"{}\".format(category) + ' )' )\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis = []\nfor ind in test_df.index: \n    if(test_df['Label'][ind] in test_df['Image'][ind]):\n        lis.append(1)\n    else:\n        lis.append(0)\n\nprint(\"Accuracy of the model on test data is {:.2f}%\".format((sum(lis)/len(lis))*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To increase the accuracy of the model on unseen data we need more training data in that way model can be improved!!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}