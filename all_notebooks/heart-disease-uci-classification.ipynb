{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ndataset = pd.read_csv('../input/heart.csv')\nX = dataset.iloc[:,:-1].values\ny = dataset.iloc[:,-1].values\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Encoding Categorical Data\nfrom sklearn.preprocessing import OneHotEncoder\n#cp\noneHotEncoder = OneHotEncoder(categorical_features=[2], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#restecg\noneHotEncoder = OneHotEncoder(categorical_features=[8], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#slope\noneHotEncoder = OneHotEncoder(categorical_features=[13], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#ca\noneHotEncoder = OneHotEncoder(categorical_features=[15], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n#thal\noneHotEncoder = OneHotEncoder(categorical_features=[19], n_values='auto')\noneHotEncoder.fit(X)\nX = oneHotEncoder.transform(X).toarray()\nX = X[:, 1:]\n\nfrom sklearn.preprocessing import StandardScaler\nscalerX = StandardScaler()\nX = scalerX.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51c565e5ea7497a5d342dc99b3c3ad9e2e8bb62d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2917d79d61f40c21f5b33473c20a9ad2bc298005"},"cell_type":"code","source":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Logistic Regression :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a101aec406cdd28b678b7b517adb1e37654d9de"},"cell_type":"code","source":"#K Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"K Nearest Neighbors :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be1be4d3f2179b081b732f6455382a55af326f47"},"cell_type":"code","source":"#Support Vector Machine\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='linear',random_state=0)\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Support Vector Machine :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31714aef9930f2b6340a17d18f51c6ed890f2721"},"cell_type":"code","source":"#Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Gaussian Naive Bayes :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84bc0824c8336717679ff0c908dcfbcd5520b20e"},"cell_type":"code","source":"#Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier as DT\nclassifier = DT(criterion='entropy', random_state=0)\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Decision Tree Classifier :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9b5cdb0d068cae4e59e6fc0141fddd07fc12aa0"},"cell_type":"code","source":"#Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier as RF\nclassifier = RF(n_estimators=10, criterion='entropy', random_state=0)\nclassifier.fit(XTrain,yTrain)\nyPred = classifier.predict(XTest)\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Random Forest Classifier :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e362e3db01bb25bde91ee2a9c19918048a315b4"},"cell_type":"code","source":"#Artificial Neural Network\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n#Initialising ANN\nclassifier = Sequential()\n\n#Adding the first hidden layer or the input layer\nclassifier.add(Dense(activation='relu',\n                     kernel_initializer='uniform',\n                     input_dim=22,\n                     units=12))\n#Adding the second hidden layer\nclassifier.add(Dense(activation='relu',\n                     kernel_initializer='uniform',\n                     units=12))\n#Adding the output layer\nclassifier.add(Dense(activation='sigmoid',\n                     kernel_initializer='uniform',\n                     units=1))\n\n#Compiling the ANN\nclassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nprint(classifier.summary())\n\n#Fitting the ANN\nhistory = classifier.fit(XTrain, yTrain, batch_size=5, epochs=20, verbose=1)\nfrom matplotlib import pyplot as plt\nplt.plot(history.history['acc'],'green')\nplt.plot(history.history['loss'],'red')\nplt.title('Model Accuracy-Loss')\nplt.xlabel('Epoch')\nplt.legend(['Accuracy','Loss'])\nplt.show()\n\n#Predicting the Test set Results\nyPred = classifier.predict(XTest)\nyPred = (yPred>0.5) #Since output is probability\ncm = confusion_matrix(yTest,yPred)\naccuracy = accuracy_score(yTest,yPred)\nprint(\"Artificial Neural Network Classifier :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}