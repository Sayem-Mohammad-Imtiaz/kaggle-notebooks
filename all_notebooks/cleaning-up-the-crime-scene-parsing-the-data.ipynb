{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"975b3b3b-1f68-8d37-4412-776bd871aebd"},"source":"# Cleaning Up The Crime Scene: Parsing The Data\n\n### Table of Contents\n\n * Introduction\n * Loading the Data\n * Properly Parsing School Names\n * Getting a DataFrame\n * Divvying Data Using Quantiles\n * Plotting a Distribution\n * Functional Data Processing\n * Parsing Law Enforcement Data\n * Parsing Offenses Data\n * Summary: Where To From Here\n\n<br />\n<br />\n<br />"},{"cell_type":"markdown","metadata":{"_cell_guid":"2d527660-6f5a-b08d-e396-2a807ae28d6b"},"source":"## Introduction\n\nThis data set contains information about crimes and law enforcement agencies in the State of California, and is provided by the FBI. The data set consists of 8 CSV files, 4 with data about law enforcement officers and 4 with data about crimes. The data is poorly formatted, and only 2 of the CSV files can be loaded as Pandas DataFrames without much effort.\n\nIn this notebook, we'll be walking through the use of regular expressions and other low-level drudgery to parse this odd assortment of typos, Linux and Windows newline characters, and an all-around tasteless use of commas, and stuff this processing into some functions that will magically return nice tidy DataFrames.\n\n(An alternative to using Python is to use command line tools like `sed` or `awk` to do the same kind of processing. However, `sed` is a line-based tool, and as we'll see, there are some issues with the data that require dealing with multiple lines. It's possible to use `awk`, but mastery of `awk` requires time and practice. Python is a good alternative.)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc05467c-b5db-3cc7-a008-4af8e7df06a9"},"outputs":[],"source":"# must for data analysis\n% matplotlib inline\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.pyplot import *\n\n# useful for data wrangling\nimport io, os, re, subprocess\n\n# for sanity\nfrom pprint import pprint"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3365fd6b-a470-7da7-1eea-c9894ed67acc"},"outputs":[],"source":"data_files = os.listdir('../input')\npprint(data_files)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b608c05f-0ed8-8f17-0b64-a69eb2f54aaf"},"source":"This notebook will demonstrate how to load just _one_ of these files - but each one presents its own challenges. Ultimately, we can abstract away the details of each file into (at least) 8 classes or 8 static methods. This notebook will cover the procedural programming that would go into those methods and classes, and illustrate how the components work. Then they can all be packaged up into a function.\n\n## Loading the Data\n\nStart by loading the lines of the file into a list of strings:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc3b14e7-c361-49ca-6ab0-0845ccc0e53f"},"outputs":[],"source":"filename = 'ca_law_enforcement_by_campus.csv'\nfilewpath = \"../input/\"+filename\n\nwith open(filewpath) as f:\n    lines = f.readlines()\n\n# First 6 lines are part of the header\nheader = ' '.join(lines[:6])\nheader = re.sub('\\n','',header)\ndata = lines[6:]\n\npprint([p.strip() for p in data[:10]])"},{"cell_type":"markdown","metadata":{"_cell_guid":"35ca587b-dddd-b2f8-43b1-fd3b9b392c1d"},"source":"This data should not be too tricky. Checking the number of commas:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d072979b-e01e-cf3e-03d8-14e84870128b"},"outputs":[],"source":"number_of_commas = [len(re.findall(',',p)) for p in data]\nprint(number_of_commas)"},{"cell_type":"markdown","metadata":{"_cell_guid":"645bc704-c699-13b2-3dfc-50fce786eba1"},"source":"All lines have 6 fields, one of which (attendance) always has one comma, which means all lines have at least 6 commas. Lines without 6 commas are empty and can be thrown out.\n\nOnce we are finished manipulating the data we can pass the resulting list of parsed strings on to a DataFrame."},{"cell_type":"markdown","metadata":{"_cell_guid":"91b4b947-f823-ccd4-62c3-09c962b5cc5e"},"source":"## Properly Parsing School Names\n\nProperly parsing school names is straightforward: there are two fields, University/College (which gives the university system of campuses) and Campus (which gives the particular campus location). \n\nWhile parsing this data, we can also add a check to make sure we're ignoring empty lines, which in this file means four or more commas in a row: `,,,,`"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dee8809a-51b9-b862-46b0-65d0098a6c8f"},"outputs":[],"source":"# Parse each line with a regular expression\nnewlines = []\nfor p in data:\n    if( len(re.findall(',,,,',p))==0):\n        newlines.append(p)\n\npprint(newlines[:10])"},{"cell_type":"markdown","metadata":{"_cell_guid":"a150f467-783e-fe80-e96b-540e42d11f18"},"source":"## Getting a DataFrame\n\nWe now have the raw data as a list of strings. We can process the string using some regular expression magic. Here's what the procedure will look like:\n* Join the list of strings together into one long string\n* Create a StringIO object to turn that string into a stream that can be read.\n* Extract column names from the (badly-mangled and poorly-formatted) header file\n* Pass the StringIO object and properly formatted column names to the Pandas `read_csv()` method to get a DataFrame.\n\nThe end result is a DataFrame that we can use to do a statistical analysis."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"655c02c4-c4fb-316a-b14b-05868a41dab1"},"outputs":[],"source":"one_string = '\\n'.join(newlines)\nsio = io.StringIO(one_string)\n\ncolumnstr = header\n\n# Get rid of \\r stuff\ncolumnstr = re.sub('\\r',' ',columnstr)\ncolumnstr = re.sub('\\s+',' ',columnstr)\n\n# Fix what can ONLY have been a typo, making this file un-parsable without superhuman regex abilities\ncolumnstr = re.sub(',Campus','Campus',columnstr)\n\ncolumns = columnstr.split(\",\")\n\ndf = pd.read_csv(sio,quotechar='\"',header=None,  names=columns, thousands=',')\ndf.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"06b62068-dde8-31e3-d19b-00b1b0bbecb1"},"source":"## Plotting a Distribution\n\nNow that we've successfully wrangled some of this data into a DataFrame, let's take it for a spin and make sure we're able to visualize the data without any issues."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5948b6ae-5201-fe59-47a2-c3f586325ae8"},"outputs":[],"source":"import seaborn as sns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8724972a-038c-a502-1969-35e842d303c3"},"outputs":[],"source":"sns.pairplot(df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"823560ed-5aaf-97bd-3776-9a6967daad8d"},"outputs":[],"source":"sns.distplot(df['Student enrollment'],bins=15,kde=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bbc8dc93-0460-e772-1c71-1bc06da505c8"},"source":"## Divvying Data using Quantiles\n\nOn a somewhat unrelated note - we can use the student enrollment data to divvy up schools into small, medium, and large schools by getting the quantiles of student enrollment. If we split the student enrollment distribution at its 33rd and 66th quantiles, we'll bin the schools into three groups of three sizes:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96a9ee00-2b16-d5bd-6049-ce104dc9fb68"},"outputs":[],"source":"# Divide the schools into three size bins using quantiles\nslice1 = np.percentile(df['Student enrollment'],q=33)\nslice2 = np.percentile(df['Student enrollment'],q=66)\n\ndef school_size(enrollment):\n    if enrollment < slice1:\n        return 'Small'\n    elif enrollment < slice2:\n        return 'Medium'\n    else:\n        return 'Large'\n\ndf['Size'] = df['Student enrollment'].map(lambda x : school_size(x))"},{"cell_type":"markdown","metadata":{"_cell_guid":"70a008f0-42a3-9003-e809-ba464048b502"},"source":"Now we can use that to get a conditional pair plot, with colors corresponding to the (terribly bland) labels of \"Small\", \"Medium\", and \"Large\". "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"42f0f69d-4bae-5cf9-00e8-deb4e9252ab4"},"outputs":[],"source":"sns.pairplot(df, hue=\"Size\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"b1309f7d-137c-3f62-57f6-397d15d518b4"},"source":"## Functional Data Processing\n\nOf the functionality we implemented above, the most useful to abstract away into an object or a function is the process of turning a file into a DataFrame. Furthermore, each file will likely have its own challenges with parsing and processing that will be unique to it.\n\nThis is a task best suited for 8 static methods, for the following reasons:\n* We have a large number of files, and each one has different formatting issues.\n* Each file has different special patterns, possible typos, etc.\n* The only shared information among each file parser is where the data file is located.\n\nWriting the parsing scripts as functions will help to separate the task of processing data and the task of analyzing data (hence, the reason we don't delve too deeply into the data above, just test out a few plots to make sure the DataFrame we imported is robust)."},{"cell_type":"markdown","metadata":{"_cell_guid":"6fc41149-12b5-a2b2-d150-5897f9345300"},"source":"## Parsing Enforcement Data\n\nWe'll start with the first four files, which contain information about law enforcement agencies broken down by agency, campus, city, and county. Each one has a roughly similar structure, so we can share some code, but there are too many particulars to make more code sharing among these methods useful."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab4f659c-d3bc-7831-4cae-f0647a1b2783"},"outputs":[],"source":"def ca_law_enforcement_by_agency(data_directory):\n    filename = 'ca_law_enforcement_by_agency.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        content = f.read()\n\n    content = re.sub('\\r',' ',content)\n    [header,data] = content.split(\"civilians\\\"\")\n    header += \"civilians\\\"\"\n    \n    data = data.strip()\n    agencies = re.findall('\\w+ Agencies', data)\n    all_but_agencies = re.split('\\w+ Agencies',data)\n    del all_but_agencies[0]\n    \n    newlines = []\n    for (a,aba) in zip(agencies,all_but_agencies):\n        newlines.append(''.join([a,aba]))\n    \n    # Combine into one long string, and do more processing\n    one_string = '\\n'.join(newlines)\n    sio = io.StringIO(one_string)\n    \n    # Process column names\n    columnstr = header.strip()\n    columnstr = re.sub('\\s+',' ',columnstr)\n    columnstr = re.sub('\"','',columnstr)\n    columns = columnstr.split(\",\")\n    columns = [s.strip() for s in columns]\n\n    # Load the whole thing into Pandas\n    df = pd.read_csv(sio,quotechar='\"',header=None,names=columns)\n\n    return df\n\n\ndf1 = ca_law_enforcement_by_agency('../input/')\ndf1.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f22226b-08be-297d-d387-2c9c89dece8c"},"outputs":[],"source":"def ca_law_enforcement_by_campus(data_directory):\n    filename = 'ca_law_enforcement_by_campus.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        lines = f.readlines()\n    \n    header = ' '.join(lines[:6])\n    header = re.sub('\\n','',header)\n    data = lines[6:]\n    \n    # Process each string in the list\n    newlines = []\n    for p in data:\n        if( len(re.findall(',,,,',p))==0):\n            newlines.append(re.sub(r'^([^\"]{1,})(,\"[0-9])' ,  r'\"\\1\"\\2', p))\n\n    # Combine into one long string, and do more processing\n    one_string = '\\n'.join(newlines)\n    sio = io.StringIO(one_string)\n\n    columnstr = header\n\n    # Get rid of \\r stuff\n    columnstr = re.sub('\\r',' ',columnstr)\n    columnstr = re.sub('\\s+',' ',columnstr)\n\n    # Fix what can ONLY have been a typo, making this file un-parsable without superhuman regex abilities\n    columnstr = re.sub(',Campus','Campus',columnstr)\n\n    columns = columnstr.split(\",\")\n\n    df = pd.read_csv(sio,quotechar='\"',header=None,  names=columns, thousands=',')\n\n    return df\n\n\ndf2 = ca_law_enforcement_by_campus('../input/')\ndf2.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"529c57a0-04fa-8670-b7d2-23a0d7b82393"},"outputs":[],"source":"def ca_law_enforcement_by_city(data_directory):\n    filename = 'ca_law_enforcement_by_city.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        content = f.read()\n\n    content = re.sub('\\r',' ',content)\n    [header,data] = content.split(\"civilians\\\"\")\n    header += \"civilians\\\"\"\n    \n    data = data.strip()\n        \n    # Combine into one long string, and do more processing\n    one_string = re.sub(r'([0-9]) ([A-Za-z])',r'\\1\\n\\2',data)\n    sio = io.StringIO(one_string)\n    \n    # Process column names\n    columnstr = header.strip()\n    columnstr = re.sub('\\s+',' ',columnstr)\n    columnstr = re.sub('\"','',columnstr)\n    columns = columnstr.split(\",\")\n\n    # Load the whole thing into Pandas\n    df = pd.read_csv(sio,quotechar='\"', header=None, names=columns, thousands=',')\n\n    return df\n\n\ndf3 = ca_law_enforcement_by_city('../input/')\ndf3.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c60bb91c-c4eb-7fe0-58b3-c1d423ef68a6"},"outputs":[],"source":"def ca_law_enforcement_by_county(data_directory):\n    filename = 'ca_law_enforcement_by_county.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        content = f.read()\n\n    content = re.sub('\\r',' ',content)\n    [header,data] = content.split(\"civilians\\\"\")\n    header += \"civilians\\\"\"\n    \n    data = data.strip()\n        \n    # Combine into one long string, and do more processing\n    one_string = re.sub(r'([0-9]) ([A-Za-z])',r'\\1\\n\\2',data)\n    sio = io.StringIO(one_string)\n    \n    # Process column names\n    columnstr = header.strip()\n    columnstr = re.sub('\\s+',' ',columnstr)\n    columnstr = re.sub('\"','',columnstr)\n    columns = columnstr.split(\",\")\n\n    # Load the whole thing into Pandas\n    df = pd.read_csv(sio,quotechar='\"',header=None,names=columns,thousands=',')\n\n    return df\n\n\ndf4 = ca_law_enforcement_by_county('../input/')\ndf4.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"23448e41-6b7e-0eca-fcf1-078b217d476a"},"source":"## Parsing Offenses Data\n\nNow that we've parsed information about law enforcement agencies and how many officers and civilians they employ, we can get to the business of parsing data that tells us how good a job the bobbies are doing - we'll be loading data about criminal offenses."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08a1c785-5bcb-46e0-0613-2b4ad9e9dec2"},"outputs":[],"source":"def ca_offenses_by_agency(data_directory):\n    filename = 'ca_offenses_by_agency.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        lines = f.readlines()\n    \n    one_line = '\\n'.join(lines[1:])\n    sio = io.StringIO(one_line)\n    \n    # Process column names\n    columnstr = lines[0].strip()\n    columnstr = re.sub('\\s+',' ',columnstr)\n    columnstr = re.sub('\"','',columnstr)\n    columns = columnstr.split(\",\")\n    \n    # Load the whole thing into Pandas\n    df = pd.read_csv(sio,quotechar='\"',names=columns, thousands=',')\n\n    return df\n\ndf5 = ca_offenses_by_agency('../input/')\ndf5.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1796048f-9b9d-1a47-0a61-ed3fcc08d798"},"outputs":[],"source":"def ca_offenses_by_campus(data_directory):\n    filename = 'ca_offenses_by_campus.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        lines = f.readlines()\n    \n    # Process each string in the list\n    newlines = []\n    for p in lines[1:]:\n        if( len(re.findall(',,,,',p))==0):\n            # This is a weird/senseless/badly formatted line\n            if( len(re.findall('Medical Center, Sacramento5',p))==0):\n                newlines.append(re.sub(r'^([^\"]{1,})(,\"[0-9])' ,  r'\"\\1\"\\2', p))\n\n    one_line = '\\n'.join(newlines)\n    sio = io.StringIO(one_line)\n    \n    # Process column names\n    columnstr = lines[0].strip()\n    columnstr = re.sub('\\s+',' ',columnstr)\n    columnstr = re.sub('\"','',columnstr)\n    columnstr = re.sub(',Campus','Campus',columnstr)\n    columns = columnstr.split(\",\")\n    \n    # Load the whole thing into Pandas\n    df = pd.read_csv(sio, quotechar='\"', thousands=',', names=columns)\n    \n    return df\n\ndf6 = ca_offenses_by_campus('../input/')\ndf6.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"362b61bb-509b-2c41-d373-da2d75d6c852"},"outputs":[],"source":"def ca_offenses_by_city(data_directory):\n    filename = 'ca_offenses_by_city.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        content = f.read()\n    \n    lines = content.split('\\n')\n    one_line = '\\n'.join(lines[1:])\n    sio = io.StringIO(one_line)\n    \n    # Process column names\n    columnstr = lines[0].strip()\n    columnstr = re.sub('\\s+',' ',columnstr)\n    columnstr = re.sub('\"','',columnstr)\n    columns = columnstr.split(\",\")\n    \n    # Load the whole thing into Pandas\n    df = pd.read_csv(sio,quotechar='\"',names=columns,thousands=',')\n\n    return df\n\ndf7 = ca_offenses_by_city('../input/')\ndf7.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"148543ec-a089-0b2d-0ba4-5c223771db57"},"outputs":[],"source":"def ca_offenses_by_county(data_directory):\n    filename = 'ca_offenses_by_county.csv'\n\n    # Load file into list of strings\n    with open(data_directory + '/' + filename) as f:\n        lines = f.readlines()\n    \n    one_line = '\\n'.join(lines[1:])\n    sio = io.StringIO(one_line)\n    \n    # Process column names\n    columnstr = lines[0].strip()\n    columnstr = re.sub('\\s+',' ',columnstr)\n    columnstr = re.sub('\"','',columnstr)\n    columns = columnstr.split(\",\")\n    \n    # Load the whole thing into Pandas\n    df = pd.read_csv(sio,quotechar='\"',names=columns,thousands=',')\n\n    return df\n\ndf8 = ca_offenses_by_county('../input/')\ndf8.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"5ab35db1-4237-dc57-9d44-b98a97503c47"},"source":"## Summary: Where To From Here\n\nNow that we've got functions to handle the ugly bits of regular expressions, cleanup, and parsing, we can set to work with analysis.\n\nWe have *many* choices of where to go from here with the analysis. I won't even begin to plot distributions, since, with 8 tables of data, we'll be here all day.\n\nThis notebook provides functions for obtaining each data file provided in this data set as a cleaned up DataFrame with a single function call, making it easier to combine these 8 DataFrames to explore this rich, multivariate dataset. Now get a move on, and get to the good stuff."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}