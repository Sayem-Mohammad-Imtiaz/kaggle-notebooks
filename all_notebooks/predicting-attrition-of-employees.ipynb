{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Project on Predicting the attrition of Employee in a Company","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the required libraries\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"importing the data set ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df = pd.read_csv('../input/hrdepartment20_may_2020.csv')\nemployee_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing Yes/no in attrition column with 1/0\nemployee_df['Attrition'] = employee_df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.hist(figsize=(20,20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing EmployeeCount, EmployeeNumber, Over18, StandardHours as they dont add much value to the code\n\nemployee_df.drop(['EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shape has reduced from 35 to 31 columns as we dropped 4 columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataframes for people who stayed or left\nleft_df = employee_df[employee_df['Attrition'] == 1]\nstayed_df = employee_df[employee_df['Attrition'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets analyse the data now","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#based on Age\nplt.figure(figsize=[15, 8])\nsns.countplot(x = 'Age', hue = 'Attrition', data = employee_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graph above, it could be observed that there were higher percentage of people leaving the firm at lower age .\nThis is quite evident from general intuition as well","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[20,12])\nplt.subplot(411)\nsns.countplot(x = 'JobRole', hue = 'Attrition', data = employee_df)\nplt.subplot(412)\nsns.countplot(x = 'MaritalStatus', hue = 'Attrition', data = employee_df)\nplt.subplot(413)\nsns.countplot(x = 'JobInvolvement', hue = 'Attrition', data = employee_df)\nplt.subplot(414)\nsns.countplot(x = 'JobLevel', hue = 'Attrition', data = employee_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(10,6))\n\nsns.kdeplot(left_df['DistanceFromHome'], label = 'Employees who left', shade = True, color = 'r')\nsns.kdeplot(stayed_df['DistanceFromHome'], label = 'Employees who Stayed', shade = True, color = 'b')\n\nplt.xlabel('Distance From Home')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the curve, it seems employees staying far from home have higher chances of attrition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\n\nsns.kdeplot(left_df['TotalWorkingYears'], shade = True, label = 'Employees who left', color = 'r')\nsns.kdeplot(stayed_df['TotalWorkingYears'], shade = True, label = 'Employees who Stayed', color = 'b')\n\nplt.xlabel('Total Working Years')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Employees with less total working years have higher attrition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking monthly income based on job role\nplt.figure(figsize=(10, 6))\nsns.boxplot(x = 'MonthlyIncome', y = 'JobRole', data = employee_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some job groups having higher salary range. These job groups might have lower attrition compared to other groups \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df['OverTime'] = employee_df['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_df.OverTime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_numerical = employee_df[['Age', 'DailyRate', 'DistanceFromHome',\t'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement',\t'JobLevel',\t'JobSatisfaction',\t'MonthlyIncome',\t'MonthlyRate',\t'NumCompaniesWorked',\t'OverTime',\t'PercentSalaryHike', 'PerformanceRating',\t'RelationshipSatisfaction',\t'StockOptionLevel',\t'TotalWorkingYears'\t,'TrainingTimesLastYear'\t, 'WorkLifeBalance',\t'YearsAtCompany'\t,'YearsInCurrentRole', 'YearsSinceLastPromotion',\t'YearsWithCurrManager']]\n\nX= X_numerical\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= employee_df['Attrition']\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X_numerical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\nprint(\"Accuracy of the Model is\",100*accuracy_score(y_pred,y_test), '%')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing Set Performance\nConfusionMatrix = confusion_matrix(y_pred, y_test)\nsns.heatmap(ConfusionMatrix, annot=True,linewidths=1 )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ConfusionMatrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although the accuracy of the model is good , but here f1 score needs to be checked , which is on the lower side. The model needs to be further worked on to improve this number","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Trying Random Forest to check the accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFConfusionMatrix = confusion_matrix(y_pred, y_test)\nsns.heatmap(RFConfusionMatrix, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Clasiification Report from Random Forest \\n\",classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest gives even lower f1 score,\nFrom the f1-scores, we can say that the Logistic Regression Model has worked better. Although, that also needs further improvement","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Will further try further data analysis to improve the accuracy of the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}