{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Oppgave\nEn kjøpesenterkjede har leid inn BearingPoint fordi de ønsker å bli mer datadrevet. Som et steg i denne prosessen har vi identifisert at det kan være nyttig å segmentere kundene for å skreddersy kommunikasjonen til kundene i større grad.\n\nI denne Notebooken finner dere et konstruert datasett med 5 dimensjoner: `CustomerID`,\t`Gender`,\t`Age`,\t`Annual Income (k$)` og\t`Spending Score (1-100)`\nDet er allerede gjort en god del \"Exploratory Data Analysis\" (EDA) som dere kan se på for å forstå dataene, dere står fritt til å grave mer om det skulle være nødvendig.\nUnder EDA har vi laget noen funksjoner som bør være nyttige for denne oppgaven. Det er også en del nyttige kommentarer rundt omkring i Notebooken som forklarer plot og funksjoner. Det anbefales å se på disse. \n\n1. Dere skal gjøre en cluster analyse med Kmeans clustering. Det er opp til dere å velge hvilke dimensjoner og hvor mange cluster som er riktig. Hint: bruk Elbow method til å finne riktig antall cluster når dere gjennomfører analysen.\n2. Ledelsen i kjøpesenterkjeden har sett at deres tidligere kampanjer har hatt lite effekt på omsetningen. De har en hypotese om at dette kan skyldes at de tidligere ikke har truffet de riktige segmentene. Ledelsen ønsker at dere definerer segmenter basert på datagrunnlaget i denne Notebooken og presenterer tiltak som vil kunne øke omsetningen basert på disse segmentene.\n\nPS: Det er ikke behov for å lage en egen PowerPoint for å presentere, her kan dere bare ta utgangspunkt i Notebooken.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# K-Means Clustering\nK-means clustering er en type unsupervised Machine Learning-algoritme (så der har dere noen buzzwords å snakke om), som brukes til å gruppere data som ligner på hverandre over én eller flere (potensielt veldig mange) dimensjoner eller variable. Clustering er at man deler dataen inn i grupper, clusters, og K-means er en algoritme for å gjøre dette basert på euklidisk distanse mellom dataene. Dere trenger ikke forstå eller implementere den spesifikke algoritmen i denne oppgaven. I K-means clustering må man velge antallet clusters man vil dele dataen inn i, K, før algoritmen kjøres. Det er derfor vanlig å kjøre algoritmen for flere K og så velge det antallet som gir best resultat, basert på et eller annet måltall. Det er her Elbow method kommer inn. Man må også velge hvilke dimensjoner man skal ta med i clusteringen. Man bruker derfor en del tid på å analysere og gjøre seg kjent med dataen på forhånd, slik at man for eksempel kan finne ut om det er noen dimensjoner som ikke er relevante.\n\nDere kan lese mer om K-means clustering for eksempel her: \n\nhttps://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\n\nhttps://www.geeksforgeeks.org/k-means-clustering-introduction/\n\nOg om Elbow method her: \n\nhttps://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/\n\nhttp://www.nbertagnolli.com/jekyll/update/2015/12/10/Elbow.html","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://images.unsplash.com/photo-1519567241046-7f570eee3ce6?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1000&q=80\" width=\"1000px\">","execution_count":null},{"metadata":{"id":"afbCd3JScaDD"},"cell_type":"markdown","source":"# Lese inn data og installere nødvendige bibliotek\n\n**Installerer bibliotek**","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"fYCzevADcO5h","trusted":true},"cell_type":"code","source":"# for basic mathematics operation \nimport numpy as np\nimport pandas as pd\nfrom pandas import plotting\n\n# for visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\n# for interactive visualizations\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\n# for path\nimport os\nprint(os.listdir('../input/'))","execution_count":null,"outputs":[]},{"metadata":{"id":"3CPkewAscpyK"},"cell_type":"markdown","source":"**Leser inn datasett**\nHer ser du også hva de forskjellige dimensjonene heter","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"dnV20cUxcohO","outputId":"82b49b9c-58b5-4be5-b585-165563ed304c","trusted":true},"cell_type":"code","source":"# importing the dataset\ndata = pd.read_csv('../input/Mall_Customers.csv')\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Litt enkel informasjon om dataen**","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"kCddXZRpdaEr","outputId":"a02f964b-bad9-4fca-de32-1cb8a535f407","trusted":true},"cell_type":"code","source":"# describing the data\n\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"QQVxAt8ZdeZB","outputId":"189bcfaa-3bc6-4ad1-8659-178a6444c161","trusted":true},"cell_type":"code","source":"# checking if there is any NULL data\n\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Datavisualisering\n\n## Visualisering av dimensjoner hver for seg\n\nHvilke dimensjoner vil intuitivt være viktige for kjøpesenteret å kjenne til når de skal tilpasse salgskommunikasjonen sin til kundene?\n\n**Empirisk fordeling**","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"eZJRA2aRkgiD","outputId":"7a919656-a0a2-466d-ea6f-2864d316d25f","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['figure.figsize'] = (25, 8)\n\nplt.subplot(1, 3, 1)\nsns.set(style = 'whitegrid')\nsns.distplot(data['Annual Income (k$)'])\nplt.title('Distribution of Annual Income', fontsize = 20)\nplt.xlabel('Range of Annual Income')\nplt.ylabel('Count')\n\n\nplt.subplot(1, 3, 2)\nsns.set(style = 'whitegrid')\nsns.distplot(data['Age'], color = 'red')\nplt.title('Distribution of Age', fontsize = 20)\nplt.xlabel('Range of Age')\nplt.ylabel('Count')\n\n\nplt.subplot(1, 3, 3)\nsns.set(style = 'whitegrid')\nsns.distplot(data['Spending Score (1-100)'], color = 'green')\nplt.title('Distribution of Spending Score', fontsize = 20)\nplt.xlabel('Range of Spending Score')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I plottene over ser man fordelingen av inntekt, alder og spending score for kundene. Her kan man notere seg noen initielle trender og typiske trekk ved kunder. Hvem er kundene som handler?\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Mer detaljert oversikt**","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"bNWTBRakkU__","outputId":"5b092b6b-b35a-4b04-cd39-8494c5afb5b0","trusted":true},"cell_type":"code","source":"data['Gender'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n> Her ser man antall kunder som er kvinner og menn.","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"6xZzbPo3dxmT","outputId":"8e2d994d-cf8f-4193-8b6c-f6fc182eb434","trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 8)\nsns.countplot(data['Age'], palette = 'hsv')\nplt.title('Distribution of Age', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Fordeling i antall kunder av hver alder fra 18 til 70 år.","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"Zt0sFOPud5xy","outputId":"c0dfa419-f1be-499c-a2d1-3b00352c7185","trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(data['Annual Income (k$)'], palette = 'rainbow')\nplt.title('Distribution of Annual Income', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Detaljert oversikt over hvilken inntekt kunder har. Hvilket inntektsområde er mest vanlig?","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"o_csXNtneJ0d","outputId":"394e603c-981b-4ef6-cb09-1b4390887979","trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(data['Spending Score (1-100)'], palette = 'copper')\nplt.title('Distribution of Spending Score', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Detaljert fordeling av spending scores. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Sammenheng mellom dimensjoner\n\nNår man driver analyse på data, er det viktig å se på interaksjonen mellom dimensjonene man har. Vi skal gruppere kunder på tvers av flere dimensjoner, og det er da lurt å ha innsikt i om det er noen sammenheng mellom dimensjonene. Er det noen sett med dimensjoner som i større grad bidrar til å segmentere kundene enn andre? \n\nHer er et pairplot av dimensjonene, det vil si at kundene er plottet i et grid på to dimensjoner om gangen. Man kan da se om det er noen sammenhenger mellom disse dimensjonene. Er det for eksempel sånn at noen aldersgrupper tjener mer enn andre, eller bruker mer penger enn andre? Ser det ut til at hvor mye penger man bruker og hvor mye man tjener har en sammenheng? Er det noen dimensjonskombinasjoner som ser ut til å dele kundene i grupper mer enn andre? Kanskje er det også noen litt merkelige sammenhenger innimellom (en konsekvens av konstruert datasett?)? Noen tips til hvordan lese grafene finnes under figuren. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a numberic label column for gender:\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndata['Gender_Numeric'] = label_encoder.fit_transform(data['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"id":"jOtDAQC8e_pX","outputId":"d303c7fa-c82e-4845-ef0e-623903f1065d","trusted":true},"cell_type":"code","source":"sns.pairplot(data)\nplt.title('Pairplot for the Data', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Figuren kan se litt rotete ut, men se på hver enkelt firkant for seg. På diagonalen finner du plottene vi allerede har sett på, nemlig hver dimensjon hver for seg. Du finner de samme plottene på hver side av diagonalen, men med aksene snudd. I disse har du én dimensjon på hver akse, og scorene til en enkelt kunde ses som en blå prikk.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Korrelasjon**\n\nKorrelasjon er hvor mye to dimensjoner, eller variable, henger sammen. Korrelasjonen går fra -1 til 1, hvor begge ytterpunktene betyr at variablene er perfekt korrelerte. Positiv korrelasjon vil si at høye verdier i den ene variabelen har en tendens til å gi høye verdier i den andre, mens høye verdier i én variabel gir ofte lave i den andre dersom de to er negativt korrelerte. Ved 0 korrelasjon er det ingen sammenheng mellom verdiene i den ene og andre variabelen. \n\nHvorfor er korrelasjon relevant? Å bruke sterkt korrelerte variable i analyse, kan gi misvisende resultater. Det blir vanskelig å trekke konklusjoner om kausalitet (Dersom eldre mennesker har en tendens til å ha diabetes og svake lunger, er det da alder, diabetes eller svake lunger som gjør at disse er i risikogruppen for alvorlig covid-19?). I tillegg vil to sterkt korrelerte variable i stor grad representere det samme konseptet, og dersom begge variablene tas med i analysen, vil dette konseptet telle dobbelt i algoritmen. Man bør derfor vurdere å droppe en dimensjon dersom det er veldig sterk korrelasjonen (enten positiv eller negativ) mellom denne og en annen dimensjon.","execution_count":null},{"metadata":{"_kg_hide-input":true,"id":"6lI0QgyfhNjo","outputId":"60e9a53e-0ab5-4a39-8281-53b912c3de0e","trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 8)\nsns.heatmap(data.corr(), cmap = 'Wistia', annot = True)\nplt.title('Heatmap for the Data', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I denne grafen er korrelasjonen mellom de forskjellige dimensjonene notert. Grafen leses tilsvarende parplottet over. Du kan se bort fra diagonalen når du ser etter korrelerte dimensjoner, ettersom diagonalen viser korrelasjon mellom en dimensjon og seg selv, som alltid er 1. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Flere plot for forskjell mellom mann og kvinne","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#  Gender vs Spendscore\n\nplt.rcParams['figure.figsize'] = (18, 7)\nsns.boxenplot(data['Gender'], data['Spending Score (1-100)'], palette = 'Blues')\nplt.title('Gender vs Spending Score', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">Plottet viser hvilke Spending Scores som er mest vanlig for menn og kvinner. Særlig de store boksene på midten forteller henholdsvis hvilke scores en mann og en kvinne typisk har. Er det en vesentlig forskjell?","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (18, 7)\nsns.violinplot(data['Gender'], data['Annual Income (k$)'], palette = 'rainbow')\nplt.title('Gender vs Annual Income', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> En annen type plot (er bare til å bytte dette til \"boxenplot\" som over om du ønsker) for årlig inntekt per kjønn. ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (18, 7)\nsns.stripplot(data['Gender'], data['Age'], palette = 'Purples', size = 10)\nplt.title('Gender vs Age', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Nok en måte å visualisere kunder, her for alder per kjønn. Det ser ikke ut til å være en stor forskjell i alderfordelingen for menn og kvinner. Generelt ville man vel også synes det var litt spesielt om kvinner hadde en tendens til å være yngre eller eldre enn menn? Men i et datasett på 200 shoppere kunne man fått en forskjell. Det er da viktig å være litt kritisk til de funnene man gjør, og reflektere rundt hva som kan være grunnen.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Nyttige funksjoner","execution_count":null},{"metadata":{"_kg_hide-input":false,"id":"vhf219y1lKbn","outputId":"18f6cea1-7082-425d-a088-2c3eb2ab1b2a","trusted":true},"cell_type":"code","source":"def run_elbow_method_to_find_optimal_no_of_clusters(x):\n    from sklearn.cluster import KMeans\n\n    wcss = []\n    for i in range(1, 11):\n        km = KMeans(n_clusters = i, init = 'k-means++')\n        km.fit(x)\n        wcss.append(km.inertia_)\n\n    plt.plot(range(1, 11), wcss)\n    plt.title('The Elbow Method', fontsize = 20)\n    plt.xlabel('No. of Clusters')\n    plt.ylabel('wcss')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"id":"4teho5mpnARV","outputId":"2859f139-a905-451c-b041-4c2adae48f19","trusted":true},"cell_type":"code","source":"\nimport matplotlib\ndef fit_predict_and_visualize_in_2d_clusters(kmeans, x):\n    ### Takes as input a sklearn kmeans model and a 2d matrix and plots the clusters###\n    \n    if x.shape[1] != 2:\n        raise TypeError(\"This function only accepts matricies with 2 dimensions\")\n    \n    if isinstance(x, pd.core.frame.DataFrame):\n        columns = x.columns.to_list()\n        x = x.values\n        \n    color_iterator = matplotlib.colors.cnames.__iter__()\n    \n    y_means = kmeans.fit_predict(x)\n    \n    for i in range(kmeans.get_params()['n_clusters']):\n        plt.scatter(x[y_means == i, 0], x[y_means == i, 1], s = 100, c = next(color_iterator), label = f'Segment {i}')\n        \n    plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n    plt.style.use('fivethirtyeight')\n    plt.title('K Means Clustering', fontsize = 20)\n    if columns:\n        plt.xlabel(columns[0])\n        plt.ylabel(columns[1])\n    plt.legend()\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def fit_predict_and_visualize_in_3d_clusters(kmeans, x):\n    ### Takes as input a sklearn kmeans model and a 3d matrix and plots the clusters###\n    \n    if x.shape[1] != 3:\n        raise TypeError(\"This function only accepts matricies with 3 dimensions\")\n        \n    kmeans.fit(x)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    data = x\n    data['labels'] =  labels\n    trace1 = go.Scatter3d(\n        x= data.iloc[:,0],\n        y= data.iloc[:,1],\n        z= data.iloc[:,2],\n        mode='markers',\n         marker=dict(\n            color = data['labels'], \n            size= 10,\n            line=dict(\n                color= data['labels'],\n                width= 12\n            ),\n            opacity=0.8\n         )\n    )\n    df = [trace1]\n\n    layout = go.Layout(\n        margin=dict(\n            l=0,\n            r=0,\n            b=0,\n            t=0  \n        ),\n        scene = dict(\n                xaxis = dict(title  = data.columns[0]),\n                yaxis = dict(title  = data.columns[1]),\n                zaxis = dict(title  = data.columns[2])\n            )\n    )\n\n    fig = go.Figure(data = df, layout = layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOTE: It is not good design to take a k-means model and the whole dataframe as\n# parameters when we only need the cluster centers and the column names, \n# but we wanted to keep the parameters similar between all visialization functions\n\ndef fit_predict_and_visualize_cluster_with_barchart(kmeans, x_dataframe):\n    y_means = km.fit_predict(x_dataframe)\n    df = pd.DataFrame(kmeans.cluster_centers_, columns= x_dataframe.columns)\n    df = pd.DataFrame(data=StandardScaler().fit_transform(X=df), columns=df.columns)\n    df.plot.bar(figsize=(12,7))\n    plt.legend(bbox_to_anchor=(1,.6))\n    plt.axhline(color = 'lightgrey', linestyle = '--')\n    plt.xlabel('Cluster')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start oppgaven her:\nFinn passende dimensjoner å segmentere dataene på og et passende antall cluster. Ta gjerne utgangspunkt i vurderinger dere har gjort i dataanalysen, men dere må nok også prøve dere fram og se på resultatene.\nEksempelkoden lager 2 cluster basert på dimensjonene `Age` og `Gender_Numeric`\nDere kan bruke så mange dimensjoner dere ønsker, men husk at dere skal klare å kommunisere hva segmentene innebærer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO: Her velger dere hvilke features som skal være med clusteringen, skriv data.columns for å se alle kolonnene\n\nfeatures = ['Age','Gender_Numeric']\nx = data[features]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"id":"worK1OurkRGx","outputId":"f82ce7dd-9067-42ca-c8e0-20ca9ec32cdc","trusted":true},"cell_type":"code","source":"\n#Plotter WCSS mot antall cluster\n#WCSS = the sum of squares of the distances of each data point in all clusters to their respective centroids\nrun_elbow_method_to_find_optimal_no_of_clusters(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TODO: Her må dere definere hvor mange clustere K-means skal segmentere i.\nkm = KMeans(n_clusters = 2, init = 'k-means++')\n#2d-funksjonen kan kun brukes til å visualisere to dimensjoner, men kan byttes til 3d om man bruker tre dimensjoner.\nfit_predict_and_visualize_in_2d_clusters(km, x)\n# fit_predict_and_visualize_in_3d_clusters(km, x) #Kan brukes hvis dere har 3 features/dimensjoner som dere lager cluster basert på","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Segmenter i forskjellige farger. Blå prikk er sentrum av segmentet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_predict_and_visualize_cluster_with_barchart(km, x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Dette plottet visere tendensene i verdiene til dimensjonene innad i hvert cluster. Verdiene er sentrert rundt 0, så søylene forteller om verdiene til dimensjonen i clusteret er lave, høye eller gjennomsnittlige. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://media1.tenor.com/images/251da9c5c43d4bf2e4ddb36ed6d4c2eb/tenor.gif?itemid=10603325\" width=\"500px\">","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}