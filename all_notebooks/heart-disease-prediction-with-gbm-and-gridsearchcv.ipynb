{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nThis Dataset is taken from UCI Database about heart diseases. Our goal is to predict the the presence of heart disease in patients ranging from 0 to 4. For this purpose, I will use GridSearchCV with Gradient Boosting Machines as a main algorithm comparing it with using Gradient Boosting Machine without cross validation.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Basic Operations","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n%matplotlib inline\nimport sys,matplotlib,plotly\n\nprint(\"Python version: {}\".format(sys.version))\nprint(\"NumPy version: {}\".format(np.__version__))\nprint(\"pandas version: {}\".format(pd.__version__))\nprint(\"matplotlib version: {}\".format(matplotlib.__version__))\nprint(\"plotly version:{}\".format(plotly.__version__))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A few words about attributes.\n\nThe dataset contains of 14 columns with 303 instances.\nFollowing is the outline of attributes:\n\n* age\n* sex\n* chest pain type (4 values)\n* resting blood pressure\n* serum cholestoral in mg/dl\n* fasting blood sugar > 120 mg/dl\n* resting electrocardiographic results (values 0,1,2)\n* maximum heart rate achieved\n* exercise induced angina\n* oldpeak = ST depression induced by exercise relative to rest\n* the slope of the peak exercise ST segment\n* number of major vessels (0-3) colored by flourosopy\n* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n* target: 0-4\n\nAll data is integer, except oldpeak which is floating point number.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.info())\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summary(df, pred=None):\n    obs=df.shape[0]\n    types=df.dtypes\n    counts = df.apply(lambda x: x.count())\n    uniques = df.apply(lambda x: [x.unique()])\n    nulls=df.apply(lambda x: x.isnull().sum())\n    distincts=df.apply(lambda x: x.unique().shape[0])\n    missing_ratio=(df.isnull().sum()/ obs)*100\n    print('Data Shape: ', df.shape)\n    if pred is None:\n        cols = ['types', 'counts', 'distincts', 'nulls', 'missing ratio', 'uniques']\n        str = pd.concat([types, counts, distincts, nulls, missing_ratio, uniques], axis = 1)\n    else:\n        corr = df.corr()[pred]\n        str = pd.concat([types, counts, distincts, nulls, missing_ratio, uniques, corr], axis = 1, sort=False)\n        corr_col = 'corr '+ pred\n        cols = ['types', 'counts', 'distincts', 'nulls', 'missing_ratio', 'uniques', corr_col ]\n    str.columns = cols\n    dtypes = str.types.value_counts()\n    print('___________________________\\nData types:\\n',str.types.value_counts())\n    print('___________________________')\n    return str","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"details=summary(df,'target')\ndetails.sort_values(by='missing_ratio', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Eploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=df.corr(method='pearson')\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nf, ax = plt.subplots(figsize=(11, 9))\nsns.heatmap(corr, mask=mask, cmap='Spectral', vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: I don't want to focus on visualizing data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boosting Machines and Grid Search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling and Splitting Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.copy()\ndf1=df1.apply(LabelEncoder().fit_transform)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std_sclr=StandardScaler().fit(df1.drop('target',axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=std_sclr.transform(df1.drop('target',axis=1))\ny=df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Gradient Boosting Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gbrt=GradientBoostingClassifier(max_depth=1,learning_rate=1,random_state=0)\ngbrt.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Classifier Using GridSearchCV\n\nIn order to perform grid search, I need to create a dictionary that GridSearchCV will use during tuning the parameters. Thus, (1) I will assign two paramters with 6 corresponding values (learning_rate and n_estimators) and (2) one paramter (max_depth) with 6 values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], 'n_estimators':[100,250,500,750,1000,1250,1500,1750]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search = GridSearchCV(\n    GradientBoostingClassifier(max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n    param_grid, scoring='accuracy', cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.fit(X_train, y_train)\n#grid_search.grid_scores_, grid_search.best_params_, grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train set score: {:.2f}\".format(grid_search.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion 1: Our model will have best benefit when our learning_rate is equal to 0.01 and n_estimators to 250 having 0.84 accuracy comparing to previous example without tuning.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid2 = {'max_depth': [2,3,4,5,6,7]}\ngrid_search2 = GridSearchCV(\n    GradientBoostingClassifier(max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n    param_grid2, scoring='accuracy', cv=5)\n\ngrid_search2.fit(X_train, y_train)\n#grid_search.grid_scores_, grid_search.best_params_, grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train set score: {:.2f}\".format(grid_search2.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(grid_search2.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best parameters: {}\".format(grid_search2.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search2.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best estimator:\\n{}\".format(grid_search2.best_estimator_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion 2: Our accuracy had not changed significantly on a test set, but decreased train set accuracy.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}