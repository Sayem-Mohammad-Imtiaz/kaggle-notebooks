{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=Iceberg&effect=3d';      \n    </style><h1 class='font-effect-3d' \n    style='font-family:Iceberg; color:#ff1155; font-size:35px;'>\n    %s</h1>\"\"\"%str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/gan/dcgan-cats-and-dogs.ipynb)\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dhtml('Code Modules, Functions, & Classes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision import transforms,utils,models\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nimport tensorflow.image as timage\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef display_examples(data):\n    letters=u'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n    for images,labels in dataloaders[data]:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=letters[labels[i].item()])\n            ax.imshow((images[i]).reshape(img_size,img_size,3))\n        break","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size=64\nfpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages2.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')\nx=timage.resize(x,[img_size,img_size])\nx=x.numpy().reshape(-1,3,img_size,img_size)\nx=x/255\nprint(x.mean(),x.std())\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids][:46*128],y[shuffle_ids][:46*128]\nrandom_seed=23; batch_size=128\ntrain=TData(x,y)\ndataloaders={'train':tdl(dataset=train,shuffle=True, \n                         batch_size=batch_size)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_examples train","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('DCGAN')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def weights_init(module):\n    classname=module.__class__.__name__\n    if classname.find('Conv')!=-1:\n        tnn.init.normal_(module.weight.data,0.,.02)\n    elif classname.find('BatchNorm')!=-1:\n        tnn.init.normal_(module.weight.data,1.,.02)\n        tnn.init.constant_(module.bias.data,0)\ndef convt(x,y,k,s,p):\n    return tnn.Sequential(\n        tnn.ConvTranspose2d(\n            x,y,kernel_size=k,stride=s,\\\n            padding=p,bias=False),\\\n        tnn.BatchNorm2d(y),\n        tnn.ReLU(True))\ndef conv(x,y,k,s,p,b):\n    return tnn.Sequential(\n        tnn.Conv2d(x,y,kernel_size=k,\n                   stride=s,padding=p,\n                   bias=b),\n        tnn.BatchNorm2d(y),\n        tnn.LeakyReLU(.2,inplace=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DCGAN(tnn.Module):\n    def __init__(self):\n        super(DCGAN,self).__init__()\n        self.generator=tnn.Sequential(\n            convt(latent_dim,gmaps_num*8,4,1,0),\n            convt(gmaps_num*8,gmaps_num*4,4,2,1),\n            convt(gmaps_num*4,gmaps_num*2,4,2,1),\n            convt(gmaps_num*2,gmaps_num,4,2,1),\n            tnn.ConvTranspose2d(\n                gmaps_num,3,\n                kernel_size=4,stride=2,\n                padding=1,bias=False),\n            tnn.Tanh())        \n        self.discriminator=tnn.Sequential(\n            conv(3,dmaps_num,4,2,1,True),\n            conv(dmaps_num,dmaps_num*2,4,2,1,False),           \n            conv(dmaps_num*2,dmaps_num*4,4,2,1,False),\n            conv(dmaps_num*4,dmaps_num*8,4,2,1,False),\n            tnn.Conv2d(\n                dmaps_num*8,1,kernel_size=4,\n                stride=1,padding=0),\n            tnn.Sigmoid())          \n    def generator_forward(self,z):\n        img=self.generator(z)\n        return img \n    def discriminator_forward(self,img):\n        pred=model.discriminator(img)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"random_seed=(123); latent_dim=100\ngmaps_num=64; dmaps_num=64\nglearning_rate=.0018\ndlearning_rate=.001\ngrid_num=64\ntorch.manual_seed(random_seed)\nloss_function=tnn.BCELoss()\nreal_label=1; fake_label=0\nfixed_noise=torch\\\n.randn(grid_num,latent_dim,1,1,device=dev)\nmodel=DCGAN(); model=model.to(dev)\nmodel.apply(weights_init)\nprint(model)\ngoptim=torch.optim.Adam(\n    model.generator.parameters(),\n    betas=(.5,.999),lr=glearning_rate)\ndoptim=torch.optim.Adam(\n    model.discriminator.parameters(),\n    betas=(.5,.999),lr=dlearning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"epochs=150\ndcosts,gcosts=[],[]\nimages_from_noise=[]\ninfo='Epoch: %03d/%03d | Batch: %03d/%03d | Gen/Dis Loss: %.4f/%.4f'\nfor epoch in range(epochs):\n    model=model.train()\n    for batch_ids,(features,targets) in enumerate(dataloaders['train']):\n        doptim.zero_grad()      \n        real_images=features.to(dev)\n        num_real=real_images.size(0)\n        real_label_vec=torch.full((num_real,),real_label,device=dev)\n        discr_pred_real=model.discriminator_forward(real_images).view(-1)\n        real_loss=loss_function(discr_pred_real,real_label_vec)\n\n        random_vec=torch.randn(batch_size,latent_dim,1,1,device=dev)\n        fake_images=model.generator_forward(random_vec)\n        fake_label_vec=torch.full((num_real,),fake_label,device=dev)\n        discr_pred_fake=model.discriminator_forward(fake_images.detach()).view(-1)\n        fake_loss=loss_function(discr_pred_fake,fake_label_vec)\n        discr_loss=.5*(real_loss+fake_loss)\n        discr_loss.backward()\n        doptim.step()        \n\n        goptim.zero_grad()                \n        discr_pred_fake=model.discriminator_forward(fake_images).view(-1)\n        gener_loss=loss_function(discr_pred_fake,real_label_vec)\n        gener_loss.backward()\n        goptim.step()\n\n        dcosts.append(discr_loss.item())\n        gcosts.append(gener_loss.item())\n        if not batch_ids%30:\n            print(info%(epoch+1,epochs,batch_ids,\n                        len(dataloaders['train']),gener_loss,discr_loss))\n    with torch.no_grad():\n        if ((discr_loss.item()>.7 and \\\n            discr_loss.item()<1.2 and \\\n            gener_loss.item()<discr_loss.item()) or not epoch%50):\n            fake_images=model\\\n            .generator_forward(fixed_noise).detach().cpu()\n            images_from_noise.append(\n                utils.make_grid(fake_images,padding=2,\n                                normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"for i in range(len(images_from_noise)):\n    pl.figure(figsize=(10,10))\n    pl.imshow(np.transpose(images_from_noise[i],\n                           (1,2,0)))\npl.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}