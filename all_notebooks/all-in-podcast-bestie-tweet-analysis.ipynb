{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-10T03:46:56.059844Z","iopub.execute_input":"2021-08-10T03:46:56.060324Z","iopub.status.idle":"2021-08-10T03:46:56.071775Z","shell.execute_reply.started":"2021-08-10T03:46:56.060294Z","shell.execute_reply":"2021-08-10T03:46:56.070797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd   # importing and manipulating data\nimport numpy as np    # for performing linear algebric functions\nimport matplotlib.pyplot as plt    #visualization of data\nplt.style.use('ggplot')\nimport seaborn as sns\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport re\nfrom nltk.tokenize import WordPunctTokenizer\ntok = WordPunctTokenizer()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:46:59.744933Z","iopub.execute_input":"2021-08-10T03:46:59.745325Z","iopub.status.idle":"2021-08-10T03:46:59.7674Z","shell.execute_reply.started":"2021-08-10T03:46:59.745298Z","shell.execute_reply":"2021-08-10T03:46:59.766513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chamath = pd.read_csv('/kaggle/input/chamath-palihapitiya-tweets/chamathtweets.csv',  sep='\\t')\njason = pd.read_csv('/kaggle/input/chamath-palihapitiya-tweets/jasontweets.csv',  sep='\\t')\nsacks = pd.read_csv('/kaggle/input/chamath-palihapitiya-tweets/davidsackstweets.csv',  sep='\\t')\nfriedberg = pd.read_csv('/kaggle/input/chamath-palihapitiya-tweets/friedbergtweets.csv',  sep='\\t')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:05.619468Z","iopub.execute_input":"2021-08-10T03:47:05.620061Z","iopub.status.idle":"2021-08-10T03:47:06.113276Z","shell.execute_reply.started":"2021-08-10T03:47:05.620015Z","shell.execute_reply":"2021-08-10T03:47:06.112431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chamath.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:09.754536Z","iopub.execute_input":"2021-08-10T03:47:09.755109Z","iopub.status.idle":"2021-08-10T03:47:09.783986Z","shell.execute_reply.started":"2021-08-10T03:47:09.755064Z","shell.execute_reply":"2021-08-10T03:47:09.782975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jason.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:16.02443Z","iopub.execute_input":"2021-08-10T03:47:16.024789Z","iopub.status.idle":"2021-08-10T03:47:16.053605Z","shell.execute_reply.started":"2021-08-10T03:47:16.024758Z","shell.execute_reply":"2021-08-10T03:47:16.052581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sacks.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:27.00969Z","iopub.execute_input":"2021-08-10T03:47:27.010056Z","iopub.status.idle":"2021-08-10T03:47:27.037556Z","shell.execute_reply.started":"2021-08-10T03:47:27.010025Z","shell.execute_reply":"2021-08-10T03:47:27.03664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"friedberg.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:32.22972Z","iopub.execute_input":"2021-08-10T03:47:32.230085Z","iopub.status.idle":"2021-08-10T03:47:32.258748Z","shell.execute_reply.started":"2021-08-10T03:47:32.230056Z","shell.execute_reply":"2021-08-10T03:47:32.257636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for null value in data\nplt.figure(figsize = (16,5))\nsns.heatmap(chamath.isnull())","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:36.799345Z","iopub.execute_input":"2021-08-10T03:47:36.799688Z","iopub.status.idle":"2021-08-10T03:47:38.532779Z","shell.execute_reply.started":"2021-08-10T03:47:36.799659Z","shell.execute_reply":"2021-08-10T03:47:38.531743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for null value in data\nplt.figure(figsize = (16,5))\nsns.heatmap(jason.isnull())","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:43.459609Z","iopub.execute_input":"2021-08-10T03:47:43.461897Z","iopub.status.idle":"2021-08-10T03:47:45.62142Z","shell.execute_reply.started":"2021-08-10T03:47:43.461856Z","shell.execute_reply":"2021-08-10T03:47:45.620679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for null value in data\nplt.figure(figsize = (16,5))\nsns.heatmap(sacks.isnull())","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:50.509535Z","iopub.execute_input":"2021-08-10T03:47:50.510046Z","iopub.status.idle":"2021-08-10T03:47:51.737765Z","shell.execute_reply.started":"2021-08-10T03:47:50.510015Z","shell.execute_reply":"2021-08-10T03:47:51.736842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for null value in data\nplt.figure(figsize = (16,5))\nsns.heatmap(friedberg.isnull())","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:47:56.639305Z","iopub.execute_input":"2021-08-10T03:47:56.639689Z","iopub.status.idle":"2021-08-10T03:47:57.749014Z","shell.execute_reply.started":"2021-08-10T03:47:56.63964Z","shell.execute_reply":"2021-08-10T03:47:57.747878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(chamath.corr(), annot=True, cmap=\"coolwarm\").set_title('Correlation Heatmap of Chamath')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:48:03.770133Z","iopub.execute_input":"2021-08-10T03:48:03.770519Z","iopub.status.idle":"2021-08-10T03:48:04.816507Z","shell.execute_reply.started":"2021-08-10T03:48:03.770486Z","shell.execute_reply":"2021-08-10T03:48:04.81576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(jason.corr(), annot=True, cmap=\"coolwarm\").set_title('Correlation Heatmap of Jason')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:48:10.484749Z","iopub.execute_input":"2021-08-10T03:48:10.485112Z","iopub.status.idle":"2021-08-10T03:48:11.519265Z","shell.execute_reply.started":"2021-08-10T03:48:10.485083Z","shell.execute_reply":"2021-08-10T03:48:11.518276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(sacks.corr(), annot=True, cmap=\"coolwarm\").set_title('Correlation Heatmap of Sacks')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:48:16.784518Z","iopub.execute_input":"2021-08-10T03:48:16.784983Z","iopub.status.idle":"2021-08-10T03:48:17.763833Z","shell.execute_reply.started":"2021-08-10T03:48:16.78492Z","shell.execute_reply":"2021-08-10T03:48:17.763052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(friedberg.corr(), annot=True, cmap=\"coolwarm\").set_title('Correlation Heatmap of Friedberg')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:48:22.859109Z","iopub.execute_input":"2021-08-10T03:48:22.8595Z","iopub.status.idle":"2021-08-10T03:48:23.874486Z","shell.execute_reply.started":"2021-08-10T03:48:22.85947Z","shell.execute_reply":"2021-08-10T03:48:23.873748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all = pd.concat([chamath,jason,sacks,friedberg], ignore_index=True)\n\nall","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:48:28.604717Z","iopub.execute_input":"2021-08-10T03:48:28.605108Z","iopub.status.idle":"2021-08-10T03:48:28.711454Z","shell.execute_reply.started":"2021-08-10T03:48:28.605074Z","shell.execute_reply":"2021-08-10T03:48:28.710462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\nimport plotly.express as px\ndf_new = all['username'].value_counts().reset_index()\ndf_new.columns = ['username', 'tweets_count']\ndf_new = df_new.sort_values(['tweets_count'])\n\nfig = px.bar(\n    df_new.tail(20), \n    x=\"tweets_count\", \n    y=\"username\", \n    orientation='h', \n    title='Besties by number of tweets', \n    width=800, \n    height=800\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:49:48.409525Z","iopub.execute_input":"2021-08-10T03:49:48.409901Z","iopub.status.idle":"2021-08-10T03:49:48.495787Z","shell.execute_reply.started":"2021-08-10T03:49:48.409865Z","shell.execute_reply":"2021-08-10T03:49:48.494792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new.tail(4)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:01.174755Z","iopub.execute_input":"2021-08-10T03:50:01.175148Z","iopub.status.idle":"2021-08-10T03:50:01.185813Z","shell.execute_reply.started":"2021-08-10T03:50:01.175114Z","shell.execute_reply":"2021-08-10T03:50:01.184713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all.drop(['hashtags','cashtags','thumbnail','source','user_rt','retweet_id','reply_to','retweet_date','translate','trans_src','trans_dest', 'timezone', 'name', 'created_at', 'user_id', 'place', 'likes_count', 'link', 'retweet', 'quote_url', 'video', 'user_rt_id', 'near', 'geo', 'mentions', 'urls', 'photos', 'replies_count', 'retweets_count','conversation_id'], axis = 1, inplace = True)\nall.drop_duplicates()\nall.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:05.174617Z","iopub.execute_input":"2021-08-10T03:50:05.174985Z","iopub.status.idle":"2021-08-10T03:50:05.268545Z","shell.execute_reply.started":"2021-08-10T03:50:05.174929Z","shell.execute_reply":"2021-08-10T03:50:05.267566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chamath.drop(['hashtags','cashtags','thumbnail','source','user_rt','retweet_id','reply_to','retweet_date','translate','trans_src','trans_dest', 'timezone', 'name', 'created_at', 'user_id', 'place', 'likes_count', 'link', 'retweet', 'quote_url', 'video', 'user_rt_id', 'near', 'geo', 'mentions', 'urls', 'photos', 'replies_count', 'retweets_count','conversation_id'], axis = 1, inplace = True)\nchamath.drop_duplicates()\n\njason.drop(['hashtags','cashtags','thumbnail','source','user_rt','retweet_id','reply_to','retweet_date','translate','trans_src','trans_dest', 'timezone', 'name', 'created_at', 'user_id', 'place', 'likes_count', 'link', 'retweet', 'quote_url', 'video', 'user_rt_id', 'near', 'geo', 'mentions', 'urls', 'photos', 'replies_count', 'retweets_count','conversation_id'], axis = 1, inplace = True)\njason.drop_duplicates()\n\nsacks.drop(['hashtags','cashtags','thumbnail','source','user_rt','retweet_id','reply_to','retweet_date','translate','trans_src','trans_dest', 'timezone', 'name', 'created_at', 'user_id', 'place', 'likes_count', 'link', 'retweet', 'quote_url', 'video', 'user_rt_id', 'near', 'geo', 'mentions', 'urls', 'photos', 'replies_count', 'retweets_count','conversation_id'], axis = 1, inplace = True)\nsacks.drop_duplicates()\n\nfriedberg.drop(['hashtags','cashtags','thumbnail','source','user_rt','retweet_id','reply_to','retweet_date','translate','trans_src','trans_dest', 'timezone', 'name', 'created_at', 'user_id', 'place', 'likes_count', 'link', 'retweet', 'quote_url', 'video', 'user_rt_id', 'near', 'geo', 'mentions', 'urls', 'photos', 'replies_count', 'retweets_count','conversation_id'], axis = 1, inplace = True)\nfriedberg.drop_duplicates()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:10.750368Z","iopub.execute_input":"2021-08-10T03:50:10.750725Z","iopub.status.idle":"2021-08-10T03:50:10.834175Z","shell.execute_reply.started":"2021-08-10T03:50:10.750695Z","shell.execute_reply":"2021-08-10T03:50:10.833156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport collections\nimport re\nimport networkx as nx\n\nimport nltk\nfrom nltk.corpus import stopwords\nstopwords=set(stopwords.words('english'))\nfrom nltk.util import ngrams\nfrom nltk import bigrams\nnltk.download('stopwords')\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\nsns.set(font_scale=1.5)\nsns.set_style(\"whitegrid\")\n!pip install vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyzer = SentimentIntensityAnalyzer()\n%config InlineBackend.figure_format = 'retina'","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:15.114815Z","iopub.execute_input":"2021-08-10T03:50:15.115182Z","iopub.status.idle":"2021-08-10T03:50:22.319674Z","shell.execute_reply.started":"2021-08-10T03:50:15.115151Z","shell.execute_reply":"2021-08-10T03:50:22.318568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new1 = chamath[chamath['tweet'].notnull()]\ndf_new1['text'] = df_new1['tweet'].apply(lambda x: ' '.join([item for item in x.split() if item not in stopwords]))\nprint(df_new1)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:27.734897Z","iopub.execute_input":"2021-08-10T03:50:27.735366Z","iopub.status.idle":"2021-08-10T03:50:27.785562Z","shell.execute_reply.started":"2021-08-10T03:50:27.735328Z","shell.execute_reply":"2021-08-10T03:50:27.784557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new2 = jason[jason['tweet'].notnull()]\ndf_new2['text'] = df_new2['tweet'].apply(lambda x: ' '.join([item for item in x.split() if item not in stopwords]))\nprint(df_new2)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:33.235656Z","iopub.execute_input":"2021-08-10T03:50:33.236019Z","iopub.status.idle":"2021-08-10T03:50:33.420914Z","shell.execute_reply.started":"2021-08-10T03:50:33.23599Z","shell.execute_reply":"2021-08-10T03:50:33.419798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new3 = sacks[sacks['tweet'].notnull()]\ndf_new3['text'] = df_new3['tweet'].apply(lambda x: ' '.join([item for item in x.split() if item not in stopwords]))\nprint(df_new3)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:38.914928Z","iopub.execute_input":"2021-08-10T03:50:38.915303Z","iopub.status.idle":"2021-08-10T03:50:38.955246Z","shell.execute_reply.started":"2021-08-10T03:50:38.915271Z","shell.execute_reply":"2021-08-10T03:50:38.954102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new4 = friedberg[friedberg['tweet'].notnull()]\ndf_new4['text'] = df_new4['tweet'].apply(lambda x: ' '.join([item for item in x.split() if item not in stopwords]))\nprint(df_new4)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:43.55559Z","iopub.execute_input":"2021-08-10T03:50:43.555909Z","iopub.status.idle":"2021-08-10T03:50:43.576773Z","shell.execute_reply.started":"2021-08-10T03:50:43.555882Z","shell.execute_reply":"2021-08-10T03:50:43.57586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove Urls and HTML links\ndef remove_urls(text):\n    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_remove.sub(r'', text)\ndf_new1['text']=df_new1['text'].apply(lambda x:remove_urls(x))\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\ndf_new1['text']=df_new1['text'].apply(lambda x:remove_html(x))\n\n# Lower casing\ndef lower(text):\n    low_text= text.lower()\n    return low_text\ndf_new1['text']=df_new1['text'].apply(lambda x:lower(x))\n\n# Number removal\ndef remove_num(text):\n    remove= re.sub(r'\\d+', '', text)\n    return remove\ndf_new1['text']=df_new1['text'].apply(lambda x:remove_num(x))\n\ndef punct_remove(text):\n    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n    return punct\ndf_new1['text']=df_new1['text'].apply(lambda x:punct_remove(x))\n\ndef remove_mention(x):\n    text=re.sub(r'@\\w+','',x)\n    return text\ndf_new1['text']=df_new1['text'].apply(lambda x:remove_mention(x))\n\ndef remove_hash(x):\n    text=re.sub(r'#\\w+','',x)\n    return text\ndf_new1['text']=df_new1['text'].apply(lambda x:remove_hash(x))\n\n\n#Remove extra white space left while removing stuff\ndef remove_space(text):\n    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n    return space_remove\ndf_new1['text']=df_new1['text'].apply(lambda x:remove_space(x))\n\n###########################################################################################################\n\n'''\ndef clean(text):\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)  \n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub(r'@\\w+','',text)\n    text = re.sub(r'#\\w+','',text)\n    return text   \ndf_new['text'] = df_new['text'].apply(lambda x:clean(x))\n'''\n\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\nscores=[]\nfor i in range(len(df_new1['text'])):\n    \n    score = analyser.polarity_scores(df_new1['text'][i])\n    score=score['compound']\n    scores.append(score)\nsentiment=[]\nfor i in scores:\n    if i>=0.05:\n        sentiment.append('Positive')\n    elif i<=(-0.05):\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndf_new1['sentiment']=pd.Series(np.array(sentiment))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:49.341657Z","iopub.execute_input":"2021-08-10T03:50:49.34206Z","iopub.status.idle":"2021-08-10T03:50:50.218209Z","shell.execute_reply.started":"2021-08-10T03:50:49.342019Z","shell.execute_reply":"2021-08-10T03:50:50.217158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove Urls and HTML links\ndef remove_urls(text):\n    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_remove.sub(r'', text)\ndf_new2['text']=df_new2['text'].apply(lambda x:remove_urls(x))\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\ndf_new2['text']=df_new2['text'].apply(lambda x:remove_html(x))\n\n# Lower casing\ndef lower(text):\n    low_text= text.lower()\n    return low_text\ndf_new2['text']=df_new2['text'].apply(lambda x:lower(x))\n\n# Number removal\ndef remove_num(text):\n    remove= re.sub(r'\\d+', '', text)\n    return remove\ndf_new2['text']=df_new2['text'].apply(lambda x:remove_num(x))\n\ndef punct_remove(text):\n    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n    return punct\ndf_new2['text']=df_new2['text'].apply(lambda x:punct_remove(x))\n\ndef remove_mention(x):\n    text=re.sub(r'@\\w+','',x)\n    return text\ndf_new2['text']=df_new2['text'].apply(lambda x:remove_mention(x))\n\ndef remove_hash(x):\n    text=re.sub(r'#\\w+','',x)\n    return text\ndf_new2['text']=df_new2['text'].apply(lambda x:remove_hash(x))\n\n\n#Remove extra white space left while removing stuff\ndef remove_space(text):\n    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n    return space_remove\ndf_new2['text']=df_new2['text'].apply(lambda x:remove_space(x))\n\n###########################################################################################################\n\n'''\ndef clean(text):\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)  \n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub(r'@\\w+','',text)\n    text = re.sub(r'#\\w+','',text)\n    return text   \ndf_new['text'] = df_new['text'].apply(lambda x:clean(x))\n'''\n\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\nscores=[]\nfor i in range(len(df_new2['text'])):\n    \n    score = analyser.polarity_scores(df_new2['text'][i])\n    score=score['compound']\n    scores.append(score)\nsentiment=[]\nfor i in scores:\n    if i>=0.05:\n        sentiment.append('Positive')\n    elif i<=(-0.05):\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndf_new2['sentiment']=pd.Series(np.array(sentiment))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:50:56.631344Z","iopub.execute_input":"2021-08-10T03:50:56.631705Z","iopub.status.idle":"2021-08-10T03:51:00.992966Z","shell.execute_reply.started":"2021-08-10T03:50:56.631674Z","shell.execute_reply":"2021-08-10T03:51:00.992121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove Urls and HTML links\ndef remove_urls(text):\n    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_remove.sub(r'', text)\ndf_new3['text']=df_new3['text'].apply(lambda x:remove_urls(x))\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\ndf_new3['text']=df_new3['text'].apply(lambda x:remove_html(x))\n\n# Lower casing\ndef lower(text):\n    low_text= text.lower()\n    return low_text\ndf_new3['text']=df_new3['text'].apply(lambda x:lower(x))\n\n# Number removal\ndef remove_num(text):\n    remove= re.sub(r'\\d+', '', text)\n    return remove\ndf_new3['text']=df_new3['text'].apply(lambda x:remove_num(x))\n\ndef punct_remove(text):\n    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n    return punct\ndf_new3['text']=df_new3['text'].apply(lambda x:punct_remove(x))\n\ndef remove_mention(x):\n    text=re.sub(r'@\\w+','',x)\n    return text\ndf_new3['text']=df_new3['text'].apply(lambda x:remove_mention(x))\n\ndef remove_hash(x):\n    text=re.sub(r'#\\w+','',x)\n    return text\ndf_new3['text']=df_new3['text'].apply(lambda x:remove_hash(x))\n\n\n#Remove extra white space left while removing stuff\ndef remove_space(text):\n    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n    return space_remove\ndf_new3['text']=df_new3['text'].apply(lambda x:remove_space(x))\n\n###########################################################################################################\n\n'''\ndef clean(text):\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)  \n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub(r'@\\w+','',text)\n    text = re.sub(r'#\\w+','',text)\n    return text   \ndf_new['text'] = df_new['text'].apply(lambda x:clean(x))\n'''\n\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\nscores=[]\nfor i in range(len(df_new3['text'])):\n    \n    score = analyser.polarity_scores(df_new3['text'][i])\n    score=score['compound']\n    scores.append(score)\nsentiment=[]\nfor i in scores:\n    if i>=0.05:\n        sentiment.append('Positive')\n    elif i<=(-0.05):\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndf_new3['sentiment']=pd.Series(np.array(sentiment))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:51:07.27947Z","iopub.execute_input":"2021-08-10T03:51:07.279821Z","iopub.status.idle":"2021-08-10T03:51:07.917814Z","shell.execute_reply.started":"2021-08-10T03:51:07.27979Z","shell.execute_reply":"2021-08-10T03:51:07.917054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove Urls and HTML links\ndef remove_urls(text):\n    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_remove.sub(r'', text)\ndf_new4['text']=df_new4['text'].apply(lambda x:remove_urls(x))\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\ndf_new4['text']=df_new4['text'].apply(lambda x:remove_html(x))\n\n# Lower casing\ndef lower(text):\n    low_text= text.lower()\n    return low_text\ndf_new4['text']=df_new4['text'].apply(lambda x:lower(x))\n\n# Number removal\ndef remove_num(text):\n    remove= re.sub(r'\\d+', '', text)\n    return remove\ndf_new4['text']=df_new4['text'].apply(lambda x:remove_num(x))\n\ndef punct_remove(text):\n    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n    return punct\ndf_new4['text']=df_new4['text'].apply(lambda x:punct_remove(x))\n\ndef remove_mention(x):\n    text=re.sub(r'@\\w+','',x)\n    return text\ndf_new4['text']=df_new4['text'].apply(lambda x:remove_mention(x))\n\ndef remove_hash(x):\n    text=re.sub(r'#\\w+','',x)\n    return text\ndf_new4['text']=df_new4['text'].apply(lambda x:remove_hash(x))\n\n\n#Remove extra white space left while removing stuff\ndef remove_space(text):\n    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n    return space_remove\ndf_new4['text']=df_new4['text'].apply(lambda x:remove_space(x))\n\n###########################################################################################################\n\n'''\ndef clean(text):\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)  \n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub(r'@\\w+','',text)\n    text = re.sub(r'#\\w+','',text)\n    return text   \ndf_new['text'] = df_new['text'].apply(lambda x:clean(x))\n'''\n\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\nscores=[]\nfor i in range(len(df_new4['text'])):\n    \n    score = analyser.polarity_scores(df_new4['text'][i])\n    score=score['compound']\n    scores.append(score)\nsentiment=[]\nfor i in scores:\n    if i>=0.05:\n        sentiment.append('Positive')\n    elif i<=(-0.05):\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndf_new4['sentiment']=pd.Series(np.array(sentiment))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:51:14.533827Z","iopub.execute_input":"2021-08-10T03:51:14.534466Z","iopub.status.idle":"2021-08-10T03:51:14.719909Z","shell.execute_reply.started":"2021-08-10T03:51:14.534406Z","shell.execute_reply":"2021-08-10T03:51:14.719001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n\ntweet_All = \" \".join(review for review in df_new1.text)\n\n\nfig, ax = plt.subplots(1, 1, figsize  = (16,5))\n# Create and generate a word cloud image:\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"black\").generate(tweet_All)\n\n# Display the generated image:\nax.imshow(wordcloud_ALL, interpolation='bilinear')\nax.set_title(\"Chamath's Tweets Word Cloud\")\nax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:51:21.63583Z","iopub.execute_input":"2021-08-10T03:51:21.636238Z","iopub.status.idle":"2021-08-10T03:51:22.817969Z","shell.execute_reply.started":"2021-08-10T03:51:21.636207Z","shell.execute_reply":"2021-08-10T03:51:22.817127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n\ntweet_All = \" \".join(review for review in df_new2.text)\n\n\nfig, ax = plt.subplots(1, 1, figsize  = (16,5))\n# Create and generate a word cloud image:\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"black\").generate(tweet_All)\n\n# Display the generated image:\nax.imshow(wordcloud_ALL, interpolation='bilinear')\nax.set_title(\"Jason's Tweets Word Cloud\")\nax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:51:29.419902Z","iopub.execute_input":"2021-08-10T03:51:29.420431Z","iopub.status.idle":"2021-08-10T03:51:33.135565Z","shell.execute_reply.started":"2021-08-10T03:51:29.420399Z","shell.execute_reply":"2021-08-10T03:51:33.134823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n\ntweet_All = \" \".join(review for review in df_new3.text)\n\n\nfig, ax = plt.subplots(1, 1, figsize  = (16,5))\n# Create and generate a word cloud image:\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"black\").generate(tweet_All)\n\n# Display the generated image:\nax.imshow(wordcloud_ALL, interpolation='bilinear')\nax.set_title(\"Sacks's Tweets Word Cloud\")\nax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:51:40.84102Z","iopub.execute_input":"2021-08-10T03:51:40.841396Z","iopub.status.idle":"2021-08-10T03:51:41.84235Z","shell.execute_reply.started":"2021-08-10T03:51:40.841361Z","shell.execute_reply":"2021-08-10T03:51:41.841181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n\ntweet_All = \" \".join(review for review in df_new4.text)\n\n\nfig, ax = plt.subplots(1, 1, figsize  = (16,5))\n# Create and generate a word cloud image:\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"black\").generate(tweet_All)\n\n# Display the generated image:\nax.imshow(wordcloud_ALL, interpolation='bilinear')\nax.set_title(\"Friedberg's Tweets Word Cloud\")\nax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:51:49.890296Z","iopub.execute_input":"2021-08-10T03:51:49.890663Z","iopub.status.idle":"2021-08-10T03:51:50.549257Z","shell.execute_reply.started":"2021-08-10T03:51:49.890615Z","shell.execute_reply":"2021-08-10T03:51:50.548294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp1 = df_new1.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp1.style.background_gradient(cmap='Purples')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:51:59.070015Z","iopub.execute_input":"2021-08-10T03:51:59.070422Z","iopub.status.idle":"2021-08-10T03:51:59.100181Z","shell.execute_reply.started":"2021-08-10T03:51:59.070391Z","shell.execute_reply":"2021-08-10T03:51:59.09909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp2 = df_new2.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp2.style.background_gradient(cmap='Purples')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:03.289663Z","iopub.execute_input":"2021-08-10T03:52:03.290034Z","iopub.status.idle":"2021-08-10T03:52:03.334404Z","shell.execute_reply.started":"2021-08-10T03:52:03.290004Z","shell.execute_reply":"2021-08-10T03:52:03.333455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp3 = df_new3.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp3.style.background_gradient(cmap='Purples')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:07.32967Z","iopub.execute_input":"2021-08-10T03:52:07.330038Z","iopub.status.idle":"2021-08-10T03:52:07.351161Z","shell.execute_reply.started":"2021-08-10T03:52:07.330008Z","shell.execute_reply":"2021-08-10T03:52:07.350149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp4 = df_new4.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp4.style.background_gradient(cmap='Purples')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:11.109563Z","iopub.execute_input":"2021-08-10T03:52:11.109955Z","iopub.status.idle":"2021-08-10T03:52:11.128533Z","shell.execute_reply.started":"2021-08-10T03:52:11.109904Z","shell.execute_reply":"2021-08-10T03:52:11.12735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\n\nfig = go.Figure(go.Funnelarea(\n    text =temp1.sentiment,\n    values = temp1.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution of Chamath's Tweets\"}\n    ))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:16.309728Z","iopub.execute_input":"2021-08-10T03:52:16.3101Z","iopub.status.idle":"2021-08-10T03:52:16.3277Z","shell.execute_reply.started":"2021-08-10T03:52:16.310071Z","shell.execute_reply":"2021-08-10T03:52:16.326415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\n\nfig = go.Figure(go.Funnelarea(\n    text =temp2.sentiment,\n    values = temp2.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution of Jason's Tweets\"}\n    ))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:22.315168Z","iopub.execute_input":"2021-08-10T03:52:22.315518Z","iopub.status.idle":"2021-08-10T03:52:22.3338Z","shell.execute_reply.started":"2021-08-10T03:52:22.31549Z","shell.execute_reply":"2021-08-10T03:52:22.33245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\n\nfig = go.Figure(go.Funnelarea(\n    text =temp3.sentiment,\n    values = temp3.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution of Sack's Tweets\"}\n    ))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:27.409316Z","iopub.execute_input":"2021-08-10T03:52:27.409653Z","iopub.status.idle":"2021-08-10T03:52:27.432338Z","shell.execute_reply.started":"2021-08-10T03:52:27.409627Z","shell.execute_reply":"2021-08-10T03:52:27.431485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\n\nfig = go.Figure(go.Funnelarea(\n    text =temp4.sentiment,\n    values = temp4.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution of Freidberg's Tweets\"}\n    ))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:32.674807Z","iopub.execute_input":"2021-08-10T03:52:32.675192Z","iopub.status.idle":"2021-08-10T03:52:32.69451Z","shell.execute_reply.started":"2021-08-10T03:52:32.67516Z","shell.execute_reply":"2021-08-10T03:52:32.693198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\n\ndf_pos = df_new1[df_new1[\"sentiment\"]==\"Positive\"]\ndf_neg = df_new1[df_new1[\"sentiment\"]==\"Negative\"]\ndf_neu = df_new1[df_new1[\"sentiment\"]==\"Neutral\"]\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n\nfor val in df_pos.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n   \nwordcloud1 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greens\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title(\"Chamath's Positive Sentiment\",fontsize=35);\n\ncomment_words = ''\n\nfor val in df_neg.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud2 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Reds\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words)  \nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title(\"Chamath's Negative Sentiment\",fontsize=35);\n\ncomment_words = ''\nfor val in df_neu.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud3 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greys\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title(\"Chamath's Neutral Sentiment\",fontsize=35);","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:52:38.6838Z","iopub.execute_input":"2021-08-10T03:52:38.684216Z","iopub.status.idle":"2021-08-10T03:52:44.550048Z","shell.execute_reply.started":"2021-08-10T03:52:38.684183Z","shell.execute_reply":"2021-08-10T03:52:44.549067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\n\ndf_pos = df_new2[df_new2[\"sentiment\"]==\"Positive\"]\ndf_neg = df_new2[df_new2[\"sentiment\"]==\"Negative\"]\ndf_neu = df_new2[df_new2[\"sentiment\"]==\"Neutral\"]\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n\nfor val in df_pos.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n   \nwordcloud1 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greens\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title(\"Jason's Positive Sentiment\",fontsize=35);\n\ncomment_words = ''\n\nfor val in df_neg.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud2 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Reds\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words)  \nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title(\"Jason's Negative Sentiment\",fontsize=35);\n\ncomment_words = ''\nfor val in df_neu.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud3 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greys\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title(\"Jason's Neutral Sentiment\",fontsize=35);","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:53:00.489186Z","iopub.execute_input":"2021-08-10T03:53:00.489774Z","iopub.status.idle":"2021-08-10T03:53:08.715488Z","shell.execute_reply.started":"2021-08-10T03:53:00.489741Z","shell.execute_reply":"2021-08-10T03:53:08.714321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\n\ndf_pos = df_new3[df_new3[\"sentiment\"]==\"Positive\"]\ndf_neg = df_new3[df_new3[\"sentiment\"]==\"Negative\"]\ndf_neu = df_new3[df_new3[\"sentiment\"]==\"Neutral\"]\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n\nfor val in df_pos.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n   \nwordcloud1 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greens\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title(\"Sacks's Positive Sentiment\",fontsize=35);\n\ncomment_words = ''\n\nfor val in df_neg.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud2 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Reds\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words)  \nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title(\"Sacks's Negative Sentiment\",fontsize=35);\n\ncomment_words = ''\nfor val in df_neu.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud3 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greys\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title(\"Sacks's Neutral Sentiment\",fontsize=35);","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:53:25.908619Z","iopub.execute_input":"2021-08-10T03:53:25.90921Z","iopub.status.idle":"2021-08-10T03:53:31.40987Z","shell.execute_reply.started":"2021-08-10T03:53:25.909165Z","shell.execute_reply":"2021-08-10T03:53:31.408484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\n\ndf_pos = df_new4[df_new4[\"sentiment\"]==\"Positive\"]\ndf_neg = df_new4[df_new4[\"sentiment\"]==\"Negative\"]\ndf_neu = df_new4[df_new4[\"sentiment\"]==\"Neutral\"]\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n\nfor val in df_pos.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n   \nwordcloud1 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greens\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title(\"Friedberg's Positive Sentiment\",fontsize=35);\n\ncomment_words = ''\n\nfor val in df_neg.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud2 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Reds\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words)  \nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title(\"Friedberg's Negative Sentiment\",fontsize=35);\n\ncomment_words = ''\nfor val in df_neu.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n    \nwordcloud3 = WordCloud(width = 800, height = 800, \n                background_color ='white',\n                colormap=\"Greys\",\n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title(\"Friedberg's Neutral Sentiment\",fontsize=35);","metadata":{"execution":{"iopub.status.busy":"2021-08-10T03:53:54.133778Z","iopub.execute_input":"2021-08-10T03:53:54.134403Z","iopub.status.idle":"2021-08-10T03:53:59.488547Z","shell.execute_reply.started":"2021-08-10T03:53:54.134355Z","shell.execute_reply":"2021-08-10T03:53:59.487802Z"},"trusted":true},"execution_count":null,"outputs":[]}]}