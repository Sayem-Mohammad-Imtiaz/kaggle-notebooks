{"cells":[{"execution_count":null,"cell_type":"markdown","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"2fdeaa142fbab66bb25cfc404d8db66ac789e465","_cell_guid":"21bcf484-7f02-4d32-b956-7fb40d7ce9cf"},"source":"Stage 1: Data Exploration & Cleansing\n\nThe following analysis was performed as part of the first stage of a comparison of Temperature data and Snowfall for key ski resorts in North America. The ultimate goal of the analysis was to assess the following research question:\n\n**\"Can Temperature trends be used as an indicator to predict upcoming snowfall\"**\n\nThe first stage was focussed on initial data exploration and cleansing to determine if the data sets were appropriate to answer the research question. This involved assessing what data was available for analysis, what data types existed and what needed to be converted to enable latter analysis.\n\nStage 2 will then establish a simple linear regression model that utilises temperature data as an independent variable and assess the strength of the model to make predictions of daily snowfall."},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"trusted":false,"_execution_state":"idle","_uuid":"954b4dab183e0c170a0e775f1b12904ec94eac5b","_cell_guid":"afbff1a5-1c8c-41d4-b220-e5ba1b8de143"},"source":"encoding = 'utf8'\n\n## IMPORT LIBRARIES & DEFINE INPUTS\nimport csv\nimport itertools\nimport collections\nimport matplotlib.pyplot as plt\nimport warnings\nimport numpy as np\nimport re\nfrom tabulate import tabulate\nimport math\nfrom sklearn import linear_model\nfrom scipy import stats\n\nTemperatureDataInput = '../input/climate-change-earth-surface-temperature-data/GlobalLandTemperaturesByCity.csv'\nJacksonDataInput = '../input/resort-daily-snowfall-20092017/Jackson Hole - Wyoming.csv'\nSnowbirdDataInput = '../input/resort-daily-snowfall-20092017/Snowbird - Utah.csv'\nTellurideDataInput = '../input/resort-daily-snowfall-20092017/Telluride - Colorado.csv'\nWhistlerDataInput = '../input/resort-daily-snowfall-20092017/Whistler Blackcomb - BC Canada.csv'\n\nprint(\"Note: Longer processing time may be experienced due to the size of the temperature data set\\n\")"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"e085c884-d423-461e-9ab4-95292dbfd9f0","trusted":false,"_execution_state":"idle","_uuid":"a82a7f4472d78973a3f1c2bb8fe09977708aeae4","collapsed":false},"source":"## DATA SIZE\ndef RecordCounter(filename, encodingformat):\n    RecordCount = 0\n    for row in csv.reader(open(filename, encoding=encodingformat)):\n        RecordCount += 1\n    return RecordCount\n\nprint('----- DATA SIZE -----')\nprint('Temperature Data Records:', RecordCounter(TemperatureDataInput, encoding))\nprint('Jackson Hole Snowfall Records:', RecordCounter(JacksonDataInput, encoding))\nprint('Snowbird Snowfall Records:', RecordCounter(SnowbirdDataInput, encoding))\nprint('Telluride Snowfall Records:', RecordCounter(TellurideDataInput, encoding))\nprint('Whistler Snowfall Records:', RecordCounter(WhistlerDataInput, encoding))\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"b224c785-1a1f-4ca4-9742-fa564dc67d15","trusted":false,"_execution_state":"idle","_uuid":"456deb4271d5a40924820fdd63fe48ded91e6110","collapsed":false},"source":"## INITIAL DATA EXPLORATION\n#Given the size of the temperature data set, data exploration is required \n#to determine whether all data within this set is relevant to the analysis. \n#The types of records received, and the volume of records will be analysed below.\n\nprint('\\n----- INITIAL DATA EXPLORATION -----')\n\nprint('\\n\\nDATA TYPES:')\nprint('\\nTemperature Data:')   \nfor row in itertools.islice(csv.reader(open(TemperatureDataInput)), 2):\n    print(row)\n\nprint('\\nSnowfall - Jackson Hole:')\nfor row in itertools.islice(csv.reader(open(JacksonDataInput)), 2):\n    print(row)\n\nprint('\\nSnowfall - Snowbird:')\nfor row in itertools.islice(csv.reader(open(SnowbirdDataInput)), 2):\n    print(row)\n\nprint('\\nSnowfall - Telluride:')\nfor row in itertools.islice(csv.reader(open(TellurideDataInput)), 2):\n    print(row)\n\nprint('\\nSnowfall - Whistler:')\nfor row in itertools.islice(csv.reader(open(WhistlerDataInput)), 2):\n    print(row)\n\n\n# The above demonstrates that the following data cleansing will be required:\n# - Conversion of date format in Snowfall Data to enable comparison to Temperature data\n# - Manipulation of the three snowfall measurements in Snowfall Data to separate reading from unit of measurement\n# - Manupulation of the latitude and longitude readings to separate the measurement and direction\n# \n# In addition, all records appear to be string data types, and some fields within the data (e.g. temperature, snowfall) reflect continuous, numeric data, the following will also be required:\n# - Conversion of Average Temperature and Average Temperature Uncertainty to float data type\n# - Conversion of the snowfall readings subsequent to separation above into either integer or float data type\n\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"b08b987f-b15f-47e4-8601-1aa0d2678514","trusted":false,"_execution_state":"idle","_uuid":"0e393adb11f64420178595b7026b28b23010db51","collapsed":false},"source":"print(\"----- FURTHER EXPLORATION - TEMPERATURE RECORDS -----\")\n\nprint('\\n\\nTEMPERATURE RECORD DETAILS:')\n# Check how many countries within temperature data set\nRecordSummary = collections.defaultdict(int)\nfor row in csv.reader(open(TemperatureDataInput, encoding=encoding)):\n    RecordSummary[row[4]] += 1\n\n# print records less heading row\nprint(\"\\nNumber of Countries in temperature data set:\")\nprint(len(RecordSummary)-1)\n\n# Records per Country\nd = RecordSummary\ncount = sorted(d, key=d.get, reverse=True)\n\n# Most Records per Country\nprint(\"\\nTemperature Data - Most Records:\")\nfor a in count[:5]:\n    print(a +':', RecordSummary[a])\n\n# Least Records per Country (excluding header row)\nprint(\"\\nTemperature Data - Least Records:\")\nfor b in count[-6:-1]:\n    print(b + ':', RecordSummary[b])\n\n# Years in Data Set\nYearSummary = collections.defaultdict(int)\nfor row in csv.reader(open(TemperatureDataInput, encoding=encoding)):\n    YearSummary[row[0][0:4]] += 1\n\nYearSummary = dict(YearSummary)\ndel YearSummary['dt']\n\nx_axis = list(int(item) for item in YearSummary.keys())\ny_axis = list(YearSummary.values())\n\n# print records less heading row\nprint(\"\")\nprint(\"Number of Years in Temperature Data Set:\", len(YearSummary)-1)\nprint('First Year in Temperature Data Set:', sorted(x_axis)[0])\nprint('Last Year in Temperature Data Set:', sorted(x_axis)[-1])\nprint(\"\")\n\nplt.bar(x_axis, y_axis, color='b')\nplt.xlabel('Year')\nplt.ylabel('Number of Records')\nplt.title('Temperature Records per Year')\nplt.show()\n\n# The above exploration of Temperature Data demonstrates that the data set contains records for a large \n# number of locations which will not be examined in this analysis. Those locations also contain a large \n# volume of records which will not be necessary given the focus on US and Canada resorts. Therefore\n# temperature data for only the US and Canada will be extracted. Additionally, given the volume of records \n# made available per year, only a subset of years will be considered. The snowfall data appears manageable \n# and hence will be used in its entirety.\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"bb308ad8-db5f-4f32-928c-b65f9b5ce9e9","trusted":false,"_execution_state":"idle","_uuid":"625d80b827a6a081d64cc4af6527642b8515e322","collapsed":false},"source":"## DATA CLEANSING & LOADING\n\nprint(\"----- DATA CLEANSING & LOADING  (SNOWFALL) -----\")\n\n# Function - Amend Data Types (iteration)\nDEFAULT_VALUE = np.nan\ndef iter_clean(data, column_key, convert_function, default_value):\n    for row in data:\n        old_value = row[column_key]\n        new_value = default_value\n        try:\n            new_value = convert_function(old_value)\n        except (ValueError, TypeError):\n            warnings.warn('Replacing {} with {} in column {}'.format(\n                row[column_key], new_value, column_key))\n        row[column_key] = new_value\n        yield row\n        \n## Function - Split Snowfall Data Readings\ndef ReadingSplit(source, column):\n    for row in source:\n        value, measure = row[column].split(' ')\n        row[column] = value\n        \n## Function - Convert Snowfall Data Dates to appropriate format        \ndef DateConvert(source):\n    months = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06',\n          'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n    for row in source:\n        day, month, year = row['\\ufeffDate'].split('-')\n        row['\\ufeffDate'] = ('20'+ year + '-' + months[month] + '-' + day)\n\n# Snowfall Data Cleansing\ndata_JacksonHole = list(csv.DictReader(open(JacksonDataInput, encoding=encoding)))\ndata_Snowbird = list(csv.DictReader(open(SnowbirdDataInput, encoding=encoding)))\ndata_Telluride = list(csv.DictReader(open(TellurideDataInput, encoding=encoding)))\ndata_Whistler = list(csv.DictReader(open(WhistlerDataInput, encoding=encoding)))\n\n# Convert Date Fields in Snowfall Data for Loading\nDateConvert(data_JacksonHole)\nDateConvert(data_Snowbird)\nDateConvert(data_Telluride)\nDateConvert(data_Whistler)\n\n# Split Snowfall Readings to obtain numeric value\nReadingSplit(data_JacksonHole, '24 hr New Snow')\nReadingSplit(data_Snowbird, '24 hr New Snow') \nReadingSplit(data_Telluride, '24 hr New Snow') \nReadingSplit(data_Whistler, '24 hr New Snow') \nReadingSplit(data_JacksonHole, 'Season Snowfall Total')\nReadingSplit(data_Snowbird, 'Season Snowfall Total') \nReadingSplit(data_Telluride, 'Season Snowfall Total') \nReadingSplit(data_Whistler, 'Season Snowfall Total') \nReadingSplit(data_JacksonHole, 'Base Depth')\nReadingSplit(data_Snowbird, 'Base Depth') \nReadingSplit(data_Telluride, 'Base Depth') \nReadingSplit(data_Whistler, 'Base Depth') \n\n# Convert Snowfall Readings to Float\ndata_JacksonHole = list(iter_clean(data_JacksonHole, '24 hr New Snow', float, DEFAULT_VALUE))\ndata_Snowbird = list(iter_clean(data_Snowbird, '24 hr New Snow', float, DEFAULT_VALUE))\ndata_Telluride = list(iter_clean(data_Telluride, '24 hr New Snow', float, DEFAULT_VALUE))\ndata_Whistler = list(iter_clean(data_Whistler, '24 hr New Snow', float, DEFAULT_VALUE))\ndata_JacksonHole = list(iter_clean(data_JacksonHole, 'Season Snowfall Total', float, DEFAULT_VALUE))\ndata_Snowbird = list(iter_clean(data_Snowbird, 'Season Snowfall Total', float, DEFAULT_VALUE))\ndata_Telluride = list(iter_clean(data_Telluride, 'Season Snowfall Total', float, DEFAULT_VALUE))\ndata_Whistler = list(iter_clean(data_Whistler, 'Season Snowfall Total', float, DEFAULT_VALUE))\ndata_JacksonHole = list(iter_clean(data_JacksonHole, 'Base Depth', float, DEFAULT_VALUE))\ndata_Snowbird = list(iter_clean(data_Snowbird, 'Base Depth', float, DEFAULT_VALUE))\ndata_Telluride = list(iter_clean(data_Telluride, 'Base Depth', float, DEFAULT_VALUE))\ndata_Whistler = list(iter_clean(data_Whistler, 'Base Depth', float, DEFAULT_VALUE))\n\nprint('\\n\\nSnowfall Data Cleansing Complete')\nprint('\\nJacksonHole:', data_JacksonHole[0:1])\nprint('\\nSnowbird:', data_Snowbird[0:1])\nprint('\\nTelluride:', data_Telluride[0:1])\nprint('\\nWhistler:', data_Whistler[0:1])\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"acd072ed-977d-4c09-ada8-1e28a810fc9f","trusted":false,"_execution_state":"idle","_uuid":"09cedd37a5ea3a384fd656b109ec4d2a02fbe952","collapsed":false},"source":"# Temperature Data Cleansing\n\n# Function - Amend Data Types (pipeline)\nDEFAULT_VALUE = np.nan\ndef piping_clean(value, convert_function, default_value):\n    old_value = value\n    new_value = default_value\n    try:\n        new_value = convert_function(old_value)\n    except (ValueError, TypeError):\n        warnings.warn('Replacing {} with {}'.format(\n            old_value, new_value))\n    value = new_value\n    return value\n\n## Establish pattern for regex to capture date range, and define countries in scope\npattern = '\\A195|\\A196|\\A197|\\A198|\\A199|\\A20'\ncountry = ['United States', 'Canada']\n\n#Apply data conversions to each line, then load relevant records\ndata_Temperature = list()\nfor row in csv.reader(open(TemperatureDataInput, encoding=encoding)):\n    # Convert Temperature Readings to Float\n    row[1] = piping_clean(row[1], float, DEFAULT_VALUE)\n    row[2] = piping_clean(row[2], float, DEFAULT_VALUE)\n    # Separate Latitude Measure and Direction\n    row.append(row[5][-1])  \n    row[5] = row[5][0:-1]\n    row[5] = piping_clean(row[5], float, DEFAULT_VALUE)\n    # Separate Longitude Measure and Direction\n    row.append(row[6][-1])\n    row[6] = row[6][0:-1]\n    row[6] = piping_clean(row[6], float, DEFAULT_VALUE)\n    # Load row into Database for in scope years and countries\n    if re.match(pattern, row[0]) != None and row[4] in country:\n        data_Temperature.append(row)\n\nprint('\\n\\nTemperature Data Cleansing Complete')\nprint('\\nTemperatures:', data_Temperature[0:1])\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"b8cdcb7e-a117-4de0-833e-c140bce96426","trusted":false,"_execution_state":"idle","_uuid":"9a04bd9b3f3e5885b39cfb055f2be1516a8c9f65","collapsed":false},"source":"## DATA VISUALISATIONS\n\nprint(\"----- DATA VISUALISATIONS (TEMPERATURE) -----\")\n\n# Function - Create Line Graphs\ndef linePlot(data, xlabel, ylabel, title):\n    x_axis = []\n    y_axis = []\n    for row in data:\n        x_axis.append(row)\n        y_axis.append(data[row])\n    plt.plot(x_axis, y_axis)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plot = plt.show()\n    return plot\n\n# Canada Average Temperature Trend\nCanada_YTemp = dict()\nfor row in data_Temperature:\n    if row[4] == 'Canada':\n        if row[0][0:4] in Canada_YTemp:\n            Canada_YTemp[row[0][0:4]].append(row[1])\n        else:\n            Canada_YTemp[row[0][0:4]] = [row[1]]\n\nCanada_AVGTemp = dict()\nfor row in Canada_YTemp:\n    if row in Canada_AVGTemp:\n        continue\n    else:\n        Canada_AVGTemp[row] = np.mean(Canada_YTemp[row])\n\nlinePlot(Canada_AVGTemp, 'Year', 'Temperature(C)', 'Average Temperature: Canada')"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"f0a77a21-770b-4272-9388-dc50ad4dc342","trusted":false,"_execution_state":"idle","_uuid":"a3774dac779d1f38c73a0aa587151819bb69adb4","collapsed":false},"source":"# United States Average Temperature Trend\nUSA_YTemp = dict()\nfor row in data_Temperature:\n    if row[4] == 'United States':\n        if row[0][0:4] in USA_YTemp:\n            USA_YTemp[row[0][0:4]].append(row[1])\n        else:\n            USA_YTemp[row[0][0:4]] = [row[1]]\n\nUSA_AVGTemp = dict()\nfor row in USA_YTemp:\n    if row in USA_AVGTemp:\n        continue\n    else:\n        USA_AVGTemp[row] = np.mean(USA_YTemp[row])\n\nlinePlot(USA_AVGTemp, 'Year', 'Temperature(C)', 'Average Temperature: United States')"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"3b145ca1-d6fe-4fda-949d-8104cbadb6ff","trusted":false,"_execution_state":"idle","_uuid":"66c3cd656381fd6be6789d7a05a6e8deb65cbc87","collapsed":false},"source":"# Combined Average Temperature Trend\nx_axis = []\nfor row in Canada_AVGTemp:\n    x_axis.append(row)   \nCanada_Measures = [Canada_AVGTemp[row] for row in Canada_AVGTemp]\nUSA_Measures = [USA_AVGTemp[row]  for row in USA_AVGTemp]\nplt.plot(x_axis, Canada_Measures,'b-', label='Canada')\nplt.plot(x_axis, USA_Measures, 'r-', label='USA')\nplt.xlabel('Year')\nplt.ylabel('Temperature(C)')\nplt.title('Average Temperatures per Country')\nplt.legend(loc=5)\nplot = plt.show()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"c6c388f8-a7a8-4ea8-a8b5-1e900259ce24","trusted":false,"_execution_state":"idle","_uuid":"06624eeff4e7e1fdab76b3cf430b4cb464db10f8","collapsed":false},"source":"# Retrieve snowfall data\ndef TotalAnnualSnowfall(source):\n    output = dict()\n    for row in source:\n        if row['\\ufeffDate'][0:4] in output:\n            output[row['\\ufeffDate'][0:4]] += row['24 hr New Snow']\n        else:\n            output[row['\\ufeffDate'][0:4]] = row['24 hr New Snow']\n    return output\n\nJackson_Snow = TotalAnnualSnowfall(data_JacksonHole)\nSnowbird_Snow = TotalAnnualSnowfall(data_Snowbird)\nTelluride_Snow = TotalAnnualSnowfall(data_Telluride)\nWhistler_Snow = TotalAnnualSnowfall(data_Whistler)\n             \nx_axis = []\nfor row in Jackson_Snow:\n    x_axis.append(row)   \nJackson_Measures = [Jackson_Snow[row] for row in Jackson_Snow]\nSnowbird_Measures = [Snowbird_Snow[row] for row in Snowbird_Snow]\nTelluride_Measures = [Telluride_Snow[row] for row in Telluride_Snow]\nWhistler_Measures = [Whistler_Snow[row] for row in Whistler_Snow]\nplt.plot(x_axis, Jackson_Measures, 'b-', label='Jackson Hole')\nplt.plot(x_axis, Snowbird_Measures, 'g-', label='Snowbird')\nplt.plot(x_axis, Telluride_Measures, 'r-', label='Telluride')\nplt.plot(x_axis, Whistler_Measures, 'y-', label='Whistler')\nplt.xlabel('Year')\nplt.ylabel('Total Snowfall (cm)')\nplt.title('Snowfall')\nplt.legend(loc=2)\nplot = plt.show()\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":false,"trusted":false,"_execution_state":"idle","_uuid":"5587f202c8d854307d7fb5cba2e1a8c46ce58a08","_cell_guid":"7e7b1144-da19-4deb-8a5a-aedd40e3807e"},"source":"def AnnualSnowfallRecords(source):\n    output = dict()\n    for row in source:\n        if row['\\ufeffDate'][0:4] in output:\n            output[row['\\ufeffDate'][0:4]].append(row['24 hr New Snow'])\n        else:\n            output[row['\\ufeffDate'][0:4]] = [row['24 hr New Snow']]\n    return output\n    \ndef BasicStats(data, year):\n    v = []\n    for row in data:\n        if row == year:\n            v.append(data[row])\n    output = []\n    output.append(year)\n    output.append(np.nanmin(v))\n    output.append(np.nanmax(v))\n    output.append(np.nanmax(v)-np.nanmin(v))\n    output.append(np.nanmean(v))\n    output.append(np.nanstd(v))\n    output.append(np.nanmedian(v))\n    output.append(np.nanpercentile(v, 25))\n    output.append(np.nanpercentile(v, 75))\n    output.append(np.nanpercentile(v, 75)-np.nanpercentile(v, 25))\n    return output\n\nheaders = ['Min', 'Max', 'Range','Mean','StDev','Median','Q1', 'Q3', 'IQR']  \n\ndef LocationStatistics(location, data):\n    statistics = []\n    for year in range(2009,2018):\n        statistics.append(BasicStats(data, str(year)))\n    print(location+':', 'Basic Statistics\\n')\n    print(tabulate(statistics, headers=headers) + '\\n')\n\nLocationStatistics('Jackson Hole', AnnualSnowfallRecords(data_JacksonHole))\nLocationStatistics('Snowbird', AnnualSnowfallRecords(data_Snowbird))\nLocationStatistics('Telluride', AnnualSnowfallRecords(data_Telluride))\nLocationStatistics('Whistler', AnnualSnowfallRecords(data_Whistler))\n\n"}],"nbformat":4,"metadata":{"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","name":"python","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":0}