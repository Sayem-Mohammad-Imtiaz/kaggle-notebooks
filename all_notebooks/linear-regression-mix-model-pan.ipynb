{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Introduction:**\n In this Jupyter notebook, we are looking into how medical charges are determined by various factors such as sex, smoker, bmi and ages. In order to investigate such relations, the main tools we are using are heatmaps, K-means and linear regression. Using those tools, we found that the patients are divided into three groups depending on their smoking condition and bmi, and medical charges are determined accordingly.\n  \n  A project like this can help us understand how a hospital or insurance company determines a patient's medical charges and how it can be improved once we know the logic behind it.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/insurance/insurance.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load data","metadata":{}},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n#sex\nle = LabelEncoder()\nle.fit(df.sex.drop_duplicates()) \ndf.sex = le.transform(df.sex)\n# smoker or not\nle.fit(df.smoker.drop_duplicates()) \ndf.smoker = le.transform(df.smoker)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df[[\"age\",\"sex\",\"bmi\",\"children\",\"smoker\",\"charges\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consider factors except for region","metadata":{}},{"cell_type":"code","source":"df1.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cor = df1.corr() #Calculate the correlation of the above variables\nsns.heatmap(cor, square = True) #Plot the correlation as heat map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we check the correlation between different factors.\nIt looks like smoker, bmi and age are three important factors.","metadata":{}},{"cell_type":"markdown","source":"Therefore, I want to use K-means method on bmi and age. Can't apply k-means to smoker since smoker is not a continuous value. Using K-means can help us understand if we can categorize the patients and therefore learn the relations among the variables.","metadata":{}},{"cell_type":"markdown","source":"First we look at clusters of bmi and charges.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nss.fit_transform(df1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\ndef doKmeans(X, nclust=2):\n    model = KMeans(nclust)\n    model.fit(X)\n    clust_labels = model.predict(X)\n    cent = model.cluster_centers_\n    return (clust_labels, cent)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clust_labels, cent = doKmeans(df1, 2)\nkmeans = pd.DataFrame(clust_labels)\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nscatter = ax.scatter(df1['bmi'],df1['charges'],\n                     c=kmeans[0],s=50)\nax.set_title('K-Means Clustering')\nax.set_xlabel('bmi')\nax.set_ylabel('charges')\nplt.colorbar(scatter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When using two clusters, we get the graph above.","metadata":{}},{"cell_type":"code","source":"clust_labels, cent = doKmeans(df1, 3)\nkmeans = pd.DataFrame(clust_labels)\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nscatter = ax.scatter(df1['bmi'],df1['charges'],\n                     c=kmeans[0],s=50)\nax.set_title('K-Means Clustering')\nax.set_xlabel('bmi')\nax.set_ylabel('charges')\nplt.colorbar(scatter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Case of three clusters. Clearly there are other factors affecting charges except for bmi. We need to find those factors.","metadata":{}},{"cell_type":"markdown","source":"Below we look at clusters of age and charges.","metadata":{}},{"cell_type":"code","source":"clust_labels, cent = doKmeans(df1, 3)\nkmeans = pd.DataFrame(clust_labels)\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nscatter = ax.scatter(df1['age'],df1['charges'],\n                     c=kmeans[0],s=50)\nax.set_title('K-Means Clustering')\nax.set_xlabel('age')\nax.set_ylabel('charges')\nplt.colorbar(scatter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Case of three clusters for age. Combined with the three cluster graph above, we can conclude that categorize the whole data set into three categories is reasonable.","metadata":{}},{"cell_type":"markdown","source":"To discover how the data is categorized into such three groups, consider smoker first, since it is relatively easy to filter value of 0 and 1.","metadata":{}},{"cell_type":"code","source":"sns.lmplot(x=\"age\", y=\"charges\", hue=\"smoker\", data=df1, palette = 'inferno_r', height = 7)\nax.set_title('Smokers and non-smokers')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above is the graph when we filter smoker. When smoker == 0, we can easily see the pattern of the curve on the bottom. So one pattern is found.\nWe need to find out the pattern on the top. (When smoker == 1)","metadata":{}},{"cell_type":"markdown","source":"Below I am using df2 for patients who do smoke, the data where smoker == 1. Since pattern for smoker == 0 is found.","metadata":{}},{"cell_type":"code","source":"df2 = df1[(df1.smoker == 1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cor = df2.corr() #Calculate the correlation of the above variables\nsns.heatmap(cor, square = True) #Plot the correlation as heat map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"concentrating on people who smoke, heatmap here shows bmi and age are relevant.\nSince we have discovered pattern for smoker, we need to look at how bmi and age affect charges.\n\nWe will look at bmi first.","metadata":{}},{"cell_type":"code","source":"sns.lmplot(x=\"bmi\", y=\"charges\", hue=\"sex\", data=df2, palette = 'inferno_r', height = 7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above we can see that the graph is divided into two groups. Perform K-means can help us verify it.","metadata":{}},{"cell_type":"code","source":"clust_labels, cent = doKmeans(df2, 2)\nkmeans = pd.DataFrame(clust_labels)\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nscatter = ax.scatter(df2['bmi'],df2['charges'],\n                     c=kmeans[0],s=50)\nax.set_title('K-Means Clustering')\nax.set_xlabel('bmi')\nax.set_ylabel('charges')\nplt.colorbar(scatter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, the two cluster perform very differently, depending on bmi is below or above 30.\n\nTherefore, below we can divide the patients who smoke into two groups: bmi > 30 or bmi <= 30.","metadata":{}},{"cell_type":"code","source":"df3 = df2[(df2.bmi > 30)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(x=\"age\", y=\"charges\", hue=\"sex\", data=df3, palette = 'inferno_r', height = 7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4 = df2[(df2.bmi <= 30)]\nsns.lmplot(x=\"age\", y=\"charges\", hue=\"sex\", data=df4, palette = 'inferno_r', height = 7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat1 = df1[df1.smoker == 0]\ncat2 = df3\ncat3 = df4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This way, all three categories, cat1, cat2, cat3 are obtained.\nNow let's perform machine learning on these three individually. As they are all very linear, linear regression would suffice.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test when we train the whole data set with one linear reg.","metadata":{}},{"cell_type":"code","source":"df_x = df1[[\"age\",\"sex\",\"bmi\",\"children\",\"smoker\"]]\ndf_y = df1[[\"charges\"]]\nX_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2)\nreg = LinearRegression().fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear regression for category 1","metadata":{}},{"cell_type":"code","source":"cat1_x = cat1[[\"age\",\"sex\",\"bmi\",\"children\",\"smoker\"]]\ncat1_y = cat1[[\"charges\"]]\nX_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(cat1_x, cat1_y, test_size=0.2)\nreg_1 = LinearRegression().fit(X_train_1, y_train_1)\n\ny_pred_1 = reg_1.predict(X_test_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear regression for category 2","metadata":{}},{"cell_type":"code","source":"cat2_x = cat2[[\"age\",\"sex\",\"bmi\",\"children\",\"smoker\"]]\ncat2_y = cat2[[\"charges\"]]\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(cat2_x, cat2_y, test_size=0.2)\nreg_2 = LinearRegression().fit(X_train_2, y_train_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear regression for category 3","metadata":{}},{"cell_type":"code","source":"cat3_x = cat3[[\"age\",\"sex\",\"bmi\",\"children\",\"smoker\"]]\ncat3_y = cat3[[\"charges\"]]\nX_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(cat3_x, cat3_y, test_size=0.2)\nreg_3 = LinearRegression().fit(X_train_3, y_train_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It would be great if we can have a mixed linear regression model.","metadata":{}},{"cell_type":"code","source":"def mix_model(df):\n    result = []\n    \n    for i in range(0,df.shape[0] - 1):\n        x = df.iloc[i]\n        xx = df.iloc[i:i+1]\n        if x.smoker == 0:\n            result.append(reg_1.predict(xx))\n        elif x.bmi < 30:\n            result.append(reg_2.predict(xx))\n        else:\n            result.append(reg_3.predict(xx))\n    \n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let us compare the original linear reg. with the new model categorized into three groups.","metadata":{}},{"cell_type":"code","source":"print(reg.score(X_test_1,y_test_1),reg_1.score(X_test_1,y_test_1))\nprint(reg.score(X_test_2,y_test_2),reg_2.score(X_test_2,y_test_2))\nprint(reg.score(X_test_3,y_test_3),reg_3.score(X_test_3,y_test_3))\nmean_squared_error(y_test_1,y_pred_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the scores are greatly improved","metadata":{}},{"cell_type":"code","source":"categories = ['sex','smoker','region']\nfor col in categories:\n    df[col] = df[col].astype('category') \ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['charges'])\ny = df['charges']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nlgb_train = lgb.Dataset(X_train, label=y_train, categorical_feature = categories)\nparams = {}\nparams['learning_rate'] = 0.03\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'regression'\nparams['sub_feature'] = 0.5\nparams['num_leaves'] = 10\nparams['min_data'] = 50\nparams['max_depth'] = 10\nparams['n_estimators'] = 50\n\nlgb_model = lgb.train(params, lgb_train,categorical_feature = categories)\n#Prediction\ny_pred=lgb_model.predict(X_test)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nimport matplotlib.pylab as pl\nexplainer = shap.TreeExplainer(lgb_model)\nshap_values = explainer.shap_values(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values, X) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot('age', shap_values, X, dot_size=32, show=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot('bmi', shap_values, X, dot_size=32, show=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[200], X.iloc[200,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nmean_squared_error(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb.plot_tree(lgb_model,figsize = (15,15))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}