{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## My code","metadata":{"trusted":true}},{"cell_type":"code","source":"# Load packages\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Subset\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torchvision import transforms, datasets, models\nfrom torchvision.utils import make_grid\n\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy\nimport time\nimport seaborn as sn\nimport pandas as pd\n\nimport os\nfrom random import shuffle\nfrom shutil import copyfile, copytree\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n%matplotlib inline\n\n!pip install torchinfo --quiet # Internet On\n# !pip install livelossplot --quiet\n\n# from livelossplot import PlotLosses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"# Dataset\ndataset=\"dataset-4class\"\n\n# classes: \"Covid 19\" \"No finding\" \"Bacterial Pneumonia\" \"Viral Pneumonia\"\n\nclass1=\"Covid 19\" # EDIT\nclass2=\"No finding\" # EDIT\n\nn_folds=5\n\nfiles1=os.listdir(\"../input/\" + dataset + \"/\" + class1)\nfiles2=os.listdir(\"../input/\" + dataset + \"/\" + class2)\nl1=len(files1)\nl2=len(files2)\nprint(l1,l2)\n\nfor fold in range(n_folds):\n    for folder in [\"train\",\"val\"]:\n        for subfolder in [class1, class2]:\n            if not os.path.exists(\"set\" + str(fold+1) + \"/\" + folder + \"/\" + subfolder):\n                os.makedirs(\"set\" + str(fold+1) + \"/\" + folder + \"/\" + subfolder)\n\nkf = KFold(n_splits=n_folds, shuffle=True)\n\nfold=0\nfor m,n in kf.split(files1):  #train,val\n    fold+=1\n    for idx in m:\n        src= \"../input/\" + dataset + \"/\" + class1 + \"/\" + files1[idx]\n        dst= \"set\" + str(fold) + \"/\" + \"train\" + \"/\" + class1 + \"/\" + files1[idx]\n        copyfile(src,dst)\n\n    for idx in n:\n        src= \"../input/\" + dataset + \"/\" + class1 + \"/\" + files1[idx]\n        dst= \"set\" + str(fold) + \"/\" + \"val\" + \"/\" + class1 + \"/\" + files1[idx]\n        copyfile(src,dst)\n    \nfold=0\nfor m,n in kf.split(files2):  #train,val\n    fold+=1\n    for idx in m:\n        src= \"../input/\" + dataset + \"/\" + class2 + \"/\" + files2[idx]\n        dst= \"set\" + str(fold) + \"/\" + \"train\" + \"/\" + class2 + \"/\" + files2[idx]\n        copyfile(src,dst)\n\n    for idx in n:\n        src= \"../input/\" + dataset + \"/\" + class2 + \"/\" + files2[idx]\n        dst= \"set\" + str(fold) + \"/\" + \"val\" + \"/\" + class2 + \"/\" + files2[idx]\n        copyfile(src,dst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sample\n\ndata_transform = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n    ])\n# ColorJitter RandomAutocontrast\n\ntrain_dataset = datasets.ImageFolder(root='set1/train',\n                                           transform=data_transform)\ntrain_loader = DataLoader(train_dataset,batch_size=16, shuffle=True,num_workers=4)\n\nval_dataset = datasets.ImageFolder(root='set1/val',\n                                           transform=data_transform)\nval_loader = DataLoader(val_dataset,batch_size=16, shuffle=True,num_workers=4)\n\n# Print number of samples of each class\nfrom collections import Counter\nprint(train_dataset.class_to_idx)\n\nprint(\"\\nTrain: \",dict(Counter(train_dataset.targets)))\nprint(\"Val: \",dict(Counter(val_dataset.targets)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample images and their labels\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\nprint(images.shape)\nprint(labels.shape)\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.figure(figsize=(10,50))\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\nclasses=train_dataset.classes\n\nimshow(make_grid(images[0:5]))\nprint(' '.join('%5s' % classes[labels[j]] for j in range(5)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"### SE Net: SE module, SE Resnet, SE Inception","metadata":{}},{"cell_type":"code","source":"# Define the SE module\n\nclass SELayer(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\n# SE Resnet\n    \nfrom torch.hub import load_state_dict_from_url\nfrom torchvision.models import ResNet\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n\nclass SEBasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None,\n                 *, reduction=16):\n        super(SEBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes, 1)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.se = SELayer(planes, reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass SEBottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None,\n                 *, reduction=16):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se = SELayer(planes * 4, reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\ndef se_resnet18(num_classes=1_000):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet34(num_classes=1_000):\n    \"\"\"Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet50(num_classes=1_000, pretrained=False):\n    \"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    if pretrained:\n        model.load_state_dict(load_state_dict_from_url(\n            \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\"))\n    return model\n\n\ndef se_resnet101(num_classes=1_000):\n    \"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 4, 23, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet152(num_classes=1_000):\n    \"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 8, 36, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\nclass CifarSEBasicBlock(nn.Module):\n    def __init__(self, inplanes, planes, stride=1, reduction=16):\n        super(CifarSEBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.se = SELayer(planes, reduction)\n        if inplanes != planes:\n            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n                                            nn.BatchNorm2d(planes))\n        else:\n            self.downsample = lambda x: x\n        self.stride = stride\n\n    def forward(self, x):\n        residual = self.downsample(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.se(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass CifarSEResNet(nn.Module):\n    def __init__(self, block, n_size, num_classes=10, reduction=16):\n        super(CifarSEResNet, self).__init__()\n        self.inplane = 16\n        self.conv1 = nn.Conv2d(\n            3, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.inplane)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(\n            block, 16, blocks=n_size, stride=1, reduction=reduction)\n        self.layer2 = self._make_layer(\n            block, 32, blocks=n_size, stride=2, reduction=reduction)\n        self.layer3 = self._make_layer(\n            block, 64, blocks=n_size, stride=2, reduction=reduction)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(64, num_classes)\n        self.initialize()\n\n    def initialize(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride, reduction):\n        strides = [stride] + [1] * (blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.inplane, planes, stride, reduction))\n            self.inplane = planes\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\nclass CifarSEPreActResNet(CifarSEResNet):\n    def __init__(self, block, n_size, num_classes=10, reduction=16):\n        super(CifarSEPreActResNet, self).__init__(\n            block, n_size, num_classes, reduction)\n        self.bn1 = nn.BatchNorm2d(self.inplane)\n        self.initialize()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n\ndef se_resnet20(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = CifarSEResNet(CifarSEBasicBlock, 3, **kwargs)\n    return model\n\n\ndef se_resnet32(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEResNet(CifarSEBasicBlock, 5, **kwargs)\n    return model\n\n\ndef se_resnet56(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEResNet(CifarSEBasicBlock, 9, **kwargs)\n    return model\n\n\ndef se_preactresnet20(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = CifarSEPreActResNet(CifarSEBasicBlock, 3, **kwargs)\n    return model\n\n\ndef se_preactresnet32(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEPreActResNet(CifarSEBasicBlock, 5, **kwargs)\n    return model\n\n\ndef se_preactresnet56(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEPreActResNet(CifarSEBasicBlock, 9, **kwargs)\n    return model\n\n# SE Inception\n\nfrom torchvision.models.inception import Inception3\n\n\nclass SEInception3(nn.Module):\n    def __init__(self, num_classes, aux_logits=True, transform_input=False):\n        super(SEInception3, self).__init__()\n        model = Inception3(num_classes=num_classes, aux_logits=aux_logits,\n                           transform_input=transform_input)\n        model.Mixed_5b.add_module(\"SELayer\", SELayer(192))\n        model.Mixed_5c.add_module(\"SELayer\", SELayer(256))\n        model.Mixed_5d.add_module(\"SELayer\", SELayer(288))\n        model.Mixed_6a.add_module(\"SELayer\", SELayer(288))\n        model.Mixed_6b.add_module(\"SELayer\", SELayer(768))\n        model.Mixed_6c.add_module(\"SELayer\", SELayer(768))\n        model.Mixed_6d.add_module(\"SELayer\", SELayer(768))\n        model.Mixed_6e.add_module(\"SELayer\", SELayer(768))\n        if aux_logits:\n            model.AuxLogits.add_module(\"SELayer\", SELayer(768))\n        model.Mixed_7a.add_module(\"SELayer\", SELayer(768))\n        model.Mixed_7b.add_module(\"SELayer\", SELayer(1280))\n        model.Mixed_7c.add_module(\"SELayer\", SELayer(2048))\n\n        self.model = model\n\n    def forward(self, x):\n        _, _, h, w = x.size()\n        if (h, w) != (299, 299):\n            raise ValueError(\"input size must be (299, 299)\")\n\n        return self.model(x)\n\n\ndef se_inception_v3(**kwargs):\n    return SEInception3(**kwargs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model List","metadata":{}},{"cell_type":"code","source":"\ndef model_select(model_name,num_classes,aux_logits,pretrained):\n    \n    if(model_name==\"scratch\"):\n        #Model from scratch\n        model = nn.Sequential(\n\n            # Conv2D(input channels, output channels, kernel size, padding, stride)\n            nn.Conv2d(3,16,kernel_size=3,padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(16,32,kernel_size=3,padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Conv2d(32,64,kernel_size=3,padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Conv2d(64,128,kernel_size=3,padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n\n            nn.MaxPool2d(2, stride=2),\n\n            nn.Conv2d(128, 3, kernel_size=1),\n            nn.Flatten(),\n            nn.Linear(in_features=2352, out_features=100, bias=True),\n            nn.Linear(in_features=100, out_features=num_classes, bias=True)\n        )\n\n    # New\n    elif(model_name==\"se_resnet18\"):\n        model = se_resnet18(num_classes=num_classes)\n        \n    elif(model_name==\"se_resnet34\"):\n        model = se_resnet34(num_classes=num_classes)\n    \n    elif(model_name==\"se_resnet50\"):\n        model = se_resnet50(num_classes=num_classes,pretrained=pretrained)\n        \n    elif(model_name==\"se_resnet101\"):\n        model = se_resnet101(num_classes=num_classes)\n        \n    elif(model_name==\"se_resnet152\"):\n        model = se_resnet152(num_classes=num_classes)\n            \n    elif(model_name==\"se_inception_v3\"):\n        model = se_inception_v3(num_classes=num_classes,aux_logits=aux_logits)\n    \n    elif(model_name == \"inceptionV3\"):\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model = models.inception_v3(pretrained=pretrained)\n        # Handle the auxilary net\n        num_ftrs = model.AuxLogits.fc.in_features\n        model.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs,num_classes)   \n        \n    # Resnet family\n    elif(model_name==\"resnet18\"):\n        model=models.resnet18(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"resnet34\"):\n        model=models.resnet34(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"resnet50\"):\n        model=models.resnet50(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"resnet101\"):\n        model=models.resnet101(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"resnet152\"):\n        model=models.resnet152(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"alexnet\"):\n        model = models.alexnet(pretrained=pretrained)\n        num_ftrs = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n\n    # Wide Resnet family\n    elif(model_name==\"wide_resnet50\"):\n        model=models.wide_resnet50_2(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"wide_resnet101\"):\n        model=models.wide_resnet101_2(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    # VGG family\n    elif(model_name==\"vgg11_bn\"):\n        model = models.vgg11_bn(pretrained=pretrained)\n        num_ftrs = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n\n    elif(model_name==\"vgg16_bn\"):\n        model = models.vgg16_bn(pretrained=pretrained)\n        num_ftrs = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n\n    elif(model_name==\"vgg19_bn\"):\n        model = models.vgg19_bn(pretrained=pretrained)\n        num_ftrs = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n\n    elif(model_name==\"squeezenet\"):\n        model= models.squeezenet1_1(pretrained=pretrained)\n        model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n\n    # Densenet family\n    elif(model_name==\"densenet121\"):\n        model= models.densenet121(pretrained=pretrained)\n        num_ftrs = model.classifier.in_features\n        model.classifier = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"densenet169\"):\n        model= models.densenet169(pretrained=pretrained)\n        num_ftrs = model.classifier.in_features\n        model.classifier = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"densenet201\"):\n        model= models.densenet201(pretrained=pretrained)\n        num_ftrs = model.classifier.in_features\n        model.classifier = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"densenet161\"):\n        model= models.densenet161(pretrained=pretrained)\n        num_ftrs = model.classifier.in_features\n        model.classifier = nn.Linear(num_ftrs, num_classes)\n\n    # ResNext family\n    elif(model_name==\"resnext50\"):\n        model= models.resnext50_32x4d(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif(model_name==\"resnext101\"):\n        model= models.resnext101_32x8d(pretrained=pretrained)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    else:\n        print(\"Error in model_name\")\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Select Model","metadata":{}},{"cell_type":"code","source":"# Select model\nnum_classes=2\nmodel_name=\"resnext101\" # EDIT\naux_logits=False\npretrained=True # EDIT\n\nmodel=model_select(model_name,num_classes,aux_logits,pretrained)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model summary\nfrom torchinfo import summary\nsummary(model, (16, 3, 224, 224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions: Early Stopping","metadata":{}},{"cell_type":"code","source":"# Early stopping\nclass EarlyStopping(object):\n    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n        self.mode = mode\n        self.min_delta = min_delta\n        self.patience = patience\n        self.best = None\n        self.num_bad_epochs = 0\n        self.is_better = None\n        self._init_is_better(mode, min_delta, percentage)\n\n        if patience == 0:\n            self.is_better = lambda a, b: True\n            self.step = lambda a: False\n\n    def step(self, metrics):\n        if self.best is None:\n            self.best = metrics\n            return False\n\n        if torch.isnan(metrics):\n            return True\n\n        if self.is_better(metrics, self.best):\n            self.num_bad_epochs = 0\n            self.best = metrics\n        else:\n            self.num_bad_epochs += 1\n\n        if self.num_bad_epochs >= self.patience:\n            return True\n\n        return False\n\n    def _init_is_better(self, mode, min_delta, percentage):\n        if mode not in {'min', 'max'}:\n            raise ValueError('mode ' + mode + ' is unknown!')\n        if not percentage:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - min_delta\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + min_delta\n        else:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - (\n                            best * min_delta / 100)\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + (\n                            best * min_delta / 100)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training + Validation","metadata":{}},{"cell_type":"code","source":"# Training Parameters\n\nnum_epochs=10 # EDIT\n\n# Loss fn\nweights = [5.0, 1.0] # classes are acc. to alphabetical order # EDIT\nclass_weights = torch.FloatTensor(weights).cuda()\ncriterion = nn.CrossEntropyLoss(weight = class_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training + Validation + Testing\n\nt0=time.time()\n# groups = {'Accuracy': ['accuracy', 'val_accuracy'], 'Loss': ['loss', 'val_loss']}\n# liveloss = PlotLosses(groups=groups)\nlogs={}\nop={}\n\nfor fold in range(1):\n    t1=time.time()\n    \n    # Load data\n    train_dataset = datasets.ImageFolder(root='set' + str(fold+1) + '/train',transform=data_transform)\n    train_loader = DataLoader(train_dataset,batch_size=16, shuffle=True,num_workers=4)\n    val_dataset = datasets.ImageFolder(root='set'  + str(fold+1) +  '/val',transform=data_transform)\n    val_loader = DataLoader(val_dataset,batch_size=16, shuffle=True,num_workers=4)\n\n    model=model_select(model_name,num_classes,aux_logits,pretrained)\n    model = model.to(device)\n\n    # Optimizer\n    optimizer = optim.Adam(model.parameters(), lr=1e-4) # EDIT\n\n    # LR scheduler: Decays the learning rate of each parameter group by gamma every step_size epochs \n    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) # EDIT\n\n    # Early stopping: patience: Number of epochs with no improvement after which training will be stopped\n    es = EarlyStopping(patience = 25) # EDIT\n\n    logs[ str(fold+1) + \"_\" + \"train_loss\"] = []\n    logs[ str(fold+1) + \"_\" + \"train_accuracy\"] = []\n    logs[ str(fold+1) + \"_\" + \"val_loss\"] = []\n    logs[ str(fold+1) + \"_\" + \"val_accuracy\"] = []\n    op[ str(fold+1) + \"_\" + \"y\"]=[]\n    op[ str(fold+1) + \"_\" + \"yhat\"]=[]\n    \n    for epoch in range(num_epochs):\n        t2=time.time()\n\n        # Training\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in train_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            if aux_logits: \n                # Inception models have two losses during training\n                outputs, aux_outputs = model(inputs)\n                loss1 = criterion(outputs, labels)\n                loss2 = criterion(aux_outputs, labels)\n                loss = loss1 + 0.4*loss2\n\n            else:\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.detach() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        train_loss = (running_loss / len(train_loader.dataset))\n        train_accuracy = (running_corrects.float() / len(train_loader.dataset))\n        logs[ str(fold+1) + \"_\" + \"train_loss\"].append(train_loss.item())\n        logs[ str(fold+1) + \"_\" + \"train_accuracy\"].append(train_accuracy.item())\n\n        scheduler.step() # LR scheduler\n\n        # Validation\n        model.eval()\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.detach() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        val_loss = (running_loss / len(val_loader.dataset))\n        val_accuracy = (running_corrects.float() / len(val_loader.dataset))\n        logs[ str(fold+1) + \"_\" + \"val_loss\"].append(val_loss.item())\n        logs[ str(fold+1) + \"_\" + \"val_accuracy\"].append(val_accuracy.item())\n\n        if es.step(val_loss): # Early stopping by monitoring val_loss\n            break\n\n    #     liveloss.update(logs)\n    #     liveloss.send()\n\n        print(\"\\nTrain loss: {:.4f} \\t Val loss: {:.4f} \\t Train acc.: {:.4f} \\t Val acc.: {:.4f}\"\n              .format(train_loss.item(),val_loss.item(),train_accuracy.item(),val_accuracy.item()))\n\n        print('Epoch: {} \\t LR: {:.2e} \\tEpoch time: {:.2f} s'\n                .format(epoch+1,optimizer.param_groups[0]['lr'],time.time()- t2))\n        \n        print(\"Fold: {} \\t\" \"Fold time: {:.2f} s \\tTotal time: {:.2f} s\"\n                 .format(fold+1,time.time()-t1,time.time()-t0))\n        \n    # Plot\n    plt.figure(figsize=(12,6))\n    plt.subplot(121)\n    plt.plot(logs[ str(fold+1) + \"_\" + \"train_loss\"])\n    plt.plot(logs[ str(fold+1) + \"_\" + \"val_loss\"])\n    plt.legend([\" Train loss\", \"Val loss\"])\n    plt.title(\"Loss\")\n    plt.subplot(122)\n    plt.plot(logs[ str(fold+1) + \"_\" + \"train_accuracy\"])\n    plt.plot(logs[ str(fold+1) + \"_\" + \"val_accuracy\"])\n    plt.legend([\"Train accuracy\",\"Val accuracy\"])\n    plt.title(\"Accuracy\")\n    plt.show()\n    \n    # Testing\n    correct = 0\n    total = 0\n    yhat=[]\n    y=[]\n    with torch.no_grad():\n        for data in val_loader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            y.append(labels.tolist())\n            yhat.append(predicted.tolist())\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print(\"\\nFold: {} \\t Accuracy: {:.4f}\" .format(str(fold+1),100 * correct / total))\n    \n    # Get y,yhat as list\n    op[ str(fold+1) + \"_\" + \"y\"]=[item for sublist in y for item in sublist]\n    op[ str(fold+1) + \"_\" + \"yhat\"]=[item for sublist in yhat for item in sublist]\n\nprint(\"\\nModel name: \",model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance Metrics","metadata":{}},{"cell_type":"code","source":"class_names = val_dataset.classes\n\nmetrics={}\nmetrics[\"acc\"]=[]\n\nfor c in [class1, class2, \"weighted avg\"]:\n    metrics[c]={}\n    for m in [\"precision\",\"recall\",\"f1-score\"]:\n        metrics[c][m]=[]\n\nfor fold in range(n_folds):\n    y=op[ str(fold+1) + \"_\" + \"y\"]\n    yhat=op[ str(fold+1) + \"_\" + \"yhat\"]\n    \n    # Print confusion matrix\n#     cm=confusion_matrix(y,yhat)\n#     print(cm)\n\n    # Print metrics\n#     cm_report=classification_report(y, yhat, target_names=class_names, digits=4)\n#     print(cm_report)\n    \n    cm_dict=classification_report(y,yhat, target_names=class_names, digits=4, output_dict=True)\n    metrics[\"acc\"].append(cm_dict[\"accuracy\"])\n    for c in [class1, class2,\"weighted avg\"]:\n        for m in [\"precision\",\"recall\",\"f1-score\"]:\n            metrics[c][m].append(cm_dict[c][m])\n\nprint(\"\\nMean performance: \")\nprint(\"\\nAccuracy: {:.4f}\".format(np.mean(metrics[\"acc\"])))\nfor c in [class1, class2, \"weighted avg\"]:\n    print(c)\n    for m in [\"precision\",\"recall\",\"f1-score\"]:\n        print(\"\\t\",m,\": {:.4f}\".format(np.mean(metrics[c][m])))\n        \nprint(\"\\nModel Name: {}\".format(model_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(n_folds):\n    y=op[ str(fold+1) + \"_\" + \"y\"]\n    yhat=op[ str(fold+1) + \"_\" + \"yhat\"]\n    \n    # Print confusion matrix\n    cm=confusion_matrix(y,yhat)\n#     print(cm)\n    \n    # Enhanced confusion matrix\n    plt.figure(figsize=(6,4))\n\n    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names).astype(int)\n    heatmap = sn.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt=\"d\", annot_kws={'size':16})\n\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing a few samples\n\nfor images, labels in val_loader:\n    if len(labels[labels==0]) >= 2 and len(labels[labels==1]) >=2:\n        \n        # print images\n        print(\"Sample predictions\\n\")\n        imshow(make_grid(images[0:4]))\n        plt.show()\n        print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n\n        images=images.to(device)\n        outputs=model(images)\n        _, predicted = torch.max(outputs, 1)\n        print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                                      for j in range(4)))\n\n        # print images\n        print(\"Sample predictions\\n\")\n        images = images.cpu()\n        imshow(make_grid(images[4:8]))\n        plt.show()\n        print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4,8)))\n\n        images=images.to(device)\n        outputs=model(images)\n        _, predicted = torch.max(outputs, 1)\n        print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                                      for j in range(4,8)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing a few samples\ndataiter = iter(val_loader)\nimages, labels = dataiter.next()\n\n# print images\nprint(\"Sample predictions\\n\")\nimshow(make_grid(images[0:4]))\nplt.show()\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n\nimages=images.to(device)\noutputs=model(images)\n_, predicted = torch.max(outputs, 1)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))\n\n# print images\nprint(\"Sample predictions\\n\")\nimages = images.cpu()\nimshow(make_grid(images[4:8]))\nplt.show()\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4,8)))\n\nimages=images.to(device)\noutputs=model(images)\n_, predicted = torch.max(outputs, 1)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4,8)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Save model\n# #date-time,model name, pretrained=True or False\n# PATH=\"/kaggle/working/{}_{}.pth\".format(time.strftime(\"%Y%m%d-%H%M%S\"),model_name)\n# torch.save(model.state_dict(), PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}