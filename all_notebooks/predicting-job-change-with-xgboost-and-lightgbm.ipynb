{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Prediction of Data Scientists' Job Change"},{"metadata":{},"cell_type":"markdown","source":"1. Binary Classification Problem: Predict \"Change\" or \"Not Change\"**\n2. The data contains a lot of missing values, and the target variable is imbalanced.\n3. Apply various algorithm using various methods of handling missing values and data rebalancing.\n  - Methods for Handling missing data: 1) Dropping, 2) Mode imputation, 3) KNN imputation, 4) No imputation\n  - Data Rebalancing a) Imbalanced data, b) SMOTE, c) Scale Pos Weight  \n4. Algorithm:\n - Logistic Regression (1, 2, 3, a, b)\n - Random Forest (2, 3, a, b)\n - XGBoostn (2, 3, 4, a, b, c)\n - LightGBM (4, a, c)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load and Explore Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the necessary packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score,recall_score\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nsns.set(color_codes=True)\n%matplotlib inline\n%config InlineBackend.figure_formats = {'png', 'retina'}\n\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Dataset\ndf_train = pd.read_csv(\"../input/hr-analytics-job-change-of-data-scientists/aug_train.csv\")\ndf_test = pd.read_csv(\"../input/hr-analytics-job-change-of-data-scientists/aug_test.csv\")\n\n# Display 5 rows of the training data\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display dataset shape\nprint(\"train shape: \",df_train.shape)\nprint(\"test shape : \", df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display descriptive statistics of training data\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display training data information\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- \"gender\",\"enrolled_university\",\"major_discipline\",\"experience\",\"company_size\",\"company_type\",\"last_new_job\" contain missing values.\n- Majory of the variables are categorical variables. They need to be encoded."},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of columns which will be used in modelling\ncolumns = ['city',\n           'city_development_index',\n           'gender',\n           'relevent_experience',\n           'enrolled_university',\n           'education_level',\n           'major_discipline',\n           'experience',\n           'company_size',\n           'company_type',\n           'last_new_job',\n           'training_hours']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode categorical variables\n\n# Import package\nfrom sklearn.preprocessing import OrdinalEncoder\n\n# Instantiate encoder\nencoder = OrdinalEncoder()\n\n# Define a function for encoding\ndef encode(train_data, test_data):\n    '''function to encode non-null data and replace it in the original data'''\n    #retains only non-null values\n    train_data_nonulls = np.array(train_data.dropna())\n    test_data_nonulls = np.array(test_data.dropna())\n    #reshapes the data for encoding\n    train_impute_reshape = train_data_nonulls.reshape(-1,1)\n    test_impute_reshape = test_data_nonulls.reshape(-1,1)\n    #encode date\n    train_impute_ordinal = encoder.fit_transform(train_impute_reshape)\n    test_impute_ordinal = encoder.transform(test_impute_reshape)\n    #Assign back encoded values to non-null values\n    train_data.loc[train_data.notnull()] = np.squeeze(train_impute_ordinal)\n    test_data.loc[test_data.notnull()] = np.squeeze(test_impute_ordinal)\n    return train_data, test_data\n\n# Apply encoding funtion using a for loop to apply it to each column\nfor column in columns:\n    df_train[column], df_test[column] = encode(df_train[column], df_test[column])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if the columns were encoded properly\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The categorical variables were encoded to numeric."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the balance of target value\ndf_train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The data is imbalanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check each variable's data type\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"THe data still contains object data. So let's convert them into float manually."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert object data into float\ndf_train['gender'] = df_train['gender'].astype(float)\ndf_train['enrolled_university'] = df_train['enrolled_university'].astype(float)\ndf_train['education_level'] = df_train['education_level'].astype(float)\ndf_train['major_discipline'] = df_train['major_discipline'].astype(float)\ndf_train['experience'] = df_train['experience'].astype(float)\ndf_train['company_size'] = df_train['company_size'].astype(float)\ndf_train['company_type'] = df_train['company_type'].astype(float)\ndf_train['last_new_job'] = df_train['last_new_job'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the data type\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Object variables were converted into float."},{"metadata":{},"cell_type":"markdown","source":"# 1. Logistic Regression with Data: Observations with missing values were dropped"},{"metadata":{},"cell_type":"markdown","source":"- First, let's make prediction using logistic regression.\n- Here, let's drop the observations with one or more missing values."},{"metadata":{},"cell_type":"markdown","source":"### Keep only rows without missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rows with one or more missing values\n# Keep only rows that have no missing values\ndf_train_nonmis = pd.DataFrame(df_train).dropna(how='any', axis=1)\nprint(df_train_nonmis.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only 6 variables remain."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate the dataset into features and target\nXnonmis = df_train_nonmis.drop(['enrollee_id','city','target'],axis=1)\nynonmis = df_train_nonmis['target']\n\n# Split the data into train and test\n# Since test data does not contain the target, split the training data into train and test to evaluate the model performance \nXnonmis_train, Xnonmis_test, ynonmis_train, ynonmis_test = train_test_split(Xnonmis, ynonmis, test_size=.30, \n                                                                            stratify=ynonmis, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the data\n\n# Standardize the columns the values of which are out of 0-1 range\nscaler = StandardScaler().fit(Xnonmis_train)\n\nXnonmis_train = scaler.transform(Xnonmis_train)\nXnonmis_test = scaler.transform(Xnonmis_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nnonmis_lm = LogisticRegression()\n\n# Fit the model\nnonmis_lm.fit(Xnonmis_train, ynonmis_train.ravel())\n\n# Make Predictions\nnonmis_lm_pred = nonmis_lm.predict(Xnonmis_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nnonmis_lm_accuracy = accuracy_score(ynonmis_test, nonmis_lm_pred)\nnonmis_lm_precision = precision_score(ynonmis_test, nonmis_lm_pred)\nnonmis_lm_recall = recall_score(ynonmis_test, nonmis_lm_pred)\nnonmis_lm_f1 = 2 * (nonmis_lm_precision * nonmis_lm_recall) / (nonmis_lm_precision + nonmis_lm_recall)\n\n# Calculate AUC score\nnonmis_lm_probs = nonmis_lm.predict_proba(Xnonmis_test)\nnonmis_lm_probs = nonmis_lm_probs[:,1]\nnonmis_lm_auc = roc_auc_score(ynonmis_test, nonmis_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: Rows without missing values\")\nprint(\" - Accuracy : \",'{:.3f}'.format(nonmis_lm_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(nonmis_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(nonmis_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(nonmis_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(ynonmis_test,nonmis_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The model contains only some of the whole variables. So it lost much information.\n- So, next, let's impute missing variables."},{"metadata":{},"cell_type":"markdown","source":"# 2. Prediction with Mode Imputation"},{"metadata":{},"cell_type":"markdown","source":"- Let's imput missing values by a traditional way: since the focal variables are categorical, let's use the mode for imputation.\n- As we saw above, \"gender\",\"enrolled_university\",\"major_discipline\",\"experience\",\"company_size\",\"company_type\",\"last_new_job\" contain missing values. So let's check the distribution of these variables."},{"metadata":{},"cell_type":"markdown","source":"## Mode Imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create countplot for \"gender\"\nfig, ax =plt.subplots(4,2,figsize=(20,16))\nsns.countplot(df_train['gender'], ax=ax[0,0])\nsns.countplot(df_train['enrolled_university'], ax=ax[0,1])\nsns.countplot(df_train['major_discipline'], ax=ax[1,0])\nsns.countplot(df_train['experience'], ax=ax[1,1])\nsns.countplot(df_train['company_size'], ax=ax[2,0])\nsns.countplot(df_train['company_type'], ax=ax[2,1])\nsns.countplot(df_train['last_new_job'], ax=ax[3,0])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute missing values with mode\ndf_imp = df_train\ndf_imp.fillna(df_imp.mode().iloc[0],inplace=True)\ndf_imp.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values were imputed successfully."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummies for nominal variables\ndf_imp = pd.concat([df_imp,pd.get_dummies(df_imp[\"gender\"], prefix=\"gender\")], \n                   axis=1).drop(columns=[\"gender\"])\ndf_imp = pd.concat([df_imp,pd.get_dummies(df_imp[\"enrolled_university\"], prefix=\"enrolled_university\")], \n                   axis=1).drop(columns=[\"enrolled_university\"])\ndf_imp = pd.concat([df_imp,pd.get_dummies(df_imp[\"major_discipline\"], prefix=\"major_discipline\")], \n                   axis=1).drop(columns=[\"major_discipline\"])\ndf_imp = pd.concat([df_imp,pd.get_dummies(df_imp[\"company_type\"], prefix=\"company_type\")], \n                   axis=1).drop(columns=[\"company_type\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate the dataset into features and target\nX_imp = df_imp.drop(['enrollee_id','target'],axis=1)\ny_imp = df_imp['target']\n\n# Split the data into train and test\n# Since test data does not contain the target, split the training data into train and test to evaluate the model performance \nX_imp_train, X_imp_test, y_imp_train, y_imp_test = train_test_split(X_imp, y_imp, test_size=.30,stratify=y_imp, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the data\n\n# Standardize the columns the values of which are out of 0-1 range\nscaler = StandardScaler().fit(X_imp_train)\n\nX_imp_train = scaler.transform(X_imp_train)\nX_imp_test = scaler.transform(X_imp_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1. Prediction with Imbalanced Data: Mode Imputation"},{"metadata":{},"cell_type":"markdown","source":"### 2.1.1. Logistic Regression: Mode Imputation - Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nimp_lm = LogisticRegression()\n\n# Fit the model\nimp_lm.fit(X_imp_train, y_imp_train.ravel())\n\n# Make Predictions\nimp_lm_pred = imp_lm.predict(X_imp_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nimp_lm_accuracy = accuracy_score(y_imp_test, imp_lm_pred)\nimp_lm_precision = precision_score(y_imp_test, imp_lm_pred)\nimp_lm_recall = recall_score(y_imp_test, imp_lm_pred)\nimp_lm_f1 = 2 * (imp_lm_precision * imp_lm_recall) / (imp_lm_precision + imp_lm_recall)\n\n# Calculate AUC score\nimp_lm_probs = imp_lm.predict_proba(X_imp_test)\nimp_lm_probs = imp_lm_probs[:,1]\nimp_lm_auc = roc_auc_score(y_imp_test, imp_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: Imputation with Mode\")\nprint(\" - Accuracy : \",'{:.3f}'.format(imp_lm_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(imp_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(imp_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(imp_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_imp_test,imp_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1.2. Random Forest: Mode Imputation - Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nimp_rf = RandomForestClassifier()\n\n# Fit the model\nimp_rf.fit(X_imp_train, y_imp_train.ravel())\n\n# Make Predictions\nimp_rf_pred = imp_rf.predict(X_imp_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nimp_rf_accuracy = accuracy_score(y_imp_test, imp_rf_pred)\nimp_rf_precision = precision_score(y_imp_test, imp_rf_pred)\nimp_rf_recall = recall_score(y_imp_test, imp_rf_pred)\nimp_rf_f1 = 2 * (imp_rf_precision * imp_rf_recall) / (imp_rf_precision + imp_rf_recall)\n\n# Calculate AUC score\nimp_rf_probs = imp_rf.predict_proba(X_imp_test)\nimp_rf_probs = imp_rf_probs[:,1]\nimp_rf_auc = roc_auc_score(y_imp_test, imp_rf_probs)\n\n# Display the metrics\nprint(\"Random Forest: Imputation with Mode\")\nprint(\" - Accuracy : \",'{:.3f}'.format(imp_rf_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(imp_rf_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(imp_rf_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(imp_rf_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_imp_test,imp_rf_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1.3. XGBoost: Mode Imputation - Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nimp_xgb = XGBClassifier()\n\n# Fit the model\nimp_xgb.fit(X_imp_train, y_imp_train.ravel())\n\n# Make Predictions\nimp_xgb_pred = imp_xgb.predict(X_imp_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nimp_xgb_accuracy = accuracy_score(y_imp_test, imp_xgb_pred)\nimp_xgb_precision = precision_score(y_imp_test, imp_xgb_pred)\nimp_xgb_recall = recall_score(y_imp_test, imp_xgb_pred)\nimp_xgb_f1 = 2 * (imp_xgb_precision * imp_xgb_recall) / (imp_xgb_precision + imp_xgb_recall)\n\n# Calculate AUC score\nimp_xgb_probs = imp_xgb.predict_proba(X_imp_test)\nimp_xgb_probs = imp_xgb_probs[:,1]\nimp_xgb_auc = roc_auc_score(y_imp_test, imp_xgb_probs)\n\n# Display the metrics\nprint(\"XGBoost: Imputation with Mode\")\nprint(\" - Accuracy : \",'{:.3f}'.format(imp_xgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(imp_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(imp_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(imp_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_imp_test,imp_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Prediction with Mode Imputation & SMOTE"},{"metadata":{},"cell_type":"markdown","source":"### Apply SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since this is an imbalanced data, apply SMOTE to the training set\nfrom imblearn.over_sampling import SMOTE\nsmote=SMOTE()\nX_smote_imp_train, y_smote_imp_train = smote.fit_sample(X_imp_train,y_imp_train)\n\n# Check if SMOTE were properly applied\ny_smote_imp_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.1. Logistic Regression: Mode Imputation - SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_imp_lm = LogisticRegression()\n\n# Fit the model\nsmote_imp_lm.fit(X_smote_imp_train, y_smote_imp_train.ravel())\n\n# Make Predictions\nsmote_imp_lm_pred = smote_imp_lm.predict(X_imp_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_imp_lm_accuracy = accuracy_score(y_imp_test, smote_imp_lm_pred)\nsmote_imp_lm_precision = precision_score(y_imp_test, smote_imp_lm_pred)\nsmote_imp_lm_recall = recall_score(y_imp_test, smote_imp_lm_pred)\nsmote_imp_lm_f1 = 2 * (smote_imp_lm_precision * smote_imp_lm_recall) / (smote_imp_lm_precision + smote_imp_lm_recall)\n\n# Calculate AUC score\nsmote_imp_lm_probs = smote_imp_lm.predict_proba(X_imp_test)\nsmote_imp_lm_probs = smote_imp_lm_probs[:,1]\nsmote_imp_lm_auc = roc_auc_score(y_imp_test, smote_imp_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: Imputation with Mode: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_imp_lm_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_imp_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_imp_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_imp_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_imp_test,smote_imp_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.2. Random Forest: Mode Imputation - SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_imp_rf = RandomForestClassifier()\n\n# Fit the model\nsmote_imp_rf.fit(X_smote_imp_train, y_smote_imp_train.ravel())\n\n# Make Predictions\nsmote_imp_rf_pred = smote_imp_rf.predict(X_imp_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_imp_rf_accuracy = accuracy_score(y_imp_test, smote_imp_rf_pred)\nsmote_imp_rf_precision = precision_score(y_imp_test, smote_imp_rf_pred)\nsmote_imp_rf_recall = recall_score(y_imp_test, smote_imp_rf_pred)\nsmote_imp_rf_f1 = 2 * (smote_imp_rf_precision * smote_imp_rf_recall) / (smote_imp_rf_precision + smote_imp_rf_recall)\n\n# Calculate AUC score\nsmote_imp_rf_probs = smote_imp_rf.predict_proba(X_imp_test)\nsmote_imp_rf_probs = smote_imp_rf_probs[:,1]\nsmote_imp_rf_auc = roc_auc_score(y_imp_test, smote_imp_rf_probs)\n\n# Display the metrics\nprint(\"Random Forest: Imputation with Mode: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_imp_rf_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_imp_rf_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_imp_rf_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_imp_rf_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_imp_test,smote_imp_rf_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.3. XGBoost: Mode Imputation - SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_imp_xgb = XGBClassifier()\n\n# Fit the model\nsmote_imp_xgb.fit(X_smote_imp_train, y_smote_imp_train.ravel())\n\n# Make Predictions\nsmote_imp_xgb_pred = smote_imp_xgb.predict(X_imp_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_imp_xgb_accuracy = accuracy_score(y_imp_test, smote_imp_xgb_pred)\nsmote_imp_xgb_precision = precision_score(y_imp_test, smote_imp_xgb_pred)\nsmote_imp_xgb_recall = recall_score(y_imp_test, smote_imp_xgb_pred)\nsmote_imp_xgb_f1 = 2 * (smote_imp_xgb_precision * smote_imp_xgb_recall) / (smote_imp_xgb_precision + smote_imp_xgb_recall)\n\n# Calculate AUC score\nsmote_imp_xgb_probs = smote_imp_xgb.predict_proba(X_imp_test)\nsmote_imp_xgb_probs = smote_imp_xgb_probs[:,1]\nsmote_imp_xgb_auc = roc_auc_score(y_imp_test, smote_imp_xgb_probs)\n\n# Display the metrics\nprint(\"XGBoost: Imputation with Mode: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_imp_xgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_imp_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_imp_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_imp_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_imp_test,smote_imp_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Prediction with KNN Imputation"},{"metadata":{},"cell_type":"markdown","source":"## KNN Imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute missing values with KNN\nfrom sklearn.impute import KNNImputer\nfrom numpy import isnan\n\n# Copy the dataset for KNN imputation\ndf_knn = df_train\n\n# Separate the dataset into features and target\nX_knn = df_knn.drop(['enrollee_id','city','target'],axis=1)\ny_knn = df_knn['target']\n\n# Define imputer\nimputer = KNNImputer()\n\n# fit on the dataset\nimputer.fit(X_knn)\n\n# Transform the dataset\nX_knn = imputer.transform(X_knn)\n\n# Convert to dataframe\nX_knn = pd.DataFrame(X_knn)\nX_knn.columns = [\"city_development_index\",\"gender\",\"relevent_experience\",\"enrolled_university\",\"education_level\",\"major_discipline\",\n                 \"experience\",\"company_size\",\"company_type\",\"last_new_job\",\"training_hours\"]\nX_knn.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummies for nominal variables\nX_knn = pd.concat([X_knn,pd.get_dummies(X_knn[\"gender\"], prefix=\"gender\")], \n                   axis=1).drop(columns=[\"gender\"])\nX_knn = pd.concat([X_knn,pd.get_dummies(X_knn[\"enrolled_university\"], prefix=\"enrolled_university\")], \n                   axis=1).drop(columns=[\"enrolled_university\"])\nX_knn = pd.concat([X_knn,pd.get_dummies(X_knn[\"major_discipline\"], prefix=\"major_discipline\")], \n                   axis=1).drop(columns=[\"major_discipline\"])\nX_knn = pd.concat([X_knn,pd.get_dummies(X_knn[\"company_type\"], prefix=\"company_type\")], \n                   axis=1).drop(columns=[\"company_type\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into train and test\nX_knn_train, X_knn_test, y_knn_train, y_knn_test = train_test_split(X_knn, y_knn, test_size=.30,stratify=y_knn, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Prediction with KNN Imputation - Imbalanced Data"},{"metadata":{},"cell_type":"markdown","source":"### 3.1.2. Logistic Regression: KNN Imputation - Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nknn_lm = LogisticRegression()\n\n# Fit the model\nknn_lm.fit(X_knn_train, y_knn_train.ravel())\n\n# Make Predictions\nknn_lm_pred = knn_lm.predict(X_knn_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nknn_lm_accuracy = accuracy_score(y_knn_test, knn_lm_pred)\nknn_lm_precision = precision_score(y_knn_test, knn_lm_pred)\nknn_lm_recall = recall_score(y_knn_test, knn_lm_pred)\nknn_lm_f1 = 2 * (knn_lm_precision * knn_lm_recall) / (knn_lm_precision + knn_lm_recall)\n\n# Calculate AUC score\nknn_lm_probs = knn_lm.predict_proba(X_knn_test)\nknn_lm_probs = knn_lm_probs[:,1]\nknn_lm_auc = roc_auc_score(y_knn_test, knn_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: KNN Imputation\")\nprint(\" - Accuracy : \",'{:.3f}'.format(knn_lm_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(knn_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(knn_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(knn_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_knn_test,knn_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.2. Random Forest: KNN Imputation - Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nknn_rf = RandomForestClassifier()\n\n# Fit the model\nknn_rf.fit(X_knn_train, y_knn_train.ravel())\n\n# Make Predictions\nknn_rf_pred = knn_rf.predict(X_knn_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nknn_rf_accuracy = accuracy_score(y_knn_test, knn_rf_pred)\nknn_rf_precision = precision_score(y_knn_test, knn_rf_pred)\nknn_rf_recall = recall_score(y_knn_test, knn_rf_pred)\nknn_rf_f1 = 2 * (knn_rf_precision * knn_rf_recall) / (knn_rf_precision + knn_rf_recall)\n\n# Calculate AUC score\nknn_rf_probs = knn_rf.predict_proba(X_knn_test)\nknn_rf_probs = knn_rf_probs[:,1]\nknn_rf_auc = roc_auc_score(y_knn_test, knn_rf_probs)\n\n# Display the metrics\nprint(\"Random Forest: KNN Imputation\")\nprint(\" - Accuracy : \",'{:.3f}'.format(knn_rf_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(knn_rf_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(knn_rf_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(knn_rf_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_knn_test,knn_rf_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.3. XGBoost: KNN Imputation - Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nknn_xgb = XGBClassifier()\n\n# Fit the model\nknn_xgb.fit(X_knn_train, y_knn_train.ravel())\n\n# Make Predictions\nknn_xgb_pred = knn_xgb.predict(X_knn_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nknn_xgb_accuracy = accuracy_score(y_knn_test, knn_xgb_pred)\nknn_xgb_precision = precision_score(y_knn_test, knn_xgb_pred)\nknn_xgb_recall = recall_score(y_knn_test, knn_xgb_pred)\nknn_xgb_f1 = 2 * (knn_xgb_precision * knn_xgb_recall) / (knn_xgb_precision + knn_xgb_recall)\n\n# Calculate AUC score\nknn_xgb_probs = knn_xgb.predict_proba(X_knn_test)\nknn_xgb_probs = knn_xgb_probs[:,1]\nknn_xgb_auc = roc_auc_score(y_knn_test, knn_xgb_probs)\n\n# Display the metrics\nprint(\"XGBoost: Imputation with Mode\")\nprint(\" - Accuracy : \",'{:.3f}'.format(knn_xgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(knn_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(knn_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(knn_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_knn_test,knn_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Prediction with KNN Imputation - SMOTE"},{"metadata":{},"cell_type":"markdown","source":"### Apply SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since this is an imbalanced data, apply SMOTE to the training set\nsmote=SMOTE()\nX_smote_knn_train, y_smote_knn_train = smote.fit_sample(X_knn_train,y_knn_train)\n\n# Check if SMOTE were properly applied\ny_smote_knn_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2.1. Logistic Regression: KNN Imputation - SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_knn_lm = LogisticRegression()\n\n# Fit the model\nsmote_knn_lm.fit(X_smote_knn_train, y_smote_knn_train.ravel())\n\n# Make Predictions\nsmote_knn_lm_pred = smote_knn_lm.predict(X_knn_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_knn_lm_accuracy = accuracy_score(y_knn_test, smote_knn_lm_pred)\nsmote_knn_lm_precision = precision_score(y_knn_test, smote_knn_lm_pred)\nsmote_knn_lm_recall = recall_score(y_knn_test, smote_knn_lm_pred)\nsmote_knn_lm_f1 = 2 * (smote_knn_lm_precision * smote_knn_lm_recall) / (smote_knn_lm_precision + smote_knn_lm_recall)\n\n# Calculate AUC score\nsmote_knn_lm_probs = smote_knn_lm.predict_proba(X_knn_test)\nsmote_knn_lm_probs = smote_knn_lm_probs[:,1]\nsmote_knn_lm_auc = roc_auc_score(y_knn_test, smote_knn_lm_probs)\n\n# Display the metrics\nprint(\"Logistic Regression: Imputation with KNN: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_knn_lm_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_knn_lm_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_knn_lm_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_knn_lm_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_knn_test,smote_knn_lm_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2. Random Forest: KNN Imputation - SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_knn_rf = RandomForestClassifier()\n\n# Fit the model\nsmote_knn_rf.fit(X_smote_knn_train, y_smote_knn_train.ravel())\n\n# Make Predictions\nsmote_knn_rf_pred = smote_knn_rf.predict(X_knn_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_knn_rf_accuracy = accuracy_score(y_knn_test, smote_knn_rf_pred)\nsmote_knn_rf_precision = precision_score(y_knn_test, smote_knn_rf_pred)\nsmote_knn_rf_recall = recall_score(y_knn_test, smote_knn_rf_pred)\nsmote_knn_rf_f1 = 2 * (smote_knn_rf_precision * smote_knn_rf_recall) / (smote_knn_rf_precision + smote_knn_rf_recall)\n\n# Calculate AUC score\nsmote_knn_rf_probs = smote_knn_rf.predict_proba(X_knn_test)\nsmote_knn_rf_probs = smote_knn_rf_probs[:,1]\nsmote_knn_rf_auc = roc_auc_score(y_knn_test, smote_knn_rf_probs)\n\n# Display the metrics\nprint(\"Random Forest: Imputation with Mode: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_knn_rf_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_knn_rf_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_knn_rf_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_knn_rf_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_knn_test,smote_knn_rf_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2.3. XGBoost: KNN Imputation - SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nsmote_knn_xgb = XGBClassifier()\n\n# Fit the model\nsmote_knn_xgb.fit(X_smote_knn_train, y_smote_knn_train.ravel())\n\n# Make Predictions\nsmote_knn_xgb_pred = smote_knn_xgb.predict(X_knn_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nsmote_knn_xgb_accuracy = accuracy_score(y_knn_test, smote_knn_xgb_pred)\nsmote_knn_xgb_precision = precision_score(y_knn_test, smote_knn_xgb_pred)\nsmote_knn_xgb_recall = recall_score(y_knn_test, smote_knn_xgb_pred)\nsmote_knn_xgb_f1 = 2 * (smote_knn_xgb_precision * smote_knn_xgb_recall) / (smote_knn_xgb_precision + smote_knn_xgb_recall)\n\n# Calculate AUC score\nsmote_knn_xgb_probs = smote_knn_xgb.predict_proba(X_knn_test)\nsmote_knn_xgb_probs = smote_knn_xgb_probs[:,1]\nsmote_knn_xgb_auc = roc_auc_score(y_knn_test, smote_knn_xgb_probs)\n\n# Display the metrics\nprint(\"XGBoost: Imputation with Mode: SMOTE\")\nprint(\" - Accuracy : \",'{:.3f}'.format(smote_knn_xgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(smote_knn_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(smote_knn_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(smote_knn_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_knn_test,smote_knn_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data without Dropping and Imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate the dataset into features and target\nX = df_train.drop(['enrollee_id','city','target'],axis=1)\ny = df_train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummies for nominal variables\n# Set dummy_na=True to include NaN as a dummy variable \nX = pd.concat([X,pd.get_dummies(X[\"gender\"], prefix=\"gender\", dummy_na=True)], \n                   axis=1).drop(columns=[\"gender\"])\nX = pd.concat([X,pd.get_dummies(X[\"enrolled_university\"], prefix=\"enrolled_university\",  dummy_na=True)],\n                   axis=1).drop(columns=[\"enrolled_university\"])\nX = pd.concat([X,pd.get_dummies(X[\"major_discipline\"], prefix=\"major_discipline\",  dummy_na=True)], \n                   axis=1).drop(columns=[\"major_discipline\"])\nX = pd.concat([X,pd.get_dummies(X[\"company_type\"], prefix=\"company_type\",  dummy_na=True)], \n                   axis=1).drop(columns=[\"company_type\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30,stratify=y, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Prediction with Data without Imputation  - Imbalanced Data"},{"metadata":{},"cell_type":"markdown","source":"### 4.1.1. XGBoost Classifier with Data without Imputation: Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_xgb = XGBClassifier()\n# Fit the model\nbase_xgb_model = base_xgb.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_xgb_pred=base_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_xgb_accuracy = accuracy_score(y_test, base_xgb_pred)\nbase_xgb_precision = precision_score(y_test, base_xgb_pred)\nbase_xgb_recall = recall_score(y_test, base_xgb_pred)\nbase_xgb_f1 = 2 * (base_xgb_precision * base_xgb_recall) / (base_xgb_precision + base_xgb_recall)\n\n# Calculate AUC score\nbase_xgb_probs = base_xgb.predict_proba(X_test)\nbase_xgb_probs = base_xgb_probs[:,1]\nbase_xgb_auc = roc_auc_score(y_test, base_xgb_probs)\n\n# Display the metrics\nprint(\"XGBClassifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_xgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(base_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.1.2. LightGBM Classifier with Data without Imputation: Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import LightGBM\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbase_lgb = lgb.LGBMClassifier()\n# Fit the model\nbase_lgb_model = base_lgb.fit(X_train, y_train.ravel())\n# Make Predictions\nbase_lgb_pred=base_lgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbase_lgb_accuracy = accuracy_score(y_test, base_lgb_pred)\nbase_lgb_precision = precision_score(y_test, base_lgb_pred)\nbase_lgb_recall = recall_score(y_test, base_lgb_pred)\nbase_lgb_f1 = 2 * (base_lgb_precision * base_lgb_recall) / (base_lgb_precision + base_lgb_recall)\n\n# Calculate AUC score\nbase_lgb_probs = base_lgb.predict_proba(X_test)\nbase_lgb_probs = base_lgb_probs[:,1]\nbase_lgb_auc = roc_auc_score(y_test, base_lgb_probs)\n\n# Display the metrics\nprint(\"LightGBM Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(base_lgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(base_lgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(base_lgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(base_lgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,base_lgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2. Prediction with Data without Imputation - Class Weighted"},{"metadata":{},"cell_type":"markdown","source":"The dataset is imbalanced. So rebalance the data using scale_pos_weight."},{"metadata":{},"cell_type":"markdown","source":"### Rebalance Data by Weighting Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the target\ny.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# T - no. of total samples\n# P - no. of positive samples\n# scale_pos_weight = percent of negative / percent of positive\n# which translates to:\n# scale_pos_weight = (100*(T-P)/T) / (100*P/T)\n# which further simplifies to beautiful:\n# scale_pos_weight = T/P - 1\nT = 14381 + 4777\nP = 4777\nscale_pos_weight = T/P - 1\nscale_pos_weight","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2.1. XGB Classifier with Data without Imputation: Weighted"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nweighted_xgb = XGBClassifier(scale_pos_weight=scale_pos_weight)\n# Fit the model\nweighted_xgb_model = weighted_xgb.fit(X_train, y_train.ravel())\n# Make Predictions\nweighted_xgb_pred=weighted_xgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nweighted_xgb_accuracy = accuracy_score(y_test, weighted_xgb_pred)\nweighted_xgb_precision = precision_score(y_test, weighted_xgb_pred)\nweighted_xgb_recall = recall_score(y_test, weighted_xgb_pred)\nweighted_xgb_f1 = 2 * (weighted_xgb_precision * weighted_xgb_recall) / (weighted_xgb_precision + weighted_xgb_recall)\n\n# Calculate AUC score\nweighted_xgb_probs = weighted_xgb.predict_proba(X_test)\nweighted_xgb_probs = weighted_xgb_probs[:,1]\nweighted_xgb_auc = roc_auc_score(y_test, weighted_xgb_probs)\n\n# Display the metrics\nprint(\"XGBClassifier: Weighted\")\nprint(\" - Accuracy : \",'{:.3f}'.format(weighted_xgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(weighted_xgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(weighted_xgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(weighted_xgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,weighted_xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2.2. LightGBM Classifier with Data without Imputation: Weighted"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nweighted_lgb = lgb.LGBMClassifier(scale_pos_weight=scale_pos_weight)\n# Fit the model\nweighted_lgb_model = weighted_lgb.fit(X_train, y_train.ravel())\n# Make Predictions\nweighted_lgb_pred=weighted_lgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nweighted_lgb_accuracy = accuracy_score(y_test, weighted_lgb_pred)\nweighted_lgb_precision = precision_score(y_test, weighted_lgb_pred)\nweighted_lgb_recall = recall_score(y_test, weighted_lgb_pred)\nweighted_lgb_f1 = 2 * (weighted_lgb_precision * weighted_lgb_recall) / (weighted_lgb_precision + weighted_lgb_recall)\n\n# Calculate AUC score\nweighted_lgb_probs = weighted_lgb.predict_proba(X_test)\nweighted_lgb_probs = weighted_lgb_probs[:,1]\nweighted_lgb_auc = roc_auc_score(y_test, weighted_lgb_probs)\n\n# Display the metrics\nprint(\"LightGBM Classifier: Weighted\")\nprint(\" - Accuracy : \",'{:.3f}'.format(weighted_lgb_accuracy))\nprint(\" - Recall   : \",'{:.3f}'.format(weighted_lgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(weighted_lgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(weighted_lgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,weighted_lgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- LightGBClassifier with scale pos weight achieved the highest performance.\n- So let's tune parameters of this model."},{"metadata":{},"cell_type":"markdown","source":"## 5. Summary of Results"},{"metadata":{},"cell_type":"markdown","source":"Let's summarize the results:\n  - For data: 1) Mode imputation, 2) KNN imputation, 3) Without imputation\n  - For P/N balance: SMOTE rebalanced or Positive weighted\n  - For algorithm: Logistic regression, Random forest, XGBoost, LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarize results with Tables \npd.options.display.float_format = '{:.3f}'.format\n\npf_list = [\n    [smote_imp_lm_recall, smote_imp_lm_f1, smote_imp_lm_auc],\n    [smote_imp_rf_recall, smote_imp_rf_f1, smote_imp_rf_auc],\n    [smote_imp_xgb_recall, smote_imp_xgb_f1, smote_imp_xgb_auc],\n    [smote_knn_lm_recall, smote_knn_lm_f1, smote_knn_lm_auc],\n    [smote_knn_rf_recall, smote_knn_rf_f1, smote_knn_rf_auc],\n    [smote_knn_xgb_recall, smote_knn_xgb_f1, smote_knn_xgb_auc],\n    [weighted_xgb_recall, weighted_xgb_f1, weighted_xgb_auc],\n    [weighted_lgb_recall, weighted_lgb_f1, weighted_lgb_auc]]\n\npf_df = pd.DataFrame(pf_list)\npf_df.index = ['Logistic: Mode Imputation','Random Forest: Mode Imputation','XGBoost: Mode Imputation',\n               'Logistic: KNN Imputation','Random Forest: KNN Imputation','XGBoost: KNN Imputation',\n              'XGBoost: No Imputation', 'LightGBM: No Imputation']\npf_df.columns = ['Recall', 'F1','AUC']\n\npf_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Weighted LightGBM without imputation achieve the best performance.\n- So let's tune its hyperparameter to maximize AUC."},{"metadata":{},"cell_type":"markdown","source":"## 6. Gridsearch for LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Set parameters\nparameters = [{\n    'learning_rate':[0.01, 0.1,0.2],\n    'n_estimators':[10, 20,30,40],\n    'max_depth':[3,5,7,9,10],\n    'verbose':[-1],\n    'min_data_in_leaf':[30,40,50,60,70],\n    'num_leaves':[10, 20, 30]\n}]\n\n# Grid Search: Maximize AUC score\nclassifier = GridSearchCV(lgb.LGBMClassifier(scale_pos_weight=scale_pos_weight), parameters, scoring='roc_auc', cv=3, n_jobs=-1)\nclassifier.fit(X_train, y_train)\nprint(\"Accuracy score (train): \", classifier.score(X_train, y_train))\nprint(\"Accuracy score (test): \", classifier.score(X_test, y_test))\nprint(classifier.best_estimator_) # Best parameter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate the model\nbest_lgb = lgb.LGBMClassifier(learning_rate=0.2, max_depth=7, min_data_in_leaf=30, n_estimators=40, num_leaves=10,verbose=-1,\n                              scale_pos_weight=scale_pos_weight)\n# Fit the model\nbest_lgb_model = best_lgb.fit(X_train, y_train.ravel())\n# Make Predictions\nbest_lgb_pred=best_lgb_model.predict(X_test)\n\n# Calculate Accuracy, Precision, Recall, and F1 score\nbest_lgb_accuracy = accuracy_score(y_test, best_lgb_pred)\nbest_lgb_precision = precision_score(y_test, best_lgb_pred)\nbest_lgb_recall = recall_score(y_test, best_lgb_pred)\nbest_lgb_f1 = 2 * (best_lgb_precision * best_lgb_recall) / (best_lgb_precision + best_lgb_recall)\n\n# Calculate AUC score\nbest_lgb_probs = best_lgb.predict_proba(X_test)\nbest_lgb_probs = best_lgb_probs[:,1]\nbest_lgb_auc = roc_auc_score(y_test, best_lgb_probs)\n\n# Display the metrics\nprint(\"LightGBM Classifier: Imbalanced Data\")\nprint(\" - Accuracy : \",'{:.3f}'.format(best_lgb_accuracy))\nprint(\" - Precision: \",'{:.3f}'.format(best_lgb_precision))\nprint(\" - Recall   : \",'{:.3f}'.format(best_lgb_recall))\nprint(\" - F1 score : \",'{:.3f}'.format(best_lgb_f1))\nprint(\" - AUC score: \",'{:.3f}'.format(best_lgb_auc))\n\n# Display the confusion matrix\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,best_lgb_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The AUC score slightly improved."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}