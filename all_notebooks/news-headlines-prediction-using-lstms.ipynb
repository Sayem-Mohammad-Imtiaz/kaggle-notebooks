{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nnp.random.seed(0)\nplt.style.use(\"ggplot\")\n\nimport tensorflow as tf\nprint('Tensorflow version:', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"BOwsuGQQY9OL","trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\n\nimport tensorflow.keras.utils as ku \nimport numpy as np ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/news-summary/news_summary_more.csv\")\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['headlines'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"headlines=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df['headlines']:\n    headlines.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# headlines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(headlines)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# As the dataset is very large we will take only first 500 headlines..","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Tokenizing the Text-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer=Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(headlines[:500])\ntotal_words=len(tokenizer.word_index)+1\ntotal_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# headlines[:500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(headlines)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for l in headlines[:5000]:\n     token = tokenizer.texts_to_sequences([l])[0]\n#      print(token)\n     for i in range(1,len(token)):\n       ngrams_seq=token[:i+1]\n       sequences.append(ngrams_seq)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# So we had know converted the texts to sequences..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sequences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxl=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in sequences:\n    k=len(i)\n    if k>maxl:\n        maxl=k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# So the maximum length among the sequrnces is 16,so this will be our max-padding..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pad_sequences(sequences, maxlen=maxl)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SPLITTING PREDICTORS AND LABELS-->\nTaking the last word of every sequence as target variable and rest all as the independent variables..So that our neural network will learn accordingly.. So in labels we will be selecting the last column..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors=data[:,:-1]\npredictors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Selecting the Last Column-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=data[:,-1]\nlabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=ku.to_categorical(labels,num_classes=total_words)\nlabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(input_dim=total_words,output_dim=80,input_length=15))#input length is 15 not 16 as we have taken the last column for labels for 16-1=15\nmodel.add(Dropout(0.2))\nmodel.add(Bidirectional(LSTM(units=150,return_sequences=False)))#if return sequences is false,then it will return a 2-D array,if true then it will return a 3-D array..\nmodel.add(Dense(total_words,activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(predictors, labels, epochs=100, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy reached to 80%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['accuracy']\n\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.title('Training accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training accuracy')\nplt.title('Training accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"output_word = \"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_text = \"President Donald Trump\"\nnext_words = 5\n\nfor num in range(next_words):\n\ttoken = tokenizer.texts_to_sequences([test_text])\n\tnew_pad = pad_sequences(token, maxlen=15)\n\tpredicted = model.predict_classes(new_pad, verbose=0)\n\t\n\tfor word, index in tokenizer.word_index.items():\n\t\tif index == predicted:\n\t\t\toutput_word = word\n\t\t\tbreak\n\ttest_text += \" \" + output_word","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_text = \"India and China\"\nnext_words = 5\n\nfor num in range(next_words):\n\ttoken = tokenizer.texts_to_sequences([test_text])\n\tnew_pad = pad_sequences(token, maxlen=15)\n\tpredicted = model.predict_classes(new_pad, verbose=0)\n\t\n\tfor word, index in tokenizer.word_index.items():\n\t\tif index == predicted:\n\t\t\toutput_word = word\n\t\t\tbreak\n\ttest_text += \" \" + output_word","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_text = \"BCCI\"\nnext_words = 5\n\nfor num in range(next_words):\n\ttoken = tokenizer.texts_to_sequences([test_text])\n\tnew_pad = pad_sequences(token, maxlen=15)\n\tpredicted = model.predict_classes(new_pad, verbose=0)\n\t\n\tfor word, index in tokenizer.word_index.items():\n\t\tif index == predicted:\n\t\t\toutput_word = word\n\t\t\tbreak\n\ttest_text += \" \" + output_word","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We can see, the model has produced the output which looks fairly fine..","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# We can further tune the parameters to increase the model performance..","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}