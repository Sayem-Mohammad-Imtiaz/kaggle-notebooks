{"cells":[{"metadata":{"trusted":true,"_uuid":"e642ffdef445a7f9ac7100161f128d02b8715a35","scrolled":true},"cell_type":"code","source":"import numpy\nimport gzip\n# Params for MNIST\nIMAGE_SIZE = 28\nNUM_CHANNELS = 1\nPIXEL_DEPTH = 255\nNUM_LABELS = 10\n# Extract the images\ndef extract_data(filename, num_images):\n    \"\"\"\"\"\n    Extract the images into a 4D tensor [image index, y, x, channels].\n    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n    \"\"\"\n    print('Extracting', filename)\n    with gzip.open(filename) as bytestream:\n        bytestream.read(16)\n        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n    return data\ndef extract_labels(filename, num_images):\n    #Extract the labels into a vector of int64 label IDs.\n    print('Extracting', filename)\n    with gzip.open(filename) as bytestream:\n        bytestream.read(8)\n        buf = bytestream.read(1 * num_images)\n        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n        num_labels_data = len(labels)\n        one_hot_encoding = numpy.zeros((num_labels_data,NUM_LABELS))\n        one_hot_encoding[numpy.arange(num_labels_data),labels] = 1\n        one_hot_encoding = numpy.reshape(one_hot_encoding, [-1, NUM_LABELS])\n    return one_hot_encoding\ntrain_data = extract_data('../input/train-images-idx3-ubyte.gz', 40000)\ntrain_labels = extract_labels('../input/train-labels-idx1-ubyte.gz', 40000)\nx_test = extract_data('../input/t10k-images-idx3-ubyte.gz', 1000)\ny_test = extract_labels('../input/t10k-labels-idx1-ubyte.gz', 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c60ed0d7fa53eaffae1be79496a4644d3594bbb1"},"cell_type":"code","source":"print(train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2acddf3c90f8183310d141213617f868a6d84854","scrolled":false},"cell_type":"code","source":"from tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom keras import models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79104fd8bcaa20281ffb9b75b6c94860b3ae7999"},"cell_type":"code","source":"x_train,  x_val, y_train, y_val  = train_test_split(train_data, train_labels, test_size = 0.2)\nn_train = len(y_train)\nn_val = len(y_val)\n#set hyperparamters\ninput_dim = 28\nbatch_size = 50\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7e64119895c1a3c74633737d4b68f4c995ee2ac","scrolled":false},"cell_type":"code","source":"#IP => [CONV => RELU => BN => POOL]*2 =>[FC => RELU => BN => DO]*2 =>OP\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(16, (3,3), input_shape = (input_dim, input_dim,1)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size = (2, 2)))\n\nmodel.add(layers.Conv2D(32, (3,3)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size = (2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(20))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(10))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(10))\nmodel.add(layers.Activation(\"softmax\"))\n\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer = 'Adam',\n              metrics = ['accuracy'])\nmodel.summary()\n\n\"\"\"\ntrain_datagen = ImageDataGenerator(\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\"\"\"\nhistory = model.fit(\n    x_train, y_train, \n    steps_per_epoch = n_train // batch_size,\n    epochs = 50,\n    validation_data = (x_val, y_val),\n    validation_steps= n_val // batch_size\n)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# 绘制训练 & 验证的准确率值\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()\n# 绘制训练 & 验证的损失值\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()\n\nmodel.save_weights('model_wieghts.h5')\nmodel.save('model_keras.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f26b697066b3b66469c12290b39b7f276a6a6cd6"},"cell_type":"code","source":"y_pred = model.predict(x_test,verbose=1)\ncorrect_prediction = np.equal(np.argmax(y_pred, 1), np.argmax(y_test, 1))\naccuracy = correct_prediction.sum()/y_test.shape[0]\nprint(\"Accuracy on test set :{:.2%}\".format(accuracy))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}