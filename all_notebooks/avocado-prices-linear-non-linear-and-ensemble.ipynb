{"cells":[{"metadata":{},"cell_type":"markdown","source":"# End-to-End Regression Project for the Avocado dataset\nThe objective of this project is to predict the per-unit price of avocado using the dataset available on [Kaggle](https://www.kaggle.com/neuromusic/avocado-prices) or on [Github](data/avocado.csv). Note that the structure of the steps **Evaluate Algorithms** and **Improve the chosen model** is inspired from [this ebook written by Jason Brownlee](https://machinelearningmastery.com/machine-learning-with-python/). \n\n## Problem preparation\nFirstly, the avocado dataset is imported as well as the needed libraries to carry out the project.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## load libraries\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import KFold, cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (20,10)\n\n## load dataset\nurl = '../input/avocado-prices/avocado.csv'\ndf = pd.read_csv(url, delimiter=',')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summarize data\nThen, we explore the imported dataset through descriptive statistics and data visualization.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive statistics\n## Dimensions\nprint(\"Dataset {0} loaded with {1} rows and {2} columns \\n\".format('avocado', df.shape[0], df.shape[1]))\n\n## Indentification NaN\nisNan = df.isnull().values.any()\nprint(\"Dataset containing NaN values: {0} \\n\".format(isNan))\n\n## Identification duplicates\nisDuplicate = df.duplicated(subset=['Date','year', 'region', 'type']).any() \nprint(\"Dataset containing duplicate values: {0} \\n\".format(isDuplicate))\n\n## Attributes datatype\nprint(\"Dataset column initial datatype: \\n {0} \\n\".format(df.dtypes))\nlist_index_col_type_object = df.select_dtypes('object').columns\n\n## Statistical summary (numerical attribute)\nprint(\"Dataset numerical attributes statistical distribution: \\n {0} \\n\".format(df.describe()))\n\n## Classes distribution (categorical attributes)\nprint(\"Dataset categorical attributes distribution: \\n {0} {1} \\n\".format(df.groupby('region').size(), df.groupby('type').size()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" A first glance to the dataset indicates us that we have different type of attributes:\n * numerical: *Unnamed 0*, *AveragePrice*, *Total Volume*, *4046*, *4225*, *4770*, *Total Bags*, *Small Bags*, *Large Bags*, *XLarge Bags* and *year*\n * categorical: *type* and *region*\n * date format: *Date*\n\nWithin the numerical attributes, *Unnamed 0* refers to the number of measurements for one region at a given year. Also, this attribute does not carry information about the avocado price and could be removed later one. We notice that the numerical attributes have different scales (e.g. *XLarge Bags* and *4046*) which indicates that a normalization can be useful. Some outliers seem to be present in nearly all attributes except the *AveragePrice*. For the categorical attributes, we notice that the class distributions are balanced for both *type* and *region*. Concerning the *Date* attribute, its information is partially present in the attribute *year* and could be divided later on in month and day attributes. Finally, we notice that the dataset does not present any *NaN* values or duplicate rows. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data visualization\n## Univariate plots\ndf.plot(kind='density', subplots=True, layout=(4,4), sharex=False)\ndf.plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" The density plots indicate us the repartition of the data according to their value and in particular:\n * *AveragePrice* variable may follow a normal or bimodal distribution\n * *Total Volume*, *4046*, *4225* and *4770* have a concentrate distribution which may require a transformation\n * *Total Bags*, *Small Bags*, *Large Bags* and *Xlarge Bags* may as well require transformation\n * *type* is balanced meaning that we have as much *conventional* than *organic* instances in our datasets\n * *year* is balanced for *2015*, *2016* and *2017* but we have four times less instances for *2018*. We will have to take this into account when we will split our dataset for training and testing\n * *region* is balanced meaning that we have an equal representation of the different regions in the dataset\n\nThe box plot show us as well the density of the data with its quartiles. This underlines the possible outliers. Also, we remark:\n * *AveragePrice* have a significant number of outliers which indicate the need to remove them of the possible bimodal distribution many outliers requiring removal and/or transformation\n * *Total Bags*, *Small Bags*, *Large Bags* and *Xlarge Bags* have many outliers requiring removal and/or transformation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Multivariate plot\nsns.heatmap(df.corr(), cmap='viridis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If two attributes are correlated, we want to remove one of them (preferably the one with the less correlation to other variables). Indeed, removing correlated variables allow to generally to speed up the learning process of the algorithm, to decrease bias and to increase interpretability of the model.\n\nIn the figure above the lighter is the square relating two variables the higher is the correlation between those two attributes. We notice the following relationships:\n * *Small Bags* and *Total Bags* are highly correlated indicating that selecting only one of those variables will not remove information from the model\n * *Total Volume* and *4046*/*4225* present a significative correlation which could lead to remove the *Total Volume* variable\n * *Total Bags* and *Total Volume* present a significative correlation which could lead to remove one of them as they are equivalent in terms of correlation to other attributes (if they are not already removed based on the previous remarks)\n\nThe feature selection will be performed in the following selection integrating labeled categorical data and new features such as *day* and *month*.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Cleaning\n## Remove attribute Unnamed: 0\ndf = df.drop(['Unnamed: 0'], axis=1)\n\n## Label categorical data\ndef convert_string_into_numeric(dataframe, columns):\n    lookup = dict()\n    for column in columns:\n        index_column = df.columns.get_loc(column)\n        string_values = dataframe.iloc[:,index_column].unique()\n        lookup_column = dict()\n        for i, string_value in enumerate(string_values):\n            lookup_column[string_value] = i\n            index_string_values = np.where(dataframe.iloc[:,index_column] == string_value)[0]\n            dataframe.iloc[index_string_values,index_column] = i\n        lookup[column] = lookup_column\n    return lookup\n\nlookup = convert_string_into_numeric(df, ['type', 'region'])\n\n# Feature Selection\n## Add attributes from date and remove this column\ndf['month'] = pd.to_datetime(df[\"Date\"]).dt.month\ndf['day'] = pd.to_datetime(df[\"Date\"]).dt.day\ndel df['Date']\n\n## Uniformize datatype\ndf = df.apply(pd.to_numeric, downcast='float')\n\n## Apply feature selection\nX = df.drop(['AveragePrice'], 1)\ny = df['AveragePrice']\nselector = SelectKBest(f_regression, k=11).fit(X,y)\nselected_columns = selector.get_support(indices=True)\nX = X.iloc[:,selected_columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this preparation steps, we have removed the uninformative attribute *Unnamed: 0* and transform the *Date* attribute into *month* and *day*. After labelling the categorical columns *type* and *region*, we homogenized the datatype of the columns to float. Then, we selected 11 attributes among the 13 ones. Indeed, the attributes *regions* and *daye* had significative low F-score and have been removed. Finally, we normalize the remaining attributes to prepare the model selection.\n\n## Evaluate Algorithms\n\nHere, we split our data to get a training and validation datasets. Then, we set up an evaluation workflow for machine learning algorithms to compare their performance. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split dataset\nX_train, X_validation, y_train, y_validation = train_test_split(X, y.values, test_size=0.33, random_state=42, shuffle=True)\n\n# Check algorithms\n## Testing options\nnumber_folds = 5\nseed = 42\nscoring = 'neg_mean_squared_error'\n\n## Define testing workflow and select model\nmodels = []\nmodels.append((\"ScaledLR\", Pipeline([('Scaler', MinMaxScaler()), ('LR', LinearRegression())])))\nmodels.append((\"ScaledRIDGE\", Pipeline([('Scaler', MinMaxScaler()), ('RIDGE', Ridge())])))\nmodels.append((\"ScaledLASSO\", Pipeline([('Scaler', MinMaxScaler()), ('LASSO', Lasso())])))\nmodels.append((\"ScaledEN\", Pipeline([('Scaler', MinMaxScaler()), ('EN', ElasticNet())])))\nmodels.append((\"ScaledSVR\", Pipeline([('Scaler', MinMaxScaler()), ('SVR', SVR())])))\nmodels.append((\"ScaledKNN\", Pipeline([('Scaler', MinMaxScaler()), ('KNN', KNeighborsRegressor())])))\nmodels.append((\"ScaledCART\", Pipeline([('Scaler', MinMaxScaler()), ('CART', DecisionTreeRegressor())])))\nmodels.append((\"ScaledNN\", Pipeline([('Scaler', MinMaxScaler()), ('NN', MLPRegressor(random_state=1, max_iter=500))])))\n\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits = number_folds, random_state = seed, shuffle=True)\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print(\"{0}: {1} ({2})\".format(name, cv_results.mean(), cv_results.std()))\n\n# Distribution performance\nfig, ax = plt.subplots()\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the previous boxplot, we deduce that KNN is the algorithm with the best performance. Also, we are now going to tune it using the validation dataset and to consider ensemble methods.\n\n## Improve the chosen model\n\nWe first tune the parameters of the KNN algorithm to determine the best parameters set improving the performance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model tuning \n## Normalize\nscaler = MinMaxScaler().fit(X_train)\nX_normalized = scaler.transform(X_train)\n\n## Select tuning grid parameters\nn_neighbors_parameter = np.array([1,2,3,5,7,8,10,15,20])\np_parameter = np.array([1,2])\nweights_parameter = np.array(['uniform', 'distance'])\ngrid_parameters = dict(n_neighbors=n_neighbors_parameter,p=p_parameter, weights=weights_parameter)\n\n## Apply on the model\nmodel = KNeighborsRegressor()\nkfold = KFold(n_splits = number_folds, random_state = seed, shuffle=True)\ngrid = GridSearchCV(estimator=model, param_grid=grid_parameters, scoring=scoring, cv=kfold)\ngrid_results = grid.fit(X_normalized, y_train)\nprint(\"Best score {0} obtain with {1}\".format(grid_results.best_score_, grid_results.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With what preceded, we know that the optimal model for the avocado prediction is a KNN with *k=1*, weighted by distance and using the Manhattan distance (*p=1*). Finally, we explore possible ensemble methods to predict the avocado prices.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ensemble methods\nensembles = []\nensembles.append((\"ScaledRFR\", Pipeline([('Scaler', MinMaxScaler()), ('RFR', RandomForestRegressor())])))\nensembles.append((\"ScaledABR\", Pipeline([('Scaler', MinMaxScaler()), ('ABR', AdaBoostRegressor())])))\nensembles.append((\"ScaledGBR\", Pipeline([('Scaler', MinMaxScaler()), ('GBR', GradientBoostingRegressor())])))\nensembles.append((\"ScaledETR\", Pipeline([('Scaler', MinMaxScaler()), ('ETR', ExtraTreesRegressor())])))\n\nresults = []\nnames = []\nfor name, ensemble in ensembles:\n    kfold = KFold(n_splits = number_folds, random_state = seed, shuffle=True)\n    cv_results = cross_val_score(ensemble, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print(\"{0}: {1} ({2})\".format(name, cv_results.mean(), cv_results.std()))\n\n# Distribution performance\nfig, ax = plt.subplots()\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The extra-trees regressor presents better results than the KNN model. Also, we will tune it to use it as the selected model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tuning emsemble method\n## Normalize\nscaler = MinMaxScaler().fit(X_train)\nX_normalized = scaler.transform(X_train)\n\n## Select tuning grid parameters\nn_estimators_parameter = np.array([100, 200, 300])\ngrid_parameters = dict(n_estimators=n_estimators_parameter)\n\n## Apply on the model\nensemble = ExtraTreesRegressor()\nkfold = KFold(n_splits = number_folds, random_state = seed, shuffle=True)\ngrid = GridSearchCV(estimator=ensemble, param_grid=grid_parameters, scoring=scoring, cv=kfold)\ngrid_results = grid.fit(X_normalized, y_train)\nprint(\"Best score {0} obtain with {1}\".format(grid_results.best_score_, grid_results.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, the model used for the prediction will be the extra-trees regressor with 300 estimators. The last step is to evaluate it on the validation dataset.\n\n## Evaluate the final model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit optimal model\nscaler = MinMaxScaler().fit(X_train)\nX_normalized = scaler.transform(X_train)\nmodel = ExtraTreesRegressor(n_estimators=200)\nmodel.fit(X_normalized, y_train)\n\n# evaluate performance on validation dataset\nX_validation_normalized = scaler.transform(X_validation)\ny_prediction = model.predict(X_validation_normalized)\nprint(\"RMSE model: {0}\".format(mean_squared_error(y_validation, y_prediction)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If needed save the model\n#from pickle import dump\n#from pickle import load\n# save\n#filename = 'model.sav'\n#dump(model, open(filename, 'wb'))\n# load\n#load_model = load(open(filename, 'rb'))\n#X_validation_normalized = scaler.transform(X_validation)\n#y_prediction = load_model.predict(X_validation_normalized)\n#print(mean_squared_error(y_validation, y_prediction))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}