{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Cyclistic: Bike-Share Case Study**\n\n## **Overview:**\nThis case study is provided by [Google Data Analytics Professional Certificate](https://www.coursera.org/professional-certificates/google-data-analytics) on [Coursera](https://www.coursera.org/).Cyclistic is a fictional bike-share company founded in 2016. Cyclistic users are more lilely to ride for leisure, while about 30% users use this bike-share to commute. Because annual members are more profitable, the goal is to *convert casual users into annual memberships*.<br/> \nThe historical trip data used in this case study is provided by Motivate International Inc. under [license](https://www.divvybikes.com/data-license-agreement)  \n\n","metadata":{}},{"cell_type":"markdown","source":"## **Ask:**\n\n#### Business Task:\nAnalyze and discover the difference between casual users and annual members for bike-share. \n#### Key Stakeholders:\nLily Moreno: director of marketing  \nMarketing analytics team  \nExecutive team  \n\n","metadata":{}},{"cell_type":"markdown","source":"## **Prepare:**  \n**Download, Storage, and Security:**  \nThe original historical data is downloaded to the local computer in zip format.\nThe dataset is extracted localy and will be uploaded to Kaggle, BigQuery,and Tableau after filtering and sorting. \nAll the data is public and does not include personal information.      \n**Description of data:**  \n* previous 12 months of data is downloaded, which are Jun 2020 - May 2021.\n* trip data: there are 15 columns for each table\n| Field Name | Type | Desciption |\n|-------- |-----|-----|\n|ride_id | String | Id for each ride |\n|rideable_type | String | bike type |\n| started_at | Timestamp | start time|\n| ended_at | Timestamp | end time|\n| start_station_name| String |  |\n| start_station_id | Int | |\n| end_station_name | String | |\n| end_station_id | Int | |\n| start_lat | Float| start latitude|\n| start_lng | Float | start longitude |\n| end_lat | Float | end latitude|\n| end_lng | Float | end longtitude |\n| member_casual | String | identify if member|  \n\n**Organization of data:**   \n\n* All dataset are organized as csv files\n* The naming of every file is converted to Snake_Case in format:'divvy_trips_yyyymm'  \n\n**Credibility of data:**  \nThe data came from first-party data of [Divvy bike-share](www.divvybikes.com), so it is considered as credible data.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## **Process:**  \nIn this case study, I choose to use Google BigQuery with postgreSQL to process the data. \n\n**Check data for errors:**  \n >To make sure every table's integrity, I checked the tables repetitivly before merging.\n1. Check for duplicates: Check for numbers of same Id presented in the table. If the query returns no result, there is no duplicate row. The following is a sample code on data of May 2020. *All schemas contain no deuplicate.*\n```SQL\nSELECT ride_id, COUNT(*)\nFROM `cyclisticcasestudy.tripData.2020_06` \nGROUP BY ride_id\nHAVING COUNT(*) >1\n```\n2. Check integrity of member/casual inputs: member_casual field should only contain NULL, member, or casual value, indicating the rider's status. If the query returns no result, there is no invalid input in member_casual field. The following is a sample code on data of May 2020. *All schemas contain no invalid input in member_casual.*   \n```SQL\nSELECT ride_id, member_casual\nFROM `cyclisticcasestudy.tripData.2020_06` \nWHERE member_casual <> 'casual'\nAND member_casual <> 'member'\nAND member_casual IS NOT NULL;\n```\n3. Check integrity of ridable_type inputs: similar to member/casual, ridable_type should only include three types' names or NULL. *There are three ridable types: docked_bike, eletric_bike, classic_bike*\n```SQL\nSELECT ride_id, ridable_type\nFROM `cyclisticcasestudy.tripData.2020_06` \nWHERE ridable_type <> 'docked_bike'\nAND ridable_type <> 'eletric_bike'\nAND ridable_type <> 'classic_bike'\nAND ridable_type IS NOT NULL;\n```\n4. Check errors on start time and end time: end time are suppose to be later than start time. Therefore, error data containing start time later than end time will be deleted from the table:\n```SQL\nDELET FROM `cyclisticcasestudy.tripData.2020_06`\nWHERE started_at>ended_at\n```\nlog:\nThis statement removed 469 rows from cyclisticcasestudy:tripData.2020_06.\nThis statement removed 1,745 rows from cyclisticcasestudy:tripData.2020_07.\nThis statement removed 2,769 rows from cyclisticcasestudy:tripData.2020_08.\nThis statement removed 2,132 rows from cyclisticcasestudy:tripData.2020_09.\nThis statement removed 1,911 rows from cyclisticcasestudy:tripData.2020_10.\nThis statement removed 865 rows from cyclisticcasestudy:tripData.2020_11.\nThis statement removed 434 rows from cyclisticcasestudy:tripData.2020_12.\nThis statement removed 2 rows from cyclisticcasestudy:tripData.2021_01.\nThis statement removed 0 rows from cyclisticcasestudy:tripData.2021_02.\nThis statement removed 2 rows from cyclisticcasestudy:tripData.2021_03.\nThis statement removed 5 rows from cyclisticcasestudy:tripData.2021_04.\nThis statement removed 2 rows from cyclisticcasestudy:tripData.2021_05.\n**Data integrity:**  \nAfter checking for errors, I confirm that there is no significant wrong data. Table of 12 months includes 4073561 rows of data, having enough number of sample size for analysis.  \n\n**Merge all information and transform data:**  \nTo make analysis efficient, the data in timestamp is seperated to month, week of day, hour, and duration of riding. \nUsing union all to merge all 12 month tables to one big table:  \n```SQL\nSELECT ride_id,rideable_type,EXTRACT(DAYOFWEEK from started_at) AS ride_day,\n EXTRACT(HOUR from started_at) AS start_time, \n EXTRACT(MONTH from started_at) AS start_month,DATETIME_DIFF(ended_at,started_at,MINUTE) AS duration,\n start_station_name,start_lat,start_lng, end_station_name,end_lat, end_lng\nFROM `cyclisticcasestudy.tripData.2020_06` \nUNION ALL\n SELECT  ride_id,rideable_type,EXTRACT(DAYOFWEEK from started_at) AS ride_day,\n EXTRACT(HOUR from started_at) AS start_time, \n EXTRACT(MONTH from started_at) AS start_month,DATETIME_DIFF(ended_at,started_at,MINUTE) AS duration,\n start_station_name,start_lat,start_lng, end_station_name,end_lat, end_lng\nFROM `cyclisticcasestudy.tripData.2020_07` \n```\nCheck merged table:\nChecked for possible duplicates. The total row number star consistent.\n```SQL\nSELECT DISTINCT *\nFROM `cyclisticcasestudy.tripData.total_selective_data`\n```\n","metadata":{}},{"cell_type":"markdown","source":"## **Analyze:**  \n**Average Duration:**  \n\n```SQL\nSELECT member_casual,AVG(duration) AS averageDuration\nFROM `cyclisticcasestudy.tripData.total_tripdata` \nGROUP BY member_casual\n```\nresult:  \n\n|member_casual| averageDuration|\n|---|---|\n|casual|42.20672687851149|\n|member|15.01677871316342|\n\nThe average duration of casual and member are significantly different, and the result of this query implys that casual users tend to spend more time on each ride.  \n**Most ride day:**\n```SQL\nSELECT ride_day,COUNT(*) AS totalDays\nFROM `cyclisticcasestudy.tripData.total_tripdata` \nWHERE member_casual='casual'--/member\nGROUP BY ride_day\nORDER BY COUNT(*) DESC\n```\nresult:   \n\n|casual|member|\n|--|--|\n|<table> <tr><th>ride_day</th><th>totalDays</th></tr><tr><td>7</td><td>396428</td></tr><tr><td>1</td><td>329948</td></tr><tr><td>6</td><td>246652</td></tr> <tr><td>5</td><td>191762</td></tr><tr><td>2</td><td>188417</td></tr><tr><td>4</td><td>182565</td></tr><tr><td>3</td><td>174412</td></tr></table>|<table> <tr><th>ride_day</th><th>totalDays</th></tr><tr><td>7</td><td>360579</td></tr><tr><td>6</td><td>350586</td></tr><tr><td>4</td><td>347184</td></tr><tr><td>5</td><td>341971</td></tr><tr><td>3</td><td>329416</td></tr><tr><td>2</td><td>315487</td></tr><tr><td>1</td><td>307818</td></tr></table>|  \n\n\n\n>first day of week is Sunday, so 7 means Saturday and 1 means Sunday   \n\nThe results imply that casual members use bike-share mostly during weekend, and members tend to use more during the weekday while both kinds of users use bike-share often on Sunday.\n\n**Travel distance:**\n```SQL\nSELECT member_casual,AVG(ABS(end_lat-start_lat)) AS latDiff,AVG(ABS(end_lng-start_lng)) AS lngDiff\nFROM `cyclisticcasestudy.tripData.total_tripdata` \nGROUP BY member_casual\n```\nresult:  \n\n|member_casual|latDiff|lngDiff|\n|---|---|---|\n|casual|0.015071854591753685|0.01267706615532465|\n|member|0.015217680626098365 |0.013367068971533039 |\n\n\nlatDiff and lngDiff show the average latitude and longitude difference between every ride's start station and end station. The result shows little difference in casual and member's average ride. The fact that casual users tend to spend more time on each ride is consistent with the assumption: casual users tend to use bike-share for trips, while members tend to use bike-share to commute.","metadata":{}},{"cell_type":"markdown","source":"## **Share:**  \nThe merged table is uploaded to Tableau Desktop for data visualization.  \nBelow are the data visualization from Tableau.","metadata":{}},{"cell_type":"code","source":"%%HTML\n<div class='tableauPlaceholder' id='viz1623972284244' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Cy&#47;CyclisticCaseStudy_16238384116320&#47;RideableTypeBreakdown&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='CyclisticCaseStudy_16238384116320&#47;RideableTypeBreakdown' /><param name='tabs' value='yes' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Cy&#47;CyclisticCaseStudy_16238384116320&#47;RideableTypeBreakdown&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1623972284244');                    var vizElement = divElement.getElementsByTagName('object')[0];  \nvizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                \nvar scriptElement = document.createElement('script');\nscriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    \nvizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>             \n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:26:54.752465Z","iopub.execute_input":"2021-06-17T23:26:54.753162Z","iopub.status.idle":"2021-06-17T23:26:54.767858Z","shell.execute_reply.started":"2021-06-17T23:26:54.753053Z","shell.execute_reply":"2021-06-17T23:26:54.766732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the visualization, I can conclude the following differences casual users have than members:\n* Casual users tend to use bike more in the downtown Chicago. Refering to the dashboard 'HeatMap', casual users are more concentrated in the center.\n* Casual users tend to use bike for longer duration each ride, refering to the trend line charts dashboard 'Trend'.\n* Casual users tend to use bike during summer. The peaks of usage are in May and Augest, and the bottoms are in December to February.  \n* Causal users tend to use more docked cike and fewer classic bikes comparing to members.","metadata":{}},{"cell_type":"markdown","source":"## **Act:**  \nThe top three recommendations from conclusion made in the share phase:\n* Target users who live near the downtown Chicago\n* Advertise more during summer\n* Create promotion combinging popular leisure riding routes and the annual memberships","metadata":{}},{"cell_type":"markdown","source":"## **Case Study Wrap Up:**\n\nIt is my first case study that thoroughly walked through all six phases of data analysis alone. The whole case study took approximatly 10 hours to complete. It should be shorter because there are only 12 tables with 15 attributes, but it took me a really long time figuring out what data to combine or extract and what data visualizations to build. Because there are two set of nullable data on the start location and end location, I was not sure what to do with them and I could not just use COALESCE() to obtain one primary attribute because these data are in different data type. Therefore, I just kept these redundant data when I ran queries and built vizs to analyze. I also tried to drew the trips into lines on the map, but the trips' map was too messy to use because I didn't query out the poppular routes prior to analyze phase. There are much more for me to learn, and I hope I can make progress in every case study or project.   \n\n#### Thank you so much for reading my case study!","metadata":{}}]}