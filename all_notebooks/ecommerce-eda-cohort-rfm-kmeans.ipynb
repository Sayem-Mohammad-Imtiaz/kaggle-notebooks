{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sat Nov  14 10:31:35 2020\n@author: harikumar balakrishnan\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load Libraries\nLoad Libraries for Data Manipulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random \nimport datetime as dt\nimport re\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load Libraries for WordCloud Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk, warnings\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.wordnet import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load Libraries for Kmeans Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip\n!pip install feature_engine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import timedelta\nfrom scipy.stats import chi2_contingency\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, Normalizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.manifold import TSNE\nfrom feature_engine.outlier_removers import Winsorizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load Libraries for Plot Libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.cm as cm\nfrom sklearn import metrics\nimport plotly.graph_objects as go\nimport plotly.express as px\npd.set_option('display.max_rows', 100)\n%config InlineBackend.figure_format = 'svg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the dataset - Kaggle Dataset Ecom - Clarie1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ecom = pd.read_csv('../input/ecommerce-data/data.csv',encoding=\"ISO-8859-1\",dtype={'CustomerID': str,'InvoiceID': str})\ndf_ecom.head()\ndf_ecom.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Prep & Manipulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned = df_ecom.copy(deep = True)\ndf_cleaned['QuantityCanceled'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"entry_to_remove = [] ; doubtfull_entry = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"remaining_entries = df_cleaned[(df_cleaned['Quantity'] < 0) & (df_cleaned['StockCode'] != 'D')]\nprint(\"nb of entries to delete: {}\".format(remaining_entries.shape[0]))\nremaining_entries[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned.drop(remaining_entries.index, axis = 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_special_codes = df_cleaned[df_cleaned['StockCode'].str.contains('^[a-zA-Z]+', regex=True)]['StockCode'].unique()\nlist_special_codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned = df_cleaned[df_cleaned['StockCode']!= 'POST']\ndf_cleaned = df_cleaned[df_cleaned['StockCode']!= 'D']\ndf_cleaned = df_cleaned[df_cleaned['StockCode']!= 'C2']\ndf_cleaned = df_cleaned[df_cleaned['StockCode']!= 'M']\ndf_cleaned = df_cleaned[df_cleaned['StockCode']!= 'BANK CHARGES']\ndf_cleaned = df_cleaned[df_cleaned['StockCode']!= 'PADS']\ndf_cleaned = df_cleaned[df_cleaned['StockCode']!= 'DOT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned[(df_cleaned['UnitPrice'] == 0)].head(5)\ndf_cleaned['TotalPrice'] = df_cleaned['UnitPrice'] * (df_cleaned['Quantity'] - df_cleaned['QuantityCanceled'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Word Cloud / Cohort Analysis<br>\nFor this analysis considering United Kingdom as it falls on highest propotion compared to the rest of the countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"uk_ecom = df_cleaned[df_cleaned['Country']=='United Kingdom']\nuk_ecom['Description'] = uk_ecom['Description'].astype(str)\nfreq = pd.Series(' '.join(uk_ecom['Description']).split()).value_counts()[:20]\nfreq","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Identify uncommon words"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq1 =  pd.Series(' '.join(uk_ecom['Description']).split()).value_counts()[-20:]\nfreq1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words(\"english\"))\nnew_words = ['RED','PINK', 'BLUE', 'OF', 'BROWN',\"BLACK\"]\nstop_words = stop_words.union(new_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in new_words:\n  if i in stop_words:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, 8789):\n\ttext = re.sub('[^a-zA-Z]', ' ', uk_ecom['Description'].iloc[i])\n\ttext = text.lower()\n\ttext=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n\ttext=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n\ttext = text.split()\n\tps=PorterStemmer()\n\tlem = WordNetLemmatizer()\n\ttext = [lem.lemmatize(word) for word in text if word not in stop_words]\n\ttext = \" \".join(text)\n\ti\n\tcorpus.append(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nwordcloud = WordCloud(    background_color='white',\n                          stopwords=stop_words,\n                          max_words=200,\n                          max_font_size=50, \n                          random_state=42\n                         ).generate(str(corpus))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Word Cloud for Customer\\'s Products')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cohort Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_days(x):\n\treturn dt.datetime(x.year, x.month, x.day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uk_ecom['date'] = pd.DatetimeIndex(uk_ecom['InvoiceDate']).date\nuk_ecom['InvoiceDay'] = uk_ecom['date'].apply(extract_days)\ngrouping = uk_ecom.groupby('CustomerID')['InvoiceDay']\nuk_ecom['CohortDay'] = grouping.transform('min')\nprint(uk_ecom.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function to extract Year/Month"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_month_int(x):\n    return dt.datetime(x.year, x.month, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a column InvoiceMonth"},{"metadata":{"trusted":true},"cell_type":"code","source":"uk_ecom['InvoiceMonth'] = uk_ecom['date'].apply(extract_month_int)\ngrouping = uk_ecom.groupby('CustomerID')['InvoiceMonth']\nuk_ecom['CohortMonth'] = grouping.transform('min')\nuk_ecom.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_dates_int(df, column):\n    year = df[column].dt.year\n    month = df[column].dt.month\n    day = df[column].dt.day\n    return year, month, day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"invoice_year, invoice_month, _ = extract_dates_int(uk_ecom, 'InvoiceMonth')\ncohort_year, cohort_month, _ = extract_dates_int(uk_ecom, 'CohortMonth')\nyears_difference = invoice_year - cohort_year\nmonths_difference = invoice_month - cohort_month","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"~365 days in one year, ~30 days in one month and plus 1 day to differ from zero value"},{"metadata":{"trusted":true},"cell_type":"code","source":"uk_ecom['CohortIndex'] = years_difference * 12 + months_difference + 1\ngrouping = uk_ecom.groupby(['CohortMonth', 'CohortIndex'])\ncohort_data = grouping['CustomerID'].apply(pd.Series.nunique).reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating cohort pivot table "},{"metadata":{"trusted":true},"cell_type":"code","source":"cohort_counts = cohort_data.pivot(index = 'CohortMonth', columns = 'CohortIndex', values = 'CustomerID')\ncohort_sizes = cohort_counts.iloc[:, 0]\nretention = cohort_counts.divide(cohort_sizes, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Review the retention table"},{"metadata":{"trusted":true},"cell_type":"code","source":"retention.round(3) * 100\ngrouping_avg_quantity = uk_ecom.groupby(['CohortMonth', 'CohortIndex'])\ncohort_data_avg_quantity = grouping_avg_quantity['Quantity'].mean().reset_index()\naverage_quantity = cohort_data_avg_quantity.pivot(index = 'CohortMonth', columns = 'CohortIndex', values = 'Quantity')\naverage_quantity.round(1).fillna('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build a figure"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 5))\nplt.title('Retention Rate for Customers in United Kingdom')\nsns.heatmap(data = retention, annot = True, fmt = '.0%', vmin = 0.01, vmax = 0.5, cmap = 'BuGn')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initialize a heatmap grapgh "},{"metadata":{},"cell_type":"markdown","source":"#### RFM Analysis <br>\nCalcuation Monetary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned['TotalSum'] = df_cleaned['Quantity'] * df_cleaned['UnitPrice']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculation Recency "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])\nsnapshot_date = df_cleaned['InvoiceDate'].max() + timedelta(days=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping by CustomerID and Calculation frequency "},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm = df_cleaned.groupby(['CustomerID']).agg({\n        'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n        'InvoiceNo': 'count',\n        'TotalSum': 'sum'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rename the columns "},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm.rename(columns={'InvoiceDate': 'Recency',\n                         'InvoiceNo': 'Frequency',\n                         'TotalSum': 'Monetary'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"--Calculate R and F groups-- Create labels for Recency and Frequency"},{"metadata":{"trusted":true},"cell_type":"code","source":"r_labels = range(4, 0, -1); f_labels = range(1, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assign these labels to 4 equal percentile groups "},{"metadata":{"trusted":true},"cell_type":"code","source":"r_groups = pd.qcut(rfm['Recency'], q=4, labels=r_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assign these labels to 4 equal percentile groups "},{"metadata":{"trusted":true},"cell_type":"code","source":"f_groups = pd.qcut(rfm['Frequency'], q=4, labels=f_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new columns R and F "},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm = rfm.assign(R = r_groups.values, F = f_groups.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create labels for Monetary"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_labels = range(1, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assign these labels to three equal percentile groups "},{"metadata":{"trusted":true},"cell_type":"code","source":"m_groups = pd.qcut(rfm['Monetary'], q=4, labels=m_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new column M for Monetary"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm = rfm.assign(M = m_groups.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculation for RFM score (R+F+M)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def join_rfm(x): return str(x['R']) + str(x['F']) + str(x['M'])\nrfm['RFM_Segment_Concat'] = rfm.apply(join_rfm, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate RFM_Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm['RFM_Score'] = rfm[['R','F','M']].sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define rfm_level function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rfm_level(df):\n    if df['RFM_Score'] >= 9:\n        return \"Can't Loose Them\"\n    elif ((df['RFM_Score'] >= 8) and (df['RFM_Score'] < 9)):\n        return 'Champions'\n    elif ((df['RFM_Score'] >= 7) and (df['RFM_Score'] < 8)):\n        return 'Loyal'\n    elif ((df['RFM_Score'] >= 6) and (df['RFM_Score'] < 7)):\n        return 'Potential'\n    elif ((df['RFM_Score'] >= 5) and (df['RFM_Score'] < 6)):\n        return 'Promising'\n    elif ((df['RFM_Score'] >= 4) and (df['RFM_Score'] < 5)):\n        return 'Needs Attention'\n    else:\n        return 'Require Activation'\n    \n# Create a new variable RFM_Level\nrfm['RFM_Level'] = rfm.apply(rfm_level, axis=1)\nrfm.reset_index(level=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting RFM_Level"},{"metadata":{"trusted":true},"cell_type":"code","source":"plo1 = rfm.groupby('RFM_Level')['CustomerID'].nunique().sort_values(ascending=False).reset_index()\nsns.set(rc={'figure.figsize':(8, 4)})\nsns.barplot(data=plo1, x = 'CustomerID', y = 'RFM_Level', \n\t\t\tpalette = 'Greens_d', orient = 'h')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm_uc = rfm.copy()\nquantiles = rfm_uc.quantile(q=[0.8])\nprint(quantiles)\nrfm_uc['R']=np.where(rfm_uc['Recency']<=int(quantiles.Recency.values), 2, 1)\nrfm_uc['F']=np.where(rfm_uc['Frequency']>=int(quantiles.Frequency.values), 2, 1)\nrfm_uc['M']=np.where(rfm_uc['Monetary']>=int(quantiles.Monetary.values), 2, 1)\nrfm_uc.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To do the 2 x 2 matrix we will only use Recency & Monetary"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm_uc['RMScore'] = rfm_uc.M.map(str)+rfm_uc.R.map(str)\nrfm_uc = rfm_uc.reset_index()\ndf_RFM_SUM = rfm_uc.groupby('RMScore').agg({'CustomerID': lambda y: len(y.unique()),\n                                        'Frequency': lambda y: round(y.mean(),0),\n                                        'Recency': lambda y: round(y.mean(),0),\n                                        'R': lambda y: round(y.mean(),0),\n                                        'M': lambda y: round(y.mean(),0),\n                                        'Monetary': lambda y: round(y.mean(),0)})\ndf_RFM_SUM = df_RFM_SUM.sort_values('RMScore', ascending=False)\ndf_RFM_SUM.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) Average Monetary Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_RFM_M = df_RFM_SUM.pivot(index='M', columns='R', values='Monetary')\ndf_RFM_M= df_RFM_M.reset_index().sort_values(['M'], ascending = False).set_index(['M'])\nprint(df_RFM_M)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2) Number of Customer Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_RFM_C = df_RFM_SUM.pivot(index='M', columns='R', values='CustomerID')\ndf_RFM_C= df_RFM_C.reset_index().sort_values(['M'], ascending = False).set_index(['M'])\nprint(df_RFM_C)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3) Recency"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_RFM_R = df_RFM_SUM.pivot(index='M', columns='R', values='Recency')\ndf_RFM_R= df_RFM_R.reset_index().sort_values(['M'], ascending = False).set_index(['M'])\nprint(df_RFM_R)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Kmeans Clustering\nNormalization for Kmeans Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"windsoriser = Winsorizer(distribution='skewed', \n                          tail='both', # cap left, right or both tails \n                          fold=2,\n                           variables=[ 'Recency', 'Frequency', 'Monetary']\n                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_rfm_log = rfm_uc[['CustomerID', 'Recency', 'Frequency', 'Monetary']] \nrfm_or = rfm_uc[['CustomerID', 'Recency', 'Frequency', 'Monetary']] \ndf_rfm_log.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_rfm_log['CustomerID'] = df_rfm_log['CustomerID'].astype(int)\nrfm_or['CustomerID'] = rfm_or['CustomerID'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_rfm_log = np.log(df_rfm_log[['Recency', 'Frequency', 'Monetary']] +1)\nwindsoriser.fit(df_rfm_log)\ndf_rfm_log = windsoriser.transform(df_rfm_log)\nscaler = StandardScaler()\nscaler.fit(df_rfm_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM_Table_scaled = scaler.transform(df_rfm_log)\nRFM_Table_scaled = pd.DataFrame(RFM_Table_scaled, columns=df_rfm_log.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kmeans Silhoutte Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"range_n_clusters = range(5,6)\neval_scores = {'model':[],'n_clusters':[], 's_score':[], 'c_score':[], 'db_score':[]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n_clusters in range_n_clusters:\n    fig=plt.figure()\n    ax=plt.axes()\n    \n    ax.set_xlim([-0.1, 1])\n    ax.set_ylim([0, len(RFM_Table_scaled) + (n_clusters + 1) * 10])\n    clusterer = KMeans(n_clusters=4, random_state=77, init='k-means++')\n    eval_scores['model'].append('KMeans')\n    \n    cluster_labels = clusterer.fit_predict(RFM_Table_scaled)\n    silhouette_avg = silhouette_score(RFM_Table_scaled, cluster_labels, random_state = 77)\n   \n    eval_scores['n_clusters'].append(n_clusters)\n    eval_scores['s_score'].append(silhouette_avg)\n    eval_scores['c_score'].append(metrics.calinski_harabasz_score(RFM_Table_scaled, cluster_labels))\n    eval_scores['db_score'].append(metrics.davies_bouldin_score(RFM_Table_scaled, cluster_labels))\n    \n    sample_silhouette_values = silhouette_samples(RFM_Table_scaled, cluster_labels)\n    y_lower = 10\n    for i in range(n_clusters):\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n        ith_cluster_silhouette_values.sort()\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n        color = cm.nipy_spectral(float(i) / n_clusters)\n        ax.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n        y_lower = y_upper + 10  # 10 for the 0 samples\n    ax.set_title(\"The silhouette plot for the various clusters.\")\n    ax.set_xlabel(\"The silhouette coefficient values\")\n    ax.set_ylabel(\"Cluster label\")\n    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n    ax.set_yticks([])  # Clear the yaxis labels / ticks\n    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.show()\nfig.savefig('silhouette.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kmeans Function\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def kmeans(normalised_df_rfm, clusters_number, original_df_rfm):\n    \n    kmeans = KMeans(n_clusters = clusters_number, random_state = 1)\n    kmeans.fit(normalised_df_rfm)\n\n    # Extract cluster labels\n    cluster_labels = kmeans.labels_\n        \n    # Create a cluster label column in original dataset\n    df_new = original_df_rfm.assign(Cluster = cluster_labels)\n    \n    # Initialise TSNE\n    model = TSNE(random_state=1)\n    transformed = model.fit_transform(df_new)\n    \n    # Plot t-SNE\n    plt.title('Flattened Graph of {} Clusters'.format(clusters_number))\n    sns.scatterplot(x=transformed[:,0], y=transformed[:,1], hue=cluster_labels, style=cluster_labels, palette=\"Set1\")\n    \n    return df_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\ndf_rfm_k4 = kmeans(RFM_Table_scaled, 4, rfm_or)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rfm_values(df):\n    df_new = df.groupby(['Cluster']).agg({\n        'Recency': 'mean',\n        'Frequency': 'mean',\n        'Monetary': ['mean', 'count']\n    }).round(0)\n    \n    return df_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualizations for EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"revenue_per_countries = df_cleaned.groupby([\"Country\"])[\"TotalPrice\"].sum().sort_values()\nrevenue_per_countries = pd.DataFrame(revenue_per_countries)\nrevenue_per_countries['percent'] = revenue_per_countries['TotalPrice']/revenue_per_countries['TotalPrice'].sum()\nrevenue_per_countries['percent'] = revenue_per_countries['percent']*100\nrevenue_per_countries = revenue_per_countries.sort_values(by=['percent'], ascending=False)\nrevenue_per_countries = revenue_per_countries.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nrevenue_per_countries = revenue_per_countries.reset_index()\nbarplot = plt.bar(revenue_per_countries['Country'], revenue_per_countries['percent'], color = 'lightgreen', alpha = 0.90)\nbarplot[0].set_color('darkgreen')\nbarplot[1].set_color('darkgreen')\nbarplot[2].set_color('darkgreen')\nplt.xlabel('Country', fontsize = 15, weight = 'bold')\nplt.ylabel('Percent', fontsize = 15, weight = 'bold')\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Revenue Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned['AmountSpent']=df_cleaned['Quantity']*df_cleaned['UnitPrice']\ninvoice_customer_df=df_cleaned.groupby(by=['InvoiceNo','InvoiceDate']).agg({'AmountSpent':sum,'CustomerID':max,'Country':max,}).reset_index()\ninvoice_customer_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_unique_customer_df=df_cleaned.set_index('InvoiceDate')['CustomerID'].resample('M').nunique()\nmonthly_unique_customer_df\nmonthly_revenue_df=df_cleaned.set_index('InvoiceDate')['AmountSpent'].resample('M').sum()\nmonthly_rev_repeat_customer_df=invoice_customer_df.set_index('InvoiceDate').groupby([pd.Grouper(freq='M'),'CustomerID']).filter(lambda x:len(x) > 1).resample('M').sum()['AmountSpent']\nmonthly_rev_per_repeat_customers_df=monthly_rev_repeat_customer_df/monthly_revenue_df*100\nmonthly_rev_per_repeat_customers_df\nmonthly_repeat_customers_df=invoice_customer_df.set_index('InvoiceDate').groupby([pd.Grouper(freq='M'),'CustomerID']).filter(lambda x:len(x)>1).resample('M').nunique()['CustomerID']\nmonthly_repeat_customers_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the Repeat Revenue Percentage"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=pd.DataFrame(monthly_repeat_customers_df.values).plot(figsize=(12,8))\npd.DataFrame(monthly_unique_customer_df.values).plot(ax=ax,grid=True)\nax2=ax.twinx()\npd.DataFrame(monthly_rev_per_repeat_customers_df.values).plot(ax=ax2,kind='bar',color='lightgrey',alpha=0.3)\nax2.set_ylim([0,max(monthly_rev_per_repeat_customers_df.values)+30])\nax2.set_ylabel('Percentage (%)')\nax2.set_xticklabels([x.strftime('%m.%Y') for x in monthly_rev_per_repeat_customers_df.index])\nax.set_xlabel('Date')\nax.set_ylabel('Number of Customers')\nax.set_title('Number of Unique vs. Repeat Customers Over Time')\nax.legend(['Repeat Customers','All Customers'])\nax2.legend(['Repeat Revenue Percentage'],loc='upper right')\nax.set_ylim([0,monthly_unique_customer_df.values.max()+100])\nax2.set_ylim([0,100])\nplt.xticks(range(len(monthly_repeat_customers_df.index)),[x.strftime('%m.%Y') for x in monthly_repeat_customers_df.index],rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thanks"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}