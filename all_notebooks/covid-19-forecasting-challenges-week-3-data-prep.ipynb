{"cells":[{"metadata":{},"cell_type":"markdown","source":"### COVID-19 Forecasting Challenge (Week 3) Data Prep\n\nThis notebook prepared the data in Kaggle's [COVID-19 Global Forecasting Competition (Week 2)](https://www.kaggle.com/c/covid19-global-forecasting-week-2) that was used to launch the competition. The source data comes from [JHU CSSE's COVID-19 data repository on GitHub](https://github.com/CSSEGISandData/COVID-19).\n\nI re-ran this notebook on updated data to add descriptive comments, so it won't output precisely the same as the original launch data. I saved the original launch data [to this dataset](https://www.kaggle.com/benhamner/covid19-forecasting-week-two-launch-data).\n\nThe data for the submission period for the forecasting challenges is also updated every day, alongside leaderboard rescores. I use [this notebook](https://www.kaggle.com/benhamner/covid-19-forecasting-ongoing-data-updates/) to run the ongoing data updates."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from datetime import date, datetime, timedelta\nimport numpy as np\nimport pandas as pd\n\nconfirmed = pd.read_csv(\"../input/jhucovid19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\ndeaths   = pd.read_csv(\"../input/jhucovid19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"launch_date = date(2020, 4, 2)\nlatest_train_date = date(2020, 4, 1)\n\npublic_leaderboard_start_date = launch_date - timedelta(7)\nclose_date = launch_date + timedelta(7)\nfinal_evaluation_start_date = launch_date + timedelta(8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Move to ISO 8601 dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed.columns = list(confirmed.columns[:4]) + [datetime.strptime(d, \"%m/%d/%y\").date().strftime(\"%Y-%m-%d\") for d in confirmed.columns[4:]]\ndeaths.columns    = list(deaths.columns[:4])    + [datetime.strptime(d, \"%m/%d/%y\").date().strftime(\"%Y-%m-%d\") for d in deaths.columns[4:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter out problematic data points (The West Bank and Gaza had a negative value, cruise ships were associated with Canada, etc.)\nremoved_states = \"Recovered|Grand Princess|Diamond Princess\"\nremoved_countries = \"US|The West Bank and Gaza\"\n\nconfirmed.rename(columns={\"Province/State\": \"Province_State\", \"Country/Region\": \"Country_Region\"}, inplace=True)\ndeaths.rename(columns={\"Province/State\": \"Province_State\", \"Country/Region\": \"Country_Region\"}, inplace=True)\nconfirmed = confirmed[~confirmed[\"Province_State\"].replace(np.nan, \"nan\").str.match(removed_states)]\ndeaths    = deaths[~deaths[\"Province_State\"].replace(np.nan, \"nan\").str.match(removed_states)]\nconfirmed = confirmed[~confirmed[\"Country_Region\"].replace(np.nan, \"nan\").str.match(removed_countries)]\ndeaths    = deaths[~deaths[\"Country_Region\"].replace(np.nan, \"nan\").str.match(removed_countries)]\n\nconfirmed.drop(columns=[\"Lat\", \"Long\"], inplace=True)\ndeaths.drop(columns=[\"Lat\", \"Long\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deaths","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Starting to pull in US state data, since this was saved separately"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_keys = pd.read_csv(\"../input/jhucovid19/csse_covid_19_data/csse_covid_19_daily_reports/04-01-2020.csv\")\nus_keys = us_keys[us_keys[\"Country_Region\"]==\"US\"]\nus_keys = us_keys.groupby([\"Province_State\", \"Country_Region\"])[[\"Confirmed\", \"Deaths\"]].sum().reset_index()\n\nus_keys = us_keys[~us_keys.Province_State.str.match(\"Diamond Princess|Grand Princess|Recovered|Northern Mariana Islands|American Samoa\")].reset_index(drop=True)\nus_keys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed = confirmed.append(us_keys[[\"Province_State\", \"Country_Region\"]], sort=False).reset_index(drop=True)\ndeaths = deaths.append(us_keys[[\"Province_State\", \"Country_Region\"]], sort=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in confirmed.columns[2:]:\n    confirmed[col].fillna(0, inplace=True)\n    deaths[col].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding in daily US state data"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_start_date = date(2020, 3, 10)\nday_date = us_start_date\n\nwhile day_date <= latest_train_date:\n    day = pd.read_csv(\"../input/jhucovid19/csse_covid_19_data/csse_covid_19_daily_reports/%s.csv\" % day_date.strftime(\"%m-%d-%Y\"))\n    \n    if \"Country/Region\" in day.columns:\n        day.rename(columns={\"Country/Region\": \"Country_Region\", \"Province/State\": \"Province_State\"}, inplace=True)\n    \n    us = day[day[\"Country_Region\"]==\"US\"]\n    us = us.groupby([\"Province_State\", \"Country_Region\"])[[\"Confirmed\", \"Deaths\"]].sum().reset_index()\n    \n    unused_data = []\n    untouched_states = set(confirmed[confirmed[\"Country_Region\"]==\"US\"][\"Province_State\"])\n    \n    for (i, row) in us.iterrows():\n        if confirmed[(confirmed[\"Country_Region\"]==\"US\") & (confirmed[\"Province_State\"]==row[\"Province_State\"])].shape[0]==1:\n            confirmed.loc[(confirmed[\"Country_Region\"]==\"US\") & (confirmed[\"Province_State\"]==row[\"Province_State\"]), day_date.strftime(\"%Y-%m-%d\")] = row[\"Confirmed\"]\n            deaths.loc[(deaths[\"Country_Region\"]==\"US\") & (deaths[\"Province_State\"]==row[\"Province_State\"]), day_date.strftime(\"%Y-%m-%d\")] = row[\"Deaths\"]\n            untouched_states.remove(row[\"Province_State\"])\n        else:\n            unused_data.append(row[\"Province_State\"])\n            \n    print(day_date, \"Untouched\", untouched_states)\n    print(day_date, \"Unused\", unused_data)\n\n    day_date = day_date + timedelta(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deaths","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filtering out any data on or after the launch date for the competition"},{"metadata":{"trusted":true},"cell_type":"code","source":"dates_on_after_launch = [col for col in confirmed.columns[4:] if col>=launch_date.strftime(\"%Y-%m-%d\")]\nprint(\"Removing %d columns: %s\" % (len(dates_on_after_launch), str(dates_on_after_launch)))\n\ncols_to_keep = [col for col in confirmed.columns if col not in dates_on_after_launch]\n\nconfirmed = confirmed[cols_to_keep]\ndeaths = deaths[cols_to_keep]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding the rows to be forecast"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(36):\n    this_date = (launch_date + timedelta(i)).strftime(\"%Y-%m-%d\")\n    confirmed.insert(len(confirmed.columns), this_date, np.NaN)\n    deaths.insert(len(deaths.columns), this_date, np.NaN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Melting the data to a version that will be friendlier to Kaggle's evaluation system."},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_melted = confirmed.melt(confirmed.columns[:2], confirmed.columns[2:], \"Date\", \"ConfirmedCases\")\n#confirmed_melted.insert(5, \"Type\", \"Confirmed\")\ndeaths_melted = deaths.melt(deaths.columns[:2], deaths.columns[2:], \"Date\", \"Fatalities\")\n#deaths_melted.insert(5, \"Type\", \"Deaths\")\n\nconfirmed_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\ndeaths_melted.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\n\nassert confirmed_melted.shape==deaths_melted.shape\nassert list(confirmed_melted[\"Province_State\"])==list(deaths_melted[\"Province_State\"])\nassert list(confirmed_melted[\"Country_Region\"])==list(deaths_melted[\"Country_Region\"])\nassert list(confirmed_melted[\"Date\"])==list(deaths_melted[\"Date\"])\n\ncases = confirmed_melted.merge(deaths_melted, on=[\"Province_State\", \"Country_Region\", \"Date\"], how=\"inner\")\ncases = cases[[\"Country_Region\", \"Province_State\", \"Date\", \"ConfirmedCases\", \"Fatalities\"]]\n\ncases.sort_values(by=[\"Country_Region\", \"Province_State\", \"Date\"], inplace=True)\ncases.insert(0, \"Id\", range(1, cases.shape[0]+1))\ncases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = cases.loc[cases[\"Date\"]>=public_leaderboard_start_date.strftime(\"%Y-%m-%d\")]\nforecast.drop(columns=\"Id\", inplace=True)\nforecast.insert(0, \"ForecastId\", range(1, forecast.shape[0]+1))\nforecast.insert(6, \"Usage\", \"Ignored\")\nforecast.loc[forecast[\"Date\"]<launch_date.strftime(\"%Y-%m-%d\"),\"Usage\"]=\"Public\"\nforecast.loc[forecast[\"Date\"]>=final_evaluation_start_date.strftime(\"%Y-%m-%d\"),\"Usage\"]=\"Private\"\nforecast","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Global competition data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = cases[cases[\"Date\"]<launch_date.strftime(\"%Y-%m-%d\")]\ntrain.to_csv(\"train.csv\", index=False)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test = forecast[forecast.columns[:-3]]\ntest.to_csv(\"test.csv\", index=False)\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solution = forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\", \"Usage\"]].copy()\nsolution[\"ConfirmedCases\"].fillna(1, inplace=True)\nsolution[\"Fatalities\"].fillna(1, inplace=True)\nsolution.to_csv(\"solution.csv\", index=False)\nsolution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = forecast[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].copy()\nsubmission[\"ConfirmedCases\"] = 1\nsubmission[\"Fatalities\"] = 1\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}