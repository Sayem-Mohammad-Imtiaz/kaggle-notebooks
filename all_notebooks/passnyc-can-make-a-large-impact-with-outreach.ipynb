{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# How PASSNYC's outreach can have a large impact.\n\nPASSNYC aims to increase representation from minorities, ELL students and lower-income students to New York's prestigious Specialized High Schools (SHSs). \n\nTo do so, PASSNYC will target student registration for the SHS Admissions Test (SHSAT), expecting that as registration goes up among the target demographics,  attendence will follow.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# To improve registration, PASSNYC and its partners have a set of levers they can pull.\n\nRyan B. (in the [Discussion forums](http://www.kaggle.com/passnyc/data-science-for-good/discussion/61971) categorized them under umbrellas of *outreach* and *intervention*. While outreach can boost registration by improving awareness and knowledge, interventions affect scores - but are more costly and take longer."},{"metadata":{"_uuid":"a0d3b8e085b7b99e11a9d5b6f82ce677ad378941"},"cell_type":"markdown","source":"# The best analysis will help PASSNYC identify schools for each available intervention.\n\nThus, we want to produce meaningful insights for both, but we'll prioritize outreach efforts because they're cheaper, quicker, and can still be effective if there's a need."},{"metadata":{"_uuid":"45e5e2616d62d579c3d8935a40419cc144c975a1"},"cell_type":"markdown","source":"# So in what ways do we expect PASSNYC and its partners' interventions to drive registration?\n\nFrom the students' perspective, taking the SHSAT \n\n* How well do I expect to perform?\n* If I do well, what's in it for me at an SHS?\n* How easy is it for me to take the test itself?\n* How easy is it for me to actually attend the school?\n\nWithin those questions we can form hypotheses around how PASSNYC and its partners can drive scores:\n* **Preparing students for the tests** will improve the value they expect to get in return.\n* **Educating students and parents on the benefits** of attending an SHS will encourage them to take a shot at the test.\n* **Educating students on the environment and life at an SHS** may help students who question whether they'd succeed and fit in there.\n\nWe can also predict how different demographic groups may need different treatment as well, such as:\n* **Giving realistic information about costs** in time and money to families in a lower socioeconomic status (SES). Low-SES family members support one another closely, so additional travel or study time can take a toll."},{"metadata":{"_uuid":"855e74a45ed2e3d722a11e1139d6e6e051eb5f92"},"cell_type":"markdown","source":"# Finally, how do our constraints impact how we analyze the data?\n\nOur priority should be to segment students so that PASSNYC has both:\n1. One or more starting points for immediate outreach\n2. A strategy for its long-term interventions through partnerships\n\nIn doing so, I found the following:\n1. A collection of schools that registered far fewer students than would be expected given their students' Common Core test scores. Reaching out to these schools will strongly drive recommendations because students there needn't be convinced that they can perform well on the SHSAT.\n\n2. PASSNYC's best bet for outreach each year is to find the schools where students perform well on Common Core tests. Common Core scores were the best predictor by far of registration, but not all grades are equal. Scores of 6th and 7th graders - those closest to taking the test - predicted outcomes better than any other grade. \n\n3. Holding test scores constant, attendence, economic need, and special education participation became the strongest predictors. Partners that focus on improving students' scores should seek out schools scoring well on those metrics, and they should further look for schools near the middle-of-the-pack in terms of scoring, because encouraging students who are on-the-fence to sign up and improve will add greatest value."},{"metadata":{"_uuid":"7e54afac6334e8b0fca49362ac9f7fc27108ae6a"},"cell_type":"markdown","source":"# Data Analysis\n\nI start by bringing in data science tools and data before cleaning it and creating new variables. I'll move quickly through the code of this point, but here are some key takeaways:\n\n1. I calculated the percentage of students who sat for the SHSAT at each school as the main predicted variable. This was the closest datapoint available to SHSAT registration.\n2. I created variables measuring distance between each school and both the SHSs and the testing centers. I saved the smallest of each distance for each school.\n3. I averaged the % of students who attained 4s on Math and ELA for each grade level.\n4. Using two NYC Open Data sources on Kaggle, I gathered safety data (averaging the total number of crimes at each school over six years) and the % of students in special education."},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"ed444636792fed32d880003742fd6cdcdcf3355e","_kg_hide-output":true},"cell_type":"code","source":"#import libraries, including...\n\nimport os \n\n#data structuring, statistics, and other math we'll use\nimport pandas as pd\nimport numpy as np\nfrom math import radians, cos, sin, asin, sqrt\n\n#visualization\n%matplotlib inline\nimport seaborn as sns\nsns.light_palette(\"purple\", as_cmap=True)\n\n#machine learning and statistics\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats.stats import pearsonr","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"34beeb6122cde995f7a8fbad42e489ffd5cb2548","_kg_hide-output":true},"cell_type":"code","source":"# Load our school explorer data and update the index column name to match our other datasets\n\nschool_data = pd.read_csv('../input/data-science-for-good/2016 School Explorer.csv', index_col = 'Location Code')\nSHSAT_results = pd.read_csv('../input/20172018-shsat-admissions-test-offers/2017-2018_SHSAT_Admissions_Test_Offers_By_Sending_School.csv', index_col = 'Feeder School DBN')\nschool_safety = pd.read_csv('../input/ny-2010-2016-school-safety-report/2010-2016-school-safety-report.csv', index_col = 'DBN') #Open NYC dataset from Kaggle\nschool_demographics = pd.read_csv('../input/ny-school-demographics-and-accountability-snapshot/2006-2012-school-demographics-and-accountability-snapshot.csv', index_col = 'DBN') #Open NYC dataset from Kaggle\nspecialized_hs_locations = pd.read_csv('../input/nyc-specialized-high-school-locations/elite_eight_data.csv') #Source: Infocusp competition submission. Link: https://www.kaggle.com/infocusp/recommendations-to-passnyc-based-on-data-analysis/data\nSHSAT_testing_locations = pd.read_csv('../input/shsat-testing-locations/SHSAT_testing_locations.csv') #Private dataset containing lat/\n\n#Note - I used a private version of the specialized_hs_locations dataset because of a typo in the original, \n#but I give full credit to Infocusp\n\nraw_datasets = [school_data, SHSAT_results, school_safety, specialized_hs_locations, school_demographics]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"collapsed":true,"_uuid":"f1b383c645d583dac166143018eddca5b838c5ce"},"cell_type":"code","source":"# INITIAL CLEAN-UP (aka preprocessing)\n\n# Removing unecessary columns before cleaning and merging\n\nSHSAT_results.drop(['Feeder School Name'], axis=1, inplace=True) \nschool_safety = school_safety[['Major N', 'Oth N', 'NoCrim N', 'Prop N', 'Vio N']]\nschool_demographics = pd.DataFrame(school_demographics[['frl_percent','sped_percent']])\n\n# fix values before running computations\n\n# In our SHSAT results, replacing '0-5' with 0 in the 'Count' columns\n\nSHSAT_results['# of Test-takers'] = SHSAT_results['Count of Testers'][(SHSAT_results['Count of Testers'].astype(str)) != \"0-5\"]\nSHSAT_results['# of Offers'] = SHSAT_results['Count of Offers'][(SHSAT_results['Count of Offers'].astype(str)) != \"0-5\"]\n\nSHSAT_results.fillna(value = 0, inplace = True)\n\nschool_safety = school_safety.loc[school_safety.index.dropna()] # remove rows with blank DBNs\n\n# Convert dollars, percents, and numbers to the correct format; swap out non-numbers with 0s\n\ndollar_columns = ['School Income Estimate']\npercent_columns = ['Percentage of Black/Hispanic students','Percent Asian', 'Percent Black', 'Percent ELL', \n                   'Percent Hispanic', 'Percent Black / Hispanic','Percent White', 'Student Attendance Rate', \n                   'Percent of Students Chronically Absent', 'Rigorous Instruction %', \n                   'Collaborative Teachers %', 'Supportive Environment %','Effective School Leadership %', \n                   'Strong Family-Community Ties %', 'Trust %', 'sped_percent']\n\ndef fix_dollars(df):\n    for cols in dollar_columns:\n        if cols in df:\n            df[cols] = df[cols].astype(np.object_).str.replace('$','').str.replace(',','').astype(float)\n\ndef fix_percents(df):\n    for cols in percent_columns:\n        if cols in df:\n            df[cols] = (df[cols].astype(np.object_).str.replace('%','').astype(float) / 100)\n\nfor dfs in raw_datasets:\n    fix_dollars(dfs)\n    fix_percents(dfs)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"collapsed":true,"_uuid":"635517889d567068c971d8bcd453c4de8d9bd272"},"cell_type":"code","source":"# Making new columns with secondary datasets\n\nschool_safety['Average Total Crimes 2013-2016'] = school_safety[['Major N', 'Oth N', 'NoCrim N', 'Prop N', 'Vio N']].sum(axis=1)\nschool_safety = school_safety.groupby(['DBN']).mean()\nschool_safety = school_safety['Average Total Crimes 2013-2016']\nSHSAT_results = SHSAT_results[['Count of Students in HS Admissions','# of Test-takers','# of Offers']]\nschool_demographics = (school_demographics.groupby('DBN').mean() / 100)\nschool_demographics.columns = ['Free Meals %', 'Special Ed %']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"collapsed":true,"_uuid":"bf1e4b6735fecc3f14e3122eea144f13005e5424"},"cell_type":"code","source":"# MERGING DATASETS\n\n# merge datasets together\nschool_data = school_data.join(SHSAT_results).join(school_safety).join(school_demographics)\nschool_data = school_data.dropna(subset=['Count of Students in HS Admissions'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"1c52edaaac2ab59c7ff821dd90619069d9e61a15","collapsed":true},"cell_type":"code","source":"## Feature creation within our aggregated dataset ##\n\n# Creating our dependent, or predicted, variable\nschool_data['% Taking SHSAT'] = (school_data['# of Test-takers'].astype(float) \n                                 / school_data['Count of Students in HS Admissions'].astype(float))\n\nschool_data['% Receiving Offers'] = (school_data['# of Offers'].astype(float) \n                                     / school_data['Count of Students in HS Admissions'].astype(float))\n   \n# Estimate the % of HS candidates receiving 4s for outreach. Our 2017-2018 SHSAT cohort were 6th graders in 2015-16.                            \nschool_data['% of 2017-18 SHSAT Takers Receiving 4s in 2016'] = ((school_data['Grade 6 Math 4s - All Students'].astype(float) \n                                                / school_data['Grade 6 Math - All Students Tested'].astype(float))\n                                                + (school_data['Grade 6 ELA 4s - All Students'].astype(float) \n                                                / school_data['Grade 6 ELA - All Students Tested'].astype(float)) \n                                                / 2)\n\n# Estimate the % of 5th graders receiving 4s for medium-term interventions, since this is the 2018-2019 class.\nschool_data['% of 2018-19 SHSAT Takers Receiving 4s in 2016'] =  ((school_data['Grade 5 Math 4s - All Students'].astype(float) \n                                                / school_data['Grade 5 Math - All Students Tested'].astype(float))\n                                                + (school_data['Grade 5 ELA 4s - All Students'].astype(float) \n                                                / school_data['Grade 5 ELA - All Students Tested'].astype(float)) \n                                                / 2)\n\n# Aggregate % of students with 4s for each grade level to see how strong of a predictor each is\nschool_data['% of 7th Graders Receiving 4s'] =  ((school_data['Grade 7 Math 4s - All Students'].astype(float) \n                                                / school_data['Grade 7 Math - All Students Tested'].astype(float))\n                                                + (school_data['Grade 7 ELA 4s - All Students'].astype(float) \n                                                / school_data['Grade 7 ELA - All Students Tested'].astype(float)) \n                                                / 2)\n\nschool_data['% of 8th Graders Receiving 4s'] =  ((school_data['Grade 8 Math 4s - All Students'].astype(float) \n                                                / school_data['Grade 8 Math - All Students Tested'].astype(float))\n                                                + (school_data['Grade 8 ELA 4s - All Students'].astype(float) \n                                                / school_data['Grade 8 ELA - All Students Tested'].astype(float)) \n                                                / 2)\n\nschool_data['% of 3rd Graders Receiving 4s'] =  ((school_data['Grade 3 Math 4s - All Students'].astype(float) \n                                                / school_data['Grade 3 Math - All Students tested'].astype(float))\n                                                + (school_data['Grade 3 ELA 4s - All Students'].astype(float) \n                                                / school_data['Grade 3 ELA - All Students Tested'].astype(float)) \n                                                / 2)\n\nschool_data['% of 4th Graders Receiving 4s'] =  ((school_data['Grade 4 Math 4s - All Students'].astype(float) \n                                                / school_data['Grade 4 Math - All Students Tested'].astype(float))\n                                                + (school_data['Grade 4 ELA 4s - All Students'].astype(float) \n                                                / school_data['Grade 4 ELA - All Students Tested'].astype(float)) \n                                                / 2)\n\n# Average the CC scores accross schools for longer-term interventions.\nschool_data['Average CC Scores'] = (school_data['Average ELA Proficiency'] + \n                                    school_data['Average Math Proficiency'] / 2)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"d6aa4712be6e57e2330cd3c42dbeb4fafb77eace"},"cell_type":"code","source":"# calculate distance between schools and nearest testing center and specialized high school\n\n# taken from https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas and edited\n\ndef haversine(longitude1, latitude1, target_dataset):\n    \"\"\"\n    Calculate the great circle distance between two points \n    on the earth (specified in decimal degrees)\n    \"\"\"\n    distances = []\n    lon1, lat1 = map(radians, [longitude1, latitude1])\n    for i in range(len(target_dataset)):\n    # convert decimal degrees to radians \n        lon2, lat2 = map(radians, [target_dataset.loc[i,\"Long\"], target_dataset.loc[i,\"Lat\"]])\n        # haversine formula \n        dlon = lon2 - lon1 \n        dlat = lat2 - lat1 \n        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n        c = 2 * asin(sqrt(a)) \n        km = 6367 * c\n        distances.append(km)\n    return min(distances)\n\n# these loops iterate separately over our schools to find the nearest SHS and testing locations, respectively\nfor index, row in school_data.iterrows():\n    school_data.loc[index, 'KM to nearest SHS'] = haversine(row['Longitude'], row['Latitude'], specialized_hs_locations)\n\nfor index, row in school_data.iterrows():\n    school_data.loc[index, 'KM to nearest Testing Location'] = haversine(row['Longitude'], row['Latitude'], SHSAT_testing_locations)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"ebe7b9a98eacd5dbd888782cc3ef5e58ec9e70ba"},"cell_type":"code","source":"# Create subsets for segmenting students, predictors, target, and school ID for easy review\n\ndemographics = ['Percent Black / Hispanic', 'Economic Need Index', 'Percent ELL', \n                'Community School?', 'Special Ed %']\n\nmodel_predictors = ['KM to nearest SHS','KM to nearest Testing Location', 'Average Total Crimes 2013-2016',\n                   'Economic Need Index','Rigorous Instruction %', 'Collaborative Teachers %', \n                    'Supportive Environment %', 'Effective School Leadership %', \n                    'Strong Family-Community Ties %', 'Trust %', 'Special Ed %', 'Percent of Students Chronically Absent'] \n                    #Some data we expect to add value as a predictor and as a means of segmenting schools.\n\nmodel_target = ['% Taking SHSAT']\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83c51b27813bb433ab86ac8cf32536949bcaaf1e"},"cell_type":"markdown","source":"# Predictions and results\n\nOur first goal is to understand schools that should've produced many sign-ups last year but didn't. These schools, especially because they're likely to have high-scoring students, will be easy to improve with low-cost outreach efforts."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"3ba5e774240c85c49450678bdfdf65a8131c8395"},"cell_type":"code","source":"# Start with a predictor aimed at the short-term to identify the highest-impact schools ('quick wins').\n# I call these variables 'short_term' because they'll be easy to act on right away.\n\nshort_term_targets = school_data[model_predictors]\nshort_term_targets = short_term_targets.join(school_data['% of 2017-18 SHSAT Takers Receiving 4s in 2016'])\nshort_term_targets = short_term_targets.fillna(short_term_targets.mean())\n\nRand_Forest = RandomForestRegressor(min_samples_leaf=10, n_estimators=100, n_jobs=1, random_state=0)\n# parameter tuning\nRF_params = {\"max_depth\": [3,5,6,None],\n              \"max_features\": [0.33,0.67,1.0],\n              \"min_samples_leaf\": [4,9,16]}\nRF_Gridsearch = GridSearchCV(Rand_Forest, RF_params, cv=3, n_jobs=1)\nRF_Gridsearch.fit(short_term_targets, school_data[model_target].values.ravel())\nRand_Forest = Rand_Forest.set_params(**RF_Gridsearch.best_params_)\nRand_Forest.fit(short_term_targets, school_data[model_target])\n\n# delete variables which are not used or almost unused to keep the model on the simpler side\nshort_term_targets = short_term_targets.loc[:, Rand_Forest.feature_importances_>0.01]\nRand_Forest.fit(short_term_targets, school_data[model_target])\n\n# Save the model's predictions as a new variable\nshort_term_prediction = school_data[model_target]\nshort_term_prediction['Prediction'] = Rand_Forest.predict(short_term_targets)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eba28e6e7728f1b11f9fcb28ad1783e162ecdab0"},"cell_type":"markdown","source":"# Model 1 demonstrates the predictive power of high-scoring students.\n\nWe see clearly that schools with high-scoring students send a high rate of students to the exam. Each bar in the below chart essentially represents how well each variable predicted the SHSAT registration rate. This tells us two things:\n\n1. Students who expect to do well clearly have the strongest incentives to sign up. Pushing the needle on a student's expectation of his/her score will prove strong encouragement.\n2. Schools we find that underperform their prediction will do well in converting SHSAT registrations into acceptances, because we'll be targeting schools with students who'll score well without much help.\n\nThe model used is a Random Forests machine learning algorithm that creates decision trees to granularly understand and predict the outcome, or SHSAT completion by school.\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f76fc028f7c106432c499bb4ee80c90ff70a66d2"},"cell_type":"code","source":"# Visualize predictor strength\n\nshort_term_weights = pd.Series(index=short_term_targets.columns, data=Rand_Forest.feature_importances_).sort_values(ascending=True)\nshort_term_weights.plot(kind='barh', figsize=(10,15), color=\"purple\");","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0892f171a230b3c1efafa7d4cb7b1c8d3c364f84"},"cell_type":"markdown","source":"# We can identify many high-value schools for outreach and quantify the impact.\n\nWith every prediction comes underperformers, and those are our low-hanging fruit. Below, I calculate just how far each school underperformed, and I create a new table showing the top five examples. Note the \"Underperformance in # of Eight Graders\" column - that shows how many students would've registered if the school met its predicted registration rate.\n\nThe top five schools alone can produce another hundred test-takers with only the push to meet expectations.\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ab74c0cd668abf639c70d9846dddcb87315f4acd"},"cell_type":"code","source":"short_term_prediction['Underperformance Gap'] = (short_term_prediction[\"Prediction\"] - \n                                                 short_term_prediction['% Taking SHSAT'])\n\nshort_term_prediction = short_term_prediction.sort_values('Underperformance Gap', ascending=False)\nshort_term_prediction['Underperformance in # of Eight Graders'] = (short_term_prediction['Underperformance Gap'].astype(float)\n                                                                   * school_data['Count of Students in HS Admissions'].astype(float))\nshort_term_prediction = short_term_prediction.join(school_data[['School Name', 'Address (Full)']])\n\nshort_term_prediction.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3782ee25dadbf5f6d3bc1cde15656e46a32a7b6f"},"cell_type":"markdown","source":"It makes sense to prioritize, so I've also created a prioritization score that takes into account the demographics and size of a school. I then create a final table of 30 schools, which will display at the bottom, still sorted by the underperformance gap like the table above."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c7878661e931368b98ea2058667e3a5bd1bc939c"},"cell_type":"code","source":"# Prioritize schools\n\n# Students scoring 4s on Common Core exams were excluded as a weighing variable because they could favor schools based on which grade levels they serve.\n\nprioritization_metrics = pd.DataFrame((school_data['Economic Need Index'] + school_data['Percent ELL'] \n                          + school_data['Percent Black / Hispanic'].astype(float) / 3) \n                                      * school_data['Count of Students in HS Admissions'].astype(float))\n\nshort_term_prediction[\"Prioritization Score\"] = prioritization_metrics\nshort_term_prediction = short_term_prediction.join(school_data[demographics])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"274fc38420bbfebb00f0440ea659aee8e309502c"},"cell_type":"markdown","source":"# Analysis 2 reveals that cohorts matter when considering schools to target.\n\nNow that we have seen some schools that performed below expectations in the past, how do we start to make predictions about the future? The previous analysis showed that the future can be seen through students' Common Core performance, but how far in advance does that shed light? \n\nIt turns out, student cohorts about 1-2 years from taking the test will give much stronger indications of upcoming registration. In other words, **if you want to make sure your high-performing students ultimately take the SHSAT, start finding them in the 6th and 7th grade.** That guideline makes sense for PASSNYC partners as well, because they'll have the perfect amount of time to prepare students to perform at their peak.\n\nBelow are the relationships between the rate of 4s on Math or ELA exams and how well they ultimately predicted registration. Remember the registration data is two years ahead of the Common Core data, so our 6th graders scoring 4s became our 2017-2018 test takers. Hence the strongest correlation lies there."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1c6d6afdb4d1e05476f60cf18923405a5b9c146b"},"cell_type":"code","source":"# Estimate the % of 7th graders receiving 4s for longer-term interventions.\ntest_scores_by_grade = ['% of 3rd Graders Receiving 4s','% of 4th Graders Receiving 4s', \n                        '% of 2018-19 SHSAT Takers Receiving 4s in 2016', '% of 2017-18 SHSAT Takers Receiving 4s in 2016',\n                       '% of 7th Graders Receiving 4s', '% of 8th Graders Receiving 4s']\n\ncorrelations = pd.DataFrame()\n\nDV = school_data['% Taking SHSAT']\n\nfor items in test_scores_by_grade:\n    grade_check = school_data[items] >= 0\n    #check that the school has students of that grade\n    grade_test_scores = school_data[items]\n    correlations[items] = pearsonr(DV[grade_check],grade_test_scores[grade_check])\n    \ncorrelations = correlations.loc[0,:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa4adf4b32119a4441565ef4431e9bc9067535c3"},"cell_type":"markdown","source":"# Model 3 shows that, when looking for young students to target, attendence is key. \n\nNow that we have a sense of who we want to focus our SHSAT preparation efforts on, how do we decide where to go? What school characteristics will predict registration once we've accounted for the student test performance?\n\nPerhaps unsurprisingly, **attendence is the next-strongest predictor of SHSAT registration**. PASSNYC should emphasize to its partners the importance that students show up to the schools they visit, because it both (a) predicts SHSAT registration and (b) improves the chance that students will benefit from the services provided.\n\n**Economic need is the next-best predictor**. And though PASSNYC can't necessary drive economics, they can tailor their messaging appropriately so that students in tough economic situations can understand both (a) the additional strain they may or may not face on their time and (b) the significant financial upside of a high-quality, prestigious high school education. College bills in particular likely deter students from imagining how SHS schools could benefit them, but most young students - and likely their parents, especially if they lack college education - would not understand the volume and quality of scholarships available to those succeeding at the top New York City high schools.\n\nBelow, find another table showing the weights of the various factors."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0ff0b1beee03b5320f0e39af72614ddd066ec37b","_kg_hide-output":true},"cell_type":"code","source":"# Perform the same analysis using 7th grade scores to find schools worth targeting with tutoring programs\n\ntargets_excl_grades = school_data[model_predictors]\ntargets_excl_grades = targets_excl_grades.fillna(targets_excl_grades.mean())\n\nRand_Forest_2 = RandomForestRegressor(min_samples_leaf=10, n_estimators=100, n_jobs=1, random_state=0)\n\nRF_Gridsearch.fit(targets_excl_grades, school_data[model_target].values.ravel())\nRand_Forest_2 = Rand_Forest_2.set_params(**RF_Gridsearch.best_params_)\nRand_Forest_2.fit(targets_excl_grades, school_data[model_target])\n\n# delete variables which are not used or almost unused to keep the model on the simpler side\ntargets_excl_grades = targets_excl_grades.loc[:, Rand_Forest_2.feature_importances_>0.015]\nRand_Forest_2.fit(targets_excl_grades, school_data[model_target])\n\n# Save the model's predictions as a new variable\nprediction_excl_grades = school_data[model_target]\nprediction_excl_grades['Prediction'] = Rand_Forest_2.predict(targets_excl_grades)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e35df6f7ffd76a10c76e9600791439dec7f0c849"},"cell_type":"code","source":"excl_grades_weights = pd.Series(index=targets_excl_grades.columns, data=Rand_Forest_2.feature_importances_).sort_values(ascending=True)\nexcl_grades_weights.plot(kind='barh', figsize=(10,15), color=\"purple\");","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0fe79d5ae1e50675311f1b90f443c80588eac2e"},"cell_type":"markdown","source":"# PASSNYC should continue actively studying its student populations both to identify target audiences and best-practice approaches.\n\nAs we've seen, identifying high-performing student cohorts can prove extremely valuable for raising SHSAT registration, even through relatively easy means like outreach. However, this will take continued review each year, as the high-performing schools may change. Luckily, that data won't take challenging data analysis to provide insights - \n\n1. Find the high-scoring schools, and make sure families and students are aware of the benefits. They should be optimistic about the test and therefore likely to register with little encouragement.\n2. Focus longer interventions on schools where students are likely to engage, and if possible, focus on schools that don't perform quite at the top on test scores. They'll need more than just outreach, but they'll offer realistic returns-on-investment. "},{"metadata":{"_uuid":"d38793d577157f7e0103b4ab9fee97286db46914"},"cell_type":"markdown","source":"# Concluding remarks\n\nDo feel free to contact me if you have any questions or would like to follow-up. Attached, you should find the .CSV file with the full list of schools with recommended weights. I've recreated the first 15 results below.\n\nA special shout-out and thanks to the PASSNYC, Kaggle, and user team and community. Its fantastic to have the chance to work on meaningful projects with real organizations *and* benefit from the work of others who share the same goal."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9894230a0adef72202ccb0c78c8a95f5270204ea"},"cell_type":"code","source":"short_term_prediction.head(15)\nshort_term_prediction.to_csv(\"Chris_Deitrick_PASSNYC_School_Recommendations.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}