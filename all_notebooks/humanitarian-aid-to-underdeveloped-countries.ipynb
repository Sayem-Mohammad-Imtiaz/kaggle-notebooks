{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font color = Blue> Clustering of countries (Humanitarian Aid to Underdeveloped Countries)"},{"metadata":{},"cell_type":"markdown","source":"**Clustering based on socio-economic factors for financial aid by NGO using `K-means` and `Hierarchial` Clustering methods**\n\n"},{"metadata":{},"cell_type":"markdown","source":"**Background:**\n\nHELP International is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. It runs a lot of operational projects from time to time along with advocacy drives to raise awareness as well as for funding purposes.\n\nAfter the recent funding programmes, they have been able to raise around $ 10 million. Now the CEO of the NGO needs to decide how to use this money strategically and effectively. The significant issues that come while making this decision are mostly related to choosing the countries that are in the direst need of aid. \n\nAnd this is where you come in as a data analyst. Your job is to categorise the countries using some socio-economic and health factors that determine the overall development of the country. Then you need to suggest the countries which the CEO needs to focus on the most.\n\n**<font color= Brown> Problem Statement:**\n\nMain task is to cluster the countries by the factors mentioned above and then present your solution and recommendations to the CEO using a PPT.  The following approach is suggested :\n1. Start off with the necessary data inspection and EDA tasks suitable for this dataset - data cleaning, univariate analysis, bivariate analysis etc.\n2. Outlier Analysis: You must perform the Outlier Analysis on the dataset. However, you do have the flexibility of not removing the outliers if it suits the business needs or a lot of countries are getting removed. Hence, all you need to do is find the outliers in the dataset, and then choose whether to keep them or remove them depending on the results you get.\n3. Try both K-means and Hierarchical clustering(both single and complete linkage) on this dataset to create the clusters. [Note that both the methods may not produce identical results and you might have to choose one of them for the final list of countries.]\n4. Analyse the clusters and identify the ones which are in dire need of aid. You can analyse the clusters by comparing how these three variables - [gdpp, child_mort and income] vary for each cluster of countries to recognise and differentiate the clusters of developed countries from the clusters of under-developed countries.\n5. Also, you need to perform visualisations on the clusters that have been formed.  You can do this by choosing any two of the three variables mentioned above on the X-Y axes and plotting a scatter plot of all the countries and differentiating the clusters. Make sure you create visualisations for all the three pairs. You can also choose other types of plots like boxplots, etc. \n6. Both K-means and Hierarchical may give different results because of previous analysis (whether you chose to keep or remove the outliers, how many clusters you chose,  etc.) Hence, there might be some subjectivity in the final number of countries that you think should be reported back to the CEO since they depend upon the preceding analysis as well. Here, make sure that you report back at least 5 countries which are in direst need of aid from the analysis work that you perform.\n\n"},{"metadata":{},"cell_type":"markdown","source":"**Technical Approach:**\n\n1. Data inspection\n2. EDA tasks suitable for this dataset\n    - Data cleaning\n    - Univariate analysis\n    - Bivariate analysis \n3. Data preparation for clustering\n    - Outlier Treatment\n    - Feature Scaling\n    - Hopkin Check\n4. Perform Clustering\n    - KMean Clustering\n        - choose K using both Elbow and Silhouette score\n        - Run K-Means with the chosen K\n        - Visulise the clusters\n        - Cluster profiling using “gdpp, child_mort and income”\n     - Hierarchical Clustering\n        - Use both Single and Complete linkage\n        - Choose one method based on the results\n        - Visualise the clusters\n        - Clustering profiling using “gdpp, child_mort and income”\n5. Final Model \n    - Final Model Selection and labelling\n    - Select model based on cluster results\n6. Conclusion\n    - Top 5 countires selection for financial aid\n    - Top 5 countires selection on some socio-economic and health factor"},{"metadata":{},"cell_type":"markdown","source":"### 1. import required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supress warnings\nimport warnings\nwarnings.filterwarnings ('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing required packages\nimport numpy as np\nimport pandas as pd\n\nimport sklearn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import NearestNeighbors\nfrom kmodes.kmodes import KModes\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans\n\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\n# For Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.cm as cm\n%matplotlib inline\nfrom pylab import rcParams","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Read and Understand the data set"},{"metadata":{},"cell_type":"markdown","source":"The datasets containing those socio-economic factors and the corresponding data dictionary are provided"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading datasets\ndf = pd.read_csv('../input/pca-kmeans-hierarchical-clustering/Country-data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.1 Data Inspection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking number of columns and rows of the dataframe using shape function\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking basic information of the dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the descriptive statistics\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the columns names\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights:\n- Data set is having 167 country data of 10 features of each.\n- There is no missing malue or duplicate rows in the dataset\n- Referring to data dictionary, `exports, health and imports` are given as %age of GDP per capita. So lets convert it to actual value"},{"metadata":{},"cell_type":"markdown","source":"#### 2.2 Data Inspection"},{"metadata":{},"cell_type":"markdown","source":"Checking following details in the session\n1. The missing /null values\n2. Duplicates and dropping the duplicates"},{"metadata":{},"cell_type":"markdown","source":"**2.2.1 Missing/Null Values**\n\nChecking the missing or null values in the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cheking the missing/values in the dataset\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cheking the % of the missing/values in the NGO dataset\nround(100*df.isnull().sum()/len(df.index),2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight:\n- There is `no missing` values observed in the dataset"},{"metadata":{},"cell_type":"markdown","source":"**2.2.2 Duplicate Values Check**\n\nPerforming the duplicate function to find the duplicate values in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the duplicates\nsum(df.duplicated(subset = 'country'))==0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the duplicates and dropping the entire duplicated rows if any\ndf.drop_duplicates(subset = None, inplace =True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight: \n- There is `no duplicates` values observed in the dataset"},{"metadata":{},"cell_type":"markdown","source":"**2.3 Data Conversion/ Trasformation**"},{"metadata":{},"cell_type":"markdown","source":"We will deduce the 3 variables namely `imports`, `exports` and `health` spending from percentage values to actual values of their GDP per capita since the percentage values don’t give a clear picture of that country. \n\n**For example**:- Austria and Belarus have almost the same exports % but their gdpp has a huge gap which doesn’t give an accurate idea of which country is more developed than the other.\nThen we will remove the Country field and keep it as the row names in the final data frame and scale the remaining data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the values before transformation\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting imports, exports and health spending percentages to absolute values.\n\ndf['imports'] = df['imports'] * df['gdpp']/100\ndf['exports'] = df['exports'] * df['gdpp']/100\ndf['health'] = df['health'] * df['gdpp']/100\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the new shape of the dataframe\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selectig numerical columns and droppig country\n# list cols for upper caping\ncols = ['exports', 'health', 'imports', 'total_fer','gdpp']\ndf[cols].describe(percentiles= [0.01,0.25,0.5,0.75,0.99])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### 3. Exploratory Data Analytics (EDA)"},{"metadata":{},"cell_type":"markdown","source":"EDA is understanding the data sets by summarizing  their main characteristics often plotting them usally. Without building any model or making any predictions, lets first look at the data by itself."},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe dataset and Checking outliers at 25%,50%,75%,90%,95% and 99%\ndf.describe(percentiles=[.25,.5,.75,.90,.95,.99])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1. Univariate Analysis\n\nWe need to choose the countries that are in the direst need of aid. Hence, we need to identify those countries with using some socio-economic and health factors that determine the overall development of the country.\n\n`child_mort`,`gdpp` and `income` are important variables to finalize the financial aid and those are highlited in `orange` color"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cheking the outliers - how values in each columns are distrivuted using boxplot\nfig, axs = plt.subplots(3,3, figsize = (15,12))\n\nplt1 = sns.boxplot(df['child_mort'], ax = axs[0,0], color = 'orange')\nplt2 = sns.boxplot(df['exports'], ax = axs[0,1])\nplt3 = sns.boxplot(df['health'], ax = axs[0,2])\nplt4 = sns.boxplot(df['imports'], ax = axs[1,0])\nplt5 = sns.boxplot(df['income'], ax = axs[1,1], color = 'orange')\nplt6 = sns.boxplot(df['inflation'], ax = axs[1,2])\nplt7 = sns.boxplot(df['life_expec'], ax = axs[2,0])\nplt8 = sns.boxplot(df['total_fer'], ax = axs[2,1])\nplt9 = sns.boxplot(df['gdpp'], ax = axs[2,2], color = 'orange')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight: \n\nWe observe the following about the outliers.\n- Since we have limited number of countries(167), removing these outliers would shrink the shape of data and the under-developed countries which are in actual dire need may not contribute to the dataset.\n- So we will cap them to upper and lower limit. But simply capping them to `Upper and Lower Hinge` of box plot may shift the `cluster centroid`.\n- So considering all the sinario we would cap the extreme values in the outliers to `0.01 and 0.99` percentile. By doing this we will be avoiding the risk of cluster overlapping.\n- There are some exclusions while doing outlier treatment.\n    - `child_mort`, `inflation`: High Child mortality  and higher inflation are our matter of concern so we will not do uppercapping for these features.\n    - `export`, `health`, `imports`, `total_fer` and `gdpp` : It has outlier at higher level. We will impute outlier to upper capping (0.99 percentile)\n    - `life_expec` : It has outlers bellow the lower hinge, But again it is our matter of concern so we will not impute these values.\n      \n      \n- There are very few oultiers (<= 5) for all variables except for income and gdpp.\n- All variables have outliers on the upper side (higher values) except for life_expec which has outliers on the down side (less values) indicating that usually the life expectancy in most countries is above 50 except for 3 countries\n"},{"metadata":{},"cell_type":"markdown","source":"**Top 10 poor countries** : Selected the top 10 poor countries to check, how the variables are affeacted  "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, axs = plt.subplots(3,3,figsize = (15,15))\n\n# poor top 10 countries represented as `pt10`\n\n# Child Mortality Rate \npt10_child_mort = df[['country','child_mort']].sort_values('child_mort', ascending = False).head(10)\nplt1 = sns.barplot(x='country', y='child_mort', data= pt10_child_mort, ax = axs[0,0])\nplt1.set(xlabel = '', ylabel= 'Child Mortality Rate')\n\n# Exports\npt10_exports = df[['country','exports']].sort_values('exports', ascending = True).head(10)\nplt2 = sns.barplot(x='country', y='exports', data= pt10_exports, ax = axs[2,1])\nplt2.set(xlabel = '', ylabel= 'Exports')\n\n# Health \npt10_health = df[['country','health']].sort_values('health', ascending = True).head(10)\nplt3 = sns.barplot(x='country', y='health', data= pt10_health, ax = axs[1,0])\nplt3.set(xlabel = '', ylabel= 'Health')\n\n# Imports\npt10_imports = df[['country','imports']].sort_values('imports', ascending = True).head(10)\nplt4 = sns.barplot(x='country', y='imports', data= pt10_imports, ax = axs[2,2])\nplt4.set(xlabel = '', ylabel= 'Imports')\n\n# Per capita Income \npt10_income = df[['country','income']].sort_values('income', ascending = True).head(10)\nplt5 = sns.barplot(x='country', y='income', data= pt10_income, ax = axs[1,2])\nplt5.set(xlabel = '', ylabel= 'Per capita Income')\n\n# Inflation\npt10_inflation = df[['country','inflation']].sort_values('inflation', ascending = False).head(10)\nplt6 = sns.barplot(x='country', y='inflation', data= pt10_inflation, ax = axs[2,0])\nplt6.set(xlabel = '', ylabel= 'Inflation')\n\n# Fertility Rate\npt10_total_fer = df[['country','total_fer']].sort_values('total_fer', ascending = False).head(10)\nplt7 = sns.barplot(x='country', y='total_fer', data= pt10_total_fer, ax = axs[0,1])\nplt7.set(xlabel = '', ylabel= 'Fertility Rate')\n\n# Life Expectancy\npt10_life_expec = df[['country','life_expec']].sort_values('life_expec', ascending = True).head(10)\nplt8 = sns.barplot(x='country', y='life_expec', data= pt10_life_expec, ax = axs[0,2])\nplt8.set(xlabel = '', ylabel= 'Life Expectancy')\n\n# The GDP per capita \npt10_gdpp = df[['country','gdpp']].sort_values('gdpp', ascending = True).head(10)\nplt9 = sns.barplot(x='country', y='gdpp', data= pt10_gdpp, ax = axs[1,1])\nplt9.set(xlabel = '', ylabel= 'GDP per capita')\n\n\nfor ax in fig.axes:\n    plt.sca(ax)\n    plt.xticks(rotation = 90)\n    \nplt.tight_layout()\nplt.show()\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight: \n\n- From above bar plot we could see the common contires in the profile of `gdpp`, `child_mort` and `income` are: `Congo, Dem. Rep.`, `Niger`, `Sierra Leone`,`Central African Republic`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution Plot\nplt.figure(figsize=(15, 15))\nfeatures = ['child_mort', 'exports', 'health', 'imports', 'income','inflation', 'life_expec', 'total_fer', 'gdpp']\nfor i in enumerate(features):\n    ax = plt.subplot(3, 3, i[0]+1)\n    sns.distplot(df[i[1]])\n    plt.xticks(rotation=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights:\n- `life_expec` are right skewed and all other features are leftskewed"},{"metadata":{},"cell_type":"markdown","source":"#### 3.2.  Bi-variate analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# pairplot for continuous data type\nsns.pairplot(df.select_dtypes(['int64','float64']), diag_kind='kde', corner=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Corrleation of the df dataset\nplt.figure(figsize= (12,8))\nsns.heatmap(df.corr(), annot = True, cmap = \"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights:\n\nWe observe the following correlations from the plot.\n\n- Most of the data point are 'NOT Normally' distributed\n- From paiplot and heatmat we could observe that there are features with high correations\n    - gdpp and income are most highly correlated with correlation of 0.9\n    - child_mortality and life_expentency are highly correlated with correlation of -0.89\n    - child_mortality and total_fertility are highly correlated with correlation of 0.85\n    - imports and exports are highly correlated with correlation of 0.74\n    - life_expentency and total_fertility are highly correlated with correlation of -0.76"},{"metadata":{},"cell_type":"markdown","source":"#### 3.3. Outlier Treatment"},{"metadata":{},"cell_type":"markdown","source":"- `child_mort`: It has outliers beyond higher boundary but we will not do any imputation as we are concernened about the higher child_mort\n- `export`, `helath`, `imports`, `total_fer` and `gdpp` : It has outlier at higher level. We will impute outlier to upper capping (0.99 percentile)\n- `life_expec` : It has outlers bellow the lower boundary, But we are intersted on these values so we will not impute these values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting the numerical columns and dropping the country\ndf1 = df.drop('country', axis =1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# list cols for upper caping and get insigts of data\ncols = ['exports', 'health', 'imports', 'total_fer','gdpp']\ndf1[cols].describe(percentiles= [0.01,0.25,0.5,0.75,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# upper caping\ncap = 0.99\nfor col in cols:\n    HL = round(df1[col].quantile(cap),2)\n    df1[col] = df1[col].apply(lambda x: HL if x>HL else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive statistics after capping\ndf1[cols].describe(percentiles= [0.01,0.25,0.5,0.75,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check outliers after capping\ndf1[cols].plot.box(subplots = True, figsize = (18,6), fontsize = 12)\nplt.tight_layout(pad=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights: \n- There are still some outliers exists but, we will choose to keep them and proceed for modeling."},{"metadata":{},"cell_type":"markdown","source":"### 4. Feature Scaling"},{"metadata":{},"cell_type":"markdown","source":"Their range of all the features are different which indicates the need of standardising the data before we build the model. Since we need to compute the Euclidean distance between the data points, it is important to ensure that the attributes with a larger range of values do not out-weight the attributes with smaller range. Thus, scaling down of all attributes to the same normal scale is important here."},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset columns\ndf1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a scaling object\nscaler = MinMaxScaler()\n\n# fit_transform\ndf_scaled = scaler.fit_transform(df1)\ndf_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Hopkins Statistics\n\nBefore we apply any clustering algorithm to the given data, it's important to check whether the given data has some meaningful clusters or not? which in general means the given data is not random. The process to evaluate the data to check if the data is feasible for clustering or not is know as the clustering tendency. To check cluster tendency, we use Hopkins test. Hopkins test examines whether data points differ significantly from uniformly distributed data in the multidimensional space.\n- If the value is between {0.01, ...,0.3}, the data is regularly spaced.\n- If the value is around 0.5, it is random.\n- If the value is between {0.7, ..., 0.99}, it has a high tendency to cluster."},{"metadata":{"trusted":true},"cell_type":"code","source":"# function hopkin statustics\n\nfrom random import sample\nfrom numpy.random import uniform\nfrom math import isnan\n \ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    H = sum(ujd) / (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dataframe of sclaled fetaures\ndf_scaled = pd.DataFrame(df_scaled, columns = df1.columns)\n\n# Evaluate Hopkins Statistics\nprint('Hopkins statistics is: ', round(hopkins(df_scaled),2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight: \n- Hopkins Statistic over .70 is a good score that indicated that the data is good for cluster analysis. \n- A 'Hopkins Statistic' value close to 1 tends to indicate the data is highly clustered, random data will tend to result in values around 0.5, and uniformly distributed data will tend to result in values close to 0."},{"metadata":{},"cell_type":"markdown","source":"### 6.  Clustering\n"},{"metadata":{},"cell_type":"markdown","source":"#### 6.1 K-Means Clustering\n\nK-means is a type of unsupervised learning which is considered as one of the most used algorithms due to its simplicity. To process the learning data, the K-means algorithm in data mining starts with a first group of randomly selected centroids, which are used as the beginning points for every cluster, and then performs iterative (repetitive) calculations to optimize the positions of the centroids. The ‘means’ in the K-means refers to averaging of the data; that is, finding the centroid."},{"metadata":{},"cell_type":"markdown","source":"**6.1.1 Run K-Means and choose K using both Elbow and Silhouette score**"},{"metadata":{},"cell_type":"markdown","source":"**A. Sum of the Sqaured Distance Matrix (SSD)or (Elbow curve)**: In Elbow Curve method, the total within-cluster sum of square measures the compactness of the clustering and it should be as small as possible for better clustering results."},{"metadata":{"trusted":true},"cell_type":"code","source":"# CHeking the dataframe\ndf_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check shape\ndf_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating list of clusters for no of cluster\nnum_clusers = list(range(1,11))\nssd = []\nfor clustuer in num_clusers:\n    kmeans = KMeans(n_clusters=clustuer, max_iter= 50)\n    kmeans.fit(df_scaled)\n    ssd.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pltng elbow method plot\nplt.figure(figsize=(10,6))\nplt.plot(num_clusers,ssd, marker = 'o')\nplt.title('Elbow Method', fontsize = 16)\nplt.xlabel('Number of clusters',fontsize=12)\nplt.ylabel('Sum of Squared distance',fontsize=12)\nplt.vlines(x=3, ymax=ssd[-1], ymin=ssd[0], colors=\"r\", linestyles=\"-\")\nplt.hlines(y=ssd[2], xmax=9, xmin=1, colors=\"r\", linestyles=\"--\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**B. Silhouette Analysis** : The average silhouette approach measures the quality of a clustering. That is, it determines how well each object lies within its cluster. A high average silhouette width indicates a good clustering.\n\n$$\\text{silhouette score}=\\frac{p-q}{max(p,q)}$$\n\n$p$ is the mean distance to the points in the nearest cluster that the data point is not a part of it (inter-cluster)\n\n$q$ is the mean intra-cluster distance to all the points in its own cluster.\n\n* The value of the silhouette score range lies between -1 to 1. \n\n* A score closer to 1 indicates that the data point is very similar to other data points in the cluster, \n\n* A score closer to 0 indicates that the data point is not in the cluster, \n\n* A score closer to -1 indicates that the data point is not similar to the data points in its cluster."},{"metadata":{"trusted":true},"cell_type":"code","source":"# silhouette analysis\nnum_clusters = list(range(2,11))\nss = []\nfor cluster in num_clusters:\n    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters= cluster, max_iter=50)\n    kmeans.fit(df_scaled)\n    \n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = round(silhouette_score(df_scaled, cluster_labels),4)\n    ss.append(silhouette_avg)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(cluster, silhouette_avg))\n\n\nplt.plot(num_clusters,pd.DataFrame(ss)[0])\nplt.title('Silhouette Score', fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight: \n- The maximum silhouette score is at cluster no 3\n- There is less reduction in sum of squared distance after cluster 3 in elbow method.\n\nWith above two methods to select optimum cluster we would choose `3 clusters` as optimal no.\n"},{"metadata":{},"cell_type":"markdown","source":"**6.1.2 Run K-Means with the chosen K**\n\nChoosing the model from the above results, we could see that using 3 Clusters provided a better output in terms of a balanced cluster size. So we will consider the 'K-Means with 3 Clusters' as our FINAL MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Mean with k =3\nkmeans = KMeans(n_clusters = 3, max_iter = 50, random_state= 50)\nkmeans.fit(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we need to assign the Cluster IDs that we generated to each of the datapoints that we have with us"},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding produced labels dataframe\ndf_country = df.copy()\ndf_country['KMean_clusterid']= pd.Series(kmeans.labels_)\ndf_country.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the no of countries in each cluster\ndf_country.KMean_clusterid.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6.1.3 Visualisation and Cluster Analysis (K Mean Cluster)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter plot on various variables to visualize the clusters based on them\n\nplt.figure(figsize=(18, 5))\nplt.subplot(1, 3, 1)\nsns.scatterplot(x='gdpp', y='child_mort', hue='KMean_clusterid', data=df_country, palette=\"bright\", alpha=.4)\n\nplt.subplot(1, 3, 2)\nsns.scatterplot(x='income', y='child_mort', hue='KMean_clusterid',data=df_country, palette=\"bright\", alpha=.4)\n\nplt.subplot(1, 3, 3)\nsns.scatterplot(x='gdpp', y='income', hue='KMean_clusterid', data=df_country, palette=\"bright\", alpha=.4)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Clusters are clearly visable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualising clusters\nplt.figure(figsize=(18,5))\nplt.subplot(1,3,1)\nsns.barplot(x = 'KMean_clusterid', y = 'gdpp', data=df_country, palette=\"bright\")\nplt.title('GDP Percapita')\n\nplt.subplot(1,3,2)\nsns.barplot(x = 'KMean_clusterid', y = 'child_mort', data=df_country, palette=\"bright\")\nplt.title('Child Mortality Rate')\n\nplt.subplot(1,3,3)\nsns.barplot(x = 'KMean_clusterid', y = 'income', data=df_country, palette=\"bright\")\nplt.title('Income Per Person')\n\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"INSIGHT: \n- Its clearly showing that the cluster 2 having highest Child Mortality and lowest Income & GDPP and comes under undeveloped countries"},{"metadata":{},"cell_type":"markdown","source":"**6.1.4 Clustering profiling using “gdpp, child_mort and income”**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cheking the cluter means\ndf_country.groupby(['KMean_clusterid']).mean().sort_values(['child_mort','income','gdpp'],ascending = [False,True,True])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New dataframe for group by & analysis\n\ndf_country_analysis =  df_country.groupby(['KMean_clusterid']).mean().sort_values(['child_mort','income','gdpp'],ascending = [False,True,True])\ndf_country_analysis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"INSIGHT: \nThe mean of `gdpp, child_mort and income` shows that there is good inter cluster distance.\n\nFrom  the mean of clusters we could see that,\n> - cluster 0 : Developing\n> - Cluster 1: Developed\n> - Cluste 2: Undeveloped\n\nWe are intrested on cluster 2 in KMean Clusters"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Creating a new field for count of observations in each cluster\n\ndf_country_analysis['Observations']=df_country[['KMean_clusterid','child_mort']].groupby(['KMean_clusterid']).count()\ndf_country_analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a new field for proportion of observations in each cluster\n\ndf_country_analysis['Proportion']=round(df_country_analysis['Observations']/df_country_analysis['Observations'].sum(),2)\n\n\n#Summary View\ndf_country_analysis[['child_mort','income','gdpp','Observations','Proportion']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot1 between income and gdpp against cluster_lables3\nplt.figure (figsize = (15,10))\n\ndf_country_plot1 = df_country[['KMean_clusterid', 'gdpp', 'income']].copy()\ndf_country_plot1 = df_country_plot1.groupby('KMean_clusterid').mean()\ndf_country_plot1.plot.bar()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot 2 between child_mort and cluster_labels\n\nplt.figure (figsize = (15,10))\n\ndf_country_plot2 = df_country[['KMean_clusterid', 'child_mort']].copy()\ndf_country_plot2 = df_country_plot2.groupby('KMean_clusterid').mean()\ndf_country_plot2.plot.bar()\n\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpretation of Clusters: \n- Cluster 2 has the Highest average Child Mortality rate of ~92 when compared to other clusters, and Lowest average GDPP & Income of ~ 1909 & 3897 respectively. \n- All these figures clearly makes this cluster the best candidate for the financial aid from NGO. We could also see that Cluster 2 comprises of ~29% of overall data, and has ~48 observations in comparision to 167 total observations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort based on 'child_mort','income','gdpp' in respective order\nK_cluster_Undeveloped = df_country[df_country['KMean_clusterid']== 2]\nK_top5 = K_cluster_Undeveloped.sort_values(by = ['gdpp','income','child_mort'],\n                                                     ascending=[True, True, False]).head(5)\n\nprint( 'Top 5 countries dire need of aid  based on K cluster are:' , K_top5['country'].values )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights:\n- Top 5 countries dire need of aid  based on K cluster are: \n    1. 'Burundi' \n    2. 'Liberia' \n    3. 'Congo, Dem. Rep.' \n    4. 'Niger' \n    5. 'Sierra Leone'"},{"metadata":{},"cell_type":"markdown","source":"#### 6.2 Hierarchical Clustering\n\nHierarchical clustering is an unsupervised learning technique that groups data over a variety of scales by creating a cluster tree or dendrogram. The tree is not a single set of clusters, but rather a multilevel hierarchy, where clusters at one level are joined as clusters at the next level.\n\nAs mentioned in the 'Approach' section, we will use Hierarchical Clustering to identify appropriate cluster size with a good split of data (Max Intra-Cluster distance & Min Inter-Cluster Distance)\n\nWe will perform hierarchical clustering using methods single linkage, complete linkage, and ward and select the one which yields the best result."},{"metadata":{"trusted":true},"cell_type":"code","source":"# new dataset check\ndf_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6.2.1 Use both Single and Complete linkage**"},{"metadata":{},"cell_type":"markdown","source":"**A. <font color = brown> Single Linkage:<font>** Here, the distance between 2 clusters is defined as the `shortest` distance between points in the two clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Utilise the single linkage method for clustering this dataset \nplt.figure(figsize = (18,8))\nmergings = linkage(df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights:\n\n- The clusters of the single linkage are not truly satisfying. The single linkage method appears to be placing each outlier in its own cluster.\n\n- As you can clearly see, single linkage doesn't produce a good enough result for us to analyse the clusters. Hence, we need to go ahead and utilise the complete linkage method and then analyse the clusters once again."},{"metadata":{},"cell_type":"markdown","source":"**B. <font color = brown> Complete Linkage:<font>** Here, the distance between 2 clusters is defined as the `maximum` distance between points in the two clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Utilise the complete linkage method for clustering this dataset.\n\nplt.figure(figsize = (18,8))\nmergings = linkage(df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight:\n- From the above Dendrograms, it is evident that 'Complete Linkage' give a better cluster formation. \n- So we will use Complete linkage output for our further analysis.\n- We will build two iterations of clustering with 3 & 4 clusters and analyse the output"},{"metadata":{},"cell_type":"markdown","source":"**6.2.2 Choose one method based on the results**"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Creating the labels\ncluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\ncluster_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assign cluster labels\n#df_country = df.copy()\ndf_country['H_ClusterID'] = pd.Series(cluster_labels)\ndf_country.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6.2.3 Visualise the clusters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cheking the new dataframe shape\ndf_country.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter plot on various variables to visualize the clusters based on them\n\nplt.figure(figsize=(18, 5))\nplt.subplot(1, 3, 1)\nsns.scatterplot(x='gdpp', y='child_mort', hue='H_ClusterID', data=df_country, palette=\"bright\", alpha=.4)\n\nplt.subplot(1, 3, 2)\nsns.scatterplot(x='income', y='child_mort', hue='H_ClusterID',data=df_country, palette=\"bright\", alpha=.4)\n\nplt.subplot(1, 3, 3)\nsns.scatterplot(x='gdpp', y='income', hue='H_ClusterID', data=df_country, palette=\"bright\", alpha=.4)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Clearly clusters are visable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualising clusters\nplt.figure(figsize=(18,5))\nplt.subplot(1,3,1)\nsns.barplot(x = 'H_ClusterID', y = 'gdpp', data=df_country, palette=\"bright\")\nplt.title('GDP Percapita')\n\nplt.subplot(1,3,2)\nsns.barplot(x = 'H_ClusterID', y = 'child_mort', data=df_country, palette=\"bright\")\nplt.title('Child Mortality Rate')\n\nplt.subplot(1,3,3)\nsns.barplot(x = 'H_ClusterID', y = 'income', data=df_country, palette=\"bright\")\nplt.title('Income Per Person')\n\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"INSIGHT: \n- Its clearly showing that the cluster 0 having highest Child Mortality and lowest Income & GDPP and its comes under undevloped conutries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cheking the cluster count\ndf_country.H_ClusterID.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the countries in Cluster 2 to see which are the countries in that segment.\ncluster_2 = df_country[df_country['H_ClusterID']==2]\ncluster_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the countries in Cluster 1 to see which are the countries in that segment.\ncluster_1 = df_country[df_country['H_ClusterID']== 1]\ncluster_1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight:\n- Clusters 2 & 1 seems to be Developed or Developing countries, so our segmentation is good in terms of all our under developed countries are segmented under cluster 0. "},{"metadata":{},"cell_type":"markdown","source":"**6.2.4 Clustering profiling using “gdpp, child_mort and income”**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#New dataframe for group by & analysis\ndf_country_analysis = df_country.groupby(['H_ClusterID']).mean()\ndf_country_analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a new field for count of observations in each cluster\ndf_country_analysis['Observations'] = df_country[['H_ClusterID', 'child_mort']].groupby(['H_ClusterID']).count()\ndf_country_analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a new field for proportion of observations in each cluster\ndf_country_analysis['Proportion'] = round(df_country_analysis ['Observations'] / (df_country_analysis ['Observations'].sum()),2)\ndf_country_analysis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights:\n\nFrom  the mean of clusters we could see that,\n> - cluster 0 : Undeveloped\n> - Cluster 1: Developing\n> - Cluste 2 : Developed\n\nWe are intrested on cluster 0 as objective is to find top 5 undevelped countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot1 between income and gdpp against cluster_lables3\nplt.figure (figsize = (15,10))\n\ndf_country_plot1 = df_country[['H_ClusterID', 'gdpp', 'income']].copy()\ndf_country_plot1 = df_country_plot1.groupby('H_ClusterID').mean()\ndf_country_plot1.plot.bar()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot 2 between child_mort and cluster_labels\n\nplt.figure (figsize = (15,10))\n\ndf_country_plot2 = df_country[['H_ClusterID', 'child_mort']].copy()\ndf_country_plot2 = df_country_plot2.groupby('H_ClusterID').mean()\ndf_country_plot2.plot.bar()\n\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpretation of Clusters: \n- Cluster 0 has the Highest average Child Mortality rate of ~42 when compared to other 3 clusters, and Lowest average GDPP & Income of ~ 7551 & 12641 respectively. \n- All these figures clearly makes this cluster the best candidate for the financial aid from NGO. \n- We could also see that Cluster 1 comprises of ~89% of overall data, and has ~148 observations in comparision to 167 total observations This seems to be a problem. \n- This means that Hierarchical clustering is not giving us a good result as 89% of the data points are segmented into that cluster. \n- We also saw that increasing the cluster number is not solving this problem. We will perform K-Means Clustering and check how that turns out to be."},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort based on 'child_mort','income','gdpp' in respective order\nH_cluster_Undeveloped = df_country[df_country['H_ClusterID']== 0]\nH_top5 = H_cluster_Undeveloped.sort_values(by = ['gdpp','income','child_mort'],\n                                                     ascending=[True, True, False]).head(5)\n\nprint( 'Top 5 countries dire need of aid  based on H cluster are:' , H_top5['country'].values )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From Hierarchical Clusturing we could get top 5 undeveloped countries are:\n1. 'Burundi' \n2. 'Liberia' \n3. 'Congo, Dem. Rep.'\n4. 'Niger' \n5. 'Sierra Leone' `"},{"metadata":{},"cell_type":"markdown","source":"### 7. Clustering Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the % of cluster distribution\nH_cluster_per = df_country.H_ClusterID.value_counts(normalize = True)*100\nprint('Hierarchical Clustering Countries %:')\nprint(df_country.H_ClusterID.value_counts(normalize = True)*100)\n\nK_cluster_per = df_country.KMean_clusterid.value_counts(normalize = True)*100\nprint('\\nKMean Clustering Countries %:')\nprint(df_country.KMean_clusterid.value_counts(normalize = True)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insights:\n- The above data shows KMean is better cluseted in the term of distribution of countries. \n- So we will be creating the final cluser with KMean cluster and doing profiling considering the labels accordingly."},{"metadata":{"trusted":true},"cell_type":"code","source":"# barplot for cluster distribution\nplt.figure(figsize=(16,4))\nplt.subplot(1,2,1)\nsns.barplot(x= H_cluster_per.index, y = H_cluster_per)\nplt.title('Hierarchical Cluster Distribution')\nplt.xlabel('ClusterID')\nplt.ylabel('Percentage Distribution')\n\nplt.subplot(1,2,2)\nsns.barplot(x= K_cluster_per.index, y = K_cluster_per)\nplt.title('KMean Cluster Distribution')\nplt.xlabel('ClusterID')\nplt.ylabel('Percentage Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cluster Summary**\n\n- From above analysis we could see KMean is having better distributed cluster. So we will select final model as KMean cluster and doing profiling considering the labels accordingly.\n- Kindly note that both the model has resulted the same coutries as top 5 undeveloped county.\n- By comparing averages of K-means we can conclude that\n    - Cluster 1 belongs to `Undeveloped` Countries,\n    - Cluster 2 belongs to `Developed` Countries\n    - Cluster 0 belongs to `Developing` Countries.\n\nTo differentiate the clusters of developed countries from the clusters of under-developed countries, the notation can be changes and labeled as, {0: developed, 1:developing, 2: Undeveloped}\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final labels\ndf_country['ClusterLabels'] = df_country['KMean_clusterid'].map({0: 'Developed', 1:'Developing', 2: 'Undeveloped'})\ndf_country.head()                                                      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select final data frame for profiling\nK_cluster = df_country[['country','gdpp','child_mort','income','ClusterLabels']]\nK_cluster.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Final Cluster:** \n- Based on the above interpretation of the cluster, we now rename all the clusters accordingly. \n- The Cluster 2 now becomes 'Undeveloped Countries', which will be of our interest.\n- We will further analyse the Cluster 'Undeveloped Countries' and get to know various metrics of that data set, based on which we could identify our final set of countries which needs the financial support from the NGO"},{"metadata":{},"cell_type":"markdown","source":"### 8. Analysing the 'Under Developed Countries (UDC)' Cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subset data frame based on undeveloped countries\nK_cluster_UDC = K_cluster[K_cluster['ClusterLabels'] == 'Undeveloped']\nK_cluster_UDC.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We wiil prioritize soft the features on the order of gdpp, income and child_mort with below understanding,\n - `gdpp` and `income` are highly `+ve` correlated.\n - `gdpp` and `income` both have `-ve` correlation with `child_mort`.\n - Finalcial aid will directly improve `gdpp` and `income` and thus child_mort can be reduced."},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort based on 'child_mort','income','gdpp' in respective order\nK_top5=K_cluster_UDC.sort_values(by = ['gdpp','income', 'child_mort']).head(5).copy()\n\nK_top5 = K_top5[['country','gdpp','income', 'child_mort']]\n#Final country list\nK_top5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insight:\n- Coutries (5 most) dire need of aid are: `['Burundi' 'Liberia' 'Congo, Dem. Rep.' 'Niger' 'Sierra Leone']`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot for final top5 countries based on child_nort, gdpp and income\n\nKMean_plot = K_top5.set_index('country')\nKMean_plot.plot.bar(figsize = (8,4))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bivariate Analysis of Cluster 'Under_Developed_Countries' (recommended 5)\n\n# Scatter plot on various variables to visualize the clusters based on them\n\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nsns.scatterplot(x='gdpp', y='child_mort', hue='country',\n                data=K_top5, legend='full', palette=\"bright\", s=300, c='lightblue')\nplt.subplot(1, 3, 2)\nsns.scatterplot(x='gdpp', y='income', hue='country',\n                data=K_top5, legend='full', palette=\"bright\", s=300, c='lightblue')\nplt.subplot(1, 3, 3)\nsns.scatterplot(x='income', y='child_mort', hue='country',\n                data=K_top5, legend='full', palette=\"bright\", s=300, c='lightblue')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive Statistics\nK_top5.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9. <font color = Green> Conclusion"},{"metadata":{"trusted":true},"cell_type":"code","source":"#TOP COUNTRIES recommended for Financial bases on KMean Clustering analysis\nprint( 'Top 5 countries dire need of aid:' , K_top5['country'].values )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Final Result**:-\n\n- Performed CLUSTERING on the socio-economic data provided for various countries to identify countries to recommend for Financial Aid from the NGO. \n- Based on our Clustering Analysis, I have identified the top countries under our 'Undeveloped Countries' cluster which are in dire need of the Financial Aid. This output is purely based on the dataset we used and various analytical methodology we performed.\n\n**Finanical Aid required countries on priority bases:**\n<font color = 'Brown'> \n1. Burundi\n2. Liberia\n3. Congo, Dem. Rep.\n4. Niger\n5. Sierra Leone \n<font>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}