{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for data visualization purposes\nimport seaborn as sns # for data visualization\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN\n","metadata":{}},{"cell_type":"code","source":"data = '../input/ucibreastcancerwisconsincleaned/UCI-breast-cancer-wisconsin-data.csv'\n\ndf = pd.read_csv(data, header=None)\n\ndf.drop(index=0, axis=0, inplace=True)\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there are 683 instances and 10 attributes in the data set. \ni removed id attribute\n\nIn the dataset description, it is given that there are 10 attributes and 1 `Class` which is the target variable. So, we have 10 attributes and 1 target variable.","metadata":{}},{"cell_type":"markdown","source":"### View top 5 rows of dataset","metadata":{}},{"cell_type":"code","source":"# preview the dataset\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rename column names\n\nWe can see that the dataset does not have proper column names. The columns are merely labelled as 0,1,2.... and so on. We should give proper names to the columns. I will do it as follows:-","metadata":{}},{"cell_type":"code","source":"col_names = [ 'Clump_thickness', 'Uniformity_Cell_Size', 'Uniformity_Cell_Shape', 'Marginal_Adhesion', \n             'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class']\n\ndf.columns = col_names\n\ndf.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the column names are renamed. Now, the columns have meaningful names.","metadata":{}},{"cell_type":"code","source":"# let's agian preview the dataset\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### View summary of dataset\n","metadata":{}},{"cell_type":"code","source":"# view summary of dataset\n\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the `Id` column has been removed from the dataset. \n\nWe can see that there are 9 numerical variables and 1 categorical variable in the dataset. I will check the frequency distribution of values in the variables to confirm the same.","metadata":{}},{"cell_type":"markdown","source":"### Check data types of columns of dataframe","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    df[i] = pd.to_numeric(df[i], errors='coerce') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can see that all the columns of the dataframe are of type numeric.","metadata":{}},{"cell_type":"markdown","source":"### Summary of variables\n\n\n- There are 10 numerical variables in the dataset.\n\n\n- All of the variables are of discrete type.\n\n\n- Out of all the 10 variables, the first 9 variables are feature variables and last variable `Class` is the target variable.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# **9. Declare feature vector and target variable** <a class=\"anchor\" id=\"9\"></a>\n ","metadata":{}},{"cell_type":"code","source":"X = df.drop(['Class'], axis=1)\n\nY = df['Class']\n\nX.head()\n\n \n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print frequency distribution of classes\nprint(Y.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split X and y into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size = 0.25, random_state = 8)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape of X_train and X_test\n\nX_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have training and testing set ready.","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"code","source":"cols = X_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train, columns=[cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = pd.DataFrame(X_test, columns=[cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have `X_train` dataset ready to be fed into the Logistic Regression classifier. I will do it as follows.","metadata":{}},{"cell_type":"markdown","source":"# **13. Fit K Neighbours Classifier to the training eet** <a class=\"anchor\" id=\"13\"></a>\n ","metadata":{}},{"cell_type":"code","source":"# import KNeighbors ClaSSifier from sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n# instantiate the model\nknn = KNeighborsClassifier(n_neighbors=5,weights='distance')\n\n\n# fit the model to the training set\nknn.fit(X_train, Y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **14. Predict test-set results** \n ","metadata":{}},{"cell_type":"code","source":"Y_pred = knn.predict(X_test)\n\nY_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **15. Check Train and test errors ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint('Model test error: {0:0.4f}'. format(1-accuracy_score( Y_test, Y_pred )))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, **y_test** are the true class labels and **y_pred** are the predicted class labels in the test-set.","metadata":{}},{"cell_type":"code","source":"Y_pred_train = knn.predict(X_train)\nprint('Training-set error: {0:0.4f}'. format(1-accuracy_score(Y_train, Y_pred_train)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **17. Confusion matrix**  \n\n","metadata":{}},{"cell_type":"code","source":"# Print the Confusion Matrix with k =3 and slice it into four pieces\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(Y_test, Y_pred)\n\nprint('Confusion matrix\\n\\n', cm)\n\nprint('\\nTrue Positives(TP) = ', cm[0,0])\n\nprint('\\nTrue Negatives(TN) = ', cm[1,1])\n\nprint('\\nFalse Positives(FP) = ', cm[0,1])\n\nprint('\\nFalse Negatives(FN) = ', cm[1,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **18. Classification metrices** ","metadata":{}},{"cell_type":"code","source":"TP = cm[0,0]\nTN = cm[1,1]\nFP = cm[0,1]\nFN = cm[1,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Precision\n","metadata":{}},{"cell_type":"code","source":"# print precision score\n\nprecision = TP / float(TP + FP)\n\n\nprint('Precision : {0:0.4f}'.format(precision))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Recall or TP Rate\n\n\n","metadata":{}},{"cell_type":"code","source":"recall = TP / float(TP + FN)\n\nprint('Recall or Sensitivity : {0:0.4f}'.format(recall))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### f1-score\n","metadata":{}},{"cell_type":"code","source":"f1_score=2*precision*recall/ (precision+recall)\nprint( \"F1_score: \",f1_score)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree","metadata":{}},{"cell_type":"code","source":"# import DecisionTreeClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# instantiate the DecisionTreeClassifier model with criterion gini index\n\ngini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\ngini.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_dt = gini.predict(X_test)\nprint('Model Test error with criterion gini index: {0:0.4f}'. format(1-accuracy_score(Y_test, Y_pred_dt)))\nY_pred_train_dt = gini.predict(X_train)\n\nprint('Model Train error with criterion gini index: {0:0.4f}'. format(1-accuracy_score(Y_train, Y_pred_train_dt)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_dt = confusion_matrix(Y_test, Y_pred_dt)\n \n\nTP_dt=cm_dt[0,0]\nTN_dt=cm_dt[1,1]\nFP_dt=cm_dt[0,1]\nFN_dt=cm_dt[1,0]\n\nprint('Confusion matrix\\n\\n', cm_dt)\n\nprint('\\nTrue Positives(TP) = ', TP_dt)\n\nprint('\\nTrue Negatives(TN) = ', TN_dt)\n\nprint('\\nFalse Positives(FP) = ', FP_dt)\n\nprint('\\nFalse Negatives(FN) = ', FN_dt)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print precision score\n\nprecision_dt = TP_dt / float(TP_dt + FP_dt)\n\n\nprint('Precision : {0:0.4f}'.format(precision_dt))\n\nrecall_dt = TP_dt / float(TP_dt + FN_dt)\n\nprint('Recall or Sensitivity : {0:0.4f}'.format(recall_dt))\n\nf1_score_dt=(2*precision_dt*recall_dt)/(precision_dt+recall_dt)\n\nprint('F1 score : {0:0.4f}'.format(f1_score_dt))\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\n\n# instantiate the model\ngnb = GaussianNB()\n\n\n# fit the model\ngnb.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_nbc = gnb.predict(X_test)\n\nY_pred_nbc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Model Test error: {0:0.4f}'. format(1-accuracy_score(Y_test, Y_pred_nbc)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_train_nbc= gnb.predict(X_train)\n\nprint('Model Train error: {0:0.4f}'. format(1-accuracy_score(Y_train, Y_pred_train_nbc)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training-set accuracy score is 0.9629 while the test-set accuracy to be 0.9649. These two values are quite comparable. So, there is no sign of overfitting.","metadata":{}},{"cell_type":"code","source":"cm_nbc = confusion_matrix(Y_test, Y_pred_nbc)\n\nprint('Confusion matrix\\n\\n', cm_nbc)\n\nprint('\\nTrue Positives(TP) = ', cm_nbc[0,0])\n\nprint('\\nTrue Negatives(TN) = ', cm_nbc[1,1])\n\nprint('\\nFalse Positives(FP) = ', cm_nbc[0,1])\n\nprint('\\nFalse Negatives(FN) = ', cm_nbc[1,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP_nbc = cm_nbc[0,0]\nTN_nbc = cm_nbc[1,1]\nFP_nbc = cm_nbc[0,1]\nFN_nbc = cm_nbc[1,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# precision \n\nprecision_nbc = TP_nbc / float(TP_nbc + FP_nbc)\n\n\nprint('Precision : {0:0.4f}'.format(precision_nbc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_nbc = TP_nbc / float(TP_nbc + FN_nbc)\n\nprint('Recall or Sensitivity : {0:0.4f}'.format(recall_nbc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score_nbc=2*precision_nbc*recall_nbc/ (precision_nbc+recall_nbc)\nprint('F1 score: {0:0.4f}'.format(f1_score_nbc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ANN - ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = '../input/ucibreastcancerwisconsincleaned/UCI-breast-cancer-wisconsin-data.csv'\ncol_names = [ 'Clump_thickness', 'Uniformity_Cell_Size', 'Uniformity_Cell_Shape', 'Marginal_Adhesion', \n             'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class']\n \ndf_ann = pd.read_csv(data,names=col_names, header=None)\n\ndf_ann.drop(index=0, axis=0, inplace=True)\ndf_ann.head()\ndataset = df_ann.values\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dataset[:,:-1]\n\nscaler = StandardScaler()\nX_scale = scaler.fit_transform(X)\nY = dataset[:,-1]\n\n# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X_1 = LabelEncoder()\ny = labelencoder_X_1.fit_transform(Y)\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(X_scale, y, test_size=0.25,random_state=8)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train_and_val, Y_train_and_val, test_size=0.1)\n\nprint(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Dense(32, activation='relu', input_shape=(9,)),\n    Dense(32, activation='relu'),\n    Dense(1, activation='sigmoid'),\n])\ndef compile_and_fit(model,verbose):\n    model.compile(optimizer='sgd',\n              loss='binary_crossentropy',\n              metrics=['accuracy' ])\n    hist = model.fit(X_train, Y_train,\n          batch_size=32, epochs=100,verbose=verbose,\n          validation_data=(X_val, Y_val))\n    return hist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist=compile_and_fit(model,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def error_model(model):\n    print(\"Train error:\",1- (model.evaluate(X_train, Y_train)[1]))\n    print(\"Test error:\",1-(model.evaluate(X_test, Y_test)[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def metrics(model):\n    y_pred = model.predict(X_test)\n    cm_ann = confusion_matrix(Y_test, np.rint(y_pred))\n    print(\"Confusion Matrix:\\n\",cm_ann)\n    TP_ann=cm_ann[0,0]\n    TN_ann=cm_ann[1,1]\n    FP_ann=cm_ann[0,1]\n    FN_ann=cm_ann[1,0]\n    print(\"TP :\",TP_ann)\n    print(\"TN :\",TN_ann)\n    print(\"FP :\",FP_ann)\n    print(\"FN :\",FN_ann)\n\n\n\n    # print precision score\n\n    precision_ann = TP_ann / float(TP_ann + FP_ann)\n\n    print('Precision : {0:0.4f}'.format(precision_ann))\n\n    recall_ann = TP_ann / float(TP_ann + FN_ann)\n\n    print('Recall or Sensitivity : {0:0.4f}'.format(recall_ann))\n\n    f1_score_ann=(2*precision_ann*recall_ann)/(precision_ann+recall_ann)\n\n    print('F1 score : {0:0.4f}'.format(f1_score_ann))\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"ANN metrics\")\nerror_model(model)\nprint()\nmetrics(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q2","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(hist):\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='upper right')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1) ReLU ","metadata":{}},{"cell_type":"code","source":"\nprint(\"ReLU activation\")\nerror_model(model)\nprint()\n# metrics(model)\nplot_loss(hist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Leaky ReLU","metadata":{}},{"cell_type":"code","source":"model1 = Sequential([\n    Dense(32,activation=keras.layers.LeakyReLU(alpha=0.02),input_shape=(9,)),\n    Dense(units=32, \n              activation=keras.layers.LeakyReLU(alpha=0.02)) ,\n    Dense(1, activation='sigmoid'),\n])\n\nhist1=compile_and_fit(model1,verbose=0)\n\nprint(\"Model 2- LeakyReLU\")\nerror_model(model1)\nprint()\n# metrics(model1)\nplot_loss(hist1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### tanh","metadata":{}},{"cell_type":"code","source":"model2 = Sequential([\n    Dense(32,activation='tanh',input_shape=(9,)),\n    Dense(units=32, \n              activation='tanh') ,\n    Dense(1, activation='sigmoid'),\n])\n\nhist2=compile_and_fit(model2,verbose=0)\nprint (\"model 3- tanh\")\nerror_model(model2)\nprint()\n# metrics(model2)\nplot_loss(hist2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  It is observed that while the training loss and validation loss are very close in the cases of all cases ReLU ,tanh and LeakyReLU. Also, validation loss is higher than train loss in all cases which is comparable to real world scenario. Hence, these models are not overfitting and are performing quite well.\n","metadata":{}},{"cell_type":"markdown","source":"# Q3","metadata":{}},{"cell_type":"code","source":"test_set_errors=[]\nnumber_of_nodes=[]\n\nmodel_1 = Sequential([\n    Dense(1, activation='relu', input_shape=(9,)),\n    Dense(1, activation='sigmoid' ),\n\n    \n])\nhist_1=compile_and_fit(model_1,0)\ntest_set_errors.append((1-model_1.evaluate(X_test, Y_test)[1]))\nnumber_of_nodes.append(1)\nprint(test_set_errors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nmodel_2 = Sequential([\n    Dense(10, activation='relu', input_shape=(9,)),\n    Dense(1, activation='sigmoid' ),\n\n    \n])\nhist_2=compile_and_fit(model_2,0)\ntest_set_errors.append((1-model_2.evaluate(X_test, Y_test)[1]))\nprint(test_set_errors)\nnumber_of_nodes.append(2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nmodel_3 = Sequential([\n    Dense(3, activation='relu', input_shape=(9,)),\n    Dense(1, activation='sigmoid' ),\n\n    \n])\nhist_3=compile_and_fit(model_3,0)\ntest_set_errors.append((1-model_3.evaluate(X_test, Y_test)[1]))\nnumber_of_nodes.append(3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num=len(col_names)-1\nprint(\"Num of features:\",num)\nnum=int(np.sqrt(num))\nprint(\"Square root of features:\",num)\nmodel_sqrt_features = Sequential([\n    Dense(num, activation='relu', input_shape=(9,)),\n    Dense(1, activation='sigmoid' ),\n\n    \n])\nhist_4=compile_and_fit(model_sqrt_features,0)\ntest_set_errors.append((1-model_sqrt_features.evaluate(X_test, Y_test)[1]))\nnumber_of_nodes.append(num)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num=len(col_names)-1\nprint(\"Num of features:\",num)\nnum=int(num/2)\nprint(\"Half of features:\",num)\nmodel_half_features = Sequential([\n    Dense(num, activation='relu', input_shape=(9,)),\n    Dense(1, activation='sigmoid' ),\n\n    \n])\nhist_5=compile_and_fit(model_half_features,0)\ntest_set_errors.append((1-model_half_features.evaluate(X_test, Y_test)[1]))\nnumber_of_nodes.append(num)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_set_errors)\nplt.plot(number_of_nodes,test_set_errors,) \nplt.title('Test set errors vs. Number of nodes')\nplt.ylabel('Test set errors ')\nplt.xlabel('Number of nodes')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test set error decreases as model complexity increases","metadata":{}}]}