{"cells":[{"metadata":{"_cell_guid":"690f98f7-648f-4146-8aa4-6a47fbb72883","_uuid":"d6576d078c298c71f783ae570d9e1941be2924ed"},"cell_type":"markdown","source":"# Sentiment Analysis (PT-BR)\n\nSample forked from @leandrodoze"},{"metadata":{"_cell_guid":"6f03ca1a-3c0e-4e33-9ba6-91a9d640185f","_uuid":"2840dd041b764e287b641cc8308c68c520796d9b","collapsed":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\nimport nltk\nimport re\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_predict\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"-l\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a9cdc1e8-0e19-4f98-a377-1a8efa50331c","_uuid":"af447214f6b3b7791f19e4a17488198659a5e6ab"},"cell_type":"markdown","source":"## 1. Tweets dataset"},{"metadata":{"_cell_guid":"f1f48f72-4db1-4734-8723-9ef52aedc7b0","_uuid":"7b761277e1b96610ba67f19b27b52d6658acd2bb","collapsed":true,"trusted":true},"cell_type":"code","source":"# Counting registers\ndataset = pd.read_csv('../input/Tweets_Mg.csv',encoding='utf-8')\ndataset.count()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f39fe03f-981f-4629-b79a-50098dd59924","_uuid":"73de912a022494b152d915d3ea31ca18c14d718b"},"cell_type":"markdown","source":"## 2. Model constructing"},{"metadata":{"_cell_guid":"eca2a77a-f355-41c5-ad4a-dfbe32af62f4","_uuid":"0b90c933012a38041e975f66a60f377915b92112","collapsed":true,"trusted":true},"cell_type":"code","source":"# Separating tweets from its classes\ntweets = dataset[\"Text\"].values\ntweets","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"69e04867-3f0f-47d2-88f5-df2127042d1b","_uuid":"866709548dc8dabc53c1c758f0bfdf410182a19d","collapsed":true,"trusted":true},"cell_type":"code","source":"classes = dataset[\"Classificacao\"].values\nclasses","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"007fbaef-b5d0-4fd7-92cc-2583ba668179","_uuid":"a376262987475125694411ecb7e129f07e84e8f3","collapsed":true,"trusted":true},"cell_type":"code","source":"# Model training using Bag of Words approach and Naive Bayes Multinomial algorithm\n#    - Bag of Words creates a vector with every word from the text, so it calculates the frequency\n#      that these words appears in a given sentece, then classify/train the model.\n#    - Hypothetical example of three sentences vectorized \"by word\" and classified in its \"word frequency\":\n#         {0,3,2,0,0,1,0,0,0,1, Positivo}\n#         {0,0,1,0,0,1,0,1,0,0, Negativo}\n#         {0,1,1,0,0,1,0,0,0,0, Neutro}\n#    - Looking at these vectors, my guess is that the words in positions 2 and 3 are the ones with the greatest \n#      weight in determining which class belongs to each of the three sentences evaluated\n#    - The function fit_transform do exactly this proccess: adjust the model, learn the vocabulary,\n#      and transforms the training data in feature vectors (vector with the words frequency)\n\nvectorizer = CountVectorizer(analyzer = \"word\")\nf_tweets = vectorizer.fit_transform(tweets)\n\nmodel = MultinomialNB()\nmodel.fit(f_tweets, classes)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"466d7f29-032e-4dec-9602-94dd38109d3a","_uuid":"f55fb6c880a34170862eaf35be8f594d9e280460"},"cell_type":"markdown","source":"## 3. Testing the model"},{"metadata":{"_cell_guid":"455dcddd-6b44-4a28-97c3-fa08f0fee171","_uuid":"68bc8d6fc38abf056dca0a39b687d1c381f8fd25","collapsed":true,"trusted":true},"cell_type":"code","source":"# Sentences to test with the created model\ntests = [\"Esse governo está no início, vamos ver o que vai dar\",\n         \"Estou muito feliz com o governo de São Paulo esse ano\",\n         \"O estado de Minas Gerais decretou calamidade financeira!!!\",\n         \"A segurança desse país está deixando a desejar\",\n         \"O governador de Minas é do PT\",\n         \"O prefeito de São Paulo está fazendo um ótimo trabalho\"]\n\nf_tests = vectorizer.transform(tests)\nmodel.predict(f_tests)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"179b67d3-0050-4188-a605-b70907e14336","_uuid":"170c7c69f73a7433a0554d44a98a62308e08fc9f"},"cell_type":"markdown","source":"## 4. Evaluating the model"},{"metadata":{"_cell_guid":"6afb7e0c-ce1c-497b-8f2f-02b75587954e","_uuid":"7cff21dfc9bb07fbce32ab78ed3073b13bdc021b","collapsed":true,"trusted":true},"cell_type":"code","source":"# Model Cross Validation. In this case, the model is divided in ten parts, trained in 9 and tested in 1\nresults = cross_val_predict(model, f_tweets, classes, cv = 10)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b6b63681-0961-4da4-bd40-3c73cf0884cd","_uuid":"e8eb430cb4d6449c8f173c27fbac4fc4ec711bb3","collapsed":true,"trusted":true},"cell_type":"code","source":"# What's the accuracy of the model?\nmetrics.accuracy_score(classes, results)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a2b917b7-da10-4403-b0a7-f6f88897e29d","_uuid":"1fb21da856cc6c4ee65f7daa95137dcdfbb51c0d","collapsed":true,"trusted":true},"cell_type":"code","source":"# Model validation measurements\nsentiments = [\"Positivo\", \"Negativo\", \"Neutro\"]\nprint(metrics.classification_report(classes, results, sentiments))\n\n#    : precision = true positive / (true positive + false positive)\n#    : recall    = true positive / (true positive + false negative)\n#    : f1-score  = 2 * ((precision * recall) / (precision + recall))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ffda64a4-e0cf-443c-bb53-a1a6f2024ae1","_uuid":"aaa2cc41ea529a09c8a3c8fe504457b02769ea59","collapsed":true,"trusted":true},"cell_type":"code","source":"# Confusion Matrix\nprint(pd.crosstab(classes, results, rownames = [\"Real\"], colnames=[\"Predict\"], margins=True))\n\n#    - Predict = The program classified Negativo, Neutro, Positivo and All\n#    - Real    = What is in fact Negativo, Neutro, Positivo and All\n#\n# That is, only 9 tweets was in fact negative and the program classified positive. But the\n# positives that the program classified negative was 45.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0354f18c-b26d-42e9-b5b8-945b931cc2a0","_uuid":"0c355e4fb76bd97a114473c71a49872dcd5b5c75"},"cell_type":"markdown","source":"## 5. Making the model better"},{"metadata":{"_cell_guid":"8dfc7e26-78fe-4233-89db-3795d4c360bd","_uuid":"c4db254fe1fa38a0d05067708d37e65f007eb118","collapsed":true,"trusted":true},"cell_type":"code","source":"# With the Bigrams model, instead of vectorize the text \"by word\", the text is vectorizes\n# by \"two words\", like: Eu gosto de São Paulo => { eu gosto, gosto de, de são, são paulo }\nvectorizer = CountVectorizer(ngram_range = (1, 2))\nf_tweets = vectorizer.fit_transform(tweets)\n\nmodel = MultinomialNB()\nmodel.fit(f_tweets, classes)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e918cdc1-a49c-4868-9218-047af413b4c5","_uuid":"a6b6fe306e4a46b24150f858d88fa9b49bb58575","collapsed":true,"trusted":true},"cell_type":"code","source":"# New prediction, using Bigrams\nresults = cross_val_predict(model, f_tweets, classes, cv = 10)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eeac7ad5-01ee-495b-b014-a3cbeda59abc","_uuid":"89647d6fedfb0d600c4d32bda31a95a4b7e6c83a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Checking the accuracy\nmetrics.accuracy_score(classes, results)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ac06ba72-6bd4-41c7-8175-e1604f179ee5","_uuid":"3ae3973a12114a23096b0d35dfa298c36340a901","trusted":true,"scrolled":true},"cell_type":"code","source":"# A bit better than the last one\nprint(metrics.classification_report(classes, results, sentiments))\n\nprint(pd.crosstab(classes, results, rownames = [\"Real\"], colnames=[\"Predict\"], margins=True))","execution_count":1,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}