{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RANZCR 1st Place Solution Training Classification Model\n\nHi all,\n\nWe're very exciting to writing this notebook and the summary of our solution here.\n\nOur final pipeline has 4 training stages but the minimal pipeline I show here has only 2 stages.\n\nThe 5-fold model trained with this minimal pipeline is sufficient to achieve CV 0.968-0.969 and pub/pvt LB 0.972\n\nI published 3 notebooks to demonstrate how our MINIMAL pipeline works.\n\n* Stage1: Segmentation (https://www.kaggle.com/haqishen/ranzcr-1st-place-soluiton-seg-model-small-ver)\n* Stage2: Classification (This notebook)\n* Inference (https://www.kaggle.com/haqishen/ranzcr-1st-place-soluiton-inference-small-ver)\n\nThis notebook shows how we can train a **classification** model using the original image, and the predicted mask of the segmentation model which we trained in stage 1.\n\nI've trained 5 fold segmentation models (b1 1024, exactly the same setting to the stage1 notebookï¼‰ locally and uploaded the predicted masks here: https://www.kaggle.com/haqishen/ranzcr-pred-masks-qishen\n\nTo get a similar performance of a single classification model to ours, you only need to do:\n\n* set DEBUG to `False`\n* train for 30 epochs for each fold\n* change the model type to effnet-b3/b4/b5\n\nIn this minimal pipeline we do not use external data, so the classification model input is **5ch**, original image as 3ch, predicted masks as 2ch (w/o trachea bifurcation channel)\n\nIt tooks around 3h for training a single fold classification models by this setting (b1 512)\n\nFinally I got CV score: `0.96788` by B1 1024 segmentationg model + B1 512 classification model\n\nYou should be able to reach CV 0.968-0.969 by simply using B5-B7 backbone to train segmentation model and use B3-B5 backbone to train classification model, without changing any other setting.\n\nOur brief summary of winning solution: https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/discussion/226633\n\n# Main Ideas\n\n* amp\n* combine original image (3ch) and predicted mask (3ch) as 5ch input\n* optimized augmentation methods\n* use CrossEntropy for ETT tube\n* warmup + cosine scheduler\n\n# Thanks!","metadata":{}},{"cell_type":"code","source":"!pip -q install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:26.894743Z","iopub.execute_input":"2021-08-24T14:16:26.895091Z","iopub.status.idle":"2021-08-24T14:16:35.396745Z","shell.execute_reply.started":"2021-08-24T14:16:26.89506Z","shell.execute_reply":"2021-08-24T14:16:35.395701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\n# Add smp & timm to kernel w/o Internet\nimport sys\nsys.path = [\n    '../input/smp20210127/segmentation_models.pytorch-master/segmentation_models.pytorch-master/',\n    '../input/smp20210127/EfficientNet-PyTorch-master/EfficientNet-PyTorch-master',\n    '../input/smp20210127/pytorch-image-models-master/pytorch-image-models-master',\n    '../input/smp20210127/pretrained-models.pytorch-master/pretrained-models.pytorch-master',\n    '../input/90flip5000image',\n] + sys.path","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.40076Z","iopub.execute_input":"2021-08-24T14:16:35.401037Z","iopub.status.idle":"2021-08-24T14:16:35.408514Z","shell.execute_reply.started":"2021-08-24T14:16:35.401011Z","shell.execute_reply":"2021-08-24T14:16:35.407548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# libraries\nimport os\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport subprocess\nimport cv2\nimport PIL.Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom sklearn.metrics import roc_auc_score\nfrom warmup_scheduler import GradualWarmupScheduler\nimport albumentations\nimport timm\nfrom tqdm.notebook import tqdm\nimport torch.cuda.amp as amp\nimport warnings\n\nwarnings.simplefilter('ignore')\nscaler = amp.GradScaler()\ndevice = torch.device('cuda')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T14:16:35.410693Z","iopub.execute_input":"2021-08-24T14:16:35.41095Z","iopub.status.idle":"2021-08-24T14:16:35.427872Z","shell.execute_reply.started":"2021-08-24T14:16:35.410926Z","shell.execute_reply":"2021-08-24T14:16:35.426949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dual Cutout implementations\nclass CutoutV2(albumentations.DualTransform):\n    def __init__(\n        self,\n        num_holes=8,\n        max_h_size=8,\n        max_w_size=8,\n        fill_value=0,\n        always_apply=False,\n        p=0.5,\n    ):\n        super(CutoutV2, self).__init__(always_apply, p)\n        self.num_holes = num_holes\n        self.max_h_size = max_h_size\n        self.max_w_size = max_w_size\n        self.fill_value = fill_value\n\n    def apply(self, image, fill_value=0, holes=(), **params):\n        return albumentations.functional.cutout(image, holes, fill_value)\n\n    def get_params_dependent_on_targets(self, params):\n        img = params[\"image\"]\n        height, width = img.shape[:2]\n\n        holes = []\n        for _n in range(self.num_holes):\n            y = random.randint(0, height)\n            x = random.randint(0, width)\n\n            y1 = np.clip(y - self.max_h_size // 2, 0, height)\n            y2 = np.clip(y1 + self.max_h_size, 0, height)\n            x1 = np.clip(x - self.max_w_size // 2, 0, width)\n            x2 = np.clip(x1 + self.max_w_size, 0, width)\n            holes.append((x1, y1, x2, y2))\n\n        return {\"holes\": holes}\n\n    @property\n    def targets_as_params(self):\n        return [\"image\"]\n\n    def get_transform_init_args_names(self):\n        return (\"num_holes\", \"max_h_size\", \"max_w_size\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.429502Z","iopub.execute_input":"2021-08-24T14:16:35.429872Z","iopub.status.idle":"2021-08-24T14:16:35.442361Z","shell.execute_reply.started":"2021-08-24T14:16:35.429835Z","shell.execute_reply":"2021-08-24T14:16:35.441682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"kernel_type = 'enetb1_5ch_512_lr3e4_bs32_30epo'\nenet_type = 'tf_efficientnet_b1_ns'\ndata_dir = '../input/90flip5000image'\nnum_workers = 2\nnum_classes = 12\nn_ch = 3\nimage_size = 512\nbatch_size = 32\ninit_lr = 3e-4\nwarmup_epo = 1\n# If DEBUG == True, only run 3 epochs per fold\ncosine_epo = 3 if not DEBUG else 2\nn_epochs = warmup_epo + cosine_epo\nloss_weights = [1., 9.]\nimage_folder = 'image10000'\nmask_folder = '../input/ranzcr-pred-masks-qishen/mask_unet++b1_2cbce_1024T15tip_lr1e4_bs4_augv2_30epo/'\n\nlog_dir = './logs'\nmodel_dir = './models'\nos.makedirs(log_dir, exist_ok=True)\nos.makedirs(model_dir, exist_ok=True)\nlog_file = os.path.join(log_dir, f'log_{kernel_type}.txt')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.446064Z","iopub.execute_input":"2021-08-24T14:16:35.446385Z","iopub.status.idle":"2021-08-24T14:16:35.455314Z","shell.execute_reply.started":"2021-08-24T14:16:35.446361Z","shell.execute_reply":"2021-08-24T14:16:35.454644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/10000/a5000.csv')\n# If DEBUG == True, use only 100 samples to run.\ndf_train = pd.concat([\n    df_train.query('fold == 0').sample(10000),\n]) if DEBUG else df_train\n\nno_ETT = (df_train[['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal']].values.max(1) == 0).astype(int)\ndf_train.insert(4, column='no_ETT', value=no_ETT)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.45908Z","iopub.execute_input":"2021-08-24T14:16:35.45936Z","iopub.status.idle":"2021-08-24T14:16:35.495064Z","shell.execute_reply.started":"2021-08-24T14:16:35.459328Z","shell.execute_reply":"2021-08-24T14:16:35.49441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Dataset","metadata":{}},{"cell_type":"code","source":"class RANZCRDatasetCLS(Dataset):\n\n    def __init__(self, df, mode, transform=None):\n\n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        image = cv2.imread(os.path.join(data_dir, image_folder, row.StudyInstanceUID + '.jpg'))[:,:, ::-1]\n        #mask = cv2.imread(os.path.join(mask_folder, row.StudyInstanceUID + '.png')).astype(np.float32)[:,:,:2]\n\n        res = self.transform(image=image)\n        image = res['image'].astype(np.float32).transpose(2, 0, 1) / 255.\n        #mask = res['mask'].astype(np.float32).transpose(2, 0, 1) / 255.\n\n        #image = np.concatenate([image, mask], 0)\n\n        if self.mode == 'test':\n            return torch.tensor(image)\n        else:\n            label = row[[\n                'ETT - Abnormal',\n                'ETT - Borderline',\n                'ETT - Normal',\n                'no_ETT',\n                'NGT - Abnormal',\n                'NGT - Borderline',\n                'NGT - Incompletely Imaged',\n                'NGT - Normal',\n                'CVC - Abnormal',\n                'CVC - Borderline',\n                'CVC - Normal',\n                'Swan Ganz Catheter Present'\n            ]].values.astype(float)\n            return torch.tensor(image).float(), torch.tensor(label).float()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.497974Z","iopub.execute_input":"2021-08-24T14:16:35.498222Z","iopub.status.idle":"2021-08-24T14:16:35.507034Z","shell.execute_reply.started":"2021-08-24T14:16:35.498199Z","shell.execute_reply":"2021-08-24T14:16:35.506146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"transforms_train = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n    \n])\ntransforms_val = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.509398Z","iopub.execute_input":"2021-08-24T14:16:35.509789Z","iopub.status.idle":"2021-08-24T14:16:35.51553Z","shell.execute_reply.started":"2021-08-24T14:16:35.50974Z","shell.execute_reply":"2021-08-24T14:16:35.514656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"#df_show = df_train.sample(10)\n#dataset_show = RANZCRDatasetCLS(df_show, 'train', transform=transforms_train)\nfrom pylab import rcParams\n#rcParams['figure.figsize'] = 20,10\n\n#f, axarr = plt.subplots(1,5)\n#imgs = []\n#for p in range(5):\n  #  img, label = dataset_show[p]\n  #  imgs.append(img)\n #   axarr[p].imshow(img[:3].transpose(0, 1).transpose(1,2))\n\n#f, axarr = plt.subplots(1,5)\n#for p in range(5):\n  #  axarr[p].imshow(imgs[p][3:].sum(0))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.517175Z","iopub.execute_input":"2021-08-24T14:16:35.517566Z","iopub.status.idle":"2021-08-24T14:16:35.52398Z","shell.execute_reply.started":"2021-08-24T14:16:35.517522Z","shell.execute_reply":"2021-08-24T14:16:35.523115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, enet_type, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = timm.create_model(enet_type, True)\n        self.dropout = nn.Dropout(0.5)\n        self.enet.conv_stem.weight = nn.Parameter(self.enet.conv_stem.weight.repeat(1,n_ch//3+1,1,1)[:, :n_ch])\n        self.myfc = nn.Linear(self.enet.classifier.in_features, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        h = self.myfc(self.dropout(x))\n        return h\n\nm = enetv2(enet_type, num_classes)\nm(torch.rand(2,n_ch,image_size, image_size))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:35.525717Z","iopub.execute_input":"2021-08-24T14:16:35.526277Z","iopub.status.idle":"2021-08-24T14:16:37.646413Z","shell.execute_reply.started":"2021-08-24T14:16:35.526229Z","shell.execute_reply":"2021-08-24T14:16:37.64548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"bce = nn.BCEWithLogitsLoss()\nce = nn.CrossEntropyLoss()\n\n\ndef criterion(logits, targets, lw=loss_weights):\n    loss1 = ce(logits[:, :4], targets[:, :4].argmax(1)) * lw[0]\n    loss2 = bce(logits[:, 4:], targets[:, 4:]) * lw[1]\n    return (loss1 + loss2) / sum(lw)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:37.64812Z","iopub.execute_input":"2021-08-24T14:16:37.648608Z","iopub.status.idle":"2021-08-24T14:16:37.655465Z","shell.execute_reply.started":"2021-08-24T14:16:37.648568Z","shell.execute_reply":"2021-08-24T14:16:37.654413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LR Scheduler","metadata":{}},{"cell_type":"code","source":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\noptimizer = optim.Adam(m.parameters(), lr=init_lr)\nscheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cosine_epo)\nscheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\nlrs = []\nfor epoch in range(1, n_epochs+1):\n    scheduler_warmup.step(epoch-1)\n    lrs.append(optimizer.param_groups[0][\"lr\"])\nrcParams['figure.figsize'] = 20,3\nplt.plot(lrs)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:37.65698Z","iopub.execute_input":"2021-08-24T14:16:37.657437Z","iopub.status.idle":"2021-08-24T14:16:37.807474Z","shell.execute_reply.started":"2021-08-24T14:16:37.657374Z","shell.execute_reply":"2021-08-24T14:16:37.80659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train & Validation Function","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, targets) in bar:\n\n        optimizer.zero_grad()\n        data, targets = data.to(device), targets.to(device)\n\n        with amp.autocast():\n            logits = model(data)\n            loss = criterion(logits, targets)\n        scaler.scale(loss).backward() \n        scaler.step(optimizer)\n        scaler.update()\n\n        loss_np = loss.item()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-50:]) / min(len(train_loss), 50)\n        bar.set_description('loss: %.4f, smth: %.4f' % (loss_np, smooth_loss))\n\n    return np.mean(train_loss)\n\n\ndef valid_epoch(model, loader, get_output=False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    TARGETS = []\n    with torch.no_grad():\n        for (data, targets) in tqdm(loader):\n            data, targets = data.to(device), targets.to(device)\n            logits = model(data)\n            loss = criterion(logits, targets)\n            val_loss.append(loss.item())\n            LOGITS.append(logits.cpu())\n            TARGETS.append(targets.cpu())\n            \n    val_loss = np.mean(val_loss)\n    LOGITS = torch.cat(LOGITS)\n    LOGITS[:, :4] = LOGITS[:, :4].softmax(1)\n    LOGITS[:, 4:] = LOGITS[:, 4:].sigmoid()\n    TARGETS = torch.cat(TARGETS).numpy()\n\n    if get_output:\n        return LOGITS\n    else:\n        aucs = []\n        for cid in range(num_classes):\n            if cid == 3: continue\n            try:\n                aucs.append( roc_auc_score(TARGETS[:, cid], LOGITS[:, cid]) )\n            except:\n                aucs.append(0.5)\n        return val_loss, aucs","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:37.808985Z","iopub.execute_input":"2021-08-24T14:16:37.809351Z","iopub.status.idle":"2021-08-24T14:16:37.823441Z","shell.execute_reply.started":"2021-08-24T14:16:37.809316Z","shell.execute_reply":"2021-08-24T14:16:37.82102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run!","metadata":{}},{"cell_type":"code","source":"def run(fold):\n    content = 'Fold: ' + str(fold)\n    print(content)\n    with open(log_file, 'a') as appender:\n        appender.write(content + '\\n')\n    train_ = df_train\n    valid_ = df_train\n\n    dataset_train = RANZCRDatasetCLS(train_, 'train', transform=transforms_train)\n    dataset_valid = RANZCRDatasetCLS(valid_, 'valid', transform=transforms_val)\n    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    model = enetv2(enet_type, num_classes)\n    model = model.to(device)\n    aucs_max = 0\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{fold}.pth')\n\n    optimizer = optim.Adam(model.parameters(), lr=init_lr)\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cosine_epo)\n    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n    for epoch in range(1, n_epochs+1):\n        print(time.ctime(), 'Epoch:', epoch)\n        scheduler_warmup.step(epoch-1)\n\n        train_loss = train_epoch(model, train_loader, optimizer)\n        val_loss, aucs = valid_epoch(model, valid_loader)\n\n        content = time.ctime() + ' ' + f'Fold {fold} Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.4f}, valid loss: {(val_loss):.4f}, aucs: {np.mean(aucs):.4f}.'\n        content += '\\n' + ' '.join([f'{x:.4f}' for x in aucs])\n        print(content)\n        with open(log_file, 'a') as appender:\n            appender.write(content + '\\n')\n\n        if aucs_max < np.mean(aucs):\n            print('aucs increased ({:.6f} --> {:.6f}).  Saving model ...'.format(aucs_max, np.mean(aucs)))\n            torch.save(model.state_dict(), model_file)\n            aucs_max = np.mean(aucs)\n\n    torch.save(model.state_dict(), os.path.join(model_dir, f'{kernel_type}_model_fold{fold}.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:37.82465Z","iopub.execute_input":"2021-08-24T14:16:37.825136Z","iopub.status.idle":"2021-08-24T14:16:37.838788Z","shell.execute_reply.started":"2021-08-24T14:16:37.825097Z","shell.execute_reply":"2021-08-24T14:16:37.837946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(1):\n    run(fold)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T14:16:37.840134Z","iopub.execute_input":"2021-08-24T14:16:37.840701Z","iopub.status.idle":"2021-08-24T15:37:37.829565Z","shell.execute_reply.started":"2021-08-24T14:16:37.840662Z","shell.execute_reply":"2021-08-24T15:37:37.828689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis","metadata":{}},{"cell_type":"code","source":"dfs = []\nLOGITS = []\n\nfor fold in range(10):\n    valid_ = df_train.query(f'fold=={fold}').copy().reset_index(drop=True)\n    dfs.append(valid_)\n    dataset_valid = RANZCRDatasetCLS(valid_, 'valid', transform=transforms_val)\n    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    model = enetv2(enet_type, num_classes)\n    model = model.to(device)\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{fold}.pth')\n    model.load_state_dict(torch.load(model_file), strict=True)\n    model.eval()\n    \n    outputs = valid_epoch(model, valid_loader, get_output=True)\n    # rank prediction\n    outputs = pd.DataFrame(outputs.numpy()).rank(pct=True).values\n    LOGITS.append(outputs)\n\ndfs = pd.concat(dfs).reset_index(drop=True)\nLOGITS = np.concatenate(LOGITS)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:37:37.832801Z","iopub.execute_input":"2021-08-24T15:37:37.833188Z","iopub.status.idle":"2021-08-24T15:47:10.962132Z","shell.execute_reply.started":"2021-08-24T15:37:37.833149Z","shell.execute_reply":"2021-08-24T15:47:10.961302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:47:10.963773Z","iopub.execute_input":"2021-08-24T15:47:10.96409Z","iopub.status.idle":"2021-08-24T15:47:10.972713Z","shell.execute_reply.started":"2021-08-24T15:47:10.96406Z","shell.execute_reply":"2021-08-24T15:47:10.971489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:47:10.974558Z","iopub.execute_input":"2021-08-24T15:47:10.975028Z","iopub.status.idle":"2021-08-24T15:47:11.00302Z","shell.execute_reply.started":"2021-08-24T15:47:10.97499Z","shell.execute_reply":"2021-08-24T15:47:11.002005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOGITS","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:47:11.004425Z","iopub.execute_input":"2021-08-24T15:47:11.00476Z","iopub.status.idle":"2021-08-24T15:47:11.010933Z","shell.execute_reply.started":"2021-08-24T15:47:11.004726Z","shell.execute_reply":"2021-08-24T15:47:11.010083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aucs = []\nfor cid in range(num_classes):\n    if cid == 3: continue\n    aucs.append( roc_auc_score(dfs.values[:,1:-3].astype(float)[:, cid], LOGITS[:, cid]) )\nprint('oof cv:', np.mean(aucs))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:47:11.012213Z","iopub.execute_input":"2021-08-24T15:47:11.012793Z","iopub.status.idle":"2021-08-24T15:47:11.176885Z","shell.execute_reply.started":"2021-08-24T15:47:11.012727Z","shell.execute_reply":"2021-08-24T15:47:11.175997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\ny = np.array([0, 0, 1, 1])\nscores = np.array([0.1, 0.4, 0.35, 0.8])\nfpr, tpr, _ = roc_curve(y, scores)\nroc_auc = auc(fpr, tpr)\n\nimport matplotlib as mpl\n#mpl.use('Agg')\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\n#fig.savefig('/tmp/roc.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:47:11.178215Z","iopub.execute_input":"2021-08-24T15:47:11.178774Z","iopub.status.idle":"2021-08-24T15:47:11.341824Z","shell.execute_reply.started":"2021-08-24T15:47:11.178737Z","shell.execute_reply":"2021-08-24T15:47:11.340701Z"},"trusted":true},"execution_count":null,"outputs":[]}]}