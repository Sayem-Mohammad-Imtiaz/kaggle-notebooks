{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# importing the necessary libraries\nimport pandas as pd\nimport numpy as np\n\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/cristiano-ronaldos-goals/yds_data.csv\") # reading data from the CSV file","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape # checking how many rows and columns are in the data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head() # seeing how the data looks like","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"#### 1. Exploring the Columns of Dataset","metadata":{}},{"cell_type":"code","source":"# A. Using descriptive Statistics to find some insights\ndata.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# B. Finding the dtypes of Columns to get some Insights\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Checking for Missing Values","metadata":{}},{"cell_type":"code","source":"# Percentage and Sum of Missing values in each Columns\nmissing_data = pd.DataFrame({'total_missing': data.isnull().sum(), 'perc_missing': (data.isnull().sum()/data.shape[0])*100})\nmissing_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploring The Target Variable 'is_goal'\ndata.is_goal.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### \" It's a binary classification problem as there are only two values for the target ''is_goal\" column","metadata":{}},{"cell_type":"markdown","source":"\n\n# B.      Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"#### 1. Dropping unnessary Columns\n","metadata":{}},{"cell_type":"code","source":"#1. Droping Unnecessary Columns\ndata.drop([\"Unnamed: 0\",  'remaining_min.1', 'power_of_shot.1','knockout_match.1', 'remaining_sec.1', 'distance_of_shot.1'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head() # looking at the dataset after transformation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns # to see if the columns are dropped succesfully","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2. Changing dtypes to datetime\ndata.date_of_game = pd.to_datetime(data.date_of_game, errors='coerce')\ndata['game_season'] = data['game_season'].astype('object')\ndata['game_season']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Labelencoding the 'game_season' ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_unique = data['game_season'].unique() # fteching out the unique values from game_season/\nl_unique","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v_unique = np.arange(len(l_unique)) # obtaining values in the range of the length of I_unique\nv_unique","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['game_season'].replace(to_replace=l_unique, value=v_unique, inplace=True) # replacing categorical data with numerical values\ndata['game_season'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['game_season'] = data['game_season'].astype('int') # converting the datatype of the column from int64 to int32\ndata['game_season'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Handeling Missing Values\n","metadata":{}},{"cell_type":"code","source":"# Filling NaN values in Column \"remaining_sec\" with MEAN\ndata['power_of_shot'].fillna(value=data['power_of_shot'].mean(), inplace=True)\ndata.isnull().sum() # number of missing values for power_of_shot column should be zero\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling NaN values in Column \"type_of_combined_shot\" with MODE\nmode_com  = data.type_of_combined_shot.value_counts().keys()[0]\nprint('moded is: ',mode_com)\ndata.type_of_combined_shot.fillna(value=mode_com, inplace=True)\ndata.isnull().sum() # number of missing values for type_of_combined_shot column should be zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling NaN values in Column \"remaining_sec\" with MEDIAN\ndata.remaining_sec.fillna(value=data.remaining_sec.median(), inplace=True)\ndata.isnull().sum() # number of missing values for remaining_sec column should be zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shot_id_no.\ndata.shot_id_number = pd.Series(np.arange(1,data.shot_id_number.shape[0]+1))\ndata.isnull().sum() # number of missing values for shot_id_number column should be zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling NaN values in Columns \"location_x\" and \"location_y\" with 0\ndata['location_x'].fillna(value=0, inplace=True)\ndata['location_y'].fillna(value=0, inplace=True)\ndata.isnull().sum() # number of missing values for location_x and location_y columns should be zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Forward Filling method in appropriate Columns\nprint('Null values in column home/away before forward fill =',data['home/away'].isnull().sum())\ncol = ['home/away','lat/lng', 'team_name','match_id','match_event_id', 'team_id', 'remaining_min', 'knockout_match',  'game_season' ]\ndata.loc[:,col] = data.loc[:,col].ffill()\nprint('Null values in column home/away after the forward fill =',data['home/away'].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling Missing Values In \"shot_basics\" based on \"range_of_short\" column!\n# if the range of the shot is 16-24 ft it's a mid range shot\ndata.loc[(data.range_of_shot == '16-24 ft.'), 'shot_basics'] = data[data.range_of_shot == '16-24 ft.'].shot_basics.fillna(value='Mid Range')\n\n# if the range of the shot is less than 8 ft then randomly assign goal line or goal area value to the shot \ndata.loc[(data.range_of_shot == 'Less Than 8 ft.')&(data.shot_basics.isnull()), 'shot_basics']   =  pd.Series(data[(data.range_of_shot == 'Less Than 8 ft.')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Goal Area', 'Goal Line'],1,p=[0.7590347263095939, 0.24096527369040613])[0]))\n# if the range of the shot is  8-16 ft then randomly assign goal line or mid range value to the shot\ndata.loc[(data.range_of_shot == '8-16 ft.')&(data.shot_basics.isnull()), 'shot_basics']          =  pd.Series(data[(data.range_of_shot == '8-16 ft.')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Mid Range', 'Goal Line'],1,p=[0.6488754615642833, 0.35112453843571667])[0]))\n# if the range of the shot is more than 24 ft then randomly assign one of the values from'Penalty Spot', 'Right Corner', 'Left Corner' to shot_basic field\ndata.loc[(data.range_of_shot == '24+ ft.')&(data.shot_basics.isnull()), 'shot_basics']            =  pd.Series(data[(data.range_of_shot == '24+ ft.')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Penalty Spot', 'Right Corner', 'Left Corner'],1,p=[0.8932384341637011, 0.06192170818505338, 0.044839857651245554])[0]))\n# if the shot is a back court shot then randomly assign one of the values from''Mid Ground Line', 'Penalty Spot' to shot_basic field\ndata.loc[(data.range_of_shot == 'Back Court Shot')&(data.shot_basics.isnull()), 'shot_basics']    =  pd.Series(data[(data.range_of_shot == 'Back Court Shot')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Mid Ground Line', 'Penalty Spot'],1,p=[0.8441558441558441, 0.15584415584415584])[0]))\ndata.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['shot_basics'].unique() # now we have populated the shot types and reduced the number of missing values. Earlier we had 1575 missing values for this column, now we have only 66.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling Missing Values In \"range_of_short\" based on \"short_basics\" column!\n\n# if shot_basics is Goal Area, then range of shot is Less Than 8 ft\ndata.loc[(data.shot_basics == 'Goal Area'), 'range_of_shot']       = data[data.shot_basics == 'Goal Area'].range_of_shot.fillna(value='Less Than 8 ft.')\n# if shot_basics is Penalty Spot, then range of shot is  24+ ft.\ndata.loc[(data.shot_basics == 'Penalty Spot'), 'range_of_shot']    = data[data.shot_basics == 'Penalty Spot'].range_of_shot.fillna(value= '24+ ft.')\n# if shot_basics is Right Corner, then range of shot is  24+ ft.\ndata.loc[(data.shot_basics == 'Right Corner'), 'range_of_shot']    = data[data.shot_basics == 'Right Corner'].range_of_shot.fillna(value='24+ ft.')\n# if shot_basics is Left Corner, then range of shot is  24+ ft.\ndata.loc[(data.shot_basics == 'Left Corner'), 'range_of_shot']     = data[data.shot_basics == 'Left Corner'].range_of_shot.fillna(value='24+ ft.')\n# if shot_basics is Mid Ground Line , then range of shot is  Back Court Shot\ndata.loc[(data.shot_basics == 'Mid Ground Line'), 'range_of_shot'] = data[data.shot_basics == 'Mid Ground Line'].range_of_shot.fillna(value='Back Court Shot')\n# if shot_basics is Mid Range then randomly assign '16-24 ft.' or  '8-16 ft.' to range of shot\ndata.loc[(data.shot_basics == 'Mid Range')&(data.range_of_shot.isnull()), 'range_of_shot']       = pd.Series(data[(data.shot_basics == 'Mid Range')&(data.range_of_shot.isnull())].range_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(['16-24 ft.', '8-16 ft.'],1,p=[0.6527708850289495, 0.34722911497105047])[0]))\n# if shot_basics is Goal Line then randomly assign ''8-16 ft.' or  'Less Than 8 ft.' to range of shot\ndata.loc[(data.shot_basics == 'Goal Line')&(data.range_of_shot.isnull()), 'range_of_shot']       = pd.Series(data[(data.shot_basics == 'Goal Line')&(data.range_of_shot.isnull())].range_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(['8-16 ft.', 'Less Than 8 ft.'],1,p=[0.5054360956752839, 0.49456390432471614])[0]))\n\ndata.isnull().sum() # number of missing values for range_of_shot column should have been reduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['range_of_shot'].unique() # the number of missing values has fallen from 1564 to 66","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling the remaining missing values incase they both have NaN values using the forward fill method\ndata.shot_basics.fillna(method='ffill', inplace=True)\ndata.range_of_shot.fillna(method='ffill', inplace=True)\ndata.isnull().sum() # number of missing values for shot_basics and range_of_shot columns should be zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling the missing value in \"ärea_of_short\" Column\ndata.area_of_shot.fillna(value='Center(C)', inplace=True) # all the missing values get filled by  'Centre(C)'\ndata.isnull().sum() # number of missing values for area_of_shot column should be zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['distance_of_shot'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filling the Missing values in \"distance_of_shot\"\n# if distance_of_shot isnull randomly assign a value from 20,45,44,37\ndata.loc[data['distance_of_shot'].isnull(), 'distance_of_shot'] = pd.Series(data.loc[data['distance_of_shot'].isnull(), 'distance_of_shot'].apply(lambda x: x if type(x)==str else np.random.choice([20,45,44,37],1,p=[0.5278056615137523,0.18630797028709095,0.14384661714515157,0.1420397510540052])[0])) \ndata.isnull().sum() # number of missing values for distance_of_shot column should be zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making the Train and Test Dataset","metadata":{}},{"cell_type":"markdown","source":"##### # train and test data are divided based on the vaue of is goal column","metadata":{}},{"cell_type":"code","source":"\n# Making the train Dataset\ntrain = data[data.is_goal.notnull()]\nprint('the Shape of Train Dataset',train.shape)\ntrain.set_index(np.arange(train.shape[0]),inplace=True)\ntrain.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the Test Dataset\ntest = data[data.is_goal.isnull()]\nprint('The Shape of Test Dataset',test.shape)\ntest.set_index(np.arange(test.shape[0]), inplace=True)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Handeling Missing Values in train and Test Dataset","metadata":{}},{"cell_type":"markdown","source":"#### Filling the Nan value with a random choice from given list with there appropriate probablities\n","metadata":{}},{"cell_type":"code","source":"l_goal   = train[train.is_goal == 1].type_of_shot.value_counts().head(6).keys()     # Top six shots when it was goal\nl_goal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_g_sum  = train[train.is_goal == 1].type_of_shot.value_counts().head(6).sum() # Top six shots when it was goal\np_goal   = (train[train.is_goal == 1].type_of_shot.value_counts().head(6) / p_g_sum ).tolist()  # There respective probablities\np_goal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if is_goal is 1, if type of shot is a string value, fill with the same or else fill with randomly choosing value from l_goal\ng = pd.Series(train[train.is_goal == 1].type_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(l_goal,1,p=p_goal)[0]))\ng","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # if is_goal is 1, if type of shot is null then type of shot becomes equal to the value of g based on the index\ntrain.loc[(train.is_goal == 1)&(train.type_of_shot.isnull()), 'type_of_shot'] = g","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['type_of_shot'].isna().sum() # number of missing values got reduced from more than 15k to 6723","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### and we have applied similar concept for the scenarios when there was no goal","metadata":{}},{"cell_type":"code","source":"l_no_goal   = train[train.is_goal == 0].type_of_shot.value_counts().head(5).keys()     # Top five shots when it was not a goal\np_no_sum  = train[train.is_goal == 0].type_of_shot.value_counts().head(5).sum()\np_no_goal   = (train[train.is_goal == 0].type_of_shot.value_counts().head(5) / p_no_sum ).tolist() # There respective probablities \nng = pd.Series(train[train.is_goal == 0].type_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(l_no_goal,1,p=p_no_goal)[0]))\ntrain.loc[(train.is_goal == 0)&(train.type_of_shot.isnull()), 'type_of_shot'] = ng \ntrain['type_of_shot'].isna().sum() # number of missing values got reduced to zero","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Handeling the remaing values in test dataset with a smilira approach\ntest.loc[test['type_of_shot'].isnull(), 'type_of_shot'] = pd.Series(test.loc[test['type_of_shot'].isnull(), 'type_of_shot'].apply(lambda x: x if type(x)==str else np.random.choice(['shot - 39', 'shot - 36', 'shot - 4'],1,p=[0.37377133988618727, 0.33419555095706155, 0.2920331091567512])[0])) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['type_of_shot'].isna().sum() # we have removed the missing values from test set as well","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Label Encoding the Object type Columns","metadata":{}},{"cell_type":"code","source":"%%time\n# Labeling the catagories with integers\nfor col in train.columns:\n    if train[col].dtypes == object: # if the column has categorical values\n        l_unique = train[col].unique() # find the unique values\n        v_unique = np.arange(len(l_unique)) # create a list of number from zero to the length of the I_unique values\n        train[col].replace(to_replace=l_unique, value=v_unique, inplace=True) # replace the categorical values with numerical values\n        train[col] = train[col].astype('int') # change the type from int64 to int32\n        \n        # same has been done for test data as well\n        test[col].replace(to_replace=l_unique, value=v_unique, inplace=True)\n        test[col] = test[col].astype('int')\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the unnecessary Columns\ntrain.drop(['date_of_game'], axis=1, inplace=True)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(['date_of_game'], axis=1, inplace=True)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splliting the Target Column from the Dataset\ny = train.is_goal\ny.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['is_goal'], axis=1, inplace=True)\ntrain.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(['is_goal'], axis=1, inplace=True)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info() # we have converted all the categorical columns to numeric ones","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum() ## we have don't have any missing values as well. Our data is ready to be fed to a machine learning model.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}