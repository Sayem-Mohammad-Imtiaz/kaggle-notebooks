{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Wine Prediction: Comparing Several Classification Algorithms\n\n## Decision Trees, Random Forests, AdaBoost, Gradient Boost, and XGBoost"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib as plt\nimport seaborn as sns\nimport plotly.express as px\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading Data\ndf = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understanding Data\nprint(\"Rows, columns: \" + str(df.shape))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing Values\nprint(df.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram of quality\nfig = px.histogram(df,x='quality')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix\ncorr = df.corr()\nplt.pyplot.subplots(figsize=(15,10))\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Classification version of target variable\ndf['goodquality'] = [1 if x >= 7 else 0 for x in df['quality']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See proportion of good vs bad wines\ndf['goodquality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate feature variables and target variable\nX = df.drop(['quality','goodquality'], axis = 1)\ny = df['goodquality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize feature variables\nfrom sklearn.preprocessing import StandardScaler\nX_features = X\nX = StandardScaler().fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 1: Decision Tree\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.tree import DecisionTreeClassifier\nmodel1 = DecisionTreeClassifier(random_state=1)\nmodel1.fit(X_train, y_train)\ny_pred1 = model1.predict(X_test)\n\nprint(classification_report(y_test, y_pred1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 2: Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nmodel2 = RandomForestClassifier(random_state=1)\nmodel2.fit(X_train, y_train)\ny_pred2 = model2.predict(X_test)\n\nprint(classification_report(y_test, y_pred2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 3: AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier\nmodel3 = AdaBoostClassifier(random_state=1)\nmodel3.fit(X_train, y_train)\ny_pred3 = model3.predict(X_test)\n\nprint(classification_report(y_test, y_pred3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 4: Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\nmodel4 = GradientBoostingClassifier(random_state=1)\nmodel4.fit(X_train, y_train)\ny_pred4 = model4.predict(X_test)\n\nprint(classification_report(y_test, y_pred4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 5: XGBoost\nimport xgboost as xgb\nmodel5 = xgb.XGBClassifier(random_state=1)\nmodel5.fit(X_train, y_train)\ny_pred5 = model5.predict(X_test)\n\nprint(classification_report(y_test, y_pred5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Importance: Random Forest\nfeat_importances = pd.Series(model2.feature_importances_, index=X_features.columns)\nfeat_importances.nlargest(25).plot(kind='barh',figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Importance: XGBoost\nfeat_importances = pd.Series(model5.feature_importances_, index=X_features.columns)\nfeat_importances.nlargest(25).plot(kind='barh',figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = df[df['goodquality']==1]\ndf_temp.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp2 = df[df['goodquality']==0]\ndf_temp2.describe()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}