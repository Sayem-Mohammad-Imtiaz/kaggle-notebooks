{"cells":[{"metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"},"cell_type":"markdown","source":"# <center> Classifying amazon product reviews with logistic regression\n## <center> Two levels of structured classes\n    \nWe are faced to a simple NLP problem – Amazon product reviews classification. But classes are structured, like in this picture. \n\n<img src=\"https://habrastorage.org/webt/nf/en/j7/nfenj7gktep6dtbrtzgijcsdzwy.png\" width=40%/>\n\nThat poses a question, what's the best way to approach this hierarchical text classification problem. \n\nHere we present a basic tf-idf + logreg baseline. There're 3 levels of this taxonomy in our data, but here we disregard the 3rd one.\n\n**Idea**\n\nEach review has 3 labels which are elements of a taxonomy, eg. \n\n> 'The description and photo on this product needs to be changed to indicate this product is the BuffalOs version of this beef jerky.'\n\n> Category 1: `grocery gourmet food` \n\n> Category 2: `meat poultry`\n\n> Category 3: `jerky`\n\nFirst, we concatenate Category 1 and Category 2 classes for each sample, eg. `grocery gourmet food/meat poultry`. Then we train the model and measure F1 score for Category 2.\n\nThen we split the prediction string and thus get predictions for Category 1:\n\n-  Category 3 prediction is `grocery gourmet food/meat poultry/jerky` --> Category 1 prediction is `grocery gourmet food`\n\nAfter that we measure F1 scores for Category 1.\n\n**Results:**\n\nF1 micro (=accuracy):\n- Category 1: **0.948**\n- Category 2: **0.889**\n\nPS. using \"level\" and \"category\" interchangeably here."},{"metadata":{},"cell_type":"markdown","source":"## Reading and analyzing the data"},{"metadata":{"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score\n\nfrom matplotlib import pyplot as plt\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_DATA = Path('../input/hierarchical-text-classification/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(PATH_TO_DATA / 'train_40k.csv').fillna(' ')\nvalid_df = pd.read_csv(PATH_TO_DATA / 'val_10k.csv').fillna(' ')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27","trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fields:\n\n* productId – the review is given about this product\n* Title - title of a review as given by the author\n* user - Iduser ID of the author of the review\n* Helpfulness - whether the review is found helpful by other users\n* Score - score of a review as rated by other users\n* Time - timestamp of the review\n* Text - text of a review"},{"metadata":{"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78","trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example of a review"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[0, 'Text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[0, 'Cat1'], train_df.loc[0, 'Cat2'], train_df.loc[0, 'Cat3']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"},"cell_type":"markdown","source":"Distribution of level 1 classes"},{"metadata":{"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11","trusted":true},"cell_type":"code","source":"train_df['Cat1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We concatenate level 1 and level 2 classes, the model will be trained with these targets. It's very important that the model satisfies the class taxonomy. This way it never predicts contradicting level 1 and level 2 classes (eg. 'pet supplies' as L1 and 'meat poultry' as L2 when actually 'meat poultry' is a sub-level of 'grocery gourmet food')"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Cat1_Cat2'] = train_df['Cat1'] + '/' + train_df['Cat2']\nvalid_df['Cat1_Cat2'] = valid_df['Cat1'] + '/' + valid_df['Cat2']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have 64 classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Cat1_Cat2'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most popular ones (at level 2) are:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Cat1_Cat2'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll be training the model with concatenations of review titles and texts"},{"metadata":{"_uuid":"416321f19f5a27290bc5622e8b3384b7bbbd28c6"},"cell_type":"markdown","source":"## Training the model\n\nWe are training our model only with review titles, a ciuple of experiments show that it works better than with review text. "},{"metadata":{"_uuid":"3048a070a56b08eb4e5fe2c54b6d14905031e74a","trusted":true},"cell_type":"code","source":"# put a limit on maximal number of features and minimal word frequency\ntf_idf = TfidfVectorizer(max_features=50000, min_df=2)\n# multinomial logistic regression a.k.a softmax classifier\nlogit = LogisticRegression(C=1e2, n_jobs=4, solver='lbfgs', \n                           random_state=17, verbose=0, \n                           multi_class='multinomial',\n                           fit_intercept=True)\n# sklearn's pipeline\ntfidf_logit_pipeline = Pipeline([('tf_idf', tf_idf), \n                                 ('logit', logit)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8756bac7457218e4daf08ec276211f03971c17fb","trusted":true},"cell_type":"code","source":"%%time\ntfidf_logit_pipeline.fit(train_df['Title'], train_df['Cat1_Cat2'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2e47f77f999c2fb5aee9ef1de1542bc93de4c98","trusted":true},"cell_type":"code","source":"%%time\nvalid_pred_level_2 = tfidf_logit_pipeline.predict(valid_df['Title'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That was a level 2 model. Now to predict level 1 as well we simple take the first part of level1/level2 prediction. Eg. if 'health personal care/health care' is predicted, then the level 1 prediction is 'health personal care'"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_pred_level_1 = [el.split('/')[0] for el in valid_pred_level_2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For evaluation, let's take a look at F1 score (micro and weigthed) at Level 1 and Level 2 separately. Note that in a multiclass setting F1 score with micro averaging is the same as accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Level 1:\\n\\tF1 micro (=accuracy): {}\\n\\tF1 weighted:\\t      {}\".format(\n    f1_score(y_true=valid_df['Cat1'], y_pred=valid_pred_level_1, average='micro').round(3),\n    f1_score(y_true=valid_df['Cat1'], y_pred=valid_pred_level_1, average='weighted').round(3)\n    )\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8f93efc3db12910eaa6d7944feebb2418714203","trusted":true},"cell_type":"code","source":"print(\"Level 2:\\n\\tF1 micro (=accuracy): {}\\n\\tF1 weighted:\\t      {}\".format(\n    f1_score(y_true=valid_df['Cat1_Cat2'], y_pred=valid_pred_level_2, average='micro').round(3),\n    f1_score(y_true=valid_df['Cat1_Cat2'], y_pred=valid_pred_level_2, average='weighted').round(3)\n    )\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fefd0178f43ce832031653be70f0a0e47f62cf4c"},"cell_type":"markdown","source":"## Explaining model predictions"},{"metadata":{"_uuid":"247a13fd3ae4d5c015c0ca0489a9a95d72ad7e9f","trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title='Confusion matrix', figsize=(7,7),\n                          cmap=plt.cm.Blues, path_to_save_fig=None):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    cm = confusion_matrix(y_true, y_pred).T\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Predicted label')\n    plt.xlabel('True label')\n    \n    if path_to_save_fig:\n        plt.savefig(path_to_save_fig, dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff4a79b0368176a518fb0b84b45a508499e6183f"},"cell_type":"markdown","source":"Confusion matrix is quite balanced."},{"metadata":{"_uuid":"6df0c058a45b48b756e57e01a23bbc0974407195","trusted":true},"cell_type":"code","source":"plot_confusion_matrix(\n    y_true=valid_df['Cat1'],\n    y_pred=valid_pred_level_1, \n    classes=sorted(train_df['Cat1'].unique()),\n    figsize=(8, 8)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can explore words/ngrams, which a most indicative of different classes. With 64 classes it might me a bit overwhelming though."},{"metadata":{"_uuid":"f62f3043b6e94fb6bbd5683a0e9662c572847fa6","trusted":true},"cell_type":"code","source":"%%capture\nimport eli5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(\n    estimator=tfidf_logit_pipeline.named_steps['logit'],\n    vec=tfidf_logit_pipeline.named_steps['tf_idf'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}