{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Atividade avaliativa para a disciplina DMMLII\n## Aluno: Hermes Araujo"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importando todas as bibliotecas\n\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Carregando o banco\ndf = pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')\ndf.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dicionário dos dados"},{"metadata":{},"cell_type":"markdown","source":"**VARIÁVEL** - TIPO - DESCRIÇÃO\n<br/>**BAD** - numérico - assume 1 se o cliente não cummpriu com o empréstimo e 0 se cumpriu com o pagamento \n<br/>**LOAN** - numérico - valor total da dívida que o cliente quer contrair\n<br/>**MORTDUE** - numérico - valor atual da hipoteca\n<br/>**VALUE** - numérico - valor da propriedade hipotecada\n<br/>**REASON** - categórico - razão da hipoteca. Se DebtCon é consolidação de dívida e se HomeImp e para melhoria da propriedade\n<br/>**JOB** - categórico - emprego do devedor. Seis categorias próprias\n<br/>**YOJ** - numérico - anos no emprego\n<br/>**DEROG** - numérico - número de relatórios de inconformidades\n<br/>**DELINQ** - numérico - número de linhas de crédito inadimplentes\n<br/>**CLAGE** - númerico - idade da linha de crédito mais antiga em meses\n<br/>**NINQ** - numérico - número de linhas de crédito recentes\n<br/>**CLNO** numérico - total de linhas de crédito\n<br/>**DEBTINC** - númerico - razão entre o débito e as entradas do cliente"},{"metadata":{},"cell_type":"markdown","source":"## Análise exploratória"},{"metadata":{"trusted":true},"cell_type":"code","source":"#verificando se o tipo dos dados no banco está em conformidade com o dicionário\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#verificando a quantidade de valores faltantes dos campos\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Boxplots dos valores das dívidas contraídas em função da razão da hipoteca. Estão comparados pelo pagamento ou não.\nsns.boxplot(x=\"REASON\", y=\"LOAN\",\n            hue=\"BAD\", palette=[\"m\", \"g\"],\n            data=df)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percebemos que os inadimplentes pegaram empréstimos em valores menores quando o motivo era melhoria da propriedade. Já no motivo consolidação de débito, a massa de dados é bastante parecida entre os pagadores, com os inadimplentes tendo ainda uma mediana um pouco menor. Em todos os boxplots percebemos grandes quantidades de outliers a maior."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatterplot do valor da propriedade com o valor atual da hipoteca\nplt.plot(range(500000))\nax = sns.scatterplot(x=\"VALUE\", y=\"MORTDUE\",\n                     hue=\"BAD\",\n                     data=df)\nplt.xlim(0, 500000)\nplt.ylim(0, 500000)\nplt.gca().set_aspect('equal', adjustable='box')\nplt.draw()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todas as observações acima da linha identidade possuem um valor de hipoteca maior que o próprio valor da propriedade hipotecada. Curiosamente, a maioria não é \"má pagadora\"."},{"metadata":{},"cell_type":"markdown","source":"## Modelagem\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embonecando as variáveis categóricas\ndf = pd.get_dummies(df, columns=['REASON','JOB'])\ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Definindo as variáveis independentes\nfeats = [c for c in df.columns if c not in ['BAD']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separando a base em treino e teste\ntrain, valid = train_test_split(df, test_size=0.2, random_state=42)\n\ntrain.shape, valid.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nesse caso não temos base de teste verdadeira (sem a variável dependente), então separaremos a base somente em treino e validação"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rodando o primeiro modelo\nrf = RandomForestClassifier(n_estimators=200, random_state=42)\nrf.fit(train[feats], train['BAD'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como verificamos lá em cima, existem muitos valores faltantes na base e o modelo não vai funcionar dessa forma. Partiremos então para a imputação."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputação\ndf.fillna(-1, inplace=True)\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Refazendo a separação\ntrain, valid = train_test_split(df, test_size=0.2, random_state=42)\n\ntrain.shape, valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rodando o primeiro modelo novamente\nrf = RandomForestClassifier(n_estimators=200, random_state=42)\nrf.fit(train[feats], train['BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aplicando o modelo na base de validação e verificando a acurácia\npreds_val = rf.predict(valid[feats])\n\naccuracy_score(valid['BAD'], preds_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mostrando a matriz de confusão\nskplt.metrics.plot_confusion_matrix(valid['BAD'],preds_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Vemos na matriz de confusão os seguintes dados:**\n<br/>**Sensibilidade:** 0,72 (190/(190+75)) -> Capacidade de acertar os positivos\n<br/>**Especificidade:** 0,97 (897/(897+30)) -> Capacidade de acertar os negativos\n<br/>**Acurácia:** 0,91 (897+190)/1192) -> Número de acertos totais frente ao tamanho do teste\n<br/><br/>Surpreendentemente parece se tratar de um bom modelo, mas vamos tentar melhorá-lo ainda mais."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testando o limitador de profundidade da árvore\nfor i in range(1,11,1):\n    rft = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=i)\n    rft.fit(train[feats], train['BAD'])\n    pred_teste = rft.predict(valid[feats])\n    print(str(i)+\" de profundidade: \"+str(accuracy_score(valid['BAD'], pred_teste)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que a profundidade da árvore não melhora o modelo. Limitá-la diminuiu a acurácia em comparação com o nosso valor original"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testando o número de estimadores\nfor i in range(1000,100,-100):\n    rft = RandomForestClassifier(n_estimators=i, random_state=42)\n    rft.fit(train[feats], train['BAD'])\n    pred_teste = rft.predict(valid[feats])\n    print(str(i)+\": \"+str(accuracy_score(valid['BAD'], pred_teste)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O número de estimadores já contribui alguma coisa com o modelo. Com 1000 estimadores temos uma melhora de 0,0008 na acurácia. Mas o desempenho não é linear como na profundidade. Ao subir de 200 para 300 temos uma piora, fica um tempo estagnado, em 800 temos o valor inicial novamente e uma pequena melhora em 1000."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando o desbalanceio da variável dependente\ndf['BAD'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O valor de mal pagadores é de 20% dos registros (1189/5960). Vamos testar aplicar pesos diferentes para esses registros"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testando colocar pesos nas possibilidades pagadores para atacar o desbalanceio\nclass_weight = dict({1:4, 0:1})\nrdf = RandomForestClassifier(bootstrap=True,\n            class_weight=class_weight, \n            criterion='gini',\n            max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=4, min_samples_split=10,\n            min_weight_fraction_leaf=0.0, n_estimators=200,\n            oob_score=False,\n            random_state=42,\n            verbose=0, warm_start=False)\n\nrdf.fit(train[feats], train['BAD'])\n\npred_teste = rdf.predict(valid[feats])\nprint(accuracy_score(valid['BAD'], pred_teste))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Foram testados diversos pesos, mas o máximo de acurácia alcançada com o peso 3 para o mau pagador foi a mesma do modelo original. Deixei com peso 4 para ilustrar que o esforço não adiantou muito."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"Em vez de dividir em treino e teste como fizemos, poderiamos ter feito o cross validation logo de cara, para ter uma noção da qualidade do modelo pretendido e até mesmo comparar dois tipos de modelos diferentes. Vamos ver essa comparação entre o random forest e o XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cria o vetor de notas, mostra e mostra a média\nscores = cross_val_score(rf, df[feats], df['BAD'], n_jobs=-1, cv=5)\n\nscores, scores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que através do cross validation conseguimos modelos com acurácias piores do que a separação que foi feita com o seed 42. Demos sorte! Vamos testar agora cross validation + xgb"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cria um objeto xgb\nxgb = XGBClassifier(n_estimators=200, n_jobs=-1, random_state=42, learning_rate=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Usa o cross validation como antes, mas com o xgb\nscores = cross_val_score(xgb, df[feats], df['BAD'], n_jobs=-1, cv=5)\n\nscores, scores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os desempenhos do xgb não foram tão bons quanto da random forest"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Grid Search"},{"metadata":{},"cell_type":"markdown","source":"Uma alternativa a ter mexido nos parâmetros na mão como fizemos lá em cima é o Grid Search. Vamos demonstrá-lo abaixo com o random forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cria um dicionário com os tipos de parâmetros que serão testados\ngrid_param = {\n    'n_estimators': [100, 300, 500, 800, 1000],\n    'criterion': ['gini', 'entropy'],\n    'bootstrap': [True, False]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cria o objeto grid search utilizando o dicionário anterior\ngd_sr = GridSearchCV(estimator=rf,\n                     param_grid=grid_param,\n                     scoring='accuracy',\n                     cv=5,\n                     n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Treina o modelo testando combinações de todos os parâmetros (demorado)\ngd_sr.fit(df[feats], df['BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mostra os melhores parâmetros\nbest_parameters = gd_sr.best_params_\nprint(best_parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mostra a acurácia com os melhores parâmetros\nbest_result = gd_sr.best_score_\nprint(best_result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusão"},{"metadata":{},"cell_type":"markdown","source":"   Num próximo modelo podemos utilizar o cross validation logo de cara para decidir que tipo de modelo usar e ter uma ideia da média de acurácia dos modelos mesmo sem separar a base. Além disso, para melhorar o modelo podemos testar várias combinações de parâmetros com o Grid Search até achar os melhores parâmetros. Logicamente falando essa seria a maneira mais organizada de fazer as coisas. Entretanto foi bom ter feito a separação antes de tudo isso. Em primeiro lugar, porque ilustra o caminho de aprendizado da disciplina, mas principalmente porque mostra o poder que uma separação feita de determinada forma tem na modelagem (provavelmente mostra na realidade a força do overfitting). \n\n   Outros parâmetros poderiam ter sido testados no grid search, como class_weight, max_features, max_leaf_nodes, min_impurity_decrease, min_impurity_split, min_samples_leaf, min_samples_split, min_weight_fraction_leaf, etc.\n    \n   De qualquer forma, para todos os efeitos, o modelo de random forest gerado com a base separada foi o que desempenhou melhor, com impressionantes 91,2% de acurácia."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}