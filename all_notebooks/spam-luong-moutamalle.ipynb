{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding='latin-1')\nsms.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\nsms.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms=sms.rename(columns={\"v1\":\"label\",\"v2\":\"message\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(sms.label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Passage en minuscule\nsms['message']=sms['message'].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punct(text):\n    text_tok = word_tokenize(text)\n    l=[]\n    for word in text_tok: \n        if not word in string.punctuation:\n            l.append(word)\n           \n    resultat=\" \".join(l)  \n    return resultat\n\nsms['message']=sms.message.apply(remove_punct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop=set(stopwords.words('english'))\n\ndef remove_stopword(text):\n    text_tok = word_tokenize(text)\n    l = []\n    for a in text_tok:\n        if not a in stop:\n            l.append(a)\n            \n    resultat = \" \".join(l)\n    return resultat\n\nsms['message']=sms.message.apply(remove_stopword)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lemmatizer=WordNetLemmatizer()\n\ndef lemm(text):\n    text_tok = word_tokenize(text) \n    l=[]\n    for word in text_tok:\n        l.append(lemmatizer.lemmatize(word))\n        \n    resultat = \" \".join(l)\n\n    return resultat\n\nsms.message=sms.message.apply(lemm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bag of words","metadata":{}},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncorpus=sms['message'].values\nbw_vect = CountVectorizer()\n# tokenize et construire le vocabulaire\nbw_fit=bw_vect.fit(corpus)\n# vectoriser les mots\nbw_corpus = bw_fit.transform(corpus)\nbw_sms=pd.DataFrame(bw_corpus.toarray(),columns=bw_fit.get_feature_names())\nbw_sms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF IDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n#Initialiser les paramètres du vectoriseur\ntf_vect = TfidfVectorizer(max_features=500)\n#Apprendre le vocabulaire du vectoriseur basé sur le paramètre initialisé\ntfidf_fit=tf_vect.fit(corpus)\n#Vectoriser le corpus\ntfidf_corpus= tfidf_fit.transform(corpus)\ntfidf_sms=pd.DataFrame(tfidf_corpus.toarray(),columns=tfidf_fit.get_feature_names())\ntfidf_sms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1ère méthode : avec TFIDF","metadata":{}},{"cell_type":"markdown","source":"## Vectorisation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXtfidf=tfidf_sms\nY=sms.label\n# Split train / test data :\nX_traintfidf, X_testtfidf, Y_train, Y_test = train_test_split(Xtfidf, Y, test_size=0.3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Arbre de décision","metadata":{}},{"cell_type":"code","source":"from sklearn import tree\ntree_model = tree.DecisionTreeClassifier()\ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model = tree_model.fit(X_traintfidf, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'non spam']\ntree.plot_tree(tree_model,feature_names = Xtfidf.columns, \n               class_names=names,\n               filled = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_predicttfidf=tree_model.predict(X_testtfidf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Évaluation de l'arbre","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predicttfidf, Y_test)\nprint(mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2ème méthode : avec Bag of words","metadata":{}},{"cell_type":"markdown","source":"## Vectorisation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXbw=bw_sms\nY=sms.label\n# Split train / test data :\nX_trainbw, X_testbw, Y_train, Y_test = train_test_split(Xbw, Y, test_size=0.3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Arbre de décision","metadata":{}},{"cell_type":"code","source":"from sklearn import tree\ntree_model = tree.DecisionTreeClassifier()\ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model = tree_model.fit(X_trainbw, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'non spam']\ntree.plot_tree(tree_model,feature_names = Xbw.columns, \n               class_names=names,\n               filled = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_predictbw=tree_model.predict(X_testbw)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Évaluation de l'arbre","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predictbw, Y_test)\nprint(mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Suite avec la méthode TFIDF","metadata":{}},{"cell_type":"markdown","source":"## Gridsearch","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nimport numpy as np\ndepths = np.arange(10, 40,5)\nparam_grid = [{'max_depth':depths}]\ngrid_tree= GridSearchCV(estimator=tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='accuracy',cv=10)\ngrid_tree.fit(X_traintfidf, Y_train)\nbest_model_tree = grid_tree.best_estimator_\nY_grid=best_model_tree.predict(X_testtfidf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mat = confusion_matrix(Y_grid, Y_test)\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Forêt d'arbres","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRf_model = RandomForestClassifier()\nRf_model=Rf_model.fit(X_traintfidf, Y_train)\nY_predicttfidf=Rf_model.predict(X_testtfidf)\na_CART = accuracy_score(Y_test,Y_predicttfidf)\nprint(\"L'accuracy score du modèle RF est de : \",a_CART)\nmat = confusion_matrix(Y_predicttfidf, Y_test)\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classer","metadata":{}},{"cell_type":"code","source":"def reponse(text):\n    text=text.lower()\n    text=text.replace('covid-19','coronavirus')\n    text=remove_punct(text)\n    text=remove_stopword(text)\n    text=lemm(text)\n    tfidf_text=tfidf_fit.transform([text])\n   \n    cm=cosine_similarity(tfidf_text, tfidf_corpus)\n    pos=np.argmax(cm[0])\n    data.answers[pos]\n    return data.answers[pos]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code à tester","metadata":{}},{"cell_type":"code","source":"while True:\n    text = str(input(\"Input: \"))\n    if text== \"exit\":\n        print(\"Response: Exiting.....\")\n        break\n    print(\"Response:\",reponse(text))","metadata":{},"execution_count":null,"outputs":[]}]}