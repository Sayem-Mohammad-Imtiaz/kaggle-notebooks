{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NYC Vehicle Collisions Analysis"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# data processing\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load NYPD Motor Vehicle Collisions file\ndf = pd.read_csv(\"/kaggle/input/nypd-motor-vehicle-collisions/nypd-motor-vehicle-collisions.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's quickly analyze what we've got here ^\n# 1.5 Million records\n# 1 Million with Borough and Zip Code info >> in other words, we're missing 500k location records\n# In case we have Location, we can do reverse Geocoding with GeoPY library and find out address (Borough + Zipcode)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CLEANING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Column header titles cleaning/renaming\n\n# Number of persons injured is the total of injured (pedestrians + cyclists + motorists)\n# If the number is 0, it means 0 injures and 0 deaths in an incident, but it's still a record\n\ndf.rename(columns = {'ZIP CODE'          : 'ZIP_CODE',\n                       'ON STREET NAME'    : 'STREET_ON',\n                       'CROSS STREET NAME' : 'STREET_CROSS',\n                       'OFF STREET NAME'   : 'STREET_OFF',\n                       'NUMBER OF PERSONS INJURED'     : 'TOTAL_INJURED',\n                       'NUMBER OF PERSONS KILLED'      : 'TOTAL_KILLED',\n                       'NUMBER OF PEDESTRIANS INJURED' : 'PED_INJURED',\n                       'NUMBER OF PEDESTRIANS KILLED'  : 'PED_KILLED',\n                       'NUMBER OF CYCLIST INJURED'     : 'CYC_INJURED',\n                       'NUMBER OF CYCLIST KILLED'      : 'CYC_KILLED',\n                       'NUMBER OF MOTORIST INJURED'    : 'MOTO_INJURED',\n                       'NUMBER OF MOTORIST KILLED'     : 'MOTO_KILLED',\n                       'CONTRIBUTING FACTOR VEHICLE 1' : 'VEH_FACTOR_1',\n                       'CONTRIBUTING FACTOR VEHICLE 2' : 'VEH_FACTOR_2',\n                       'CONTRIBUTING FACTOR VEHICLE 3' : 'VEH_FACTOR_3',\n                       'CONTRIBUTING FACTOR VEHICLE 4' : 'VEH_FACTOR_4',\n                       'CONTRIBUTING FACTOR VEHICLE 5' : 'VEH_FACTOR_5',\n                       'UNIQUE KEY' : 'UNIQUE_KEY',\n                       'VEHICLE TYPE CODE 1' : 'VEH_TYPE_1',\n                       'VEHICLE TYPE CODE 2' : 'VEH_TYPE_2',\n                       'VEHICLE TYPE CODE 3' : 'VEH_TYPE_3',\n                       'VEHICLE TYPE CODE 4' : 'VEH_TYPE_4',\n                       'VEHICLE TYPE CODE 5' : 'VEH_TYPE_5'},\n           inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values in columns\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Borough and Zipcode are missing ~500k records >> ~30% which is significant and we can't disregard it\n# I'll assign missing Borough records to NYC. It will be 5 boroughs and NYC to collect what's unassigned.\n\n# Remove Total Injured and Total Killed NaN values\n# TOTAL INJURED and TOTAL KILLED are > 0, otherwise it's justa a record, so let's keep only > 0 records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Borough and Zipcode are missing ~500k records >> ~30% which is significant and we can't disregard it\n# I'll assign missing Borough records to NYC. It will be 5 borougs and NYC to collect what's unassigned\n\n# Remove Total Injured and Total Killed NaN values\n# TOTAL INJURED and TOTAL KILLED are > 0, otherwise it's just a a record, so let's keep only > 0 records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill all blank values in column Borough\n# If a value is NaN it will be NYC\ndf.loc[df['BOROUGH'].isnull(), 'BOROUGH'] = 'NYC'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check it... BOROUGH should have 0 NaN values\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove NaN from TOTAL INJURED\ndf = df.dropna(axis=0, subset=['TOTAL_INJURED'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove NaN from TOTAL KILLED\ndf = df.dropna(axis=0, subset=['TOTAL_KILLED'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep only > 0 values as df1\ndf1 = df[(df['TOTAL_INJURED'] > 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep only non-zero values as df2\ndf2 = df[(df['TOTAL_KILLED'] > 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate df1 and df2 and put it back as df; 0 values are now out\ndf = pd.concat([df1, df2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine DATE and TIME column to transform Series to DateTime needed for further analysis\ndf['DATE'] = df['DATE'] + ' ' + df['TIME']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert string to DateTime\ndf['DATE'] = pd.to_datetime(df.DATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Year filter\ndf['DATE_YEAR'] = pd.to_datetime(df['DATE']).dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quarter filter\ndf['DATE_QUARTER'] = pd.to_datetime(df['DATE']).dt.quarter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Month filter\ndf['DATE_MONTH'] = pd.to_datetime(df['DATE']).dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Day of the week filter\ndf['WEEKDAY'] = pd.to_datetime(df['DATE']).dt.weekday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have 285,116 relevant records instead of 1.5 million and our file is 68 MB from 340 MB at the beginning\n# This file is now even readable with Excel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis & Visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Year 2012 starts in July and for that reason it's incomplete and we can't use it in our analysis. \n# Let's filter out 2012 and leave 2019 just as a reference for a trend (today is mid-August 2019)\ndf = df[(df['DATE'] > '2013-01-01')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Injured per year"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 25)).subplots_adjust(hspace = 0.4)\n\n# Total number of PERSONS injured\nplt.subplot(4, 2 ,1)\ndf.groupby('DATE_YEAR').TOTAL_INJURED.sum().plot.bar()\nplt.title('Total number of PERSONS INJURED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\n# Total number of MOTORISTS injured\nplt.subplot(4, 2, 2)\ndf.groupby('DATE_YEAR').MOTO_INJURED.sum().plot.bar()\nplt.title('Total number of MOTORISTS INJURED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\n# Total number of CYCLISTS injury\nplt.subplot(4, 2 ,3)\ndf.groupby('DATE_YEAR').CYC_INJURED.sum().plot.bar()\nplt.title('Total number of CYCLISTS INJURED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\n# Total number of PEDESTRIANS injured\nplt.subplot(4, 2, 4)\ndf.groupby('DATE_YEAR').PED_INJURED.sum().plot.bar()\nplt.title('Total number of PEDESTRIANS INJURED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Killed per year"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 25)).subplots_adjust(hspace = 0.4)\n\n# Total number of PERSONS killed\nplt.subplot(4, 2 ,1)\ndf.groupby('DATE_YEAR').TOTAL_KILLED.sum().plot.bar()\nplt.title('Total number of PERSONS KILLED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\n# TTotal number of MOTORISTS killed\nplt.subplot(4, 2, 2)\ndf.groupby('DATE_YEAR').MOTO_KILLED.sum().plot.bar()\nplt.title('Total number of MOTORISTS KILLED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\n# Total number of CYCLISTS killed\nplt.subplot(4, 2 ,3)\ndf.groupby('DATE_YEAR').CYC_KILLED.sum().plot.bar()\nplt.title('Total number of CYCLISTS KILLED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\n# Total number of PEDESTRIANS killed\nplt.subplot(4, 2, 4)\ndf.groupby('DATE_YEAR').PED_KILLED.sum().plot.bar()\nplt.title('Total number of PEDESTRIANS KILLED', fontsize=16)\nplt.xlabel('Year', fontsize=13)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of people injured and killed per borough\n- NYC is the sum of all incdents without known location"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, figsize=(25, 15))\n\nplt.subplot(2, 2 ,1)\ndf.groupby('BOROUGH').TOTAL_INJURED.sum().sort_values(ascending=False).plot.bar()\nplt.title('Number of people injured per borough', fontsize=18)\nplt.xlabel('Borough,   *NYC = unknown location incidents', fontsize=14)\n\nplt.subplot(2, 2 ,2)\ndf.groupby('BOROUGH').TOTAL_KILLED.sum().sort_values(ascending=False).plot.bar()\nplt.title('Number of people killed per borough', fontsize=18)\nplt.xlabel('Borough,   *NYC = unknown location incidents', fontsize=14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Per quarter analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of injured and killed per quarter\nfig, ax = plt.subplots(1, figsize=(25, 15))\n\nplt.subplot(2, 2 ,1)\ndf.groupby('DATE_QUARTER').TOTAL_INJURED.sum().plot.bar()\nplt.title('Total number of PERSONS INJURED', fontsize=18)\nplt.xlabel('Quarter', fontsize=14)\n\nplt.subplot(2, 2 ,2)\ndf.groupby('DATE_QUARTER').TOTAL_KILLED.sum().plot.bar()\nplt.title('Total number of PERSONS KILLED', fontsize=18)\nplt.xlabel('Quarter', fontsize=14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Day of the week analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of injured and killed per quarter\nfig, ax = plt.subplots(1, figsize=(25, 15))\nplt.subplot(2, 2 ,1)\ndf.groupby('WEEKDAY').TOTAL_INJURED.sum().plot.bar()\nplt.title('Total number of PERSONS INJURED per day of the week', fontsize=18)\nplt.xlabel('Weekday,    0 = Sunday', fontsize=14)\n\nplt.subplot(2, 2 ,2)\ndf.groupby('WEEKDAY').TOTAL_KILLED.sum().plot.bar()\nplt.title('Total number of PERSONS KILLED per day of the week', fontsize=18)\nplt.xlabel('Weekday,    0 = Sunday', fontsize=14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filling Zip code & Borough data - Reverse Geocoding\n- We can conduct the reverse Geocoding to obtain the address. All we need are the coordinates from column LOCATION (40.869335, -73.8255)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#--------------------------------------------------------------------------------\n# Example code that works:\n# from geopy.geocoders import Nominatim\n# geolocator = Nominatim(user_agent=\"geoapiExercises\")\n# from tqdm import tqdm\n# tqdm.pandas()\n# geolocator = Nominatim(user_agent=\"specify_your_app_name_here\")\n# from geopy.extra.rate_limiter import RateLimiter\n# geocode = RateLimiter(geolocator.geocode, min_delay_seconds=0.0, max_retries=2, error_wait_seconds=5.0, swallow_exceptions=True, return_value_on_exception=None)\n# df['ADDRESS'] = df['LOCATION'].progress_apply(geocode)\n\n# The down side: it will return only ~1,000 addresses per day\n# With GeoPY is possible to fill all NaN values in ZIP CODE and BOROUGH\n# Example: \n# Input: 40.88939, -73.89839 \n# Output: Broadway, Fieldston, The Bronx, Bronx County, NYC, New York, 10463, USA\n#--------------------------------------------------------------------------------","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}