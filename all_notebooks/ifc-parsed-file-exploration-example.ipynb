{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Requirements\nBasic knowledge of Python and Pandas is needed to follow this notebook. Check the subjects listed in these courses:\n\n- [Python course](https://www.kaggle.com/learn/python)\n- [Pandas course](https://www.kaggle.com/learn/pandas)\n- Check out [this](https://www.kaggle.com/ponybiam/introduction-to-ifcopenshell-functions) and [this](https://www.kaggle.com/ponybiam/ifc-parsing-example) notebooks to get familiar with the package `ifcopenshell`.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Load packages\nFirst we are going to install the `ifcopenshell` package. IfcOpenShell is an open source software library that helps users and software developers to work with the IFC file format. The IFC file format can be used to describe building and construction data. The format is commonly used for Building Information Modelling (BIM).\n\nRun the following code to install the package in the curren environment:","metadata":{}},{"cell_type":"code","source":"conda install -c conda-forge -c oce -c dlr-sc -c ifcopenshell ifcopenshell","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:53:42.463044Z","iopub.execute_input":"2021-07-25T13:53:42.463442Z","iopub.status.idle":"2021-07-25T13:55:17.207067Z","shell.execute_reply.started":"2021-07-25T13:53:42.46341Z","shell.execute_reply":"2021-07-25T13:55:17.205714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now we import the packages we are going to use in this notebook:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport ifcopenshell\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:55:17.569054Z","iopub.execute_input":"2021-07-25T13:55:17.569404Z","iopub.status.idle":"2021-07-25T13:55:17.574069Z","shell.execute_reply.started":"2021-07-25T13:55:17.569372Z","shell.execute_reply":"2021-07-25T13:55:17.572767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset\nWe are going to use the parsed IFC files we obtained in our [previous notebook](https://www.kaggle.com/ponybiam/ifc-parsing-example). We exported the file as `ifc_parsed_data.csv`:","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/example-ifc-file/ifc_parsed_data.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:56:13.972188Z","iopub.execute_input":"2021-07-25T13:56:13.972584Z","iopub.status.idle":"2021-07-25T13:56:14.017187Z","shell.execute_reply.started":"2021-07-25T13:56:13.97255Z","shell.execute_reply":"2021-07-25T13:56:14.016304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are going to add some fake data; the only purpose of this is to have a continuous variable to play around with some Pandas functions. Imagine we have a column name `price` with the cost of each element. We are going to create this column with a random value between 500 and 5000 (this, for sure, won't be realistic!) with the function `uniform` from the package `random` ([documentation here](https://docs.python.org/3/library/random.html#random.uniform)). Let's try it out:","metadata":{}},{"cell_type":"code","source":"random.uniform(500, 5000)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:56:29.976382Z","iopub.execute_input":"2021-07-25T13:56:29.976778Z","iopub.status.idle":"2021-07-25T13:56:29.983244Z","shell.execute_reply.started":"2021-07-25T13:56:29.976746Z","shell.execute_reply":"2021-07-25T13:56:29.982451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try running it several times: you will obtain a different value each time. We don't need so many decimals for our dataset, we can use the `round` function to get only 2:","metadata":{}},{"cell_type":"code","source":"# A random number\nnumber = random.uniform(500, 5000)\n# Let's round it to 2 decimal\nrounded_number = round(number, 2)\nrounded_number","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:56:44.548703Z","iopub.execute_input":"2021-07-25T13:56:44.549114Z","iopub.status.idle":"2021-07-25T13:56:44.556862Z","shell.execute_reply.started":"2021-07-25T13:56:44.549084Z","shell.execute_reply":"2021-07-25T13:56:44.555696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can create a simple function that gets through both steps:","metadata":{}},{"cell_type":"code","source":"def create_random_number(min, max):\n    return round(random.uniform(min, max), 2)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:57:03.781206Z","iopub.execute_input":"2021-07-25T13:57:03.781634Z","iopub.status.idle":"2021-07-25T13:57:03.787503Z","shell.execute_reply.started":"2021-07-25T13:57:03.781597Z","shell.execute_reply":"2021-07-25T13:57:03.786253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"An now we have to add the column to our dataset. We need to create a random value for each row in our dataset; a very usefull Python feature can accomplish this task easily: [list comprehensions](https://www.kaggle.com/colinmorris/loops-and-list-comprehensions). For example, let's create a list with the double of each number from 0 to 10:","metadata":{}},{"cell_type":"code","source":"# First, we get the numbers from 1 to 10. This can be done with \"range\" (last number is excluded and by default starts in 0)\nmy_numbers = range(11)\n# And now we create the list with list comprehension\n[2*number for number in my_numbers]","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:57:17.262112Z","iopub.execute_input":"2021-07-25T13:57:17.262589Z","iopub.status.idle":"2021-07-25T13:57:17.269422Z","shell.execute_reply.started":"2021-07-25T13:57:17.262555Z","shell.execute_reply":"2021-07-25T13:57:17.268664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This can be done with any function we want (insted of using `2*number`). In our case, we want to create a random number with the function `create_random_number` for each row of our dataset:","metadata":{}},{"cell_type":"code","source":"# First, we get the length of our dataset\nlast_number = len(data)\n# Now we create the list to iterate over\nmy_numbers = range(last_number)\n# And finally, we create the colum in pour dataset\ndata[\"price\"] = [create_random_number(500, 5000) for i in my_numbers]\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:57:29.572238Z","iopub.execute_input":"2021-07-25T13:57:29.57281Z","iopub.status.idle":"2021-07-25T13:57:29.594721Z","shell.execute_reply.started":"2021-07-25T13:57:29.572775Z","shell.execute_reply":"2021-07-25T13:57:29.59387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset exploration\n- [Grouping](#Grouping)\n- [Merging](#Merging)\n- [Unique values](#Unique-values)\n- count values by building \n- sorting by price\n- fill nan in description using map\n- new_id concating strings","metadata":{}},{"cell_type":"markdown","source":"## Grouping\nNow that we have the price of each element, how can we get the **mean price of each element type**? We can use the method `groupby`; keep this method always in mind cause you are going to use it a lot.\n\nYou need two things to group your data:\n- column (or columns) to group by (of course)\n- an aggregation function\n\nLet's start by counting how many elements if each `element_type` we have in our dataset:","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:57:53.44333Z","iopub.execute_input":"2021-07-25T13:57:53.443909Z","iopub.status.idle":"2021-07-25T13:57:53.452484Z","shell.execute_reply.started":"2021-07-25T13:57:53.443873Z","shell.execute_reply":"2021-07-25T13:57:53.450614Z"}}},{"cell_type":"code","source":"data.groupby(\"element_type\").count()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:58:03.071136Z","iopub.execute_input":"2021-07-25T13:58:03.071481Z","iopub.status.idle":"2021-07-25T13:58:03.096847Z","shell.execute_reply.started":"2021-07-25T13:58:03.071453Z","shell.execute_reply":"2021-07-25T13:58:03.095646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, as we didn't specified which column we want to count, you get the count for each one of the columns in our dataset (and we get a pandas dataframe in return). Let's try out choosing only one:","metadata":{}},{"cell_type":"code","source":"data.groupby(\"element_type\")[\"element_id\"].count()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:58:17.396668Z","iopub.execute_input":"2021-07-25T13:58:17.397016Z","iopub.status.idle":"2021-07-25T13:58:17.40625Z","shell.execute_reply.started":"2021-07-25T13:58:17.396988Z","shell.execute_reply":"2021-07-25T13:58:17.405353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we get a pandas series in return. Let's calculate the mean price:","metadata":{}},{"cell_type":"code","source":"data.groupby(\"element_type\")[\"price\"].mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:58:31.221651Z","iopub.execute_input":"2021-07-25T13:58:31.222081Z","iopub.status.idle":"2021-07-25T13:58:31.232898Z","shell.execute_reply.started":"2021-07-25T13:58:31.222046Z","shell.execute_reply":"2021-07-25T13:58:31.231947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merging\nImagine we want to add the mean price to our dataset. We shoul add to each row the corresponden mean price (depending on the element type). Forthis purpose we can create a dataset with the mean prices and merge it with our original dataset. This is called *merging* or *joining*; I strongly suggest [checking out the documentatio](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html), this is another of the methods you will me using a lot.\n\nFirst we create a dataset with our mean prices:","metadata":{}},{"cell_type":"code","source":"# First, we group and obtain the mean\nmean_price_serie = data.groupby(\"element_type\")[\"price\"].mean()\n# Then, we convert it into a dataframe\nmean_price = pd.DataFrame(mean_price_serie)\n# And we reset the index\nmean_price.reset_index(inplace=True)\n# We rename the column\nmean_price.rename(columns={\"price\":\"mean_price\"}, inplace=True)\n# Check it out\nmean_price","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:58:44.673868Z","iopub.execute_input":"2021-07-25T13:58:44.674411Z","iopub.status.idle":"2021-07-25T13:58:44.691625Z","shell.execute_reply.started":"2021-07-25T13:58:44.674377Z","shell.execute_reply":"2021-07-25T13:58:44.690346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now is time to merge. We will need:\n\n- Two dataframes\n- A common column, present in both dataframe, to merge over\n- How to join\n\nHere is illustrated how two datasets can be joined ([image source](https://data36.com/pandas-tutorial-3-important-data-formatting-methods-merge-sort-reset_index-fillna/)):\n![joining](https://data36.com/wp-content/uploads/2018/08/4-pandas-merge-inner-outer-left-right-768x579.png)\n\nWe want to add the `mean_price` column to our dataset: this could be accomplished with a left join of `mean_price` dataframe on `data` dataframe.","metadata":{}},{"cell_type":"code","source":"data1 = pd.merge(data, mean_price, how=\"left\", on=\"element_type\")\ndata1.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:59:03.352867Z","iopub.execute_input":"2021-07-25T13:59:03.353414Z","iopub.status.idle":"2021-07-25T13:59:03.386391Z","shell.execute_reply.started":"2021-07-25T13:59:03.353362Z","shell.execute_reply":"2021-07-25T13:59:03.385209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unique values\nWhen you group by a column, you get as index the unique values of that column. But, what if only need the unique values? We don't need to group the data in order to get it, we can use the method `unique`, that can  be applied to any serie. For example, let's fin the unique values of the columns `element_type` and `bdg_name`:","metadata":{}},{"cell_type":"code","source":"# Get the unique values\nunique_element_type = data1.element_type.unique()\nunique_bdg_name = data1.bdg_name.unique()\n# Print it\nprint(f\"Unique element types: {unique_element_type}\\n\\nUnique building names: {unique_bdg_name}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:59:18.993114Z","iopub.execute_input":"2021-07-25T13:59:18.993472Z","iopub.status.idle":"2021-07-25T13:59:19.002552Z","shell.execute_reply.started":"2021-07-25T13:59:18.993443Z","shell.execute_reply":"2021-07-25T13:59:19.001337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}