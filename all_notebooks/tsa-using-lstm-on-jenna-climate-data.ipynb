{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf1 = pd.read_csv('/kaggle/input/jena-climate-2009-2016/jena_climate_2009_2016.csv',index_col = None)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Replace -9999 with 0**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['wv (m/s)']=df1['wv (m/s)'].replace(-9999.00, 0)\ndf1['max. wv (m/s)']=df1['max. wv (m/s)'].replace(-9999.00, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df1.corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To know the indices of point of split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df1[df1[\"Date Time\"]=='31.12.2014 23:50:00'].index.values)\nprint(df1[df1[\"Date Time\"]=='31.12.2015 23:50:00'].index.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing the redundant features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.iloc[:, [0, 1,2,6,8,9,11,12]]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extract Date-Time column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sin-Cos Extraction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"timestamp_s = date_time.map(datetime.datetime.timestamp)\nday = 24*60*60\nyear = (365.2425)*day\n\ndf['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\ndf['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\ndf['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\ndf['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split fraction to use 6 yrs of training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"split_fraction = 0.75075\ntrain_split = int(split_fraction * int(df.shape[0]))\n\nstep = 6\npast = 720\nfuture = 72\nbatch_size = 256\nepochs = 8\n\ndata_mean = df[:train_split].mean(axis=0)\ndata_std = df[:train_split].std(axis=0)\n\ndf=(df-data_mean)/data_std\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalising the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = normalize(df.values, train_split)\ndf=df.values\ndf = pd.DataFrame(df)\ndf.head()\n\ntrain_data = df.loc[0 : train_split - 1]\nval_data = df.loc[train_split:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = past + future\nend = start + train_split\n\nx_train = train_data[[i for i in range(11)]].values\ny_train = df.iloc[start:end][[1]]\n\nsequence_length = int(past / step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape == {}.'.format(x_train.shape))\nprint('y_train shape == {}.'.format(y_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n    x_train,\n    y_train,\n    sequence_length=sequence_length,\n    sampling_rate=step,\n    batch_size=batch_size,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_end = len(val_data) - past - future\n\nlabel_start = train_split + past + future\n\nx_val = val_data.iloc[:x_end][[i for i in range(11)]].values\ny_val = df.iloc[label_start:][[1]]\n\ndataset_val = keras.preprocessing.timeseries_dataset_from_array(\n    x_val,\n    y_val,\n    sequence_length=sequence_length,\n    sampling_rate=step,\n    batch_size=batch_size,\n)\n\n\nfor batch in dataset_train.take(1):\n    inputs, targets = batch\n\nprint(\"Input shape:\", inputs.numpy().shape)\nprint(\"Target shape:\", targets.numpy().shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.001\ninputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\nlstm_out = keras.layers.LSTM(48)(inputs)\noutputs = keras.layers.Dense(1)(lstm_out)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I am suing ModelCheckpoint to save checkpoints, and the EarlyStopping to stop training when the validation loss is not longer improving.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npath_checkpoint = \"model_checkpoint.h5\"\nes_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n\nmodelckpt_callback = keras.callbacks.ModelCheckpoint(\n    monitor=\"val_loss\",\n    filepath=path_checkpoint,\n    verbose=1,\n    save_weights_only=True,\n    save_best_only=True,\n)\n\nhistory = model.fit(\n    dataset_train,\n    epochs=epochs,\n    validation_data=dataset_val,\n    callbacks=[es_callback, modelckpt_callback],\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tarining is lower then validation Loass, it means the model is slightly over fittting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_loss(history, title):\n    loss = history.history[\"loss\"]\n    val_loss = history.history[\"val_loss\"]\n    epochs = range(len(loss))\n    plt.figure()\n    \n    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n    plt.title(title)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\n\nvisualize_loss(history, \"Training and Validation Loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std=data_std[1]\navg=data_mean[1]\n   \ndef show_plot(plot_data, delta, title):\n    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n    marker = [\".-\", \"rx\", \"go\"]\n    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n    if delta:\n        future = delta\n    else:\n        future = 0\n\n    plt.title(title)\n    for i, val in enumerate(plot_data):\n        if i:\n            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n        else:\n            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n    plt.legend()\n    plt.xlim([time_steps[0], (future + 5) * 2])\n    plt.xlabel(\"Time-Step\")\n    plt.show()\n    return\n\n\nfor x, y in dataset_val.take(20):\n    p=x[0][:, 1].numpy()\n    q=y[0].numpy()\n    p=p*std+avg\n    q=q*std+avg\n    pred=model.predict(x)[0]\n    pred=(pred*std + avg)\n    \n    show_plot(\n        [p, q, pred],\n        12,\n        \"Single Step Prediction\",\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}