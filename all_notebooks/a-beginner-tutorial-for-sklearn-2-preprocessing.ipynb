{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1-Introduction\n\nThis kernel is a successive kernel of the [previous kernel on a serie of a number of tutorials on the scikit-learn library](https://www.kaggle.com/yassirarezki/a-beginner-tutorial-for-sklearn-1-introduction). In the current work, the different functions for preprocessing the data will be visited. \n\nPreprocessing the data is a crucial step in ML and much care should be brought to this step before moving to constructing the model.\n\nI refere to the subsection 6.3 titled preprocessing in the skelarn user guide.\n\nA first step is to import some tools namely: pandas (for dataframes management), numpy for caluclus and matplotlib and seaborn for visualisation."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us import the data. I remind you that the data comes from [the medical cost personal dataset](https://www.kaggle.com/mirichoi0218/insurance). You can find the motication of this choice in my previous kernel."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/insurance/insurance.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Let us have a first look at the dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the data gathers the information of a number of 1338 patients. This includes: \n\n* the sex, \n\n* the body mass index (BMI), \n\n* the number of children the patien has\n\n* whether the patient is a smoker or not\n\n* the region\n\n* and finally the target variable which is the medical cost or charge.\n\nSo you might understand that this is a regression problem since we are trying to predict a continous variable (charges)."},{"metadata":{},"cell_type":"markdown","source":"Let us just check the number of null varaibles that exist in the data set. This could be achived in two manners eithe using the isnull function of the info function. The second way provides additional information about the data such as the type of the data in each column."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us now focus on the target variable: charges. We draw the histogram of this variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We create a frame for the figure. The figsize is only to set the size of the figure.\nplt.figure(figsize=(16,9))\n\n# we use the function distplot from the sns library to plot the historgram in the previously specified space.\nsns.distplot(df.charges)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2- Standardizing the data\n\nThe main objective of data standardization is to bring the mean to 0 and the varuiance to 1. This could be achived by substracting the mean of the raw data and divinding by the standard deviation of the raw data. standardization can boost the perforamnce of the algorithms. \n\nLet us first have a look at the mean and the standard devaition of the raw data."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The mean of the charges is {0:.2f}\".format(df.charges.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The standard deviation of the charges is {0:.2f}\".format(df.charges.std(),2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In order to normalize the data we can use either:\n\n* scale\n* StandardScaler\n\nThe second function could be used in the following situation: Suppose we have two data set, we apply standardization on the first one and we would like to apply the same transformation to the second. This could not be performed using the former.\n\nLet us go back to our data and let us apply the two functions on the charges variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, we need to import the scale from preprocessing that also belongs to sklearn\nfrom sklearn.preprocessing import scale\ncharges_scaled = scale(df.charges)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us now check the mean and the standard devation of the resulting data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The mean of the charges (scaled) is {0:.2}\".format(charges_scaled.mean()))\nprint(\"The standard deviation of the charges (scaled) is {0:.2}\".format(charges_scaled.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Note:** In the example above, the scale function was applied to the charges column only. However, it could be applied to more that one column and each one will be transformed seperately.\n\nNow there is a question that might arise. Did the distribution change after applying this transormation? Let us check."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,9))\nsns.distplot(charges_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The answer is No. Only the range of the axis moved. The layout of the distribution is similar as before applying the transformation.\n\nNow, we show the benefits of using standadscaler. In this case, we do not apply a straight function as in the case of scale but we create a transformer (an object). "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# Create a transformer and call it as you like. Here I used my_created_transformer\nmy_created_transformer = StandardScaler()\n# Now we fit our tranformer to our data.\nmy_created_transformer.fit(df.charges)\n# After that we can transform the data\ncharges_scaled = my_created_transformer.transform(df.charges)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you have tried to apply the previous command the code will not work. This is why I recommended the use of variable inspector in my previous tutorial. In fact the .fit() function takes only arrays while df.charges is a Serie. In order to cope with this, you should transform it to an array. This could be achived using:\n\n    my_created_transformer.fit(df.charges.values)\n    \nEven though the code will not work because df.charges.values is an array with dimension (1338, ) while it should be (1338, 1). So you need to reshape the array in order to have that size."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# Create a transformer and call it as you like. Here I used my_created_transformer\nmy_created_transformer = StandardScaler()\n# Now we fit our tranformer to our data.\nmy_created_transformer.fit(df.charges.values.reshape(-1, 1))\n# After that we can transform the data\ncharges_scaled = my_created_transformer.transform(df.charges.values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A fast check:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The mean of the charges (scaled) is {0:.2}\".format(charges_scaled.mean()))\nprint(\"The standard deviation of the charges (scaled) is {0:.2}\".format(charges_scaled.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now if I want to apply the same transformation (the one obtained using charges) to an other variable (age for example), I can use my transformer previously created and fitted. All what I need is to apply transform on the new variable (age in this case) whitout the need to create a new transformer."},{"metadata":{"trusted":true},"cell_type":"code","source":"age_scaled = my_created_transformer.transform(df.age.values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**A question:** do you think the variable age_scaled will have a mean 0 and a standard deviation of 1 as the charges variable?\n\nI let you check this question.\n\nIf the answer is yes: You are completely wrong. Please add a comment if this point is left unclear.\n\n**Note:** The standardScaler function allows the user to select whether to center the data (bring the mean to 0) or scale the data (bring the standard deviation to 1) by setting: with_std=False in the former case and setting with_mean=False in the latter.\n\nBelow is a code line for a transformer that uses centering only.\n\n    scaler_with_centering_only = StandardScaler(with_std=False)\n"},{"metadata":{},"cell_type":"markdown","source":"# 3- Scaling to a range\n\nIf we would like to set a condition on the maximum and minimum values whithin a data set, we can use scaling to a range. Scaling to a range, unlike to standardization, will preserve 0 values that exist in the data. \n\nThe structure of the command is the same as for standardScaler. MinMaxScaler or MaxAbsScaler are used instead. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n# Create a new transformer. If you do not set any paramter, the data is scaled to the range [0, 1]. \n# in order to set a range, you need to include: feature_range=(min, max). In the example we use min=3, max=7\nmy_created_transformer = MinMaxScaler(feature_range=(3, 7))\n# Fit the data to scaler\nmy_created_transformer.fit(df.charges.values.reshape(-1, 1))\n#Transform the data\ncharges_scaled_range = my_created_transformer.transform(df.charges.values.reshape(-1, 1))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us have a look at the distribution of the data after applying the transformation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,9))\nsns.distplot(charges_scaled_range)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, you can see on the X axis that the data is in the range [3, 7] as specified.\n\n**Question:** If you use the same transformer (my_created_transformer that was fitted on the charges variable) to the age variable for instance, Would the scaled data be in the range [3, 7]? leave your answer in a comment."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}