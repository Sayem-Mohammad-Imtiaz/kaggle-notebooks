{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"training loss , val loss curve\nplotting the distribution\nclean data even more\nvisualize the tree ? \ntree pruning ? \nshow results after every technique","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nfrom keras.regularizers import l1_l2\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nfrom keras import models, layers\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, multilabel_confusion_matrix, f1_score\nfrom sklearn.preprocessing import normalize\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import metrics,optimizers\n\nimport matplotlib.pyplot as plt\n\nfrom keras.backend import clear_session\nimport re","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:30:26.302724Z","iopub.execute_input":"2021-06-09T19:30:26.303148Z","iopub.status.idle":"2021-06-09T19:30:32.808412Z","shell.execute_reply.started":"2021-06-09T19:30:26.303058Z","shell.execute_reply":"2021-06-09T19:30:32.807498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.read_csv('/kaggle/input/movie-plot-title-data/data.csv', index_col = 'Unnamed: 0')['0']\ny = pd.read_csv('/kaggle/input/movie-plot-title-data/labels.csv', index_col = 'Unnamed: 0')\ny = y.iloc[:,np.where(y.sum(axis = 0) > 800)[0]]\n\nX.drop(np.where(y.sum(axis = 1) == 0)[0], inplace = True)\ny.drop(np.where(y.sum(axis = 1) == 0)[0], inplace =True)\ngenre_list =list(y.columns)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:30:32.810008Z","iopub.execute_input":"2021-06-09T19:30:32.810453Z","iopub.status.idle":"2021-06-09T19:30:34.78453Z","shell.execute_reply.started":"2021-06-09T19:30:32.810411Z","shell.execute_reply":"2021-06-09T19:30:34.783512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.sum(axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:30:34.786241Z","iopub.execute_input":"2021-06-09T19:30:34.786567Z","iopub.status.idle":"2021-06-09T19:30:34.798505Z","shell.execute_reply.started":"2021-06-09T19:30:34.786518Z","shell.execute_reply":"2021-06-09T19:30:34.797499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def preprocess_text(sen):\n#     # Remove punctuations and numbers\n#     sentence = re.sub('[^a-zA-Z.]', ' ', sen)\n\n#     # Single character removal\n#     sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n\n#     # Removing multiple spaces\n#     sentence = re.sub(r'\\s+', ' ', sentence)\n\n#     return sentence\n# X = X.apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:30:34.800749Z","iopub.execute_input":"2021-06-09T19:30:34.801187Z","iopub.status.idle":"2021-06-09T19:30:34.809724Z","shell.execute_reply.started":"2021-06-09T19:30:34.801142Z","shell.execute_reply":"2021-06-09T19:30:34.809005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'sigmoid' activaation and 'binary_crossentropy' loss\n\nUsing count_vec or tfidf with normalization","metadata":{}},{"cell_type":"code","source":"def data_generator(data, label, batch_size = 32):\n    while True:\n        rows = np.random.randint(0, len(data), size = batch_size)\n        yield data[rows,:], np.array(label)[rows,:]\ndef nn_preds_to_classes(preds, threshold = 0.3):\n    classes_preds = np.zeros(preds.shape)\n    rows, columns = np.where(preds > threshold)\n    for i in range(len(rows)):\n        classes_preds[rows[i],columns[i]] = 1\n    return classes_preds\ndef eval_nn_model(model, xtest, ytest):\n    preds = nn_preds_to_classes(model.predict(xtest))\n    \n    test_score = f1_score(ytest, preds, average = None)\n    return test_score, preds\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:30:34.810827Z","iopub.execute_input":"2021-06-09T19:30:34.811333Z","iopub.status.idle":"2021-06-09T19:30:34.823055Z","shell.execute_reply.started":"2021-06-09T19:30:34.811301Z","shell.execute_reply":"2021-06-09T19:30:34.822181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_words = 10000\n\nmaxlen = 5000\n\nxtrain, xval, ytrain, yval = train_test_split(X,y, random_state = 0, train_size = 0.8)\n\ntokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(xtrain)\nxtrain = pad_sequences(tokenizer.texts_to_sequences(xtrain), maxlen = maxlen)\nxval = pad_sequences(tokenizer.texts_to_sequences(xval), maxlen = maxlen)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:30:34.824569Z","iopub.execute_input":"2021-06-09T19:30:34.825096Z","iopub.status.idle":"2021-06-09T19:30:52.658961Z","shell.execute_reply.started":"2021-06-09T19:30:34.825063Z","shell.execute_reply":"2021-06-09T19:30:52.657927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = {}\nwith open('/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.50d.txt') as f : \n    for line in f.readlines():\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings[word] = coefs\nf.close()\n\nembeddings_dim = 50\nembeddings_matrix = np.zeros((max_words, embeddings_dim))\nfor word, i in tokenizer.word_index.items():\n    if i < max_words:\n        embedding_vec = embeddings.get(word)\n        if embedding_vec is not None:\n            embeddings_matrix[i] = embedding_vec\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:30:52.660575Z","iopub.execute_input":"2021-06-09T19:30:52.66089Z","iopub.status.idle":"2021-06-09T19:31:04.579522Z","shell.execute_reply.started":"2021-06-09T19:30:52.660858Z","shell.execute_reply":"2021-06-09T19:31:04.578527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-1,\n    decay_steps=10000,\n    decay_rate=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:31:04.581636Z","iopub.execute_input":"2021-06-09T19:31:04.58196Z","iopub.status.idle":"2021-06-09T19:31:04.588526Z","shell.execute_reply.started":"2021-06-09T19:31:04.581929Z","shell.execute_reply":"2021-06-09T19:31:04.587717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:31:04.590236Z","iopub.execute_input":"2021-06-09T19:31:04.590665Z","iopub.status.idle":"2021-06-09T19:31:10.028953Z","shell.execute_reply.started":"2021-06-09T19:31:04.590621Z","shell.execute_reply":"2021-06-09T19:31:10.0281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"31 - 33 : 64 lstm, 128 dense, rmsprop ( 37%)\nLSTM 64, dropout 0.2, dense 64 1e-3 l2 dropout 0.2 16 epochs : 48%","metadata":{}},{"cell_type":"code","source":"with tpu_strategy.scope():    \n    model = models.Sequential()\n    model.add(layers.Embedding(max_words, embeddings_dim,  input_length = xtrain.shape[1]))\n    model.add(layers.LSTM(64))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(64,kernel_regularizer = l1_l2(l1 = 0, l2 = 1e-3)))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(len(genre_list), activation = 'sigmoid'))\n    model.compile(loss = 'binary_crossentropy',\n                  optimizer = optimizers.RMSprop(),\n                  metrics = [metrics.AUC()])\n\n    model.summary()\n\n    model.layers[0].set_weights([embeddings_matrix])\n    model.layers[0].trainable = False\n\nhistory = model.fit(xtrain,ytrain,batch_size = 16,\n                    epochs = 20,\n                    validation_data = (xval,yval)\n                  )\nval_preds = model.predict(xval)\n#     train_preds = model.predict(xtrain)\npreds_classes = nn_preds_to_classes(val_preds, threshold = 0.5)\nval_score = precision_recall_fscore_support( yval, preds_classes, zero_division = 1)\nprint(val_score)\nprint(val_score[0].mean())\nprint(val_score[1].mean())\n\nprint(val_score[2].mean())\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T20:23:39.480938Z","iopub.execute_input":"2021-06-09T20:23:39.48128Z","iopub.status.idle":"2021-06-09T20:58:16.479793Z","shell.execute_reply.started":"2021-06-09T20:23:39.481249Z","shell.execute_reply":"2021-06-09T20:58:16.478823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clear_session()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T19:38:23.919874Z","iopub.status.idle":"2021-06-09T19:38:23.920297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict = history.history\nfig = plt.figure(figsize = (10,10))\nplt.plot([i for i in range(20)], history_dict['loss'], label = 'training loss')\n\nplt.plot([i for i in range(20)], history_dict['val_loss'],label = 'validation loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:00:33.745586Z","iopub.execute_input":"2021-06-09T21:00:33.74593Z","iopub.status.idle":"2021-06-09T21:00:33.944079Z","shell.execute_reply.started":"2021-06-09T21:00:33.7459Z","shell.execute_reply":"2021-06-09T21:00:33.94332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds = model.predict(xval)\n#     train_preds = model.predict(xtrain)\npreds_classes = nn_preds_to_classes(val_preds, threshold = 0.5)\nval_score = precision_recall_fscore_support( yval, preds_classes, zero_division = 1)\nprint(val_score)\nprint(val_score[0].mean())\nprint(val_score[1].mean())\n\nprint(val_score[2].mean())","metadata":{"execution":{"iopub.status.busy":"2021-06-09T20:05:55.127514Z","iopub.execute_input":"2021-06-09T20:05:55.128008Z","iopub.status.idle":"2021-06-09T20:05:59.70691Z","shell.execute_reply.started":"2021-06-09T20:05:55.127977Z","shell.execute_reply":"2021-06-09T20:05:59.706115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,10))\nplt.bar(y.columns, val_score[2])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:02:52.485154Z","iopub.execute_input":"2021-06-09T21:02:52.485653Z","iopub.status.idle":"2021-06-09T21:02:52.673207Z","shell.execute_reply.started":"2021-06-09T21:02:52.485619Z","shell.execute_reply":"2021-06-09T21:02:52.672189Z"},"trusted":true},"execution_count":null,"outputs":[]}]}