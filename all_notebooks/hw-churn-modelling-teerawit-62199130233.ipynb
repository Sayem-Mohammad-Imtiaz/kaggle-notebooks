{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/churn-modelling/Churn_Modelling.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='number')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check NULL\nprint(df.isnull().sum().sum())\nprint(df.isnull().any())\nimport missingno as msno\nmsno.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#numberic_columns\nf_columns = ['CreditScore', 'Age', 'Tenure', 'Balance','NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n\nX = df.loc[:, f_columns].values\ny = df.iloc[:, -1].values\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make train/test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X= StandardScaler()\nX_train= sc_X.fit_transform(X_train)\nX_test= sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **K-Nearest Neighbor**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting K-Nearest Neighbor Classification to the Training Set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors =5,metric = 'minkowski',p=2)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\n# Predicting the Test Set results\nfrom sklearn.metrics import confusion_matrix\nresult = confusion_matrix(y_pred,y_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_KN = confusion_matrix(y_test, y_pred)\ncm_KN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performace with confusion metrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy_KN = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance for K-Nearest Neighbor :\")\nprint(\"\\n Accuracy = \" + str(accuracy_KN*100), '%')\nprint(\"\\n Precision = \" + str(precision*100),'%')\nprint(\"\\n Recall = \" + str(recall*100),'%')\nprint(\"\\n f1 = \" + str(f1*100),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Support Vector Machine (SVM)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting SVM to the Training Set\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', degree = 3, random_state = 0) #degree for non-linear\nclassifier.fit(X_train, y_train) \n\n# Predicting the Test Set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_SVM_linear = confusion_matrix(y_test, y_pred)\ncm_SVM_linear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performace with confusion metrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy_li = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance for Support Vector Machine (Linear) :\")\nprint(\"\\n Accuracy = \" + str(accuracy_li*100), '%')\nprint(\"\\n Precision = \" + str(precision*100),'%')\nprint(\"\\n Recall = \" + str(recall*100),'%')\nprint(\"\\n f1 = \" + str(f1*100),'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting SVM to the Training Set\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'poly', degree = 5, random_state = 0) #degree for non-linear\nclassifier.fit(X_train, y_train) \n\n# Predicting the Test Set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_SVM_poly = confusion_matrix(y_test, y_pred)\ncm_SVM_poly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performace with confusion metrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy_poly = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance for Support Vector Machine (Poly) :\")\nprint(\"\\n Accuracy = \" + str(accuracy_poly*100), '%')\nprint(\"\\n Precision = \" + str(precision*100),'%')\nprint(\"\\n Recall = \" + str(recall*100),'%')\nprint(\"\\n f1 = \" + str(f1*100),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Naive Bayes to the Training Set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test Set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_NB = confusion_matrix(y_test, y_pred)\ncm_NB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performace with confusion metrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy_nb = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance for Naive Bayes :\")\nprint(\"\\n Accuracy = \" + str(accuracy_nb*100), '%')\nprint(\"\\n Precision = \" + str(precision*100),'%')\nprint(\"\\n Recall = \" + str(recall*100),'%')\nprint(\"\\n f1 = \" + str(f1*100),'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# create some fake data\npercentages = pd.Series([accuracy_KN,accuracy_li,accuracy_poly,accuracy_nb], \n                        index=['K-Nearest Neighbor','SVM Liner','SVM Poly','Naive Bayes'])\ndf = pd.DataFrame({'percentage' : percentages})\ndf = df.sort_values(by='percentage')\n\n# we first need a numeric placeholder for the y axis\nmy_range=list(range(1,len(df.index)+1))\n\nfig, ax = plt.subplots(figsize=(5,3.5))\n\n# create for each expense type an horizontal line that starts at x = 0 with the length \n# represented by the specific expense percentage value.\nplt.hlines(y=my_range, xmin=0, xmax=df['percentage'], color='#007ACC', alpha=0.2, linewidth=5)\n\n# create for each expense type a dot at the level of the expense percentage value\nplt.plot(df['percentage'], my_range, \"o\", markersize=5, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('Accuracy', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.yticks(my_range, df.index)\n\n# add an horizonal label for the y axis \nfig.text(-0.23, 0.96, 'Algorithm', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}