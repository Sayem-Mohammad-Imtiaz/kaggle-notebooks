{"cells":[{"metadata":{"_uuid":"d00247be6844898ef064099f5cd5c45db21e39ac"},"cell_type":"markdown","source":"## Implementation of Multilayer Perceptron\nImplementation without to use library, i just used basic libraries.\n\n**Dataset**: Dermatology\n\n**PS:** Neural Network with 2 layers."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rnd\nfrom random import randint\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef9a4f0e27f13f9d1c3fefd1c10c3f8728e33870"},"cell_type":"markdown","source":"### Import dataset and get the information"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dss = pd.read_csv(\"../input/derm.csv\")\ndss.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a305c596af2188ba69b34ca6e7de6afff6a28833"},"cell_type":"markdown","source":"### Prepare the dataset\nI should remove the \"age\" column because the column, there is empty data on some line."},{"metadata":{"trusted":true,"_uuid":"eda32e4049b43b231f2d4db5a4ebb29153403415"},"cell_type":"code","source":"dss.drop(['age'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0091e8ecda02f59a892ba7cdc7ff66f24785353"},"cell_type":"markdown","source":"### Basic variable"},{"metadata":{"trusted":true,"_uuid":"661f58e507f0ab4d6f7afd0d7aac8b398f5e0527"},"cell_type":"code","source":"last_col = dss.columns[len(dss.columns)-1]\nclasses = list(dss[last_col].unique())\nlen_cols = len(dss.columns) - 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f63323492589ed19ff1fa6bf85ae7cbce87dbbe9"},"cell_type":"markdown","source":"### Implementation of One Hot Encoder/Decoder"},{"metadata":{"trusted":true,"_uuid":"3eb8349b637dad5f8cd6fa7de7d99a1556526723"},"cell_type":"code","source":"# One Hot Codification\n# Coding using zeros' array and 1 to each class\ndef one_hot_encoding(classes):\n    cl_onehot = np.zeros((len(classes),len(classes)),dtype=int)\n    np.fill_diagonal(cl_onehot,1)\n    r = [(classes[i], cl) for i, cl in enumerate(cl_onehot)]\n    return r\n\n# Encode the expected classes\ndef encode_expected(expected, encoded_class):\n    return np.array([ list(filter(lambda e: e[0] == x, encoded_class))[0][1] for x in expected ])\n\n# Encode all the dataset classes\ndef encode_class(ds):\n    return one_hot_encoding(pd.unique(ds.iloc[:,-1:].values.flatten()))\n\n# Decode the result\ndef decode_result(encoded_class, value):\n    if sum(value) != 1:\n        value = list(encoded_class[randint(0,len(encoded_class)-1)][1])\n    return list(filter(lambda x: list(x[1]) == value,encoded_class))[0][0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c072efd31bd32d1273bf81c4a22a2c0f426a6512"},"cell_type":"markdown","source":"### Create Layer Class"},{"metadata":{"trusted":true,"_uuid":"8474c2d2688b82d4270ae934e1744c8397a9ed8e"},"cell_type":"code","source":"# Class to represent the hidden layer\nclass NeuronLayer():\n    def __init__(self, number_of_neurons, number_of_inputs_per_neuron):\n        self.synaptic_weights = 2 * np.random.random((number_of_inputs_per_neuron, number_of_neurons)) - 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c48a40fd9aabd64d702fabc21e3e6e1a79d63203"},"cell_type":"markdown","source":"### Create a main class to neural network"},{"metadata":{"trusted":true,"_uuid":"80e3b83d6fc74f903cde26f196b56740b25a529c"},"cell_type":"code","source":"# Classe to represent the neural network (by default, it was made with two layers)\n\nclass NeuralNetwork():\n    \n    # Construct method\n    def __init__(self, layer1, layer2):\n        self.layer1 = layer1\n        self.layer2 = layer2\n        \n    # Sigmoid function\n    def __sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n    # sigmoid's derivative\n    def __sigmoid_derivative(self, x):\n        return x * (1 - x)\n    \n    # Add bias\n    def __add_bias(self, inputs_training):\n        return np.array([ np.append(i,-1) for i in inputs_training])\n    \n    # Train network - Used: Delta Rule\n    def train(self, inputs_training, outputs_training, num_interation, rate):\n        \n        inputs_training = self.__add_bias(inputs_training)\n        \n        for interate in range(0,num_interation):\n            # Calcule the result of neuron\n            output_layer1, output_layer2 = self.__think(inputs_training)\n            \n            # Calcule the layer 2 error\n            layer2_error = outputs_training - output_layer2\n            layer2_delta = layer2_error * self.__sigmoid_derivative(output_layer2)\n            \n            # Calcule layer 1 error\n            layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)\n            layer1_delta = layer1_error * self.__sigmoid_derivative(output_layer1)\n            \n            # How much adjustment it will take in synaptic weights\n            layer1_adjustment = inputs_training.T.dot(layer1_delta) * rate\n            layer2_adjustment = output_layer1.T.dot(layer2_delta) * rate\n            \n            #Adjust synaptic weights\n            self.layer1.synaptic_weights += layer1_adjustment\n            self.layer2.synaptic_weights += layer2_adjustment\n            \n    # Return the output of neuron layer\n    def __think(self, input_training):\n        output_layer1 = self.__sigmoid(np.dot(input_training, self.layer1.synaptic_weights))\n        output_layer2 = self.__sigmoid(np.dot(output_layer1, self.layer2.synaptic_weights))\n        \n        return output_layer1, output_layer2\n    \n    # Predict passing the datas\n    def predict(self, input_):\n        input_ = input_ + [-1] \n        h, out = self.__think(input_)\n        result = [1 if o >= 0.5 else 0 for o in out]\n        return result\n        \n    # Print weights\n    def print_weights(self):\n        \n        print('Layer 1:')\n        print(self.layer1.synaptic_weights)\n        print('Layer 2:')\n        print(self.layer2.synaptic_weights)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c6799a1abf4d754a34ce76efbdb75cdda79fd25"},"cell_type":"markdown","source":"### Train and count results of training"},{"metadata":{"trusted":true,"_uuid":"ccf9debd2c4b08a9812870236aa42ca985e57744"},"cell_type":"code","source":"def train(dataset_train, dataset_test):\n    count_correct = 0\n    count_incorrect = 0\n    \n    count_by_classes_correct = [0 for i in range(0,len(classes))]\n    count_by_classes_incorrect = [0 for i in range(0,len(classes))]\n    \n    # Encode the classes of dataset\n    encoded_class = encode_class(dataset_train)\n    \n    # Neural network with 2 layers, One with 16 neurons and other with 6 neurons.\n    \n    # Layer 1: Make 16 neurons com 33 inputs (quantity of input from dataset)\n    l1 = NeuronLayer(32,len_cols + 1)\n    # Layer 2: Make 12 nerons with 16 input from the other neuron layers (output layer)\n    l2 = NeuronLayer(len(classes), 32)\n    \n    neural_network = NeuralNetwork(l1, l2)\n    \n    inputs = dataset_train.iloc[:,:-1].values\n    outputs = dataset_train.iloc[:,-1:].values\n    \n    outputs_encoded = encode_expected(outputs,encoded_class)\n    \n    neural_network.train(inputs, outputs_encoded, 10000, 0.01)\n    \n    for index, row in dataset_test.iterrows():\n        \n        tuple_t = list(row)\n        tuple_t.pop()\n        \n        r = neural_network.predict(tuple_t) # Performs the result by the value of the network\n        \n        result = decode_result(encoded_class, r)\n        \n        #Result\n        if result == row[last_col]:\n            count_correct += 1\n            count_by_classes_correct[classes.index(result)] += 1\n        else:\n            count_incorrect += 1\n            count_by_classes_incorrect[classes.index(result)] += 1\n        \n    return count_correct, count_incorrect, count_by_classes_correct, count_by_classes_incorrect","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e1b5bb5f0f76ca8bf37853427f2753f8aced2e0"},"cell_type":"markdown","source":"### Separate dataset by class\nThis function return the dataset separate by classes<br>\nIt's similar function **sklearn.model_selection.train_test_split**"},{"metadata":{"trusted":true,"_uuid":"cc1272555fb2eacab99b6d7868b149382cdaf810"},"cell_type":"code","source":"def seperate_ds_by_class(dataset, percentage):\n    rds_train = pd.DataFrame()\n    rds_test = pd.DataFrame()\n    \n    for c in classes:\n        nds = dataset[dataset[last_col]==c]\n        \n        ds_train = nds.sample(frac=percentage, random_state=randint(0,15100))\n        ds_test = nds.drop(ds_train.index) \n        \n        rds_train = rds_train.append(ds_train)\n        rds_test = rds_test.append(ds_test)\n        \n    rds_train = rds_train.reset_index()\n    rds_test = rds_test.reset_index() \n\n    rds_train.drop('index',1,inplace=True) \n    rds_test.drop('index',1,inplace=True) \n    \n    return (rds_train, rds_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b8b0ff39e42117245b1a055f2ea7a68b2271a47"},"cell_type":"markdown","source":"### Execute"},{"metadata":{"trusted":true,"_uuid":"e088ba38eaf53a99a10f35936fd0248ba3b1f4ff"},"cell_type":"code","source":"def run_nth(ds,percentage, number):\n    percentages_correct = list()\n    prob_correct_by_class = []\n    \n    for i in range(0,number):\n        ds_train, ds_test = seperate_ds_by_class(ds,percentage)\n        correct, incorrect, count_by_classes_correct, count_by_classes_incorrect = train(ds_train, ds_test)\n\n        by_class = []\n        for count_correct, count_incorrect in zip(count_by_classes_correct, count_by_classes_incorrect):\n            if count_correct+count_incorrect != 0:\n                by_class.append(count_correct/(count_correct+count_incorrect))\n            else:\n                by_class.append(0)\n                \n        prob_correct_by_class.append(by_class)\n        percentages_correct.append(correct/(correct+incorrect))\n        \n    return (percentages_correct, prob_correct_by_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccd14109a1ae1162f70a4df9aa2d1d8c335cf41b"},"cell_type":"code","source":"percents, prob_by_class = run_nth(dss,0.8,1)\n\ntaxa_acerto_min=np.min(percents)\ntaxa_acerto_max=np.max(percents)\ntaxa_acerto_med=np.mean(percents)\n\nprint('Rate')\nprint('--------------')\nprint('Min: ' + str(taxa_acerto_min))\nprint('Max: ' + str(taxa_acerto_max))\nprint('Mean: '+str(taxa_acerto_med))\n\nprint('-------------------------------')\nprint('Mean rate by class')\nprint('-------------------------------')\n\nar_value = [ np.mean(m) for m in np.array(prob_by_class).transpose() ]\n\nfor i, _class in enumerate(ar_value):\n    print('Class \\'' +  str(classes[i]) +'\\' : ' + str(_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc157288368b2073f0f6609e413d3560c6f4d4ab"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81d31d92c3784fe5aba3c319487a27938a6dd435"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f0a11fd2bcf2baae5bf11460db83fe2b1e83626"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b79b64d28c92acf2a84a9357dd123fdfc0f125e3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf9f45f03a67150c7bb775e7c2903028e41909b1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c44f7511fa752b9d40bd55903f881e4b70e8f259"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}