{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport matplotlib.pyplot as plt\nimport math\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import model_selection\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"ca_data = pd.read_csv('/kaggle/input/youtube-new/CAvideos.csv')\nca_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"channel_dataset = pd.read_csv('../input/youtube-channels-100000/channels.csv')\nchannel_dataset.head()\nchannel_dataset.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/youtube-new/CA_category_id.json') as f:\n    categories = json.load(f)\ncategories_map = {}\nfor category in categories['items']:\n    categories_map[int(category['id'])] = category['snippet']['title']\nca_data['category_id'] = ca_data['category_id'].map(categories_map)\nca_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('info', ca_data.info())\nprint('Views stats', ca_data['views'].describe())\nprint('Comment stats', ca_data['comment_count'].describe())\nprint('Like stats', ca_data['likes'].describe())\nca_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"channel_dataset = channel_dataset.rename(columns={'title':'channel_title', 'category_name': 'channel_category_name'})\nnew_ca_data= ca_data.merge(channel_dataset,how='left', on='channel_title')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('missing values percentage', new_ca_data['followers'].isnull().sum()/len(new_ca_data))\nnew_ca_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca_data['description'] = ca_data['description'].fillna(value='None',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca_data['publish_time'] = pd.to_datetime(ca_data['publish_time'], format = '%Y-%m-%dT%H:%M:%S.%fZ')\nca_data['publish_month'] = ca_data['publish_time'].dt.month\nca_data['publish_hour'] = ca_data['publish_time'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca_data['like_percentage'] = (ca_data['likes'] / ca_data['views']) * 100\nca_data['dislike_percentage'] = (ca_data['dislikes']/ca_data['views']) * 100\nca_data.loc[ca_data['likes'] >= ca_data['dislikes'],'more_likes'] = 1\nca_data.loc[ca_data['likes'] < ca_data['dislikes'],'more_likes'] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_title_length(title):\n    return len(title)\ndef get_number_of_tags(string_of_tags):\n    tags = string_of_tags.split('|')\n    tags_no_empty_strings = []\n    for tag in tags:\n        if tag != '':\n            tags_no_empty_strings.append(tag)\n    return len(tags_no_empty_strings)\n\nca_data['title_length'] = ca_data.apply(lambda row: get_title_length(row['title']), axis=1)\nca_data['number_of_tags'] = ca_data.apply(lambda row: get_number_of_tags(row['tags']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def contains_all_caps_word(title):\n    words = title.split(' ')\n    for word in words:\n        if word.isupper():\n            return True \nprint(contains_all_caps_word('HEY how are you'))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(3,1, figsize=(20,10))\nviews_by_categories_plot = sns.barplot(x=ca_data['category_id'], y=ca_data['views'], ax=ax[0])\nviews_by_categories_plot.set_title('Number of Views Per Category') \nlikes_by_categories_plot = sns.barplot(x=ca_data['category_id'], y=ca_data['likes'], ax=ax[1])\nlikes_by_categories_plot.set_title('Number of Likes Per Category')     \ncomment_count_by_categories_plot = sns.barplot(x=ca_data['category_id'], y=ca_data['comment_count'], ax=ax[2])\ncomment_count_by_categories_plot.set_title('Number of Comments Per Category')  \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\ncorrelation_matrix_heatmap = sns.heatmap(ca_data[['views', 'likes', 'comment_count','dislikes', 'title_length', 'number_of_tags']].corr(),vmin=-1,vmax=1, cmap='YlGnBu', annot=True)\ncorrelation_matrix_heatmap.set_title('Correlation Heatmap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(2,1, figsize=(16,6))\nviews_by_hour = sns.lineplot(x=ca_data['publish_hour'], y=ca_data['views'],data=ca_data,marker='o', ax=ax[0])\nviews_by_hour.set_title('Views per Publish Hour')\nviews_by_month= sns.lineplot(x=ca_data['publish_month'], y=ca_data['views'],data=ca_data,marker='o', ax=ax[1])\nviews_by_month.set_title('Views per Publish Month')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nfeeling_barplot = sns.barplot(x=ca_data['category_id'], y=ca_data['views'], hue=ca_data['more_likes'], data=ca_data)\nfeeling_barplot.set_xticklabels(feeling_barplot.get_xticklabels(),rotation=30)\nfeeling_barplot.set_title('Views Per Category Per Feeling')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"Here are some observations from our exploration that will inform the way we build our model:\n1. Movies and Music historically get ma higher number of views than other categories. Including category as a predictor is a good idea \n2. Likes and Comment count are highly correlated. Since linear regression assumes multicolinearity it could be a good idea to remove one of them\n3. The standard deviation on month 10 is quite high so it's unreasonable to draw an assumption that there is any statistical significance to videos published in this month getting many views\n4. Over the few months the trending data was collected, we saw a high amount of views for videos published at 10 AM. There is little standard deviation on this high figure. This relationship with our target variable may mean we can use publish hour as a predictor\n5. There is a relationship between likes and categories. Does that mean that one must be removed since we're assuming independance?\n6. The title length and number of tags have a very low correlation with our target variable so it might not be worth including for our model"},{"metadata":{},"cell_type":"markdown","source":"# Considerations\n\n1. Theres a concept in machine learning called data leakage:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ca_data = ca_data.drop(['comment_count'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_title_length(title):\n    return len(title)\ndef get_number_of_tags(string_of_tags):\n    tags = string_of_tags.split('|')\n    tags_no_empty_strings = []\n    for tag in tags:\n        if tag != '':\n            tags_no_empty_strings.append(tag)\n    return len(tags_no_empty_strings)\nca_data = ca_data.drop(['video_id', 'channel_title', 'description', 'likes', 'dislikes', 'thumbnail_link', 'comment_count', 'video_error_or_removed'],axis=1)\n#Convert boolean valus to integers\nca_data = ca_data.astype({'comments_disabled': 'int', 'ratings_disabled': 'int'})\nca_data['publish_time'] = ca_data.apply(lambda row: get_publish_hour(row['publish_time']), axis=1)\nca_data = ca_data.rename(columns={'publish_time':'publish_hour'})\nca_data = pd.get_dummies(ca_data,prefix='category', columns=['category_id'])\nca_data = pd.get_dummies(ca_data,prefix='hour', columns=['publish_hour'])\n\nca_data['title_length'] = ca_data.apply(lambda row: get_title_length(row['title']), axis=1)\nca_data = ca_data.drop(columns=['title'])\nca_data['number_of_tags'] = ca_data.apply(lambda row: get_number_of_tags(row['tags']), axis=1)\nca_data = ca_data.drop(['tags', 'trending_date'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = ca_data['views']\nX = ca_data[ca_data.columns.difference(['views'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\nmodel = LinearRegression()\nscoring = 'neg_mean_squared_error'\nresults = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\nprint(\"MSE: %.3f (%.3f)\" % (results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}