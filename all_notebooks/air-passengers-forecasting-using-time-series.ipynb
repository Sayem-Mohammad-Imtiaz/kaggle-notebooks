{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <font color = darkyellow><b>TimeExponential smoothingreenime series analysis:</b></font>\n        \nThis method predicts the one next period value based on the past and current value.  It involves averaging of data such that the nonsystematic components of each individual case or observation cancel out each other.  The exponential smoothing method is used to predict the short term predication.  Alpha, Gamma, Phi, and Delta are the parameters that estimate the effect of the time series data.  Alpha is used when seasonality is not present in data.  Gamma is used when a series has a trend in data.  Delta is used when seasonality cycles are present in data.  A model is applied according to the pattern of the data.  Curve fitting in time series analysis: Curve fitting regression is used when data is in a non-linear relationship. The following equation shows the non-linear behavior:\nDependent variable, where case is the sequential case number.\nCurve fitting can be performed by selecting “regression” from the analysis menu and then selecting “curve estimation” from the regression option. Then select “wanted curve linear,” “power,” “quadratic,” “cubic,” “inverse,” “logistic,” “exponential,” or “other.”<br>\n\n### <b>ARIMA:</b><br>\nARIMA stands for autoregressive integrated moving average.  This method is also known as the Box-Jenkins method.\nIdentification of ARIMA parameters: \n    \n### <b>Autoregressive component:</b>\nAR stands for autoregressive.  Autoregressive paratmeter is denoted by p.  When p =0, it means that there is no auto-correlation in the series.  When p=1, it means that the series auto-correlation is till one lag.<br>\n\n### <b>Integrated:</b> \nIn ARIMA time series analysis, integrated is denoted by d.  Integration is the inverse of differencing.  When d=0, it means the series is stationary and we do not need to take the difference of it.  When d=1, it means that the series is not stationary and to make it stationary, we need to take the first difference.  When d=2, it means that the series has been differenced twice.  Usually, more than two time difference is not reliable.<br>\n\n### <b>Moving average component:</b> \nMA stands for moving the average, which is denoted by q.  In ARIMA, moving average q=1 means that it is an error term and there is auto-correlation with one lag.\nIn order to test whether or not the series and their error term is auto correlated, we usually use W-D test, ACF, and PACF.<br>\n### <b>Decomposition:</b> \nRefers to separating a time series into trend, seasonal effects, and remaining variabilityAssumptions:<br>\n\n### <b>Stationarity:</b> \nThe first assumption is that the series are stationary.  Essentially, this means that the series are normally distributed and the mean and variance are constant over a long time period.<br>\n### <b>Uncorrelated random error:</b> \nWe assume that the error term is randomly distributed and the mean and variance are constant over a time period.  The Durbin-Watson test is the standard test for correlated errors."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"\n\n# <font color = black|red|yellow>**********Time Series Analysis**********</font>\n\nTime series analysis is a statistical technique that deals with time series data, or trend analysis.  Time series data means that data is in a series of  particular time periods or intervals.  The data is considered in three types:\n\n### <b>Time series data:</b>  \nA set of observations on the values that a variable takes at different times.\n\n### <b>Cross-sectional data:</b>\nData of one or more variables, collected at the same point in time.\n\n### <b>Pooled data:</b> \nA combination of time series data and cross-sectional data.\n<br>\n\n## <font color = darkyellow><b>Terms and concepts:</b></font>\n### <b>Dependence:</b> \nDependence refers to the association of two observations with the same variable, at prior time points.\n\n### <b>Stationarity:</b> \nShows the mean value of the series that remains constant over a time period; if past effects accumulate and the values increase toward infinity, then stationarity is not met.\n\n### <b>Differencing:</b> \nUsed to make the series stationary, to De-trend, and to control the auto-correlations; however, some time series analyses do not require differencing and over-differenced series can produce inaccurate estimates.\n\n### <b>Specification:</b> \nMay involve the testing of the linear or non-linear relationships of dependent variables by using models such as ARIMA, ARCH, GARCH, VAR, Co-integration, etc.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize']=10,6\nfrom datetime import datetime\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndataset = pd.read_csv(\"../input/air-passengers/AirPassengers.csv\")\n# Parse strings to datetime type\ndataset['Month'] = pd.to_datetime(dataset['Month'], infer_datetime_format=True)\nindexedDataset = dataset.set_index(['Month'])\n\nfrom datetime import datetime\nindexedDataset['1949-03']\nindexedDataset['1949-03':'1949-06']\nindexedDataset['1949']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = indexedDataset\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel(\"Date\")\nplt.ylabel(\"Number of Air Passengers\")\nplt.grid()\nplt.plot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color = gray>Determine Rolling Statistics</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check Stationary\n#determine rolling statistics\n\nrolmean = df.rolling(window=12).mean()\n\nrolstd = df.rolling(window=12).std()\nprint(rolmean, rolstd)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color = gray>Rolling Mean & Standard Deviation</font>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_data = plt.plot(df,color='blue',label = 'original')\nmean = plt.plot(rolmean,color='red', label='Rolling mean')\nstd = plt.plot(rolstd,color='black', label = 'Rolling std')\nplt.legend(loc='best')\nplt.title(\"Rolling Mean & Standard Deviation\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number Air Passengers\")\nplt.show(block= False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### <font color= gray >Perform Dickey-Fuller Test:</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\nprint('Results of Deckey-Fuller Test: ')\ndftest = adfuller(df['#Passengers'],autolag='AIC')\n\ndfoutput = pd.Series(dftest[0:4],index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key, value in dftest[4].items():\n    dfoutput['Critical Value (%s)' %key]= value\n    \nprint(dfoutput)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color= gray>Estimating Trend</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_logScale = np.log(df)\nplt.plot(df_logScale)\nplt.title(\"Rolling Mean & Standard Deviation\",color = 'darkgreen')\nplt.xlabel(\"Date\",color = 'darkblue')\nplt.ylabel(\"Number Air Passengers\",color ='darkblue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"moving_avg = df_logScale.rolling(window=12).mean()\nmoving_STD = df_logScale.rolling(window=12).std()\nplt.plot(df_logScale)\nplt.plot(moving_avg, color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_logScale_moving_avg = df_logScale - moving_avg\ndf_logScale_moving_avg.head(12)\n\n#Remove NA values\ndf_logScale_moving_avg.dropna(inplace =True)\ndf_logScale_moving_avg.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color = gray> Apply DCF Function</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ndef test_stationary(timeseries):\n    \n    #Determing rolling statistics\n    \n    moving_avg = timeseries.rolling(window=12).mean()\n    moving_std = timeseries.rolling(window =12).std()\n    \n    #plot rolling statistics\n    orig = plt.plot(timeseries, color = 'blue', label = 'Original')\n    mean = plt.plot(moving_avg, color = 'red', label = 'Rolling mean')\n    std = plt.plot(moving_std, color = 'darkgray', label = 'Rolling std')\n    plt.legend(loc='best')\n    plt.title('Rolling mean & Standard deviation')\n    plt.show(block=False)\n    \n    #perform Dickey_Fuller test\n    \n    print(\"Results of Dickey_Fuller test: \")\n    dftest = adfuller(timeseries['#Passengers'], autolag = 'AIC')\n    dfoutput = pd.Series(dftest[0:4],index = ['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)\n                         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationary(df_logScale_moving_avg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_dec_weight_avg = df_logScale.ewm(halflife=12, min_periods=0,adjust=True).mean()\nplt.plot(df_logScale)\nplt.plot(exp_dec_weight_avg, color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_logScale_moving_exp_dec_avg = df_logScale - exp_dec_weight_avg\ntest_stationary(df_logScale_moving_exp_dec_avg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_log_dif_shifting = df_logScale - df_logScale.shift()\n\nplt.plot(df_log_dif_shifting)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log_dif_shifting.dropna(inplace= True)\ntest_stationary(df_log_dif_shifting)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color = gray>Show  Components</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(df_logScale)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(df_logScale, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()\n\ndecomposed_log_data = residual\ndecomposed_log_data.dropna(inplace =True)\ntest_stationary(decomposed_log_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decomposed_log_data = residual\ndecomposed_log_data.dropna(inplace=True)\ntest_stationary(decomposed_log_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color=gray>ACF and PACF plots </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\n\nlag_acf = acf(df_log_dif_shifting, nlags=20)\nlag_pacf = pacf(df_log_dif_shifting, nlags=20, method='ols')\n\n\n#Plot ACF: \nplt.subplot(121) \nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(df_log_dif_shifting)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(df_log_dif_shifting)),linestyle='--',color='gray')\nplt.title('Autocorrelation Function')\n\n#Plot PACF:\nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(df_log_dif_shifting)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(df_log_dif_shifting)),linestyle='--',color='gray')\nplt.title('Partial Autocorrelation Function')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\n#AR MODEL\nmodel = ARIMA(df_logScale, order=(2, 1, 0))  \nresults_AR = model.fit(disp=-1)  \nplt.plot(df_log_dif_shifting)\nplt.plot(results_AR.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_AR.fittedvalues-df_log_dif_shifting[\"#Passengers\"])**2))\nprint('Plotting AR model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MA MODEL\nmodel = ARIMA(df_logScale, order=(0, 1, 2))  \nresults_MA = model.fit(disp=-1)  \nplt.plot(df_log_dif_shifting)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_MA.fittedvalues-df_log_dif_shifting[\"#Passengers\"])**2))\nprint('Plotting AR model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(df_logScale, order=(2, 1, 2))  \nresults_ARIMA = model.fit(disp=-1)  \nplt.plot(df_log_dif_shifting)\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-df_log_dif_shifting[\"#Passengers\"])**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\nprint (predictions_ARIMA_diff.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert to cumulative sum\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\nprint (predictions_ARIMA_diff_cumsum.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions_ARIMA_log = pd.Series(ts_log.ix[0], index=ts_log.index)\n#predictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\n#predictions_ARIMA_log.head()\n\npredictions_ARIMA_log = pd.Series(df_logScale['#Passengers'].ix[0], index=df_logScale['#Passengers'].index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA = np.exp(predictions_ARIMA_log)\nplt.plot(indexedDataset)\nplt.plot(predictions_ARIMA)\nplt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-df_logScale[\"#Passengers\"])**2)/len(df[\"#Passengers\"])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_logScale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_ARIMA.plot_predict(1,264)\nx = results_ARIMA.forecast(steps=120)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color = darkgreen> ******GOOD BYE***** </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}