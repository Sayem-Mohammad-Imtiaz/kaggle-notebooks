{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Author : Akash Kothare"},{"metadata":{},"cell_type":"markdown","source":"Data Science & Business Analytics Intern (Batch - Dec'20)"},{"metadata":{},"cell_type":"markdown","source":"## Task 2: Prediction using Unsupervised ML\n"},{"metadata":{},"cell_type":"markdown","source":"In this task, we have to develop a classifier for the 'Iris' dataset and predict an optimum numbers of clusters and thus viusalizing them."},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/tsf-datasets/Iris.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping ID Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('Id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset has no null values, thus no need to clean it"},{"metadata":{},"cell_type":"markdown","source":"### Using Seaborn features : Pair-Plot and Correlation to check dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pair-Plot\nsns.pairplot(df, hue = 'Species', diag_kind = 'hist')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation\nsns.heatmap(df.corr(), annot = True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding the optimum number of clusters for k-means classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.iloc[:, [0, 1, 2, 3]].values\n\nfrom sklearn.cluster import KMeans\nwcss=[]             #within cluster sum of squares\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the results onto a line graph to observe 'The Elbow'\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can clearly see why it is called 'The elbow method' from the above graph, the optimum clusters is where the elbow occurs. This is when the within cluster sum of squares (WCSS) doesn't decrease significantly with every iteration."},{"metadata":{},"cell_type":"markdown","source":"From this, we choose the <b>number of clusters as 3</b>"},{"metadata":{},"cell_type":"markdown","source":"### Creating the KMeans Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit_predict(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising the clusters - On the first two columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting CLusters\nplt.rcParams[\"figure.figsize\"] = 10, 10\n\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Iris-setosa')\n\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'green', label = 'Iris-versicolour')\n\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'blue', label ='Iris-virginica')\n\n#Plotting Centroids of the CLusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 250, c = 'yellow', label = 'Centroids')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}