{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Variety of models for SDSS data"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import os                       # accessing directory structure\nimport numpy as np              # linear algebra\nimport pandas as pd             # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns           # plotting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=RuntimeWarning)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/Skyserver_12_30_2019 4_49_58 PM.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store columns in a list, might will be helpful later\ncols = list(df.columns)\ncols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Our labels\ndf['class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how the classes are distributed \ndf['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization with Matplotlib\ndf['class'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization with Seaborn\nsns.countplot(x='class', data=df, palette=\"brg\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['mjd'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['redshift'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's find missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding class labels\nFor some cases, we cannot simply provide categorical values (just strings). Instead, we can convert them to numerical values.\nFor example, since we have 3 classes, we able to assign to each class some values, so that:\n\n* 0 is for GALAXY\n* 1 is for QSO\n* 2 is for STAR."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping classes to 0,1,2 values\nclass_mapping = {label: idx for idx, label in enumerate(np.unique(df['class']))}\nclass_mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['class'] = df['class'].map(class_mapping)\ndf\n\n# now we see class column with numerical (0,1,2) values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Invariant back to original\ninv_class_mapping = {v: k for k, v in class_mapping.items()}\ndf['class'] = df['class'].map(inv_class_mapping)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Labels encoding with special Scikit Learn function\nfrom sklearn.preprocessing import LabelEncoder\n\nclass_le = LabelEncoder()\ny = class_le.fit_transform(df['class'].values)\nprint(y)\nprint('We have {} values'.format(len(y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Our target\nprint(y)\n\n# We prepare data on which we will train and test\n# Labels column should be excluded\ndf = df.drop(columns=['class'])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to normalize the data, to not have bias of huge values\n\nfrom sklearn import preprocessing\n\nx = df.values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf = pd.DataFrame(x_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{},"cell_type":"markdown","source":"## Decision Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nmodel_dtc = DecisionTreeClassifier(random_state=49)\n\nmodel_dtc.fit(X_train, y_train)\n\naccuracies = {}\n\nacc = model_dtc.score(X_test, y_test)*100\naccuracies['Decision Tree'] = acc\nprint(\"Decision Tree Test Accuracy {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmodel_lr = LogisticRegression() # default parameters\n\nmodel_lr.fit(X_train,y_train)\n\ny_pred = model_lr.predict(X_test)\n\nacc = model_lr.score(X_test,y_test)*100\n\naccuracies['Logistic Regression'] = acc\nprint(\"Test Accuracy {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred)\nprint(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint('Classification Report: \\n', classification_report(y_test, y_pred))\nprint('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\nlr_train_acc = model_lr.score(X_train, y_train)\nprint('Training Score: ', lr_train_acc)\nlr_test_acc = model_lr.score(X_test, y_test)\nprint('Testing Score: ', lr_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Machines (SVM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nmodel_svm = SVC(random_state = 1)\n\nmodel_svm.fit(X_train, y_train)\n\nacc = model_svm.score(X_test,y_test)*100\n\naccuracies['SVM'] = acc\nprint(\"Test Accuracy of SVM Algorithm: {:.2f}%\".format(acc))\n\n# Attention: Slow model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nmodel_nb = GaussianNB()\n\nmodel_nb.fit(X_train, y_train)\n\nacc = model_nb.score(X_test,y_test)*100\naccuracies['Naive Bayes'] = acc\nprint(\"Accuracy of Naive Bayes: {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_nb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Classification Report: \\n', classification_report(y_test, y_pred))\nprint('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\nlr_train_acc = model_lr.score(X_train, y_train)\nprint('Training Score: ', lr_train_acc)\nlr_test_acc = model_lr.score(X_test, y_test)\nprint('Testing Score: ', lr_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN Neighbours"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel_knn = KNeighborsClassifier(n_neighbors = 3)  # n_neighbors means k\nmodel_knn.fit(X_train, y_train)\nprediction = model_knn.predict(X_test)\n\nprint(\"{} NN Score: {:.2f}%\".format(3, model_knn.score(X_test, y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try ro find best k value\nscoreList = []\nfor i in range(1,20):\n    knn2 = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    knn2.fit(X_train, y_train)\n    scoreList.append(knn2.score(X_test, y_test))\n    \nplt.plot(range(1,20), scoreList)\nplt.xticks(np.arange(1,20,1))\nplt.xlabel(\"K value\")\nplt.ylabel(\"Score\")\nplt.show()\n\nacc = max(scoreList)*100\naccuracies['KNN'] = acc\nprint(\"Maximum KNN Score is {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tasks to do:\n* Class weights for class imbalance\n* ANN models"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}