{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport csv\nimport os\ncsv_file = os.listdir(\"../input\")\nprint(csv_file)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read input file\n\nfeatures = []\nnames = []\nwith open('../input/musicfeatures/data.csv','rt')as f:\n    data = csv.reader(f)\n    for row in data:\n        features.append(np.array(row[1:]))\nfeatures = np.array(features)\n\nkey = features[0]\nfeatures = features[1:,:]\nlabels = features[:,-1]\ncategories = list(set(labels))\n\nfeatures = features[:,:-1]\nkey = key[:-1]\n\nprint('Features -', features.shape, key)\nprint('Categories -', categories, len(categories))\n\nlabels_temp = []\nfor i in range(len(categories)):\n    for label in labels:\n        if label == categories[i]:\n            labels_temp.append(i)\nlabels = np.array(labels_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert string features to number\nfeatures = features.astype(np.float)\nprint(features[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PCA\nfrom sklearn.decomposition import PCA\n\nfeatures_copy = features.copy()\nfor i in range(len(key)):\n    Xi = features[:,i]\n    features_copy[:,i] = (Xi-np.mean(Xi))/np.std(Xi)\n    \npca = PCA(n_components = 22)\nPC = pca.fit_transform(features_copy)\nprint(pca.explained_variance_ratio_)\ncumulated = []\ncumulated_score = 0\nfor val in pca.explained_variance_ratio_:\n    cumulated_score += val\n    cumulated.append(cumulated_score)\nprint(cumulated)\nprint(PC.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\nX, Y = shuffle(PC, labels)\nprint(X.shape, Y.shape)\n\ntrain_split = 1\n\nX_Train = X[:int(1000*train_split), :]\nY_Train = Y[:int(1000*train_split)]\nX_Val = X[int(1000*train_split):, :]\nY_Val = Y[int(1000*train_split):]\n\nprint(X_Train.shape, Y_Train.shape, X_Val.shape, Y_Val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, BatchNormalization, Activation, Dropout \nfrom keras.models import Model\nfrom keras import optimizers\n\n\nfrom numpy.random import seed\nseed(2019)\n\nfrom tensorflow import set_random_seed\nset_random_seed(2019)\n\ninputs = Input(shape=(22,))\n\nx = Dense(32)(inputs)\nx = BatchNormalization()(x)\n#x = Dropout(0.5)(x)\nx = Activation('relu')(x)\n\nx = Dense(64)(x)\nx = BatchNormalization()(x)\n#x = Dropout(0.5)(x)\nx = Activation('relu')(x)\n\nx = Dense(64)(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Activation('relu')(x)\n\nx = Dense(32)(x)\nx = BatchNormalization()(x)\n#x = Dropout(0.5)(x)\nx = Activation('relu')(x)\n\npredictions = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=predictions)\nopt = optimizers.SGD(lr=0.01)\n\nmodel.compile(optimizer=opt,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(np.array(X_Train), np.array(Y_Train), batch_size = 32, epochs = 250, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['loss'])\nplt.title('Training')\nplt.ylabel('Score')\nplt.xlabel('Epoch')\nplt.legend(['Accuracy', 'Loss'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(history.history['val_acc'])\nplt.plot(history.history['val_loss'])\nplt.title('Validation')\nplt.ylabel('Score')\nplt.xlabel('Epoch')\nplt.legend(['Accuracy', 'Loss'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TRAINING COMPLETE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read test data\n\nfeatures = []\nnames = []\noffsets = []\nwith open('../input/test-songs/features.csv','rt')as f:\n    data = csv.reader(f)\n    for row in data:\n        features.append(np.array(row))\n        names.append(row[0])\n        offsets.append(row[-1])\n        \nfeatures = np.array(features)\nfeatures = features[1:,1:-1].astype(np.float)\nnames = np.array(names[1:])\noffsets = np.array(offsets[1:])\n\nprint('Test Data Shape -', features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict on features with trained model\nfrom scipy import stats\n\nfeatures_copy = features.copy()\nfor i in range(len(key)):\n    Xi = features[:,i]\n    features_copy[:,i] = (Xi-np.mean(Xi))/np.std(Xi)\n\nsong_names = list(set(names))\nsong_groups = {song_name:[] for song_name in song_names}\nsong_pred = {song_name:[] for song_name in song_names}\nsong_genre = {song_name:[] for song_name in song_names}\npred_count = {song_name:{category:0 for category in categories} for song_name in song_names}\n\nfor i in range(len(names)):\n    song_groups[names[i]].append(features_copy[i])\n\nfor song_name in song_names:\n    features = song_groups[song_name]\n    for feature in features:\n        feature = pca.transform(np.reshape(feature, (1, feature.shape[0])))\n        pred = model.predict(feature)\n        idx = np.argmax(pred)\n        final_pred = categories[idx]\n        song_pred[song_name].append(final_pred)\n    for pred_temp in song_pred[song_name]:\n        pred_count[song_name][pred_temp] += 1\n\nprint(pred_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for song_name in song_names:\n    stats = pred_count[song_name]\n    song_genre[song_name] = max(stats, key=stats.get)\n    \nprint(song_genre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}