{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align=\"center\"> Air Pollution in Seoul: EDA with visualization by maps ðŸ—º </h1>\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Map_Seoul_districts_de.png/600px-Map_Seoul_districts_de.png\" width=\"350\" height=\"250\">\n\n<span style=\"text-align: center;\"><i>image form Wikipedia</i></span>\n\n**Language:** English (ðŸ‡ºðŸ‡¸) and Portuguese (ðŸ‡§ðŸ‡·)\n\nCreated: 2020-08-14\n\nLast updated: 2020-09-11\n\n## DataSet Description\n\n[Link Kaggle - Air Pollution In Seoul](https://www.kaggle.com/bappekim/air-pollution-in-seoul)\n\nThis dataset deals with air pollution measurement information in Seoul, South Korea.\nSeoul Metropolitan Government provides many public data, including air pollution information, through the 'Open Data Plaza'\nI made a structured dataset by collecting and adjusting various air pollution related datasets provided by the Seoul Metropolitan Government.\n\n## Brief Summary of DataSet\n\nThis data provides average values for six pollutants (SO2, NO2, CO, O3, PM10, PM2.5).\n\n+ Data were measured every hour between 2017 (01-01-2017) and 2019 (31-12-2019).\n+ Data were measured for 25 districts in Seoul.\n+ This dataset is divided into four files.\n\n- Measurement info (`Measurement_info.csv`):\n  + Air pollution measurement information\n  + 1 hour average measurement is provided after calibration Instrument status:\n    - 0: Normal, 1: Need for calibration, 2: Abnormal\n    - 4: Power cut off, 8: Under repair, 9: abnormal data\n    \n+ Measurement item info (`Measurement_item_info.csv`): \n  - Information on air pollution measurement items\n\n+ Measurement station info (`Measurement_station_info.csv`): \n  - Information on air pollution instrument stations\n\n+ Measurement summary (`Measurement_summary.csv`): \n    - A condensed dataset based on the above three data.\n\n  \n## Others References\n\n**Seoul map source by district in JSON**\n+ [Git](https://github.com/southkorea/seoul-maps/blob/master/kostat/2013/json/seoul_municipalities_geo_simple.json)\n\n## Understanding some Polluants\n\n**PM (*particulate matter*)**\n\nMeasured in Mircrogram/m3.\n\nPMs are divided into two categories: PM10, which comprises particles between 2.5 and 10 millionths of a millimeter or micrometers; and PM2.5, which is less than 2.5 micrometers, thirty times less than the thickness of a human hair.\n\nThe particulate material is a mixture of various materials, being almost five times thinner than a hair or the same smaller ones that have liquid chemicals. These substances can be composed of organic compounds, compounds, such as sulfates and nitrates, metals and even dust.\n\nParticulate matter such as PM10, PM2.5, PM1 and PM0.1 is defined as the fraction of particles with an aerodynamic diameter smaller than respectively 10, 2.5, 1 and 0.1 Âµm (for your information: 1 Âµm = 1 millionth of a meter or 1 thousandth of a millimeter). In comparison, the average diameter of a human hair equals 50-70 Âµm (see figure below)\n\n![](https://www.irceline.be/nl/documentatie/faq/pmsize1)\n\n**O3**\n\n1- Good ozone: 20 kilometers above them helps to protect the eyes and skin from UV radiation (ozone layer).\n\n2- Bad Ozone: at ground level, depending on the concentration, it harms the lungs.\n\nIt is the ozone found in the troposphere, produced by man, as the result of air pollution from internal combustion engines and power plants. Automobile exhaust and industrial emissions release a range of nitrous oxide (NOx) gases and volatile organic compounds (VOC), by-products of burning gasoline and coal. NOx and VOC's combine chemically with oxygen to form ozone during sunny days with high temperatures in late spring, summer and early fall.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Table of contents (TOC) <a id=\"top\"></a>\n\n**Data Preprocessing and Understanding DataSet**\n- [Import Libs and DataSet](#index01)\n- [Clean the Data](#index02)\n- [Deal with missing data](#index03)\n- [Snippets](#index04)\n- [Handler invalid data or outliers](#index05)\n  + [Check and analyze distribution of gas data](#index06)\n  + [Remove invalid values](#index07)\n  + [Handler with outilers](#index08)\n- [Feature engineering](#index09)\n\n**Questions Over DataSet**\n- [How SO2 has evolved over the years?](#index10)\n- [What is the average gas pollution for each district and which has more or less?](#index11)\n- [Are there any negative measurements of pollutants?](#index12)\n- [Where is Bad and Very Bads measures?](#index13)"},{"metadata":{},"cell_type":"markdown","source":"## Import Libs and DataSet <a id ='index01'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# TODO News ideias\n# + EvoluÃ§Ã¢o do PM.2.5 pois Ã© o que tem mais mediÃ§Ã´es negativas\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport json\nimport datetime\n\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.models import GeoJSONDataSource\nfrom bokeh.layouts import row\noutput_notebook()\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import DataFrame\nfile_path = '/kaggle/input/air-pollution-in-seoul/AirPollutionSeoul/Measurement_summary.csv'\ndf = pd.read_csv(file_path)\nprint(\"DataSet = {:,d} rows and {} columns\".format(df.shape[0], df.shape[1]))\n\nprint(\"\\nAll Columns:\\n=>\", df.columns.tolist())\n\nquantitative = [f for f in df.columns if df.dtypes[f] != 'object']\nqualitative = [f for f in df.columns if df.dtypes[f] == 'object']\n\nprint(\"\\nStrings Variables:\\n=>\", qualitative,\n      \"\\n\\nNumerics Variables:\\n=>\", quantitative)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Information on the dangerousness of the concentration of each gas\n\ndf_gas_info = pd.read_csv('/kaggle/input/air-pollution-in-seoul/AirPollutionSeoul/Original Data/Measurement_item_info.csv')\ndf_gas_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dict to pollutants level\n\nlist_cols = list(df_gas_info.columns)[3:]\n\nlevel_dangerous = {}\nfor i in range(len(df_gas_info)):\n    name = df_gas_info[\"Item name\"][i]\n    level_dangerous[name] = df_gas_info[list_cols].loc[i].tolist()\n    \nlevel_dangerous","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import geo_json with geopandas\n\nimport geopandas as gpd\n\nseoul_geojson = gpd.read_file('../input/seoul-map-geojson/seoul_municipalities_geo_simple.json')\nseoul_geojson = seoul_geojson.drop(['code', 'base_year'], axis = 1)\nseoul_geojson.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean the Data <a id ='index02'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\nðŸ‡ºðŸ‡¸\n\n+ Convert Address to Distict\n  - Convert this string: `369, Yongmasan-ro, Jungnang-gu, Seoul, Republic of Korea` => to: `Jungnang-gu`\n+  Retire Useless features\n   - `Latitude`, `Longitude`, and `State code`, because is the same to each district\n+ Convert Date to date type in pandas\n\nðŸ‡§ðŸ‡·\n\n\n+ Converter endereÃ§o para Distrito:\n  - Converterter *strings* desse tipo: `369, Yongmasan-ro, Jungnang-gu, Seoul, Republic of Korea` => para somente distrito: `Jungnang-gu`\n+ Retirar *features* inÃºteis:\n  - `Latitude`, `Longitude`, e `State code`, pois vamos considerar cada ponto de medida como o do distrito\n+ Converter *date* para o tipo de data do *pandas*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Address'].value_counts().head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Address'] = df['Address'].map(lambda street: street.split(',')[2].strip())\ndf['Address'].value_counts().head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Latitude', 'Longitude', 'Station code'], axis = 1).rename( columns = {'Address': 'District', 'Measurement date': 'Date'})\ndf['Date'] = pd.to_datetime(df['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final dataSet\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deal with missing data <a id ='index03'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\n**No missing data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as msno\nsns.heatmap(df.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Snippets <a id ='index04'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def generate_GeoJSONSource_to_districts(my_df, column_value):\n    \"\"\"\n    Generate GeoJSONDataSource. This is necessary to each part of GeoPlot except calculate low and high of colors\n        By default must be 'District' in all df in.\n    \"\"\"\n    with open('../input/seoul-map-geojson/seoul_municipalities_geo_simple.json') as json_file:\n        data = json.load(json_file)\n    if(len(my_df) != 25):\n        raise Exception('df with len != 25')\n    if('District' not in list(my_df.columns) ):\n        raise Exception('df not contains \"District\"')\n    for i in range(25):\n        city = data['features'][i]['properties']['name_eng']\n        index = my_df.query('District == \"' + city +'\"').index[0]\n        data['features'][i]['properties'][column_value] = my_df[column_value][index]\n        data['features'][i]['properties']['District'] = my_df['District'][index]\n    geo_source = GeoJSONDataSource( geojson = json.dumps(data, separators=(',', ':')) )\n    return geo_source  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from bokeh.io import show\nfrom bokeh.plotting import figure\nfrom bokeh.models import LinearColorMapper, HoverTool, ColorBar\nfrom bokeh.palettes import magma,viridis,cividis, inferno\n\ndef eda_seoul_districts_geo_plot(geosource, df_in, title, column, state_column, low = -1, high = -1, palette = -1):\n    \"\"\"\n    Generate Bokeh Plot to Brazil States:\n        geosource: GeoJSONDataSource of Bokeh\n        df_in: DataSet before transformed in GeoJSONDataSource\n        title: title of plot\n        column: column of df_in to be placed values in geoplot\n        state_column: indicate column with names of States\n        low = (optional) min value of range of color spectre\n        high = (optional) max values of range of color spectre\n        palette: (optional) can be magma, viridis, civis, inferno e etc.. (with number os colors)\n            Example: cividis(8) (8 colors to classify), cividis(256)  (256, more colors to clasify)\n    \"\"\"\n    if high == -1:\n        high = max(df_in[column])\n    if low == -1:\n        low = min(df_in[column])\n    if palette == -1:\n        palette = inferno(32)\n        \n    palette = palette[::-1]\n    color_mapper = LinearColorMapper(palette = palette, low = low, high = high)\n    \n    hover = HoverTool(tooltips = [ ('District','@{'+state_column+'}'), (column, '@{'+column+'}{%.6f}')],\n                  formatters={'@{'+column+'}' : 'printf'})\n\n    color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8, width = 300, height = 20, \n                         border_line_color=None, location = (0,0),  orientation = 'horizontal')\n\n    p = figure(title = title, plot_height = 430, plot_width = 330, tools = [hover])\n\n    p.xgrid.grid_line_color = None\n    p.ygrid.grid_line_color = None\n    p.xaxis.visible = False\n    p.yaxis.visible = False\n\n    p.patches('xs','ys', source = geosource, line_color = 'black', line_width = 0.25,\n              fill_alpha = 1, fill_color = {'field' : str(column), 'transform' : color_mapper})\n\n    p.add_layout(color_bar, 'below')\n    return p   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from bokeh.palettes import Turbo256 \nfrom bokeh.models import ColumnDataSource\nfrom bokeh.transform import factor_cmap\nfrom bokeh.palettes import magma,viridis,cividis, inferno\n\ndef eda_bokeh_horiz_bar_ranked(df, column_target, title = '', int_top = 3, second_target = 'state'):\n    \"\"\"\n    Generate Bokeh Plot ranking top fists and last value:\n        df: data_frame\n        column_targe: a column of df inputed\n        title: title of plot\n        int_top: number of the tops\n        column: column of df_in to be placed values in geoplot\n        second_targe = 'state'\n    \"\"\"\n    ranked = df.sort_values(by=column_target).reset_index(drop = True)\n    top_int = int_top\n    top = ranked[:top_int].append(ranked[-top_int:])\n    top.index = top.index + 1\n    source = ColumnDataSource(data=top)\n    list_second_target = source.data[second_target].tolist()\n    index_label = list_second_target[::-1] # reverse order label\n\n    p = figure(plot_width=500, plot_height=400, y_range=index_label, \n                toolbar_location=None, title=title)   \n\n    p.hbar(y=second_target, right=column_target, source=source, height=0.85, line_color=\"#000000\",\n          fill_color=factor_cmap(second_target, palette=inferno(16)[::-1], factors=list_second_target))\n    p.x_range.start = 0  # start value of the x-axis\n\n    p.xaxis.axis_label = \"value of '\" + column_target + \"'\"\n\n    hover = HoverTool()  # initiate hover tool\n    hover.tooltips = [(\"Value\",\"@{\" + column_target + \"}{%.6f}\" ),   \n                       (\"Ranking\",\"@indexÂ°\")]\n    hover.formatters={'@{'+column_target+'}' : 'printf'}\n\n    hover.mode = 'hline' # set the mode of the hover tool\n    p.add_tools(hover)   # add the hover tooltip to the plot\n\n    return p # show in notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def eda_foward_2_plots(my_df, primary_column, target_column, first_title, second_title, int_top = 8, location_column = 'District'):\n    \"\"\"\n    Execute and show all together:\n    @ primary_columns must to be a float to join to make a GeoSource\n    generate_GeoJSONSource_to_districts()\n    eda_seoul_districts_geo_plot()\n    eda_bokeh_horiz_bar_ranked()\n    \"\"\"\n    my_df = my_df.rename({primary_column: target_column}, axis = 1)\n\n    geo_source = generate_GeoJSONSource_to_districts(my_df, target_column)\n\n    geo = eda_seoul_districts_geo_plot(geo_source, my_df, first_title,\n                                       target_column, location_column, palette = inferno(32))\n\n    rank = eda_bokeh_horiz_bar_ranked(my_df, target_column, second_title,\n                                      int_top = int_top, second_target = location_column)\n\n    show( row( geo, rank ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def eda_categ_feat_desc_plot(series_categorical, title = \"\"):\n    \"\"\"Generate 2 plots: barplot with quantity and pieplot with percentage. \n       @series_categorical: categorical series\n       @title: optional\n    \"\"\"\n    series_name = series_categorical.name\n    val_counts = series_categorical.value_counts()\n    val_counts.name = 'quantity'\n    val_percentage = series_categorical.value_counts(normalize=True)\n    val_percentage.name = \"percentage\"\n    val_concat = pd.concat([val_counts, val_percentage], axis = 1)\n    val_concat.reset_index(level=0, inplace=True)\n    val_concat = val_concat.rename( columns = {'index': series_name} )\n    \n    fig, ax = plt.subplots(figsize = (12,4), ncols=2, nrows=1) # figsize = (width, height)\n    if(title != \"\"):\n        fig.suptitle(title, fontsize=18)\n        fig.subplots_adjust(top=0.8)\n\n    s = sns.barplot(x=series_name, y='quantity', data=val_concat, ax=ax[0])\n    for index, row in val_concat.iterrows():\n        s.text(row.name, row['quantity'], row['quantity'], color='black', ha=\"center\")\n\n    s2 = val_concat.plot.pie(y='percentage', autopct=lambda value: '{:.2f}%'.format(value),\n                             labels=val_concat[series_name].tolist(), legend=None, ax=ax[1],\n                             title=\"Percentage Plot\")\n\n    ax[1].set_ylabel('')\n    ax[0].set_title('Quantity Plot')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def measurement_evaluator(value, column):\n    if(pd.isnull(value) or value < 0):\n        return 'Error'\n    elif(value <= level_dangerous[column][0]):\n        return 'Good'\n    elif(value <= level_dangerous[column][1]):\n        return 'Normal'\n    elif(value <= level_dangerous[column][2]):\n        return 'Bad'\n    else:\n        return 'Very bad'\n    return value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def generate_level_danger_gas_series(my_df, column):\n    series = my_df[column].map(lambda x: measurement_evaluator(x, column))\n    return series","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handler invalid data or outliers <a id ='index05'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\n### Check and analyze distribution of gas data <a id ='index06'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate many boxplots to each pollutant data\n\nfig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(ncols=3, nrows=2, figsize=(15, 7), sharex=False)\n\nmap_feat_ax = {'SO2': ax1, 'NO2': ax2, 'O3': ax3, 'CO': ax4, 'PM10': ax5, 'PM2.5': ax6}\n\nfor key, value in map_feat_ax.items():\n    sns.boxplot(x=df[key], ax=value)\n    \nfig.suptitle('Distribution to each polluant', fontsize=18)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate DataFrame with each 'describe' to each pollutant data\n\ngas_list = list(map_feat_ax.keys())\n\nlist_describes = []\nfor f in gas_list:\n    list_describes.append(df[f].describe())\n\ndf_describe_gas = pd.concat(list_describes, axis = 1)\ndf_describe_gas   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ðŸ‡ºðŸ‡¸\n\nWe have some invalid data, those with values less than zero, and some outiliers with very high values above normal.\n\nðŸ‡§ðŸ‡·\n\nTemos alguns dados invÃ¡lidos, aqueles com valores menores que zero, e alguns outiliers com valores muito altos acima do normal.\n"},{"metadata":{},"cell_type":"markdown","source":"### Remove invalid values <a id ='index07'></a> <a id ='index05'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\nThere are values less than 0, which is impossible for a gas measurement. Then it will be removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"condicional = df[gas_list] > 0.0\n\ndf = df[condicional.all(axis=1)]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ðŸ‡ºðŸ‡¸\n\nWas removed 647,511 - 632,447 = 15,064 rows\n\nðŸ‡§ðŸ‡·\n\nFoi removido 647.511 - 632.447 = 15.064 rows"},{"metadata":{},"cell_type":"markdown","source":"### Handler with outilers <a id ='index08'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\nðŸ‡ºðŸ‡¸\n\nusing z-score we will remove the outliers\n\nðŸ‡§ðŸ‡·\n\nusando z-score vamos remover os outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove rows where one of gas data has z_score bigger than threshold\n\n# link to talbe of z score associated to percentage of distriution: associated\n## https://www.math.arizona.edu/~rsims/ma464/standardnormaltable.pdf\n## Examples\n# 3 = .99865 = 99,85%\n# 2 = .97725 = 97,72%\n\nfrom scipy import stats\n\nz = np.abs(stats.zscore(df[gas_list]))\n\nthreshold = 2\n\ndf = df[(z < 2).all(axis=1)]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Was removed 632.447 - 616336 = 16.111 rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally, we have ...\n\nf, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(ncols=3, nrows=2, figsize=(15, 7), sharex=False)\n\nmap_feat_ax = {'SO2': ax1, 'NO2': ax2, 'O3': ax3, 'CO': ax4, 'PM10': ax5, 'PM2.5': ax6}\n\nfor key, value in map_feat_ax.items():\n    sns.boxplot(x=df[key], ax=value)\n    \nfig.suptitle('Distribution of polluants after remove outiliers', fontsize=18)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show describe() to each pollutant\n\ngas_list = list(map_feat_ax.keys())\n\nlist_describes = []\nfor f in gas_list:\n    list_describes.append(df[f].describe())\n\ndf_describe_gas1 = pd.concat(list_describes, axis = 1)\ndf_describe_gas1  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering <a id ='index09'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\nðŸ‡ºðŸ‡¸\n\nCreate the columns: Month, Year, WeekDay, Semester\n\nðŸ‡§ðŸ‡·\n\nCriar as colunas: Month, Year, WeekDay, Semester\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate columns to year, mont and weekday\n\ndf['Year']  = pd.DatetimeIndex(df['Date']).year\ndf['Month']  = pd.DatetimeIndex(df['Date']).month\ndf['Weekday'] = pd.DatetimeIndex(df['Date']).strftime(\"%A\")\ndf['Semester'] = ((pd.DatetimeIndex(df['Date']).month.astype(int) - 1) // 6) + 1\n\n# show new columns\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How SO2 has evolved over the years <a id ='index10'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\n<span style='font-size: 15pt'>Analyze the overall evolution of the SO2 </span>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\n\ndf.groupby(['Year','Semester', 'District']).mean()['SO2'].unstack().plot(ax=ax)\nax.set_ylabel(\"SO2\")\nax.set_title(\"S02 Evolution\")\nax.set_title(\"Evolution of SO2\")\nplt.legend(bbox_to_anchor=(0, 1), loc='upper left', ncol=2)\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"district_list = df['District'].unique().tolist()\n\nturbo_pallete = Turbo256[0:256:int(256/len(district_list) )][::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gas_type = 'SO2'\ndf_SO2_semester = df.groupby(['Year','Semester', 'District']).mean()[gas_type].reset_index()\n\navg_semester = {}\nfor d in district_list:\n    avg_semester[d] = np.array(df_SO2_semester.query('District == \"' + d + '\"')[gas_type])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.palettes import Turbo256\nfrom bokeh.models import Legend\n\nx_axis = np.array([2017,2017.5,2018,2018.5,2019,2019.5])\n\nfig = figure(title=\"Interactive overall evolution of the SO in Bokeh\", plot_width=1000, plot_height=700, x_axis_type=\"linear\")\n\ncount = 0\nfor d in district_list:\n    line = fig.line(x_axis, avg_semester[d], legend_label=d, color=turbo_pallete[count] ,line_width=3)\n    fig.circle(x_axis, avg_semester[d], legend_label=d, color=turbo_pallete[count], fill_color='white', size=7)\n    count += 1\n# plot title\nfig.legend.title = 'Gas'\n# Relocate Legend\nfig.legend.location = 'bottom_left'\n# Click to hide/show lines\nfig.legend.click_policy = 'hide'\n# Add Hover\nfig.add_tools(HoverTool(tooltips=[('SO2', '@y{%.5f}')], formatters={'@y' : 'printf'} ))\n\nshow(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:**\n\nðŸ‡ºðŸ‡¸\n\nWe can conclude that the average SO2 has decreased over the years\n\nðŸ‡§ðŸ‡·\n\nPodemos concluir a mÃ©dia de SO2 tem diminuido com o decorrer dos anos"},{"metadata":{},"cell_type":"markdown","source":"## What is the average gas pollution for each district and which has more or less? <a id ='index11'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\n<span style='font-size: 15pt'>Plot of total average per districts to each pollutant</span>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"primary_column = 'SO2'\ntarget_column = 'total_average_SO2'\n\ndf1 = df.groupby(['District']).mean()[primary_column].reset_index()\n\neda_foward_2_plots(df1, primary_column, target_column, \"SO total average per district\", \"The first and last 8 on average for SO\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"primary_column = 'CO'\ntarget_column = 'total_average_CO'\n\ndf1 = df.groupby(['District']).mean()[primary_column].reset_index()\n\neda_foward_2_plots(df1, primary_column, target_column, \"CO total average per district\", \"The first and last 8 on average for CO\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"primary_column = 'O3'\ntarget_column = 'total_average_O3'\n\ndf1 = df.groupby(['District']).mean()[primary_column].reset_index()\n\neda_foward_2_plots(df1, primary_column, target_column,\n                   \"O3 total average per district\", \"The first and last 8 on average for O3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"primary_column = 'PM10'\ntarget_column = 'total_average_PM10'\n\ndf1 = df.groupby(['District']).mean()[primary_column].reset_index()\n\neda_foward_2_plots(df1, primary_column, target_column,\n                   \"PM10 total average per district\", \"The first and last 8 on average for PM10\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"primary_column = 'PM2.5'\ntarget_column = 'total_average_PM2.5'\n\ndf1 = df.groupby(['District']).mean()[primary_column].reset_index()\n\neda_foward_2_plots(df1, primary_column, target_column,\n                   \"PM2.5 total average per district\", \"The first and last 8 on average for PM2.5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"primary_column = 'NO2'\ntarget_column = 'total_average_NO2'\n\ndf1 = df.groupby(['District']).mean()[primary_column].reset_index()\n\neda_foward_2_plots(df1, primary_column, target_column,\n                   \"NO2 total average per district\", \"The first and last 8 on average for NO2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nðŸ‡ºðŸ‡¸\n\nIt is curious to realize that for each gas, the district with the highest and lowest average differs between the gases\n\nðŸ‡§ðŸ‡·\n\nÃ‰ curioso perceber que para cada gas, o distrito com maior e mnor media diferem entre os gases"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Are there any negative measurements of pollutants? <a id ='index12'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>\n\n<span style='font-size: 15pt'>Analyse dangerous measurements of each pollutant</span>\n\n**Feature Engineering**: Create Good, Normal, Bad, Very Bad to each pollutant"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create `df_measures`\n\n# Filter only measures columns\nl_cols = df.columns.tolist()[1:8]\ndf_measures = df[l_cols]\n\n# Generate level dangerous to each gas\nl_level = [x+'_Level' for x in df_measures.columns.tolist()[1:] ]\nfor l in l_level:\n    df_measures[l] = generate_level_danger_gas_series(df_measures, l[:-6])\ndf_measures = df_measures.reset_index().drop('index', axis = 1)\n\n# output\ndf_measures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df_measures['SO2_Level'], 'SO2 level in all gas measurements')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df_measures['NO2_Level'], \"NO2 level in all gas measurements\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df_measures['O3_Level'], 'O3 level in all gas measurements')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df_measures['PM10_Level'], 'PM10 level in all gas measurements')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_categ_feat_desc_plot(df_measures['PM2.5_Level'], \"PM2.5 level in all gas measurements\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nðŸ‡ºðŸ‡¸\n\nGood(Blue) < Normal(Green) < Bad(Yellow) < Very bad(Red)\n\n+ SO2: All records seens Good\n+ NO2: 3,52% Bad\n+ 03: 0,62% Bad\n+ PM10: 7,20% Bad and 0,34% Very Bad\n+ PM2.5: 15.95% Bad and 1,79% Very Bad\n\nThere are few medications considered bad\n\nðŸ‡§ðŸ‡·\n\nGood(Blue) < Normal(Green) < Bad(Yellow) < Very bad(Red)\n\n+ SO2: Todos os registro sofram bons *Good*\n+ NO2: 3,52% *Bad*\n+ 03: 0,62% *Bad*\n+ PM10: 7,20% *Bad* e *0,34%* Very Bad\n+ PM2.5: 15.95% *Bad* e *1,79%* Very Bad\n\nHÃ¡ poucas medicaÃ§Ãµes consideradas ruins\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Where is Bad and Very Bads measures? <a id ='index13'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 30px\" data-toggle=\"popover\">Go to TOC</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting Data Frame with rows where exist 'Bad' or 'Very Bad' on measures gas level\n\ngas_level_list = list(df_measures.columns)[7:]\n\ncond = df_measures.isin(['Bad', 'Very Bad'])\ncond = cond[ cond[gas_level_list] == True].dropna(how=\"all\")\nlist_remove = list(cond.index)\ndf_bad = df_measures.iloc[list_remove]\ndf_bad.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_df_bad = df_bad['District'].value_counts().reset_index().rename(columns={'index': 'District', 'District': 'count_bad_measures'})\nmy_df_bad['count_bad_measures'] = my_df_bad['count_bad_measures'].astype(float)\n\nprimary_column = 'count_bad_measures'\ntarget_column = 'count_bad_measures'\n\neda_foward_2_plots(my_df_bad, primary_column, target_column,\n                   \"Counting 'Bad' and 'Very Bad' values for all pollutants\", \"The first and last 8 Counting 'Bad' and 'Very Bad' \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nðŸ‡ºðŸ‡¸\n\nThe region with the greatest amount of choice 'Bad' or 'Very bad' is the south-west, with the districts of Gwanak-gu in 1 Â° and Yeongdeungpo-gu in 2 Â°.\n\nNote that:\n+ The north has less research ruins than the south\n+ The east has fewer ruins than the west\n\nIn addition, the northern districts near the bukhasan national park were the lowest levels of negative level\n\nðŸ‡§ðŸ‡·\n\nA regiÃ£o com maior quantidade de mediÃ§Ãµes 'Ruim' ou 'Muito ruim' Ã© o sul d'oeste, com os distritos de Gwanak-gu em 1Â° e Yeongdeungpo-gu em 2Â°.\n\nNota-se que que:\n+ O norte tem menos mediÃ§Ãµes ruins queo que o sul\n+ O leste tem menos mediÃ§Ãµes ruins que o oeste\n\nAlÃ©m disso, os distritos ao norte prÃ³ximos do parque nacional de bukhasan foram os que apresentaram menor nÃ­vel de mediÃ§Ãµes negativas\n\n"},{"metadata":{},"cell_type":"markdown","source":"## FeedBack <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px\" data-toggle=\"popover\">Go to TOC</a>\n\nðŸ‡ºðŸ‡¸\n\nThis kernel is under development and new ideas can be added. Suggestions for improvements, new ideas for research or errors can be commented on, I would be grateful.\n\nIf you like it, vote positively!\n\nðŸ‡§ðŸ‡·\n\nEste Kernel estÃ¡ em desenvolvimento e novas ideias podem ser adicionadas. SujestÃµes de melhorias, novas ideias para investigaÃ§Ã£o ou erros podem ser comentados, ficaria grato.\n\nSe vocÃª gostar, vote positivamente!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}