{"cells":[{"metadata":{},"cell_type":"markdown","source":"# LIME on structure data\n****"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Any results you write to the current directory are saved as output.\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Ignore all warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n   \n# Importing Libraries\nimport numpy as np # linear algebra\nnp.random.seed(1)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas_profiling import ProfileReport\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport sklearn\nimport sklearn.datasets\nfrom sklearn.model_selection import train_test_split \nimport sklearn.ensemble\nimport lime\nimport lime.lime_tabular\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. LIME on IRIS dataset (toy example)\nDataset Source: https://www.kaggle.com/uciml/iris"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading toy dataset\niris_data = pd.read_csv(\"../input/iris/Iris.csv\")\n\n# Overview of dataset using pandas-profiling.\nprofile = ProfileReport(iris_data.drop([\"Id\"],axis = 1), title='Pandas Profiling Report',minimal=False, html={'style':{'full_width':True}})\nprofile.to_widgets()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spiliting\ntrain, test, labels_train, labels_test = train_test_split(iris_data.drop(['Id','Species'],axis=1).values, iris_data.Species, train_size=0.75)\n\n# Modeling usimg Random forest model\nrf = sklearn.ensemble.RandomForestClassifier(n_estimators=500,random_state=1234)\nrf.fit(train, labels_train)\n\n# Accuracy\nsklearn.metrics.accuracy_score(labels_test, rf.predict(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LIME explainer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explainer initialise\nexplainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=iris_data.drop(['Id','Species'],axis=1).columns, class_names= iris_data.Species.unique(), discretize_continuous=True)\n\n# Explaing random instance using LIME explainer \ni = np.random.randint(0, test.shape[0])\nexp = explainer.explain_instance(test[i], rf.predict_proba, num_features=2, top_labels=1)\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"----\n----"},{"metadata":{},"cell_type":"markdown","source":"## 2. Dataset containing only numerical values\n\nSource: https://www.kaggle.com/mariosfish/default-of-credit-card-clients\n### Dataset: Default of Credit Card Clients Dataset\n\n#### Dataset Information\nThis dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n\n\n#### Inspiration\nSome ideas for exploration:\n\n1. How does the probability of default payment vary by categories of different demographic variables?\n\n2. Which variables are the strongest predictors of default payment?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading toy dataset\ndata = pd.read_csv(\"../input/default-of-credit-card-clients/default of credit card clients.csv\")\n\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spiliting\ntrain, test, labels_train, labels_test = train_test_split(data.drop(['ID','dpnm'],axis=1).values, data.dpnm, train_size=0.75)\n\n# Modeling usimg Random forest model\nrf = sklearn.ensemble.RandomForestClassifier(n_estimators=500,random_state=1234)\nrf.fit(train, labels_train)\npredict_test = rf.predict(test)\n\n# Accuracy\nsklearn.metrics.accuracy_score(labels_test, predict_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LIME"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explainer initialise\nexplainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=data.drop(['ID','dpnm'],axis=1).columns, class_names= ['0','1'], discretize_continuous=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dpnm.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding index of misclassified datapoints\nnp.where(labels_test!=predict_test)[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Explaing random instance using LIME explainer \nidx = 4\nexp = explainer.explain_instance(test[idx], rf.predict_proba, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint(f\"Instance Datapoint\\n{'-'*20}\\n{test[idx]}\\n\")\nprint('Probability(0) =',rf.predict_proba([test[idx]])[0,0])\nprint('Probability(1) =',rf.predict_proba([test[idx]])[0,1])\nprint('True class: %s' % labels_test.iloc[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explaing random instance using LIME explainer \nidx = 18\nexp = explainer.explain_instance(test[idx], rf.predict_proba, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint(f\"Instance Datapoint\\n{'-'*20}\\n{test[idx]}\\n\")\nprint('Probability(0) =',rf.predict_proba([test[idx]])[0,0])\nprint('Probability(1) =',rf.predict_proba([test[idx]])[0,1])\nprint('True class: %s' % labels_test.iloc[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explaing random instance using LIME explainer \nidx = 20\nexp = explainer.explain_instance(test[idx], rf.predict_proba, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint(f\"Instance Datapoint\\n{'-'*20}\\n{test[idx]}\\n\")\nprint('Probability(0) =',rf.predict_proba([test[idx]])[0,0])\nprint('Probability(1) =',rf.predict_proba([test[idx]])[0,1])\nprint('True class: %s' % labels_test.iloc[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***\n***"},{"metadata":{},"cell_type":"markdown","source":"## 3. Dataset containing only categorical feature\n\nsource: https://www.kaggle.com/windblowbutt/mushroom-dataset\n### Dataset: Mushroom Classification \nSafe to eat or deadly poison?\n\n#### Context\nAlthough this dataset was originally contributed to the UCI Machine Learning repository nearly 30 years ago, mushroom hunting (otherwise known as \"shrooming\") is enjoying new peaks in popularity. Learn which features spell certain death and which are most palatable in this dataset of mushroom characteristics. And how certain can your model be?\n\n#### Content\nThis dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like \"leaflets three, let it be'' for Poisonous Oak and Ivy.\n\n#### Inspiration\n1. What types of machine learning models perform best on this dataset?\n\n2. Which features are most indicative of a poisonous mushroom?\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset Loading\n\ndata = np.genfromtxt('/kaggle/input/mushroom-dataset/mushroom.data', delimiter=',', dtype='<U20')\nlabels = data[:,0]\n\n# Categories name\nle= sklearn.preprocessing.LabelEncoder()\nle.fit(labels)\nlabels = le.transform(labels)\nclass_names = le.classes_\ndata = data[:,1:]\npd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncategorical_features = range(22)\n\nfeature_names = 'cap-shape,cap-surface,cap-color,bruises?,odor,gill-attachment,gill-spacing,gill-size,gill-color,stalk-shape,stalk-root,stalk-surface-above-ring, stalk-surface-below-ring, stalk-color-above-ring,stalk-color-below-ring,veil-type,veil-color,ring-number,ring-type,spore-print-color,population,habitat'.split(',')\n\ncategorical_names = '''bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\nfibrous=f,grooves=g,scaly=y,smooth=s\nbrown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\nbruises=t,no=f\nalmond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\nattached=a,descending=d,free=f,notched=n\nclose=c,crowded=w,distant=d\nbroad=b,narrow=n\nblack=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\nenlarging=e,tapering=t\nbulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\nfibrous=f,scaly=y,silky=k,smooth=s\nfibrous=f,scaly=y,silky=k,smooth=s\nbrown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\nbrown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\npartial=p,universal=u\nbrown=n,orange=o,white=w,yellow=y\nnone=n,one=o,two=t\ncobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\nblack=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\nabundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\ngrasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d'''.split('\\n')\n\nfor j, names in enumerate(categorical_names):\n    values = names.split(',')\n    values = dict([(x.split('=')[1], x.split('=')[0]) for x in values])\n    data[:,j] = np.array(list(map(lambda x: values[x], data[:,j])))\n    \npd.DataFrame(data,columns=feature_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_names = {}\nfor feature in categorical_features:\n    le = sklearn.preprocessing.LabelEncoder()\n    le.fit(data[:, feature])\n    data[:, feature] = le.transform(data[:, feature])\n    categorical_names[feature] = le.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\ndata = data.astype(float)\ntrain, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels, train_size=0.80)\n\n# one hotEncoding\nencoder = sklearn.preprocessing.OneHotEncoder()\nencoder.fit(train)\nencoded_train = encoder.transform(train)\n\n# Modeling\nrf = sklearn.ensemble.RandomForestClassifier(n_estimators=500,random_state=1234)\nrf.fit(encoded_train, labels_train)\npredict_fn = lambda x: rf.predict_proba(encoder.transform(x))\n\n# Accuracy\npresict_test = rf.predict(encoder.transform(test))\nsklearn.metrics.accuracy_score(labels_test, rf.predict(encoder.transform(test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LIME explainer"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1)\nexplainer = lime.lime_tabular.LimeTabularExplainer(train ,class_names=['edible', 'poisonous'], feature_names = feature_names,\n                                                   categorical_features=categorical_features, \n                                                   categorical_names=categorical_names, kernel_width=3, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding index of misclassified points.\nnp.where(labels_test!=presict_test)[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation: No misclassified points"},{"metadata":{},"cell_type":"markdown","source":"#### Example 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 22\nexp = explainer.explain_instance(test[i], predict_fn, num_features=5)\nexp.show_in_notebook()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****\n****"},{"metadata":{},"cell_type":"markdown","source":"## 4. Dataset containg both Numerical and Categorical features.\n\nsource: https://www.kaggle.com/blastchar/telco-customer-churn\n### Dataset: telco-customer-churn tabular dataset \n\n#### Context\n\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n\n#### Content\nEach row represents a customer, each column contains customer’s attributes described on the column Metadata.\n\nThe data set includes information about:\n\nCustomers who left within the last month – the column is called Churn\nServices that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\nCustomer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\nDemographic info about customers – gender, age range, and if they have partners and dependents\nInspiration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset Loading\ndata = pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data overview\nprint (\"Shape     : \" ,data.shape)\nprint (\"\\nFeatures : \\n\" ,data.columns.tolist())\nprint (\"\\nMissing values :  \", data.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",data.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing\ntotalcharges_float = []\nnull_idx = []\nfor idx,val in enumerate(data['TotalCharges'].values):\n    try:\n        totalcharges_float.append(np.float(val))\n    \n    except:\n        null_idx.append(idx)\n        \ndata = data.drop(labels=data.iloc[null_idx].index, axis=0)\ndata['TotalCharges'] = data['TotalCharges'].values.astype(float)\ndata.drop('customerID',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = data['Churn']\n\nle= sklearn.preprocessing.LabelEncoder()\nle.fit(labels)\nlabels = le.transform(labels)\nclass_names = le.classes_\ndata = data.drop('Churn',axis=1)\npd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = range(data.shape[1]-2)\n\nfeature_names = data.columns.values\n\ncategorical_names = {}\nfor feature in categorical_features:\n    le = sklearn.preprocessing.LabelEncoder()\n    le.fit(data.iloc[:, feature])\n    data.iloc[:, feature] = le.transform(data.iloc[:, feature])\n    categorical_names[feature] = le.classes_\n    \n# data after label encoding\nprint(feature_names)\n(categorical_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\ntrain, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data , labels, train_size=0.80)\n\n# one hotEncoding\nencoder = sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore')\nencoder.fit(train.iloc[:,categorical_features])\nencoded_train = encoder.transform(train.iloc[:,categorical_features])\nencoded_test= encoder.transform(test.iloc[:,categorical_features])\n\ntrain_concat = np.hstack((encoded_train.toarray(),train.iloc[:,-2:]))\n\nrf = sklearn.ensemble.RandomForestClassifier(n_estimators=500,random_state=1234)\nrf.fit(train_concat, labels_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict function\npredict_fn = lambda x: rf.predict(np.hstack((encoder.transform(x[:,categorical_features]).toarray(), x[:,-2:])))\n\n# predict probability function\npredict_proba_fn = lambda x: rf.predict_proba(np.hstack((encoder.transform(x[:,categorical_features]).toarray(), x[:,-2:])))\n                                  \n                              \n# Acuuracy\nprint(\"Accuracy :\")\nsklearn.metrics.accuracy_score(labels_test, predict_fn(test.values))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LIME explainer\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explainer initialise\nclass_name = ['no','yes']\nexplainer = lime.lime_tabular.LimeTabularExplainer(train.values, class_names= class_names, feature_names= feature_names,\n                                                   categorical_features= categorical_features, \n                                                   categorical_names= categorical_names, kernel_width=3, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# misclassified points\nnp.where(labels_test!=predict_fn(test.values))[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explaing random instance using LIME explainer \n\nidx = 19\nexp = explainer.explain_instance(test.values[idx],  predict_proba_fn, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint('Probability(0) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,0])\nprint('Probability(1) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,1])\nprint('True class: %s' % labels_test[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explaing random instance using LIME explainer \n\nidx = 40\nexp = explainer.explain_instance(test.values[idx],  predict_proba_fn, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint('Probability(0) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,0])\nprint('Probability(1) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,1])\nprint('True class: %s' % labels_test[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explaing random instance using LIME explainer \n\nidx = 51\nexp = explainer.explain_instance(test.values[idx],  predict_proba_fn, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint('Probability(0) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,0])\nprint('Probability(1) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,1])\nprint('True class: %s' % labels_test[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBOOST LIME"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Modeling\nclassifier = XGBClassifier()\nclassifier.fit(train_concat, labels_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict function\npredict_fn = lambda x: classifier.predict(np.hstack((encoder.transform(x[:,categorical_features]).toarray(), x[:,-2:])))\n\n# predict probability function\npredict_proba_fn = lambda x: classifier.predict_proba(np.hstack((encoder.transform(x[:,categorical_features]).toarray(), x[:,-2:])))\n                                                            \n# Acuuracy\nprint(\"Accuracy :\")\nsklearn.metrics.accuracy_score(labels_test, predict_fn(test.values))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LIME"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explainer initialise\nclass_name = ['no','yes']\nexplainer = lime.lime_tabular.LimeTabularExplainer(train.values, class_names= class_names, feature_names= feature_names,\n                                                   categorical_features= categorical_features, \n                                                   categorical_names= categorical_names, kernel_width=3, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mis classified points\nnp.where(labels_test!=predict_fn(test.values))[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 3\nexp = explainer.explain_instance(test.values[i],predict_proba_fn, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint('Probability(0) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,0])\nprint('Probability(1) =',predict_proba_fn(test.values[idx].reshape(1,-1))[0,1])\nprint('True class: %s' % labels_test[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 1404\nexp = explainer.explain_instance(test.values[i],predict_proba_fn, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint('Probability(0) =',predict_proba_fn(test.values[i].reshape(1,-1))[0,0])\nprint('Probability(1) =',predict_proba_fn(test.values[i].reshape(1,-1))[0,1])\nprint('True class: %s' % labels_test[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 1406\nexp = explainer.explain_instance(test.values[i],predict_proba_fn, num_features=5, top_labels=1)\n\nprint('\\nDocument id: %d' % idx)\nprint('Probability(0) =',predict_proba_fn(test.values[i].reshape(1,-1))[0,0])\nprint('Probability(1) =',predict_proba_fn(test.values[i].reshape(1,-1))[0,1])\nprint('True class: %s' % labels_test[idx])\n\nexp.show_in_notebook(show_table=True, show_all=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****\n***"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}