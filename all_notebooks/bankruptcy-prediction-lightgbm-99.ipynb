{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Company Bankruptcy Prediction"},{"metadata":{},"cell_type":"markdown","source":"## Table of Contents\n\n<ul>\n    <li><a href='#intro'>Introduction</a></li>\n    <li><a href='#wrangle'>Data Wrangling</a></li>\n    <li><a href='#eda'>Exploratory Data Analysis</a></li>\n    <li><a href='#conclusion'>Conclusion</a></li>\n</ul>"},{"metadata":{},"cell_type":"markdown","source":"<a id='intro'></a>\n## Introduction\nThe data were collected from the Taiwan Economic Journal for the years 1999 to 2009. \n\nIn this notebook, I built a LightGBM Classifier to predict company bankruptcy using financial features. The model has accuracy 0.99 and F1-score 0.99. Then I used SHAP to explain the predictions of this model. \n\nI made a [Data Visualization Web Application](https://bankruptcy-visualization.herokuapp.com/) by Streamlit and Heroku. In the application, you can select two random features to generate a scatterplot, with the colors represent bankruptcy condition."},{"metadata":{},"cell_type":"markdown","source":"<a id='wrangle'></a>\n## Data Wrangling"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import packages\n\n## general packages\nimport os\nimport numpy as np\nimport pandas as pd\n\n## Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.transform import factor_cmap, jitter\nfrom bokeh.layouts import row\n\n## Machine learning\nimport time\nfrom sklearn.model_selection import train_test_split\n### Oversampling\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTEENN\n### LightGBM\nimport lightgbm as lgb\n### Metrics\nfrom sklearn.metrics import roc_auc_score, precision_score, classification_report\n### Feature Selection\nimport shap","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Upload dataset\ndf = pd.read_csv('data.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df2=df.copy()\ndf2['Bankrupt?'].replace({0:'No', 1: 'Yes'}, inplace=True)\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalize each feature"},{"metadata":{},"cell_type":"markdown","source":"There are 95 variables describing the condition of companies, plus one column \"Bankrupt?\" as the label.\n\nThe number of records is 6819.\n\nNext, I'll check the existence of replicates and null values."},{"metadata":{"trusted":false},"cell_type":"code","source":"# check duplicates\ndf.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# check null values\ndf.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class Balancing"},{"metadata":{"trusted":false},"cell_type":"code","source":"labels = df['Bankrupt?'].value_counts()\nlabels.index=['No', 'Yes']\nlabels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To solve the unbalance of labels, I'll use SMOTEENN method to oversample the minority class then clean the noisy samples."},{"metadata":{"trusted":false},"cell_type":"code","source":"ori_X = df.drop(['Bankrupt?'], axis=1)\nori_y = df['Bankrupt?']\n\nsmote_enn = SMOTEENN(random_state=28)\nX, y = smote_enn.fit_resample(ori_X, ori_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_labels = y.value_counts()\nnew_labels.index = ['No', 'Yes']\nnew_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize=[10, 6])\ngs = fig.add_gridspec(1, 2)\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\n\nax0.pie(labels, labels=labels.index, pctdistance=0.5, autopct='%.1f%%')\nax1.pie(new_labels, labels=new_labels.index, pctdistance=0.5, autopct='%.1f%%')\n\nax0.set_title('Distribution of Labels before SMOTEENN')\nax1.set_title('Distribution of Labels after SMOTEENN');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='eda'></a>\n## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Modeling"},{"metadata":{},"cell_type":"markdown","source":"Use Scikit-learn API:"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Split data into random train and test subsets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)\n# Set the dataset\nd_train = lgb.Dataset(X_train, label=y_train)\nd_test = lgb.Dataset(X_test, label=y_test)\n# Specify parameters\nparams = {'boosting':'gbdt',\n          'max_bin':512,\n          'num_leaves':10,\n          'learning_rate':0.03,\n          'objective':'binary',\n          'force_col_wise':True,\n          'metric':'binary_logloss'}\n\n# Train\nlgbm = lgb.train(params, d_train, 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = lgbm.predict(X_test)\ny_pred = y_pred.round(0)\ny_pred = y_pred.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"roc_auc_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature selection"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Load JS visualization code\nshap.initjs()\n\n# Explain the model's predictions using SHAP\nexplainer = shap.TreeExplainer(lgbm)\nshap_values = explainer.shap_values(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"shap_values[1].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The total impact of features on the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"shap.summary_plot(shap_values, features=X_train, feature_names=X_train.columns, plot_type='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot shows the importance of features in a descending order. For example, the top feature \"Continuous interest rate\" contribute more to the model than the second feature \"Total debt/total net worth\". To figure out the relationships between features and labels,I plotted the effect of these features on all records in the training data as shown below:"},{"metadata":{},"cell_type":"markdown","source":"#### The impact of features on the model for individual data"},{"metadata":{"trusted":false},"cell_type":"code","source":"shap.summary_plot(shap_values[1], features=X, feature_names=X.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot shows the positive and negative relationships of the features with the label. Similarly, features are ranked in descending order. Each dot represents one record in the training data. The color represents the value of the feature (red high, blue low). The horizontal axis represents the effect of feature on model prediction. For example, high continuous interest rate lowers the probability that model predict bankrupt. There is a negative relationship between continuous interest rate with bankrupt."},{"metadata":{},"cell_type":"markdown","source":"#### The effect of a single feature across the whole dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"for name in X.columns:\n    shap.dependence_plot(name, shap_values[1], X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, I'll explore the effect of features on the prediction of each record, such as the first one with index 0:"},{"metadata":{"trusted":false},"cell_type":"code","source":"shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X.iloc[0,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How about the second record?"},{"metadata":{"trusted":false},"cell_type":"code","source":"shap.force_plot(explainer.expected_value[1], shap_values[1][1,:], X.iloc[1,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The prediction of both records are lower than the base value, which means these two records were classified as \"not bankrupt\". Those features which push the prediction to the direction of \"not bankrupt\" are shown in blue."},{"metadata":{},"cell_type":"markdown","source":"### Visualization"},{"metadata":{},"cell_type":"markdown","source":"First, let's take a look at the relationship between the top two variables: \n  - Continuous interest rate\n  - Total debt/ Total net worth\n  \nMore visualizations are shown on [Heroku app](https://bankruptcy-visualization.herokuapp.com)"},{"metadata":{"trusted":false},"cell_type":"code","source":"output_notebook()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# figure1\np1 = figure(plot_width=500, plot_height=500)\n\ncolormap = {0:'green', 1: 'red'}\ncolors= [colormap[x] for x in df['Bankrupt?']]\n\np1.circle(df[' Continuous interest rate (after tax)'], \n         df[' Total debt/Total net worth'], \n         size=10, line_color='black', fill_color=colors, fill_alpha=0.2)\n\np1.xaxis.axis_label='Continuous interest rate (after tax)'\np1.yaxis.axis_label='Total debt/Total net worth'\n\n#figure2\np2 = figure(plot_width=500, plot_height=500)\n\ncolormap = {0:'green', 1: 'red'}\ncolors= [colormap[x] for x in df['Bankrupt?']]\n\np2.circle(df[' Continuous interest rate (after tax)'], \n         df[' Retained Earnings to Total Assets'], \n         size=10, line_color='black', fill_color=colors, fill_alpha=0.2)\n\np2.xaxis.axis_label='Continuous interest rate (after tax)'\np2.yaxis.axis_label='Retained Earnings to Total Assets'\n\n\nshow(row(p1, p2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='conclusion'></a>\n## Conclusion"},{"metadata":{},"cell_type":"markdown","source":"The performance of the LightGBM model is pretty good, with accuracy 0.99 and F1-score 0.99. This model could help investigators distinguish companies with potentiation before making business decisions. "},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}