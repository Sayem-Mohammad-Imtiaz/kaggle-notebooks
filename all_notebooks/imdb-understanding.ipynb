{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В этом ноутбуке вы познакомитесь с основными средствами работы с пакетом pandas.\nЗадачей на сегодня является научиться работать с pandas в рамках описательной статистики.\nПакет пандас импортирован в самом начале \"import pandas as pd\"","metadata":{}},{"cell_type":"code","source":"# Here we are reading csv files from the sources\ndata = pd.read_csv(\"/kaggle/input/imdb-extensive-dataset/IMDb movies.csv\")\nrating = pd.read_csv(\"/kaggle/input/imdb-extensive-dataset/IMDb ratings.csv\")\nactors = pd.read_csv(\"/kaggle/input/imdb-extensive-dataset/IMDb names.csv\")\ntitles = pd.read_csv(\"/kaggle/input/imdb-extensive-dataset/IMDb title_principals.csv\")\n\n# to view columns of the panel table we just print the \"columns\" field of the object \"dataframe\".\n# The latter \"dataframe\" is the core class in pandas.\n\nprint(actors.columns)\nprint(titles.columns)\nprint(rating.columns)\nprint(data.columns)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here we concretize te features that are interesing for us\nfeatures = ['imdb_title_id', 'title', 'original_title', 'year', 'date_published',\n       'genre', 'duration', 'country', 'language', 'director', 'writer',\n       'production_company', 'actors', 'description', 'avg_vote', 'votes',\n       'budget', 'usa_gross_income', 'worlwide_gross_income', 'metascore',\n       'reviews_from_users', 'reviews_from_critics']\nfor feature in features:\n    print(feature, data[feature].unique()) # unique method gives all unique values that are in the column \"feature\". ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_currecy(x):\n    if len(str(x).split())>1:\n        return str(x).split()[0]\n    else:\n        return \"$\"\n\ndef get_amount(x):\n    if len(str(x).split())>1:\n        return float(str(x).split()[1])\n    else:\n        return float(x)\n    \n# we have defined functions above and want to apply them to some column\n# to apply we use .apply(function) method. \n\ndata[\"budget currecy\"] = data[\"budget\"].apply(get_currecy)\ndata[\"budget amount\"] = data[\"budget\"].apply(get_amount)\n\n# we do not need the \"budget\" column itself, so we can delete it from the dataframe\n\ndel data[\"budget\"]\n\ndata[\"worlwide_gross_income currecy\"] = data[\"worlwide_gross_income\"].apply(get_currecy)\ndata[\"worlwide_gross_income amount\"] = data[\"worlwide_gross_income\"].apply(get_amount)\ndel data[\"worlwide_gross_income\"]\n\ndata[\"usa_gross_income currecy\"] = data[\"usa_gross_income\"].apply(get_currecy)\ndata[\"usa_gross_income amount\"] = data[\"usa_gross_income\"].apply(get_amount)\ndel data[\"usa_gross_income\"]\n\n\n\nmoney = [\"budget currecy\", \"budget amount\", \n         \"usa_gross_income currecy\", \"usa_gross_income amount\", \n         \"worlwide_gross_income currecy\", \"worlwide_gross_income amount\"]\n\n# here we want to filter the dataframe by some condition, for example to filter the records with dollar currency\n# it is made using the condition data[condition].\n\nnew_data = data[money][(data[\"budget currecy\"] == \"$\") & \n                       (data[\"usa_gross_income currecy\"] == \"$\") & \n                       (data[\"worlwide_gross_income currecy\"] == \"$\")].dropna()\n\n# dropna is used to drop all records including NaN values \n\nnew_data[\"usa_income/budget ratio\"] = new_data[\"usa_gross_income amount\"].apply(float)/new_data[\"budget amount\"].apply(float)\nnew_data[\"world_income/budget ratio\"] = new_data[\"worlwide_gross_income amount\"].apply(float)/new_data[\"budget amount\"].apply(float)\n\ndata = data.merge(new_data)\ncol_names = data.columns\nfor name in col_names:\n    if \"currecy\" in name:\n        data = data[data[name]==\"$\"]\n        del data[name]\n\ndata[\"duration\"] = data[\"duration\"].apply(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#here we buila a histogram\n\ndata[\"world_income/budget ratio\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data[data[\"world_income/budget ratio\"]>500])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[data[\"world_income/budget ratio\"]<100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"world_income/budget ratio\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import log\n\ndata[\"log(usa_income/budget ratio)\"] = data[\"usa_income/budget ratio\"].apply(log)\ndata[\"log(usa_income/budget ratio)\"].hist()\ndata[\"log(usa_income/budget ratio)\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"log(world_income/budget ratio)\"] = data[\"world_income/budget ratio\"].apply(log)\ndata[\"log(world_income/budget ratio)\"].hist()\ndata[\"log(world_income/budget ratio)\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom statsmodels.distributions.empirical_distribution import ECDF\nimport matplotlib.pyplot as plt\n\necdf = ECDF(data[\"world_income/budget ratio\"])\nplt.plot(ecdf.x,ecdf.y, label = \"Эмпирическая функция распределения\")\nplt.plot(ecdf.x*0+1,ecdf.y, color=\"black\")\nplt.plot(ecdf.x,ecdf.y*0+0.42, color=\"black\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dynamics_mean = data.groupby(\"year\").mean()\ndynamics_std = data.groupby(\"year\").std()\n\n# maplotlib is added to gain visual aids\nfrom matplotlib import pyplot as plt\n\nplt.plot(dynamics_mean[\"world_income/budget ratio\"], label=\"средняя эффективность\")\nplt.plot(dynamics_mean[\"log(usa_income/budget ratio)\"]*0, color=\"black\")\nplt.legend() #we add legend to the plot\nplt.show()\nplt.plot(dynamics_mean[\"world_income/budget ratio\"]*0, color=\"black\")\nplt.plot(dynamics_std[\"world_income/budget ratio\"], label=\"ср.кв. откл. эффективности\")\nplt.legend()\nplt.show()\nplt.plot(dynamics_mean[\"log(world_income/budget ratio)\"], label=\"средняя логарифмическая эффективность\")\nplt.plot(dynamics_mean[\"log(usa_income/budget ratio)\"]*0, color=\"black\")\nplt.legend()\nplt.show()\nplt.plot(dynamics_mean[\"world_income/budget ratio\"]*0, color=\"black\")\nplt.plot(dynamics_std[\"log(world_income/budget ratio)\"], label=\"ср.кв. откл. логарифмической эффективности\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dynamics_mean = data.groupby(\"year\").mean()\ndynamics_std = data.groupby(\"year\").std()\n\nfrom matplotlib import pyplot as plt\n\nplt.scatter(data[\"year\"], data[\"log(world_income/budget ratio)\"])\nplt.plot(dynamics_mean[\"log(usa_income/budget ratio)\"]*0, color=\"black\")\nplt.legend()\nplt.show()\nplt.scatter(data[\"year\"], data[\"world_income/budget ratio\"])\nplt.plot(dynamics_mean[\"log(usa_income/budget ratio)\"]*0+1, color=\"black\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n\nplt.scatter(data[\"year\"], data[\"log(world_income/budget ratio)\"])\nplt.plot(dynamics_mean[\"log(usa_income/budget ratio)\"]*0, color=\"black\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collect_set(df_series, col_name):\n    answer = set()\n    for value in df_series[col_name].apply(lambda x: str(x).split(\",\")):\n        for x in value:\n            x = x.strip()\n            if not (x in answer):\n                answer.add(x)\n    return answer\n\ngenres = collect_set(data, \"genre\")\ncountries = collect_set(data, \"country\")\nlanguages = collect_set(data, \"language\")\n\ndef splitter(x):\n    x = str(x).split(\",\")\n    mt = []\n    for word in x:\n        mt.append(word.strip())\n    return mt\n\nprint(\"Genres\")\nfor genre in genres:\n    length = len(data[data[\"genre\"].apply(lambda x: int(genre in splitter(x)))==1])\n    if length>100:\n        print(genre, length)\nprint()\nprint(\"Countries\")\nfor country in countries:\n    length = len(data[data[\"country\"].apply(lambda x: int(country in splitter(x)))==1])\n    if length>100:\n        print(country, length)\nprint()\nprint(\"Languages\")\nfor language in languages:\n    length = len(data[data[\"language\"].apply(lambda x: int(language in splitter(x)))==1])\n    if length>100:\n        print(language, length)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Languages = [\"Spanish\", \"Russian\", \"Arabic\", \"Mandarin\", \"English\", \"French\", \"Italian\", \"Japanese\", \"German\"]\nRus = [\"Испанский\", \"Русский\", \"Арабский\", \"Китайский\", \n       \"Английский\", \"Французский\", \"Итальянский\", \"Японский\", \"Немецкий\"]\nRus_Languages=dict()\nfor i in range(len(Languages)):\n    Rus_Genres[Languages[i]] = Rus[i]\nprint(Rus_Genres)\n\n\nfor language in Languages:\n    loc_data = data[data[\"language\"].apply(lambda x: language in splitter(x))]\n    #if (loc_data1[\"world_income/budget ratio\"].mean()<standard_deviation):\n    #    loc_data1 = loc_data1[loc_data1[\"world_income/budget ratio\"]<standard_deviation]\n    #    standard_deviation = loc_data1[\"world_income/budget ratio\"].std()\n    #if (loc_data2[\"usa_income/budget ratio\"].mean()<standard_deviation):\n    #    loc_data1 = loc_data2[loc_data2[\"usa_income/budget ratio\"]<standard_deviation]\n    #    standard_deviation = loc_data2[\"usa_income/budget ratio\"].std()\n    dynamics_mean = loc_data.groupby(\"year\").mean()\n    dynamics_std = loc_data.groupby(\"year\").std()\n    print(language, \"World\", loc_data[\"log(world_income/budget ratio)\"].mean(), loc_data[\"log(world_income/budget ratio)\"].std())\n    plt.ylim(top=3)\n    plt.ylim(bottom=-3)\n    plt.plot(dynamics_mean[\"log(world_income/budget ratio)\"], label=Rus_Genres[language])\n    plt.plot(dynamics_mean[\"log(world_income/budget ratio)\"]*0, color=\"black\")\n    plt.legend()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Countries = [\"Spain\", \"UK\", \"France\", \"USA\", \"Australia\", \"Mexico\", \"China\", \"Japan\", \"Germany\", \"Hong Kong\",\n             \"Canada\", \"Italy\"]\nRus = [\"Испания\", \"Великобритания\", \"Франция\", \"США\",  \"Австралия\",\n       \"Мексика\", \"Китай\", \"Япония\", \"Германия\", \"Гонконг\", \"Канада\", \"Италия\"]\nRus_Countries=dict()\nfor i in range(len(Countries)):\n    Rus_Countries[Countries[i]] = Rus[i]\nprint(Rus_Countries)\n\nfor country in Countries:\n    loc_data = data[data[\"country\"].apply(lambda x: country in splitter(x))]\n    dynamics_mean = loc_data.groupby(\"year\").mean()\n    dynamics_std = loc_data.groupby(\"year\").std()\n    print(country, \"World\", loc_data[\"log(world_income/budget ratio)\"].mean(), loc_data[\"log(world_income/budget ratio)\"].std())\n    plt.plot(dynamics_mean[\"log(world_income/budget ratio)\"], label=Rus_Countries[country])\n    plt.plot(0*dynamics_mean[\"log(usa_income/budget ratio)\"])\n    plt.legend()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import floor\nfrom scipy.special import softmax\n\ndef count_rating_max(x):\n    answer = np.dot(np.array(x), softmax(x))\n    return answer\n\ndef count_rating(x):\n    answer = np.mean(x)\n    return answer\n\ndef count_rating_min(x):\n    answer = np.dot(np.array(x), softmax(-np.array(x)))\n    return answer\n\n\nnew_directors_df = directors_df.groupby(\"Director_for_grouping\")\nnew_directors_df = new_directors_df.agg(lambda x: list(x))\nnew_directors_df = new_directors_df.reset_index()\nnew_directors_df[\"rating mean\"] = new_directors_df[\"log(world_income/budget ratio)\"].apply(count_rating)\nnew_directors_df[\"rating mean\"].hist()\nfor i in range(len(new_directors_df)):\n    X = new_directors_df[\"year\"].loc[i]\n    Y = [new_directors_df[\"rating mean\"].loc[i]]*len(X)\n    plt.scatter(X,Y)\nplt.plot([0]*len(data[\"year\"]))\nplt.xlim(left=1980)\nplt.xlim(right=2020)\nplt.ylim(bottom=-5)\nplt.ylim(top=5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.DataFrame()\nProducer = collect_set(data, \"production_company\")\nfor production_company in Producer:\n    prod = pd.DataFrame(data[\"production_company\"].apply(lambda x: production_company in splitter(x)))\n    prod[production_company] = prod[\"production_company\"] \n    del prod[\"production_company\"] \n    #loc_data = data[prod]\n    features = pd.concat([features, prod], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Writers = collect_set(data, \"writer\")\nfor writer in Writers:\n    prod = pd.DataFrame(data[\"writer\"].apply(lambda x: writer in splitter(x)))\n    prod[writer] = prod[\"writer\"] \n    del prod[\"writer\"] \n    #loc_data = data[prod]\n    features = pd.concat([features, prod], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Directors = collect_set(data, \"director\")\nfor director in Directors:\n    direc = pd.DataFrame(data[\"director\"].apply(lambda x: director in splitter(x)))\n    direc[director] = direc[\"director\"] \n    del direc[\"director\"] \n    #loc_data = data[prod]\n    features = pd.concat([features, direc], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.to_csv(\"boolean.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = features.applymap(lambda x: int(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.to_csv(\"boolean_maped.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = data[\"log(world_income/budget ratio)\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import sqrt\n\ndef criteria(x):\n    if x==1:\n        return True\n    else:\n        return x/sqrt(1-x*x)*sqrt(l-2)>1.96\n\nbackup = data.copy()\nl = len(data)\ndel data[\"log(usa_income/budget ratio)\"]\ndel data[\"usa_income/budget ratio\"]\ndel data[\"usa_gross_income amount\"]\ndel data[\"reviews_from_users\"]\ndel data[\"reviews_from_critics\"]\ndel data[\"metascore\"]\ndel data[\"votes\"]\ndel data[\"avg_vote\"]\ncor = data.corr()\ncor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.concat([features, data[\"budget amount\"]], axis=1)\nfeatures = pd.concat([features, data[\"duration\"]], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del features[\"budget amount\"]\ndel features[\"duration\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = features.corrwith(target).apply(criteria)\nfor i in dataframe[dataframe].index:\n    print(i, dataframe.loc[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import exp\n\noutput_df = pd.DataFrame(features.columns)\noutput_df[\"factor\"] = output_df[0]\ndel output_df[0]\noutput_df = pd.concat([output_df, pd.DataFrame(model.coef_)], axis=1)\noutput_df[\"coef\"] = output_df[0]\ndel output_df[0]\noutput_df[\"a's\"] = output_df[\"coef\"].apply(exp)\nprint(output_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_features = features[dataframe[dataframe].index]\nnew_features = pd.concat([new_features, data[\"budget amount\"]], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import exp\n\noutput_df = pd.DataFrame(new_features.columns)\noutput_df[\"factor\"] = output_df[0]\ndel output_df[0]\noutput_df = pd.concat([output_df, pd.DataFrame(model.coef_)], axis=1)\noutput_df[\"coef\"] = output_df[0]\ndel output_df[0]\noutput_df[\"a's\"] = output_df[\"coef\"].apply(exp)\nprint(output_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in output_df.sort_values(by=\"coef\").index:\n    print(i, output_df[\"factor\"].loc[i], output_df[\"a's\"].loc[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Actors = collect_set(data, \"actors\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = len(Actors)\ni = 0\nfor actors in Actors:\n    act = pd.DataFrame(data[\"actors\"].apply(lambda x: actors in splitter(x)))\n    act[actors] = act[\"actors\"] \n    del act[\"actors\"] \n    act = act.corrwith(target).apply(criteria).loc[actors]\n    if act:\n        print(actors, \";\", act, \";\", i, l)\n    i+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"influencial_actors = pd.read_csv(\"/kaggle/input/inf-actors/IMDB_Influencial_actors.csv\", sep=\";\", header=None)\nprint(influencial_actors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_2 = pd.DataFrame()\ni=0\nfor actor in list(influencial_actors[0]):\n    actors = pd.DataFrame(data[\"actors\"].apply(lambda x: actor in splitter(x)))\n    actors[actor] = actors[\"actors\"]\n    del actors[\"actors\"]\n    features_2 = pd.concat([features_2, actors], axis=1)\n    print(i, end=\"; \")\n    i += 1\n    if i%20==0:\n        print()\nprint(features_2)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_2.to_csv(\"boolean2.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_2.applymap(lambda x: int(x)).to_csv(\"boolean2_maped.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_2 = pd.read_csv(\"boolean2_maped.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_genre = pd.DataFrame()\nfor genre in Genres:\n    features_genre[genre] = data[\"genre\"].apply(lambda x: genre in splitter(x))\nfeatures_genre = features_genre.applymap(lambda x: int(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import exp\n\noutput_df = pd.DataFrame(features_3.columns)\noutput_df[\"factor\"] = output_df[0]\ndel output_df[0]\noutput_df = pd.concat([output_df, pd.DataFrame(model.coef_)], axis=1)\noutput_df[\"coef\"] = output_df[0]\ndel output_df[0]\noutput_df[\"a's\"] = output_df[\"coef\"].apply(exp)\nprint(output_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(output_df.loc[12186:12204])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for genre in Genres:\n    print(genre, (target-target.mean() - 0.163059*features_3[genre]).apply(lambda x: x**2).sum()/target.apply(lambda x: x**2).sum())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords #we must reduce the stopwords from the text\n\ndata[\"description\"] = data[\"description\"].apply(lambda x: str(x).lower())\n\nprint(\"1 OK!\")\n\nstopWords = set(stopwords.words('english')) \n\nfor sep in [\".\", \",\", \"!\", \")\", \"(\", \"&\", \"*\", \"_\", \"-\", \"+\", \"=\", \"\\'\", \"\\\"\", \"|\", \":\", \";\", \"/\"]:\n    data[\"description\"] = data[\"description\"].apply(lambda x: x.replace(sep, \" \"))\n\nprint(\"2 OK!\")\n    \ndef trim(x):\n    while \"  \" in x:\n        x = x.replace(\"  \", \" \")\n        print(x)\n    return x\n\nprint(\"3 OK!\")\n\ndata[\"description\"] = data[\"description\"].apply(trim)\n\nprint(\"4 OK!\")\n\nfor w in stopWords:\n    data[\"description\"] = data[\"description\"].apply(lambda x: x.replace(\" \"+w+\" \", \" \"))\n\nprint(\"5 OK!\")\n    \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\n\nprint(\"6 OK!\")\n\ntfidf_train = vectorizer.fit_transform(data[\"description\"])\n\nprint(\"7 OK!\")\n\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=500)\nlower_dim_tfidf_train = pca.fit_transform(tfidf_train.todense())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lower_dim_tfidf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Упражнения\n\n1. Сформируйте many-to-many таблицу, в которой можно посмотреть пары режиссер, актер и количество общих работ\n\n2. Сформируйте many-to-many, где для любых двух режиссеров установлено число \"общих\" актеров - сколько актеров работало и у того, и у того режиссеров","metadata":{}}]}