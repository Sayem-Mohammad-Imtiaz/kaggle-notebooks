{"cells":[{"metadata":{"_uuid":"64543270-5350-4ff3-8d7c-7726d2894cff","_cell_guid":"75a309f0-fdf5-4eb5-870a-e156aa2912af","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a91319f-69c9-4750-9f40-d24055498533","_cell_guid":"8677333e-1809-46da-9df1-c496692504ce","trusted":true},"cell_type":"code","source":"train_orig=pd.read_csv(\"/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv\")\ntest_nolabel=pd.read_csv(\"/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dee2eb2-187a-4c3a-b64e-51dc1430eb2f","_cell_guid":"80ce4088-4773-4d25-a386-b5ec642bbb6d","trusted":true},"cell_type":"markdown","source":"**Let us do some pre-processing. Without preprocessing results are:  (Avoid looking at these metrics in the beginning, will be explained in the end of notebook)**\n<pre>\n               precision    recall  f1-score   support\n \n            0       0.95      1.00      0.97     14880\n            1       0.85      0.35      0.49      1101\n \n     accuracy                           0.95     15981\n    macro avg       0.90      0.67      0.73     15981\n weighted avg       0.95      0.95      0.94     15981\n \n [[14815    65]\n [  718   383]]\n</pre>"},{"metadata":{"_uuid":"75b0c50a-2998-4104-9f13-2d7cf4cde9c9","_cell_guid":"009f0b7e-0725-4ef3-9988-5c5ad92f4d5c","trusted":true},"cell_type":"markdown","source":"**New metric:**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14848\n           1       0.88      0.40      0.55      1133\n\n    accuracy                           0.95     15981\n   macro avg       0.92      0.70      0.76     15981\nweighted avg       0.95      0.95      0.95     15981\n\n[[14786    62]\n [  683   450]]\n</pre>"},{"metadata":{"_uuid":"fa225e65-f762-4020-aa90-10f1797d50a1","_cell_guid":"bbccf848-0d15-4057-9d00-1c98ee42456b","trusted":true},"cell_type":"markdown","source":"**New report with stratification enabled. Shows further improvement in results\n**<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14860\n           1       0.89      0.42      0.57      1121\n\n    accuracy                           0.96     15981\n   macro avg       0.92      0.71      0.77     15981\nweighted avg       0.95      0.96      0.95     15981\n\n[[14800    60]\n [  650   471]]\n</pre>"},{"metadata":{"_uuid":"6e4e876c-8f6f-4e59-9117-f6efcfc42c36","_cell_guid":"29fe89a1-536a-46d2-9afd-c8bc7f114183","trusted":true},"cell_type":"markdown","source":"**Classification report after upsampling the minority classes. Look at updated values for label 1**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.98      0.91      0.94     14860\n           1       0.92      0.98      0.95     14860\n\n    accuracy                           0.94     29720\n   macro avg       0.95      0.94      0.94     29720\nweighted avg       0.95      0.94      0.94     29720\n\n[[13542  1318]\n [  345 14515]]\n</pre>"},{"metadata":{"_uuid":"d7966c76-d2fb-4a20-a5c6-142314acd3ae","_cell_guid":"1c1454b0-4a67-4b9f-b22c-b361391ddc48","trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk import word_tokenize\nimport string\nimport re\nstop_words = set(stopwords.words('english'))\n\ntrain = train_orig\n\ndef remove_stopwords(line):\n    word_tokens = word_tokenize(line)\n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    return \" \".join(filtered_sentence)\n\ndef preprocess(line):\n    line = line.lower()  #convert to lowercase\n    line = re.sub(r'\\d+', '', line)  #remove numbers\n    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))  #remove punctuation\n#     line = line.translate(None, string.punctuation)  #remove punctuation\n    line = remove_stopwords(line)\n    return line\nfor i,line in enumerate(train.tweet):\n    train.tweet[i] = preprocess(line)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7297d3b1-6cc4-47e9-b823-59fe6cf1c946","_cell_guid":"ae158c16-07f8-4fee-a698-806e9e575c18","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['label'], test_size=0.5, stratify=train['label'])\n\ntrainp=train[train.label==1]\ntrainn=train[train.label==0]\nprint(trainp.info())\ntrainn.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2d8b7b0-7ee9-46df-ac68-c2478cda7d47","_cell_guid":"e8a722de-c5d7-4126-81d1-f946a80156e6","trusted":true},"cell_type":"code","source":"# Let us balance the dataset\ntrain_imbalanced = train\nfrom sklearn.utils import resample\ndf_majority = train[train.label==0]\ndf_minority = train[train.label==1]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=len(df_majority),    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\nprint(\"Before\")\nprint(train.label.value_counts())\nprint(\"After\")\nprint(df_upsampled.label.value_counts())\n\nX_train, X_test, y_train, y_test = train_test_split(df_upsampled['tweet'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f807001d-48cb-4acb-a50e-0fb10b150472","_cell_guid":"db540e57-6d34-4042-809c-20da4c34547a","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\n# Xtext=train.tweet\n# Xtest=test.tweet\n# y=train.label\n# test\n# ytest=test.label","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0691fbd1-5f91-45b8-9cb2-c1ebed2a6044","_cell_guid":"83a87983-e7b9-455d-96b0-63ed9bde717a","trusted":true},"cell_type":"markdown","source":"**Convert text data to numerical data**"},{"metadata":{"_uuid":"de800b82-cfeb-4acd-bf3c-de3f668103a7","_cell_guid":"0553db88-b9dd-452c-9675-cdf9f115d190","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nvect = CountVectorizer()\ntf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\ntf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f890f04b-aa66-4314-b063-d35799117749","_cell_guid":"8b06e01f-6e5a-4c9f-84d2-051550c1c785","trusted":true},"cell_type":"code","source":"tf_test_nolabel=vect.transform(test_nolabel.tweet)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9889e7b2-1613-41a5-bd0e-2079dfa25693","_cell_guid":"0da5c92d-8208-4811-ad2d-b0bef6d9461a","trusted":true},"cell_type":"code","source":"# print(tf_train)\n# vect.get_feature_names()[:10] #print few features only to avoid slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52e1f6bc-a5f4-4991-b3ad-64807698c1cc","_cell_guid":"40f0b1ae-9e9f-4f55-8841-476b8039ceed","trusted":true},"cell_type":"code","source":"model.fit(X=tf_train,y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00c598a3-acf5-4505-8f04-7c29ef3db593","_cell_guid":"b4232f33-b434-4f10-8add-5e1b535780d8","trusted":true},"cell_type":"code","source":"expected = y_test\npredicted=model.predict(tf_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2186654-f245-4c66-992b-6fb8e2eb1270","_cell_guid":"8c3c3317-b63d-4bf9-afac-925cfa8a5d95","trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bc1029d-7753-4ee9-9c4f-4800a0c9b435","_cell_guid":"983262de-94e0-4472-95c4-6b2763074448","trusted":true},"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\n\nplot_confusion_matrix(metrics.confusion_matrix(expected, predicted))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6bb6ab3-7e8f-4395-8199-15627fdd8693","_cell_guid":"fca5949c-c255-4321-be5b-858af51c3b90","trusted":true},"cell_type":"code","source":"print(trainp.iloc[:10])\ntrainn.iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d609aa2-8820-46e3-836b-570020f1c377","_cell_guid":"6328b745-c912-42a5-9c56-a8bb74dccc50","trusted":true},"cell_type":"code","source":"gg=X_test.reset_index(drop=True)\n# print(gg)\nfor i, p in enumerate(predicted):\n#     print(i)\n    print (gg[i] + \" - \" + str(p))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd53c238-3b87-463d-ac86-908ba16367ec","_cell_guid":"e8931fe5-b82e-4cd6-958d-8dfaf9d41dee","trusted":true},"cell_type":"code","source":"predicted_nolabel=model.predict(tf_test_nolabel)\nfor i, p in enumerate(tf_test_nolabel):\n#     print(i)\n    print (test_nolabel.tweet[i] + \" - \" + str(predicted_nolabel[i]))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97b9f4b9-1e91-40ba-a6f8-c962be1cedcf","_cell_guid":"247a530c-ea97-485e-b2cb-dcfdfec07ba6","trusted":true},"cell_type":"code","source":"test_custom=pd.DataFrame([\"racist\", \"white judge trial\", \"it is a horrible incident\", \"@user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why\", \" @user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why\", \"@user  at work: attorneys for white officer who shot #philandocastile remove black judge from presiding over trial. htâ¦\"])\ntf_custom = vect.transform(test_custom[0])\nmodel.predict(tf_custom)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1487c897-28bc-4d93-8f33-609a203458be","_cell_guid":"deb9d41c-2aa2-4bc2-a441-a2fb27dd3566","trusted":true},"cell_type":"code","source":"twit=pd.read_csv(\"../input/godrejtweet/Tweets.csv\")\ntf_twit=vect.transform(twit.tweet)\npredicted_twit=model.predict(tf_twit)\nneg=0\npos=0\n\nfor i, p in enumerate(tf_twit):\n#     print(i)\n    print (twit.tweet[i] + \" - \" + str(predicted_twit[i]))\n    if (predicted_twit[i]==0):\n        pos+=1\n    else:\n        neg+=1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e04f3ccb-4500-469c-afdc-c9cdba0620ae","_cell_guid":"db79a077-0bf1-4d94-bee4-a6cad39dbbd3","trusted":true},"cell_type":"code","source":"print (\"Positive Tweets - \",pos)\nprint (\"Negative Tweets - \",neg)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}