{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Regression Tree: Continuos quantitative target variable : Predicting rainfall, marks, revenue,etc\n\n# Regression classifier : Discrete categorical variables : Predicting high or low, win or loss, healthy or unhealthy."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/others/Movie_regression.xls',header=0) #since our csv file has header at 0th row, we use header=o\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We want to predict values for Collection (Y)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Genre'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time taken has missing values, look at the table, there are only 494 values"},{"metadata":{},"cell_type":"markdown","source":"# Misssing Values Imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Time_taken'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Time_taken'].fillna(value=df['Time_taken'].mean(),inplace=True) \n#we have filled the missing values with mean values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dummy variable creation"},{"metadata":{},"cell_type":"markdown","source":"We have to convert all our categorical variables, into numerical variables.\nAnd we do that by Dummy variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3d and Genre are categorical \n# we will convert them into dummy variable\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.get_dummies(df,columns=['3D_available','Genre'],drop_first=True) #drop_first = n-1 , \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# X-y split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.loc[:,df.columns!='Collection']\ntype(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df['Collection']\ntype(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n# since we are randomly assigning our data into test and train , to get the same test data everytime, so that \n#we can compare the performmace of the data\n#if i keep random state the same, we will get the same train test split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head() #indexes are shuffled, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Regression Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nregtree=tree.DecisionTreeRegressor(max_depth=3)\n# max depth = no of layers in our tree, we dont want to overfit, we use 3 . \n# Don't exceed beyond 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regtree.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Predict values using trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred=regtree.predict(X_train)\ny_test_pred=regtree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model performance = mean squared error, r2 value(goodness value= lies between 0(no fit) and 1 (perfect fit))\n\n# 0.4 to 0.8 for good models and above foe excellent models => r2 values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test,y_test_pred)\n# here we give test values and predicted values for y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_train,y_train_pred)\n# the value obtained is 0.83 which means our model is performing great","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate r2 values on our test data\nr2_score(y_test,y_test_pred)\n\n#always look at your test r2 values to evaluate your model performance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting Decision Tree"},{"metadata":{},"cell_type":"markdown","source":"1. firstly we create a dot file\n2. convert dot file into an image.\n3. Then use that image to creat a graph."},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data=tree.export_graphviz(regtree, out_file=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph=pydotplus.graph_from_dot_data(dot_data)\nImage(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pruning a tree= cutting the parts of the tree which are not beneficial for us"},{"metadata":{},"cell_type":"markdown","source":"# Pre-Prunning = controlling tree growth"},{"metadata":{},"cell_type":"markdown","source":"# Max number of Levels in tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"regtree1=tree.DecisionTreeRegressor(max_depth=3)\nregtree1.fit(X_train,y_train)\ndot_data=tree.export_graphviz(regtree1, out_file=None,feature_names=X_train.columns,filled=True) #filled = it will fill colors as per the conditon for the target variable = collection\ngraph1=pydotplus.graph_from_dot_data(dot_data)\nImage(graph1.create_png())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Minimum observations at internal node"},{"metadata":{"trusted":true},"cell_type":"code","source":"regtree2=tree.DecisionTreeRegressor(min_samples_split=40)\nregtree2.fit(X_train,y_train)\ndot_data=tree.export_graphviz(regtree2, out_file=None,feature_names=X_train.columns,filled=True) \ngraph2=pydotplus.graph_from_dot_data(dot_data)\nImage(graph2.create_png())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Minimum observations at leaf node"},{"metadata":{"trusted":true},"cell_type":"code","source":"regtree3=tree.DecisionTreeRegressor(min_samples_leaf=25)\nregtree3.fit(X_train,y_train)\ndot_data=tree.export_graphviz(regtree3, out_file=None,feature_names=X_train.columns,filled=True) \ngraph3=pydotplus.graph_from_dot_data(dot_data)\nImage(graph3.create_png())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we can also add conidtions to the above graph, by limiting the number of layers using max_depth"},{"metadata":{"trusted":true},"cell_type":"code","source":"regtree3=tree.DecisionTreeRegressor(min_samples_leaf=25,max_depth=4)\nregtree3.fit(X_train,y_train)\ndot_data=tree.export_graphviz(regtree3, out_file=None,feature_names=X_train.columns,filled=True) \ngraph3=pydotplus.graph_from_dot_data(dot_data)\nImage(graph3.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}