{"cells":[{"metadata":{"_uuid":"e9c166af7e3ad4f1c7f0853b7430760c64a33817"},"cell_type":"markdown","source":"# IBM HR Analytics"},{"metadata":{"_uuid":"ff1bcd95e2c8a4c0d1115bd7c53ea921d1e3a286"},"cell_type":"markdown","source":"## Dataset: [IBM HR Analytics Attrition Dataset](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset)"},{"metadata":{"_uuid":"d13bc835e806d38a1cab48e5d7b8eed2f199d0ef"},"cell_type":"markdown","source":"### Import all the necessary header files as follows:"},{"metadata":{"_uuid":"0ecafe8245ed1942c8a4f7a090277391ebc3014d"},"cell_type":"markdown","source":"**pandas** : An open source library used for data manipulation, cleaning, analysis and visualization. <br>\n**numpy** : A library used to manipulate multi-dimensional data in the form of numpy arrays with useful in-built functions. <br>\n**matplotlib** : A library used for plotting and visualization of data. <br>\n**seaborn** : A library based on matplotlib which is used for plotting of data. <br>\n**sklearn.metrics** : A library used to calculate the accuracy, precision and recall. <br>\n**sklearn.preprocessing** : A library used to encode and onehotencode categorical variables. <br>"},{"metadata":{"trusted":true,"_uuid":"0122804f0c92a1e68daade3f792e9670035dfbd6"},"cell_type":"code","source":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a0c02a1a7a4aab8df918ac80e6456cf8464252c"},"cell_type":"markdown","source":"### Read the data from the dataset using the read_csv() function from the pandas library."},{"metadata":{"trusted":true,"_uuid":"a5432b08bf1a1b1eb44f4cf1b191b71c9e9c6d9c"},"cell_type":"code","source":"# Importing the dataset\ndata = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"676e9253604490925b8e275b3d16a538febfa808"},"cell_type":"markdown","source":"### Inspecting and cleaning the data"},{"metadata":{"trusted":true,"_uuid":"a0b4e1d8b238244c3a23e317b48e7d14e4043b8b"},"cell_type":"code","source":"# Printing the 1st 5 columns\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d8f1601893180484013d5657da77372fe916887"},"cell_type":"code","source":"# Printing the dimenions of data\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce161884afd7238d401b46f3e8da395163f67f77"},"cell_type":"code","source":"# Viewing the column heading\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86b2d03ca76f1fb5592ee423242581a06a06ceca"},"cell_type":"code","source":"# Inspecting the target variable\ndata.Attrition.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54bc9ce2b4d26305e4f109c320f3f61c69ab0c07"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f55e37232003f15c48e3d61037f5e3be328fd011"},"cell_type":"code","source":"# Identifying the unique number of values in the dataset\ndata.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50432d4f041ad5f0c79a4f99fbe3b4757ce2d32c"},"cell_type":"code","source":"# Checking if any NULL values are present in the dataset\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d76e6dc8163d14f8eb9cade570819dec6dd39463"},"cell_type":"code","source":"# See rows with missing values\ndata[data.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67e039d1f98fc42df4482e2b1d36c06d5baaf477"},"cell_type":"code","source":"# Viewing the data statistics\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c4dc5ae77271557d40c16bb7c075f0ba4b6ad24"},"cell_type":"code","source":"# Here the value for columns, Over18, StandardHours and EmployeeCount are same for all rows, we can eliminate these columns\ndata.drop(['EmployeeCount','StandardHours','Over18','EmployeeNumber'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b083f29bcc51d8a3b27138dc11c23f4864112a4"},"cell_type":"markdown","source":"### Data Visualization"},{"metadata":{"trusted":true,"_uuid":"c53af988bb4b3336dbf2745e0bc04e55acc563b0"},"cell_type":"code","source":"# Plotting a boxplot to study the distribution of features\nfig,ax = plt.subplots(1,3, figsize=(20,5))               \nplt.suptitle(\"Distribution of various factors\", fontsize=20)\nsns.boxplot(data['DailyRate'], ax = ax[0]) \nsns.boxplot(data['MonthlyIncome'], ax = ax[1]) \nsns.boxplot(data['DistanceFromHome'], ax = ax[2])  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efda41ad62d52e493c4739bd0340a115cc116432"},"cell_type":"code","source":"# Finding out the correlation between the features\ncorr = data.corr()\ncorr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b00574e36563084433d001d0d80ee2e5d160b0b8"},"cell_type":"code","source":"# Plotting the heatmap of correlation between features\nplt.figure(figsize=(20,20))\nsns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ebf7dd6a92baef49f8b3c529012e536389c6738"},"cell_type":"code","source":"# Check for multicollinearity using correlation plot\nf,ax = plt.subplots(figsize=(10,10))\nsns.heatmap(data[['DailyRate','HourlyRate','MonthlyIncome','MonthlyRate']].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52368d5f2e6141508fc4df79647723c93ff31d74"},"cell_type":"code","source":"# Plotting countplots for the categorical variables\nfig,ax = plt.subplots(2,3, figsize=(20,20))            \nplt.suptitle(\"Distribution of various factors\", fontsize=20)\nsns.countplot(data['Attrition'], ax = ax[0,0]) \nsns.countplot(data['BusinessTravel'], ax = ax[0,1]) \nsns.countplot(data['Department'], ax = ax[0,2]) \nsns.countplot(data['EducationField'], ax = ax[1,0])\nsns.countplot(data['Gender'], ax = ax[1,1])  \nsns.countplot(data['OverTime'], ax = ax[1,2]) \nplt.xticks(rotation=20)\nplt.subplots_adjust(bottom=0.4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfc12fdadd7646379ec068b3758dd194723efdfc"},"cell_type":"code","source":"# Combine levels in a categorical variable by seeing their distribution\nJobRoleCrossTab = pd.crosstab(data['JobRole'], data['Attrition'], margins=True)\nJobRoleCrossTab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc377199b20a58e55e01a3fb0b3fb7c8bfd23629"},"cell_type":"code","source":"JobRoleCrossTab.div(JobRoleCrossTab[\"All\"], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6007864be9d7379b6d0cf1fd6b299d4ec2a3c6a3"},"cell_type":"code","source":"# Combining job roles with high similarities together\ndata['JobRole'].replace(['Human Resources','Laboratory Technician'],value= 'HR-LT',inplace = True)\ndata['JobRole'].replace(['Research Scientist','Sales Executive'],value= 'RS-SE',inplace = True)\ndata['JobRole'].replace(['Healthcare Representative','Manufacturing Director'],value= 'HE-MD',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c713b9bca979a579b8630c610d06d7e620480944"},"cell_type":"code","source":"# Encoding Yes / No values in Attrition column to 1 / 0\ndata.Attrition.replace([\"Yes\",\"No\"],[1,0],inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb9bd39c62de7728ccfaf605ccb7141788a7db46"},"cell_type":"code","source":"# One hot encoding for categorical variables\nfinal_data = pd.get_dummies(data)\nfinal_data.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc427b1d064cdb1b6b7106231fd44ba838777fa8"},"cell_type":"code","source":"final_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da336ff438c53db8b136ca09141c650c7967249b"},"cell_type":"markdown","source":"#### Once the data is cleaned, we split the data into training set and test set to prepare it for our machine learning model in a suitable proportion."},{"metadata":{"trusted":true,"_uuid":"a6497abad3515f1b9907cfcebd11c763b0d4fe29"},"cell_type":"code","source":"# Spliting target variable and independent variables\nX = final_data.drop(['Attrition'], axis = 1)\ny = final_data['Attrition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89f7c1176462a44cd9dac65531c02b6f195b2bd3"},"cell_type":"code","source":"# Splitting the data into training set and testset\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f9488f63cf7a2a5c8b51a93be05e231d5942b97"},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a426d12fd6553f16277f363bb649091e60dcb6a9"},"cell_type":"code","source":"# Checking distribtution of Target varaible in training set\ny_train.value_counts()[1]/(y_train.value_counts()[0]+y_train.value_counts()[1])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"698c70ee48228794d493f91d9b1e8575251f25cc"},"cell_type":"code","source":"y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad5b6abd991f983cfcbe2dc59110d04f01377b20"},"cell_type":"code","source":"# Checking distribtution of Target varaible in test set\ny_test.value_counts()[1]/(y_test.value_counts()[0]+y_test.value_counts()[1])*100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22533552c21ab2387ef3a00978509ac3df2f9b70"},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"c18050bda39fe3e5bafbd9e4f4b67ffaddbd4078"},"cell_type":"code","source":"# Logistic Regression\n\n# Import library for LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\n\n# Create a Logistic regression classifier\nlogreg = LogisticRegression()\n\n# Train the model using the training sets \nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecd1126e99f94776a85934a8c6bcba509ff3184d"},"cell_type":"code","source":"# Prediction on test data\ny_pred = logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a36e7e41f624f11418237cf69f558c81e393df29"},"cell_type":"code","source":"# Calculating the accuracy, precision and the recall\nacc_logreg = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_logreg )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"835f50f96793ef78dcda2c2f58d91e187afd3eb0"},"cell_type":"code","source":"# Create confusion matrix function to find out sensitivity and specificity\nfrom sklearn.metrics import auc,confusion_matrix\ndef draw_cm(actual, predicted):\n    cm = confusion_matrix( actual, predicted, [1,0]).T\n    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels = [\"Yes\",\"No\"] , yticklabels = [\"Yes\",\"No\"] )\n    plt.ylabel('Predicted')\n    plt.xlabel('Actual')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7ea6bb28a9f7aff05e7361a4aee23690a5f8a88"},"cell_type":"code","source":"# Confusion matrix \ndraw_cm(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d1f108152dcc8b80f68f84040a49c5af3aa1dc7"},"cell_type":"markdown","source":"### Gaussian Naive Bayes"},{"metadata":{"trusted":true,"_uuid":"c6bc0eef191148e3befc55a56d0d14c2b7911a4c"},"cell_type":"code","source":"# Gaussian Naive Bayes\n\n# Import library of Gaussian Naive Bayes model\nfrom sklearn.naive_bayes import GaussianNB\n\n# Create a Gaussian Classifier\nmodel = GaussianNB()\n\n# Train the model using the training sets \nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8670aef746f89e54465b3f47de49dab1b9cadffb"},"cell_type":"code","source":"# Prediction on test set\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"053946ca34bc4013896c34d35de23e9e40f98704"},"cell_type":"code","source":"# Calculating the accuracy, precision and the recall\nacc_nb = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_nb )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9009831d021faae06da7a9b46dcf9427ef43ecb3"},"cell_type":"code","source":"# Confusion matrix \ndraw_cm(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fea5b941026bc7032adea60c485f8927c8561359"},"cell_type":"markdown","source":"### Decision Tree Classifier"},{"metadata":{"trusted":true,"_uuid":"0ba64bd91583ba0bcfbfe2ef23aa806c5254267c"},"cell_type":"code","source":"# Decision Tree Classifier\n\n# Import Decision tree classifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create a Decision tree classifier model\nclf = DecisionTreeClassifier(criterion = \"gini\" , min_samples_split = 100, min_samples_leaf = 10, max_depth = 50)\n\n# Train the model using the training sets \nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d50fdf9f7d9f9cb250c02dff5b494329415b440"},"cell_type":"code","source":"# Model prediction on train data\ny_pred = clf.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ece5a983c58a3a68017d006d946f8441e9827012"},"cell_type":"code","source":"# Finding the variable with more importance\nfeature_importance = pd.DataFrame([X_train.columns, clf.tree_.compute_feature_importances()])\nfeature_importance = feature_importance.T.sort_values(by = 1, ascending=False)[1:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba8c3e1c4cbeb841cf272546a31412b676d756a6"},"cell_type":"code","source":"sns.barplot(x=feature_importance[1], y=feature_importance[0])\n# Add labels to the graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb1bf7bb522f28eec89e43a4fb475eb3d50ba41d"},"cell_type":"code","source":"# Prediction on test set\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abc8595ef151a93c035026ab650dffc21c1a8152"},"cell_type":"code","source":"# Confusion matrix\ndraw_cm(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d4e484d43890c3e601796025a585e35ee2c6718"},"cell_type":"code","source":"# Calculating the accuracy, precision and the recall\nacc_dt = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_dt )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac29d702e90aa1a2437f9b17da2cbc5af326910d"},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true,"_uuid":"b903f399d0375147a00f1e59468649541d7e73ba"},"cell_type":"code","source":"# Random Forest Classifier\n\n# Import library of RandomForestClassifier model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Create a Random Forest Classifier\nrf = RandomForestClassifier()\n\n# Train the model using the training sets \nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfbcc17247e2e5ed153f81542cde2558cc16355b"},"cell_type":"code","source":"# Finding the variable with more importance\nfeature_imp = pd.Series(rf.feature_importances_,index= X_train.columns).sort_values(ascending=False)\n# Creating a bar plot\nfeature_imp=feature_imp[0:10,]\nsns.barplot(x=feature_imp, y=feature_imp.index)\n# Add labels to the graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f72b2c3b363883844706c6f5930afcacbab1f93"},"cell_type":"code","source":"# Prediction on test data\ny_pred = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"466be57cf786c03aa23565a5f9440391dd631744"},"cell_type":"code","source":"# Confusion metrix\ndraw_cm(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cb00d425028566155c4de81b0fe9031de638ef2"},"cell_type":"code","source":"# Calculating the accuracy, precision and the recall\nacc_rf = round( metrics.accuracy_score(y_test, y_pred) * 100 , 2 )\nprint( 'Total Accuracy : ', acc_rf )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100 , 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fdbfe43d56f982265d7c5bf94917e3ab7ac8e26"},"cell_type":"markdown","source":"### Support Vector Machine Classifier"},{"metadata":{"trusted":true,"_uuid":"e76ba1953952f7eb66d9f469c286766a73799647"},"cell_type":"code","source":"# SVM Classifier\n\n# Creating scaled set to be used in model to improve the results\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41bebdebae59cf9a41e85b7e9204413f6a627211"},"cell_type":"code","source":"# Import Library of Support Vector Machine model\nfrom sklearn import svm\n\n# Create a Support Vector Classifier\nsvc = svm.SVC()\n\n# Train the model using the training sets \nsvc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0edfb06b996d8e6eafeca6432351c774374e3eca"},"cell_type":"code","source":"# Prediction on test data\ny_pred = svc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ad0722b0db883bf7acc2e9573019cf732b37fd7"},"cell_type":"code","source":"# Confusion Matrix\ndraw_cm(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52b622dd9e6cd73b461e90301705a608ce1afc76"},"cell_type":"code","source":"# Calculating the accuracy, precision and the recall\nacc_svm = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_svm )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ad80fe21270df89716153c23c452867937a69b3"},"cell_type":"markdown","source":"## Evaluation and comparision of all the models"},{"metadata":{"trusted":true,"_uuid":"df74e61bba3c58438932f8dabb9d39fbbbfa7502"},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines'],\n    'Score': [acc_logreg, acc_nb, acc_dt, acc_rf, acc_svm]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3315a46f92b03cf2370b005c1157e6a466a936a6"},"cell_type":"markdown","source":"## Hence we can see that the Logistic Regression works the best for this dataset. "},{"metadata":{"_uuid":"07adcd011c857c0cb96216151e54b716c193b415"},"cell_type":"markdown","source":"### Please upvote if you found this kernel useful! :) <br>\n### Any sort of feedback is appreciated!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"position":{"height":"608.8px","left":"789.6px","right":"20px","top":"79px","width":"535.8px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}