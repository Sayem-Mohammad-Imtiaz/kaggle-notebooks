{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Churn Prediction‚òéÔ∏èüìäüîñüìâ"},{"metadata":{},"cell_type":"markdown","source":"In this notebook:\n\n- EDA for Iranian Churn Dataset\n- Grid Search for hyperparameter tuning with cross-val&hold-out methods\n- Decision Tree\n- Naive Bayes\n- SVM\n- Neural Networks\n- Bagging ensemble method\n- Boosting ensemble method"},{"metadata":{"id":"hmX5VrUZ5brp","outputId":"1fdda48f-fd91-49fc-b8d0-91f091bee982","trusted":true},"cell_type":"code","source":"import csv\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport time","execution_count":null,"outputs":[]},{"metadata":{"id":"UIJT2OJf6Ah4","outputId":"9c490dc1-03ea-4abf-afe0-7db0d13d671c","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/customer-churn/Customer Churn.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"xLSSHoeRG9GU","outputId":"f0945caa-4d2b-4673-ecdb-2ee301449fec","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"C8da31hJ4-uw","trusted":true},"cell_type":"code","source":"#rename columns\ndf=df.rename(columns={\"Call  Failure\": \"call_failure\", \"Complains\": \"complains\", \"Subscription  Length\": \"subs_len\", \"Charge  Amount\": \"charge_amount\",\n                   \"Seconds of Use\": \"total_sec_calls\", \"Frequency of use\": \"total_num_calls\", \"Frequency of SMS\": \"total_num_sms\", \"Distinct Called Numbers\": \"distinct_call_nums\",\n                   \"Age Group\": \"age_group\", \"Tariff Plan\": \"tariff_plan\", \"Status\": \"status\", \"Age\": \"age\", \"Customer Value\": \"customer_value\"})","execution_count":null,"outputs":[]},{"metadata":{"id":"DxbM0CO993eB","outputId":"84b484c3-c4be-4a5b-eade-8848918a8c48","trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"id":"PvP33E6v6AWL","outputId":"5f196cd5-6a36-4b12-c590-34dbe3725726","trusted":true},"cell_type":"code","source":"#see how many unique values for each col\ndf.nunique()","execution_count":null,"outputs":[]},{"metadata":{"id":"03zrwoYV6ASg","outputId":"367a8491-d792-4584-c6d4-74e279298aee","trusted":true},"cell_type":"code","source":"#there is no Nan values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"o-NRP9lvYWdi"},"cell_type":"markdown","source":"# EDA"},{"metadata":{"id":"9zJJ4CsYST7k","outputId":"1a57622c-22f4-4c6b-9da3-1c2b6b872124","trusted":true},"cell_type":"code","source":"#see target class is imbalanced\n\nsns.set_style(\"dark\")\nsns.set(rc={'figure.figsize':(4,4)})\nsns.countplot(x=\"Churn\", data=df, palette=sns.color_palette(\"Paired\", 7), saturation=10)","execution_count":null,"outputs":[]},{"metadata":{"id":"4TQbuO78Ddxe","outputId":"f9e06e7a-2de6-47b9-ff88-e12423486fe7","trusted":true},"cell_type":"code","source":"sns.set_style(\"dark\")\nsns.countplot(x=\"age_group\", data=df, palette=sns.color_palette(\"husl\", 8), saturation=10)","execution_count":null,"outputs":[]},{"metadata":{"id":"TQ6cx6xzDduk","outputId":"0cb6db22-8a4b-4af9-c4cf-72dee9a69037","trusted":true},"cell_type":"code","source":"sns.set_style(\"dark\")\nsns.countplot(x=\"charge_amount\", data=df, palette=sns.color_palette(\"husl\", 8), saturation=10)","execution_count":null,"outputs":[]},{"metadata":{"id":"EqtBzVWsFL9I","outputId":"338d35a4-40ef-4836-ed21-faa1d129b8f1","trusted":true},"cell_type":"code","source":"sns.set_style(\"dark\")\nsns.countplot(x=\"age_group\", data=df, palette=sns.color_palette(\"husl\", 8), saturation=10, hue=\"Churn\")","execution_count":null,"outputs":[]},{"metadata":{"id":"CsfalU4eFteB","outputId":"4814157e-d59a-4af3-94e0-08440bc7bd99","trusted":true},"cell_type":"code","source":"sns.set(rc={\"font.style\":\"normal\",\n            \"text.color\":\"black\",\n            \"xtick.color\":\"black\",\n            \"ytick.color\":\"black\",\n            \"axes.labelcolor\":\"black\",\n            \"axes.grid\":False,\n            'axes.labelsize':30,\n            'figure.figsize':(12.0, 6),\n            'xtick.labelsize':25,\n            'ytick.labelsize':20})\n\nsns.set(style=\"white\",font_scale=1)\n\n\nsns.set_style(\"dark\")\nsns.countplot(x=\"charge_amount\", data=df, palette=sns.color_palette(\"husl\", 8), \n              saturation=10, edgecolor=(0,0,0), linewidth=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"e_lgrQj0Ykx7","outputId":"db6e4d57-c02b-4d91-8336-275ac4e029e0","trusted":true},"cell_type":"code","source":"# library\nimport matplotlib.pyplot as plt\nfrom palettable.colorbrewer.qualitative import Pastel1_7\n\n# create data\nnames=list(df[\"age\"].unique())\nsizes=[df[\"age\"].value_counts()[unique_class]*100/len(df[\"age\"]) for unique_class in names]\ncolors = Pastel1_7.hex_colors\nexplode = (0, 0, 0, 0, 0)  # explode a slice if required\n\nplt.pie(sizes, explode=explode, labels=names, colors=colors,\n        autopct='%1.1f%%', shadow=True)\n        \n#draw a circle at the center of pie to make it look like a donut\ncentre_circle = plt.Circle((0,0), 0.50, color='black', fc='white',linewidth=0.80)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n\n# Set aspect ratio to be equal so that pie is drawn as a circle.\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"yxAN8MsjtgKI","outputId":"089c1dbf-0ce5-4bf3-ca67-e913252b50f8","trusted":true},"cell_type":"code","source":"cat_feature_col=[\"complains\", \"charge_amount\", \"tariff_plan\", \"status\", \"age\",\"Churn\"]\nfor i in cat_feature_col:\n    print(f\"{i} : {df[i].unique()}\")\n    print(df[i].value_counts())\n    print(\"-------------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"id":"rm-uWsueYkks","outputId":"2a5f23c0-c190-4744-fa40-89c7f2ffcbcb","trusted":true},"cell_type":"code","source":"#heatmap for correlation coefficient\n\n# calculate correlation\ndf_corr = df.corr()\n\n# correlation matrix\nsns.set(font_scale=0.8)\nplt.figure(figsize=(16,12))\nsns.heatmap(df_corr, annot=True, fmt=\".4f\",vmin=-1, vmax=1, linewidths=.5, cmap = sns.diverging_palette(145, 300, s=60, as_cmap=True))\n\n#plt.yticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"hXFhcs-KYkiI","outputId":"cb415082-d09e-44f8-a606-fea78d704364","trusted":true},"cell_type":"code","source":"#feature importance using corr\ndf.drop('Churn', axis=1).corrwith(df.Churn).plot(kind='barh', figsize=(8, 6), color='skyblue', title=\"Churn vs all features\")","execution_count":null,"outputs":[]},{"metadata":{"id":"7SJ9m3534DWW","outputId":"3a519a7b-17a6-48e9-ac49-de1c82f423b6","trusted":true},"cell_type":"code","source":"!pip install ppscore","execution_count":null,"outputs":[]},{"metadata":{"id":"jlDmZtmK7F2H","outputId":"969af058-4a11-431a-faea-969cde0978ad","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport ppscore as pps\n\nmatrix_df = pps.matrix(df).pivot(columns='x', index='y',  values='ppscore')\n\nsns.heatmap(matrix_df, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"LMTZwnFakp2R","outputId":"ae78cbb0-9482-4b5f-c996-fdd191c51932","trusted":true},"cell_type":"code","source":"#for cat data distribution\nimport matplotlib\n\nplt.figure(figsize=(32, 32))\nmatplotlib.rc('axes', titlesize=24)#cols size\n\ncat_feature_col=[\"complains\", \"charge_amount\", \"age_group\", \"tariff_plan\", \"status\", \"age\"]\nfor i, column in enumerate(cat_feature_col, 1):\n    plt.subplot(4, 4, i)\n    df[df[\"Churn\"] == 0][column].hist(bins=20, color='pink', label='churn = 0(non-churn)', alpha=1)\n    df[df[\"Churn\"] == 1][column].hist(bins=20, color='tomato', label='churn = 1(churn)', alpha=1)\n    plt.legend(fontsize='medium')\n    plt.title(column)","execution_count":null,"outputs":[]},{"metadata":{"id":"bgJE5A6mmx3M","trusted":true},"cell_type":"code","source":"#since age_group and age is highly correlated, we decide to del age_group\ndf=df.drop(columns=[\"age_group\", \"FN\", \"FP\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"ZWFs2u3xAMIt","outputId":"ce9207d0-b15e-4033-94a0-b86109787c73","trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"id":"mmX-sZy7pnpR","outputId":"fbf3baf7-5921-495b-e978-a69b54489bfa","trusted":true},"cell_type":"code","source":"#for cont data scatterplot matrix\ncont_feature_col=[\"call_failure\", \"subs_len\", \"total_sec_calls\", \"total_num_calls\", \"total_num_sms\", \"distinct_call_nums\",\"customer_value\"]\n\nsns.set(style=\"ticks\")\n\nsns.pairplot(df[cont_feature_col + ['Churn']], hue='Churn', palette=\"husl\", corner=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"sq0ocLtAq0rU","outputId":"0518274d-2e79-4560-b1cc-320a16da17c2","trusted":true},"cell_type":"code","source":"#outlier analysis using box-plot(continuos data can have outliers)\n\nsns.set(style=\"whitegrid\",font_scale=1)\nplt.figure(figsize=(10,8))\nsns.boxplot(data=df[cont_feature_col])\nplt.xticks(rotation=80)\nplt.title(\"Box plot \")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"edXVFMgZdCoZ","outputId":"dfe68963-896b-4b60-b6be-5fced0066eac","trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"XDulGNWwve1p","outputId":"59f3725c-3257-4665-e620-03b7f146b12d","trusted":true},"cell_type":"code","source":"# find the IQR\nq1 = df[cont_feature_col].quantile(.25)\nq3 = df[cont_feature_col].quantile(.75)\nIQR = q3-q1\n\noutliers_df = np.logical_or((df[cont_feature_col] < (q1 - 1.5 * IQR)), (df[cont_feature_col] > (q3 + 1.5 * IQR))) \n\noutlier_list=[]\ntotal_outlier=[]\nfor col in list(outliers_df.columns):\n    try:\n        total_outlier.append(outliers_df[col].value_counts()[True])\n        outlier_list.append((outliers_df[col].value_counts()[True] / outliers_df[col].value_counts().sum()) * 100)\n    except:\n        outlier_list.append(0)\n        total_outlier.append(0)\n        \noutlier_list\n\noutlier_df=pd.DataFrame(zip(list(outliers_df.columns), total_outlier, outlier_list), columns=['name of the column', 'total', 'outlier(%)'])\n\n#see totally how many outliers in cont features\noutlier_df.set_index('name of the column', inplace=True)\n#del outlier_df.index.name\noutlier_df","execution_count":null,"outputs":[]},{"metadata":{"id":"D7cRmVE34Iks","outputId":"a1a86fb2-765d-4c71-c35b-752b32dee23d","trusted":true},"cell_type":"code","source":"outliers_df","execution_count":null,"outputs":[]},{"metadata":{"id":"Hrx3KJdC54W8","outputId":"0672d28f-6b55-46ac-94f5-3170477d8fd2","trusted":true},"cell_type":"code","source":"df_cont=df[cont_feature_col]\nout_nan_df=df_cont[~outliers_df]\nout_nan_df","execution_count":null,"outputs":[]},{"metadata":{"id":"HzKHmYASciOv","trusted":true},"cell_type":"code","source":"for col in cont_feature_col:\n  #qq=out_nan_df.dropna()\n  col_mean=df[col].mean() #calculate mean for each col\n  out_nan_df[col]=out_nan_df[col].fillna(col_mean) #first convert outliers to Nan values then fill Nan's with col mean\n  #df[cont_feature_col]=df_cont","execution_count":null,"outputs":[]},{"metadata":{"id":"dGBiNihV9VJ5","outputId":"0ac7c5f2-75f2-4416-ad84-be5ad7cac438","trusted":true},"cell_type":"code","source":"out_nan_df","execution_count":null,"outputs":[]},{"metadata":{"id":"h8sVOlL1W0Bd","trusted":true},"cell_type":"code","source":"deneme=df.drop(columns=[\"call_failure\", \"subs_len\", \"total_sec_calls\", \"total_num_calls\", \"total_num_sms\", \"distinct_call_nums\", \"customer_value\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"Cm08MOPnWz9y","trusted":true},"cell_type":"code","source":"#concat cat_df and clear out of outliers cont_df\n\ndf=pd.concat([out_nan_df, deneme], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"2X8v94UIWzwh","outputId":"39aa341a-bf12-403c-c8bf-5efaba94b0ad","trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"id":"zmCe4eOCS5ZH"},"cell_type":"markdown","source":"# CLASSIFICATION"},{"metadata":{"id":"jGwo2k_WTLkg","trusted":true},"cell_type":"code","source":"#import sklearn methods\nfrom sklearn.metrics import accuracy_score, roc_curve, confusion_matrix, classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, CategoricalNB\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import learning_curve\nimport sys \nimport os","execution_count":null,"outputs":[]},{"metadata":{"id":"PQXzC_xSIpAD","trusted":true},"cell_type":"code","source":"# split df to X and Y\ny = df.loc[:, 'Churn'].values\nX = df.drop('Churn', axis=1)\n\n# split data into 80-20 for training set / test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n\n# cross-validation with 5 splits\ncv = StratifiedShuffleSplit(n_splits=5, random_state = 88)\n\n#hold-out\nhold_out=StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state = 88)","execution_count":null,"outputs":[]},{"metadata":{"id":"gwt9sUVzY6Yj","outputId":"caa08111-ff3e-4fa0-babc-777f6283be92","trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train size is\", len(X_train))\nprint(\"y_train size is\", len(y_train))\nprint(\"--------------------\")\nprint(\"X_test size is\", len(X_test))\nprint(\"y_test size is\", len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"id":"PhiNqVfaUE6P"},"cell_type":"markdown","source":"# Normalization"},{"metadata":{"id":"sMaSwgdcUILO","trusted":true},"cell_type":"code","source":"#normalization(make all values bet. 0-1)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train_normalized_arr=scaler.transform(X_train)\nX_train_normalized_df=pd.DataFrame(X_train_normalized_arr, columns=list(X.columns))\n\nX_test_normalized_arr=scaler.transform(X_test)\nX_test_normalized_df=pd.DataFrame(X_test_normalized_arr, columns=list(X.columns))","execution_count":null,"outputs":[]},{"metadata":{"id":"YNSFk_ZQT254","outputId":"1e12238f-8506-4013-890f-122406da6dda","trusted":true},"cell_type":"code","source":"X_train_normalized_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_normalized_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train_normalized_df size is\", len(X_train_normalized_df))\nprint(\"----------------------------------\")\nprint(\"X_test_normalized_df size is\", len(X_test_normalized_df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# feature importances"},{"metadata":{"id":"X2l7nzfbaEig","outputId":"2dc5099a-9d08-4cdf-83b8-d2edf469fd80","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 500, max_depth=5)\nrf.fit(X_train_normalized_df, y_train)\nrf_y_pred = rf.predict(X_test_normalized_df)\n\npd.Series(rf.feature_importances_, index = X_train_normalized_df.columns).nlargest(15).plot(kind = 'pie',\n                                                                               figsize = (8, 8),\n                                                                              title = 'Feature importance from RandomForest', colormap='magma')","execution_count":null,"outputs":[]},{"metadata":{"id":"QkxxQo5l5DSR"},"cell_type":"markdown","source":"Here, our display test scores method"},{"metadata":{"id":"hMeILAj3T2xL","trusted":true},"cell_type":"code","source":"# display test scores and return result string and indexes of false samples\ndef display_test_scores(test, pred):\n    str_out = \"\\n\"\n    str_out += (\"#####  TEST SCORES  #####\\n--------------------\")\n    str_out += (\"\\n\")\n\n    #print accuracy\n    accuracy = accuracy_score(test, pred)\n    str_out += (\"ACCURACY: {:.4f}\\n\".format(accuracy))\n    str_out += (\"\\n\")\n\n    #print AUC score\n    auc = roc_auc_score(test, pred)\n    str_out += (\"AUC: {:.4f}\\n\".format(auc))\n    str_out += (\"\\n\")\n\n    #print confusion matrix\n    str_out += (\"CONFUSION MATRIX:\\n--------------------\\n\")\n    conf_mat = confusion_matrix(test, pred)\n    str_out += (\"{}\".format(conf_mat))\n    str_out += (\"\\n\")\n    str_out += (\"\\n--------------------\\n\")\n\n    #print classification report\n    str_out += (\"{}\".format(classification_report(test, pred)))\n    \n    false_indexes = np.where(test != pred)\n    return str_out, false_indexes","execution_count":null,"outputs":[]},{"metadata":{"id":"g16yoE_KT43a"},"cell_type":"markdown","source":"# **Classifier #1: Decision Tree**"},{"metadata":{"id":"L2y9ftg4T21v","outputId":"db537df0-d220-4421-fa34-df901d3cbf18","trusted":true},"cell_type":"code","source":"# decision tree with \"gini\"\ndt_1 = DecisionTreeClassifier(random_state = 0, criterion=\"gini\")\n\n# parameters \nparameters = {\n                \"splitter\": [\"best\",\"random\"],\n                \"class_weight\": [None, \"balanced\"],\n                \"max_depth\": [9, 11, 13, 15, 17, None]\n                }\n\nstart_time=time.time()##\n\n# grid search for parameters\ngrid_1 = GridSearchCV(estimator=dt_1, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_1.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_1.best_params_, grid_1.best_score_))\n\n################################################\n# detailed dataframe of gridsearch\n\n#detailed_grid_results = pd.DataFrame(grid.cv_results_)\n#detailed_grid_results\n\n\n################################################\n\n# prediction results\ny_pred = grid_1.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test cv (DT-gini): \",end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"id":"120Ky4miagDf"},"cell_type":"markdown","source":"*### hold_out DT1*"},{"metadata":{"id":"g08CNMDX6mK5","outputId":"9b26aa7e-33da-48f9-8696-43aec29bd5b2","trusted":true},"cell_type":"code","source":"start_time=time.time()##\n\n# grid search for parameters for hold_out\ngrid_1_h = GridSearchCV(estimator=dt_1, param_grid=parameters, cv=hold_out, n_jobs=-1)\ngrid_1_h.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_1_h.best_params_, grid_1_h.best_score_))\n\n#########################################\n\n# prediction results\ny_pred = grid_1_h.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test hold_out (DT-gini): \",end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"qkYZ2sza7RS7"},"cell_type":"markdown","source":"# **Classifier #2: Decision Tree**"},{"metadata":{"id":"5v8jgjvVT2sW","outputId":"c71f3362-989d-4dd1-bb76-dcc2b990ace6","trusted":true},"cell_type":"code","source":"# decision tree with \"entropy\" gain_ratio\ndt_2 = DecisionTreeClassifier(random_state = 0, criterion=\"entropy\")\n\n# parameters \nparameters = {\n                \"splitter\": [\"best\",\"random\"],\n                \"class_weight\": [None, \"balanced\"],\n                \"max_depth\": [11, 13, 15, 17, 19, 21, None]\n                }\n\nstart_time=time.time()##\n\n# grid search for parameters\ngrid_2 = GridSearchCV(estimator=dt_2, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_2.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_2.best_params_, grid_2.best_score_))\n\n########################################\n\n# prediction results\ny_pred = grid_2.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test cv (DT-gain ratio): \",end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"id":"SsvfafEQayFl"},"cell_type":"markdown","source":"*### hold_out DT2*"},{"metadata":{"id":"N7_dwWddaxoR","outputId":"0eb66aa2-3277-4ca3-aea8-ab71be63a0c5","trusted":true},"cell_type":"code","source":"start_time=time.time()##\n\n# grid search for parameters for hold_out\ngrid_2_h = GridSearchCV(estimator=dt_2, param_grid=parameters, cv=hold_out, n_jobs=-1)\ngrid_2_h.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_2_h.best_params_, grid_2_h.best_score_))\n\n#####################################\n\n# prediction results\ny_pred = grid_2_h.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test hold_out (DT-gain ratio): \",end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"id":"HMBDo2K-87Nh"},"cell_type":"markdown","source":"# **Classifier #3: Naive Bayes**"},{"metadata":{"id":"odsKfaFB6skc","outputId":"49a70b5f-d7d0-4b99-eaf4-c873755be241","trusted":true},"cell_type":"code","source":"# Naive-Bayes with different approaches\nnb_list = [GaussianNB(), MultinomialNB(), ComplementNB()]\n\nfor nb in nb_list:\n    print(\"*********\", str(nb), \"**********\")\n    # parameters \n    parameters = {}\n\n    start_time=time.time()##\n    # grid search for parameters\n    grid_3 = GridSearchCV(estimator=nb, param_grid=parameters, cv=cv, n_jobs=-1)\n    grid_3.fit(X_train_normalized_df, y_train)\n\n    # print best scores\n    print(\"The best parameters are %s with a score of %0.4f\\n\"\n          % (grid_3.best_params_, grid_3.best_score_))\n\n    # prediction results\n    y_ord_pred = grid_3.predict(X_test_normalized_df)\n    \n    end_time=time.time()##\n    print(\"\\nRun time for train&test cv{}: \".format(str(nb)), end_time-start_time)\n\n    # print accuracy metrics\n    results, false = display_test_scores(y_test, y_pred)\n    print(\"\\n>>>>>>>>><<<<<<<<<<>>>>>>>>>>><<<<<<<<<<<<<>>>>>>>>><<<<<<<<\\n\")\n    print(results)\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"ml1oISsca_2F"},"cell_type":"markdown","source":"*### hold_out NB*"},{"metadata":{"id":"BeXFyo-ka_nS","outputId":"10a3dea0-0e9a-4232-af23-e173fa0d15a2","trusted":true},"cell_type":"code","source":"for nb in nb_list:\n    print(\"*********\", str(nb), \"**********\")\n    # parameters \n    parameters = {}\n\n    start_time=time.time()##\n    # grid search for parameters\n    grid_3_h = GridSearchCV(estimator=nb, param_grid=parameters, cv=hold_out, n_jobs=-1)\n    grid_3_h.fit(X_train_normalized_df, y_train)\n\n    # print best scores\n    print(\"The best parameters are %s with a score of %0.4f\\n\"\n          % (grid_3_h.best_params_, grid_3_h.best_score_))\n\n    # prediction results\n    y_ord_pred = grid_3_h.predict(X_test_normalized_df)\n    \n    end_time=time.time()##\n    print(\"\\nRun time for train&test hold_out{}: \".format(str(nb)), end_time-start_time)\n\n    # print accuracy metrics\n    results, false = display_test_scores(y_test, y_pred)\n    print(\"\\n>>>>>>>>><<<<<<<<<<>>>>>>>>>>><<<<<<<<<<<<<>>>>>>>>><<<<<<<<\\n\")\n    print(results)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier #4: ANN - 1 layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NN with 1 layer\nann_1 = MLPClassifier(tol=1e-5, random_state=0, solver='adam', activation='tanh', max_iter=1000, batch_size=256)\n\nparameters = {\n                'hidden_layer_sizes': [(10,),(50,),(100,)],\n                'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n            }\n\n\nstart_time=time.time()##\n# grid search for parameters\ngrid_4 = GridSearchCV(estimator=ann_1, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_4.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid_4.best_params_, grid_4.best_score_))\n\n###################################\n\n# prediction results\ny_pred = grid_4.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test cv NN-1 layer: \", end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*### hold_out NN-1*"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time=time.time()##\n\n# grid search for parameters for hold_out\ngrid_4_h = GridSearchCV(estimator=ann_1, param_grid=parameters, cv=hold_out, n_jobs=-1)\ngrid_4_h.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_4_h.best_params_, grid_4_h.best_score_))\n\n####################################\n\n# prediction results\ny_pred = grid_4_h.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test hold_out NN-1 layer: \", end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier #5: ANN - 2 layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NN with 2 layers\nnn_2 = MLPClassifier(tol=1e-5, random_state=0, solver='adam', activation='tanh', max_iter=1000, batch_size=256)\n\n\nparameters = {\n                'hidden_layer_sizes': [(10, 10),(50, 50),(100, 100)],\n                'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n            }\n\nstart_time=time.time()##\n# grid search for parameters\ngrid_5 = GridSearchCV(estimator=nn_2, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_5.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid_5.best_params_, grid_5.best_score_))\n\n############################\n\n# prediction results\ny_pred = grid_5.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test cv NN-2 layer: \", end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*### hold_out NN-2*"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time=time.time()##\n\n# grid search for parameters for hold_out\ngrid_5_h = GridSearchCV(estimator=nn_2, param_grid=parameters, cv=hold_out, n_jobs=-1)\ngrid_5_h.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_5_h.best_params_, grid_5_h.best_score_))\n\n####################################\n\n# prediction results\ny_pred = grid_5_h.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test hold_out NN-2 layer: \", end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"FxXs3LzU82HS"},"cell_type":"markdown","source":"# **Classifier #6: SVM**"},{"metadata":{"id":"C2ERnJly7wWu","trusted":true},"cell_type":"code","source":"# SVM classifier\nsvm = SVC(tol=1e-5)\n\n# parameters \nparameters = {\n                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n                'max_iter': [100, 300, 800, 1000, 1200],\n                'class_weight': [None, 'balanced']\n            }\n\nstart_time=time.time()##\n\n# grid search for parameters\ngrid_6 = GridSearchCV(estimator=svm, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_6.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid_6.best_params_, grid_6.best_score_))\n\n# prediction results\ny_pred = grid_6.predict(X_test_normalized_df)\n\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test cv SVM : \", end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"id":"kslsIPxebocL"},"cell_type":"markdown","source":"*### hold_out SVM*"},{"metadata":{"id":"Q0WwuT0J9MhL","trusted":true},"cell_type":"code","source":"start_time=time.time()##\n\n# grid search for parameters\ngrid_6_h = GridSearchCV(estimator=svm, param_grid=parameters, cv=hold_out, n_jobs=-1)\ngrid_6_h.fit(X_train_normalized_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid_6_h.best_params_, grid_6_h.best_score_))\n\n# prediction results\ny_pred = grid_6_h.predict(X_test_normalized_df)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test hold_out SVM : \", end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier #7: Bagging"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time=time.time()##\n\n#generate subsamples by indices\nindexes=X_train.index.values\nrep = np.array([np.random.choice(indexes, len(indexes), replace = True) for _ in range(6)])\n\n#rep_x_train has 6 dfs \nrep_x_train=[df.iloc[arr,:-1] for arr in rep]\nrep_y_train=[df.iloc[arr,-1] for arr in rep]\n\n#dfs are created by bootstrapping\nrep_x_train[0].duplicated()\nrep_y_train[0].duplicated()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"preds=[]\n\n#dt_1 --> cv \nmodel_1 = grid_1.best_estimator_\nmodel_1.fit(rep_x_train[0], rep_y_train[0])\n\npred_1=model_1.predict(X_test)\npreds.append(pred_1)\n\n#####################################\n\n#dt_2 --> cv \nmodel_2 = grid_2.best_estimator_\nmodel_2.fit(rep_x_train[1], rep_y_train[1])\n\npred_2=model_2.predict(X_test)\npreds.append(pred_2)\n\n#####################################\n\n#nb --> cv\nmodel_3 = grid_3.best_estimator_\nmodel_3.fit(rep_x_train[2], rep_y_train[2])\n\npred_3=model_3.predict(X_test)\npreds.append(pred_3)\n\n###################################\n\n#ann_1 --> cv\nmodel_4 = grid_4.best_estimator_\nmodel_4.fit(rep_x_train[3], rep_y_train[3])\n\npred_4=model_4.predict(X_test)\npreds.append(pred_4)\n\n###################################\n\n#ann_2 --> cv\nmodel_5 = grid_5.best_estimator_\nmodel_5.fit(rep_x_train[4], rep_y_train[4])\n\npred_5=model_5.predict(X_test)\npreds.append(pred_5)\n\n\n###################################\n\n#svm --> hold\nmodel_6 = grid_6_h.best_estimator_\nmodel_6.fit(rep_x_train[5], rep_y_train[5])\n\npred_6=model_6.predict(X_test)\npreds.append(pred_6)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr_preds=np.array(preds)\narr_preds_mean=arr_preds.mean(axis=0)\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test bagging: \", end_time-start_time)\n\n#see it has same len with X_test\nprint(len(arr_preds_mean))\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, arr_preds_mean.round())\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier #8: Boosting"},{"metadata":{},"cell_type":"markdown","source":"- https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/\n- https://www.python-course.eu/Boosting.php#Boosting-Pseudocode"},{"metadata":{"trusted":true},"cell_type":"code","source":"def boosting_step(grid, initial_weight, X_train, y_train):\n    \n    # Initialize the weights of each sample with wi = 1/N and \n    #create a dataframe in which the evaluation is computed\n    df_eval = pd.DataFrame(y_train, columns=[\"target\"])\n    df_eval['weights'] = initial_weight \n\n\n    model = grid.best_estimator_\n    model.fit(X_train, y_train, sample_weight=np.array(df_eval['weights']))\n    pred=model.predict(X_train)\n    score = model.score(X_train,y_train)\n\n    #add values to the df_eval\n    df_eval['predictions'] = pred\n    df_eval['evaluation'] = np.where(df_eval['predictions'] == df_eval['target'], 1, 0)\n    df_eval['misclassified'] = np.where(df_eval['predictions'] != df_eval['target'], 1, 0)\n\n    #cal the misclassification rate and accuracy\n    accuracy = sum(df_eval['evaluation']) / len(df_eval['evaluation'])\n    misclassification = sum(df_eval['misclassified']) / len(df_eval['misclassified'])\n\n\n    #cal the error\n    err = np.sum(df_eval['weights'] * df_eval['misclassified']) / np.sum(df_eval['weights'])\n\n\n    #cal the alpha values\n    alpha = np.log((1-err) / err)\n \n\n    # Update the weights wi --> These updated weights are used in the sample_weight parameter\n    # for the training of the next decision stump. \n    df_eval['weights'] *= np.exp(alpha * df_eval['misclassified'])\n\n    prediction = alpha * df_eval[\"predictions\"]\n\n    return prediction, df_eval['weights']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set the initial weights w = 1/N\nstart_time=time.time()##\n\npred_1, w_1=boosting_step(grid_1, 1/len(y_train), X_train, y_train)\n\npred_2, w_2=boosting_step(grid_2, w_1, X_train, y_train)\n\npred_3, w_3=boosting_step(grid_3, w_2, X_train, y_train)\n\n#alpha_4, w_4=boosting_step(grid_4, w_3, X_train, y_train)\n\n#alpha_5, w_5=boosting_step(grid_5, w_4, X_train, y_train)\n\npred_6, w_6=boosting_step(grid_6_h, w_3, X_train, y_train)\n\npred_final=(pred_1+pred_2+pred_3+pred_6) / 4\n\npred_final=np.where(pred_final >=0.5, 1, 0)\n\n\nend_time=time.time()##\nprint(\"\\nRun time for train&test boosting: \", end_time-start_time)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_train, pred_final)\nprint(results)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}