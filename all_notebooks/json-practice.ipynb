{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example 1: Chipotle Locations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\ndf=pd.read_json('/kaggle/input/chipotle-locations/us-states.json')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reads json into a dataframe, but based on how the json is structured, only two columns are created and much information is embedded deep in the dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This column is useless--> let's look at the features column that contains the embedded data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['features'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a list of dictionaries (dictionaries are like lists, but contain specified keys/headers). This is the data we actually want.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's look at the first list item and see how the data is stored.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['features'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['features'][0].keys()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's say the information we want is the id (state abbreviation), state name, geometry type, and the number of coordinate pairs provided in that given state.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['features'][0]['geometry']['coordinates'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frame=pd.DataFrame()\nfor i in range(len(df['features'])):\n    ID=df['features'][i]['id']\n    state=df['features'][i]['properties']['name']\n    shape=len(df['features'][i]['geometry']['coordinates'])\n    geo=df['features'][i]['geometry']['type']\n    shape=len(df['features'][i]['geometry']['coordinates'])\n    if shape>1:\n        num=0\n        for j in range(shape):\n            num+=len(df['features'][i]['geometry']['coordinates'][j][0])\n    else:\n        num=len(df['features'][i]['geometry']['coordinates'][0])\n    frame=frame.append({'id':ID,'state':state,'geometry':geo,'shape':shape,'coordinate pairs':num},ignore_index=True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example 2: German Recipes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ger=pd.read_json('/kaggle/input/german-recipes-dataset/recipes.json')\nger.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This came out much cleaner than the previous file- the JSON file is set up in such a way that the keys directly lead to the information (there are not multiple levels of organization in which we have to dig for the data we want).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ger['Ingredients'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only minor thing is that the ingredients are stored as a list. Let's add to this dataset by adding a new column for the number of ingredients required.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ger['num']=[len(ger['Ingredients'][i]) for i in range(len(ger))]\nger.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Idea: Let's find a Sauerkraut recipe with the least amount of ingredients.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sk=ger[ger['Name'].str.contains(\"Sauerkraut\")]\nsk.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sk)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"66 sauerkraut recipes in this dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Min=sk[sk['num']==sk['num'].min()]\nMin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Min)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Minumum number of ingredients is 12, 29 sauerkraut recipes have 12 ingredients. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now which one of these has the least amount of instructions?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#compute number of letters as length of instructions\nlen(Min.reset_index()['Instructions'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None\nMin['length']=[len(Min['Instructions'][index]) for index in Min.reset_index()['index']]\nMin","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Actually it looks like these are all repeats. Going to have to revert back and get rid of all the duplicates. This will significantly reduce the number of entries in the dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fix=ger.drop_duplicates(subset=['Instructions'])\nlen(fix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sk2=fix[fix['Name'].str.contains(\"Sauerkraut\")]\nsk2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only two unique sauerkraut recipes here. Let's try to analytically determine which has more instructions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sk2['letters']=[len(sk2['Instructions'][index]) for index in sk2.reset_index()['index']]\nsk2['words']=[len(sk2['Instructions'][index].split()) for index in sk2.reset_index()['index']]\nsk2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the top one is the better recipe given our priorities.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}