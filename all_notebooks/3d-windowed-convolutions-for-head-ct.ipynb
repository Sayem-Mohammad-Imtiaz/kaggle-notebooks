{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom pydicom import read_file as read_dicom\nimport SimpleITK as sitk\nbase_dir = os.path.join('..', 'input', 'qureai-headct')\nreads_dir = os.path.join('..', 'input', 'headctreads')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Windowed Convolutions\nTaken from layers in lungstage_lib"},{"metadata":{"trusted":true},"cell_type":"code","source":"from warnings import warn\nfrom keras import backend as K\nfrom keras.layers import Activation, Conv3D, Conv2D, multiply\nfrom keras.layers import Convolution2D, Convolution3D\nfrom keras.layers import Input\nfrom keras.models import Model\n\ndef make_window_weights(window_list, is3d=False, dim_order=None, verbose=False):\n    # type: (List[Tuple[str, Tuple[float, float]]], bool) -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]\n    \"\"\"\n    A function to convert a list of windows to a set of tensorflow/keras weights\n    :param window_list:\n    :param is3d:\n    :return:\n    Examples\n    --------\n    >>> (w1, w2), (w3, w4) = make_window_weights(_ct_windows, dim_order = 'tf')\n    >>> [w1.shape, w2.shape, w3.shape, w4.shape]\n    [(1, 1, 1, 6), (6,), (1, 1, 6, 6), (6,)]\n    >>> (w1, w2), (w3, w4) = make_window_weights(_ct_windows, is3d = True, dim_order = 'tf')\n    >>> [w1.shape, w2.shape, w3.shape, w4.shape]\n    [(1, 1, 1, 1, 6), (6,), (1, 1, 1, 6, 6), (6,)]\n    >>> (w1, w2), (w3, w4) = make_window_weights(_ct_windows, dim_order = 'th')\n    >>> [w1.shape, w2.shape, w3.shape, w4.shape]\n    [(6, 1, 1, 1), (6,), (6, 6, 1, 1), (6,)]\n    >>> (w1, w2), (w3, w4) = make_window_weights(_ct_windows, is3d = True, dim_order = 'th')\n    >>> [w1.shape, w2.shape, w3.shape, w4.shape]\n    [(6, 1, 1, 1, 1), (6,), (6, 6, 1, 1, 1), (6,)]\n    \"\"\"\n    if is3d:\n        base_size = (1, 1, 1)\n    else:\n        base_size = (1, 1)\n\n    if dim_order is None:\n        dim_order = K.image_dim_ordering()\n    if dim_order == 'tf':\n        pass\n    elif dim_order == 'th':\n        pass\n    else:\n        raise ValueError('Dim ordering must be either tf (tensorflow) or th (theano): {}'.format(dim_order))\n\n    neg_wind_slopes = np.zeros(base_size + (1, len(window_list)), dtype=np.float32)\n    pos_wind_slopes = np.zeros(base_size + (len(window_list), len(window_list)), dtype=np.float32)\n    neg_wind_offsets = np.zeros((len(window_list),), dtype=np.float32)\n    pos_wind_offsets = np.zeros((len(window_list),), dtype=np.float32)\n    \"\"\"\n    x = [-1024, 1024]\n    layer_output = W*x + b\n    neg_layer: W = -1, b = -max_val\n    neg_layer output = -1*x - max_val -> max_val - x\n    pos_layer: W = -1/w, b =\n    pos_layer output = -1/w * (max_val - x) - 1/w (max_val+min_val)\n    x/w - (max_val + k)/w\n    \"\"\"\n    for i, (name, (center, width)) in enumerate(window_list):\n        n_width = width / 2.0\n        min_val = center - n_width\n        max_val = center + n_width\n\n        if is3d:\n            neg_wind_slopes[:, :, :, :, i] = -1 / width\n        else:\n            neg_wind_slopes[:, :, :, i] = -1 / width\n        neg_wind_offsets[i] = max_val / width\n\n        if is3d:\n            pos_wind_slopes[:, :, :, i, i] = -1\n        else:\n            pos_wind_slopes[:, :, i, i] = -1\n        pos_wind_offsets[i] = -(min_val - max_val) / width\n\n        if verbose: print(name, (min_val, '-', max_val), width)\n\n    if dim_order == 'tf':\n        pass\n    elif dim_order == 'th':\n        roll_func = lambda ty: np.rollaxis(np.rollaxis(ty, -2, 0), -1, 0)\n        neg_wind_slopes = roll_func(neg_wind_slopes)\n        pos_wind_slopes = roll_func(pos_wind_slopes)\n        pass\n\n    return ((neg_wind_slopes, neg_wind_offsets), (pos_wind_slopes, pos_wind_offsets))\n\n\ndef wind_net_2d(in_img, w_list, dim_order=None, suffix=''):\n    # type: (np.ndarray, List[Tuple[str, Tuple[float, float]]]) -> keras.models.Model\n    \"\"\"\n    A function for creating a 2D network for applying windows to an image\n    :param in_img:\n    :param w_list:\n    :return:\n    Examples\n    ------\n    >>> t_model = wind_net_2d(np.zeros((2, 3)), _ct_windows, dim_order = 'tf')\n    >>> [(ilay.name, ilay.output_shape) for ilay in t_model.layers]\n    [('RawImageInput', (None, 2, 3, 1)), ('Negative-Windows', (None, 2, 3, 6)), ('Positive-Windows', (None, 2, 3, 6))]\n    >>> fit_img = (t_model.predict(np.linspace(-1000, 1000, num = 6).reshape((1,2,3,1)))[0]*100).astype(int)\n    >>> [(name, sorted(np.unique(fit_img[:,:,i]))) for i, (name, _) in enumerate(_ct_windows)]\n    [('Soft Tissue', [0, 90, 100]), ('Lung', [16, 50, 83, 100]), ('Bone', [0, 6, 33, 60, 86]), ('Liver', [0, 100]), ('Brain', [0, 100]), ('LungNodes', [0, 100])]\n    >>> h_model = wind_net_2d(np.zeros((2, 3)), _ct_windows, dim_order = 'th')\n    >>> [(ilay.name, ilay.output_shape) for ilay in h_model.layers]\n    [('RawImageInput', (None, 1, 2, 3)), ('Negative-Windows', (None, 6, 2, 3)), ('Positive-Windows', (None, 6, 2, 3))]\n    >>> hfit_img = (h_model.predict(np.linspace(-1000, 1000, num = 6).reshape((1, 1, 2, 3)))[0]*100).astype(int)\n    >>> [(name, sorted(np.unique(hfit_img[i, :,:]))) for i, (name, _) in enumerate(_ct_windows)]\n    [('Soft Tissue', [0, 90, 100]), ('Lung', [16, 50, 83, 100]), ('Bone', [0, 6, 33, 60, 86]), ('Liver', [0, 100]), ('Brain', [0, 100]), ('LungNodes', [0, 100])]\n    \"\"\"\n    if dim_order is None:\n        dim_order = K.image_dim_ordering()\n    if dim_order == 'th':\n        in_shape = (1,) + in_img.shape[:2]\n    elif dim_order == 'tf':\n        in_shape = in_img.shape[:2] + (1,)\n    else:\n        raise ValueError('Dim ordering must be either tf (tensorflow) or th (theano): {}'.format(dim_order))\n    K.set_image_dim_ordering(dim_order)\n    bonus_args = {}\n    if KERAS_2:\n        bonus_args['data_format'] = K.image_data_format()\n    return wind_net_2d_custom(in_shape=in_shape,\n                              w_list=w_list,\n                              suffix=suffix, **bonus_args)\n\n\ndef wind_net_2d_custom(in_shape, w_list, suffix, **bonus_args):\n    in_node = Input(shape=in_shape, name='RawImageInput{}'.format(suffix))\n    neg_weights, pos_weights = make_window_weights(w_list, is3d=False,\n                                                   dim_order='tf'  # as of keras 2 this is always tf\n                                                   )\n\n    neg_node = Convolution2D(filters=len(w_list), kernel_size=(1, 1),\n                             name='Negative-Windows{}'.format(suffix), activation='relu', use_bias=True,\n                             weights=neg_weights, **bonus_args)(in_node)\n    pos_node = Convolution2D(filters=len(w_list), kernel_size=(1, 1),\n                             name='Positive-Windows{}'.format(suffix), activation='relu', use_bias=True,\n                             weights=pos_weights, **bonus_args)(neg_node)\n    return Model(inputs=[in_node], outputs=[pos_node])\n\n\ndef wind_net_3d(in_img, w_list, dim_order=None, suffix=''):\n    # type: (np.ndarray, List[Tuple[str, Tuple[float, float]]]) -> keras.models.Model\n    \"\"\"\n    Make a 3D windowing network using 2 1x1x1 convolutional layers with the appropriate weights\n    :param in_img:\n    :param w_list:\n    :return: a simple two layer network\n    Examples\n    ------\n    >>> t_model = wind_net_3d(np.zeros((2, 3, 4)), _ct_windows, dim_order = 'tf')\n    >>> [(ilay.name, ilay.output_shape) for ilay in t_model.layers]\n    [('RawImageInput', (None, 2, 3, 4, 1)), ('Negative-Windows', (None, 2, 3, 4, 6)), ('Positive-Windows', (None, 2, 3, 4, 6))]\n    >>> fit_img = (t_model.predict(np.linspace(-1000, 1000, num = 24).reshape((1,2,3,4,1)))[0]*100).astype(int)\n    >>> [(name, fit_img[:,:,:,i].min(),fit_img[:,:,:,i].max()) for i, (name, _) in enumerate(_ct_windows)]\n    [('Soft Tissue', 0, 100), ('Lung', 16, 100), ('Bone', 0, 86), ('Liver', 0, 100), ('Brain', 0, 100), ('LungNodes', 0, 100)]\n    >>> th_model = wind_net_3d(np.zeros((2, 3, 4)), _ct_windows, dim_order = 'th')\n    >>> [(ilay.name, ilay.output_shape) for ilay in th_model.layers]\n    [('RawImageInput', (None, 1, 2, 3, 4)), ('Negative-Windows', (None, 6, 2, 3, 4)), ('Positive-Windows', (None, 6, 2, 3, 4))]\n    \"\"\"\n    if in_img is None:\n        in_shape = (None, None, None)\n    else:\n        in_shape = in_img.shape[:3]\n    if dim_order is None:\n        dim_order = K.image_dim_ordering()\n    if dim_order == 'th':\n        in_shape = (1,) + in_shape\n    elif dim_order == 'tf':\n        in_shape = in_shape + (1,)\n    else:\n        raise ValueError('Dim ordering must be either tf (tensorflow) or th (theano): {}'.format(dim_order))\n    return wind_net_3d_custom(in_shape, w_list=w_list, suffix=suffix)\n\n\ndef wind_net_3d_custom(in_shape, w_list, suffix):\n    \"\"\"\n    For custom sized windows\n    :param in_shape:\n    :param w_list:\n    :return:\n    \"\"\"\n    in_node = Input(shape=in_shape, name='RawImageInput{}'.format(suffix))\n    neg_weights, pos_weights = make_window_weights(w_list, is3d=True,\n                                                   dim_order='tf'  # as of keras 2 this is always tf\n                                                   )\n\n    neg_node = Convolution3D(filters=len(w_list),\n                             kernel_size=(1, 1, 1),\n                             name='Negative-Windows{}'.format(suffix), activation='relu', use_bias=True,\n                             weights=neg_weights)(in_node)\n    pos_node = Convolution3D(filters=len(w_list),\n                             kernel_size=(1, 1, 1),\n                             name='Positive-Windows{}'.format(suffix), activation='relu', use_bias=True,\n                             weights=pos_weights)(neg_node)\n    return Model(inputs=[in_node], outputs=[pos_node])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"all_dicom_paths = glob(os.path.join(base_dir, '*', '*', '*', '*', '*'))\nprint(len(all_dicom_paths), 'dicom files')\ndicom_df = pd.DataFrame(dict(path = all_dicom_paths))\ndicom_df['SliceNumber'] = dicom_df['path'].map(lambda x: int(os.path.splitext(x.split('/')[-1])[0][2:]))\ndicom_df['SeriesName'] = dicom_df['path'].map(lambda x: x.split('/')[-2])\ndicom_df['StudyID'] = dicom_df['path'].map(lambda x: x.split('/')[-3])\ndicom_df['PatientID'] = dicom_df['path'].map(lambda x: x.split('/')[-4].split(' ')[0])\ndicom_df['PatSeries'] = dicom_df.apply(lambda x: '{PatientID}-{SeriesName}'.format(**x), 1)\ndicom_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"small_scans = dicom_df.groupby('PatSeries').count().reset_index().query('SliceNumber<240')\ndicom_df = dicom_df[dicom_df['PatSeries'].isin(small_scans['PatSeries'])]\nprint('Removed big scans', dicom_df.shape[0], 'remaining images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_overview_df = pd.read_csv(os.path.join(reads_dir, 'reads.csv'))\nread_overview_df['PatientID'] = read_overview_df['name'].map(lambda x: x.replace('-', '')) \nread_overview_df.sample(2).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ff117050589356170973c7e835330a2cda4c15a"},"cell_type":"code","source":"from collections import OrderedDict\nnew_reads = []\nfor _, c_row in read_overview_df.iterrows():\n    base_dict = OrderedDict(PatientID = c_row['PatientID'], Category = c_row['Category'])\n    for reader in ['R1', 'R2', 'R3']:\n        c_dict = base_dict.copy()\n        c_dict['Reader'] = reader\n        for k,v in c_row.items():\n            if (reader+':') in k:\n                c_dict[k.split(':')[-1]] = v\n        new_reads += [c_dict]\nnew_reads_df = pd.DataFrame(new_reads)\nnew_reads_df.to_csv('formatted_reads.csv')\nnew_reads_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_reads_df = new_reads_df.groupby(['PatientID', 'Category']).agg('mean').reset_index()\nread_dicom_df = pd.merge(avg_reads_df, dicom_df, on = 'PatientID')\nread_dicom_df['Bleed'] = read_dicom_df.apply(lambda x: np.clip(x['BleedLocation-Left']+x['BleedLocation-Right']+x['ChronicBleed'], 0, 1), 1)\nprint(read_dicom_df.shape[0], 'total weakly-labeled slices')\nread_dicom_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Organize by image instead of slices"},{"metadata":{"trusted":true},"cell_type":"code","source":"read_dicom_df['directory'] = read_dicom_df['path'].map(lambda x: os.path.split(x)[0])\ndicom_dir_df = read_dicom_df.groupby(['directory']).agg('first').reset_index().drop(['path'], 1)\nprint(dicom_dir_df.shape[0])\ndicom_dir_df.sample(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_dicom_folder(in_dir):\n    series_reader = sitk.ImageSeriesReader()\n    # series_reader.LoadPrivateTagsOn()\n    dicom_names = series_reader.GetGDCMSeriesFileNames(in_dir)\n    series_reader.SetFileNames(dicom_names)\n    out_img = series_reader.Execute()\n    return sitk.GetArrayFromImage(out_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Show the middle slice"},{"metadata":{"trusted":true,"_uuid":"3421e85a831427d3688e31b6a48c9bd78952b328"},"cell_type":"code","source":"fig, m_axs = plt.subplots(3, 3, figsize = (20, 20))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), dicom_dir_df.groupby(['Bleed', 'Fracture']).apply(lambda x: x.sample(1)).reset_index(drop=True).iterrows()):\n    try:\n        c_img = read_dicom_folder(c_row['directory'])\n        c_slice = np.mean(c_img, 0)\n        c_ax.imshow(c_slice, cmap = 'bone')\n        c_ax.set_title('Bleed: {Bleed:2.2f}, Fracture: {Fracture:2.2f}\\n{SeriesName}'.format(**c_row))\n    except Exception as e:\n        c_ax.set_title('{}'.format(str(e)[:40]))\n        print(e)\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fc33fa62086453ce818c33d1637e11a4cc35382"},"cell_type":"markdown","source":"# Classify bleed status from image\nWe can make a simple model here to identify which series type an image came from"},{"metadata":{"trusted":true,"_uuid":"c9241f8d1d775da185a755cfa5dde109d66e614d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nvalid_df = dicom_dir_df[['PatientID', 'Bleed']].drop_duplicates()\nprint('Patients', valid_df.shape[0])\ntrain_ids, test_ids = train_test_split(valid_df[['PatientID']], \n                                       test_size = 0.25, \n                                       stratify = valid_df['Bleed'].map(lambda x: x>0))\n\ntrain_unbalanced_df = dicom_dir_df[dicom_dir_df['PatientID'].isin(train_ids['PatientID'])]\ntest_df = dicom_dir_df[dicom_dir_df['PatientID'].isin(test_ids['PatientID'])]\nprint(train_unbalanced_df.shape[0], 'training images', test_df.shape[0], 'testing images')\ntrain_unbalanced_df['Bleed'].hist(figsize = (10, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_unbalanced_df.groupby(train_unbalanced_df['Bleed'].map(lambda x: round(x*3)/3)).apply(lambda x: x.sample(200, replace = True)\n                                                      ).reset_index(drop = True)\nprint('New Data Size:', train_df.shape[0], 'Old Size:', train_unbalanced_df.shape[0])\ntrain_df['Bleed'].hist(figsize = (20, 5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a771c6664f6de7bbb205787f7814b5810b045cd4"},"cell_type":"markdown","source":"# Make Generators to Load Volumes"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ct_gen(in_df):\n    while True:\n        c_row = in_df.sample(1).iloc[0]\n        c_image = read_dicom_folder(c_row['directory'])\n        c_tensor = np.expand_dims(np.expand_dims(c_image, 0), -1)\n        yield {'RawImageInput': c_tensor}, {'Bleed': np.reshape([c_row['Bleed']], (1, 1)), 'Fracture': np.reshape([c_row['Fracture']], (1, 1))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = ct_gen(train_df)\nx_vars, y_vars = next(train_gen)\nfor k,v in x_vars.items():\n    print(k, v.shape)\nfor k,v in y_vars.items():\n    print(k, v.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct_windows = [\n    ('Soft Tissue', (40, 400)),\n    ('Lung', (-600, 1200)),\n    ('Bone', (450, 1500)),\n    ('Liver', (90, 190)),\n    ('Brain', (40, 80)),\n    ('LungNodes', (-800, 400))\n]\nt_model = wind_net_3d(None, ct_windows, dim_order = 'tf')\nt_model.trainable=False\nt_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wind_tensor = t_model.predict(x_vars)\ntest_tensor = x_vars['RawImageInput']\nprint(wind_tensor.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(3, wind_tensor.shape[-1]+1, figsize = (25, 8))\nfor n_axs, c_slice in zip(m_axs, np.linspace(0, wind_tensor.shape[1], m_axs.shape[0]+2)[1:-1].astype(int)):\n    n_axs[0].imshow(test_tensor[0, c_slice, :, :, 0], cmap='bone')\n    n_axs[0].set_title('Raw Image')\n    for i, c_ax in enumerate(n_axs[1:]):\n        c_ax.imshow(wind_tensor[0, c_slice, :, :, i], cmap='bone')\n        c_ax.axis('off')\n        c_ax.set_title('Wind:{}'.format(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers, models\nin_ct_scan = layers.Input((None, 512, 512, 1), name='RawImageInput')\nclean_scan = t_model(in_ct_scan)\nx = clean_scan\nfor i in range(3):\n    x = layers.Conv3D(8*2**i, (3, 3, 3), strides=(1, 2, 2), activation='relu', padding='same')(x)\nimage_features = layers.GlobalAveragePooling3D()(x)\nimage_features = layers.Dropout(0.5)(image_features)\ndense_features = layers.Dense(64, activation='relu')(image_features)\nbleed_out = layers.Dense(1, activation='sigmoid', name='Bleed')(dense_features)\nfracture_out = layers.Dense(1, activation='sigmoid', name='Fracture')(dense_features)\nbf_model = models.Model(inputs=[in_ct_scan], outputs=[bleed_out, fracture_out], name='BleedFractureModel')\nbf_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy'])\nbf_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"176d48f680ce43f525f1243e7d6332727dcfd726"},"cell_type":"code","source":"fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y), c_ax in zip(train_gen, m_axs.flatten()):\n    c_ax.imshow(c_x['RawImageInput'][0, 10, :, :, 0], cmap = 'bone')\n    pred_y = bf_model.predict(c_x)\n    c_ax.set_title(f\"B:{c_y['Bleed'][0,0]:2.1%} F:{c_y['Fracture'][0,0]:2.1%}\\nPred: B:{pred_y[0][0,0]:2.1%} F:{pred_y[1][0,0]:2.1%}\")\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cthead')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=6) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen = ct_gen(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b448e63763fb9f218e0a5f39345e01d62c5c6e78"},"cell_type":"code","source":"bf_model.fit_generator(ct_gen(train_df), \n                       steps_per_epoch = 50,\n                        validation_data = test_gen, \n                       validation_steps = 50,\n                              epochs = 20, \n                              callbacks = callbacks_list,\n                             workers = 4,\n                             use_multiprocessing=True, \n                             max_queue_size = 5\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y), c_ax in zip(test_gen, m_axs.flatten()):\n    c_ax.imshow(c_x['RawImageInput'][0, 10, :, :, 0], cmap = 'bone')\n    pred_y = bf_model.predict(c_x)\n    c_ax.set_title(f\"B:{c_y['Bleed'][0,0]:2.1%} F:{c_y['Fracture'][0,0]:2.1%}\\nPred: B:{pred_y[0][0,0]:2.1%} F:{pred_y[1][0,0]:2.1%}\")\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e18e3170d7456486a9bbb2b3cf13e5f4f2537c85"},"cell_type":"code","source":"out_vals = bf_model.evaluate_generator(test_gen, steps = 5, workers=1)\nprint(out_vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11d542adc3aeb10ecdc4074d296401434283aa0a"},"cell_type":"code","source":"print('Accuracy Bleeds: %2.1f%%\\nAccuracy Fractures: %2.1f%%' % (out_vals[-2]*100, out_vals[-1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}