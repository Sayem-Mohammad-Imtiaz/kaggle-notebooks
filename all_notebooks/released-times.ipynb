{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n![](https://specials-images.forbesimg.com/imageserve/1207431330/960x0.jpg?fit=scale)\n\n> Today's world has been evolving so rapidly to new digital future, so is the real concept of data science,artifical intelligence, deep and machine learning. As an novice, I have applied this data which stays miniscule comparing to real-big-ones whose companies like Netflix,Google have. My purpose is to enhance myself in understanding and writing codes of basic of Data Analyze by using libraries such as Pandas, Matplotlib, Numpy etc. My second work is focusing on both TV Series and Movies released after 2000s by defining their relationships between time in year schedule and in month schedule for last five years, especially. I hope you will enjoy and like my content or you can feedback me about things in which I made careless mistakes :)\n ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First Look at Data\nIn this section, I used some known methods to define data as you can see like head, info methods.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/netflix-shows/netflix_titles.csv\")\ndf.head() #This code turns first 6 lines of data.","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info() #This code gives us a summary about data.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum() #Thanks to this, we can detect the nan variables.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classifying Years\n\nAs you can see first code, there is so much unique years to classify, so firstly we should detect the real number of products released after 21th century.\n","metadata":{}},{"cell_type":"code","source":"dfYearAll = df[\"release_year\"].unique()\nprint(dfYearAll)\nprint(len(dfYearAll))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.release_year.plot(kind = \"hist\",color = \"green\", bins = 125, grid = True, label=\"Frequency of Numbers\")\nplt.legend()\nplt.xlabel(\"Years\")\nplt.ylabel(\"Frequency\")\nplt.title=(\"Products Released Year By Year\")\nfig1 =plt.gcf()\nfig1.set_size_inches(18.5, 10.5)\n#These codes are creating histagram below, you can have more knowledge them if you search pandas/matplotlib libraries.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only %9 of them are released before 21th century, so in later section we can ignore them to show data more effectively.   ","metadata":{}},{"cell_type":"code","source":"dfYearNew = df[df[\"release_year\"] > 1999] #creating new dataframe with filtering\ndfYearNew = dfYearNew.drop(columns = [\"director\",\"description\",\"rating\",\"cast\"]) #cleaning needless part of data\ndfYearNew.info() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With this section, we created new dataframe actually, and we dropped some of the columns that we will not use.","metadata":{}},{"cell_type":"code","source":"print(dfYearNew[\"release_year\"].unique())\nprint(len(dfYearNew[\"release_year\"].unique()))\ntype(dfYearNew[\"release_year\"].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that only aproximately 20 years left to examine, likely  %90 of products are made in these years though.","metadata":{}},{"cell_type":"markdown","source":"# Graph Years by Years","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This section takes a lot of time and it includes a bit of complex code. I don't know yet if there is more easy way to do this, I am sure that there is, but I tried to explain it with some basic notes.","metadata":{}},{"cell_type":"code","source":"\"\"\"\n#Warning! = Since this section examines thousands of data, it can harden your cpu if it is weak.\nmlist = []  #this is our first blank main list\nfor a in list(dfYearNew[\"release_year\"].unique()):  #this iters our years list \n    global count \n    count = 0  #this variable is to count appropriate values\n    for b in dfYearNew[\"show_id\"]:  #we should use an unique value to this iteration because it might have some problems\n        if a == int(dfYearNew[dfYearNew['show_id'] == b]['release_year']): \n            #this is a method from pandas, we can reach other values from one value of it \n            count += 1\n        else:\n            count\n    print(count)           \n    mlist.append(count) #this method adds the value into our main list  \n    \n\"\"\"\n# I have finally found much more efficient way to do this, but I want to show this code as a sign of progress I have made.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mList = dict(dfYearNew[\"release_year\"].value_counts(dropna = False))\nprint(mList)\ndf2 = pd.Series(mList)\ndf2 = pd.DataFrame([df2])\ndf2 = pd.melt(frame = df2,value_vars = list(mList.keys()))\ndf2 = df2.drop(index = 20)\ndf2\n#Here we created new dataframe with our new outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.plot(kind = \"scatter\",x = \"variable\", y = \"value\" , color = \"orange\", label=\"Release Numbers Year by Year\",s = 450, grid = True)\nplt.legend()\nplt.xlabel(\"Years\")\nplt.ylabel(\"Numbers\")\nplt.title=(\"Products Released Year By Year\")\nplt.xticks(list(df2.variable))\nfig4 =plt.gcf()\nfig4.set_size_inches(18.5, 10.5)\n#These codes are creating scatter graph below, you can have more knowledge them if you search pandas/matplotlib libraries.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see the number of products increasing year by year especially after 2015, there is a jump. So I thought that we can use \"date_added\" parts to deep into data for these years so we should make the data more usable way.","metadata":{}},{"cell_type":"markdown","source":"# Graphs Month by Month","metadata":{}},{"cell_type":"code","source":"def selectMonth(x):\n        #this function for splitting months for date_added columns of netflix.csv\n        x = str(x)\n        if x == \"nan\" :\n            return \"January\" #Ä°f I do not know their month, I added them to January.\n        elif x.split(\" \")[0] == \"\":\n            return x.split(\" \")[1] #This is made since some strings were written like \" April\" with blanket in their beginning.\n        else:\n            return x.split(\" \")[0]\n    \ndfYearNew[\"release_month\"] = dfYearNew.date_added.apply(selectMonth)\nprint(dfYearNew[\"date_added\"].unique())\nprint(len(dfYearNew[\"release_month\"].unique()))\nprint(dfYearNew[\"release_month\"].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfYearNew.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtre1 = dfYearNew.release_year > 2014\nfiltre2 = dfYearNew.release_year < 2020\ndf3 = dfYearNew[filtre1 & filtre2]\nyearList = list(df3[\"release_year\"].unique())\n#I created this list to order months correctly.\nprint(yearList)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After these codes, we have three columns to use to draw six graphs. These are show_id release_year and release_month which we have just added to our data.","metadata":{}},{"cell_type":"code","source":"monthList = list(dict(df3[\"release_month\"].value_counts(dropna = False)).keys())\nprint(monthList)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mArray = np.zeros((12,5))  \nindex = -1 \nfor a in yearList:\n    filtered_data = df3[df3[\"release_year\"] == a]\n    tlist = list(filtered_data[\"release_month\"].value_counts(dropna = False))\n    index = index + 1\n    print(tlist)\n    mArray[:,index] = tlist\n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n#Warning! = Since this section examines thousands of data, it can harden your cpu if it is weak.\nmArray = np.zeros((12,6))  #Array is more usable to these graphs\nindex = -1 \nfor a in yearList:\n    #Firstly we should apply this for years to months to numbers.\n    tList = []\n    for b in monthList:\n        #Again we should apply every month this.\n        count2 = 0\n        for c in df3[\"show_id\"]:\n            #we have last iterable to detect months with numbers\n            if a == int(df3[df3['show_id'] == c]['release_year']) and b in str(df3[df3['show_id'] == c]['release_month']):\n                #this means that find appropirate values according to our variables a,b year;month and count it\n                count2 += 1 \n            else:\n                count2\n        tList.append(count2) #again append method\n    index = index + 1\n    print(tList)  #this is for controlling\n    mArray[:,index] = tList  #this is we actually rewrite the array\n    tList.clear()   #we should clear the temporary list since the program will add a lot of values too\n\"\"\"\n\n# I have finally found much more efficient way to do this in previous code block, but I want to show this code as a sign of progress I have made.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_yearList = []\nc_monthList = ['January','February','March','April','May','June','July','August','September','October','November','December']\nfor each in yearList:\n    each = \"Year_\"+ str(each)\n    c_yearList.append(each)\ngraphList = [\"Year_2015\",\"Year_2016\",\"Year_2017\",\"Year_2018\",\"Year_2019\"]\ndf4 = pd.DataFrame(data=mArray, index=monthList, columns=c_yearList)\ndf4 = df4.reindex(columns = graphList , index = c_monthList )\ndf4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our last dataframe consists of twelve months with six yearsso it is ready, last thing we should do is to create graphs :)","metadata":{}},{"cell_type":"code","source":"colorList = [\"#0040FF\",\"#61210b\",\"#ff8000\",\"#cc0000\",\"#4b8a08\"]\n#Firstly I used iter and next method it but, afret running couple of times","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graphList = [\"Year_2015\",\"Year_2016\",\"Year_2017\",\"Year_2018\",\"Year_2019\"]\ne = 0  #for visualization \nfor each in graphList:\n    labelYear = \"Products Released in \" + each.split(\"_\")[1]\n    fig = px.bar(df4,y=each, x = c_monthList, color_discrete_sequence=[colorList[e]], text=each)\n    fig.add_annotation(x=2, y=141,text=labelYear,showarrow=False,yshift=10, font=dict(family=\"Time\",size=40,color=colorList[e]))\n    fig.show()\n    e = e + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying Datetime as Index\n\nLet's add more details to our data, or transform the our first data's release month column to much more usable ways.\n","metadata":{}},{"cell_type":"code","source":"df5 = dfYearNew.copy()\nwList = []\n#How can we split and transform this 09.09.2019?\n\nfor a in df5[\"show_id\"]:\n    exList = str(df5[df5['show_id'] == a]['date_added']).split()\n    if exList[1] == \"NaN\":\n        nanYear = str(int(df5[df5['show_id'] == a]['release_year']))\n        aTime = nanYear +\"-01-01\"\n        wList.append(aTime)\n    else:\n        for b in c_monthList:\n            if exList[1] == b:\n                exMonth = str(c_monthList.index(b) + 1)\n                if len(exMonth) == 1:\n                    exMonth = \"0\" + exMonth\n                else:\n                    exMonth\n        if len(exList[2]) == 2:\n            exDay = \"0\" + exList[2][0]\n        else:\n            exDay = exList[2][0:2]\n\n        rTime = exList[3] + \"-\" + exMonth + \"-\" + exDay\n        wList.append(rTime)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(wList)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_object = pd.to_datetime(wList)\ndf5[\"date\"] = time_object","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5 = df5.drop(columns = [\"date_added\",\"release_year\",\"release_month\",\"duration\"])\ndf5.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After this I decided to use new multiple indexes method, for instance just US, index level 1 US, if more than one so it means that ","metadata":{}},{"cell_type":"code","source":"df5[\"status\"] = [\"International\" if len(str(i).split(\", \")) > 1 else \"Unknown\" if str(i) == \"nan\" else \"Single\" for i in df5.country]\ndf5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5[\"status\"].value_counts(dropna = False)\nfig = px.sunburst(df5, path=['type',\"status\"])\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5_single = df5[df5[\"status\"] == \"Single\"]\ndf5_int = df5[df5[\"status\"] == \"International\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nAs you can see that I really like the for loops, we can use them to create different graphs automaticly, too. This was really my second notebook and not professional ones I know. However, I did this to learn new things and practice, and for my daily homework as I planned with the course from DATAI Team.. As I mentioned, if you like this or give me some feedback about it, I will be so glad. \n\nHealthy days.","metadata":{}}]}