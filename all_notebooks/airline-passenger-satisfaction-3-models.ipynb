{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/airline-passenger-satisfaction/train.csv')\ndata_test = pd.read_csv('/kaggle/input/airline-passenger-satisfaction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data analysis ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And look at type of every column.\n\nMachine learning models require all input and output variables to be numeric.\n\nBecause our data contains categorical data, we must transform it to numbers before we will fit and evaluate a model.\n\nWe have next categorical data:\n- Gender\n- Customer Type\n- Type of Travel\n- Class\n\nFor these columns to use method of Pandas get_dummies.\n\nFor categorical column 'satisfaction' to use LabelEncoder from sklearn:\n\n* neutral or dissatisfied = 0\n* satisfied = 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndata_train['satisfaction'] = labelencoder.fit_transform(data_train['satisfaction'])\ndata_test['satisfaction'] = labelencoder.fit_transform(data_test['satisfaction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'How many people satisfacted by Airline:'\ndata_train.groupby('Gender')[['satisfaction']].sum()\n'How many people participated in the study:'\ndata_train.groupby('Gender')[['satisfaction']].count()\n'Percentage of satisfacted people :'\ndata_train.groupby('Gender')[['satisfaction']].sum()/ data_train.groupby('Gender')[['satisfaction']].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, people`s satisfaction do not depend from gender.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'Satisfaction of people depending on the class:'\ndata_train.groupby('Class')[['satisfaction']].sum()\n'How many people participated in the study:'\ndata_train.groupby('Class')[['satisfaction']].count()\n'Percentage of satisfacted people depending from the class:'\ndata_train.groupby('Class')[['satisfaction']].sum()/ data_train.groupby('Class')[['satisfaction']].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that satisfaction depend from class: Business class promotes to satisfaction and not if eco class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'Percentage of satisfacted people depending from the type of travel:'\ndata_train.groupby('Type of Travel')[['satisfaction']].sum()/ data_train.groupby('Type of Travel')[['satisfaction']].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Business travel also promotes to satisfaction.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dummies=pd.get_dummies(data_train, columns=[\"Gender\",\"Customer Type\",\"Type of Travel\",\"Class\"],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test=pd.get_dummies(data_test, columns=[\"Gender\",\"Customer Type\",\"Type of Travel\",\"Class\"],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14,14))\nsns.heatmap(data_dummies.corr(), annot=True, square=True, cbar=False, ax=ax, linewidths=0.25);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data_dummies.drop(columns=['Arrival Delay in Minutes', 'Unnamed: 0', 'id', 'satisfaction'])\nX_test = data_test.drop(columns=['Arrival Delay in Minutes', 'Unnamed: 0', 'id', 'satisfaction'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there is correlation: 'Departure Delay in Minutes', 'Arrival Delay in Minutes'.\nDrop from data column 'Arrival Delay in Minutes'.\nAlso columns 'Unnamed: 0', 'id' don`t have useful information - drop them too.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = data_dummies['satisfaction']\ny_test = data_test['satisfaction']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our data haven`t 'Null'.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\nCreate one more data without outliers and will be train models on 2 data with a choice of the best.\n</div>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_outliers = []\nfor col in X_train.columns:    \n        Q_min = X_train[col].quantile(0.01)\n        Q_max = X_train[col].quantile(0.99)\n        idx = ((X_train[col] < Q_min) | (X_train[col] > Q_max))\n        data_outliers.append(X_train[idx])\n\ndata_outliers = pd.concat(data_outliers)\ndata_cleared = X_train.drop(data_outliers.index.unique())\ny_cleared = y_train.drop(data_outliers.index.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train models ##","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom numpy import mean\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def models_result(model, X_test, y_test):\n    labels = model.predict(X_test)\n    matrix = confusion_matrix(y_test, labels)\n    sns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False)\n    plt.xlabel('true label')\n    plt.ylabel('predicted label');\n    \n    logit_roc_auc = roc_auc_score(y_test, labels)\n    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n    plt.figure()\n    plt.plot(fpr, tpr, label='(area = %0.2f)' % logit_roc_auc)\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.legend(loc=\"lower right\")\n    plt.savefig('Log_ROC')\n    plt.show();\n    \n    print(classification_report(y_test, labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RandomForestClassifier ###","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this model, we will select hyperparameters for the best result. Then the already selected hyperparameters will be substituted.\n\nWe will iterate over different values for parameters:\n- max_features\n- n_estimators","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nn_estimators = [50, 75, 100]\nmax_features = ['sqrt', 'log2']\ngrid = dict(n_estimators=n_estimators,max_features=max_features)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_RandomForestClassifier = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\nmodel_RandomForestClassifier = grid_search_RandomForestClassifier.fit(X_train, y_train)\n\nprint(\"Best: %f using %s\" % (model_RandomForestClassifier.best_score_, model_RandomForestClassifier.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means = model_RandomForestClassifier.cv_results_['mean_test_score']\nstds = model_RandomForestClassifier.cv_results_['std_test_score']\nparams = model_RandomForestClassifier.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And to use RandomForestClassifier we need choose hyperparameters: max_features = log2, n_estimators = 100","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RandomForestClassifier_cleared = grid_search_RandomForestClassifier.fit(data_cleared, y_cleared)\nprint(\"Result: %f\" % (model_RandomForestClassifier_cleared.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_result(model_RandomForestClassifier, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### BaggingClassifier ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\n\nmodel = BaggingClassifier(random_state=28)\nn_estimators = [40]\ngrid = dict(n_estimators=n_estimators)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_BaggingClassifier = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\nmodel_BaggingClassifier = grid_search_BaggingClassifier.fit(X_train, y_train)\n\nprint(\"Result: %f\" % (model_BaggingClassifier.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_BaggingClassifier_cleared = grid_search_BaggingClassifier.fit(data_cleared, y_cleared)\nprint(\"Result: %f\" % (model_BaggingClassifier_cleared.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_result(model_BaggingClassifier, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AdaBoostClassifier ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n                        learning_rate = 1.1,\n                        random_state=42)\n\nn_estimators = [75]\ngrid = dict(n_estimators=n_estimators)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_ABC = GridSearchCV(estimator=ABC, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\nmodel_ABC = grid_search_ABC.fit(X_train, y_train)\n\nprint(\"Result: %f\" % (model_ABC.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ABC_cleared = grid_search_ABC.fit(data_cleared, y_cleared)\nprint(\"Result: %f\" % (model_ABC_cleared.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_result(model_ABC, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use 3 models:\n\n- RandomForestClassifier\n- BaggingClassifier\n- AdaBoostClassifier( with DecisionTreeClassifier)\n\nThe best result gave a model with using RandomForestClassifier = 96,23% accuracy.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\">\n    \nThanks to:\n\nauthor of this dataset;\n    \nhttps://machinelearningmastery.com/\n        \n### Happy coding ###\n</div>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}