{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nimport re\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/Sentiment.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd2454fab4e1fc43cdb940cbf099350389799406","collapsed":true},"cell_type":"code","source":"# Exploring the number of columns\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff6551ca44219032811d33f5649ec796b9a5cb5","scrolled":true,"collapsed":true},"cell_type":"code","source":"#lets see how many subjects do we have here\ndf['subject_matter'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a767c1cf2588acf4b75f6b1446910cca7bc29077"},"cell_type":"markdown","source":"**Since the data set has many topics we can explore the sentiments for each topic**\n\nIn the next steps we will try to dive deepr and visualize the distributions of tweets against topics and confidence factors"},{"metadata":{"trusted":true,"_uuid":"ea7ad1b5e2bbd5f812b992aad7df309d98d83a38","collapsed":true},"cell_type":"code","source":"#Using seaborn to plot a visually pleasant charts\nimport seaborn as se\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n#Here we are just controlling the size of the grid and the orientation of the labels in the x-axis\nplt.figure(figsize=(20, 8))\nplt.xticks(rotation=45)\n\nse.countplot(x=\"subject_matter\", data=df, palette=\"Greens_d\");\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d76ea67120f763ad1c9c0d77d18c41d6622e75b"},"cell_type":"markdown","source":"**We can that majoriety of the tweets don't belong to any specific topic.**\n\n\n> Lets look into the sentiment distribution through all the topics."},{"metadata":{"trusted":true,"_uuid":"58835f2e8735dac0d5a5f66aad7a928233f0eb1b","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\nplt.xticks(rotation=45)\n\nse.barplot(x=\"subject_matter\", y=\"sentiment_confidence\", hue=\"sentiment\", data=df);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a7b09b244c89d4efdbaa9970f4d30ef8b086a59"},"cell_type":"markdown","source":"**We can see that the negative sentiment out-weights the positive and neutral sentiment in all the topics.**\n\n> Except in the Gun control there is no positive conversations there,,, Surprise lol"},{"metadata":{"trusted":true,"_uuid":"64fd8251d5050146b74eab51b73b594765995296","scrolled":true,"collapsed":true},"cell_type":"code","source":"df['tweet_location'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ebcbd5aa23a64e3977a811c2767a9ceaf05ffbf","collapsed":true},"cell_type":"code","source":"#Lets look at that in barplot\nplt.figure(figsize=(20, 8))\nplt.xticks(rotation=45)\n\nse.countplot(x=\"tweet_location\", data=df);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"419e2f45e7557be4d32e35c585c34f89f73eb5e5"},"cell_type":"markdown","source":"**OK that was totally messed up, you shouldn't expect all the people to:**\n\n* Use a real location.\n* Write the right spelling.\n* Have one way to write NYC (they will have 100 ways to do that)"},{"metadata":{"_uuid":"e5c126fe937f3b8dd884f50a7c94a89665a5d042"},"cell_type":"markdown","source":"**Now lets just keep only the features that we need to train the model. Mostly  we will need the texts (tweets) and their sentiments (as our labels).\nWe can try to do many other things like predicting the topic of the tweet, sentiments and so on. First lets just build an LSTM model to classify the sentiments of the tweets.**"},{"metadata":{"trusted":true,"_uuid":"7ae426149a8d2b34a09b5de7b113d1f23e68e817","collapsed":true},"cell_type":"code","source":"#We extract the two columns text and sentiment from the dataframe\ndata = df[['text','sentiment']]\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aef1d5cd04545c8217da4d392237e114176acc61","collapsed":true},"cell_type":"code","source":"#This code borrowed from Peter Nagy \"LSTM Sentiment Analysis | Keras\"\n\ndata['text'] = data['text'].apply(lambda x: x.lower())\ndata['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n\nprint(data[ data['sentiment'] == 'Positive'].size)\nprint(data[ data['sentiment'] == 'Negative'].size)\nprint(data[ data['sentiment'] == 'Neutral'].size)\n\n\nfor idx,row in data.iterrows():\n    row[0] = row[0].replace('rt',' ')\n    \nmax_fatures = 2000\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"451270fec42bb813d05d6690b0b6f13f867193e7"},"cell_type":"markdown","source":"**Training the model in the same in architecture used by Peter Nagy in \"LSTM Sentiment Analysis | Keras\"**"},{"metadata":{"trusted":true,"_uuid":"e46bdb0303dd8da4ae62449385dc6820ceab18e5","collapsed":true},"cell_type":"code","source":"#Used the same model architecture used by Peter Nagy \"LSTM Sentiment Analysis | Keras\"\n\nembed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1], dropout=0.2))\nmodel.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\nmodel.add(Dense(3,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"468553ce7763c2c86e7a1a53e7d5e3d3317f0c55","collapsed":true},"cell_type":"code","source":"Y = pd.get_dummies(data['sentiment']).values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b09427821628304c7584dc5dee0e23e5082cb030","scrolled":true,"collapsed":true},"cell_type":"code","source":"batch_size = 32\nmodel.fit(X_train, Y_train, nb_epoch = 7, batch_size=batch_size, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"695077cfcf6c95b234b9d8042463f1e476b29a3b","collapsed":true},"cell_type":"code","source":"#Retrain again in 90 epochs\nmodel.fit(X_train, Y_train, epochs = 90, batch_size=batch_size, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfa2774b89cc2c612836ad718e0ac510618dac06"},"cell_type":"markdown","source":"**Experimenting new architecture**"},{"metadata":{"trusted":true,"_uuid":"a419bc573d35da7982afeb262b4a228a619f4bbd","scrolled":true,"collapsed":true},"cell_type":"code","source":"embed_dim = 280\nlstm_out = 210\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1], dropout=0.2))\nmodel.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\nmodel.add(Dense(3,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a5d56be9ea5f6237dca085f7b8ccd47c7c98f757"},"cell_type":"code","source":"model.fit(X_train, Y_train, nb_epoch = 7, batch_size=batch_size, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"538b9b698e8ea2a615493999fc7b4695ce6af8e3"},"cell_type":"code","source":"model.fit(X_train, Y_train, epochs = 90, batch_size=batch_size, verbose = 2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}