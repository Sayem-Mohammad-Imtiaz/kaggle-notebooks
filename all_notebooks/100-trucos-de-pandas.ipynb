{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Integrantes:\n* Zaida Lizbeth Alvarado Tolentino\n* Rogelio Gaona Sanchez"},{"metadata":{},"cell_type":"markdown","source":"# Benvienido a este Kernel\n\n* Este kernel es una recopilación de trucos de pandas publicados por Kevin Markham semanalmente.\n\nPuedes encontrar los 100 trucos originales de Pandas (creado por [Kevin Markham](https://www.linkedin.com/in/justmarkham/) de Data School) en esta página: \n\nhttps://www.dataschool.io/python-pandas-tips-and-tricks/\n\n## <span style=\"color:green\">* Si quieres aprender **sklearn** revisa este kernel con trucos y consejos:</span>\n\nhttps://www.kaggle.com/python10pm/sklearn-24-best-tips-and-tricks"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"table_of_contents\"></a>\n# Tabla de Contenido\n\n[Importar bibliotecas y configurar algunas funciones auxiliares](#Imports)\n\n[Truco 100: Carga de muestra de Big Data](#trick100)\n\n[Truco 99: Cómo evitar columnas Unnamed: 0](#trick99)\n\n[Truco 98: Convierte el ancho de un DF en uno largo](#trick98)\n\n[Truco 97: Convierte el año y el día del año en una sola columna de \"DateTime\"](#trick97)\n\n[Truco 96: Gráficos interactivos listos para usar en Pandas](#trick96)\n\n[Truco 95: Cuenta los valores perdidos](#trick95)\n\n[Truco 94: Ahorra memoria fijando tu fecha](#trick94)\n\n[Truco 93: Combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando frecuencias)](#trick93)\n\n[Truco 92: Columna de Clean Object con datos mixtos usando expresiones regulares](#trick92)\n\n[Truco 91: Creación de un \"DataSet\" para realizar pruebas](#trick91)\n\n[Truco 90: Mover columnas a una ubicación específica](#trick90)\n\n[Truco 89: Divide los \"nombres\" en nombre y apellido](#trick89)\n\n[Truco 88: Reorganizar columnas en un DF](#trick88)\n\n[Truco 87: Agregue su \"fecha y hora por\" y filtre los \"fines de semana\"](#trick87)\n\n[Truco 86: Agregaciones con nombre: evita el índice múltiple](#trick86)\n\n[Truco 86bis: Agregaciones con nombre en varias columnas-evita el índice múltiple](#trick86bis)\n\n[Truco 85: Convierte un tipo de valores en otros](#trick85)\n\n[Truco 84: Mostrar menos filas en un DF](#trick84)\n\n[Truco 83: Corrija los tipos de datos al importar el DF](#trick83)\n\n[Truco 82: Seleccionar datos por etiqueta y posición (iloc y loc encadenados)](#trick82)\n\n[Truco 81: Use aplicar (Type) para ver si tiene tipos de datos mixtos](#trick81)\n\n[Truco 80: Seleccione varias secciones de columnas de un DF](#trick80)\n\n[Truco 79: Recuento de filas que coinciden con una condición](#trick79)\n\n[Truco 78: Realice un seguimiento de la procedencia de sus datos cuando utilice varias fuentes](#trick78)\n\n[Truco 77: Combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando where)](#trick77)\n\n[Truco 76: Filtra en Pandas solo las categorías más grandes.](#trick76)\n\n[Truco 75: Cuenta el número de palabras en una serie de Pandas](#trick75)\n\n[Truco 74: Webscraping usando read_html () y parámetro de coincidencia](#trick74)\n\n[Truco 73: Eliminar una columna y almacenarla como una serie separada](#trick73)\n\n[Truco 72: Convertir variable continua en categórica (corte y qcut)](#trick72)\n\n[Truco 71: Leer datos de un PDF (tabula py)](#trick71)\n\n[Truco 70: Imprime la versión actual de Pandas y sus dependencias](#trick70)\n\n[Truco 69: Comprobar si 2 series son \"similares\"](#trick69)\n\n[Truco 68: Webscraping usando read_html ()](#trick68)\n\n[Truco 67: Cree nuevas columnas o sobrescriba usando assing y establezca un título para el DF](#trick67)\n\n[Truco 66: Cree un montón de columnas nuevas usando un bucle for y f-strings df [f '{col} _new']](#trick66)\n\n[Truco 65: Seleccione columnas usando f-strings (nuevo en pandas 3.6+)](#trick65)\n\n[Truco 64: Arreglando \"SettingWithCopyWarning\" al crear nuevas columnas](#trick64)\n\n[Truco 63: Calcular el recuento corriente con grupos usando cumcount () + 1](#trick63)\n\n[Truco 62: Arreglando \"SettingWithCopyWarning\" al cambiar columnas usando loc](#trick62)\n\n[Truco 61: Leer JSON de la web en un DF](#trick61)\n\n[Truco 60: Creación de totales acumulados con la función cumsum](#trick60)\n\n[Truco 59: Combine la salida de una agregación con el df original usando transform](#trick59)\n\n[Truco 58: Utilice encabezados y saltos para deshacerse de datos incorrectos o filas vacías durante la importación](#trick58)\n\n[Truco 57: Accediendo a los grupos de un objeto groupby (get_group ())](#trick57)\n\n[Truco 56: Aplicar asignaciones o funciones a todo el DF (applymap)](#trick56)\n\n[Truco 55: Filtrar un DF con múltiples criterios usando reducir](#trick55)\n\n[Truco 54: Calcule la diferencia entre cada fila y la anterior (diff ())](#trick54)\n\n[Truco 53: Barajar las filas de un df (df.sample ())](#trick53)\n\n[Truco 52: Hacer parcelas con pandas](#trick52)\n\n[Truco 51: Concatenar cadenas de 2 columnas](#trick51)\n\n[Truco 50: Agregación con nombre con varias columnas que pasan tupples (nuevo en pandas 0.25)](#trick50)\n\n[Truco 49: Muestreo con pandas (con reemplazo y pesos)](#trick49)\n\n[Truco 48: Parámetros útiles al usar pd.read_csv ()](#trick48)\n\n[Truco 47: Cree una fila para cada elemento en una lista (explotar)](#trick47)\n\n[Truco 46: Almacene NaN en un tipo entero con Int64 (no int64)](#trick46)\n\n[Truco 45: Cree filas para valores separados por comas en una celda (asigne y explote)](#trick45)\n\n[Truco 44: Use una variable local dentro de una consulta en pandas (usando @)](#trick44)\n\n[Truco 43: Crea una fila para cada elemento en una lista (explotar) !!! Truco 47 duplicado !!!](#trick43)\n\n[Truco 42: Nueva función agregada -> Ultima ()](#trick42)\n\n[Truco 41: Categorías ordenadas (de pandas.api.types import CategoricalDtypee)](#trick41)\n\n[Truco 40: Estilo de df rápido con ocultar índice () y establecer título ()](#trick40)\n\n[Truco 39: Una codificación en caliente (obtén maniquíes)](#trick39)\n\n[Truco 38: Pandas fecha y hora (muchos ejemplos)](#trick38)\n\n[Truco 37: Pandas cortando loc e iloc (6 ejemplos)](#trick37)\n\n[Truco 36: Convierte de UTC a otra zona horaria](#trick36)\n\n[Truco 35: Consulta una columna que tenga espacios en el nombre (usando comillas invertidas)](#trick35)\n\n[Truco 34: Explore un DataSet con creación de perfiles](#trick34)\n\n[Truco 33: Opciones de visualización de Pandas](#trick33)\n\n[Truco 32: Filtrar un DF con consulta y evitar variables intermedias](#trick32)\n\n[Truco 31: Ver todas las columnas de un gran DF](#trick31)\n\n[Truco 30: Pandas se fusionan -> vea de dónde vienen las columnas (indicador = True)](#trick30)\n\n[Truco 29: Acceda a NumPy dentro de Pandas (sin importar NumPy como np)](#trick29)\n\n[Truco 28: Agregando por múltiples columnas (usando agg)](#trick28)\n\n[Truco 27: Agregación sobre series temporales (remuestreo)](#trick27)\n\n[Truco 26: Formatear diferentes columnas de un DF (usando diccionarios)](#trick26)\n\n[Truco 25: 3 formas de cambiar el nombre de las columnas](#trick25)\n\n[Truco 24: Copie datos de Excel a Pandas rápidamente (read_clipboard ())](#trick24)\n\n[Truco 23: Complete los valores faltantes en los datos de series de tiempo (interpolar ())](#trick23)\n\n[Truco 22: Crea DataFrames para probar](#trick22)\n\n[Truco 21: Divide una columna de cadena en varias columnas](#trick21)\n\n[Truco 20: Crea columnas de DateTime a partir de varias columnas](#trick20)\n\n[Truco 19: Muestra el uso de memoria de un df y cada columna](#trick19)\n\n[Truco 18: Leer y escribir en un archivo comprimido (csv.zip)](#trick18)\n\n[Truco 17: Seleccione varias filas y columnas con \"loc\"](#trick17)\n\n[Truco 16: Convierta valores continuos en categóricos (cut())](#trick16)\n\n[Truco 15: Remodelar una MultiIndex DF (unstack())](#trick15)\n\n[Truco 14: Creando juguete DF (3 métodos)](#trick14)\n\n[Truco 13: Evita la serie de listas TRAP](#trick13)\n\n[Truco 12: Fusionar conjuntos de datos y verificar la unicidad](#trick12)\n\n[Truco 11: Cambie el nombre de todas las columnas con el mismo patrón](#trick11)\n\n[Truco 10: Comprueba la igualdad de 2 series](#trick10)\n\n[Truco 9: ¡Reduzca el uso de memoria de un DF al importar! ¡¡¡Truco 83 duplicado !!!](#trick9)\n\n[Truco 8: ¡Usar glob para generar un DF a partir de varios archivos! ¡¡¡Truco 78 duplicado !!!](#trick8)\n\n[Truco 7: Manejo de valores perdidos (NaN)](#trick7)\n\n[Truco 6: Dividir un DF entre 2 subconjuntos random](#trick6)\n\n[Truco 5: Convertir números almacenados como strings (coerce)](#trick5)\n\n[Truco 4: Seleccionar columnas por dtype](#trick4)\n\n[Truco 3: Filtrar un DF por múltiples condiciones (Usando isin and inverse)](#trick3)\n\n[Truco 2: Orden inverso de una DF](#trick2)\n\n[Truco 1: Añadir prefijo o sufijo](#trick1)\n"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"Imports\"></a>\n# Importar bibliotecas y configurar algunas funciones auxiliares\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Bibliotecas Básicas\nimport os\nimport numpy as np\nimport pandas as pd\n\n# Esto nos permitirá imprimir todos los archivos a medida que generamos más en el kernel\ndef print_files():\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n# Consulte el Truco 91 para ver un ejemplo\ndef generate_sample_data(): # Crea un DF falso para hacer pruebas\n    number_or_rows = 20\n    num_cols = 7\n    cols = list(\"ABCDEFG\")\n    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n    df.index = pd.util.testing.makeIntIndex(number_or_rows)\n    return df\n\n# Consulte el Truco 91 para ver un ejemplo\ndef generate_sample_data_datetime(): # Crea un DF falso para hacer pruebas\n    number_or_rows = 365*24\n    num_cols = 2\n    cols = [\"sales\", \"customers\"]\n    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n    df.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\n    return df\n\n# Mostrar varias impresiones en una celda. Esto nos permitirá condensar cada truco en una celda.\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nprint_files()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick100\"></a>\n# Truco 100: Carga de muestra de Big Data\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/us-accidents/US_Accidents_June20.csv\")\nprint(\"La forma del DF es {}\".format(df.shape))\n\ndel df\n\ndf = pd.read_csv(\"../input/us-accidents/US_Accidents_June20.csv\", skiprows = lambda x: x>0 and np.random.rand() > 0.01)\nprint(\"La forma del DF es {}. Se ha reducido 10 veces!\".format(df.shape))\n\n\n'''\nCómo funciona:\nskiprows acepta una función que se evalúa con el index entero.\nx > 0 se asegura de que los encabezados no se omitan\nnp.random.rand() > 0.01 devuelve True 99% del empate, por lo que se salta el 99% del tiempo.\nTenga en cuenta que estamos usando skiprows\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick99\"></a>\n# Truco 99: Cómo evitar columnas Unnamed: 0\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"zip_code\": [12345, 56789, 101112, 131415],\n\"factory\": [100, 400, 500, 600],\n\"warehouse\": [200, 300, 400, 500],\n\"retail\": [1, 2, 3, 4]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Guardar a csv\ndf.to_csv(\"trick99data.csv\")\n\ndf = pd.read_csv(\"trick99data.csv\")\ndf\n# Para evitar Unnamed: 0\n\ndf = pd.read_csv(\"trick99data.csv\", index_col=0)\n# O cuando guardamos df = pd.read_csv(\"trick99data.csv\", index = False)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick98\"></a>\n# Truco 98: Convierte el ancho de un DF en uno largo\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"zip_code\": [12345, 56789, 101112, 131415],\n\"factory\": [100, 400, 500, 600],\n\"warehouse\": [200, 300, 400, 500],\n\"retail\": [1, 2, 3, 4]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Nosotros tenemos que reasignar\n\n# location_type se genera automáticamente a partir de las columnas que quedan después de especificar id_vars (también puede pasar una lista)\ndf = df.melt(id_vars = \"zip_code\", var_name = \"location_type\", value_name = \"distance\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick97\"></a>\n# Truco 97: Convierte el año y el día del año en una sola columna de \"DateTime\"\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Truco 97\n# Convertir\nd = {\\\n\"year\": [2019, 2019, 2020],\n\"day_of_year\": [350, 365, 1]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: Crea una columna combinada\ndf[\"combined\"] = df[\"year\"]*1000 + df[\"day_of_year\"]\ndf\n\n# Paso 2: Convertir a  DateTime\ndf[\"date\"] = pd.to_datetime(df[\"combined\"], format = \"%Y%j\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick96\"></a>\n# Truco 96: Gráficos interactivos listos para usar en Pandas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.__version__)\n# Se requiere la versión 0.25 o superior de Pandas y necesita hvplot\n\nimport pandas as pd\ndf = pd.read_csv(\"../input/drinks-by-country/drinksbycountry.csv\")\ndf\n\n# Este no es interactivo\ndf.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\")\n\n# run !pip install hvplot\n#pd.options.plotting.backend = \"hvplot\"\n#df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\", c = \"continent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick95\"></a>\n# Truco 95: Cuenta los valores perdidos\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"col1\": [2019, 2019, 2020],\n\"col2\": [350, 365, 1],\n\"col3\": [np.nan, 365, None]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Solución 1\ndf.isnull().sum().sum()\n\n# Solución 2\ndf.isna().sum()\n\n# Solución 3\ndf.isna().any()\n\n# Solución 4:\ndf.isna().any(axis = None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick94\"></a>\n# Truco 94: Ahorra memoria fijando tu fecha\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/titanic/train.csv\", usecols = [\"Pclass\", \"Sex\", \"Parch\", \"Cabin\"])\ndf\n\n# Veamos cuanto ocupa nuestra DF en memoria\ndf.memory_usage(deep = True)\n\n# Convertir a datatypes más pequeños\ndf = df.astype({\"Pclass\":\"int8\",\n                \"Sex\":\"category\", \n                \"Parch\": \"Sparse[int]\", # la mayoría de los valores son 0\n                \"Cabin\":\"Sparse[str]\"}) # la mayoría de los valores son NaN\n\ndf.memory_usage(deep = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick93\"></a>\n# Truco 93: Combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando frecuencias)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"genre\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: Cuenta las frecuencias\nfrequencies = df[\"genre\"].value_counts(normalize = True)\nfrequencies\n\n# Paso 2: establezca su threshold y filtre las categorías más pequeñas\nthreshold = 0.1\nsmall_categories = frequencies[frequencies < threshold].index\nsmall_categories\n\n# Paso 3: Reemplace los valores\ndf[\"genre\"] = df[\"genre\"].replace(small_categories, \"Other\")\ndf[\"genre\"].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick92\"></a>\n# Truco 92: Columna de Clean Object con datos mixtos usando expresiones regulares\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"d = {\"customer\": [\"A\", \"B\", \"C\", \"D\"], \"sales\":[1100, 950.75, \"$400\", \"$1250.35\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: Verifique los tipos de datos\ndf[\"sales\"].apply(type)\n\n# Paso 2: Usa expresiones regulares\ndf[\"sales\"] = df[\"sales\"].replace(\"[$,]\", \"\", regex = True).astype(\"float\")\ndf\ndf[\"sales\"].apply(type)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick91\"></a>\n# Truco 91: Creación de un \"DataSet\" para realizar pruebas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Solución 1\nnumber_or_rows = 365*24 # horas en un año\npd.util.testing.makeTimeDataFrame(number_or_rows, freq=\"H\")\n\n# Solución 2\nnum_cols = 2\ncols = [\"sales\", \"customers\"]\ndf = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\ndf.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick90\"></a>\n# Truco 90: Mover columnas a una ubicación específica\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[15, 20], \"B\":[20, 25], \"C\":[30 ,40], \"D\":[50, 60]}\ndf = pd.DataFrame(d)\ndf\n\n# Usando insertar\ndf.insert(3, \"C2\", df[\"C\"]*2)\ndf\n\n# Otra solución\ndf[\"C3\"] = df[\"C\"]*3 # crea nuevas columnas, estará al final\ncolumns = df.columns.to_list() # crea una lista con todas las columnas\nlocation = 4 # especifique la ubicación donde desea su nueva columna\ncolumns = columns[:location] + [\"C3\"] + columns[location:-1] # reaorganizar la lista\ndf = df[columns] # cree el dataframe con el orden de columnas que desee\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick89\"></a>\n# Truco 89: Divide los \"nombres\" en nombre y apellido\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.Series([\"Geordi La Forge\", \"Deanna Troi\", \"Data\"]).to_frame()\ndf.rename({0:\"names\"}, inplace = True, axis = 1)\ndf\n# Dividir en el primer espacio\ndf[\"first_name\"] = df[\"names\"].str.split(n = 1).str[0]\ndf[\"last_name\"] = df[\"names\"].str.split(n = 1).str[1]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick88\"></a>\n# Truco 88: Reorganizar columnas en un DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\n\n# Solución 1\ndf[[\"A\", \"C\", \"D\", \"F\", \"E\", \"G\", \"B\"]].head() # No se modifica en su lugar\n\n# Solución 2\ncols_to_move = [\"A\", \"G\", \"B\"]\n\nnew_order = cols_to_move + [c for c in df.columns if c not in cols_to_move] # genera tu nuevo pedido\ndf[new_order].head()\n\n# Solución 3: Usando index\ncols = df.columns[[0, 5 , 3, 4, 2, 1, 6]] # df.columns devuelve una serie con index, usamos la lista para ordenar el index como queramos --> así ordenamos las columnas\ndf[cols].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick87\"></a>\n# Truco 87: Agregue su \"fecha y hora por\" y filtre los \"fines de semana\"\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()\ndf.shape\ndf.head()\n\n# Paso 1: remuestrear por D. Basically agregue por día y use to_frame() para convertirlo en frame\ndaily_sales = df.resample(\"D\")[\"sales\"].sum().to_frame()\ndaily_sales\n\n# Paso 2: filtra los fines de semana\nweekends_sales = daily_sales[daily_sales.index.dayofweek.isin([5, 6])]\nweekends_sales\n\n'''\ndayofweek day\n0         Monday\n1         Tuesday\n2         Wednesday\n3         Thursday\n4         Friday\n5         Saturday\n6         Sunday\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick86\"></a>\n# Truco 86: Agregaciones con nombre: evita el índice múltiple\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.head()\n\n# Problema 1\nprint(\"El problema se basa en que no sabemos el nombre de la columna.\")\ndf.groupby(\"Pclass\")[\"Age\"].agg([\"mean\", \"max\"])\n\n# Problema 2\nprint(\"El problema se basa en que tenemos multi-índice\")\ndf.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"]})\n\n# Soluciones nuevas en Pandas 0.25 y mucho mayor\nprint(\"Ahora hemos resuelto los problemas anteriores especificando el nombre final de la columna que queremos.\")\nprint(\"PERO SOLO FUNCIONA CON COLUMNA. PARA ESTE TIPO DE OPERACIONES EN MÚLTIPLES COLUMNAS VERIFIQUE LA PRÓXIMA CELDA\")\ndf.groupby(\"Pclass\")[\"Age\"].agg(age_mean = \"mean\", age_max = \"max\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick86bis\"></a>\n# Truco 86bis: Agregaciones con nombre en varias columnas-evita el índice múltiple\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_agg(x):\n    names = {\n        'age_mean': x['Age'].mean(),\n        'age_max':  x['Age'].max(),\n        'fare_mean': x['Fare'].mean(),\n        'fare_max': x['Fare'].max()\n    } # Definir sus operaciones y nombres de columnas personalizados\n\n    return pd.Series(names, index=[ key for key in names.keys()]) # Todas las columnas que cree en el diccionario anterior estarán en esta lista de comprensión\n\ndf.groupby('Pclass').apply(my_agg)\n\n# Referencia\n# https://stackoverflow.com/questions/44635626/rename-result-columns-from-pandas-aggregation-futurewarning-using-a-dict-with\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick85\"></a>\n# Truco 85: Convierte un tipo de valores en otros\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Haz algunas funciones rápidas en el DF\nd = {\"gender\":[\"male\", \"female\", \"male\"], \"color\":[\"red\", \"green\", \"blue\"], \"age\":[25, 30, 15]}\ndf = pd.DataFrame(d)\ndf\n\n# Solución\nmap_dict = {\"male\":\"M\", \"female\":\"F\"}\ndf[\"gender_mapped\"] = df[\"gender\"].map(map_dict) # Usar diccionarios para mapear valores\ndf[\"color_factorized\"] = df[\"color\"].factorize()[0] # Usando factorizar: devuelve una tupla de matrices (array([0, 1, 2]), Index(['red', 'green', 'blue'], dtype='object')) por eso seleccionamos [0]\ndf[\"age_compared_boolean\"] = df[\"age\"] < 18 # Devuelve un valor booleano True False\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick84\"></a>\n# Truco 84: Mostrar menos filas en un DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Este df ocupa demasiado espacio\")\ndf = generate_sample_data()\ndf\n\nprint(\"usando set_option para ahorrar espacio en la pantalla\")\npd.set_option(\"display.max_rows\", 6)\ndf\n\nprint(\"use reset_option para restablecer todos los valores predeterminados\")\npd.reset_option(\"all\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick83\"></a>\n# Truco 83: Corrija los tipos de datos al importar el DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n\n# Paso 1: Permite el tipo de datos de las columnas\ncol_types = df.dtypes.to_frame()\ncol_types.rename({0:\"type\"}, inplace = True, axis = 1)\ncol_types\ncol_types.to_csv(\"trick83data.csv\")\n\n# Paso 2: Vamos a importar los datos anteriores y convertirlos en un diccionario.\ncol_dict = pd.read_csv(\"trick83data.csv\", index_col = 0)[\"type\"].to_dict()\n\n# Paso 3: Edite el diccionario con los tipos de datos correctos\nprint(\"Original dictionary\")\ncol_dict\ncol_dict[\"country\"] = \"category\"\ncol_dict[\"continent\"] = \"category\"\nprint(\"Modified dictionary\")\ncol_dict\n\n# Paso 4: Usa el diccionario para importar los datos\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", dtype=col_dict)\ndf.dtypes\n\n# Nota: tenga en cuenta que puede usar el dict del paso 1 y pegarlo así\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", \\\ndtype=\n{'country': 'category',\n 'beer_servings': 'int64',\n 'spirit_servings': 'int64',\n 'wine_servings': 'int64',\n 'total_litres_of_pure_alcohol': 'float64',\n 'continent': 'category'})\n# Sin embargo, si tiene muchas columnas, esto puede resultar confuso.\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick82\"></a>\n# Truco 82: Seleccionar datos por etiqueta y posición (iloc y loc encadenados)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", index_col=\"country\")\ndf.iloc[15:20, :].loc[:, \"beer_servings\":\"wine_servings\"]\n# iloc se usa para filtrar las filas y loc las columnas","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick81\"></a>\n# Truco 81: Use aplicar (Type) para ver si tiene tipos de datos mixtos\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"customer\":[\"A\", \"B\", \"C\", \"D\", \"E\"], \"sales\":[100, \"100\", 50, 550.20, \"375.25\"]}\ndf = pd.DataFrame(d)\n# Todo parece, pero esta operación bloquea df[\"sales\"].sum(). Tenemos tipos de datos mixtos\ndf.dtypes\ndf[\"sales\"].apply(type) # Wow, podemos ver que tenemos int, str, floats en una columnna\ndf[\"sales\"].apply(type).value_counts() # Ver el número de cada valor\n\ndf[\"sales\"] = df[\"sales\"].astype(float) # Convertir los datos a float\ndf[\"sales\"].sum()\ndf[\"sales\"].apply(type).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick80\"></a>\n# Truco 80: Seleccione varias secciones de columnas de un DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data().T\ncols_str = list(map(str, list(df.columns))) # para que podamos hacer df [\"0\"] como string para el ejemplo\ndf.columns = cols_str\n\n# Usando la concatenación de Pandas\n# si alguna vez se siente confundido acerca del axis = 1 o del axis = 0, simplemente coloque axis = \"columns\" o axis = \"rows\"\npd.concat([df.loc[:, \"0\":\"2\"], df.loc[:, \"6\":\"10\"], df.loc[:, \"16\":\"19\"]], axis = \"columns\") # ------------------> Aquí estamos seleccionando columnas convertidas a strings\n\n# Usando listas\n# Tenga en cuenta que df.columns es una serie con index, por lo que estamos usando index para filtrar # -------------------------> Aquí estamos seleccionando el index de columnas\ndf[list(df.columns[0:3]) + list(df.columns[6:11]) + list(df.columns[16:20])]\n\n# Usando NumPy\ndf.iloc[:, np.r_[0:3, 6:11, 16:20]] # Probablemente la solución más genial","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick79\"></a>\n# Truco 79: Recuento de filas que coinciden con una condición\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\ndf.shape\n\n# Valores absolutos\n(df[\"A\"] < 5).sum()\nprint(\"In the columns A we have {} of rows that are below 5\".format((df[\"A\"] < 5).sum()))\n\n# Porcentaje\n(df[\"A\"] < 5).mean()\nprint(\"In the columns A the values that are below 5 represent {}%\".format((df[\"A\"] < 5).mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick78\"></a>\n# Truco 78: Realice un seguimiento de la procedencia de sus datos cuando utilice varias fuentes\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generemos algunos datos falsos\ndf1 = generate_sample_data()\ndf2 = generate_sample_data()\ndf3 = generate_sample_data()\n# df1.head()\n# df2.head()\n# df3.head()\ndf1.to_csv(\"trick78data1.csv\")\ndf2.to_csv(\"trick78data2.csv\")\ndf3.to_csv(\"trick78data3.csv\")\n\n# Paso 1. Generar lista con el nombre del archivo\nlf = []\nfor _,_, files in os.walk(\"/kaggle/working/\"):\n    for f in files:\n        if \"trick78\" in f:\n            lf.append(f)\n            \nlf\n\n# Puede usar esto en su máquina local\n#from glob import glob\n#files = glob(\"trick78.csv\")\n\n# Paso 2: Crear una nueva columna llamada \"filename\" y el valor es \"file\"\n# Aparte de esto, solo estamos concatenando los diferentes dataframes\ndf = pd.concat((pd.read_csv(file).assign(filename = file) for file in lf), ignore_index = True)\ndf.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick77\"></a>\n# Truco 77: Combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando where)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"genre\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf[\"genre\"].value_counts()\n\n# Paso 1: Cuenta las frecuencias\ntop_four = df[\"genre\"].value_counts().nlargest(4).index\ntop_four\n\n# Paso 2: Actualice el df\ndf_updated = df.where(df[\"genre\"].isin(top_four), other = \"Other\")\ndf_updated[\"genre\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick76\"></a>\n# Truco 76: Filtra en Pandas solo las categorías más grandes.\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.columns = map(str.lower, list(df.columns)) # Convertir encabezados a tipo inferior\ndf.shape\n# Seleccione los 3 mejores géneros\ntop_genre = df[\"genre\"].value_counts().to_frame()[0:3].index\n\n# Ahora vamos a filtrar el df con el género superior\ndf_top = df[df[\"genre\"].isin(top_genre)]\ndf_top\ndf_top.shape\ndf_top[\"genre\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick75\"></a>\n# Truco 75: Cuenta el número de palabras en una serie de Pandas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\", usecols=[\"Title\"])\ndf[\"Words\"] = df[\"Title\"].str.count(\" \") + 1\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick74\"></a>\n# Truco 74: Webscraping usando read_html () y parámetro de coincidencia\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ejecute esto en su máquina local\n# url = \"https://es.wikipedia.org/wiki/Twitter\"\n# tables = pd.read_html(url)\n# len(tables)\n\n# matching_tables = pd.read_html(url, match = \"Followers\")\n# matching_tables[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick73\"></a>\n# Truco 73: Eliminar una columna y almacenarla como una serie separada\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.head()\n\nmeta = df.pop(\"Metascore\").to_frame()\ndf.head()\nmeta.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick72\"></a>\n# Truco 72: Convertir variable continua en categórica (corte y qcut)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.head()\n\n# Usando cortar puede especificar los bordes del contenedor\npd.cut(df[\"Metascore\"], bins = [0, 25, 50, 75, 99]).head()\n\n# Usando qcut puede especificar el número de bins y llenarlos generando aproximadamente el mismo tamaño\npd.qcut(df[\"Metascore\"], q = 3).head()\n\n# cut y qcut aceptan el tamaño de la bandeja de etiquetas\npd.qcut(df[\"Metascore\"], q = 4, labels = [\"awful\", \"bad\", \"average\", \"good\"]).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick71\"></a>\n# Truco 71: Leer datos de un PDF (tabula py)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tendrás que ejecutarlo en tu máquina local\n# Códigos\n# from tabula import read_pdf\n# df = read_pdf(\"test.pdf\", pages = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick70\"></a>\n# Truco 70: Imprime la versión actual de Pandas y sus dependencias\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.__version__)\nprint(pd.show_versions())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick69\"></a>\n# Truco 69: Comprobar si 2 series son \"similares\"\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[1, 2, 3, 4,], \"B\":[1.0, 2.0, 3.0, 4.0], \"C\":[1.00000, 2.00000, 3.00000, 4.000003], \"D\":[1.0, 2.0, 3.0, 4.0], \"E\":[4.0, 2.0, 3.0, 1.0]}\ndf = pd.DataFrame(d)\ndf\n\ndf[\"A\"].equals(df[\"B\"]) # Se requieren tipos de datos idénticos\ndf[\"B\"].equals(df[\"C\"])\ndf[\"B\"].equals(df[\"D\"])\ndf[\"B\"].equals(df[\"E\"]) # y en el mismo orden\n\nprint(pd.testing.assert_series_equal(df[\"A\"], df[\"B\"], check_names=False, check_dtype=False)) # Pasa la afirmación","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick68\"></a>\n# Truco 68: Webscraping usando read_html ()\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tendrá que ejecutar esto en su máquina local\n#apple_stocks = pd.read_html (\"https://finance.yahoo.com/quote/AAPL/history?p=AAPL\")\n# pd.concat ([apple_stocks [0], apple_stocks [1]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick67\"></a>\n# Truco 67: Cree nuevas columnas o sobrescriba usando assing y establezca un título para el DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", usecols=[\"continent\", \"beer_servings\"])\ndf.head()\n\n(df.assign(continent = df[\"continent\"].str.title(),\n           beer_ounces = df[\"beer_servings\"]*12,#                                   esto te permitirá establecer un título\n           beer_galons = lambda df: df[\"beer_ounces\"]/128).query(\"beer_galons > 30\").style.set_caption(\"Average beer consumption\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick66\"></a>\n# Truco 66: Cree un montón de columnas nuevas usando un bucle for y f-strings df [f '{col} _new']\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"d = {\"state\":[\"ny\", \"CA\", \"Tx\", \"FI\"], \"country\":[\"USA\", \"usa\", \"UsA\", \"uSa\"], \"pop\":[1000000, 2000000, 30000, 40000]}\ndf = pd.DataFrame(d)\ndf\n\nint_types = [\"int64\"]\n# creando nuevas columnas\nfor col in df.columns:\n    ctype = str(df[col].dtype)\n    if ctype in int_types:\n        df[f'{col}_millions'] = df[col]/1000000\n    elif ctype == \"object\":\n        df[f'{col}_new'] = df[col].str.upper()\n        # también puedes soltar las columnas\n        df.drop(col, inplace = True, axis = \"columns\")\n        \ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick65\"></a>\n# Truco 65: Seleccione columnas usando f-strings (nuevo en pandas 3.6+)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf\n\ndrink = \"wine\"\n\n# Nos permite iterar rápidamente sobre columnas\ndf[f'{drink}_servings'].to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick64\"></a>\n# Truco 64: Arreglando \"SettingWithCopyWarning\" al crear nuevas columnas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\ndf\n\n# Recibiendo esta desagradable advertencia\nmales = df[df[\"gender\"] == \"Male\"]\nmales[\"abbreviation\"] = \"M\"\n\n# Arreglando el error\nprint(\"Fixing the warning with print\")\nmales = df[df[\"gender\"] == \"Male\"].copy()\nmales[\"abbreviation\"] = \"M\"\nmales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick63\"></a>\n# Truco 63: Calcular el recuento corriente con grupos usando cumcount () + 1\n[Vplver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[\"Car\", \"Truck\", \"Car\", \"Truck\", \"cAr\", \"Car\", \"Truck\", \"Moto\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Fijación de columnas\ndf[\"salesperson\"] = df[\"salesperson\"].str.title()\ndf[\"item\"] = df[\"item\"].str.title()\n\ndf[\"count_by_person\"] = df.groupby(\"salesperson\").cumcount() + 1\ndf[\"count_by_item\"] = df.groupby(\"item\").cumcount() + 1\ndf[\"count_by_both\"] = df.groupby([\"salesperson\",\"item\"]).cumcount() + 1\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick62\"></a>\n# Truco 62: Arreglando \"SettingWithCopyWarning\" al cambiar columnas usando loc\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\ndf\n\n# Recibiendo esta desagradable advertencia\ndf[df[\"gender\"] == \"Male\"][\"gender\"] = 1\ndf[df[\"gender\"] == \"Female\"][\"gender\"] = 0\n\n\nprint(\"Arreglar usando loc\")\ndf.loc[df[\"gender\"] == \"Male\", \"gender\"] = 1\ndf.loc[df[\"gender\"] == \"Female\", \"gender\"] = 0\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick61\"></a>\n# Truco 61: Leer JSON de la web en un DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"https://github.com/justmarkham?tab=repositories\"\n\n\n# ejecútelo en su máquina local\n# df = pd.read_json (url)\n# df = df [df [\"fork\"] == False]\n# df.shape\n# df.head ()\n\n# lc = [\"name\", \"stargazers_count\", \"forks_count\"]\n# df [lc] .sort_values ​​(\"stargazers_count\", asending = False) .head (10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick60\"></a>\n# Truco 60: Creación de totales acumulados con la función cumsum\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\ndf = pd.DataFrame(d)\ndf\n\ndf[\"running_total\"] = df[\"item\"].cumsum()\ndf[\"running_total_by_person\"] = df.groupby(\"salesperson\")[\"item\"].cumsum()\ndf\n\n# otras funciones útiles son cummax (), cummin (), cumprod ()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick59\"></a>\n# Truco 59: Combine la salida de una agregación con el df original usando transform\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"orderid\":[1, 1, 1, 2, 2, 3, 4, 5], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"This is the output we want to aggregate to the original df\")\ndf.groupby(\"orderid\")[\"item\"].sum().to_frame()\n\ndf[\"total_items_sold\"] = df.groupby(\"orderid\")[\"item\"].transform(sum)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick58\"></a>\n# Truco 58: Utilice encabezados y saltos para deshacerse de datos incorrectos o filas vacías durante la importación\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tenemos filas vacías y datos incorrectos\ndf = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\")\ndf\n\n# importando datos correctos\ndf = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\", header = 2, skiprows = [3,4])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick57\"></a>\n# Truco 57: Accediendo a los grupos de un objeto groupby (get_group ())\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\")\ndf\n\ngbdf = df.groupby(\"Genre\")\ngbdf.get_group(\"Horror\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick56\"></a>\n# Truco 56: Aplicar asignaciones o funciones a todo el DF (applymap)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"A\":[\"Male\", \"Female\", \"Female\", \"Male\"], \"B\":[\"x\", \"y\", \"z\", \"A\"], \"C\":[\"male\", \"female\", \"male\", \"female\"], \"D\":[1, 2, 3, 4]})\ndf\n\n# primero usemos applymap para convertir y estandarizar el texto\ndf = df.applymap(lambda x: x.lower() if type(x) == str else x)\n\nmapping = {\"male\":0, \"female\":1}\n\nprint(\"PROBLEMA: Se aplica a todo el DF pero se vuelve a ejecutar None\")\ndf.applymap(mapping.get)\n\nprint(\"Obtenga el resultado correcto pero debe especificar las columnas. Si no desea hacer esto, verifique el siguiente resultado\")\ndf[[\"A\", \"C\"]].applymap(mapping.get)\n\nprint(\"Mapa de aplicación condicional: si se puede mapa --> mapa de lo contrario, devuelve el mismo valor\")\ndf = df.applymap(lambda x: mapping[x] if x in mapping.keys() else x)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick55\"></a>\n# Truco 55: Filtrar un DF con múltiples criterios usando reducir\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf\n\nprint(\"Classical filter hard to read and mantain.\")\ndf[(df[\"continent\"] == \"Europe\") & (df[\"beer_servings\"] > 150) & (df[\"wine_servings\"] > 50) & (df[\"spirit_servings\"] < 60)]\n\nprint(\"You can split it across multiple lines to make it more readable. But it's still hard to read.\")\ndf[\n    (df[\"continent\"] == \"Europe\") & \n    (df[\"beer_servings\"] > 150) & \n    (df[\"wine_servings\"] > 50) & \n    (df[\"spirit_servings\"] < 60)\n]\n\nprint(\"Solution saving criteria as objects\")\n\ncr1 = df[\"continent\"] == \"Europe\"\ncr2 = df[\"beer_servings\"] > 150\ncr3 = df[\"wine_servings\"] > 50\ncr4 = df[\"spirit_servings\"] < 60\n\ndf[cr1 & cr2 & cr3 & cr4]\n\nprint(\"Solution using reduce\")\nfrom functools import reduce\n\n# crea nuestros criterios utilizando lambda\n# lambda toma 2 parámetros, x e y\n# Reducir las combina y para cada cr en el (cr1, cr2, cr3, cr4)\ncriteria = reduce(lambda x, y: x & y, (cr1, cr2, cr3, cr4))\ndf[criteria]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick54\"></a>\n# Truco 54: Calcule la diferencia entre cada fila y la anterior (diff ())\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf[\"A_diff\"] = df[\"A\"].diff() # calcular la diferencia entre 2 filas\ndf[\"A_diff_pct\"] = df[\"A\"].pct_change()*100 # calcula la variación porcentual entre 2 filas\n\n# agrega un poco de estilo\ndf.style.format({\"A_diff_pct\":'{:.2f}%'})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick53\"></a>\n# Truco 53: Barajar las filas de un df (df.sample ())\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\n\ndf.sample(frac = 0.5, random_state = 2)\ndf.sample(frac = 0.5, random_state = 2).reset_index(drop = True) # restablecer el índice después de barajar\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick52\"></a>\n# Truco 52: Hacer parcelas con pandas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\n\ndf.plot(kind = \"line\")\ndf.plot(kind = \"bar\")\ndf.plot(kind = \"barh\")\ndf.plot(kind = \"hist\")\ndf.plot(kind = \"box\")\ndf.plot(kind = \"kde\")\ndf.plot(kind = \"area\")\n\n# las siguientes parcelas requieren x e y\ndf.plot(x = \"A\", y = \"B\", kind = \"scatter\")\ndf.plot(x = \"A\", y = \"B\", kind = \"hexbin\")\ndf.plot(x = \"A\", y = \"B\", kind = \"pie\") # aquí puede pasar solo x pero necesita agregar subparcelas = Verdadero\n\n\n# otras parcelas están disponibles a través de pd.plotting\n# más sobre cómo trazar https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick51\"></a>\n# Truco 51: Concatenar cadenas de 2 columnas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\n# Solución 1: usando str.cat\ndf[\"Name\"].str.cat(df[\"Sex\"], sep = \", \").head()\n\n# usando + signo\ndf[\"Name\"] + \", \" + df[\"Sex\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick50\"></a>\n# Truco 50: Agregación con nombre con varias columnas que pasan tupples (nuevo en pandas 0.25)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\n# Grupo típico\nprint(\"Problem: MultiIndex\")\ndf.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"], \"Survived\": \"mean\"})\n\n# Tenga en cuenta que esto se ha cubierto en 86 y 86 bis.\n# Esta es solo una forma más de hacerlo.\nprint(\"Named aggregation\")\ndf.groupby(\"Pclass\").agg(avg_age = (\"Age\", \"mean\"),\n                        max_age = (\"Age\", \"max\"), \n                        survival_rate = (\"Survived\", \"mean\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick49\"></a>\n# Truco 49: Muestreo con pandas (con reemplazo y pesos)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\": [100, 200, 300, 400, 100], \"W\":[10, 5, 0, 3, 8]}\ndf = pd.DataFrame(d)\ndf\n\n# con reemplazo\ndf.sample(n = 5, replace = True, random_state = 2)\n\n# sumando pesos\ndf.sample(n = 5, replace = True, random_state = 2, weights = \"W\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick48\"></a>\n# Truco 48: Parámetros útiles al usar pd.read_csv ()\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf.head()\ndf.dtypes\n\n# Vamos a importar las columnas country y beer_servings, convertirlas a string y float64 respectevly\n# Importe solo las primeras 5 filas e hilo 0 como nans\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\",\n                    usecols=[\"country\", \"beer_servings\"],\n                    dtype={\"country\":\"category\", \"beer_servings\":\"float64\"},\n                    nrows = 5,\n                    na_values = 0.0)\ndf.head()\ndf.dtypes\n\n# más sobre read_csv en https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick47\"></a>\n# Truco 47: Cree una fila para cada elemento en una lista (explotar)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"equipo\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"jugadores\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n\nprint(\"Tenga en cuenta que tenemos una lista de jugadores para cada equipo. Generemos una fila para cada jugador..\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Usando explotar para generar nuevas filas para cada jugador.\")\ndf1 = df.explode(\"jugadores\")\ndf1\n\nprint(\"Invierta esta operación con groupby y agg\")\ndf[\"Impleado\"] = df1.groupby(df1.index)[\"jugadores\"].agg(list)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick46\"></a>\n# Truco 46: Almacene NaN en un tipo entero con Int64 (no int64)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Serie predeterminada\")\nser1 = pd.Series([10, 20])\nser1\n\nprint(\"Agreguemos un NaN a una serie int64\")\nser1 = pd.Series([10, 20, np.nan])\nser1 # Notice it has been converted to float64\n\nprint(\"Pero si usamos Int64, todo funcionará.\")\nser1 = pd.Series([10, 20, np.nan], dtype = \"Int64\")\nser1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick45\"></a>\n# Truco 45: Cree filas para valores separados por comas en una celda (asigne y explote)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"equipo\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"jugadores\":[\"Ter Stegen, Semedo, Piqué, Lenglet, Alba, Rakitic, De Jong, Sergi Roberto, Messi, Suárez, Griezmann\",\n               \"Courtois, Carvajal, Varane, Sergio Ramos, Mendy, Kroos, Valverde, Casemiro, Isco, Benzema, Bale\"]}\n\nprint(\"Tenga en cuenta que tenemos una lista de jugadores para cada equipo separados por comas. Generemos una fila para cada jugador..\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Observe que nos hemos convertido a algo similar visto en el ejemplo 47..\")\ndf.assign(Players = df[\"jugadores\"].str.split(\",\"))\n\nprint(\"Ahora agregue explotar y listo.\")\ndf.assign(Players = df[\"jugadores\"].str.split(\",\")).explode(\"jugadores\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick44\"></a>\n# Truco 44: Use una variable local dentro de una consulta en pandas (usando @)\n[Vpolver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf\n\n# crear una media de variable local\nmedia = df[\"A\"].mean()\n\n# ahora usemos dentro de una consulta de pandas usando @\ndf.query(\"A > @media\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick43\"></a>\n# Truco 43: Crea una fila para cada elemento en una lista (explotar) !!! Truco 47 duplicado !!!\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parece que este truco está duplicado, pasa al siguiente\n# Decidí quedarme, así que en el futuro no habrá confusión si consulta el material original\n# y este kernel\nd = {\"equipo\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"jugadores\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n\nprint(\"Tenga en cuenta que tenemos una lista de jugadores para cada equipo. Generemos una fila para cada jugador..\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Usando explotar para generar nuevas filas para cada jugador.\")\ndf1 = df.explode(\"jugadores\")\ndf1\n\nprint(\"Invierta esta operación con groupby y agg\")\ndf[\"Impleado\"] = df1.groupby(df1.index)[\"jugadores\"].agg(list)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick42\"></a>\n# Truco 42: Nueva función agregada -> Ultima ()\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"paciente\":[1, 2, 3, 1, 1, 2], \"visitar\":[2015, 2016, 2014, 2016, 2017, 2020]}\ndf = pd.DataFrame(d)\ndf.sort_values(\"visitar\")\n\nprint(\"Hagamos la última visita para cada paciente.\")\ndf.groupby(\"paciente\")[\"visitar\"].last().to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick41\"></a>\n# Truco 41: Categorías ordenadas (de pandas.api.types import CategoricalDtypee)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pandas.api.types import CategoricalDtype\nd = {\"ID\":[100, 101, 102, 103], \"calidad\":[\"malo\", \"muy bueno\", \"bueno\", \"excelente\"]}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Creemos nuestro propio orden categórico.\")\ncat_type = CategoricalDtype([\"malo\", \"bueno\", \"muy bueno\", \"excelente\"], ordered = True)\ndf[\"calidad\"] = df[\"calidad\"].astype(cat_type)\ndf\n\nprint(\"Ahora podemos usar la ordenación lógica.\")\ndf = df.sort_values(\"calidad\", ascending = True)\ndf\n\nprint(\"We can also filter this as if they are numbers. AMAZING.\")\ndf[df[\"calidad\"] > \"malo\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick40\"></a>\n# Truco 40: Estilo de df rápido con ocultar índice () y establecer título ()\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\nprint(\"Original df\")\ndf\n\ndf.style.hide_index().set_caption(\"Estilo df sin índice y título\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick39\"></a>\n# Truco 39: Una codificación en caliente (obtén maniquíes)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\", usecols = [2, 4, 5, 11], nrows = 10)\ndf\n\npd.get_dummies(df) # Observe que podemos eliminar una columna de cada una ya que esta información está contenida en las demás\n\npd.get_dummies(df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick38\"></a>\n# Truco 38: Pandas fecha y hora (muchos ejemplos)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()\ndf = df.sample(500)\ndf[\"Año\"] = df[\"index\"].dt.year\ndf[\"Mes\"] = df[\"index\"].dt.month\ndf[\"Dia\"] = df[\"index\"].dt.day\ndf[\"Hora\"] = df[\"index\"].dt.hour\ndf[\"Minuto\"] = df[\"index\"].dt.minute\ndf[\"Segundo\"] = df[\"index\"].dt.second\ndf[\"Nanosegundo\"] = df[\"index\"].dt.nanosecond\ndf[\"Fecha\"] = df[\"index\"].dt.date\ndf[\"Tiempo\"] = df[\"index\"].dt.time\ndf[\"Tiempo_de_zona\"] = df[\"index\"].dt.timetz\ndf[\"Dia_del_año\"] = df[\"index\"].dt.dayofyear\ndf[\"Semana_del_año\"] = df[\"index\"].dt.weekofyear\ndf[\"Semana\"] = df[\"index\"].dt.week\ndf[\"Dia_de_la_semana\"] = df[\"index\"].dt.dayofweek\ndf[\"Semana_Dia\"] = df[\"index\"].dt.weekday\ndf[\"Nombre_del_Dia_de_la_Semana\"] = df[\"index\"].dt.weekday_name\ndf[\"Trimestre\"] = df[\"index\"].dt.quarter\ndf[\"Dias_en_el_mes\"] = df[\"index\"].dt.days_in_month\ndf[\"Es_Inicio_de_Mes\"] = df[\"index\"].dt.is_month_start\ndf[\"Es_final-de_Mes\"] = df[\"index\"].dt.is_month_end\ndf[\"Es_Inicio_de_Trimestre\"] = df[\"index\"].dt.is_quarter_start\ndf[\"Es_Final_de_Trimestre\"] = df[\"index\"].dt.is_quarter_end\ndf[\"Es_Año_Bisiesto\"] = df[\"index\"].dt.is_leap_year\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick37\"></a>\n# Truco 37: Pandas cortando loc e iloc (6 ejemplos) \n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf\n\n# usando loc -> etiquetas\ndf.loc[0, \"A\"]\n\n# usando iloc -> posición\ndf.iloc[0, 0]\n\n# mezcla de etiquetas y posición con loc\ndf.loc[0, df.columns[0]]\n\n# mezcla de etiquetas y posición con loc\ndf.loc[df.index[0], \"A\"]\n\n# mezcla de etiquetas y posición con iloc\ndf.iloc[0, df.columns.get_loc(\"A\")]\n\n# mezcla de etiquetas y posición con iloc\ndf.iloc[df.index.get_loc(0), 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick36\"></a>\n# Truco 36: Convierte de UTC a otra zona horaria\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = pd.Series(range(1552194000, 1552212001, 3600))\ns = pd.to_datetime(s, unit = \"s\")\ns\n\n# establecer timezome en la zona horaria actual (UTC)\ns = s.dt.tz_localize(\"UTC\")\ns\n\n# establecer zona horaria en otra zona horaria (Chicago) \ns = s.dt.tz_convert(\"America/Chicago\")\ns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick35\"></a>\n# Truco 35: Consulta una columna que tenga espacios en el nombre (usando comillas invertidas)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"columna con espacio\":np.array([1, 2, 3, 4, 5, 6]), \"columna sin espacio\":np.array([1, 2, 3, 4, 5, 6])*2}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"consultar una columna sin espacio\")\ndf.query(\"columna sin espacio > 4\")\nprint(\"consultar una columna con espacio usando comillas invertidas``\")\nprint(\"esto es una columna invertida``\")\ndf.query(\"`columna con espacio` > 8\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick34\"></a>\n# Truco 34: Explore un DataSet con creación de perfiles\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\n\ndf = generate_sample_data()\n\ndf\n\nprint(\"Generación de informes con perfiles de Pandas\")\ndf.profile_report()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick33\"></a>\n# Truco 33: Opciones de visualización de Pandas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# usar pd.describe_option() para ver todo\n# max_rows\n# max_columns\n# max_colwidth\n# precision\n# date_dayfirst\n# date_yearfirst\n\ndf = generate_sample_data_datetime()[:10].reset_index()\ndf[\"sales\"] = df[\"sales\"].astype(\"float\")\ndf\n\npd.set_option(\"display.max_rows\",5)\npd.set_option(\"display.max_columns\",3)\npd.set_option('display.width', 1000)\npd.set_option('display.date_dayfirst', True)\npd.describe_option()\n\npd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n#pd.reset_option('display.width') # restaurar uno por uno","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick32\"></a>\n# Truco 32: Filtrar un DF con consulta y evitar variables intermedias\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:10]\ndf[\"A\"] = pd.Series([\"APP\", \"GOO\", \"APP\", \"GOO\", \"MIC\", \"MIC\", \"APP\", \"GOO\", \"MIC\", \"APP\"])\ndf.rename(columns = {\"A\":\"stock\"}, inplace = True)\nprint(\"DF Original\")\ndf\n\nprint(\"Filtrar datos usando variables intermedias\")\ntemp = df.groupby(\"stock\").mean()\ntemp \n\nfv = temp[\"B\"].sort_values(ascending = False)[1] # filtrar por el segundo gran. De esta forma cada vez que generamos datos de muestra tendremos un resultado\ntemp[temp[\"B\"] < fv]\n\nprint(\"Filtrar mediante un query\")\ndf.groupby(\"stock\").mean().query(\"B < {}\".format(fv))\ndf.groupby(\"stock\").mean().query(\"B < @fv\")\ndf.groupby(\"stock\").mean().query(\"B < 10\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick31\"></a>\n# Truco 31: Ver todas las columnas de un gran DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n\ndf = generate_sample_data()\ndf1 = df.copy(deep = True)\ndf = df.append(df1)\n\nprint(\"Imagina que tenemos un gran DF donde podemos ver todas las columnas ...\")\ndf.T.head() # Nosotras estamos transponiendo SOLO PARA CREAR UN DF GIGANTE\n\n# Solución 1\nprint(\"Solución 1 usando pd.set_option display.max_columns\")\npd.set_option(\"display.max_columns\", None)\ndf.T.head()\npd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n\n# Solución 2\nprint(\"Otra solución inteligente usando Traspose\")\ndf.T.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick30\"></a>\n# Truco 30: Pandas se fusionan -> vea de dónde vienen las columnas (indicador = True)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf1 = df.copy(deep = True)\ndf1 = df1.drop([0, 1, 2], axis = \"rows\") # suelte un índice solo para ver el funcionamiento de ejemplo\ndf.head()\ndf1.head()\n\npd.merge(df, df1, how = \"left\", indicator = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick29\"></a>\n# Truco 29: Acceda a NumPy dentro de Pandas (sin importar NumPy como np)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pandas se basa en numpy, por lo que podemos acceder a todas las funciones de numpy de pandas\npd.np.random.rand(2, 3)\npd.np.nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick28\"></a>\n# Truco 28: Agregando por múltiples columnas (usando agg)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\nprint(\"DF Original\")\ndf\n\nprint(\"Groupby contiene beer_servings\")\ndf.groupby(\"continent\")[\"beer_servings\"].mean()\n\nprint(\"Usando agg para pasar múltiples funciones\")\ndf.groupby(\"continent\")[\"beer_servings\"].agg([\"mean\", \"count\"])\n\nprint(\"Usar describe sobre un groupby object\")\ndf.groupby(\"continent\")[\"beer_servings\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick27\"></a>\n# Truco 27: Agregación sobre series temporales (remuestreo)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()\n\nprint(\"DF Original\")\ndf\nprint(\"Volvamos a resample/groupby por mes\")\ndf.resample(\"M\")[\"sales\"].sum()\n\nprint(\"Volvamos a resample/groupby por día\")\ndf.resample(\"D\")[\"sales\"].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick26\"></a>\n# Truco 26: Formatear diferentes columnas de un DF (usando diccionarios)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()[:10]\ndf.rename(columns = {\"index\":\"time\"}, inplace = True)\ndf[\"sales_100\"] = df[\"sales\"]*100\nprint(\"DF Original\")\ndf.head()\n\n# declarar un dictado de formato: individual para cada columna\nfd = {\"time\":\"{:%d/%m/%y}\", \"sales\":\"${:.2f}\", \"customers\":\"{:,}\"}\ndf.style.format(fd)\ndf\n\n# añadir mas informacion\n(df.style.format(fd)\n .hide_index()\n .highlight_min(\"sales\", color =\"red\")\n .highlight_max(\"sales\", color =\"green\")\n .background_gradient(subset = \"sales_100\", cmap =\"Blues\")\n .bar(\"customers\", color = \"lightblue\", align = \"zero\")\n .set_caption(\"Un DF con diferentes estilos\")\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick25\"></a>\n# Truco 25: 3 formas de cambiar el nombre de las columnas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head(2)\n\n# Solucion 1\ndf.rename({\"A\":\"col_1\", \"B\":\"col_2\"}, axis = \"columns\", inplace = True)\ndf.head(2)\n\n# Solucion 2\ndf.columns = [\"col1\", \"col2\", \"col3\", \"col4\",\"col5\", \"col6\", \"col7\"] # la lista debe ser igual al numero de columnas\ndf.head(2)\n\n# Solucion 3\ndf.columns = df.columns.str.title() # aplicar cualquier método de cadena a los nombres de columnas\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick24\"></a>\n# Truco 24: Copie datos de Excel a Pandas rápidamente (read_clipboard ())\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tendrá que verificar esto en su máquina local\n# Útil para importar rápidamente\n# Paso 1: copie una tabla de la hoja de Excel usando ctrl + c (al portapapeles)\n# Paso 2: ejecuta este comando\n# df = pd.read_clipboard()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick23\"></a>\n# Truco 23: Complete los valores faltantes en los datos de series de tiempo (interpolar ())\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"col1\":[100, 120 ,140, np.nan, 160], \"col2\":[9, 10, np.nan, 7.5, 6.5]}\ndf = pd.DataFrame(d)\ndf.index = pd.util.testing.makeDateIndex()[0:5]\nprint(\"DF Original\")\ndf\nprint(\"DataFrame después de interpolar\")\ndf.interpolate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick22\"></a>\n# Truco 22: Crea DataFrames para probar\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Contiene valores aleatorios\")\ndf1 = pd.util.testing.makeDataFrame() # Contiene valores aleatorios\ndf1\nprint(\"Contiene valores perdidos\")\ndf2 = pd.util.testing.makeMissingDataframe() # Contiene valores perdidos\ndf2\nprint(\"Contiene valores de DateTime\")\ndf3 = pd.util.testing.makeTimeDataFrame() # Contiene valores de fecha y hora\ndf3\nprint(\"Contiene valores mixtos\")\ndf4 = pd.util.testing.makeMixedDataFrame() # Contiene valores mixtos\ndf4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick21\"></a>\n# Truco 21: Divide una columna de cadena en varias columnas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"name\":[\"John Artur Doe\", \"Jane Ann Smith\", \"Nico P\"], \"location\":[\"Los Angeles, CA\", \"Washington, DC\", \"Barcelona, Spain\"]}\ndf = pd.DataFrame(d)\ndf\n\ndf[[\"first\", \"middle\", \"last\"]] = df[\"name\"].str.split(\" \", expand = True)\ndf[\"city\"] = df[\"location\"].str.split(\",\", expand = True)[0]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick20\"></a>\n# Truco 20: Crea columnas de DateTime a partir de varias columnas\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"day\":[1, 2, 10 ,25, 12], \"month\":[1, 2, 4, 5, 6], \"year\":[2000, 2001, 2010, 2015, 2020]}\ndf = pd.DataFrame(d)\ndf[\"date\"] = pd.to_datetime(df[[\"day\", \"month\", \"year\"]])\ndf\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick19\"></a>\n# Truco 19: Muestra el uso de memoria de un df y cada columna\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()\ndf.columns = [\"date\", \"sales\", \"customers\"]\ndf\n\nprint(\"Muestra el uso global de la memoria del DF\")\ndf.info(memory_usage = \"deep\")\nprint()\nprint(\"Muestra el uso de la memoria de cada columna.\")\ndf.memory_usage(deep = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick18\"></a>\n# Truco 18: Leer y escribir en un archivo comprimido (csv.zip)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\n\nprint(\"Escribir datos en un archivo csv.zip\")\ndf.to_csv(\"trick18data.csv.zip\")\n\nprint(\"Eliminando DF\")\ndel df\n\nprint(\"Importación de datos de un archivo csv.zip\")\ndf = pd.read_csv(\"/kaggle/working/trick18data.csv.zip\", index_col=0)\ndf.head()\n\n# otros archivos de compresión compatibles .gz, .bz2, .xz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick17\"></a>\n# Truco 17: Seleccione varias filas y columnas con \"loc\"\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\nprint(\"DF Original\")\ndf\n\nprint(\"Usando una slice (inclusive)\")\ndf.loc[0:4, \"A\":\"E\"]\n\nprint(\"Usando una lista\")\ndf.loc[[0,4], [\"A\",\"E\"]]\n\nprint(\"Usando una condición\")\ndf.loc[df[\"A\"] > 10, [\"A\",\"E\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick16\"></a>\n# Truco 16: Convierta valores continuos en categóricos (cut())\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf[\"A\"] = df[\"A\"] + 5\ndf.rename(columns = {\"A\":\"age\"}, inplace = True)\ndf.sample(5)\n\ndf[\"age_groups\"] = pd.cut(df[\"age\"], bins = [0, 18, 65, 99], labels = [\"kids\", \"adult\", \"elderly\"])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick15\"></a>\n# Truco 15: Remodelar una MultiIndex DF (unstack ())\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(\"DF Original\")\ndf.head()\n\nprint(\"Groupby y crear un DF MultiIndex\")\nprint(\"Observe que tenemos un DF con MultiIndex (Sex and Pclass)\")\ndf.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().to_frame()\n\nprint(\"Remodelar usando unstack\")\nprint(\"Ahora podemos interactuar con el como con un DF normal\")\ndf.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().unstack()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick14\"></a>\n# Truco 14: Creando juguete DF (3 métodos)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metodo 1: de un dictado\npd.DataFrame({\"A\":[10 ,20], \"B\":[30, 40]})\n\n# Metodo 2: usando numpy\npd.DataFrame(np.random.rand(2, 3), columns = list(\"ABC\"))\n\n# Metodo 3: usando pandas integrando funcionalidades\npd.util.testing.makeMixedDataFrame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick13\"></a>\n# Truco 13: Evita la serie de listas TRAP\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[1, 2, 3], \"B\":[[10, 20], [40, 50], [60, 70]]}\ndf = pd.DataFrame(d)\nprint(\"Observe que la columna B tiene listas de valores\")\ndf\nprint(\"Conviértelo a serie normal\")\ndf_ = df[\"B\"].apply(pd.Series)\ndf_\n\nprint(\"Unir a los 2 DF\")\npd.merge(df, df_, left_index = True, right_index = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick12\"></a>\n# Truco 12: Fusionar conjuntos de datos y verificar la unicidad\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:10]\ndf1 = df.copy(deep = True)\ndf = df.drop([0, 1, 2])\ndf1 = df1.drop([8, 9])\ndf\ndf1\n\ndf_one_to_one = pd.merge(df, df1, validate = \"one_to_one\")\ndf_one_to_one\n\ndf_one_to_many = pd.merge(df, df1, validate = \"one_to_many\")\ndf_one_to_many\n\ndf_many_to_one = pd.merge(df, df1, validate = \"many_to_one\")\ndf_many_to_one\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick11\"></a>\n# Truco 11: Cambie el nombre de todas las columnas con el mismo patrón\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.columns = [\"Passenger ID\", \"Survived\", \"Pclass\", \"Name         \", \"Sex\", \"Age\", \"Sib SP\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"] # creando nombres de columna para el ejemplo\ndf\ndf1 = df.copy(deep = True)\n\nprint(\"Reemplazar todos los espacios con undescore y convertir a menor\")\nprint(\"Observe que la columna Passenger y Sib SP ahora tiene un guión bajo\")\ndf.columns = df.columns.str.replace(\" \", \"_\").str.lower()\ndf.head()\n\nprint(\"Quite la parte blanca final (al final) y conviértala en menor\")\nprint(\"Observe que la columna Passenger y Sib SP ahora tiene un guión bajo\")\ndf1.columns = df1.columns.str.lower().str.rstrip()\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick10\"></a>\n# Truco 10: Comprueba la igualdad de 2 series\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[[\"A\", \"B\"]][:5]\ndf[\"A\"] = pd.Series([15, 15, 18, np.nan, 12])\ndf[\"B\"] = pd.Series([15, 15, 18, np.nan, 12])\ndf\n\nprint(\"No use  ==, no maneja NaN correctamente\")\nprint(\"Observe que el elemento 4 de cada lista es np.nan pero == aún devuelve False\")\ndf[\"A\"] == df[\"B\"]\n\nprint(\"Usando iguales. Ahora obtenemos True, por lo que las 2 series son iguales\")\ndf[\"A\"].equals(df[\"B\"])\n\nprint(\"Igual también funciona para DF\")\ndf1 = df.copy(deep = True)\ndf.equals(df1)\n\nprint(\"== de DF tiene el mismo problema que para la serie\")\ndf == df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick9\"></a>\n# Truco 9: ¡Reduzca el uso de memoria de un DF al importar! ¡¡¡Truco 83 duplicado !!!\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"])\ndf.dtypes\ndf.memory_usage(deep = True)\n\nprint(\"Importando solo unas pocas columnas y convirtiendo al tipo de archivo adecuado\")\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"], \\\n                dtype = {\"Genre\":\"category\", \"Metascore\":\"Int64\", \"Year\":\"int8\"})\ndf.dtypes\ndf.memory_usage(deep = True) # observe cómo el género y el año consumen ahora menos memoria\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick8\"></a>\n# Truco 8: ¡Usar glob para generar un DF a partir de varios archivos! ¡¡¡Truco 78 duplicado !!!\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# generemos datos falsos \ndf1 = generate_sample_data()\ndf2 = generate_sample_data()\ndf3 = generate_sample_data()\n# df1.head()\n# df2.head()\n# df3.head()\ndf1.to_csv(\"trick8data1.csv\", index = False)\ndf2.to_csv(\"trick8data2.csv\", index = False)\ndf3.to_csv(\"trick8data3.csv\", index = False)\n\n# Paso 1 generar lista con el nombre del archivo\nlf = []\nfor _,_, files in os.walk(\"/kaggle/working/\"):\n    for f in files:\n        if \"trick8data\" in f:\n            lf.append(f)\n            \nlf\n\n# Puedes ustar esto en tu maquina local\n#de glob importar glob\n#archivos = glob(\"trick8.csv\")\n\n# Paso 2: hacemos lo mismo que en el truco 78 excepto que no creamos una nueva columna del origen de las filas (archivo del que provienen)\ndf = pd.concat((pd.read_csv(file) for file in lf), ignore_index = True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick7\"></a>\n# Truco 7: Manejo de valores perdidos (NaN)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.util.testing.makeMissingDataframe().reset_index() # contiene valores perdidos\ndf.rename(columns = {\"index\":\"A\"})\ndf1 = df.copy(deep = True)\ndf\n\nprint(\"Calcule el % de valores perdidos en cada fila\")\ndf.isna().mean() # calcular el porcentaje de valores perdidos en cada fila\nprint(\"Descartando cualquier columna que tenga valores perdidos. Solo quedará la columna A\")\ndf.dropna(axis = \"columns\") # soltar cualquier columna que haya perdido valor\nprint(\"Descartando cualquier fila que tenga valores perdidos.\")\ndf1.dropna(axis = \"rows\") # soltar cualquier fila que haya perdido valor\nprint(\"Columna de caída donde los valores perdidos están por encima de un threshold\")\ndf.dropna(thresh = len(df)*0.95, axis = \"columns\") # soltar cualquier fila que haya perdido valor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick6\"></a>\n# Truco 6: Dividir un DF entre 2 subconjuntos random \n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf_1 = df.sample(frac = 0.7)\ndf_2 = df.drop(df_1.index) # solo funciona si el indice df es unico \n\ndf.shape\ndf_1.shape\ndf_2.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick5\"></a>\n# Truco 5: Convertir números almacenados como strings (coerce)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"col1\":[\"1\", \"2\", \"3\", \"stuff\"], \"col2\":[\"1\", \"2\", \"3\", \"4\"]}\ndf = pd.DataFrame(d)\ndf.astype({\"col2\":\"int\"}) # esto fallara para col1 --> ValueError: invalid literal for int() with base 10: 'stuff'\n\nprint(\"Observe que ahora los Stuff se convirtieron en NaN\")\ndf.apply(pd.to_numeric, errors = \"coerce\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick4\"></a>\n# Truco 4: Seleccionar columnas por tipo\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()[:10].reset_index()\ndf[\"string_col\"] = list(\"ABCDEABCDE\")\ndf[\"sales\"] = df[\"sales\"].astype(\"float\")\nprint(\"DF Original\")\ndf\n\nprint(\"Seleccionar columnas numéricas\")\ndf.select_dtypes(include = \"number\")\n\nprint(\"Seleccionar columnas de string\")\ndf.select_dtypes(include = \"object\")\n\nprint(\"Seleccionar columnas de datetime\")\ndf.select_dtypes(include = [\"datetime\", \"timedelta\"])\n\nprint(\"Seleccionar varios\")\ndf.select_dtypes(include = [\"number\", \"object\", \"datetime\", \"timedelta\"])\n\nprint(\"Seleccione pasando los dtypes que necesita\")\ndf.select_dtypes(include = [\"int8\", \"int16\", \"int32\", \"int64\", \"float\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick3\"></a>\n# Truco 3: Filtrar un DF por múltiples condiciones (Usando isin and inverse)\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\ndf[\"A\"] = [1, 2, 3, 4, 5]\n\nprint(\"Filtrar usando múltiples |\")\ndf[(df[\"A\"] == 1) | (df[\"A\"] == 3)]\n\nprint(\"Filtrar usando isin\")\ndf[df[\"A\"].isin([1, 3])]\n\nprint(\"Invertir usando ~ (ctrl + alt + 4)\")\ndf[~df[\"A\"].isin([1, 3])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick2\"></a>\n# Truco 2: Orden inverso de una DF\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\ndf\n\nprint(\"Orden de columna inverso\")\ndf.loc[:, ::-1]\n\nprint(\"Orden de filas inverso\")\ndf.loc[::-1]\n\nprint(\"Invertir el orden de las filas y restablecer el index\")\ndf.loc[::-1].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick1\"></a>\n# Truco 1: Añadir prefijo o sufijo\n[Volver a la tabla de contenido](#table_of_contents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\nprint(\"DF Original\")\ndf\n\nprint(\"Agregar prefijo\")\ndf.add_prefix(\"1_\")\n\nprint(\"Agregar sufijo\")\ndf.add_suffix(\"_Z\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# El fin\n# Muchas gracias. Si lo terminaste hasta el final haz aprendido mucho sobre Pandas."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}