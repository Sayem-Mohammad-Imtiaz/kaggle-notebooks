{"cells":[{"metadata":{"_uuid":"9fd1d18f2841e8db6dca899c56a358fa63b4b383"},"cell_type":"markdown","source":"# First GOP Debate Twitter Sentiment  \nComparing the use of AutoML and Deep Learning Architectures (Bi-Directional LSTM) to predict Twitter Sentiments  \n\n**Sentiment Analysis**: the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral."},{"metadata":{"trusted":true,"_uuid":"08add6afc3d0d8747a68ff9884cbf7ff49fdc79e"},"cell_type":"code","source":"from __future__ import division\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nimport re\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('white')\nplt.style.use('fivethirtyeight')","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"36820e868274aa42bab053251a1b918e4c1a9178"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix as cf\nfrom sklearn.metrics import accuracy_score","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"07897fbef89227c0373240587af371d1cc5fecc5"},"cell_type":"code","source":"from tpot import TPOTClassifier\nfrom deap import creator\nfrom sklearn.model_selection import cross_val_score","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"20be684a5f219f3f9f374c2d79c821f45cf1a3c8"},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"aed4af77349a42c9027817069cbb5a21b6def182"},"cell_type":"code","source":"data = pd.read_csv('../input/Sentiment.csv')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7a3900f1039c0c9ef19d6718ca4bd1f3adc0621"},"cell_type":"code","source":"data.head()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"31d803449a5272127c60baf00060fe9b959dde4a"},"cell_type":"markdown","source":"### Data Discovery"},{"metadata":{"_uuid":"d2ee0be89fb09e279a54a4c3b43ea11c4ba51c08"},"cell_type":"markdown","source":"Number of Candidate Tweet Mentions"},{"metadata":{"trusted":true,"_uuid":"798aaf183ba4465ee48352d1248bc49ce78a5ab2"},"cell_type":"code","source":"data.groupby(['candidate']).size().drop('No candidate mentioned').sort_values().plot(kind = 'barh')","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"b94999843a3d6e8140c6250d3fabeba970df1f9a"},"cell_type":"markdown","source":"Number of candidate mentions cross-referenced to the sentiments of the tweets."},{"metadata":{"trusted":true,"_uuid":"786d9941b29a39ef3897d72745a174dbb2fd9cce"},"cell_type":"code","source":"pd.crosstab(data.candidate, data.sentiment).drop('No candidate mentioned').sort_values('Negative', ascending = False)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"10ae281f11055b2ae6cf1b4988b332eae6b9fbb5"},"cell_type":"markdown","source":"Tweets per user timezone"},{"metadata":{"trusted":true,"_uuid":"2095456793dda8efc4e39c43588119bea57d68c7"},"cell_type":"code","source":"data.groupby('user_timezone').size().sort_values(ascending = False)[:10].plot(kind='barh')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0093a59817fdab9c078770e396347d6562f130f"},"cell_type":"code","source":"pd.crosstab(data.subject_matter, data.candidate)\\\n.drop('No candidate mentioned', axis = 1)\\\n.drop('None of the above').sort_values('Donald Trump', ascending = False)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"eec86e9e68a7eb427163554d8f78780c1d01dafa"},"cell_type":"markdown","source":"### Clean Data"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ca0f708081956751caec6630f2186d95c24e2ccd"},"cell_type":"code","source":"# Keep the sentiments only\ndata = data[['text','sentiment']]","execution_count":10,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"3f37db8f904beea4c13edca48081a82ddfe107a8"},"cell_type":"code","source":"# Lowercase, clean non-alphanumeric characters and remove 'rt's\ndata['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x.lower()))\\\n.str\\\n.replace('rt', '') ","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"8ab715abc9a18096e3705bce9f7484a883cbb21c"},"cell_type":"markdown","source":"### Tokenize"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"080333631638a94ee5995be1c13b17db9b16e654"},"cell_type":"code","source":"max_features = 2000\ntokenizer = Tokenizer(num_words=max_features, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\n\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)\ny = pd.get_dummies(data['sentiment'])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9520043308da980a1b111880c3ff7b4d7620de7"},"cell_type":"code","source":"X.shape","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e7d68b39988e3183a37eb0a50d04f028d7f56f7"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"a4e39d874138a89f303443e1fa79cd3f51873707"},"cell_type":"markdown","source":"# Auto-Machine Learning using TPOT"},{"metadata":{"trusted":true,"_uuid":"2ce6932afb5330760e6d2f8f288697fbf1d5f9ce"},"cell_type":"code","source":"tpot = TPOTClassifier(generations=5, max_time_mins=15, max_eval_time_mins=0.04, population_size=50, verbosity = 2)\ntpot.fit(X_train, np.argmax(y_train.as_matrix(), axis = 1))\nprint(tpot.score(X_test, np.argmax(y_test.as_matrix(), axis = 1)))","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"e8b571ddb6a9600dd2fe027d8959bd032ccc5e53"},"cell_type":"markdown","source":"### Check Which Models were Evaluated"},{"metadata":{"trusted":true,"_uuid":"13a93fdd3167d034b3737b280098966606b155b0"},"cell_type":"code","source":"pd.DataFrame(dict(list(tpot.evaluated_individuals_.items()))).T\\\n.replace([np.inf, -np.inf], np.nan)\\\n.dropna()\\\n.drop('generation', axis = 1)\\\n.sort_values('internal_cv_score', ascending = False)\\\n.head()","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"14076b4271e19c6646f7542e5c95362e18a86aa6"},"cell_type":"markdown","source":"### Prediction Score Using TPOT"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5ff84add567e0806c859a4244a80f51237c4f8af"},"cell_type":"code","source":"y_pred_tpot = tpot.predict(X_test)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d19daa35d4968725f994af6f2d0ed05674c0064"},"cell_type":"code","source":"conf_mat = cf(np.argmax(y_test.as_matrix(), axis = 1), y_pred_tpot)\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"0e621631b4c59ef23c89da819f526ac3eff0420b"},"cell_type":"markdown","source":"# Using Deep Learning (Recurrent Neural Networks)"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"fe0365196ae731f91d55af8904125b91bbf0a0de"},"cell_type":"code","source":"# Deep Learning Architecture Parameters\ninput_dim = 2000\noutput_dim = 128\ndropout = 0.8\nrec_dpout = 0.8\nLSTM_units = 256\n\n# Model fit Parameters\nbatch_size = 200\nepochs = 30\nval_split = 0.3\ndense_out = 3 # three categories","execution_count":22,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"1b4a1c0e3b07c2d25d2a7b7bdff6c9b8fc30de0d"},"cell_type":"code","source":"model = Sequential()\n\nmodel.add( Embedding(input_dim=input_dim, output_dim = output_dim, input_length = X.shape[1]))\nmodel.add(SpatialDropout1D(dropout))\nmodel.add(LSTM(LSTM_units, dropout = dropout, recurrent_dropout=rec_dpout,return_sequences=True))\nmodel.add(LSTM(LSTM_units, dropout = dropout, recurrent_dropout=rec_dpout, return_sequences=False))\nmodel.add( Dense(dense_out, activation = 'softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e8104b50f7d511eb8978aa7d15607c7a62d46ff"},"cell_type":"code","source":"print(model.summary())","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"632ad63b500388785dce17927a16e08242aab669"},"cell_type":"markdown","source":"### Train 2-LSTM Model"},{"metadata":{"trusted":true,"_uuid":"7e8ea850b0e6d42cf4cf3c3ada55f56a57759dc4"},"cell_type":"code","source":"\nhistory = model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, validation_split=val_split)\n\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86f8eccad5c31acf85e1abfc91ef2d00d5a435ff"},"cell_type":"code","source":"score,acc = model.evaluate(X_test, y_test, verbose = 2, batch_size = batch_size)\nprint(\"score: %.2f\" % (score))\nprint(\"acc: %.2f\" % (acc))","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08fd7b4a6cb12c5ac40a380bae35937362270a16"},"cell_type":"code","source":"y_pred = model.predict(X_test)\n\nconf_mat = cf(np.argmax(y_test.as_matrix(), axis = 1), np.argmax(y_pred, axis = 1))\n\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"c85706d5bbcfa7bc3f396a7ca19c95c0bfd67872"},"cell_type":"markdown","source":"# Conclusion  \n2-LSTM worked better than AutoML which swept through 1008 different kinds of predictive models."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}