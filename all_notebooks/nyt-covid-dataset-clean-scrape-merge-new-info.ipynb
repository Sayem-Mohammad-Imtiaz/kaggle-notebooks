{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Background\n\nData gathered from the [NYT github page](https://github.com/nytimes/covid-19-data), [USDA](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697), and the US Census [population](https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/) and [land area](https://www.census.gov/geographies/reference-files/2010/geo/state-area.html) pages.\n\nThis notebook is the first in a series of analyzing covid data from head to toe. The goals for this notebook include:\n\n* Importing data as gathered by the NYT\n* Merging covid data with geographical and census datasets\n\nThe notebook is divided into four sections:\n\n1. Setup: importing of libraries, creating helper functions\n2. County Data: reading and merging all data related to counties including mask useage survey results, covid cases by county, county populations\n3. State Data: reading and merging all data related to states including covid cases by state, state populations, state geographical data\n4. Save to DB: saving the newly created `county_time`, `df_county`, and `df_state` dataframes to an sqlite database.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## NYT Methodology\n\nThe NYT used mask-survey responses to estimate mask-use at the county level.\n\n> To transform raw survey responses into county-level estimates, the survey data was weighted by age and gender, and survey respondents’ locations were approximated from their ZIP codes. Then estimates of mask-wearing were made for each census tract by taking a weighted average of the 200 nearest responses, with closer responses getting more weight in the average. These tract-level estimates were then rolled up to the county level according to each tract’s total population.\n> \n> By rolling the estimates up to counties, it reduces a lot of the random noise that is seen at the tract level. In addition, the shapes in the map are constructed from census tracts that have been merged together — this helps in displaying a detailed map, but is less useful than county-level in analyzing the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Setup","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # dataframe analysis and manipulation\nimport numpy as np # mostly for np.nan\n\nfrom bs4 import BeautifulSoup # for scraping\nimport requests # for downloading html files","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def github_link_formatter(url):\n    '''\n    Formats a given direct github-file url so it can be used with pd.read_excel()\n    '''\n    url = url.replace('github.com','raw.githubusercontent.com')\n    url = url.replace('/blob','')\n    \n    return url","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def list_diff(list1,list2):\n    '''\n    Finds what is missing from, or what is different between, the two lists.\n    \n    return\n    ------\n    list_difference: list\n    '''\n    list_difference = {}\n    \n    if len(list1) > len(list2):\n        bigger = list1\n        smaller = list2\n        small_list = 'list2'\n    else:\n        bigger = list2\n        smaller = list1\n        small_list = 'list1'\n        \n    for item in bigger:\n        if item not in smaller:\n            list_difference[item] = f'missing from {small_list}'\n\n    return list_difference","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# County Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Goals:__\n\n* Merge mask dataset with latest county cases and populations\n* Create a separate covid cases dataset for time domain ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Mask Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mask = pd.read_csv(\"../input/nytimes-covid19-data/mask-use/mask-use-by-county.csv\")\ndf_mask.columns = df_mask.columns.str.lower()\ndf_mask.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mask Mandate Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In order to find out the effect of masks on corona spread, it would be useful to know when masks were mandated. To do this, we gathered data from [AARP](https://www.aarp.org/health/healthy-living/info-2020/states-mask-mandates-coronavirus.html) and [CNN](https://www.cnn.com/2020/06/19/us/states-face-mask-coronavirus-trnd/index.html). In situations when the date was different, the earliest date was taken. `Type` includes tags for description of mandate currently in effect.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"url = github_link_formatter('https://github.com/pomkos/nyt-covid-data/blob/master/data/added_data/mask_mandates.xlsx')\n\ndf_mand = pd.read_excel(url, skiprows=2)\ndf_mand.columns = df_mand.columns.str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mand['type'] = df_mand['type'].str.lower()\ndf_mand['type_split'] = df_mand['type'].str.split(',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_mand['type_split']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def who_exempt(cell):\n    if pd.isna(cell):\n        return 'no mandate'\n    elif 'children' in cell:\n        return 'child exempt'\n    elif 'toddler' in cell:\n        return 'toddler exempt'\n    else:\n        return 'no exemptions'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mand['children_toddlers_none'] = df_mand['type'].apply(who_exempt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mand['month_mandate'] = df_mand['date'].dt.month\ndf_mand['month_mandate'] = df_mand['month_mandate'].fillna('no mandate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mand.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"States implemented mask orders at different times, it may be more useful to look at blocks of times.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mandate_when(x):\n    if pd.isna(x):\n        return 'No Mandate'\n    elif x<dt.datetime.strptime('20200515','%Y%m%d'):\n        return 'Before May 15'\n    elif x>dt.datetime.strptime('20200715','%Y%m%d'):\n        return 'After Jul 15'\n    else:\n        return 'In Between'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mand['mandate_when'] = df_mand['date'].apply(mandate_when)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mand.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Covid Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"county_time = pd.read_csv(\"../input/nytimes-covid19-data/us-counties.csv\",parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_time = county_time.astype({\n    'county':str,\n    'fips':float,\n    'cases':int,\n    'deaths':int\n})","execution_count":null,"outputs":[]},{"metadata":{"comments":[{"body":[{"created":"2020-08-18T20:36:48.68Z","creator":{"image":"https://avatars3.githubusercontent.com/u/8731022?v=4","name":"pomkos","user":"pomkos"},"edited":true,"value":"This should be merged with state/fips/county and saved to db as time series"}],"id":"anno/0","resolved":true,"total":1}],"trusted":true},"cell_type":"code","source":"# Rename columns\ncounty_time.columns = ['date','county','state','fips','covid_cases','covid_deaths']\n# Rearrange columns\ncounty_time = county_time[['date','state','county','fips','covid_cases','covid_deaths']]\ncounty_time.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On a previous (now removed) merging of the NYT `df_mask` and NYT `county_time` datasets we found that the `df_mask` dataset was missing some counties. To double check what these counties are, the [USDA link](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697) was scraped for all fips, name, and state data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## What was Missing?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"response = requests.get(\"https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697\")\nsoup = BeautifulSoup(response.content)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"table_tag = soup.find(class_='data')\n\ncounty_scrape = pd.DataFrame(columns=['fips','county','state'])\n\nfor tr in table_tag.find_all('tr')[1:]:\n    tds = tr.find_all('td')\n    d = pd.DataFrame(data = {'fips':[tds[0].text], 'county':[tds[1].text], 'state':[tds[2].text]})\n    county_scrape = county_scrape.append(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_scrape = county_scrape.reset_index(drop=True)\ncounty_scrape = county_scrape.astype({\n    'fips':int,\n    'county':str,\n    'state':'category'\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_scrape.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = list_diff(county_scrape['county'].unique(),county_time['county'].unique())\nmissing_df = pd.DataFrame.from_dict(missing,orient='index')\nscraped = county_scrape.set_index('county')\nmissing_df = missing_df.sort_index().reset_index()\nmissing_from_scrape = scraped.merge(missing_df, left_on='county',right_on='index')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"missing_from_scrape.groupby('state').count().sort_values('fips',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The vast majority of missing counties are from Virginia and Alaska.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"missing_from_scrape[(missing_from_scrape['state']=='AS') ] # repeated for other states","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The reasons for missing counties include:\n\n* Virginia's missing counties are all cities\n* Alaska: unclear why\n* Louisiana: unincorporated communities or parishes\n* MO: De Kalb has a population of 220, is part of St. Joseph statistical area.\n* MO: St. Francois has a population of 65k, but the county seat is in Farmington. The rest are similar, with the county seat being in another county.\n* NY: boroughs of NYC, St. Lawrence has county seat in Canton\n* AS: Indian reservation\n\nThe rest of the list have 4 or less missing counties, reasons are assumed to be similar as above.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Merging Mask and County Covid Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The NYT mask data is merged with the NYT-included `county_time` dataset. This allows us to see  the number of covid cases per county, along with the reported mask use.\n\nBecause `county_time` is a timeseries, we first filter to include only the latest total cases (from August 15, 2020) and then take the mean per county. In this way we should have one row per county.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mask.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_time.sort_values('date', ascending=False).head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_cases_aug = county_time[county_time['date'] == '20200815'].groupby('fips').mean().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_cases_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_mask = county_cases_aug.merge(df_mask,left_on='fips',right_on='countyfp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_mask = county_mask[['fips', 'covid_cases', 'covid_deaths', 'never', 'rarely', 'sometimes','frequently', 'always']]\ncounty_mask.columns = ['fips', 'covid_cases', 'covid_deaths', 'mask_never', 'mask_rarely', 'mask_sometimes','mask_frequently', 'mask_always']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"county_mask.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far we:\n\n* Imported and cleaned `df_mask` dataframe. It includes survey results of how often people wear masks in each county.\n* Import and cleaned the `county_time` dataframe, then filtered for the most recent data on Aug 15, 2020. This includes total (not new) covid19 cases and deaths.\n* The two dataframes were merged into one `county_mask` dataframe. This includes all NYT data to date (Aug 16, 2020).\n\n__Problem:__\nAfter using the `groupby()` function all `str` type columns were removed (as you cannot take the mean of strings). We lost the county and state names, but the `fips` values remained.\n\n__Solution:__ We can merge our new `county_mask` dataset with another dataset to get these names back. Since we want to find the population per county anyways, we will use the [US Census 2019 population estimate](https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-total.html) dataset to get county name, state name, county population, and some other variables.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## County Population","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__NOTE:__ last 6 rows of the raw excel file contain disclaimers and citing instructions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__NOTE:__ When shown without a date variable, county covid data from here on will reflect the mean of only \"recent\" (August 15, 2020) figures.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"url2 = github_link_formatter('https://github.com/pomkos/nyt-covid-data/blob/master/data/added_data/countypop.xlsx')\ncountypop = pd.read_excel(url2)\ncountypop.columns = countypop.columns.str.lower()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following keys were provided in a separate pdf file by the US census, letting us map them for interpretation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"region_key = {\n    1:'northeast',\n    2:'midwest',\n    3:'south',\n    4:'west'\n}\ndivision_key = {\n    1:'new_england',\n    2:'middle_atlantic',\n    3:'east_north_central',\n    4:'west_north_central',\n    5:'south_atlantic',\n    6:'east_south_central',\n    7:'west_south_central',\n    8:'mountain',\n    9:'pacific'\n}\nsumlev_key = {\n    40:'state_or_equiv',\n    50:'county_or_equiv'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select only the columns that are relevant, which is the latest (2019) estimates\ncountypop = countypop[['sumlev','region','division','state','county','stname','ctyname','popestimate2019',\n                       'births2019','internationalmig2019','domesticmig2019','rbirth2019','rdeath2019']]\ncountypop.columns = ['sumlev','region_fips','division_fips','state_fips','county_fips','state','county',\n                     'population','births','intnl_migration','domestic_migration','birth_rate','death_rate']\ncountypop.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find the counties that are present in our dataset\ncty_fip = county_time[['state','county','fips']].groupby(['state','county']).mean().reset_index()\ncty_fip.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like the two datasets have very similar naming styles, with the exception that the NYT `county_time` dataset does not include the words `County` or `Parish` after each territory. These are removed from the Census dataset, along with any spaces, and then merged on relevant county and state names.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# format for merging\ncountypop['county'] = countypop['county'].str.replace('County','')\ncountypop['county'] = countypop['county'].str.replace('Parish','')\ncountypop['county'] = countypop['county'].str.replace(' ','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge fips from covid dataset with 2019pop\ncty_pop = cty_fip.merge(countypop,left_on=['state','county'],right_on=['state','county'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cty_pop = cty_pop[['state', 'county', 'fips', 'sumlev', 'region_fips', 'division_fips',\n       'population','births', 'intnl_migration', 'domestic_migration', 'birth_rate',\n       'death_rate']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cty_pop.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merging Mask with County Pop","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We now have two datasets:\n\n* `county_mask` that contains all NYT data regarding covid19 cases and mask use\n* `cty_pop` that contains US Census data about the population\n\nIf we can merge these dataframes, we can find out the number of cases per population and a bunch of other interesting statistics. So that's what we will do next.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"list_diff(county_time['county'].unique(),cty_pop['county'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From our list it looks like the following are not included in our `cty_pop` Census dataset, but are in the NYT `county_mask` dataset:\n\n* Cities (ex: Los Angeles, Walla Walla)\n* Commonwealth areas (ex: Saipan) are not included\n* Some counties (ex: Roger Mills County in Oklahoma)\n\nSome other areas (ex: Roger Mills County) are also not included.\n\nWe will ignore these for now, but still keep them in our dataframe by doing a left merge. This will keep all rows in the `county_mask` dataframe even though they have no corresponding data in the `cty_pop` dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_county = county_mask.merge(cty_pop, on=['fips'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"100 * (sum(df_county['population'].isna()) / df_county.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Approximately 8% of the NYT dataframe has no corresponding data in the Census dataframe. This is acceptable to us for now, so we will go ahead with the analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_county.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We map the given keys to their appropriate values for ease of categorization in the future","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_county['region'] = df_county['region_fips'].map(region_key)\ndf_county['division'] = df_county['division_fips'].map(division_key)\ndf_county['area_type'] = df_county['sumlev'].map(sumlev_key)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And add some preliminary per capita calculations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_county['cases_per_million'] = (df_county['covid_cases']/df_county['population']) * 1000000\ndf_county['cases_per_hthousand'] = (df_county['covid_cases']/df_county['population']) * 100000\ndf_county['cases_per_thousand'] = (df_county['covid_cases']/df_county['population']) * 1000\ndf_county['cases_per_hundred'] = (df_county['covid_cases']/df_county['population']) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rearrange the columns\ndf_county = df_county[['state','region', 'county', 'division', 'area_type',\n                       'population', 'covid_cases', 'covid_deaths', 'cases_per_million', 'cases_per_hthousand', \n                       'cases_per_thousand', 'cases_per_hundred',\n                       'mask_never', 'mask_rarely','mask_sometimes', 'mask_frequently', 'mask_always', \n                       'births','intnl_migration', 'domestic_migration', \n                       'birth_rate', 'death_rate',\n                       'fips', 'sumlev', 'region_fips', 'division_fips'\n                    ]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_county.head()","execution_count":null,"outputs":[]},{"metadata":{"toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"# State Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Goals:__ Merge state population, land area, and latest covid data into one dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Covid Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"state_covid = pd.read_csv(\"../input/nytimes-covid19-data/us-states.csv\",parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_covid = state_covid.astype({\n    'state':str,\n    'fips':float,\n    'cases':int,\n    'deaths':int\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename columns\nstate_covid.columns = ['date','state','state_fips','covid_cases','covid_deaths']\nstate_covid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_time = state_covid.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will do the same sort of filtering as for the county data by only including total covid cases on August 15, 2020","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"state_covid = state_covid[state_covid['date'] >= '20200815'].reset_index(drop=True)\nstate_covid = state_covid.groupby('state_fips').mean().reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Land Area","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It would be nice to know the county and state land areas, so we can get some sort of estimate for the population density. I was unable to find information for every county, however information about state land area was found at this [US Census source](https://www.census.gov/geographies/reference-files/2010/geo/state-area.html).\n\nWe will scrape and format this data to get it ready for a future merge.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"response = requests.get(\"https://www.census.gov/geographies/reference-files/2010/geo/state-area.html\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"soup = BeautifulSoup(response.content)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"table_tag = soup.find('tbody')\n\nstate_land_scrape = pd.DataFrame(columns=range(1,17))\n\nfor tr in table_tag.find_all('tr')[3:]:\n    tds = tr.find_all('td')\n    d = {}\n    for i in range(0,17):\n        d[i] = [tds[i].text]\n    data = pd.DataFrame.from_dict(data=d)\n    state_land_scrape = state_land_scrape.append(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['state']\nareas = ['total_area_','land_area_','total_water_area_','inland_water_area_','coastal_water_area_',\n         'great_lakes_water_area_','territorial_water_area_','latitude','longitude']\nfor i in range(1,17):\n    if (i in range(1,16)) & (i % 2 == 0):\n        unit = 'sqkm'\n    elif (i in range(1,16)) & (i % 2 != 0):\n        unit = 'sqmi'\n    if (i == 1) | (i == 2):\n        cols.append(f'total_area_{unit}')\n    elif (i == 3) | (i == 4):\n        cols.append(f'land_area_{unit}')\n    elif (i == 5) | (i == 6):\n        cols.append(f'total_water_area_{unit}')\n    elif (i == 7) | (i == 8):\n        cols.append(f'inland_water_area_{unit}')\n    elif (i == 9) | (i == 10):\n        cols.append(f'coastal_water_area_{unit}')\n    elif (i == 11) | (i == 12):\n        cols.append(f'great_lakes_water_area_{unit}')\n    elif (i == 13) | (i == 14):\n        cols.append(f'territorial_water_area_{unit}')\n    elif (i == 15):\n        cols.append('latitude')\n    elif (i == 16):\n        cols.append('longitude')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_land_scrape.columns=cols\nstate_land_scrape = state_land_scrape.reset_index(drop=True)\nstate_land_scrape = state_land_scrape.iloc[3:,:].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_land_scrape.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## State Pop","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We could just figure out the state population from the county data, but the [US census](https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/state/) has this precompiled for us.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"url3 = github_link_formatter(\"https://github.com/pomkos/nyt-covid-data/blob/master/data/added_data/statepop.csv\")\nstatepop_raw = pd.read_csv(url3)\nstatepop_raw.columns = statepop_raw.columns.str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statepop_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statepop = statepop_raw[['name','popestimate2019','sumlev','region','division','state']].reset_index(drop=True)\nstatepop.columns = ['state', 'population','sumlev','region_fips','division_fips','state_fips']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statepop.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 represents territories and regions, which we are not interested in. \n# This data is also included in our county datasets.\nstatepop = statepop[statepop['state_fips']!=0].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statepop.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merge Land Area with State Population","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"By merging the two we can get population density data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge population with land area\nstatepop = statepop.merge(state_land_scrape, on='state')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statepop = statepop.replace(to_replace = '—', value = np.nan)\nstatepop = statepop.replace(to_replace = ',', value = '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statepop.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merge with State Covid Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_state = state_covid.merge(statepop, on='state_fips')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We replicate what we did to `df_county` with `df_state`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['region_fips', 'division_fips',\n       'total_area_sqmi', 'total_area_sqkm', 'land_area_sqmi',\n       'land_area_sqkm', 'total_water_area_sqmi', 'total_water_area_sqkm',\n       'inland_water_area_sqmi', 'inland_water_area_sqkm',\n       'coastal_water_area_sqmi', 'coastal_water_area_sqkm',\n       'great_lakes_water_area_sqmi', 'great_lakes_water_area_sqkm',\n       'territorial_water_area_sqmi', 'territorial_water_area_sqkm',\n       'latitude', 'longitude']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cols:\n    df_state[col] = df_state[col].str.replace('X','NaN')\n    df_state[col] = df_state[col].str.replace(',','')\n    df_state[col] = df_state[col].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_state['region'] = df_state['region_fips'].map(region_key)\ndf_state['division'] = df_state['division_fips'].map(division_key)\ndf_state['area_type'] = df_state['sumlev'].map(sumlev_key)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And add some preliminary per capita calculations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_state['cases_per_million'] = (df_state['covid_cases']/df_state['population']) * 1000000\ndf_state['cases_per_hthousand'] = (df_state['covid_cases']/df_state['population']) * 100000\ndf_state['cases_per_thousand'] = (df_state['covid_cases']/df_state['population']) * 1000\ndf_state['cases_per_hundred'] = (df_state['covid_cases']/df_state['population']) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And rearrange the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_state = df_state[['state', 'region', 'division', 'area_type','covid_cases', 'covid_deaths', 'population',\n                    'cases_per_million', 'cases_per_hthousand', 'cases_per_thousand',\n                    'cases_per_hundred', 'state_fips','sumlev', 'region_fips', 'division_fips', \n                    'total_area_sqmi','total_area_sqkm', 'land_area_sqmi', 'land_area_sqkm',\n                    'total_water_area_sqmi', 'total_water_area_sqkm',\n                    'inland_water_area_sqmi', 'inland_water_area_sqkm',\n                    'coastal_water_area_sqmi', 'coastal_water_area_sqkm',\n                    'great_lakes_water_area_sqmi', 'great_lakes_water_area_sqkm',\n                    'territorial_water_area_sqmi', 'territorial_water_area_sqkm',\n                    'latitude', 'longitude']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_state.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save to DB","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Finally `county_time`,`state_time`,`df_county`, `df_state` are saved into an sqlite database for ease of access:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"```python\nimport sqlalchemy as sq\nlocation = 'sqlite:///data/nyt_covid.db'\ncnx = sq.create_engine(location)\n\n# save county time series\ncounty_time.to_sql('county_time_dates', con=cnx, if_exists='fail', index=False)\n# save state time series\nstate_time.to_sql('state_time_dates',con=cnx,if_exists='fail',index=False)\n# save county\ndf_county.to_sql('county_dataset', con=cnx, if_exists='fail', index=False)\n# save state\ndf_state.to_sql('state_dataset', con=cnx, if_exists='fail', index=False)\n# save mask mandate\ndf_mand.to_sql('mandate_date',con=cnx,if_exists='fail',index=False)\n```","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To access in the future we just need to run:\n\n```python\nimport pandas as pd\nimport sqlalchemy as sq\n\nlocation = 'sqlite:///data/nyt_covid.db'\ncnx = sq.create_engine(location)\n\ncounty_time = pd.read_sql_table('county_time_dates',cnx)\nstate_time = pd.read_sql_table('state_time_dates',cnx)\ndf_county = pd.read_sql_table('county_dataset',cnx)\ndf_state = pd.read_sql_table('state_dataset',cnx)\ndf_mand = pd.read_sql_table('mandate_date',cnx)\n```","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nIn this notebook we:\n\n## County Level:\n\n1. Imported NYT mask-use survey (`df_mask`)\n2. Manually gathered data from AARP and CNN for dates that mask orders went into effect (`df_mand`)\n2. Imported NYT county-level total covid cases over time (`county_time`)\n3. Scraped the US Census for county-state-fips information (`county_scrape`) to double check the accuracy of the NYT dataset\n3. Filtered for only the latest, Aug 15, total covid cases (`county_cases_aug`)\n4. Imported the US Census county 2019 population estimate (`cty_pop`)\n5. Merged `df_mask` + `county_cases_aug` + `cty_pop` into one dataframe `df_county`\n\nNOTE: Some 8% of counties were excluded, as were larger cities such as NYC.\n\n## State Level:\n\n1. Imported NYT state-level total covid cases over time (`state_time`)\n2. Filtered for only the latest, Aug 15, total covid cases (`state_covid`)\n3. Imported the US Census state 2019 population estimate (`statepop`)\n4. Scraped and cleaned the US Census state area geographic reference (`state_land_scrape`)\n5. Merged `statepop` + `state_land_scrape` + `state_covid` into one dataframe `df_state`\n\n# Next Steps\n\nIn the next notebook we will look at the following questions:\n\n1. Do states with earlier mask mandates have lower cases of covid?\n2. How did cases change in each state over time?\n3. Which states (large, med, small population) fared better?\n4. Which states (Northeast, West, Midwest, South) fared better?\n5. Which states (Democrat led, Republican led) fared better?\n6. Is there any pattern in the first appearance of covid from county-to-county?\n7. Has the amount of cases relative to deaths or hospitalizations change over time? IE: are cases becoming more severe? (Age groups may be relevant here)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}