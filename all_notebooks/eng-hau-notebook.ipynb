{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:52.233382Z","iopub.execute_input":"2021-05-21T21:28:52.233756Z","iopub.status.idle":"2021-05-21T21:28:53.518497Z","shell.execute_reply.started":"2021-05-21T21:28:52.233678Z","shell.execute_reply":"2021-05-21T21:28:53.51764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:53.519933Z","iopub.execute_input":"2021-05-21T21:28:53.520338Z","iopub.status.idle":"2021-05-21T21:28:53.625876Z","shell.execute_reply.started":"2021-05-21T21:28:53.520296Z","shell.execute_reply":"2021-05-21T21:28:53.624876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:53.628311Z","iopub.execute_input":"2021-05-21T21:28:53.628821Z","iopub.status.idle":"2021-05-21T21:28:53.638213Z","shell.execute_reply.started":"2021-05-21T21:28:53.628785Z","shell.execute_reply":"2021-05-21T21:28:53.637104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !unzip englishhausa-corpus.zip","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:53.684821Z","iopub.execute_input":"2021-05-21T21:28:53.685396Z","iopub.status.idle":"2021-05-21T21:28:53.692204Z","shell.execute_reply.started":"2021-05-21T21:28:53.68536Z","shell.execute_reply":"2021-05-21T21:28:53.691431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import dependencies\nimport numpy as np\nimport pandas as pd\nimport unicodedata\nimport string\nimport re\nimport random\nimport torch","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:53.695083Z","iopub.execute_input":"2021-05-21T21:28:53.695369Z","iopub.status.idle":"2021-05-21T21:28:53.701895Z","shell.execute_reply.started":"2021-05-21T21:28:53.695345Z","shell.execute_reply":"2021-05-21T21:28:53.701103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:53.704188Z","iopub.execute_input":"2021-05-21T21:28:53.705178Z","iopub.status.idle":"2021-05-21T21:28:53.71215Z","shell.execute_reply.started":"2021-05-21T21:28:53.704442Z","shell.execute_reply":"2021-05-21T21:28:53.711457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:53.713249Z","iopub.execute_input":"2021-05-21T21:28:53.713822Z","iopub.status.idle":"2021-05-21T21:28:53.722695Z","shell.execute_reply.started":"2021-05-21T21:28:53.713787Z","shell.execute_reply":"2021-05-21T21:28:53.721904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/englishhausa-corpus/en-ha.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:53.725511Z","iopub.execute_input":"2021-05-21T21:28:53.72581Z","iopub.status.idle":"2021-05-21T21:28:55.68153Z","shell.execute_reply.started":"2021-05-21T21:28:53.725769Z","shell.execute_reply":"2021-05-21T21:28:55.680685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:55.683646Z","iopub.execute_input":"2021-05-21T21:28:55.683897Z","iopub.status.idle":"2021-05-21T21:28:55.703526Z","shell.execute_reply.started":"2021-05-21T21:28:55.683872Z","shell.execute_reply":"2021-05-21T21:28:55.702533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:55.705072Z","iopub.execute_input":"2021-05-21T21:28:55.705529Z","iopub.status.idle":"2021-05-21T21:28:55.711988Z","shell.execute_reply.started":"2021-05-21T21:28:55.705493Z","shell.execute_reply":"2021-05-21T21:28:55.711152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop duplicate translations\ndata = data.drop_duplicates()\n\n# Shuffle the data to remove bias in dev set selection.\ndata = data.sample(frac=1, random_state=seed).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:55.713228Z","iopub.execute_input":"2021-05-21T21:28:55.713635Z","iopub.status.idle":"2021-05-21T21:28:56.132118Z","shell.execute_reply.started":"2021-05-21T21:28:55.7136Z","shell.execute_reply":"2021-05-21T21:28:56.131258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.133343Z","iopub.execute_input":"2021-05-21T21:28:56.133682Z","iopub.status.idle":"2021-05-21T21:28:56.14319Z","shell.execute_reply.started":"2021-05-21T21:28:56.133647Z","shell.execute_reply":"2021-05-21T21:28:56.142371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.rename( columns={'Unnamed: 0':'numbers'}, inplace=True )","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.144728Z","iopub.execute_input":"2021-05-21T21:28:56.145269Z","iopub.status.idle":"2021-05-21T21:28:56.150172Z","shell.execute_reply.started":"2021-05-21T21:28:56.145231Z","shell.execute_reply":"2021-05-21T21:28:56.149395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('numbers', inplace=True, axis=1) #drop column with floats","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.151421Z","iopub.execute_input":"2021-05-21T21:28:56.151873Z","iopub.status.idle":"2021-05-21T21:28:56.190392Z","shell.execute_reply.started":"2021-05-21T21:28:56.151838Z","shell.execute_reply":"2021-05-21T21:28:56.189633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Create a Language class to store  util functions\n## such as index to word and word to index\nSOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {\"<blank>\":0, \"SOS\":1,\"EOS\":2}\n        self.word2count = {}\n        self.index2word = {0:\"<blank>\", 1: \"SOS\", 2: \"EOS\"}\n        self.n_words = 3  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n      try:\n        for word in sentence.split(' '):\n          self.addWord(word)\n      except:\n        a = 1\n        # Do nothing\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.191594Z","iopub.execute_input":"2021-05-21T21:28:56.191914Z","iopub.status.idle":"2021-05-21T21:28:56.20001Z","shell.execute_reply.started":"2021-05-21T21:28:56.19188Z","shell.execute_reply":"2021-05-21T21:28:56.199265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = s.strip()\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s.strip()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.201236Z","iopub.execute_input":"2021-05-21T21:28:56.201796Z","iopub.status.idle":"2021-05-21T21:28:56.207272Z","shell.execute_reply.started":"2021-05-21T21:28:56.201747Z","shell.execute_reply":"2021-05-21T21:28:56.206469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove empty rows\ndata = data.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.208473Z","iopub.execute_input":"2021-05-21T21:28:56.208809Z","iopub.status.idle":"2021-05-21T21:28:56.362409Z","shell.execute_reply.started":"2021-05-21T21:28:56.208774Z","shell.execute_reply":"2021-05-21T21:28:56.361575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.366931Z","iopub.execute_input":"2021-05-21T21:28:56.367183Z","iopub.status.idle":"2021-05-21T21:28:56.37611Z","shell.execute_reply.started":"2021-05-21T21:28:56.367158Z","shell.execute_reply":"2021-05-21T21:28:56.375177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## create lang\neng_lang = Lang(\"source_sentence\")\nhau_lang = Lang(\"hau_new\")","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:28:56.379356Z","iopub.execute_input":"2021-05-21T21:28:56.379776Z","iopub.status.idle":"2021-05-21T21:28:56.385721Z","shell.execute_reply.started":"2021-05-21T21:28:56.379733Z","shell.execute_reply":"2021-05-21T21:28:56.384897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, (source_sentence, target_sentence) in data.iterrows():\n  # print(source_sentence, target_sentence)\n  eng_lang.addSentence(source_sentence)\n  hau_lang.addSentence(target_sentence)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-05-21T21:28:56.387024Z","iopub.execute_input":"2021-05-21T21:28:56.387379Z","iopub.status.idle":"2021-05-21T21:29:28.27623Z","shell.execute_reply.started":"2021-05-21T21:28:56.387345Z","shell.execute_reply":"2021-05-21T21:29:28.275381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hau_lang.n_words","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:28.277504Z","iopub.execute_input":"2021-05-21T21:29:28.277828Z","iopub.status.idle":"2021-05-21T21:29:28.284582Z","shell.execute_reply.started":"2021-05-21T21:29:28.277794Z","shell.execute_reply":"2021-05-21T21:29:28.283663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eng_lang.n_words","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:28.286041Z","iopub.execute_input":"2021-05-21T21:29:28.28644Z","iopub.status.idle":"2021-05-21T21:29:28.295346Z","shell.execute_reply.started":"2021-05-21T21:29:28.286372Z","shell.execute_reply":"2021-05-21T21:29:28.294274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(list(eng_lang.word2count))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:28.296569Z","iopub.execute_input":"2021-05-21T21:29:28.296932Z","iopub.status.idle":"2021-05-21T21:29:28.307785Z","shell.execute_reply.started":"2021-05-21T21:29:28.296894Z","shell.execute_reply":"2021-05-21T21:29:28.306994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## convert word to their index\ndef tokenize(Lang,sentence):\n    return np.array([Lang.word2index.get(word) for word in sentence.split(' ')])\n    #X = [[word2idx.get(token, None) for token in d.split()] for d in desc]","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:28.308821Z","iopub.execute_input":"2021-05-21T21:29:28.309074Z","iopub.status.idle":"2021-05-21T21:29:28.316322Z","shell.execute_reply.started":"2021-05-21T21:29:28.30905Z","shell.execute_reply":"2021-05-21T21:29:28.315553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['source_index'] = data['source_sentence'].apply(lambda s: tokenize(eng_lang, s))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:28.31909Z","iopub.execute_input":"2021-05-21T21:29:28.31934Z","iopub.status.idle":"2021-05-21T21:29:31.961131Z","shell.execute_reply.started":"2021-05-21T21:29:28.319317Z","shell.execute_reply":"2021-05-21T21:29:31.960308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['target_index'] = data['target_sentence'].apply(lambda s: tokenize(hau_lang, s))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:31.962441Z","iopub.execute_input":"2021-05-21T21:29:31.962782Z","iopub.status.idle":"2021-05-21T21:29:36.047866Z","shell.execute_reply.started":"2021-05-21T21:29:31.962746Z","shell.execute_reply":"2021-05-21T21:29:36.047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.049085Z","iopub.execute_input":"2021-05-21T21:29:36.049422Z","iopub.status.idle":"2021-05-21T21:29:36.065479Z","shell.execute_reply.started":"2021-05-21T21:29:36.049389Z","shell.execute_reply":"2021-05-21T21:29:36.064414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs2 = data[['source_index', 'target_index']]","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.067057Z","iopub.execute_input":"2021-05-21T21:29:36.067847Z","iopub.status.idle":"2021-05-21T21:29:36.164308Z","shell.execute_reply.started":"2021-05-21T21:29:36.067657Z","shell.execute_reply":"2021-05-21T21:29:36.163474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs2.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.165582Z","iopub.execute_input":"2021-05-21T21:29:36.165922Z","iopub.status.idle":"2021-05-21T21:29:36.180098Z","shell.execute_reply.started":"2021-05-21T21:29:36.165886Z","shell.execute_reply":"2021-05-21T21:29:36.179115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs2.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.181414Z","iopub.execute_input":"2021-05-21T21:29:36.181822Z","iopub.status.idle":"2021-05-21T21:29:36.190088Z","shell.execute_reply.started":"2021-05-21T21:29:36.181788Z","shell.execute_reply":"2021-05-21T21:29:36.189257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create the input lan english tokenization","metadata":{}},{"cell_type":"code","source":"input_token = data['source_index']","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.191454Z","iopub.execute_input":"2021-05-21T21:29:36.191832Z","iopub.status.idle":"2021-05-21T21:29:36.200327Z","shell.execute_reply.started":"2021-05-21T21:29:36.191744Z","shell.execute_reply":"2021-05-21T21:29:36.199513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_token.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.201537Z","iopub.execute_input":"2021-05-21T21:29:36.201939Z","iopub.status.idle":"2021-05-21T21:29:36.213114Z","shell.execute_reply.started":"2021-05-21T21:29:36.201847Z","shell.execute_reply":"2021-05-21T21:29:36.212147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_token = data['target_index']","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.214486Z","iopub.execute_input":"2021-05-21T21:29:36.214916Z","iopub.status.idle":"2021-05-21T21:29:36.222092Z","shell.execute_reply.started":"2021-05-21T21:29:36.214876Z","shell.execute_reply":"2021-05-21T21:29:36.221236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_token.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.223129Z","iopub.execute_input":"2021-05-21T21:29:36.223434Z","iopub.status.idle":"2021-05-21T21:29:36.235847Z","shell.execute_reply.started":"2021-05-21T21:29:36.223402Z","shell.execute_reply":"2021-05-21T21:29:36.235053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(input_token), len(output_token)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.238723Z","iopub.execute_input":"2021-05-21T21:29:36.239027Z","iopub.status.idle":"2021-05-21T21:29:36.247115Z","shell.execute_reply.started":"2021-05-21T21:29:36.239002Z","shell.execute_reply":"2021-05-21T21:29:36.246341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_arr = map(lambda x: len(x), input_token)\nmax_input_length = np.array(list(len_arr)).max()\nmax_input_length","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.248172Z","iopub.execute_input":"2021-05-21T21:29:36.248545Z","iopub.status.idle":"2021-05-21T21:29:36.402982Z","shell.execute_reply.started":"2021-05-21T21:29:36.248509Z","shell.execute_reply":"2021-05-21T21:29:36.402231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_arr = map(lambda x: len(x), output_token)\nmax_output_length = np.array(list(len_arr)).max()\nmax_output_length","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.4042Z","iopub.execute_input":"2021-05-21T21:29:36.404541Z","iopub.status.idle":"2021-05-21T21:29:36.553887Z","shell.execute_reply.started":"2021-05-21T21:29:36.404512Z","shell.execute_reply":"2021-05-21T21:29:36.553144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the input and output lang is padded and converted into a numpy array","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = (np.array([max_input_length, max_output_length])).max()\nMAX_LENGTH = min(256, MAX_LENGTH)\nMAX_LENGTH","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.555008Z","iopub.execute_input":"2021-05-21T21:29:36.555335Z","iopub.status.idle":"2021-05-21T21:29:36.563527Z","shell.execute_reply.started":"2021-05-21T21:29:36.5553Z","shell.execute_reply":"2021-05-21T21:29:36.562863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tokenPad = np.zeros((len(input_token),MAX_LENGTH))\noutput_tokenPad = np.zeros((len(input_token),MAX_LENGTH))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.565001Z","iopub.execute_input":"2021-05-21T21:29:36.565444Z","iopub.status.idle":"2021-05-21T21:29:36.571143Z","shell.execute_reply.started":"2021-05-21T21:29:36.565407Z","shell.execute_reply":"2021-05-21T21:29:36.570372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.unique(input_tokenPad[2]))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.572359Z","iopub.execute_input":"2021-05-21T21:29:36.572686Z","iopub.status.idle":"2021-05-21T21:29:36.582977Z","shell.execute_reply.started":"2021-05-21T21:29:36.572649Z","shell.execute_reply":"2021-05-21T21:29:36.582088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_token[0], output_token[0]","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.58439Z","iopub.execute_input":"2021-05-21T21:29:36.584773Z","iopub.status.idle":"2021-05-21T21:29:36.608676Z","shell.execute_reply.started":"2021-05-21T21:29:36.584734Z","shell.execute_reply":"2021-05-21T21:29:36.607979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,v in enumerate(input_token):\n    \n    for j, token in enumerate(v[:MAX_LENGTH]):\n        \n        input_tokenPad[i,j] = token","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:36.61099Z","iopub.execute_input":"2021-05-21T21:29:36.611242Z","iopub.status.idle":"2021-05-21T21:29:41.32252Z","shell.execute_reply.started":"2021-05-21T21:29:36.611217Z","shell.execute_reply":"2021-05-21T21:29:41.32165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,v in enumerate(output_token):\n    \n    for j, token in enumerate(v[:MAX_LENGTH]):\n        \n        output_tokenPad[i,j] = token","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:41.32375Z","iopub.execute_input":"2021-05-21T21:29:41.324148Z","iopub.status.idle":"2021-05-21T21:29:46.598179Z","shell.execute_reply.started":"2021-05-21T21:29:41.324105Z","shell.execute_reply":"2021-05-21T21:29:46.597371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(input_tokenPad[1], output_tokenPad[1])","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:46.59934Z","iopub.execute_input":"2021-05-21T21:29:46.599682Z","iopub.status.idle":"2021-05-21T21:29:46.612938Z","shell.execute_reply.started":"2021-05-21T21:29:46.599648Z","shell.execute_reply":"2021-05-21T21:29:46.609872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## we only want up to 20K rows------cause of batching\ninput_tokenPad1 = input_tokenPad[:1000]\noutput_tokenPad1 = output_tokenPad[:1000]","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:46.61422Z","iopub.execute_input":"2021-05-21T21:29:46.614615Z","iopub.status.idle":"2021-05-21T21:29:46.622063Z","shell.execute_reply.started":"2021-05-21T21:29:46.61458Z","shell.execute_reply":"2021-05-21T21:29:46.621228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(input_tokenPad1.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:46.623265Z","iopub.execute_input":"2021-05-21T21:29:46.623629Z","iopub.status.idle":"2021-05-21T21:29:46.632913Z","shell.execute_reply.started":"2021-05-21T21:29:46.623595Z","shell.execute_reply":"2021-05-21T21:29:46.63195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:46.634238Z","iopub.execute_input":"2021-05-21T21:29:46.634613Z","iopub.status.idle":"2021-05-21T21:29:47.47897Z","shell.execute_reply.started":"2021-05-21T21:29:46.634577Z","shell.execute_reply":"2021-05-21T21:29:47.478188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split the dataset into train, test and validation\ntrain_eng, valid_eng,train_hau,valid_hau = train_test_split(input_tokenPad1,output_tokenPad1,test_size=0.2,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.480185Z","iopub.execute_input":"2021-05-21T21:29:47.480585Z","iopub.status.idle":"2021-05-21T21:29:47.48816Z","shell.execute_reply.started":"2021-05-21T21:29:47.48055Z","shell.execute_reply":"2021-05-21T21:29:47.487385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_eng[0], train_hau[0])","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.489519Z","iopub.execute_input":"2021-05-21T21:29:47.489893Z","iopub.status.idle":"2021-05-21T21:29:47.502926Z","shell.execute_reply.started":"2021-05-21T21:29:47.489854Z","shell.execute_reply":"2021-05-21T21:29:47.501936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataloader is created to make batching easy","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\ntrain_data = TensorDataset(torch.from_numpy(train_eng).long(),torch.from_numpy(train_hau).long())\nvalid_data = TensorDataset(torch.from_numpy(valid_eng).long(),torch.from_numpy(valid_hau).long())\n\nbatch_size = 8 # 32\n\ntrain_loader= DataLoader(train_data,shuffle=True,batch_size=batch_size,)\nvalid_loader =DataLoader(valid_data,shuffle=True,batch_size=batch_size,)\n\n# print(train_eng[3])","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.504157Z","iopub.execute_input":"2021-05-21T21:29:47.504514Z","iopub.status.idle":"2021-05-21T21:29:47.541777Z","shell.execute_reply.started":"2021-05-21T21:29:47.50448Z","shell.execute_reply":"2021-05-21T21:29:47.538624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(list(train_loader))[0][0]","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.542898Z","iopub.execute_input":"2021-05-21T21:29:47.543239Z","iopub.status.idle":"2021-05-21T21:29:47.604986Z","shell.execute_reply.started":"2021-05-21T21:29:47.543201Z","shell.execute_reply":"2021-05-21T21:29:47.603708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# obtain one batch of training data\ndataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\n\nprint(\"shape of english\", sample_x.device)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.608583Z","iopub.execute_input":"2021-05-21T21:29:47.608917Z","iopub.status.idle":"2021-05-21T21:29:47.619373Z","shell.execute_reply.started":"2021-05-21T21:29:47.60888Z","shell.execute_reply":"2021-05-21T21:29:47.618587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transformer model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport math, copy, time\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport seaborn\nseaborn.set_context(context=\"talk\")\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.623272Z","iopub.execute_input":"2021-05-21T21:29:47.625425Z","iopub.status.idle":"2021-05-21T21:29:47.712187Z","shell.execute_reply.started":"2021-05-21T21:29:47.625389Z","shell.execute_reply":"2021-05-21T21:29:47.711378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transformer","metadata":{}},{"cell_type":"code","source":"class EncoderDecoder(nn.Module):\n    \"\"\"\n    A standard Encoder-Decoder architecture. Base for this and many \n    other models.\n    \"\"\"\n    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n        super(EncoderDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.generator = generator\n        \n    def forward(self, src, tgt, src_mask, tgt_mask):\n        \"Take in and process masked src and target sequences.\"\n        return self.decode(self.encode(src, src_mask), src_mask,\n                            tgt, tgt_mask)\n    \n    def encode(self, src, src_mask):\n        return self.encoder(self.src_embed(src), src_mask)\n    \n    def decode(self, memory, src_mask, tgt, tgt_mask):\n        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.718068Z","iopub.execute_input":"2021-05-21T21:29:47.71995Z","iopub.status.idle":"2021-05-21T21:29:47.734038Z","shell.execute_reply.started":"2021-05-21T21:29:47.719912Z","shell.execute_reply":"2021-05-21T21:29:47.733111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    \"Define standard linear + softmax generation step.\"\n    def __init__(self, d_model, vocab):\n        super(Generator, self).__init__()\n        self.proj = nn.Linear(d_model, vocab)\n\n    def forward(self, x):\n        return F.log_softmax(self.proj(x), dim=-1)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.738198Z","iopub.execute_input":"2021-05-21T21:29:47.740827Z","iopub.status.idle":"2021-05-21T21:29:47.749213Z","shell.execute_reply.started":"2021-05-21T21:29:47.740785Z","shell.execute_reply":"2021-05-21T21:29:47.748226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"encoder and decoder stacks","metadata":{}},{"cell_type":"code","source":"def clones(module, N):\n    \"Produce N identical layers.\"\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.753452Z","iopub.execute_input":"2021-05-21T21:29:47.755897Z","iopub.status.idle":"2021-05-21T21:29:47.762013Z","shell.execute_reply.started":"2021-05-21T21:29:47.755861Z","shell.execute_reply":"2021-05-21T21:29:47.761071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \"Core encoder is a stack of N layers\"\n    def __init__(self, layer, N):\n        super(Encoder, self).__init__()\n        self.layers = clones(layer, N)\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, mask):\n        \"Pass the input (and mask) through each layer in turn.\"\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.766218Z","iopub.execute_input":"2021-05-21T21:29:47.768734Z","iopub.status.idle":"2021-05-21T21:29:47.776858Z","shell.execute_reply.started":"2021-05-21T21:29:47.768696Z","shell.execute_reply":"2021-05-21T21:29:47.775835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    \"Construct a layernorm module (See citation for details).\"\n    def __init__(self, features, eps=1e-6):\n        super(LayerNorm, self).__init__()\n        self.a_2 = nn.Parameter(torch.ones(features))\n        self.b_2 = nn.Parameter(torch.zeros(features))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.780958Z","iopub.execute_input":"2021-05-21T21:29:47.783491Z","iopub.status.idle":"2021-05-21T21:29:47.792737Z","shell.execute_reply.started":"2021-05-21T21:29:47.783447Z","shell.execute_reply":"2021-05-21T21:29:47.791728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SublayerConnection(nn.Module):\n    \"\"\"\n    A residual connection followed by a layer norm.\n    Note for code simplicity the norm is first as opposed to last.\n    \"\"\"\n    def __init__(self, size, dropout):\n        super(SublayerConnection, self).__init__()\n        self.norm = LayerNorm(size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, sublayer):\n        \"Apply residual connection to any sublayer with the same size.\"\n        return x + self.dropout(sublayer(self.norm(x)))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.797076Z","iopub.execute_input":"2021-05-21T21:29:47.799711Z","iopub.status.idle":"2021-05-21T21:29:47.807654Z","shell.execute_reply.started":"2021-05-21T21:29:47.799675Z","shell.execute_reply":"2021-05-21T21:29:47.806905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    \"Encoder is made up of self-attn and feed forward (defined below)\"\n    def __init__(self, size, self_attn, feed_forward, dropout):\n        super(EncoderLayer, self).__init__()\n        self.self_attn = self_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n        self.size = size\n\n    def forward(self, x, mask):\n        \"Follow Figure 1 (left) for connections.\"\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n        return self.sublayer[1](x, self.feed_forward)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.812102Z","iopub.execute_input":"2021-05-21T21:29:47.814559Z","iopub.status.idle":"2021-05-21T21:29:47.823565Z","shell.execute_reply.started":"2021-05-21T21:29:47.814455Z","shell.execute_reply":"2021-05-21T21:29:47.822698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decoder","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    \"Generic N layer decoder with masking.\"\n    def __init__(self, layer, N):\n        super(Decoder, self).__init__()\n        self.layers = clones(layer, N)\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, memory, src_mask, tgt_mask):\n        for layer in self.layers:\n            x = layer(x, memory, src_mask, tgt_mask)\n        return self.norm(x)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.828019Z","iopub.execute_input":"2021-05-21T21:29:47.830193Z","iopub.status.idle":"2021-05-21T21:29:47.838126Z","shell.execute_reply.started":"2021-05-21T21:29:47.830157Z","shell.execute_reply":"2021-05-21T21:29:47.837375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n        super(DecoderLayer, self).__init__()\n        self.size = size\n        self.self_attn = self_attn\n        self.src_attn = src_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n \n    def forward(self, x, memory, src_mask, tgt_mask):\n        \"Follow Figure 1 (right) for connections.\"\n        m = memory\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n        return self.sublayer[2](x, self.feed_forward)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.842739Z","iopub.execute_input":"2021-05-21T21:29:47.845066Z","iopub.status.idle":"2021-05-21T21:29:47.8552Z","shell.execute_reply.started":"2021-05-21T21:29:47.845013Z","shell.execute_reply":"2021-05-21T21:29:47.854369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def subsequent_mask(size):\n    \"Mask out subsequent positions.\"\n    attn_shape = (1, size, size)\n    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n    return torch.from_numpy(subsequent_mask) == 0","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.866345Z","iopub.execute_input":"2021-05-21T21:29:47.868376Z","iopub.status.idle":"2021-05-21T21:29:47.875001Z","shell.execute_reply.started":"2021-05-21T21:29:47.868339Z","shell.execute_reply":"2021-05-21T21:29:47.873974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.imshow(subsequent_mask(20)[0])\nNone","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:47.879888Z","iopub.execute_input":"2021-05-21T21:29:47.882261Z","iopub.status.idle":"2021-05-21T21:29:48.103514Z","shell.execute_reply.started":"2021-05-21T21:29:47.88222Z","shell.execute_reply":"2021-05-21T21:29:48.102703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Attention","metadata":{}},{"cell_type":"code","source":"def attention(query, key, value, mask=None, dropout=None):\n    \"Compute 'Scaled Dot Product Attention'\"\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n             / math.sqrt(d_k)\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n    p_attn = F.softmax(scores, dim = -1)\n    if dropout is not None:\n        p_attn = dropout(p_attn)\n    return torch.matmul(p_attn, value), p_attn","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.107479Z","iopub.execute_input":"2021-05-21T21:29:48.109593Z","iopub.status.idle":"2021-05-21T21:29:48.118836Z","shell.execute_reply.started":"2021-05-21T21:29:48.109553Z","shell.execute_reply":"2021-05-21T21:29:48.117778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadedAttention(nn.Module):\n    def __init__(self, h, d_model, dropout=0.1):\n        \"Take in model size and number of heads.\"\n        super(MultiHeadedAttention, self).__init__()\n        assert d_model % h == 0\n        # We assume d_v always equals d_k\n        self.d_k = d_model // h\n        self.h = h\n        self.linears = clones(nn.Linear(d_model, d_model), 4)\n        self.attn = None\n        self.dropout = nn.Dropout(p=dropout)\n        \n    def forward(self, query, key, value, mask=None):\n        \"Implements Figure 2\"\n        if mask is not None:\n            # Same mask applied to all h heads.\n            mask = mask.unsqueeze(1)\n        nbatches = query.size(0)\n        \n        # 1) Do all the linear projections in batch from d_model => h x d_k \n        query, key, value = \\\n            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n             for l, x in zip(self.linears, (query, key, value))]\n        \n        # 2) Apply attention on all the projected vectors in batch. \n        x, self.attn = attention(query, key, value, mask=mask, \n                                 dropout=self.dropout)\n        \n        # 3) \"Concat\" using a view and apply a final linear. \n        x = x.transpose(1, 2).contiguous() \\\n             .view(nbatches, -1, self.h * self.d_k)\n        return self.linears[-1](x)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.123418Z","iopub.execute_input":"2021-05-21T21:29:48.126184Z","iopub.status.idle":"2021-05-21T21:29:48.141223Z","shell.execute_reply.started":"2021-05-21T21:29:48.126144Z","shell.execute_reply":"2021-05-21T21:29:48.140086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Position-wise feedforward","metadata":{}},{"cell_type":"code","source":"class PositionwiseFeedForward(nn.Module):\n    \"Implements FFN equation.\"\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.w_2(self.dropout(F.relu(self.w_1(x))))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.145578Z","iopub.execute_input":"2021-05-21T21:29:48.148219Z","iopub.status.idle":"2021-05-21T21:29:48.157055Z","shell.execute_reply.started":"2021-05-21T21:29:48.148116Z","shell.execute_reply":"2021-05-21T21:29:48.156175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"embedding and softmax","metadata":{}},{"cell_type":"code","source":"class Embeddings(nn.Module):\n    def __init__(self, d_model, vocab):\n        super(Embeddings, self).__init__()\n        self.lut = nn.Embedding(vocab, d_model)\n        self.d_model = d_model\n\n    def forward(self, x):\n        return self.lut(x) * math.sqrt(self.d_model)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.161492Z","iopub.execute_input":"2021-05-21T21:29:48.163752Z","iopub.status.idle":"2021-05-21T21:29:48.171454Z","shell.execute_reply.started":"2021-05-21T21:29:48.163716Z","shell.execute_reply":"2021-05-21T21:29:48.170672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"positional encoding","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    \"Implement the PE function.\"\n    def __init__(self, d_model, dropout, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        \n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0., max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0., d_model, 2) *\n                             -(math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n        \n    def forward(self, x):\n        x = x + Variable(self.pe[:, :x.size(1)], \n                         requires_grad=False)\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.175743Z","iopub.execute_input":"2021-05-21T21:29:48.178089Z","iopub.status.idle":"2021-05-21T21:29:48.189399Z","shell.execute_reply.started":"2021-05-21T21:29:48.178053Z","shell.execute_reply":"2021-05-21T21:29:48.188635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\npe = PositionalEncoding(20, 0)\ny = pe.forward(Variable(torch.zeros(1, 100, 20)))\nplt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\nplt.legend([\"dim %d\"%p for p in [4,5,6,7]])\nNone","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.19357Z","iopub.execute_input":"2021-05-21T21:29:48.196083Z","iopub.status.idle":"2021-05-21T21:29:48.505452Z","shell.execute_reply.started":"2021-05-21T21:29:48.196047Z","shell.execute_reply":"2021-05-21T21:29:48.504645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Full model","metadata":{}},{"cell_type":"code","source":"def make_model(src_vocab, tgt_vocab, N=6, \n               d_model=512, d_ff=2048, h=8, dropout=0.1):\n    \"Helper: Construct a model from hyperparameters.\"\n    c = copy.deepcopy\n    attn = MultiHeadedAttention(h, d_model)\n    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n    position = PositionalEncoding(d_model, dropout)\n    model = EncoderDecoder(\n        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n                             c(ff), dropout), N),\n        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n        Generator(d_model, tgt_vocab))\n    \n    # This was important from their code. \n    # Initialize parameters with Glorot / fan_avg.\n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.507037Z","iopub.execute_input":"2021-05-21T21:29:48.508701Z","iopub.status.idle":"2021-05-21T21:29:48.524091Z","shell.execute_reply.started":"2021-05-21T21:29:48.508656Z","shell.execute_reply":"2021-05-21T21:29:48.523331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Small example model.\ntmp_model = make_model(10, 10, 2)\nNone","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.527414Z","iopub.execute_input":"2021-05-21T21:29:48.527691Z","iopub.status.idle":"2021-05-21T21:29:48.731255Z","shell.execute_reply.started":"2021-05-21T21:29:48.527657Z","shell.execute_reply":"2021-05-21T21:29:48.730359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"class Batch:\n    \"Object for holding a batch of data with mask during training.\"\n    def __init__(self, src, trg=None, pad=0):\n        self.src = src\n        self.src_mask = (src != pad).unsqueeze(-2)\n        if trg is not None:\n            self.trg = trg[:, :-1]\n            self.trg_y = trg[:, 1:]\n            self.trg_mask = \\\n                self.make_std_mask(self.trg, pad)\n            self.ntokens = (self.trg_y != pad).data.sum()\n    \n    @staticmethod\n    def make_std_mask(tgt, pad):\n        \"Create a mask to hide padding and future words.\"\n        tgt_mask = (tgt != pad).unsqueeze(-2)\n        tgt_mask = tgt_mask & Variable(\n            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n        return tgt_mask","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.73325Z","iopub.execute_input":"2021-05-21T21:29:48.733744Z","iopub.status.idle":"2021-05-21T21:29:48.741443Z","shell.execute_reply.started":"2021-05-21T21:29:48.733706Z","shell.execute_reply":"2021-05-21T21:29:48.740563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_epoch(data_iter, model, loss_compute):\n    \"Standard Training and Logging Function\"\n    start = time.time()\n    total_tokens = 0\n    total_loss = 0\n    tokens = 0\n    for i, data in enumerate(data_iter):\n        \n        src, trg = data\n        batch = Batch(src.cuda(),trg.cuda())\n        out = model.forward(batch.src, batch.trg, \n                            batch.src_mask, batch.trg_mask)\n        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n        total_loss += loss\n        total_tokens += batch.ntokens\n        tokens += batch.ntokens\n        if i % 50 == 1:\n            elapsed = time.time() - start\n            # print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %(i, loss / batch.ntokens, tokens / elapsed))\n            start = time.time()\n            tokens = 0\n    return (total_loss / total_tokens).cpu().item()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.742714Z","iopub.execute_input":"2021-05-21T21:29:48.743065Z","iopub.status.idle":"2021-05-21T21:29:48.752489Z","shell.execute_reply.started":"2021-05-21T21:29:48.74303Z","shell.execute_reply":"2021-05-21T21:29:48.751695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"optim","metadata":{}},{"cell_type":"code","source":"class NoamOpt:\n    \"Optim wrapper that implements rate.\"\n    def __init__(self, model_size, factor, warmup, optimizer):\n        self.optimizer = optimizer\n        self._step = 0\n        self.warmup = warmup\n        self.factor = factor\n        self.model_size = model_size\n        self._rate = 0\n        \n    def step(self):\n        \"Update parameters and rate\"\n        self._step += 1\n        rate = self.rate()\n        for p in self.optimizer.param_groups:\n            p['lr'] = rate\n        self._rate = rate\n        self.optimizer.step()\n        \n    def rate(self, step = None):\n        \"Implement `lrate` above\"\n        if step is None:\n            step = self._step\n        return self.factor * \\\n            (self.model_size ** (-0.5) *\n            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n        \ndef get_std_opt(model):\n    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.75389Z","iopub.execute_input":"2021-05-21T21:29:48.754225Z","iopub.status.idle":"2021-05-21T21:29:48.765567Z","shell.execute_reply.started":"2021-05-21T21:29:48.754192Z","shell.execute_reply":"2021-05-21T21:29:48.764805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Three settings of the lrate hyperparameters.\nopts = [NoamOpt(512, 1, 4000, None), \n        NoamOpt(512, 1, 8000, None),\n        NoamOpt(256, 1, 4000, None)]\nplt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\nplt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\nNone","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:48.76705Z","iopub.execute_input":"2021-05-21T21:29:48.767315Z","iopub.status.idle":"2021-05-21T21:29:49.167952Z","shell.execute_reply.started":"2021-05-21T21:29:48.767267Z","shell.execute_reply":"2021-05-21T21:29:49.166942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"label smoothing","metadata":{}},{"cell_type":"code","source":"class LabelSmoothing(nn.Module):\n    \"Implement label smoothing.\"\n    def __init__(self, size, padding_idx, smoothing=0.0):\n        super(LabelSmoothing, self).__init__()\n        self.criterion = nn.KLDivLoss(size_average=False)\n        self.padding_idx = padding_idx\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.size = size\n        self.true_dist = None\n        \n    def forward(self, x, target):\n        assert x.size(1) == self.size\n        true_dist = x.data.clone()\n        true_dist.fill_(self.smoothing / (self.size - 2))\n        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        true_dist[:, self.padding_idx] = 0\n        mask = torch.nonzero(target.data == self.padding_idx)\n        if mask.dim() > 0:\n            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n        self.true_dist = true_dist\n        return self.criterion(x, Variable(true_dist, requires_grad=False))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:49.169513Z","iopub.execute_input":"2021-05-21T21:29:49.169849Z","iopub.status.idle":"2021-05-21T21:29:49.18131Z","shell.execute_reply.started":"2021-05-21T21:29:49.169811Z","shell.execute_reply":"2021-05-21T21:29:49.180398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"loss computation","metadata":{}},{"cell_type":"code","source":"class SimpleLossCompute:\n    \"A simple loss compute and train function.\"\n    def __init__(self, generator, criterion, opt=None):\n        self.generator = generator\n        self.criterion = criterion\n        self.opt = opt\n        \n    def __call__(self, x, y, norm):\n        x = self.generator(x)\n        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n                              y.contiguous().view(-1)) / norm\n        loss.backward()\n        if self.opt is not None:\n            self.opt.step()\n            self.opt.optimizer.zero_grad()\n        return loss.item() * norm","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:49.183188Z","iopub.execute_input":"2021-05-21T21:29:49.183775Z","iopub.status.idle":"2021-05-21T21:29:49.192995Z","shell.execute_reply.started":"2021-05-21T21:29:49.183739Z","shell.execute_reply":"2021-05-21T21:29:49.192187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def greedy_decode(model, src, src_mask, max_len, start_symbol):\n    memory = model.encode(src, src_mask)\n    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n    for i in range(max_len-1):\n        out = model.decode(memory, src_mask, \n                           Variable(ys), \n                           Variable(subsequent_mask(ys.size(1))\n                                    .type_as(src.data)))\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim = 1)\n        next_word = next_word.data[0]\n        ys = torch.cat([ys, \n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n    return ys","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:49.195647Z","iopub.execute_input":"2021-05-21T21:29:49.195891Z","iopub.status.idle":"2021-05-21T21:29:49.204448Z","shell.execute_reply.started":"2021-05-21T21:29:49.195868Z","shell.execute_reply":"2021-05-21T21:29:49.203449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"training begins","metadata":{}},{"cell_type":"code","source":"pad_idx = hau_lang.word2index[\"<blank>\"]\nprint(eng_lang.n_words, hau_lang.n_words)\nmodel = make_model(eng_lang.n_words,hau_lang.n_words,N=6)\nmodel.cuda()\ncriterion = LabelSmoothing(size=hau_lang.n_words,padding_idx=pad_idx,smoothing=0.1)\ncriterion.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:49.205982Z","iopub.execute_input":"2021-05-21T21:29:49.206343Z","iopub.status.idle":"2021-05-21T21:29:55.494862Z","shell.execute_reply.started":"2021-05-21T21:29:49.206309Z","shell.execute_reply":"2021-05-21T21:29:55.494067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_opt = NoamOpt(model.src_embed[0].d_model, 1, 4000,\n            torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9))\n\nfor epoch in range(135):\n    print(\"Epoch:\", epoch)\n\n    model.train()\n    print(\"train\", run_epoch(train_loader,model, SimpleLossCompute(model.generator,criterion,model_opt)))\n    \n    model.eval()\n    print(\"test\", run_epoch(valid_loader,model, SimpleLossCompute(model.generator,criterion,None)))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T21:29:55.49618Z","iopub.execute_input":"2021-05-21T21:29:55.496539Z","iopub.status.idle":"2021-05-21T22:39:31.520767Z","shell.execute_reply.started":"2021-05-21T21:29:55.496501Z","shell.execute_reply":"2021-05-21T22:39:31.519896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, data in enumerate(list(valid_loader)[:5]):\n    # print(\"English\", data[0][0])\n    # print(\"Hausa\", data[0][1])\n    src,trg = data[:10][0], data[:10][1]\n    # src,trg = src.cuda(), trg.cuda()\n    # print(len(src), len(trg))\n    batch = Batch(src.cuda(),trg.cuda())\n    src = batch.src[:1]\n    # print(src.cuda(), trg.cuda())\n    src_mask = (src != eng_lang.word2index[\"<blank>\"]).unsqueeze(-2)\n    # print(len(src), len(src_mask))\n    out = greedy_decode(model.cuda(), src, src_mask, \n                        max_len=60, start_symbol=hau_lang.word2index[\"SOS\"])\n    \n    # print(eng_lang.word2index)\n    # print(eng_lang.index2word[src[0, 0].item()])\n\n    # print(out)\n\n    # print(batch.trg.data)\n\n    # print(src[0, 2].item())\n    print(\"Source language:\", end=\"\\t\")\n    for i in range(0, src.size(1)):\n        sym = eng_lang.index2word[src[0, i].item()]\n        if sym == \"<blank>\": break\n        print(sym, end =\" \")\n    print()\n    print(\"Translation:\", end=\"\\t\")\n    for i in range(1, out.size(1)):\n        sym = hau_lang.index2word[out[0, i].item()]\n        if sym == \"EOS\": break\n        print(sym, end =\" \")\n    print()\n    print(\"Target:\", end=\"\\t\")\n    for i in range(1, batch.trg.size(1)):\n        \n        sym = hau_lang.index2word[batch.trg.data[0,i].item()]\n        if sym == \"<blank>\": break\n        print(sym, end =\" \")\n    print()\n    break","metadata":{"execution":{"iopub.status.busy":"2021-05-21T23:30:05.774997Z","iopub.execute_input":"2021-05-21T23:30:05.77533Z","iopub.status.idle":"2021-05-21T23:30:06.608404Z","shell.execute_reply.started":"2021-05-21T23:30:05.775295Z","shell.execute_reply":"2021-05-21T23:30:06.607593Z"},"trusted":true},"execution_count":null,"outputs":[]}]}