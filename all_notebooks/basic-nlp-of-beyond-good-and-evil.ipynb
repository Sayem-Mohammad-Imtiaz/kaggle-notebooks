{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\n\nimport numpy as np \nimport requests\nfrom PIL import Image\nfrom io import BytesIO \n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nfrom collections import Counter\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(12,8)})\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T14:55:27.098951Z","iopub.execute_input":"2021-06-14T14:55:27.099519Z","iopub.status.idle":"2021-06-14T14:55:28.784499Z","shell.execute_reply.started":"2021-06-14T14:55:27.099402Z","shell.execute_reply":"2021-06-14T14:55:28.783442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nietzsches-bibliography/Nietzsche_works_corpus.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:55:33.410066Z","iopub.execute_input":"2021-06-14T14:55:33.410412Z","iopub.status.idle":"2021-06-14T14:55:33.741501Z","shell.execute_reply.started":"2021-06-14T14:55:33.410382Z","shell.execute_reply":"2021-06-14T14:55:33.740462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Isolate the book wanted: Beyond Good and Evil\nbge = df[df['book_title']=='Beyond Good and Evil']['text_clean'][0]\ntokens = word_tokenize(bge)\n# items to be removed\nremoved = {'project', 'gutenberg', 'ebook', 'it', 's', 'the', 'and'}\ntokens = [ele for ele in tokens if ele not in removed]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:55:36.243938Z","iopub.execute_input":"2021-06-14T14:55:36.244276Z","iopub.status.idle":"2021-06-14T14:55:36.402382Z","shell.execute_reply.started":"2021-06-14T14:55:36.244244Z","shell.execute_reply":"2021-06-14T14:55:36.401631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Frequency","metadata":{}},{"cell_type":"code","source":"freq = Counter(tokens)\nsorted_freq = dict(sorted(freq.items(), key=lambda x: x[1], reverse=True))\ntop_25_words = list(sorted_freq.keys())[:25]\ntop_25_freq = list(sorted_freq.values())[:25]\nsns.barplot(y=top_25_words, x=top_25_freq)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:55:40.171252Z","iopub.execute_input":"2021-06-14T14:55:40.171614Z","iopub.status.idle":"2021-06-14T14:55:40.611593Z","shell.execute_reply.started":"2021-06-14T14:55:40.171578Z","shell.execute_reply":"2021-06-14T14:55:40.610784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Cloud","metadata":{}},{"cell_type":"markdown","source":"## 1- Simple","metadata":{}},{"cell_type":"code","source":"def plot_cloud(wordcloud):\n    # Set figure size\n    plt.figure(figsize=(12, 8))\n    # Display image\n    plt.imshow(wordcloud) \n    # No axis details\n    plt.axis(\"off\");\n    \n\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, \n                      background_color='black', colormap='Set2', \n                      collocations=False, stopwords = STOPWORDS)\nwordcloud.generate_from_frequencies(sorted_freq)\nplot_cloud(wordcloud)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:55:43.763196Z","iopub.execute_input":"2021-06-14T14:55:43.763544Z","iopub.status.idle":"2021-06-14T14:55:57.734636Z","shell.execute_reply.started":"2021-06-14T14:55:43.763513Z","shell.execute_reply":"2021-06-14T14:55:57.73396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2 - With a mask image of Nietzsche","metadata":{}},{"cell_type":"code","source":"def read_img_from_url(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    img_matrix = np.array(img)\n    return img_matrix\n\ndef read_txt_from_url(url, *size):\n    text = requests.get(url).text\n    wc = WordCloud(background_color=\"white\", max_words=100 , max_font_size=100, width=size[0], height=size[1], random_state=42)\n    wc.generate(text)\n    return wc.to_array()\n    \nimg_url = \"https://nearemmaus.files.wordpress.com/2014/01/nietzsche_by_vanjamrgan.jpg\"\nimg_matrix = read_img_from_url(img_url)\n\nstopwords = set(STOPWORDS)\nstopwords.add(\"said\")\n\nwc = WordCloud(width = 3000, height = 2000, random_state=1, \n              background_color='black', colormap='Reds', \n              collocations=False, stopwords = STOPWORDS, mask=img_matrix)\n\n# generate word cloud\nwc.generate_from_frequencies(sorted_freq)\n\n# show\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.figure()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:56:18.607756Z","iopub.execute_input":"2021-06-14T14:56:18.608078Z","iopub.status.idle":"2021-06-14T14:56:20.588837Z","shell.execute_reply.started":"2021-06-14T14:56:18.60805Z","shell.execute_reply":"2021-06-14T14:56:20.588188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stemming","metadata":{}},{"cell_type":"code","source":"stemmer = PorterStemmer()\nstemmed_words = [stemmer.stem(word) for word in tokens]\nstemmed_words[100:120]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:56:26.479639Z","iopub.execute_input":"2021-06-14T14:56:26.480019Z","iopub.status.idle":"2021-06-14T14:56:27.090215Z","shell.execute_reply.started":"2021-06-14T14:56:26.479988Z","shell.execute_reply":"2021-06-14T14:56:27.089163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmatizing","metadata":{}},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\nlemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\nlemmatized_words[100:120]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:56:29.089774Z","iopub.execute_input":"2021-06-14T14:56:29.090295Z","iopub.status.idle":"2021-06-14T14:56:30.755999Z","shell.execute_reply.started":"2021-06-14T14:56:29.090255Z","shell.execute_reply":"2021-06-14T14:56:30.755128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tagging words in the text","metadata":{}},{"cell_type":"code","source":"words_tags = nltk.pos_tag(tokens)\nwords_tags[:20]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:56:32.885135Z","iopub.execute_input":"2021-06-14T14:56:32.885458Z","iopub.status.idle":"2021-06-14T14:56:34.734289Z","shell.execute_reply.started":"2021-06-14T14:56:32.88543Z","shell.execute_reply":"2021-06-14T14:56:34.733685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dispersion Plot","metadata":{}},{"cell_type":"code","source":"from nltk.draw.dispersion import dispersion_plot\nfrom nltk.text import Text\n# inaugural_tokens=inaugural.words()\ntext = Text(tokens)\ndispersion_plot(text, top_25_words, ignore_case=True, title='Beyond Good and Evil top 25 words Plot')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:56:36.828625Z","iopub.execute_input":"2021-06-14T14:56:36.829127Z","iopub.status.idle":"2021-06-14T14:56:37.152668Z","shell.execute_reply.started":"2021-06-14T14:56:36.82908Z","shell.execute_reply":"2021-06-14T14:56:37.151987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Frequency Distribution with NLTK","metadata":{}},{"cell_type":"code","source":"from nltk import FreqDist\nfrom nltk.corpus import stopwords\nfrequency_distribution = FreqDist(tokens)\nfrequency_distribution.most_common(20)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:56:39.978327Z","iopub.execute_input":"2021-06-14T14:56:39.978897Z","iopub.status.idle":"2021-06-14T14:56:40.004127Z","shell.execute_reply.started":"2021-06-14T14:56:39.978847Z","shell.execute_reply":"2021-06-14T14:56:40.003273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequency_distribution.plot(20, cumulative=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:56:42.570257Z","iopub.execute_input":"2021-06-14T14:56:42.570738Z","iopub.status.idle":"2021-06-14T14:56:42.805383Z","shell.execute_reply.started":"2021-06-14T14:56:42.570705Z","shell.execute_reply":"2021-06-14T14:56:42.804756Z"},"trusted":true},"execution_count":null,"outputs":[]}]}