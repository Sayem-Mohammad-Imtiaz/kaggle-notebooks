{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm, trange\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.listdir(\"../input\")\n\n#Version 5 replaces mean squared error with mean absolute error.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I'll load image data and show a few values:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def toArray(k):\n    return np.array(list(k.getdata())).reshape(k.size[1], k.size[0], 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error as mae #Because we won't be able to \nfrom skimage.measure import compare_psnr as psnr\n\nos.listdir(\"../input/images\")\ntrain_data = []\nfor img_path in os.listdir(\"../input/images\"):\n    train_data += [Image.open('../input/images/'+img_path)]\nfor img_path in os.listdir(\"../input/general100\"):\n    train_data += [Image.open('../input/general100/'+img_path)]\nfor img_path in os.listdir(\"../input/intel-data-scene/scene_classification/scene_classification/train\")[:3000]:\n    train_data += [Image.open('../input/intel-data-scene/scene_classification/scene_classification/train/'+img_path)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=train_data[30]\nprint(img.size)\nplot5= plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = img.size\nimg5=img.resize((100,100), resample = Image.LANCZOS)\nimgp = img5.resize((x,y), resample = Image.LANCZOS)\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgq = img5.resize((x,y), resample = Image.LANCZOS)\nprint(psnr(toArray(img), toArray(imgp)), psnr(toArray(img), toArray(imgq)))\nprint(mae(toArray(img).reshape(x*y*3), toArray(imgp).reshape(x*y*3)), mae(toArray(img).reshape(x*y*3), toArray(imgq).reshape(x*y*3)))\ntry:\n    print(psnr(toArray(img), toArray(img)))\nexcept:\n    print(\"PSNR is not continuous so I'll train with MAE\")\ncomp = plt.figure(figsize=(9, 13))\nfirst = comp.add_subplot(3,1,1)\nfirst.imshow(img)\nsecond =comp.add_subplot(3,1,2)\nsecond.imshow(imgp)\nsecond =comp.add_subplot(3,1,3)\nsecond.imshow(imgq)\ncomp.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparison of different upsamplings** "},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = img.size\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgp = img5.resize((x,y), resample = Image.BICUBIC)\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgq = img5.resize((x,y), resample = Image.BILINEAR)\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgr = img5.resize((x,y), resample = Image.LANCZOS)\nprint(mae(toArray(img).reshape(x*y*3), toArray(imgp).reshape(x*y*3)), mae(toArray(img).reshape(x*y*3), toArray(imgq).reshape(x*y*3)),mae(toArray(img).reshape(x*y*3), toArray(imgr).reshape(x*y*3)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This should give an idea about what we want to beat."},{"metadata":{},"cell_type":"markdown","source":"Now I'll generate some training samples:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def imageListToNiceSamples(images, downscale_factor = 2, img_size = 40, n_convolutions = 4): \n    X = []\n    Y = []\n    for image in tqdm(images):\n        cutoff = n_convolutions+1\n        size = np.array(image.size)\n        samples_from_image = size//img_size\n        newimage = image.resize(size//downscale_factor, resample = Image.LANCZOS).resize(size, resample = Image.LANCZOS)\n        try:\n            image_array = toArray(image)\n            newimage_array = toArray(newimage)\n        except:\n            continue\n        X_temp = []\n        Y_temp = []\n      #  print(size, image.size, samples_from_image)\n        for j in range(samples_from_image[0]):\n            for i in range(samples_from_image[1]):\n                x = newimage_array[i*img_size:(i+1)*img_size,j*img_size:(j+1)*img_size,:]/130-0.99\n                y = image_array[i*img_size+cutoff:(i+1)*img_size-cutoff,j*img_size+cutoff:(j+1)*img_size-cutoff,:]/130-0.99 #these fit for tanh\n                x = newimage_array[i*img_size:(i+1)*img_size,j*img_size:(j+1)*img_size,:]/255+0.005\n                y = image_array[i*img_size+cutoff:(i+1)*img_size-cutoff,j*img_size+cutoff:(j+1)*img_size-cutoff,:]/255+0.005 #these are for sigmoid or no activation - I've found someone not using it.\n                \n                X_temp+=[x.reshape(1,img_size,img_size,3)]\n                Y_temp+=[y.reshape(1,img_size-2*cutoff,img_size-2*cutoff,3)]\n        X+=[np.concatenate(X_temp, axis=0)] # these may look redundant, but they actually keep memory usage from blowing up and kernel from dying\n        Y+=[np.concatenate(Y_temp, axis=0)]\n    return(np.concatenate(X, axis=0), np.concatenate(Y, axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size = 30\nn_convolutions = 4\nX_train, y_train = imageListToNiceSamples(train_data, img_size = image_size, downscale_factor = 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'd like to beat lanczos, because otherwise there isn't much point to using any of these methods.\n\nThe only way to have larger output, that I know of, is Conv2DTransposed which may also be worth looking at, but I don't see how it could be better in principle than using lanczos first.\n\nFor the Keras model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D, Dense, Activation, Dropout, Lambda, MaxPooling2D, BatchNormalization, Reshape, Flatten, Input\nfrom keras.optimizers import Nadam\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getModel(lr = 0.002, dropout_rate = .2, input_dropout = .2, mid_layer_size = 64, activation = 'sigmoid', image_size =40): # encapsulation to facilitate skopt usage, even though I didn't use it in the end.\n    opt = Nadam(lr)\n\n    \n    model = Sequential()\n    model.add(Dropout(input_dropout, input_shape = (image_size,image_size,3)))\n    model.add(Conv2D(32, (3,3), activation = 'elu', padding = 'valid', \n                     \n                    ))\n #   model.add(Dropout(dropout_rate))\n    model.add(BatchNormalization())\n    model.add(Conv2D(mid_layer_size, (3,3), activation = 'elu', padding = 'valid'))\n #   model.add(Dropout(dropout_rate))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3,3), activation = 'elu', padding = 'valid'))\n  #  model.add(Dropout(dropout_rate))\n    model.add(BatchNormalization())\n    \n    # I'll compute size of the dense layer:\n    n= (image_size-6)*(image_size-6)*3\n    model.add(Flatten())\n    model.add(Dense(n, activation = 'elu'))\n    model.add(Reshape((image_size-6, image_size-6, 3)))\n    \n    model.add(Conv2D(3, (5,5), activation = 'relu',  padding = 'valid'))\n    \n    n= (image_size-10)*(image_size-10)*3\n    model.add(Flatten())\n    model.add(Dense(n, activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(n, activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Reshape((image_size-10, image_size-10, 3)))\n    \n    model.add(Conv2D(3, (5,5), activation = activation, padding = 'same', name = 'output_layer'))\n    \n    model.compile(loss = 'mean_absolute_error', optimizer = opt)\n    return(model)\n\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae(X_train[:,5:image_size-5,5:image_size-5,:].reshape(-1,((image_size-10)*(image_size-10)*3)), y_train.reshape(-1,(image_size-10)*(image_size-10)*3)) # Because mse takes array of dim <=2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = getModel(dropout_rate = .35, input_dropout = 0.0, image_size = image_size, mid_layer_size = 64)\nmodel.summary() #to give overview of number of params\nstop = EarlyStopping(patience=10, restore_best_weights = True)\nmodel.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_split = 0.2, callbacks = [stop], verbose = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems to have gone after the identity map and not overfitting.\n\nTweaking input dropout we can discourage it from learning identity, but I'm not convinced it's a local minumum.\n\nLet's have a look at how bad the final result is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mae(model.predict(X_train).reshape(-1,(image_size-2-2*n_convolutions)**2*3), y_train.reshape(-1,(image_size-2-2*n_convolutions)**2*3)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And graphically:"},{"metadata":{"trusted":true},"cell_type":"code","source":"comp = plt.figure(figsize=(9, 13))\nfirst = comp.add_subplot(3,1,1)\nfirst.imshow(y_train[30])\nsecond =comp.add_subplot(3,1,2)\nsecond.imshow(X_train[30])\nsecond =comp.add_subplot(3,1,3)\nsecond.imshow(model.predict(np.array([X_train[30]]))[0])\ncomp.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below code was used to tweak hyperparameters but didn't show me anything substantially better."},{"metadata":{"trusted":true},"cell_type":"code","source":"#from skopt import gp_minimize\n#from skopt.space import Real, Integer\n#dropout_rate_space = Real(low = 0.0, high = 0.7)\n#mid_layer_size_space = Integer(low = 16, high = 512)\n#def f(v):\n#    model = getModel(dropout_rate = v[0], mid_layer_size= v[1])\n#    model.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_split = 0.2, callbacks = [stop], verbose = False)\n#    return(mse(model.predict(X_train).reshape(-1,(image_size-2-2*n_convolutions)**2*3), y_train.reshape(-1,(image_size-2-2*n_convolutions)**2*3)) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#res = gp_minimize(f, [dropout_rate_space, mid_layer_size_space],\n#                  n_calls = 50, n_random_starts = 6, verbose = True\n#                 )\n#print(res.v)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}