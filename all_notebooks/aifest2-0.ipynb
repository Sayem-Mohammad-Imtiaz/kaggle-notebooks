{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport cv2\nimport tensorflow.compat.v1 as tf\nimport skimage.color as color\nimport skimage.io as io\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"mydir =\"/kaggle/input/sample/\"\nN= 1\nimages = [files for files in os.listdir(mydir)][1:2]\nprint(type(images))\nprint(len(images))\n\ndata = np.zeros([N, 256, 256, 3]) #image loaded in this array\nfor count in range(N):\n    img = cv2.resize(io.imread(mydir + '/'+ images[count]), (256, 256))\n    grey = cv2.resize(cv2.imread(mydir + '/'+ images[count],0),(256,256))\n    data[count,:,:,:] = img\nprint(\"grayscale image\")\nplt.imshow(grey) #saving the input image\nplt.show()\nnum_train = N\nXtrain = color.rgb2lab(data[:num_train]*1.0/255)\nxt = Xtrain[:,:,:,0] #loading l channel as input\nyt = Xtrain[:,:,:,1:] #loading ab channel\nyt = yt/128 #normalization\nxt = xt.reshape(num_train, 256, 256, 1) #resizing inpput\nyt = yt.reshape(num_train, 256, 256, 2) #resizing output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.disable_eager_execution()\nsession = tf.Session()\nx = tf.placeholder(tf.float32, shape = [None, 256, 256, 1], name = 'x')\nytrue = tf.placeholder(tf.float32, shape = [None, 256, 256, 2], name = 'ytrue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_weights(shape):\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\ndef create_bias(size):\n    return tf.Variable(tf.constant(0.1, shape = [size]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolution(inputs, num_channels, filter_size, num_filters):\n    weights = create_weights(shape = [filter_size, filter_size, num_channels, num_filters])\n    bias = create_bias(num_filters)\n    layer = tf.nn.conv2d(input = inputs, filter = weights, strides= [1, 1, 1, 1], padding = 'SAME') + bias\n    layer = tf.nn.tanh(layer)\n    return layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def maxpool(inputs, kernel, stride):\n    layer = tf.nn.max_pool(value = inputs, ksize = [1, kernel, kernel, 1], strides = [1, stride, stride, 1], padding = \"SAME\")\n    return layer\ndef upsampling(inputs):\n    layer = tf.image.resize_nearest_neighbor(inputs, (2*inputs.get_shape().as_list()[1], 2*inputs.get_shape().as_list()[2]))\n    return layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model layers\nconv1 = convolution(x, 1, 3, 3)\nmax1 = maxpool(conv1, 2, 2)\nconv2 = convolution(max1, 3, 3, 8)\nmax2 = maxpool(conv2, 2, 2)\nconv3 = convolution(max2, 8, 3, 16)\nmax3 = maxpool(conv3, 2, 2)\nconv4 = convolution(max3, 16, 3, 16)\nmax4 = maxpool(conv4, 2, 2)\nconv5 = convolution(max4, 16, 3, 32)\nmax5 = maxpool(conv5, 2, 2)\nconv6 = convolution(max5, 32, 3, 32)\nmax6 = maxpool(conv6, 2, 2)\nconv7 = convolution(max6, 32, 3, 64)\nupsample1 = upsampling(conv7)\nconv8 = convolution(upsample1, 64, 3, 32)\nupsample2 = upsampling(conv8)\nconv9 = convolution(upsample2, 32, 3, 32)\nupsample3 = upsampling(conv9)\nconv10 = convolution(upsample3, 32, 3, 16)\nupsample4 = upsampling(conv10)\nconv11 = convolution(upsample4, 16, 3, 16)\nupsample5 = upsampling(conv11)\nconv12 = convolution(upsample5, 16, 3, 8)\nupsample6 = upsampling(conv12)\nconv13 = convolution(upsample6, 8, 3, 2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = tf.losses.mean_squared_error(labels = ytrue, predictions = conv13)\ncost = tf.reduce_mean(loss)\n# optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(cost)\n# session.run(tf.global_variables_initializer())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# saver = tf.train.Saver() #//train\n\nwith tf.Session() as session:\n    new_saver = tf.train.import_meta_graph('/kaggle/input/lasta6/a6.meta')\n    new_saver.restore(session, tf.train.latest_checkpoint('/kaggle/input/lasta6/'))\n#     num_epochs = 50\n#     for i in range(num_epochs):\n#         session.run(conv13, feed_dict = {x: xt, ytrue:yt})\n#         lossvalue = session.run(cost, feed_dict = {x:xt, ytrue : yt})\n#         print(\"epoch: \" + str(i) + \" loss: \" + str(lossvalue))\n#     saver.save(session, 'train1') #//train\n    \n    #using trained model\n    output = session.run(conv13, feed_dict = {x: xt[0].reshape([1, 256, 256, 1])})*128\n#     output = session.run( )\n\n    image = np.zeros([256, 256, 3])\n    image[:,:,0]=xt[0][:,:,0]\n    image[:,:,1:]=output[0]\n    image = color.lab2rgb(image)\n    plt.imshow(image)\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}