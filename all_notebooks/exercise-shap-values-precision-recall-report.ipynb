{"cells":[{"metadata":{"_uuid":"e7fe941fa42cc627c5e831a53797609659c3e593"},"cell_type":"markdown","source":"# Exercises\n\n## Set Up\n\nWe've had our fun and learned a fair amount with the Taxi data. But now you have enough tools to put together compelling solutions to real-world problems. The following scenario will require you to pick the right techniques for each part of your data science project. Along the way, you'll use SHAP values along with your other insights tools.\n\n**The questions below give you feedback on your work by using some checking code. Run the following cell to set up our feedback system.**"},{"metadata":{"_uuid":"4a3d724a09d8f7b3def50cda3d909f69979ee3e4","trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/ml-insights-tools')\nfrom ex4 import *\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97116e1bdf04c324541bc7cdb6eb9b93d3de1198"},"cell_type":"markdown","source":"## The Scenario\nA hospital has struggled with \"readmissions,\" where they release a patient before the patient has recovered enough, and the patient returns with health complications. \n\nThe hospital wants your help identifying patients at highest risk of being readmitted. Doctors (rather than your model) will make the final decision about when to release each patient; but they hope your model will highlight issues the doctors should consider when releasing a patient.\n\nThe hospital has given you relevant patient medical information.  Here is a list of columns in the data:\n"},{"metadata":{"_uuid":"51b5017c3981d4380de6158a44d17acdbc117308","trusted":true},"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv('../input/hospital-readmissions/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96776eb7bf6bea728296ad40c45e6b49b9911171"},"cell_type":"markdown","source":"## Step 1:\nYou have built a simple model, but the doctors say they don't know how to evaluate a model, and they'd like you to show them some evidence the model is doing something in line with their medical intuition. Create any graphics or tables that will show them a quick overview of what the model is doing?\n\nThey are very busy. So they want you to condense your model overview into just 1 or 2 graphics, rather than a long string of graphics.\n\nWe'll start after the point where you've built a basic model. Just run the following cell to build the model called `my_model`."},{"metadata":{"_uuid":"aa70aeb11e0826801c94a943852db0c5ea4b91f7","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ny = data.readmitted\n\nbase_features = [c for c in data.columns if c != \"readmitted\"]\n\nX = data[base_features]\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nmy_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eea094ac650b82e7c13c2b0e2c3def8e90340c0f"},"cell_type":"code","source":"from sklearn import metrics\nimport numpy as np\n\nmy_preds = my_model.predict(val_X)\n# A random baseline to compare our predictions to. Flip a coin for each patient.\nbaseline_preds = np.random.rand(len(val_y))\n\ndef report_summary_stats(predictions):\n    # Round to binary 0/1 predictions\n    pred_labels = predictions.round()\n    acc = metrics.accuracy_score(val_y, pred_labels)\n    pre = metrics.precision_score(val_y, pred_labels)\n    rec = metrics.recall_score(val_y, pred_labels)\n    print(\"Accuracy = {:.1%}, Precision = {:.1%}, Recall = {:.1%}\".format(\n        acc, pre, rec\n    ))\n    \nprint(\"** Our model **\")\nreport_summary_stats(my_preds)\nprint(\"** Random baseline **\")\nreport_summary_stats(baseline_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3552edfe19da37267c77b454a28c0e3fd6aa3d0"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_precision_recall_curve(preds):\n    plt.figure(figsize=(12, 8))\n    precision, recall, _ = metrics.precision_recall_curve(val_y, preds)\n\n    average_precision = metrics.average_precision_score(val_y, preds)\n\n    plt.step(recall, precision, color='b', alpha=0.2,\n             where='post')\n    plt.fill_between(recall, precision, step='post', alpha=0.2,\n                     color='b')\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    plt.title('2-class Precision-Recall curve: Average Precision={0:0.2f}'.format(\n              average_precision))\n    \nplot_precision_recall_curve(my_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4aa4ca20a2631c12a702d03142e6b21e9d31a8ea"},"cell_type":"code","source":"# Baseline precision-recall curve\nplot_precision_recall_curve(baseline_preds)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}