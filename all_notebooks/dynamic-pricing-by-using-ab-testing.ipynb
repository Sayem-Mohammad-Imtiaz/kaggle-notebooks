{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Business Problem\n\nA Game Company gives gift coins to their users for purchasing items.\n\nThe users purchase various tools for their characters by using this coins.\n\nThe company does not remark any price for any item and it provides users to buy this item at the price they wanted.\n\nIn other words while one user pay 30 units for any item, other user also might pay 45 units for the same item. Therefore, users could buy this item with the amounts that they can afford to pay.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Project Goal\n\n1. Are there any difference for item's price according to category id's?\n2. What price should it be for this item?\n3. The company wants to be flexible for the price. Therefore, create a decision support system for price strategies.\n4. Simulate item purchases and income for price change possibilities.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Dataset and Descriptive Statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings \nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ = pd.read_csv(\"/kaggle/input/pricing/pricing.csv\", sep=\";\")\ndf = df_.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Defining functions for taking a quick look to dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_data(dataframe, head=5):\n    \"\"\"It returns descriptive statistics and information about a given dataset\"\"\"\n    print (\"####### SHAPE #######\")\n    print (dataframe.shape)\n    print (\"####### INFO #######\")\n    print (dataframe.info ())\n    print (\"####### DESCRIBE #######\")\n    print (dataframe.describe ([0.01, 0.1, 0.25, 0.50, 0.75, 0.9, 0.95, 0.99]))\n    print (\"####### NA VALUES #######\")\n    print (dataframe.isnull ().sum ())\n    print (\"####### FIRST {} ROWS #######\".format (head))\n    print (dataframe.head (head))\n    \ndef defining_quantile_th(dataframe, col, quantilelow=0, quantileup=1):\n    \"\"\"It returns, when outliers were truncated by using given quantiles what percentage of observations will be affected\"\"\"\n    up_ratio = (len (dataframe[dataframe[col] > dataframe[col].quantile (quantileup)]) / dataframe[col].shape[0]) * 100\n    low_ratio = (len (dataframe[dataframe[col] < dataframe[col].quantile (quantilelow)]) / dataframe[col].shape[\n        0]) * 100\n    total_ratio = up_ratio + low_ratio\n    print (\n        \"When quantified in the {} - {} range, %{} of customers' data will be truncated.\".format (\n            quantilelow, quantileup, round (total_ratio, 2)))\n    \ndef outliers_threshold(dataframe, col, low_ratio, up_ratio):\n    \"\"\"It truncates the outliers by using given low and up quantiles and assings to given column of dataset\"\"\"\n    threshold_range = dataframe[col].quantile (up_ratio) - dataframe[col].quantile (low_ratio)\n    up_limit = dataframe[col].quantile (up_ratio) + 1.5 * threshold_range\n    low_limit = dataframe[col].quantile (low_ratio) - 1.5 * threshold_range\n    dataframe.loc[dataframe[col] > up_limit, \"price\"] = up_limit\n    dataframe.loc[dataframe[col] < low_limit, \"price\"] = low_limit\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_data (df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"defining_quantile_th (df, \"price\", 0.05, 0.95) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"price\"].value_counts ().sort_values (ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking a quick look to the distribution of prices, before data manipulation by using distplot\nsns.distplot (df[\"price\"])\nplt.xlabel(\"Price\")\nplt.ylabel(\"Density\")\nplt.title(\"Before Data Manipulation, The Distribution of Prices\", size=(15), color=\"blue\")\nplt.show ();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking a quick look to the distribution of prices for each category ids, before data manipulation by using boxplot\nsns.boxplot (x=\"category_id\", y=\"price\", data=df)\nplt.xlabel(\"Category ID\")\nplt.ylabel(\"Price\")\nplt.title(\"Before Data Manipulation, The Distribution of Prices\", size=(15), color=\"blue\")\nplt.show ();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Truncating outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_threshold (df, \"price\", 0.05, 0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_data (df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The distribution of prices after data manipulation\ndf[\"price\"].value_counts ().sort_values (ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking a quick look to the distribution of prices, after data manipulation by using distplot\nsns.distplot (df[\"price\"])\nplt.xlabel(\"Price\")\nplt.ylabel(\"Density\")\nplt.title(\"After Data Manipulation, The Distribution of Prices\", size=(15), color=\"blue\")\nplt.show ();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking a look to some of descriptive statistics for each category ids\ndf.groupby (\"category_id\").agg ({\"price\": [\"count\", \"median\", \"mean\", \"std\", \"min\", \"max\"]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking a quick look to the distribution of prices for each category ids, after data manipulation by using boxplot\nsns.boxplot (x=\"category_id\", y=\"price\", data=df)\nplt.xlabel(\"Category ID\")\nplt.ylabel(\"Price\")\nplt.title(\"After Data Manipulation, The Distribution of Prices\", size=(15), color=\"blue\")\nplt.show ();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A/B Testing\n\nDefining functions for checking the normality and do ab testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def normality_test(dataframe, col, class_col):\n    \"\"\"It returns a dataframe which has normality test results of given column and classes of column. \n    It also returns two lists while one has classes of column as non-normal distribution \n    and the other has normal distribution.\"\"\"\n    # H0 : normal distribution\n    # H1 : nonnormal distribution\n    from scipy.stats import shapiro\n    category_ids = list (set (dataframe[class_col]))\n    df = pd.DataFrame()\n    nonnormal = []\n    normal = []\n    for i in category_ids:\n        ttest, p_value = shapiro (dataframe.loc[dataframe[class_col] == i, col])\n        if p_value < 0.05:\n            df = df.append({\"Category_ID\":str(i),\"Distribution\": \"Non-normal Distribution\", \"Hypothesis_Situation\":\"H0 was Rejected\"}, ignore_index=True)\n            nonnormal.append(i)\n        else:\n            df = df.append ({\"Category_ID\": str (i), \"Distribution\": \"Normal Distribution\", \"Hypothesis_Situation\":\"H0 was Failed to Reject\"}, ignore_index=True)\n            normal.append(i)\n    return nonnormal, normal, df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nonnormal_list, normal_list, normality_df = normality_test (df, \"price\",\"category_id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normality_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **\"Normal Distribution\" hypothesis is declined for all category ids. It means that all categories are distributed non-normally.Therefore we could skip the Homogeneity of Variance Test. Let's pass to A/B Testing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def nonparametric_ind_ab_test(dataframe, col, class_col, nonnormally_list):\n    \"\"\"It returns two lists end of the nonparametric independent ab testing \n    while one has the classes of similar averages \n    and the other has the classes of different averages.\"\"\"\n    # H0: There is no difference between the average  of two groups\n    # H1: There is difference between the average of two groups\n    from scipy.stats import mannwhitneyu\n    different_avg = []\n    similar_avg = []\n    for i in range (len (nonnormally_list)):\n        for k in range (i + 1, len (nonnormally_list)):\n            ttest_lev, p_value_lev = mannwhitneyu ((dataframe.loc[df[class_col] == nonnormally_list[i], col]),\n                                                   (dataframe.loc[dataframe[class_col] == nonnormally_list[k], col]))\n            if p_value_lev < 0.05:\n                different_avg.append ((nonnormally_list[i], nonnormally_list[k]))\n            else:\n                similar_avg.append ((nonnormally_list[i], nonnormally_list[k]))\n    return similar_avg, different_avg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Let's take a look at the categories which their averages are similar and different.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_avg, diff_avg = nonparametric_ind_ab_test (df, \"price\", \"category_id\", nonnormal_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting a dataframe of non-parametric ab testing results.\nsim_df = pd.DataFrame ({\"Category_IDs\": sim_avg})\nsim_df[\"AB_Test_Result\"] = \"No difference\"\n\ndiff_df = pd.DataFrame ({\"Category_IDs\": diff_avg})\ndiff_df[\"AB_Test_Result\"] = \"There is a difference\"\n\nab_test_df = pd.concat ([sim_df, diff_df], axis=0).reset_index (drop=True)\nab_test_df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def comparing(dataframe, col, class_col, list_):\n    \"\"\"It compares the classes of column in a given list by using some of descriptive statistics\"\"\"\n    for i in list_:\n        new_df = pd.concat ([dataframe[dataframe[class_col] == i[0]], dataframe[dataframe[class_col] == i[1]]],\n                            axis=0).reset_index (drop=True)\n        print (new_df.groupby (class_col).agg ({col: [\"mean\", \"median\", \"std\"]}))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Comparing descriptive statistics of categories which have different averages**"},{"metadata":{"trusted":true},"cell_type":"code","source":"comparing (df, \"price\", \"category_id\", diff_avg) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **I would like to accept categories which have similar averages as a single category**"},{"metadata":{"trusted":true},"cell_type":"code","source":"similar_categories = set ()\nfor i in sim_avg:\n    similar_categories.add (i[0])\n    similar_categories.add (i[1])\n\ndifferent_categories = set (df[\"category_id\"].unique()) - similar_categories\n\ndifferent_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"similar_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def price_df(dataframe, low_price, high_price, median_price, method_name):\n    \"\"\"It returns a dataframe which calculates incomes and count that affected with given low, high and median prices.\"\"\"\n    mean_price = (low_price + high_price) / 2\n    income_p_mean = dataframe.loc[dataframe[\"price\"] >= mean_price].shape[0] * mean_price\n    income_p_median = dataframe.loc[dataframe[\"price\"] >= median_price].shape[0] * median_price\n    income_p_lower = dataframe.loc[dataframe[\"price\"] >= low_price].shape[0] * low_price\n    income_p_upper = dataframe.loc[dataframe[\"price\"] >= high_price].shape[0] * high_price\n    df = pd.DataFrame ({\"Income_according_to_mean\": income_p_mean,\n                        \"Mean_price\": [mean_price],\n                        \"Mean_count\": [dataframe.loc[dataframe[\"price\"] >= mean_price].shape[0]],\n                        \"Income_according_to_median\": income_p_median,\n                        \"Median_price\":[median_price],\n                        \"Median_count\":[dataframe.loc[dataframe[\"price\"] >= median_price].shape[0]],\n                        \"Income_according_to_low_price\": income_p_lower,\n                        \"Lower_price\": [low_price],\n                        \"Low_price_count\": [dataframe.loc[dataframe[\"price\"] >= low_price].shape[0]],\n                        \"Income_according_to_high_price\": income_p_upper,\n                        \"High_price\": [high_price],\n                        \"High_price_count\": [dataframe.loc[dataframe[\"price\"] >= high_price].shape[0]]})\n    df.insert (loc=0, column=\"Method\", value=[method_name])\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confidence Intervals"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Determining lower and upper limits of confidence intervals and average of lower and upper limits and mean values \n# according to determined categories\n\nfrom statsmodels.stats.api import DescrStatsW\n\nlower, upper = DescrStatsW (df[\"price\"]).tconfint_mean ()\nmedian_all = df[\"price\"].median()\n\nall_df = price_df (df, lower, upper, median_all, \"According_to_all_cat_ids\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"low_lim, high_lim = DescrStatsW (df.loc[df[\"category_id\"] != 326584, \"price\"]).tconfint_mean ()\nmedian_exc32 = df.loc[df[\"category_id\"] != 326584, \"price\"].median()\n\nexc_cat3_df = price_df (df, low_lim, high_lim, median_exc32, \"Excepted_326584_id_prices\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"low_limit, high_limit = DescrStatsW (df.loc[df[\"category_id\"] != 489756, \"price\"]).tconfint_mean ()\nmedian_exc48 = df.loc[df[\"category_id\"] != 489756, \"price\"].median()\n\nexc_cat4_df = price_df (df, low_limit, high_limit, median_exc48, \"Excepted_489756_id_prices\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_lim, higher_lim = DescrStatsW (df.loc[(df[\"category_id\"] != 489756) & (df[\"category_id\"] != 326584), \"price\"]).tconfint_mean ()\nmedian_similar = df.loc[(df[\"category_id\"] != 489756) & (df[\"category_id\"] != 326584), \"price\"].median()\n\nsimilar_prices_df = price_df (df, lower_lim, higher_lim, median_similar, \"Similar_cat_id_prices\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.concat([all_df, exc_cat3_df, exc_cat4_df, similar_prices_df]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"Lower_price\", y=\"Income_according_to_low_price\", hue=\"Method\", data=final_df, \n                size = round(final_df[\"Income_according_to_low_price\"], 2), sizes=(30,300))\nplt.xlabel(\"Lower Limit of Confidence Interval of 4 Methods\")\nplt.ylabel(\"Incomes\")\nplt.title(\"Price-Income\", size=(15), color=\"blue\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_df = (final_df[[\"Method\",\"Income_according_to_median\", \"Median_price\", \"Median_count\"]]\n .sort_values(by=\"Income_according_to_median\",ascending=False)).reset_index(drop=True)\n\nmedian_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = final_df.drop([\"Income_according_to_median\", \"Median_price\", \"Median_count\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Arranging a new dataframe according to confidence interval limits and averages\n\nlow_confint_df = temp_df.iloc[:,4:7]\nhigh_confint_df = temp_df.iloc[:, 7:]\navg_confint_df = temp_df.iloc[:, 1:4]\n\nlow_confint_df[\"Approach\"] = \"Lower Limit of Confidence Interval\"\nhigh_confint_df[\"Approach\"] = \"Upper Limit of Confidence Interval\"\navg_confint_df[\"Approach\"] = \"Average Value of Confidence Interval\"\n\nlow_confint_df.rename(columns={\"Income_according_to_low_price\":\"Income\",\n                              \"Lower_price\":\"Price\",\n                              \"Low_price_count\":\"Count\"}, inplace=True)\nhigh_confint_df.rename(columns={\"Income_according_to_high_price\":\"Income\",\n                              \"High_price\":\"Price\",\n                              \"High_price_count\":\"Count\"}, inplace=True)\navg_confint_df.rename(columns={\"Income_according_to_mean\":\"Income\",\n                              \"Mean_price\":\"Price\",\n                              \"Mean_count\":\"Count\"}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_list = [high_confint_df, avg_confint_df, low_confint_df]\nfor i in conf_list:\n    i.insert(0, \"Method\", final_df[[\"Method\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_df = pd.concat(conf_list, axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_df.insert(4, \"User_Ratio\" ,round(conf_df[\"Count\"]/len(df), 4))\nconf_df[\"Price\"] = round(conf_df[\"Price\"], 2)\nconf_df[\"Income\"] = round(conf_df[\"Income\"], 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_df = conf_df.sort_values(by=\"Income\", ascending=False)\nconf_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x=\"Price\", y=\"Income\", data=conf_df)\nplt.xlim((38, 46))\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(conf_df[\"Price\"])\nplt.show();\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nPrices are not normally distributed according to category ids. That is why non-parametric A/B Testing was performed. As a result of A/B Testing, it was observed that there was no statistically significant difference between the price averages of 201436, 361254, 675201, 874521 category ids and these category ids were accepted as a single category in some calculations. It was observed that the averages of 326584, 489756 category ids were statistically different from the others. These two category ids were evaluated as two seperate groups.\n\nBecause the data were not normally distributed, the median values of each category were examined. In order to provide price flexibility, calculations were made according to the lower and upper limits of the 95% confidence interval and the average values of the lower and upper limits.\n\nWhat should be the price of the item? The price is determined by four different methods.\n* To determine the median value of all prices in whole dataset as price without distinction between categories.\n* To determine the median value of the prices of similar categories as price.\n* To determine the median value of the prices outside the category id 326584 as price.\n* To determine the median value of the prices outside the category id 489756 as price.\n\nWhen the median value of the prices other than the 489756 category id is considered as the item price; the item price was 34.21 units, and the total income reached its highest value with 67754.14 units.\n\nWhat should be the price flexibility? The income distribution was examined by determining the lower and upper limit of confidence interval values and the average of the lower and upper limit values of each 4 different methods as price. When the confidence interval of prices outside the category id of 489756 is 39.88 units, which is the average of the lower and upper limit, it has been observed that the income is 37687.13 units and reaches the highest value.\n\nIt has been observed that the price range is between 38.74 and 44.96 units, and a graph of the income obtained according to the relevant prices has been created. As analyzed on the graph it is seen when the unit price increases, the income decreases.\n \nIn the analyzed dataset; a single price was applied to all categories because there are no concepts such as cost, category features, flexibility of transition between categories. However, incase of having detailed information about the relevant situations, the pricing specific to each category can be examined in detail.\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}