{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Glass Classification"},{"metadata":{},"cell_type":"markdown","source":"**Data Description**\n\n1) RI: refractive index\n\n2) Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n\n3) Mg: Magnesium\n\n4) Al: Aluminum\n\n5) Si: Silicon\n\n6) K: Potassium\n\n7) Ca: Calcium\n\n8) Ba: Barium\n\n9) Fe: Iron\n\n**Type of glass: (class attribute)**\n\n1) buildingwindowsfloatprocessed\n\n2) buildingwindowsnonfloatprocessed \n\n3) vehiclewindowsfloatprocessed\n\n4) vehiclewindowsnonfloatprocessed (none in this database)\n\n5) containers\n\n6) tableware\n\n7) headlamps"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(43)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"ggplot\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/glass/glass.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import parallel_coordinates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nparallel_coordinates(df, \"Type\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as msno","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"Type\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.groupby(\"Type\").min())\nprint(\"------------------------------------------------------------------\")\nprint(df.groupby(\"Type\").max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = df.columns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,3, figsize=(10,10))\naxes_all = [axes for axes_row in ax for axes in axes_row]\nfor i, c in enumerate(df[col]):\n    if c  == \"Type\":\n        break\n    else:\n        sns.boxplot(df[c], data = df, ax = axes_all[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detecting the no of outliers present in our data\n\ndef outlier_func(data, col):\n    \n    Q1 = df.quantile(q = 0.25, axis = 0)\n    Q3 = df.quantile(q = 0.70, axis = 0)\n    IQR = Q3-Q1\n    \n    min_val = Q1 - 1.5*IQR\n    max_val = Q3 + 1.5*IQR\n    \n    df1 = df[df[col] <=  min_val[col]].shape[0]\n    df2 = df[df[col] >=  max_val[col]].shape[0]\n    \n    print(f\"There are {df1 + df2} total number of outliers in which {df1} datapoints are below or equals to the Q1 Deviation {Q1[col]} and {df2} are above or equal to the {Q3[col]}\\n\")\n    print(f\"The IQR of '{col}' is: {IQR[col]}\")\n    \n    print(f\"The Q1 Deviation of '{col}' is: {Q1[col]}\")\n    print(f\"The Q3 Deviation of '{col}' is: {Q3[col]} \\n\")\n    \n    print(\"The min value is:\", min(data[col]))\n    print(\"The max value is:\", max(data[col]), \"\\n\")\n    \n    print(\"The skewness is: \",scipy.stats.skew(data[col]))\n    print(\"The Kurtosis is: \",scipy.stats.kurtosis(data[col]))\n    \n    \n    \n    #Also returning the visual representation of the outlier\n    \n    plt.figure(figsize=(8,6))\n    sns.distplot(data[col], color = 'g')\n    plt.axvline(df[col].mean(), linestyle = '--', color = 'k')\n    plt.axvline(df[col].median(), linestyle = '--', color = 'orange')\n    \n    plt.axvspan(xmin = Q1[col], xmax=data[col].min(), alpha = 0.15, color = 'r')\n    plt.axvspan(xmin = Q3[col], xmax=data[col].max(), alpha = 0.15, color = 'r')\n    \n    plt.legend([\"Mean\", \"Median\",\"Outlier Bound\"])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"outlier_func(df, \"RI\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Ba\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(labels = 'Ba', axis = 1, inplace = True) #Lets remove the 'Ba' from our datset as most of the values are 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.heatmap(corrmat, annot = True, cmap = 'Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(labels = \"RI\", axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.heatmap(df.corr(), annot = True, cmap = 'Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, :7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df.iloc[:, 7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = []\ntrain_score = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,16):\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train, y_train)\n    \n    train_score.append(knn.score(X_train, y_train))\n    test_score.append(knn.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1,16), train_score)\nplt.plot(range(1,16), test_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As per the above plot we can see that the 1 neighbors will be the ideal but we know if try to use the n with 1 it will overfit our model so we do not want that."},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets try to standardize the data and then try\n#We will also on additional parameter to \nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"se = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_col = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_std = se.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_std = pd.DataFrame(X_std, columns = X_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_std.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_std.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_std, y , test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = []\ntrain_score = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,16):\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train, y_train)\n    \n    train_score.append(knn.score(X_train, y_train))\n    test_score.append(knn.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1,16), train_score)\nplt.plot(range(1,16), test_score, linestyle = '--', marker = '*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(y_test, y_pred) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_std, y , test_size = 0.2, random_state = 0, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbors = [x for x in range(1,16)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_score = []\nfor k in neighbors:\n    KNN = KNeighborsClassifier(n_neighbors = k)\n    scores = cross_val_score(KNN, X, y, cv = 10, scoring = 'accuracy')\n    cross_score.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MSE = [1-x for x in cross_score]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(neighbors, MSE)\nplt.xlabel(\"K Neighbors\")\nplt.ylabel(\"Error\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So based on this, our best value for k is 3\nKNN_Model = KNeighborsClassifier(n_neighbors = 3)\nKNN_Model_Fit = KNN_Model.fit(X_train, y_train)\nKNN_Model_Predict = KNN_Model_Fit.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(round(accuracy_score(y_test, KNN_Model_Predict) * 100),\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, KNN_Model_Predict))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets Try to Standardize the data after splitting the data and see if our accuracy improved or not\n#By normalizing or standardizing the data after splitting, means we can avoid the issue of data leakage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X, y, test_size = 0.2, random_state =0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now try to standardize the data\nse_new = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_std = se_new.fit_transform(X_train_n)\nX_test_std = se_new.fit_transform(X_test_n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So based on this, our best value for k is 3\nKNN_Model = KNeighborsClassifier(n_neighbors = 3)\nKNN_Model_Fit = KNN_Model.fit(X_train_std, y_train)\nKNN_Model_Predict = KNN_Model_Fit.predict(X_test_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(round(accuracy_score(y_test, KNN_Model_Predict) * 100),\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, KNN_Model_Predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our accuracy score is not good because of the class imbalance and to fix this we can use some sampling techniques to tackle the class imbalance issue which I will be trying soon.\n\nIf you like this kernel, please do upvote. I am new to Machine Learning so if you have some feedbacks, please feel free to share with me."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}