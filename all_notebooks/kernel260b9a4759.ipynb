{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing the libraries\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nimport os\nimport scipy.io\nimport math\n\nfrom sklearn.utils import shuffle\n\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls '/kaggle/input/fashion-product-images-dataset/fashion-dataset'\nstyles = pd.read_csv('/kaggle/input/fashion-product-images-dataset/fashion-dataset/styles.csv', error_bad_lines=False)\n\nshirts = styles[styles['articleType'].isin(['Shirts'])]\ntshirts = styles[styles['articleType'].isin(['Tshirts'])]\npants =  styles[styles['articleType'].isin(['Track Pants','Shorts', 'Trunk', 'Trousers', 'Track Pants', 'Tights', 'Lounge Pants', 'Lounge Shorts', 'Leggings', 'Jeans', 'Jeggings'])]\n# np.unique(styles['articleType'])\nshirts, tshirts, pants = shirts['id'].to_numpy(), tshirts['id'].to_numpy(), pants['id'].to_numpy()\nshirts.shape, tshirts.shape, pants.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path = '/kaggle/input/fashion-product-images-dataset/fashion-dataset/images/'\nIMG_SIZE = 128\nLIMIT_IMAGES = 2400\nNUM_OUTPUTS = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shirt_images = []\nfor shirt in shirts[:LIMIT_IMAGES]:\n    img = cv2.imread(f'{image_path}{shirt}.jpg')\n    if img is None:\n        continue\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = img.astype('float32')\n    img = img / 255.0\n    shirt_images.append(img)\nshirt_images = np.array(shirt_images)\nshirt_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tshirt_images = []\nfor tshirt in tshirts[:LIMIT_IMAGES]:\n    img = cv2.imread(f'{image_path}{tshirt}.jpg')\n    if img is None:\n        continue\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = img.astype('float32')\n    img = img / 255.0\n    tshirt_images.append(img)\ntshirt_images = np.array(tshirt_images)\ntshirt_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pant_images = []\nfor pant in pants[:LIMIT_IMAGES]:\n    img = cv2.imread(f'{image_path}{pant}.jpg')\n    if img is None:\n        continue\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = img.astype('float32')\n    img = img / 255.0\n    pant_images.append(img)\npant_images = np.array(pant_images)\npant_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.concatenate((shirt_images, tshirt_images, pant_images), axis = 0)\n# Y = np.concatenate((np.repeat(np.array((1,0,0)), shirt_images.shape[0]), np.repeat(np.array((1,0,0)), tshirt_images.shape[0]), np.repeat(np.array((1,0,0)), pant_images.shape[0])))\nY = np.repeat([0, 1, 2], [shirt_images.shape[0], tshirt_images.shape[0], pant_images.shape[0]], axis=0)\n# X = np.concatenate((shirt_images, pant_images), axis = 0)\n# Y = np.concatenate((np.repeat(0, shirt_images.shape[0]), np.repeat(2, pant_images.shape[0])))\nX.shape, Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, Y = shuffle(X, Y)\nX.shape, Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, test_x, trainY, test_y = train_test_split(X, Y, test_size = 0.1)\ntrain_x, val_x, train_y, val_y = train_test_split(trainX, trainY, test_size = 0.2)\n(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)\n\n# train_x = train_x.reshape(train_x.shape[0], train_x.shape[3], IMG_SIZE, IMG_SIZE)\ntrain_x  = torch.from_numpy(train_x)\ntrain_x = train_x.permute(0,3,1,2)\ntrain_y = train_y.astype(int);\ntrain_y = torch.from_numpy(train_y)\n\n# val_x = val_x.reshape(val_x.shape[0], val_x.shape[3], IMG_SIZE, IMG_SIZE)\nval_x  = torch.from_numpy(val_x)\nval_x = val_x.permute(0,3,1,2)\nval_y = val_y.astype(int);\nval_y = torch.from_numpy(val_y)\ntrain_x.shape, train_y.shape, val_x.shape, val_y.shape\n\n# test_x = test_x.reshape(test_x.shape[0], test_x.shape[3], IMG_SIZE, IMG_SIZE)\ntest_x  = torch.from_numpy(test_x)\ntest_x = test_x.permute(0,3,1,2)\ntest_y = test_y.astype(int);\ntest_y = torch.from_numpy(test_y)\ntrain_x.shape, train_y.shape, val_x.shape, val_y.shape, test_x.shape, test_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(Module):   \n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.cnn_layers = Sequential(\n            # Defining a 2D convolution layer\n            Conv2d(3, 4, kernel_size=3, stride=1, padding=1),\n            BatchNorm2d(4),\n            ReLU(inplace=True),\n            MaxPool2d(kernel_size=2, stride=2),\n            # Defining another 2D convolution layer\n            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n            BatchNorm2d(4),\n            ReLU(inplace=True),\n            MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.linear_layers = Sequential(\n            Linear(int(IMG_SIZE * IMG_SIZE / 4), NUM_OUTPUTS)\n        )\n\n    # Defining the forward pass    \n    def forward(self, x):\n        x = self.cnn_layers(x)\n        # x = x.view(x.size(0), -1)\n        x = x.reshape(x.size(0), -1)\n        x = self.linear_layers(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net()\noptimizer = Adam(model.parameters(), lr=0.07)\ncriterion = CrossEntropyLoss()\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(epoch):\n    model.train()\n    tr_loss = 0\n    # getting the training set\n    X_train, Y_train = Variable(train_x), Variable(train_y)\n    # getting the validation set\n    X_val, Y_val = Variable(val_x), Variable(val_y)\n    # converting the data into GPU format\n    if torch.cuda.is_available():\n        X_train = X_train.cuda()\n        Y_train = Y_train.cuda()\n        X_val = X_val.cuda()\n        Y_val = Y_val.cuda()\n\n    # clearing the Gradients of the model parameters\n    optimizer.zero_grad()\n    \n    # prediction for training and validation set\n    output_train = model(X_train)\n    output_val = model(X_val)\n\n    # computing the training and validation loss\n    loss_train = criterion(output_train, Y_train)\n    loss_val = criterion(output_val, Y_val)\n    train_losses.append(loss_train.item())\n    val_losses.append(loss_val.item())\n\n    # computing the updated weights of all the model parameters\n    loss_train.backward()\n    optimizer.step()\n    tr_loss = loss_train.item()\n    if epoch%2 == 0:\n        # printing the validation loss\n        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 40\ngeneration_num = 0\ntrain_losses = []\nval_losses = []\nbest_loss = 100000000000\nbest_model = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generation_num += 1\nfor epoch in range(n_epochs):\n    torch.cuda.empty_cache()\n    train(epoch)\n    if best_loss > val_losses[-1]:\n        best_loss = val_losses[-1]\n        best_model = model.state_dict()\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction for training set\nwith torch.no_grad():\n  if(torch.cuda.is_available()):\n    output = model(train_x.cuda())\n  else:\n    output = model(train_x)\n    \nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy on training set\ntrain_sample_accuracy = accuracy_score(train_y, predictions)\nprint(\"Accuracy on In-Sample Training Set: %s\"% train_sample_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction for validation set\nwith torch.no_grad():\n  if(torch.cuda.is_available()):\n    output = model(val_x.cuda())\n  else:\n    output = model(val_x)\n    \nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy on validation set\nval_sample_accuracy = accuracy_score(val_y, predictions)\nprint(\"Accuracy on In-Sample Validation Set: %s\"% val_sample_accuracy)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction for out-of-sample set\nwith torch.no_grad():\n  if(torch.cuda.is_available()):\n    output = model(test_x.cuda())\n  else:\n    output = model(test_x)\n    \nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy on out-of-sample set\nout_sample_accuracy = accuracy_score(test_y, predictions)\nprint(\"Accuracy on Out-Of-Sample Validation (Test) Set: %s\"% out_sample_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.save(model.state_dict(), f'model_{generation_num}.h5')\ntorch.save(model.state_dict(), f'/kaggle/working/model_3_bigset_{generation_num}.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_url = \"https://www.lordsindia.com/image/cache/1/TROUSER/NEW%20TROUSER%202019/a480b0c2e22dcccf2276c4116ad6ff10-500x500.jpg\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"response = requests.get(image_url)\npil_img = Image.open(BytesIO(response.content))\n\nraw_img = np.array(pil_img)\nraw_img = raw_img [:,:,::-1].copy()\nraw_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)\nraw_img = cv2.resize(raw_img, (IMG_SIZE, IMG_SIZE))\nplt.imshow(raw_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nparr = np.array([raw_img])\nnparr = nparr.astype('float32')\nnparr /= 255\n\npred_x  = torch.from_numpy(nparr)\npred_x = pred_x.permute(0,3,1,2)\n\n# prediction for out-of-sample set\nwith torch.no_grad():\n  if(torch.cuda.is_available()):\n    output = model(pred_x.cuda())\n  else:\n    output = model(pred_x)\n    \nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.numpy())\npredictions = np.argmax(prob, axis=1)\n\nprint(predictions)\nprint(\"Shirt\" if predictions[0] == 0 else \"Tshirt\" if predictions[0] == 1 else \"Pant\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}