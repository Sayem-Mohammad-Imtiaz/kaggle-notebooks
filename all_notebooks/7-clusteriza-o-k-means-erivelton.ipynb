{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**[Voltar para a Página Inicial do Curso](https://www.kaggle.com/c/ml-em-python)**\n\n# **Clusterização**\nA clusterização ou agrupamento é uma técnica de aprendizado de máquina **não-supervisionada**. Na criação do modelo de clusterização não usamos a target, por isso é chamado de não-supervisionado. Também não fazemos a separação do dataset entre treino e teste. Usamos todos os dados, sem fazer divisões das linhas dos dados. No aprendizado não-supervisionado, chamamos as colunas do dataset de **dimensões** e não mais de atributos ou variáveis. Por exemplo, no dataset de Flores (iris dataset) temos 4 dimensões: altura da pétala, largura da pétala, altura da sépala e largura da sépala. \n\n![](https://blog.bismart.com/hs-fs/hubfs/Imported_Blog_Media/ClassificationAndClustering/Clustering&clasification-Animales.gif?width=900&name=Clustering&clasification-Animales.gif)\n\nCom várias imagens não rotuladas, poderíamos usar clusterização para agrupar as imagens por semelhança. Inclusive seria possível identificar as anomalias, ou seja, aqueles casos que são diferentes de todos os demais.\n![](https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/face-clustering/face_clustering_animation.gif)\n\nA Clusterização pode ser usada tanto na preparação de dados para descobrir padrões ainda desconhecidos quanto para a criação de modelos com o objetivo de criar grupos, separando os dados em grupos ainda desconhecidos. A clusterização já é aplicada em diversos cenários, como no reconhecimento de padrões, análise de imagens, no agrupamento de espécies, na detecção de anomalias, na compressão de dados, no agrupamento de clientes, na classificação de documentos, no agrupamento de notícias.\n\n### O resultado pode ser bem diferente do que você esperava. \nSua intenção era em separar as imagens entre: imagens de cachorros x imagens de comida. Mas ao invés disso, os clusters foram criados de outra forma e o resultado foi este. \n![](https://www.vuzo.co.uk/wp-content/uploads/2018/10/Vuzo-Blog-chihuahuas-and-muffins.jpeg)\n![](https://pbs.twimg.com/media/DXGH9PZX4AADYsS.jpg:large)\n![](https://pbs.twimg.com/media/DCKduB-UMAAIRmX.jpg)\n![](https://cookvids.co.uk/wp-content/uploads/2017/09/krosanai__700.jpg)\n![](https://pbs.twimg.com/media/Cd3RI19WIAE5Dr9.jpg)\n![](https://www.lifewithdogs.tv/wp-content/uploads/2016/03/3.11.16-Labradoodle-Fried-Chicken4.jpg)\n\n**Conteúdo:**\n1. O que é K-means?\n2. Em mais detalhes: como calculamos a distância?\n3. Como avaliar o modelo?\n4. Como descobrir o número ideal de clusters?\n5. Model Tuning\n6. Exercício\n7. Conclusão\n8. Material Complementar"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualiza o scatterplot de duas dimensões\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom bokeh.sampledata.iris import flowers as floresdf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Quantos grupos existem nos dados\nplt.scatter(x=floresdf.petal_length, y=floresdf.petal_width)\nplt.xlabel('Largura da Pétala')\nplt.ylabel('Altura da Pétala')\nplt.title('Quantos CLUSTERS existem aqui?')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Faz o gráfico \nsns.scatterplot(x=floresdf.petal_length, y=floresdf.petal_width, hue=floresdf.species)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualiza em Matriz\nsns.pairplot(floresdf, hue=\"species\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# O que é K-MEANS?\nPara a clusterização, existem vários algoritmos. O mais utilizado é o K-means. O K-means costuma ser mais aplicado em dados com poucas dimensões de dados numéricos e continuos para organizar os dados em grupos categóricos. O **K-Means** tem o objetivo de dividir as observações em k clusters. K é o número de clusters. Esta divisão dos dados entre os clusters tem que ser de forma que os diferentes clusters fiquem mais separados entre eles, enquanto que as observações dentro de cada cluster fiquem mais próximas entre elas. Para isso, é utilizada a soma dos erros quadrados ou Sum of Squared Errors (SSE) que busca minimizar a distância entre os pontos e seu centroid. Depois que o modelo é criado, o K-means quando é aplicado lembra a média de cada cluster, também chamada de **centroids** e, com isso, encontra o centroid mais próximo a cada novo dado. O centroid representa o centro do cluster.\n\n![](https://www.saedsayad.com/images/Clustering_kmeans_c.png)\n\nA clusterização com K-means compreende as seguintes etapas:\n1. Inicialização: a localização dos centroids são geradas aleatoriamente\n2. Designação: os K clusters são criados associando cada observação ao seu centroid mais próximo\n3. Atualização: o centroid de cada cluster se torna a nova média do cluster\nEste processo é repetido várias vezes até convergir. \n\n![](https://stanford.edu/~cpiech/cs221/img/kmeansViz.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"flores = floresdf.iloc[:,2:4].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importa a biblioteca kmeans\nfrom sklearn.cluster import KMeans\n\n# Se não colocarmos o número de clusters, o valor default de número de clusters é de 8 clusters.\nmodelokm = KMeans(n_clusters=3)\n\n# Cria o modelo de clusterização para agrupar os dados de flores\nmodelokm = modelokm.fit(flores)\n\n# Mostra quais são as coordenadas de cada centroid para cada dimensão. Temos 2 dimensões e 3 clusters.\nmodelokm.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mostra a quantidade de clusters\nmodelokm.n_clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mostra as labels\nlabels = modelokm.labels_\nlabels ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Faz a clusterização dos dados usando o modelo criado\ngrupos = modelokm.predict(flores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mostra o Gráfico de Clusters\nsns.scatterplot(x=flores[:,0], y=flores[:,1], hue=labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compara com o Gráfico anterior\nsns.scatterplot(x=floresdf.petal_length, y=floresdf.petal_width, hue=floresdf.species)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizar os clusters com os Centroids\nplt.scatter(flores[grupos == 0, 0], flores[grupos == 0, 1], s = 100, c = 'red', label = 'Iris-setosa')\nplt.scatter(flores[grupos == 1, 0], flores[grupos == 1, 1], s = 100, c = 'blue', label = 'Iris-versicolour')\nplt.scatter(flores[grupos == 2, 0], flores[grupos == 2, 1], s = 100, c = 'green', label = 'Iris-virginica')\nplt.scatter(modelokm.cluster_centers_[:, 0], modelokm.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Em mais detalhes: Como calculamos a distância?\nA similaridade é a métrica que mostra o quanto as observações de um mesmo grupo estão próximas entre si, ou seja, são mais similares entre si. Enquanto que ao mesmo tempo mostra o quanto as observações entre grupos diferentes estão mais distantes. \n![](https://chrisjmccormick.files.wordpress.com/2013/08/2d_euclidean_distance_illustration.png)\nA Distância Euclidiana é usada para aproximar as observações ao centroid mais próximo. A distância entre o centroid e a observação é calculada com a distância euclidiana. Considere os pontos D1(2,0) e D2(1,3) e D4(2,2) .Teríamos:\n![](https://sunainasblog.files.wordpress.com/2018/03/untitled1.png?w=620&h=210)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exemplo do cálculo da distancia euclidiana \nimport math\nd1 = (2, 0)\nd2 = (1, 3)\ndistance = math.sqrt(sum([(a - b) ** 2 for a, b in zip(d1, d2)]))\nprint(\"Distância Euclidiana do Ponto D1 ao D2: \",distance)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Como avaliar o modelo?\nPara medir a qualidade do modelo de cluster. Usamos a **cross-tabulation** do pandas para comparar a clusterização com a classe de cada grupo."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross-tabulation\nimport pandas as pd\ndf1 = pd.DataFrame({'labels':labels,\"species\":floresdf['species']})\nct1 = pd.crosstab(df1['labels'],df1['species'])\nct1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"KMeans\")\nsns.heatmap(ct1,annot=True,cbar=False,cmap=\"Blues\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para os datasets que não possuem labels, temos que usar outras formas, como usando a **Inertia**. A Inertia corresponde ao somatório dos erros quadráticos das instâncias de cada cluster. Assim:\n* Mede o quanto os clusters estão separados entre eles\n* Mede a distância de cada dado para o centroid do seu cluster\n* Aplicamos `fit()` na `inertia_` em busca de minimizar a inertia na escolha dos clusters\n* Quanto mais próximos entre si e do centroid, menor a inertia"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(modelokm.inertia_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Como descobrir o número ideal de clusters?\nUm bom cluster tem uma baixa inertia_ (SSE) e também o menor número de clusters. Não queremos muitos clusters. A Curva de Cotovelo ou Método Elbow Curve é uma técnica usada para encontrar a quantidade ideal de clusters K. Este método testa a variância dos dados em relação ao número de clusters. O valor ideal de K é aquele que tem um menor Within Sum of Squares (WSS) e ao mesmo tempo o menor número de clusters. Chamamos de **curva de cotovelo**, porque a partir do ponto que seria o “cotovelo” não existe uma discrepância tão significativa em termos de variância. Dessa forma, a melhor quantidade de clusters K seria exatamente onde o cotovelo estaria.\n\n![](https://media.giphy.com/media/12vVAGkaqHUqCQ/giphy.gif)"},{"metadata":{"trusted":true,"_uuid":"81f48eb0d54aba71f8b89557b9feb1abc3c43eb1"},"cell_type":"code","source":"# Cria a Curva de Cotovelo para encontrar o Numero Ideal de Clusters\nfrom sklearn.cluster import KMeans\nwcss = []\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(flores)\n    wcss.append(kmeans.inertia_)\n    \n# Mostra o Gráfico\nplt.plot(range(1, 11), wcss)\nplt.title('Curva de Cotovelo')\nplt.xlabel('Numero de Clusters')\nplt.ylabel('WCSS') #within cluster sum of squares\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Silhueta\nA silhueta é uma medida do quanto observações mais similares estão próximas entre si e, ao mesmo tempo, o quanto estão distantes de outros clusters diferentes. Busca maior **coesão** dentro do cluster e maior **separação** entre clusters. A silhueta vai de -1 a 1, onde o maior valor indica que a observação se encaixou mais dentro do cluster e se distanciou dos outros clusters. Se a silhueta for negativa, a configuração do cluster pode ter ou clusters de mais ou clusters de menos. A silhueta também usa a distância euclidiana para medir a distância entre as observações.\n![](http://www.mtechprojects.org/wp-content/uploads/2017/12/silhouette-coefficient.jpg)\n\nPor exemplo:\n![](https://www.researchgate.net/profile/Frans_Coenen/publication/221570710/figure/fig1/AS:670029003644935@1536758771429/Derivation-of-the-Overall-Silhouette-Coefficient-OverallSil.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Silhueta\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\nfor i in range(2, 11):\n    clusterer = KMeans(n_clusters=i)\n    preds = clusterer.fit_predict(flores)\n    score = silhouette_score(flores, preds)\n    print('Silhueta para ' + str(i) + ' clusters : ' + str(score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning\nNão temos a garantia que os centroids serão iniciados de posições que levem ao melhor resultado. Podemos ter um resultado que convergiu, mas que não levou ao resultado ótimo porque os centroids do início que foram designados de forma randômica começaram de uma posição ruim. Para aliviar este problema, realizamos a execução do algoritmo várias vezes e isso é controlado pelo parâmetro `n_init`, que por default é 10. O que representa que o algoritmo K-means será iniciado 10 vezes com pontos de início diferentes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"modelorm = KMeans(n_init=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"---\n# Exercício\nVocê consegue descobrir padrões em uma base de dados de clientes de supermercado para direcionar o marketing para determinados grupos de clientes, com base em seu perfil de compras?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Importa os dados de clientes do supermercado\n# 2. Visualize o scatterplot em matriz com o hue = \"Gender\". Dá pra notar algum grupo?\n# 3. Crie um DataFrame apenas com as colunas Annual Income e Spending Score\n# 4. Importe o k-means\n# 5. Crie o modelo em cluster padrão, sem especificar a quantidade K de clusters\n# 6. Crie uma curva de cotovelo. Qual seria o número ideal de clusters?\n# 7. Crie novamente o cluster com kmeans com a quantidade de n_clusters ajustada\n# 8. Quais foram os centroids? Imprima os centroids\n# 9. Mostra o gráfico do resultado com os centroids\n# 10. Analise o resultado. Pra qual grupo você direcionaria com maior prioridade a campanha de marketing?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n# Conclusão\nTem que se tomar cuidado ao usar clusterização com dados que não foram padronizados. Isto porque o K-means é muito sensível à escala dos dados porque utiliza a Distância Euclidiana para medir a distância. Por isso, sempre é importante aplicar o **Scaling** antes de usar o K-means. Outra desvantagem é que o K-Means pode ser bem **lento com grande número de observações**. Por isso, em alguns casos, utiliza-se uma amostra dos dados e não o conjunto inteiro por questões de performance. Clusterização pode ter resultado ruim se os dados tiverrem **ruídos** (overlapping) ou outliers. Um grande número de clusters (K) pode diminuir os erros, mas também pode ter maior risco de overfitting.\n\nComo vantagem, a clusterização não precisa de dados previamente classificados. \n\n# Material Complementar\n1. [K-means lecture by Andrew Ng](http://cs229.stanford.edu/notes/cs229-notes7a.pdf)\n2. [Some Methods for Classification and Analysis of Mutivariate Observations. J. MacQueen,1967. pp.281-297](https://books.google.com.br/books?hl=pt-BR&lr=&id=IC4Ku_7dBFUC&oi=fnd&pg=PA281&dq=Some+methods+for+classification+and+analysis+of+multivariate+observations&ots=nOXjKWGcmO&sig=I9vBrrMQWVgLKYk577zS944OA1k)\n3. [K-Means Clustering Algorithm](http://www.labri.fr/perso/bpinaud/userfiles/downloads/hartigan_1979_kmeans.pdf)\n4. [K-Means ++](http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf)\n\n## Resposta dos Exercícios"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# 1. Importa os dados de clientes do supermercado\nimport pandas as pd\nperfil = pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\n\n# 2. Visualize o scatterplot em matriz com o hue = \"Gender\". Dá pra notar algum grupo?\nimport seaborn as sns\nsns.pairplot(perfil, hue=\"Gender\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# 3. Crie um DataFrame apenas com as colunas Annual Income e Spending Score\nperfil = pd.DataFrame(perfil, columns=[\"Annual Income (k$)\", \"Spending Score (1-100)\"])\n\n# 4. Importe o k-means\nfrom sklearn.cluster import KMeans\n\n# 5. Crie o modelo em cluster padrão, sem especificar a quantidade K de clusters\nmodelokm = KMeans()\nmodelokm = modelokm.fit(perfil)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# 6. Crie uma curva de cotovelo. Qual seria o número ideal de clusters?\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(perfil)\n    wcss.append(kmeans.inertia_)\n    \n# Mostra o Gráfico\nplt.plot(range(1, 11), wcss)\nplt.title('Curva de Cotovelo')\nplt.xlabel('Numero de Clusters')\nplt.ylabel('WCSS') #within cluster sum of squares\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# 7. Crie novamente o cluster com kmeans com a quantidade de n_clusters ajustada\nmodelokm = KMeans(n_clusters=5)\nmodelokm = modelokm.fit(perfil)\nymodelokm= modelokm.fit_predict(perfil)\n\n# 8. Quais foram os centroids? Imprima os centroids\nmodelokm.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# 9. Mostra o gráfico do resultado com os centroids\nplt.scatter(perfil.values[ymodelokm == 0, 0], perfil.values[ymodelokm == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(perfil.values[ymodelokm == 1, 0], perfil.values[ymodelokm == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(perfil.values[ymodelokm == 2, 0], perfil.values[ymodelokm == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(perfil.values[ymodelokm == 3, 0], perfil.values[ymodelokm == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(perfil.values[ymodelokm == 4, 0], perfil.values[ymodelokm == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(modelokm.cluster_centers_[:, 0], modelokm.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()\n\n# 10. Analise o resultado. Pra qual grupo você direcionaria com maior prioridade a campanha de marketing?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Próxima Aula\n[Mineração de Textos](https://www.kaggle.com/debkings/8-minera-o-de-textos-1)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}