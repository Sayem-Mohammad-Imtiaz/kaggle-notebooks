{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch-transformers > null","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import string\nimport numpy as np\nimport pandas as pd \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport tqdm\nimport spacy\n\nimport torch\nfrom pytorch_transformers import *\n\nclass StockNewsDataset:\n    def __init__(self, file_path='Combined_News_DJIA.csv'):\n        data = pd.read_csv(file_path)\n        self.train = data[data['Date'] < '2014-01-01']\n        self.val = data[(data['Date'] >= '2014-01-01') & (data['Date'] < '2015-01-01')]\n        self.test = data[data['Date'] >= '2015-01-01']\n\n    def get_splits(self):\n        return self.train, self.val, self.test\n\n    def get_headlines(self, df):\n        headlines = []\n        for _, row in df.iterrows():\n            headlines.append(self._cleaning(' '.join(str(x) for x in row[2:27])))\n            #headlines.append(self._cleaning(' '.join(str(x) for x in row[2:3])))\n        return headlines\n        \n    def _cleaning(self, text):\n        table = str.maketrans({key: ' ' for key in string.punctuation})\n        text = text.replace(\"b\\'\", \" \")\n        text = text.replace(\"b\\\"\", \" \")\n        text = text.translate(table)\n        return text\n\n    def get_tfidfs(self):\n        train_headlines = self.get_headlines(self.train)\n        val_headlines = self.get_headlines(self.val)\n        test_headlines = self.get_headlines(self.test)\n\n        vectorizer = TfidfVectorizer(min_df=0.03, max_df=0.97, max_features=10000, ngram_range=(2, 2))\n\n        train_tfidf = vectorizer.fit_transform(train_headlines)\n        val_tfidf = vectorizer.transform(val_headlines)\n        test_tfidf = vectorizer.transform(test_headlines)\n\n        return (train_tfidf, self.train['Label']), \\\n            (val_tfidf, self.val['Label']), \\\n            (test_tfidf, self.test['Label']) \\\n\n    def get_vectors(self):\n        nlp = spacy.load('en_core_web_lg')\n\n        train_vec = np.array([nlp(headline).vector for headline in self.get_headlines(self.train)])\n        val_vec = np.array([nlp(headline).vector for headline in self.get_headlines(self.val)])\n        test_vec = np.array([nlp(headline).vector for headline in self.get_headlines(self.test)])\n\n        return (train_vec, self.train['Label']), (val_vec, self.val['Label']), (test_vec, self.test['Label'])\n\n    def _bert_vector(self, df):\n        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        model = BertModel(BertConfig.from_pretrained('bert-base-uncased'))\n        output = []\n        for _, row in tqdm.tqdm(df.iterrows()):\n            vec = np.zeros((768,))\n            for headline in row[2:12]:\n                input_ids = tokenizer.encode('[CLS] '+self._cleaning(str(headline))+' [SEP]')[:512]\n                vec += model(torch.tensor([input_ids]))[1].detach().numpy().squeeze()\n            output.append(vec/10.)\n        return np.array(output)\n\n    def get_bert_vectors(self):\n        train_vec = self._bert_vector(self.train)\n        val_vec = self._bert_vector(self.val)\n        test_vec = self._bert_vector(self.test)\n        return (train_vec, self.train['Label']), (val_vec, self.val['Label']), (test_vec, self.test['Label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom utils import *","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset = StockNewsDataset('../input/Combined_News_DJIA.csv')\n(train_x, train_y), (val_x, val_y), (test_x, test_y) = dataset.get_tfidfs()\nprint(train_x.shape, val_x.shape, test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel = model.fit(train_x, train_y)\nval_pred = model.predict(val_x)\ntest_pred = model.predict(test_x)\nval_acc = accuracy_score(val_y, val_pred)\ntest_acc = accuracy_score(test_y, test_pred)\nprint(val_acc, test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_x, train_y), (val_x, val_y), (test_x, test_y) = dataset.get_vectors()\nprint(train_x.shape, val_x.shape, test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel = model.fit(train_x, train_y)\nval_pred = model.predict(val_x)\ntest_pred = model.predict(test_x)\nval_acc = accuracy_score(val_y, val_pred)\ntest_acc = accuracy_score(test_y, test_pred)\nprint(val_acc, test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_x, train_y), (val_x, val_y), (test_x, test_y) = dataset.get_bert_vectors()\nprint(train_x.shape, val_x.shape, test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(penalty='l2')\nmodel = model.fit(train_x, train_y)\nval_pred = model.predict(val_x)\ntest_pred = model.predict(test_x)\nval_acc = accuracy_score(val_y, val_pred)\ntest_acc = accuracy_score(test_y, test_pred)\nprint(val_acc, test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}