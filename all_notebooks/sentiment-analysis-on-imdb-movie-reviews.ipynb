{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This invlolves the Sentiment prediction for a number of movies reviews obtained from Internet Movie data (IMDB).This dataset containes 50,000 movie reviews.Here we are predicting the sentiment of 20,000 labeled movie reviews and using remaining 30,000 reviews for training our models.**"},{"metadata":{},"cell_type":"markdown","source":"> **Import required libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport nltk  # For test pre-processing\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn import preprocessing\nimport scikitplot as skplt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import roc_curve,auc\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import Sequential\nfrom keras.layers import Embedding,LSTM,Dense\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Load the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"Movie_df=pd.read_csv('../input/IMDB Dataset.csv')\nprint('Shape of dataset::',Movie_df.shape)\nMovie_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stats of our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"General stats::\")\nprint(Movie_df.info())\nprint(\"Summary stats::\\n\")\nprint(Movie_df.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Number of poitive & negative reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"Movie_df.sentiment.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews=Movie_df['review']\nsentiment=Movie_df['sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Summarize no. of classes\nprint('Classes::\\n',np.unique(sentiment))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Split the data into train & test datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reviews=reviews[:30000]\ntrain_sentiment=sentiment[:30000]\ntest_reviews=reviews[30000:]\ntest_sentiment=sentiment[30000:]\n#Shape of train & test dataset\nprint('Shape of train dataset::',train_reviews.shape,train_sentiment.shape)\nprint('Shape of test dataset::',test_reviews.shape,test_sentiment.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Encode our target labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"lb=preprocessing.LabelBinarizer()\n#Encode 1 for positive label & 0 for Negative label\ntrain_sentiment=lb.fit_transform(train_sentiment)\ntest_sentiment=lb.transform(test_sentiment)\n#Reshape the array\ntrain_sentiment=train_sentiment.ravel()  \ntest_sentiment=test_sentiment.ravel()\n#Convert categoricals to numeric ones\ntrain_sentiment=train_sentiment.astype('int64')\ntest_sentiment=test_sentiment.astype('int64')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nLet's explore our data before normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reviews[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_reviews[30001]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In above paragraphs, we can observe stopwords,html tags,special charcters & numbers, which are not required for sentiment analysis.So we need to remove those by normalizing the review data to reduce dimensionality & noise in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentiment[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Data Pre-processing"},{"metadata":{},"cell_type":"markdown","source":"Let's normalize our data to remove stopwords, html tags and so on."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nps=PorterStemmer()\nstopwords=set(stopwords.words('english'))\n# Define function for data mining\ndef normalize_reviews(review):\n    #Excluding html tags\n    data_tags=re.sub(r'<[^<>]+>',\" \",review)\n    #Remove special characters/whitespaces\n    data_special=re.sub(r'[^a-zA-Z0-9\\s]','',data_tags)\n    #converting to lower case\n    data_lowercase=data_special.lower()\n    #tokenize review data\n    data_split=data_lowercase.split()\n    #Removing stop words\n    meaningful_words=[w for w in data_split if not w in stopwords]\n    #Appply stemming\n    text= ' '.join([ps.stem(word) for word in meaningful_words])\n    return text\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Normalize the train & test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_train_reviews=train_reviews.apply(normalize_reviews)\nnorm_test_reviews=test_reviews.apply(normalize_reviews)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nLet's look at our normalized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnorm_train_reviews[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_test_reviews[30001]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's create features using bag of words model"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=CountVectorizer(ngram_range=(1,2))\ntrain_cv=cv.fit_transform(norm_train_reviews)\ntest_cv =cv.transform(norm_test_reviews)\nprint('Shape of train_cv::',train_cv.shape)\nprint('Shape of test_cv::',test_cv.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our train & test dataset contains 1929440 attributes each."},{"metadata":{},"cell_type":"markdown","source":"> Let's build our traditional ML models"},{"metadata":{},"cell_type":"markdown","source":"> Random Forest model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Training the classifier\nrfc=RandomForestClassifier(n_estimators=20,random_state=42)\nrfc=rfc.fit(train_cv,train_sentiment)\nscore=rfc.score(train_cv,train_sentiment)\nprint('Accuracy of trained model is ::',score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Making predicitions\nrfc_predict=rfc.predict(test_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How accuate our model is?\ncm=confusion_matrix(test_sentiment,rfc_predict)\n#plot our confusion matrix\nskplt.metrics.plot_confusion_matrix(test_sentiment,rfc_predict,normalize=False,figsize=(12,8))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 0-Negative class,\n> 1-Positive class"},{"metadata":{},"cell_type":"markdown","source":"From the confusion matrix plot, it is concluded that, the Random Forest classifier with 20 decision trees classified the 81% of the reviews (16183 reviews) correctly & remaining 19% of reviews (3817 reviews) are misclassified."},{"metadata":{"trusted":true},"cell_type":"code","source":"#print classification report for performance metrics\ncr=classification_report(test_sentiment,rfc_predict)\nprint('Classification report is::\\n',cr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC curve for Random Forest Classifier\nfpr_rf,tpr_rf,threshold_rf=roc_curve(test_sentiment,rfc_predict)\n#Area under curve (AUC) score, fpr-False Positive rate, tpr-True Positive rate\nauc_rf=auc(fpr_rf,tpr_rf)\nprint('AUC score for Random Forest classifier::',np.round(auc_rf,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Let's build our deep learning model**"},{"metadata":{},"cell_type":"markdown","source":"\n> Recurrent neural network (RNN) with LSTM (Long Short Term Memory) model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train dataset\nX_train=train_cv\nX_train=[str(x[0]) for x in X_train]\ny_train=train_sentiment\n# Test dataset\nX_test=test_cv\nX_test=[str(x[0]) for x in X_test]\ny_test=test_sentiment\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tokenize the train & test dataset\nMax_Review_length=500\ntokenizer=Tokenizer(num_words=Max_Review_length,lower=False)\ntokenizer.fit_on_texts(X_train)\n#tokenizig train data\nX_train_token=tokenizer.texts_to_sequences(X_train)\n#tokenizing test data\nX_test_token=tokenizer.texts_to_sequences(X_test)\n\n#Truncate or pad the dataset for a length of 500 words for each review\nX_train=pad_sequences(X_train_token,maxlen=Max_Review_length)\nX_test=pad_sequences(X_test_token,maxlen=Max_Review_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of X_train datset after padding:',X_train.shape)\nprint('Shape of X_test dataset after padding:',X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Most poplar words found in the dataset\nvocabulary_size=5000 \nembedding_size=64\nmodel=Sequential()\nmodel.add(Embedding(vocabulary_size,embedding_size,input_length=Max_Review_length))\nmodel.add(LSTM(30))\nmodel.add(Dense(1,activation='sigmoid',kernel_initializer='random_uniform'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Complile our model\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Train our model\nbatch_size=128\nnum_epochs=6\nX_valid,y_valid=X_train[:batch_size],train_sentiment[:batch_size]\nX_train1,y_train1=X_train[batch_size:],train_sentiment[batch_size:]\n# Fit the model\nmodel.fit(X_train1,y_train1,validation_data=(X_valid,y_valid),validation_split=0.2,\n          batch_size=batch_size,epochs=num_epochs, verbose=1,shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Predictions\ny_predict_rnn=model.predict(X_test)\n#Changing the shape of y_predict to 1-Dimensional\ny_predict_rnn1=y_predict_rnn.ravel()\ny_predict_rnn1=(y_predict_rnn1>0.5)\ny_predict_rnn1[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix for RNN with LSTM\ncm_rnn=confusion_matrix(y_test,y_predict_rnn1)\n#plot our confusion matrix\nskplt.metrics.plot_confusion_matrix(y_test,y_predict_rnn1,normalize=False,figsize=(12,8))\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 0-Negative class,\n> 1-Positive class"},{"metadata":{},"cell_type":"markdown","source":"The confusion matrix plot states that the RNN with LSTM model classified 79% of reviews (15866 reviews) correctly & remaining 21% of reviews (4134 reviews) are misclassified."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report for performance metrics\ncr_rnn=classification_report(y_test,y_predict_rnn1)\nprint('The Classification report is::\\n',cr_rnn)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC curve for RNN with LSTM\nfpr_rnn,tpr_rnn,thresold_rnn=roc_curve(y_test,y_predict_rnn)\n#AUC score for RNN\nauc_rnn=auc(fpr_rnn,tpr_rnn)\nprint('AUC score for RNN with LSTM ::',np.round(auc_rnn,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Receiver Operating Characterstic (ROC) Curve for Model Evaluation**"},{"metadata":{},"cell_type":"markdown","source":"> Now, let's plot the ROC for both Random Forest Classifier &  RNN with LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplt.figure(1)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr_rnn,tpr_rnn,label='RNN(area={:.3f})'.format(auc_rnn))\nplt.plot(fpr_rf,tpr_rf,label='Random Forest (area={:.3f})'.format(auc_rf))\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Evaluation on unseen dataset\nModel_evaluation=pd.DataFrame({'Model':['Random Forest Classifier','RNN with LSTM'],\n                              'f1_score':[0.81,0.79],\n                              'roc_auc_score':[0.809,0.879]})\nModel_evaluation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The f1_score for Random forest classier is higher than for RNN with LSTM model & the roc_auc score for Random forest classifier is lower than for RNN with LSTM model. From the above scores, it is good to consider Random forest classifier than RNN with LSTM because it is comparatively less computationally expensive & works well on small & large amount of datasets."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}