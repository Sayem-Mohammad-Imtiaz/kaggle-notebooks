{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/customer/Train.csv')\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"rename Var_1 to catergory fron Train Data frame , as it is writting the new data frame reasighn , else you can also use in_place=True "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.rename(columns={'Var_1': 'Category'})\ntrain_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove Id column and print 10 samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop(columns=['ID'])\ntrain_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"check for the missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets drop the empty rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dropna().isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets encode non numerical columns "},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_encode_dict(values):\n    return {val:i for i,val in enumerate(values)}\n\n#lets convert non numeric column to numeric \ngender_dict = get_encode_dict(train_data.Gender.unique())\nmerital_status_dict = get_encode_dict(train_data.Ever_Married.unique())\ngrad_dict = get_encode_dict(train_data.Graduated.unique())\nspending_dict = get_encode_dict(train_data.Spending_Score.unique())\ncat_dict = get_encode_dict(train_data.Category.unique())\nsegment_dict = get_encode_dict(train_data.Segmentation.unique())\nsegment_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create single dictionary\n\nencoded_dict = {\n    'Gender' : gender_dict,\n    'Ever_married' : merital_status_dict,\n    'Graduated' : grad_dict,\n    'Spending_score' : spending_dict,\n    'Category' : cat_dict,\n    'Segmentation' : segment_dict\n}\n\n# replace non numberic to numberic in data_frame\ntrain_data.replace(encoded_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_clms = ['Gender','Ever_Married','Age','Graduate','Profession','Work_Experience','Spending_Score','Family_Size','Var_1']\ntarget_clms = ['Segmentation']\n\nfrom sklearn.model_selection import train_test_split # we need it to split train and test\n#feature_data = train_data.loc[:, feature_clms]\nfeature_data = train_data.reindex(columns = feature_clms)\ntarget_data = train_data.reindex(columns = target_clms)\ntrain_x,test_x,train_y,test_y = train_test_split(feature_data,target_data,test_size=0.2)\nprint(train_x.shape,test_x.shape,train_y.shape,test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feed it naive bayes algo\n\nfrom sklearn.naive_bayes import CategoricalNB\ncnb = CategoricalNB()\nvalue = -1\n#cnb.fit(train_x.to_numpy(),train_y.to_numpy().reshape(-1))\nactual_y = train_y.to_numpy().reshape(-1)\npredict_y = cnb.predict(train_x.to_numpy())\n\nfrom sklearn import metrics\nmetrics.accuracy.score(actual_y,predicted_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(actual_y, predicted_y))\nprint(classification_report(actual_y,predicted_y,target_name=['D','B','C','A']))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}