{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import make_scorer, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/health-insurance-cross-sell-prediction/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data description"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(df).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##ditribution of Response\nfig_dims = (5, 5)\nfig, ax = plt.subplots()\nsns.countplot('Response',\n              data = df,\n              order = df['Response'].value_counts().index,\n              ax = ax)\nax.set(xlabel='Response', ylabel='Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ditribution of Gender,Driving_License,Previously_Insured,Previously_Insured\nfig, axarr = plt.subplots(2, 2, figsize=(10, 10))\n\ndf['Gender'].value_counts().sort_index().plot.pie(\n    ax=axarr[0][0])\naxarr[0][0].set_title(\"Gender\", fontsize=18)\ndf['Previously_Insured'].value_counts().sort_index().plot.pie(\n    ax=axarr[1][0])\naxarr[1][0].set_title(\"Previously_Insured\", fontsize=18)\n\ndf['Vehicle_Damage'].value_counts().sort_index().plot.pie(\n    ax=axarr[1][1])\naxarr[1][1].set_title(\"Vehicle_Damage\", fontsize=18)\n\ndf['Driving_License'].value_counts().head().plot.pie(\n    ax=axarr[0][1])\naxarr[0][1].set_title(\"Driving_License\", fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(5, 5))\nsns.countplot(x=\"Gender\", hue=\"Vehicle_Damage\", data=df)\nplt.title(\"Vehicle Damage by Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find male are more likely to cause Vehicle_Damage lol."},{"metadata":{"trusted":true},"cell_type":"code","source":"#ditribution of Age\nfig_dims = (15, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.countplot('Age',\n              data = df,\n              ax = ax)\nax.set(xlabel='Age', ylabel='Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# represent binary variable as 1and 0\ndf['Gender'].replace(to_replace={'Male':0,'Female':1},\n             inplace=True)\ndf['Vehicle_Damage'].replace(to_replace={'No':0,'Yes':1},\n             inplace=True)\ndf['Vehicle_Age'].replace(to_replace={'< 1 Year':0,'1-2 Year':1,'> 2 Years':2},\n             inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Heatmap"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\ncor=df.corr()\nsns.heatmap(cor,annot=True,cmap=plt.cm.Blues)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Descriptive Statistic"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split into Train and Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(columns=['id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df.Response\nX=df.drop(columns=['Response'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## split into 70%train set and 30%test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"### decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ndt_predict = dt.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, dt_predict))\ndt_accuracy = accuracy_score(y_test, dt_predict)\nprint(\"Accuracy of decision tree\" + ' : ' + str(dt_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # Compute 10-fold cross-validation scores: cv_scores\nfrom sklearn.model_selection import cross_val_score \ncv_scores = cross_val_score(dt,X,y,cv=10)\n\nprint(cv_scores)\nprint(\"Average 10-Fold CV Score: {}\".format(np.mean(cv_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Improve the decision tree model "},{"metadata":{"trusted":true},"cell_type":"code","source":"# use  GridSearchCV to test all accuracy, and choose the combinations of the highest accuracy\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'max_depth': np.arange(3, 10),\n             'criterion' : ['gini','entropy'],\n             'max_leaf_nodes': [5,10,50,100],\n             'min_samples_split': [2, 5, 10, 20]}\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = 5, scoring= 'accuracy')\ngrid_tree.fit(X_train, y_train)\nnp.abs(grid_tree.best_score_)\n#test the accuracy of all the combination of the parameters, then output the highest parameter.\nprint(grid_tree.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the best performance combinations  to test\nTree = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=9, max_features=None, max_leaf_nodes=50,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\nTree.fit(X_train, y_train)\npredictions = Tree.predict(X_test)\naccuracy_score(y_true = y_test, y_pred = predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot ROC_AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\n# calculate the fpr and tpr for all thresholds of the classification\nprobs = dt.predict_proba(X_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n#  plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic for Decision Tree')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_Predict = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, rf_Predict))\nrf_accuracy = accuracy_score(y_test, rf_Predict)\nprint(\"Accuracy of rf\" + ' : ' + str(rf_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = cross_val_score(rf,X,y,cv=10)\n\nprint(cv_scores)\nprint(\"Average 10-Fold CV Score: {}\".format(np.mean(cv_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC_AUC for random forest\nprobs = rf.predict_proba(X_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n#  plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic for Random Forest')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, lr_predict))\nlr_accuracy = accuracy_score(y_test, lr_predict)\nprint(\"Accuracy of Logistic Regression\" + ' : ' + str(lr_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC_AUC for logistic regression\nprobs = lr.predict_proba(X_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic for Logistic Regression')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# build the knn model and calculate the accuracy score when n=10\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\nknn_predict = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nknn_accuracy = accuracy_score(y_test, knn_predict)\nprint(\"Accuracy of Logistic Regression\" + ' : ' + str(knn_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC_AUC for knn\nprobs = knn.predict_proba(X_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n#  plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic for KNN')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}