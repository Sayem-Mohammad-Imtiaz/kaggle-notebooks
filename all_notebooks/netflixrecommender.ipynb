{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport math\nimport re\nfrom scipy.sparse import csr_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom surprise import Reader, Dataset, SVD\nsns.set_style(\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nmovie_titles = pd.read_csv(\"../input/netflix-prize-data/movie_titles.csv\",error_bad_lines=False, encoding=\"latin-1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Skip date\ndf1 = pd.read_csv('../input/netflix-prize-data/combined_data_1.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n\ndf1['Rating'] = df1['Rating'].astype(float)\n\nprint('Dataset 1 shape: {}'.format(df1.shape))\nprint('-Dataset examples-')\nprint(df1.iloc[::5000000, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ndf = df1\ndf = df1.append(df2)\ndf = df.append(df3)\ndf = df.append(df4)\n\ndf.index = np.arange(0,len(df))\nprint('Full dataset shape: {}'.format(df.shape))\nprint('-Dataset examples-')\nprint(df.iloc[::5000000, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = df.groupby('Rating')['Rating'].agg(['count'])\n\n# get movie count\nmovie_count = df.isnull().sum()[1]\n\n# get customer count\ncust_count = df['Cust_Id'].nunique() - movie_count\n\n# get rating count\nrating_count = df['Cust_Id'].count() - movie_count\n\nax = p.plot(kind = 'barh', legend = False, figsize = (15,10))\nplt.title('Total pool: {:,} Movies, {:,} customers, {:,} ratings given'.format(movie_count, cust_count, rating_count), fontsize=20)\nplt.axis('off')\n\nfor i in range(1,6):\n    ax.text(p.iloc[i-1][0]/4, i-1, 'Rating {}: {:.0f}%'.format(i, p.iloc[i-1][0]*100 / p.sum()[0]), color = 'white', weight = 'bold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nan = pd.DataFrame(pd.isnull(df.Rating))\ndf_nan = df_nan[df_nan['Rating'] == True]\ndf_nan = df_nan.reset_index()\n\nmovie_np = []\nmovie_id = 1\n\nfor i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n    # numpy approach\n    temp = np.full((1,i-j-1), movie_id)\n    movie_np = np.append(movie_np, temp)\n    movie_id += 1\n\n# Account for last record and corresponding length\n# numpy approach\nlast_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\nmovie_np = np.append(movie_np, last_record)\n\nprint('Movie numpy: {}'.format(movie_np))\nprint('Length: {}'.format(len(movie_np)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove those Movie ID rows\ndf = df[pd.notnull(df['Rating'])]\n\ndf['Movie_Id'] = movie_np.astype(int)\ndf['Cust_Id'] = df['Cust_Id'].astype(int)\nprint('-Dataset examples-')\nprint(df.iloc[::5000000, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = ['count','mean']\n\ndf_movie_summary = df.groupby('Movie_Id')['Rating'].agg(f)\ndf_movie_summary.index = df_movie_summary.index.map(int)\nmovie_benchmark = round(df_movie_summary['count'].quantile(0.7),0)\ndrop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n\nprint('Movie minimum times of review: {}'.format(movie_benchmark))\n\ndf_cust_summary = df.groupby('Cust_Id')['Rating'].agg(f)\ndf_cust_summary.index = df_cust_summary.index.map(int)\ncust_benchmark = round(df_cust_summary['count'].quantile(0.7),0)\ndrop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n\nprint('Customer minimum times of review: {}'.format(cust_benchmark))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Original Shape: {}'.format(df.shape))\ndf = df[~df['Movie_Id'].isin(drop_movie_list)]\ndf = df[~df['Cust_Id'].isin(drop_cust_list)]\nprint('After Trim Shape: {}'.format(df.shape))\nprint('-Data Examples-')\nprint(df.iloc[::5000000, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p = pd.pivot_table(df,values='Rating',index='Cust_Id',columns='Movie_Id')\n\nprint(df_p.shape)\n\n# Below is another way I used to sparse the dataframe...doesn't seem to work better\n\n#Cust_Id_u = list(sorted(df['Cust_Id'].unique()))\n#Movie_Id_u = list(sorted(df['Movie_Id'].unique()))\n#data = df['Rating'].tolist()\n#row = df['Cust_Id'].astype('category', categories=Cust_Id_u).cat.codes\n#col = df['Movie_Id'].astype('category', categories=Movie_Id_u).cat.codes\n#sparse_matrix = csr_matrix((data, (row, col)), shape=(len(Cust_Id_u), len(Movie_Id_u)))\n#df_p = pd.DataFrame(sparse_matrix.todense(), index=Cust_Id_u, columns=Movie_Id_u)\n#df_p = df_p.replace(0, np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_title = pd.read_csv('../input/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'])\ndf_title.set_index('Movie_Id', inplace = True)\nprint (df_title.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reader = Reader()\n\n# get just top 100K rows for faster run time\ndata = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']][:100000], reader)\ndata.split(n_folds=3)\n\nsvd = SVD()\nevaluate(svd, data, measures=['RMSE', 'MAE'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_785314 = df[(df['Cust_Id'] == 785314) & (df['Rating'] == 5)]\ndf_785314 = df_785314.set_index('Movie_Id')\ndf_785314 = df_785314.join(df_title)['Name']\nprint(df_785314)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_785314 = df_title.copy()\nuser_785314 = user_785314.reset_index()\nuser_785314 = user_785314[~user_785314['Movie_Id'].isin(drop_movie_list)]\n\n# getting full dataset\ndata = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']], reader)\n\ntrainset = data.build_full_trainset()\nsvd.train(trainset)\n\nuser_785314['Estimate_Score'] = user_785314['Movie_Id'].apply(lambda x: svd.predict(785314, x).est)\n\nuser_785314 = user_785314.drop('Movie_Id', axis = 1)\n\nuser_785314 = user_785314.sort_values('Estimate_Score', ascending=False)\nprint(user_785314.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recommend(movie_title, min_count):\n    print(\"For movie ({})\".format(movie_title))\n    print(\"- Top 10 movies recommended based on Pearsons'R correlation - \")\n    i = int(df_title.index[df_title['Name'] == movie_title][0])\n    target = df_p[i]\n    similar_to_target = df_p.corrwith(target)\n    corr_target = pd.DataFrame(similar_to_target, columns = ['PearsonR'])\n    corr_target.dropna(inplace = True)\n    corr_target = corr_target.sort_values('PearsonR', ascending = False)\n    corr_target.index = corr_target.index.map(int)\n    corr_target = corr_target.join(df_title).join(df_movie_summary)[['PearsonR', 'Name', 'count', 'mean']]\n    print(corr_target[corr_target['count']>min_count][:10].to_string(index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recommend(\"What the #$*! Do We Know!?\", 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recommend(\"X2: X-Men United\", 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}