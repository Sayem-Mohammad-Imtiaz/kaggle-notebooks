{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nI am going to analysis and visulize some datasets. In this note book, I am analyzing the time series dataset â€“ [Parking Birmingham](https://archive.ics.uci.edu/ml/machine-learning-databases/00482/) downloaded from the UCI machine learning repository.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Time Series\nA time series data is a series of data points or observations recorded at different or regular time intervals. In general, a time series is a sequence of data points taken at equally spaced time intervals. The frequency of recorded data points may be hourly, daily, weekly, monthly, quarterly or annually.\n\nA time series analysis encompasses statistical methods for analyzing time series data. These methods enable us to extract meaningful statistics, patterns and other characteristics of the data. Time series are visualized with the help of line charts. So, time series analysis involves understanding inherent aspects of the time series data so that we can create meaningful and accurate forecasts.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Types of Data\nA time series data means that data is recorded at different time periods or intervals. The time series data may be of three types:-\n\n1. **Time series data** - The observations of the values of a variable recorded at different points in time is called time series data.\n2. **Cross sectional data** - It is the data of one or more variables recorded at the same point in time.\n3. **Pooled data** - It is the combination of time series data and cross sectional data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Terminology\nThere are various terms and concepts in time series that we should know. These are as follows:-\n\n1. **Dependence** - It refers to the association of two observations of the same variable at prior time periods.\n2. **Stationarity** - It shows the mean value of the series that remains constant over the time period. If past effects accumulate and the values increase towards infinity then stationarity is not met.\n3. **Differencing** - Differencing is used to make the series stationary and to control the auto-correlations. There may be some cases in time series analyses where we do not require differencing and over-differenced series can produce wrong estimates.\n4. **Specification** - It may involve the testing of the linear or non-linear relationships of dependent variables by using time series models such as ARIMA models.\n5. **Exponential Smoothing** - Exponential smoothing in time series analysis predicts the one next period value based on the past and current value. It involves averaging of data such that the non-systematic components of each individual case or observation cancel out each other. The exponential smoothing method is used to predict the short term prediction.\n6. **Curve fitting** - Curve fitting regression in time series analysis is used when data is in a non-linear relationship.\n7. **ARIMA** - ARIMA stands for Auto Regressive Integrated Moving Average.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# About The Dataset\n**Source:** Daniel H. Stolfi, dhstolfi '@' lcc.uma.es, University of Malaga - Spain.\n\n**Data Set Information:** Occupancy rates (8:00 to 16:30) from 2016/10/04 to 2016/12/19\n\n**Attribute Information:**\n\n    SystemCodeNumber: Car park ID\n    Capacity: Car park capacity\n    Occupancy: Car park occupancy rate\n    LastUpdated: Date and Time of the measure\n    \n**Data Set Characteristics:** Multivariate, Univariate, Sequential, Time-Series\n\n**Number of Instances:** 35717\n\n**Number of Attributes:** 4","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Import necessary libraries.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom scipy.stats import pearsonr\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import data set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parking_data = pd.read_csv('/kaggle/input/dataset.csv')\nparking_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing inconsistence data. Such as duplicate values, negative occupancy, occupancy value greater than capacity.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print('Before removing inconsistence data:',parking_data.shape)\nparking_data.dropna(inplace = True)\nparking_data.drop_duplicates(keep='first',inplace=True) \nparking_data = parking_data[parking_data['Occupancy']>=0 ]\nparking_data = parking_data[parking_data['Capacity']>=0 ]\nfalse_data = parking_data[parking_data['Occupancy']> parking_data['Capacity']]\nparking_data = pd.concat([parking_data, false_data]).drop_duplicates(keep=False)\nprint('After removing inconsistence data:',parking_data.shape)\nparking_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert LastUpdated column into Time and Date column. Add new columns for occupancy rate in percentage and Day of Week.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parking_data['OccupancyRate'] = (100.0*parking_data['Occupancy'])/parking_data['Capacity']\ndateTime = parking_data['LastUpdated'].str.split(\" \", n = 1, expand = True) \ndate = dateTime[0]\ntime = dateTime[1]\nparking_data['Date'] = date\nparking_data['Time'] = time\nday_name = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\nparking_data['DayOfWeek'] = pd.to_datetime(parking_data['Date']).dt.dayofweek.apply(lambda x: day_name[x])\nparking_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot occupancy rate for all car parks with respect to time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([],[])\npark_name = parking_data['SystemCodeNumber'].unique()\n#print(park_name)\nfor i in range(len(park_name)):\n    s = park_name[i]\n    rate = parking_data[parking_data['SystemCodeNumber'] == s]['OccupancyRate']\n    time=pd.to_datetime(parking_data[parking_data['SystemCodeNumber'] == s]['Time'],format='%H:%M:%S')\n    plt.scatter(time,rate,label=s)\nplt.gcf().autofmt_xdate()\nmyFmt = mdates.DateFormatter('%H:%M')\nplt.gca().xaxis.set_major_formatter(myFmt)    \nplt.xlabel('Time')\nplt.ylabel('Occupancy Rate')\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot mean occupancy rate with respect to each carpark.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xData = parking_data.groupby('SystemCodeNumber')['OccupancyRate'].mean()\nkey_list = list(xData.keys()) \nval_list = []\nfor x in key_list:\n    val_list.append(xData[x])\ndf = pd.DataFrame(list(zip(key_list, val_list)), \n               columns =['Park ID', 'Mean Occupancy Rate']) \nax = sns.barplot(y='Park ID',x='Mean Occupancy Rate',data=df,orient=\"h\")\nax.set(ylabel=\"Car Park ID\", xlabel = \"Mean Occupancy Rate\")\nax.tick_params(axis='y', labelsize=7)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scatter plot of occupancy rate of **BHMBCCMKT01** car park.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1):\n    s = park_name[i]\n    rate = parking_data[parking_data['SystemCodeNumber'] == s]['OccupancyRate']\n    time=pd.to_datetime(parking_data[parking_data['SystemCodeNumber'] == s]['Time'],format='%H:%M:%S')\n    plt.scatter(time,rate,label=s)\nplt.gcf().autofmt_xdate()\nmyFmt = mdates.DateFormatter('%H:%M')\nplt.gca().xaxis.set_major_formatter(myFmt)    \nplt.xlabel('Time')\nplt.ylabel('Occupancy Rate')\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"park_name = ['BHMEURBRD01']\nfor i in range(len(park_name)):\n    s = park_name[i]\n    rate = parking_data[parking_data['SystemCodeNumber'] == s]['OccupancyRate']\n    time=pd.to_datetime(parking_data[parking_data['SystemCodeNumber'] == s]['Date'])\n    plt.plot(time,rate)\n    plt.gcf().autofmt_xdate()\nplt.xlabel('Date')\nplt.ylabel('Occupancy Rate')\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some difference in occupancy rate in weekends and workday. I am going to plot occupancy rate for Shopping car parks on a weekends and workday.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([],[])\n\nrate = parking_data[parking_data['SystemCodeNumber'] == 'Shopping']\nrate = rate[rate['Date'] == '2016-10-06']['OccupancyRate']\ntime = parking_data[parking_data['SystemCodeNumber'] == 'Shopping'] \ntime=pd.to_datetime(time[time['Date'] == '2016-10-06']['Time'],format='%H:%M:%S')\nplt.plot(time,rate,label='2016-10-06')\n\nrate = parking_data[parking_data['SystemCodeNumber'] == 'Shopping']\nrate = rate[rate['Date'] == '2016-10-09']['OccupancyRate']\ntime = parking_data[parking_data['SystemCodeNumber'] == 'Shopping'] \ntime=pd.to_datetime(time[time['Date'] == '2016-10-09']['Time'],format='%H:%M:%S')\nplt.plot(time,rate,label='2016-10-09')\n\n\n\nplt.gcf().autofmt_xdate()\nmyFmt = mdates.DateFormatter('%H:%M')\nplt.gca().xaxis.set_major_formatter(myFmt)\nplt.xlabel('Time')\nplt.ylabel('Occupancy Rate')\nplt.legend()\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can plot data count with respect to days of week. We can see that we get less data on weekends.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.catplot(x='DayOfWeek',kind='count',data=parking_data,orient=\"h\")\nax.fig.autofmt_xdate()\nax.set(xlabel=\"Week Days\", ylabel = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be clear from this box graph.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.catplot(x = \"DayOfWeek\",y=\"OccupancyRate\",kind='box',data=parking_data)\nax.set(xlabel=\"Week Days\", ylabel = \"Occupancy Rate\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can plot heatmap for occupancy rate with respect to data for each carpark.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"heatmap_data = pd.pivot_table(parking_data, values='OccupancyRate', \n                     index=['SystemCodeNumber'], \n                     columns='Date')\nax = sns.heatmap(heatmap_data , cmap=\"BuGn\")\nax.set(ylabel=\"Car Park ID\", xlabel = \"Date\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Set Preparation\nThere are data for 12 weeks. I choose the last week as our test data and remaining as our train data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = parking_data[(pd.to_datetime(parking_data['Date']) >= pd.to_datetime('2016-12-13'))]\ntrain_data = pd.concat([parking_data, test_data]).drop_duplicates(keep=False)\nprint('Train data size:',train_data.shape)\nprint('Test data size:',test_data.shape)\ntrain_data.to_csv('train.csv',index=False)\ntest_data.to_csv('test.csv',index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}