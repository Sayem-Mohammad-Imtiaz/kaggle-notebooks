{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/suicide-rates-overview-1985-to-2016/master.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# After reading the data, we should investigate basics"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Are ther any NA or NAN values?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['HDI for year'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Are there any outlier values? Controlling the quartiles.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visual investigation with box plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.set_theme(style=\"whitegrid\")\nax = sns.boxplot(x=data[\"HDI for year\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=\"sex\", y=\"HDI for year\", data=data, palette='Set1', hue='sex')\nplt.title('Box-Plot')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Concatenating Melting, menaging columns and rows and Pivoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a new dataset from orginial data and concatenating with row wise\ndata1 = data.head()\ndata2= data.tail()\ndata_new = pd.concat([data1,data2], axis=0, ignore_index=True)\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"melting = pd.melt(frame=data_new, id_vars='country', value_vars=['suicides_no','suicides/100k pop'])\nmelting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visual reprensentation of melted data\nsns.barplot(data=melting, x=melting.index, y='value', hue='variable')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pivoting - reverse melt method**"},{"metadata":{"trusted":true},"cell_type":"code","source":"melting.pivot(index='country', columns='variable', values='value')\n# The code given above will give you an error about duplicate entries\n# which our country column has many duplicates.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just to observe how it's done, let's create another dataframe with 2 entries\ndata_new1 = data.head(1)\ndata_new2 = data.tail(1)\ndata_new3 = pd.concat([data_new1,data_new2], axis=0, ignore_index=True)\ndata_new3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_melting = pd.melt(frame=data_new3, id_vars='country', value_vars=['suicides_no','suicides/100k pop'])\nnew_melting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's pivot our new melted dataset\n\nnew_melting.pivot(index='country', columns='variable', values='value')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data types and converting between them"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First check the data types\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's change the country as category\ndata['country']= data['country'].astype('category')\ndata.dtypes['country']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# and change back\ndata['country']= data['country'].astype('object')\ndata.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Data and how to handle\n\nThere are several ways to handle miissing data and it depends according to situation.\nBasically, you can leave them as it is or remove all the entries with missing data or\nyou can fill them with statistical methods."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's start to explore\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#HDI for year has missing observations\ndata['HDI for year'].value_counts(dropna=False)\n\n#It can be seen from the output that we have 19456 missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['HDI for year'].dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data[\"HDI for year\"].notnull().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling na with empty \n\ndata['HDI for year'].fillna('empty',inplace = True)\ndata['HDI for year'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}