{"cells":[{"metadata":{},"cell_type":"markdown","source":"I have implemented some newly gained data analysis and visualization skills on 'Data Scientist Jobs'\n\nYou can also check my similar work on:\n1. [Analysis of Data Engineer Jobs](https://www.kaggle.com/samruddhim/analysis-of-data-engineer-jobs)\n2. [Analysis of Data Analyst Jobs](https://www.kaggle.com/samruddhim/analysis-of-data-analyst-jobs)\n\nData Ananlysis on 'Data Scientist Jobs' Data Set.\n\n1. Data Cleaning\n2. Statistics\n3. Data Visulization\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the dataset\n\ndf = pd.read_csv('../input/data-scientist-jobs/DataScientist.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.isnull().sum()) #checking for null values in the dataset\nprint(df.info()) #checking the general information of the dataset: non-null count, d-type, etc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Easy Apply'] = df['Easy Apply'].fillna(False).astype(bool) #As seen in dataset, Easy Apply column has -1 values, replacing them with boolean value False\ndf['Easy Apply'].value_counts() # Checking for value count of Easy Apply column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **1. Data Cleaning**"},{"metadata":{},"cell_type":"markdown","source":"**Replacing -1 with nan**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.replace(['-1'], [np.nan], inplace=True)\ndf.replace(['-1.0'], [np.nan], inplace=True)\ndf.replace([-1], [np.nan], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()  #After replacing -1 with nan, we can see that there are null values in the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating separate columns of Salary Estimate as minimum and maximum salary**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_salary = df['Salary Estimate'].str.split(\"-\",expand=True,)\n\nminimum_salary = df_salary[0]\nminimum_salary = minimum_salary.str.replace('K',' ')\n\n\nmaximum_salary = df_salary[1].str.replace('(Glassdoor est.)', ' ')\nmaximum_salary = maximum_salary.str.replace('(', ' ')\nmaximum_salary = maximum_salary.str.replace(')', ' ')\nmaximum_salary = maximum_salary.str.replace('K', ' ')\nmaximum_salary = maximum_salary.str.replace('Employer est.', ' ')\nmaximum_salary = maximum_salary.str.replace('Per Hour', ' ')\n\nmaximum_salary = maximum_salary.str.replace('$', ' ').fillna(0).astype(int)\nminimum_salary = minimum_salary.str.replace('$', ' ').fillna(0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maximum_salary.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Minimum Salary'] = minimum_salary\ndf['Maximum Salary'] = maximum_salary\n\ndf.drop('Salary Estimate',axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Company Name'] = df['Company Name'].str.replace('\\n.*', ' ')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Making city and state columns for both Location and Headquaters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Location = df['Location'].str.split(\",\",expand=True,)\nLocation_City = Location[0]\nLocation_State = Location[1]\ndf['Location City'] = Location_City\ndf['Location State'] = Location_State\ndf.drop('Location',axis = 1, inplace = True)\n\nHQ = df['Headquarters'].str.split(\",\",expand=True)\nHeadquarters_City = HQ[0]\nHeadquarters_State = HQ[1]\ndf['Headquarters City'] = Headquarters_City\ndf['Headquarters State'] = Headquarters_State\ndf.drop('Headquarters',axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Separating department and from job title column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"department = df['Job Title'].str.split(',', expand = True)\ndf['Job Title'], df['Department'] = department[0],department[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since, department has too many missing values (2023/2253), it can be dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Department',1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Job Title'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Job Title'] = df['Job Title'].str.replace('Sr.', 'Senior')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking values from the columns for cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Type of ownership'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Industry'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Sector'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the Revenue column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'] = df['Revenue'].replace('Unknown / Non-Applicable', None)\n# data['Revenue']=data['Revenue'].replace('Unknown / Non-Applicable', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'] = df['Revenue'].str.replace('$', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('(USD)', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('(', ' ')\ndf['Revenue'] = df['Revenue'].str.replace(')', ' ')\ndf['Revenue'] = df['Revenue'].str.replace(' ', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'] = df['Revenue'].str.replace('2to5billion', '2billionto5billion')\ndf['Revenue'] = df['Revenue'].str.replace('5to10billion ', '5billionto10billion ')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'] = df['Revenue'].replace('million', ' ')\ndf['Revenue'] = df['Revenue'].replace('10+billion', '10billionto11billion')\ndf['Revenue'] = df['Revenue'].str.replace('Lessthan1million', '0millionto1million')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'] = df['Revenue'].str.replace('million', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('billion', '000 ')\ndf['Revenue'] = df['Revenue'].replace('Unknown/Non-Applicable', np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Revenue = df['Revenue'].str.split(\"to\",expand=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating two separate columns of Revenue as Minimum and Maximum Revenue**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Minimum Revenue'] = Revenue[0]\ndf['Maximum Revenue'] = Revenue[1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Maximum Revenue'] = pd.to_numeric(df['Maximum Revenue'])\ndf['Minimum Revenue'] = pd.to_numeric(df['Minimum Revenue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Revenue',1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the Size column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Size'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Size'] = df['Size'].str.replace('employees', '')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Size'] = df['Size'].str.replace('+', 'plus')\ndf['Size'] = df['Size'].replace('Unknown', None)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Size'] = df['Size'].str.replace('10000plus', '10000 to 10001')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size = df['Size'].str.split(\"to\",expand=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating separate columns of Size as minimum and maximum size**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Minimum Size'] = size[0]\ndf['Maximum Size'] = size[1]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Size',1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def contains_word(s, w):\n#     return f' {w} ' in f' {s} '\n\n# # def rev(text):\n# #     #if contains_word(text,'billion') is True:\n# #     text.str.replace('billion','')\n         \n# #     return text\n\n# def revenue(text):\n#     if contains_word(text,'billion') is True:\n#         max_rev = float(data_analyst_jobs['Maximum Revenue'].replace(\"billion\", \" \").strip())*1000\n#         #revenue = float(maxRev[0].replace('+','').strip())*100\n#     return max_rev\n\n# data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].apply(lambda text: clean_revenue(text))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Statistics"},{"metadata":{},"cell_type":"markdown","source":"Distribution of minimum and maximum salary of all Data Analyst job titles"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\nsns.despine(left=True)\nsns.distplot(df['Minimum Salary'],color = 'r',ax = axes[0])\nsns.distplot(df['Maximum Salary'],ax = axes[1])\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for outliers in Company Ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = df['Rating']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Minimum Size'] = df['Minimum Size'].astype('float')\ndf['Maximum Size'] = df['Maximum Size'].astype('float')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for outliers in company size"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(20, 5), sharex=True)\nsns.boxplot(x = df['Minimum Size'], ax = axes[0],palette='Set1');\nsns.boxplot(x = df['Maximum Size'], ax = axes[1],palette='Set2');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Visualization# "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,10))\nsplot = sns.barplot(x=df['Job Title'].value_counts()[0:20].index,y=df['Job Title'].value_counts()[0:20], palette = 'winter_r')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Job Title',fontsize=15)\nplt.ylabel('Job Count',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=15)\nplt.title('Top 20 Job Title Counts',fontsize=25);\n\n# for index, row in data_analyst_jobs.iterrows():\n#     splot.text(row.name,row.tip, round('Job Title',2), color='black', ha=\"center\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,15))\nsplot = sns.barplot(x = df['Company Name'][0:20], y = df['Maximum Revenue'][0:20], data = df, palette = 'spring')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\n\nplt.xlabel('Company Name',fontsize=15)\nplt.ylabel('Maximum revenue in million dollars',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Maximum Revenue of top 20 Companies',fontsize=25);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating 'Average Revenue' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Average Revenue'] = df[['Minimum Revenue','Maximum Revenue']].mean(axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_rev = df['Average Revenue'][0:20]\navg_rev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(20,15))\nsplot = sns.barplot(x = df['Company Name'][0:20], y = df['Average Revenue'][0:20], data = df, palette = 'summer')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Company Name')\nplt.ylabel('Average revenue in million dollars')\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Average Revenue of top 20 Companies',fontsize=25);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 cities', barmode = 'group')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = df.groupby('Job Title')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 job titles', barmode = 'stack')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Average Salary'] = df[['Minimum Salary', 'Maximum Salary']].mean(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(df, x=df['Rating'], y= df['Average Salary'])\nfig.update_layout(title = 'Relation between average salary and rating of companies')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = df.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).head(25)\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(x=data2['Average Revenue'], y=data2.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3 = df.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).tail(25)\ndata3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(x=data3['Average Revenue'], y=data3.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data4 = pd.DataFrame(df['Sector'].value_counts())\ndata4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.pie(data4, values=data4['Sector'], names=data4.index)\nfig.update_layout(title = 'Percentage of Different Sectors with requirement of Data Scientist  Roles')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data5 = pd.DataFrame(df['Industry'].value_counts().head(25))\ndata5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.pie(data5, values=data5['Industry'], names=data5.index)\nfig.update_layout(title = 'Percentage of top 25 Industries with requirement of Data Analyst Roles')\nfig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data6 = pd.DataFrame(df['Type of ownership'].value_counts())\ndata6\n\nimport plotly.express as px\nfig = px.pie(data6, values=data6['Type of ownership'], names=data6.index)\nfig.update_layout(title = 'Type of ownership')\nfig.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data7 = pd.DataFrame(df['Headquarters City'].value_counts().head(25))\ndata7\n\nimport plotly.express as px\nfig = px.pie(data7, values=data7['Headquarters City'], names=data7.index)\nfig.update_layout(title = 'Top 25 Headquarter City')\nfig.show()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data8 = pd.DataFrame(df['Location City'].value_counts().head(25))\ndata8\n\nimport plotly.express as px\nfig = px.pie(data8, values=data8['Location City'], names=data8.index)\nfig.update_layout(title = 'Top 25 Job Locations')\nfig.show()\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Word Cloud of Job Titles**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,15))\nwc = WordCloud()\ntext = df['Job Title']\nwc.generate(str(' '.join(text)))\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import nltk\n# from nltk.corpus import stopwords\n# import re\n# from nltk.stem.porter import PorterStemmer\n# print(stopwords.words('english'))\n\n# stop_words = set(stopwords.words('english'))\n# jobdes = data_analyst_jobs['Job Description'].to_csv()\n# jobdes = jobdes.split(' ')\n# jobdes = jobdes.lower()\n# jobdes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# skills = ['python', 'java','c', 'r','c++', 'hadoop', 'communication']\n\n# for word in all_words:\n#     print(word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_map = df.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_map = usa_map.reset_index()\nusa_map.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = usa_map['Location City']\ncities.head(20)\n\n['Daly City','Marin City', 'Los Gatos', 'Berkeley', 'San Jose', 'Cupertino','Santa Clara', 'Pico Rivera', 'Whittier','Far Rockaway', 'Secaucus', 'Sunnyvale', 'Menlo Park', 'Elk Grove Village', 'Glenview', 'Maywood', 'Northfield', 'Stanford', 'San Francisco', 'El Cajon']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a new DataFrame 'use_maps' consisting of 'Location State', 'Minimum Salary' and 'Maximum Salary' columns for ploting choropleth map for top 20 states with maximum salary."},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_maps = df.groupby('Location State')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_maps = usa_maps.reset_index()\n\nusa_maps = usa_maps.drop([3, 0])\nusa_maps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.choropleth(locations= ['AZ','NJ','NY','CO','IL','NC','VA','SC','WA','PA','DE','TX','KS','FL','IN','OH','GA','UT'], \n                    locationmode=\"USA-states\", \n                    color=[94.494845, 90.232558, 89.026087, 89.022727, 88.829268,85.233333, 85.125000, 83.000000, 82.759259, 77.824561, 75.909091, 74.116751, 67.000000, 66.666667, 61.000000, 58.800000, 56.000000, 48.454545],\n                    labels={'color':'Maximum Salary', 'locations':'State'},\n                    scope=\"usa\") \n\n\nfig.update_layout(\n    \n    title_text = 'Top 20 States with Maximum Salary',\n    geo_scope='usa'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If you like my notebook, give it an upvote! Suggestions for improvements are welcomed!**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}