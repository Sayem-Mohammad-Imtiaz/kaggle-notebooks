{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T03:50:20.629791Z","iopub.execute_input":"2021-08-01T03:50:20.630668Z","iopub.status.idle":"2021-08-01T03:50:20.659862Z","shell.execute_reply.started":"2021-08-01T03:50:20.630432Z","shell.execute_reply":"2021-08-01T03:50:20.65891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn import *\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:20.974781Z","iopub.execute_input":"2021-08-01T03:50:20.975127Z","iopub.status.idle":"2021-08-01T03:50:22.438047Z","shell.execute_reply.started":"2021-08-01T03:50:20.975096Z","shell.execute_reply":"2021-08-01T03:50:22.437179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the data from 'https://archive.ics.uci.edu/ml/datasets/phishing+websites'\ntraining_data = np.genfromtxt('../input/phishing/phishing.csv', delimiter=',', dtype=np.int32)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:22.43937Z","iopub.execute_input":"2021-08-01T03:50:22.439649Z","iopub.status.idle":"2021-08-01T03:50:22.747764Z","shell.execute_reply.started":"2021-08-01T03:50:22.439623Z","shell.execute_reply":"2021-08-01T03:50:22.74685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"training_data","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:22.74926Z","iopub.execute_input":"2021-08-01T03:50:22.749515Z","iopub.status.idle":"2021-08-01T03:50:22.758299Z","shell.execute_reply.started":"2021-08-01T03:50:22.74949Z","shell.execute_reply":"2021-08-01T03:50:22.757486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify the inputs (all of the attributes, except for the last one) and the outputs (the last attribute):\ninputs = training_data[:,:-1]\noutputs = training_data[:,-1]\n\nprint(inputs.shape)\nprint(outputs.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:22.759867Z","iopub.execute_input":"2021-08-01T03:50:22.76011Z","iopub.status.idle":"2021-08-01T03:50:22.770939Z","shell.execute_reply.started":"2021-08-01T03:50:22.760086Z","shell.execute_reply":"2021-08-01T03:50:22.770014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:22.772009Z","iopub.execute_input":"2021-08-01T03:50:22.772311Z","iopub.status.idle":"2021-08-01T03:50:22.781292Z","shell.execute_reply.started":"2021-08-01T03:50:22.772286Z","shell.execute_reply":"2021-08-01T03:50:22.780513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:22.782365Z","iopub.execute_input":"2021-08-01T03:50:22.782624Z","iopub.status.idle":"2021-08-01T03:50:22.791643Z","shell.execute_reply.started":"2021-08-01T03:50:22.782601Z","shell.execute_reply":"2021-08-01T03:50:22.790809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\n# To improve the estimators' accuracy scores, we are going to use the\n# sklearn.feature_selection module. This module is used in feature selection or\n# dimensionality reduction in the dataset.\n\n# To compute the features' importance, in our case, we are going to use tree-based feature\n# selection. Load the sklearn.feature_selection module:\n\nimport sklearn\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:22.792823Z","iopub.execute_input":"2021-08-01T03:50:22.793201Z","iopub.status.idle":"2021-08-01T03:50:22.801098Z","shell.execute_reply.started":"2021-08-01T03:50:22.793175Z","shell.execute_reply":"2021-08-01T03:50:22.800469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n# Obtaining the relevant feature set using ExtraTreesClassifier\n\nfeatselect = sklearn.ensemble.ExtraTreesClassifier().fit(inputs, outputs)\nmodel = SelectFromModel(featselect, prefit=True)\ninputs_new = model.transform(inputs)\nprint (inputs.shape)\nprint (inputs_new.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:22.80194Z","iopub.execute_input":"2021-08-01T03:50:22.802277Z","iopub.status.idle":"2021-08-01T03:50:23.55232Z","shell.execute_reply.started":"2021-08-01T03:50:22.802244Z","shell.execute_reply":"2021-08-01T03:50:23.55152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\n# Dataset normalization\nmin_max_scaler = preprocessing.MinMaxScaler()\ninputs_new_scaled = min_max_scaler.fit_transform(inputs_new)\ndata_new_features = pd.DataFrame(inputs_new_scaled)\n# After normalization\ndata_new_features.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:23.554314Z","iopub.execute_input":"2021-08-01T03:50:23.554543Z","iopub.status.idle":"2021-08-01T03:50:23.606623Z","shell.execute_reply.started":"2021-08-01T03:50:23.554519Z","shell.execute_reply":"2021-08-01T03:50:23.605826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\n# Outliers\nnum_cols = data_new_features.columns\nplt.figure(figsize=(18,9))\ndata_new_features[num_cols].boxplot()\nplt.title(\"Numerical variables in dataset\", fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:23.608067Z","iopub.execute_input":"2021-08-01T03:50:23.608489Z","iopub.status.idle":"2021-08-01T03:50:23.903052Z","shell.execute_reply.started":"2021-08-01T03:50:23.608458Z","shell.execute_reply":"2021-08-01T03:50:23.902155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Outliers exist only for the first column. Although it seems reasonable to remove those samples, if we remove those that column would be useless for classification, since it would have only a single value, which is zero. So it will remain as-is.","metadata":{}},{"cell_type":"code","source":"# Added by Luiz\n\nprint(f'Percentage of outlier samples (value=1) for first column: {data_new_features[data_new_features[0]==1].shape[0]/data_new_features.shape[0]*100:.2f}%')\nprint(f'Percentage of standard samples (value=0) for first column: {data_new_features[data_new_features[0]==0].shape[0]/data_new_features.shape[0]*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:23.904217Z","iopub.execute_input":"2021-08-01T03:50:23.90445Z","iopub.status.idle":"2021-08-01T03:50:24.034795Z","shell.execute_reply.started":"2021-08-01T03:50:23.904426Z","shell.execute_reply":"2021-08-01T03:50:24.033884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\nnew_inputs = data_new_features.values\nnew_inputs","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.035965Z","iopub.execute_input":"2021-08-01T03:50:24.036222Z","iopub.status.idle":"2021-08-01T03:50:24.043394Z","shell.execute_reply.started":"2021-08-01T03:50:24.036196Z","shell.execute_reply":"2021-08-01T03:50:24.042416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\nprint(f'Current size of the inputs: {new_inputs.shape}')\nprint(f'Current size of the outputs: {outputs.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.044529Z","iopub.execute_input":"2021-08-01T03:50:24.044874Z","iopub.status.idle":"2021-08-01T03:50:24.052387Z","shell.execute_reply.started":"2021-08-01T03:50:24.044834Z","shell.execute_reply":"2021-08-01T03:50:24.051671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\n# We have roughly the same amount of phishing and non-phishing samples, but we'll proceed to undersampling for a 50%/50% distribution anyway\nfreq = Counter(outputs)\nfishing_perc = freq[1]/(freq[-1] + freq[1])\nnon_fishing_perc = freq[-1]/(freq[-1] + freq[1])\n\nprint(f'Percentage of phishing is: {fishing_perc*100:.2f}%')\nprint(f'Percentage of non-phishing is: {non_fishing_perc*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.05345Z","iopub.execute_input":"2021-08-01T03:50:24.053932Z","iopub.status.idle":"2021-08-01T03:50:24.064724Z","shell.execute_reply.started":"2021-08-01T03:50:24.053894Z","shell.execute_reply":"2021-08-01T03:50:24.063837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n\n# Using undersampling to balance the dataset\n\nunder_sampler = RandomUnderSampler()\nX_res, y_res = under_sampler.fit_resample(new_inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.066205Z","iopub.execute_input":"2021-08-01T03:50:24.066577Z","iopub.status.idle":"2021-08-01T03:50:24.135042Z","shell.execute_reply.started":"2021-08-01T03:50:24.06654Z","shell.execute_reply":"2021-08-01T03:50:24.134297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Added by Luiz\n\n# After undersampling, the percentage should be even\nfreq = Counter(y_res)\nfishing_perc = freq[1]/(freq[-1] + freq[1])\nnon_fishing_perc = freq[-1]/(freq[-1] + freq[1])\n\nprint(f'Percentage of phishing is: {fishing_perc*100:.2f}%')\nprint(f'Percentage of non-phishing is: {non_fishing_perc*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.135955Z","iopub.execute_input":"2021-08-01T03:50:24.136312Z","iopub.status.idle":"2021-08-01T03:50:24.143113Z","shell.execute_reply.started":"2021-08-01T03:50:24.136284Z","shell.execute_reply":"2021-08-01T03:50:24.142506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dividing the dataset into training and testing:\nx_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X_res, y_res, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.144159Z","iopub.execute_input":"2021-08-01T03:50:24.144565Z","iopub.status.idle":"2021-08-01T03:50:24.155897Z","shell.execute_reply.started":"2021-08-01T03:50:24.144505Z","shell.execute_reply":"2021-08-01T03:50:24.15512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.156974Z","iopub.execute_input":"2021-08-01T03:50:24.157424Z","iopub.status.idle":"2021-08-01T03:50:24.165831Z","shell.execute_reply.started":"2021-08-01T03:50:24.157392Z","shell.execute_reply":"2021-08-01T03:50:24.165034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the scikit-learn logistic regression classifier with standard parameters\nclassifier1 = LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.167111Z","iopub.execute_input":"2021-08-01T03:50:24.167637Z","iopub.status.idle":"2021-08-01T03:50:24.176795Z","shell.execute_reply.started":"2021-08-01T03:50:24.167598Z","shell.execute_reply":"2021-08-01T03:50:24.175739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the scikit-learn Decision Tree classifier with standard parameters.\nclassifier2 = DecisionTreeClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.179942Z","iopub.execute_input":"2021-08-01T03:50:24.180202Z","iopub.status.idle":"2021-08-01T03:50:24.187391Z","shell.execute_reply.started":"2021-08-01T03:50:24.180178Z","shell.execute_reply":"2021-08-01T03:50:24.186592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the classifiers:\nclassifier1.fit(x_train, y_train)\nclassifier2.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.188481Z","iopub.execute_input":"2021-08-01T03:50:24.189045Z","iopub.status.idle":"2021-08-01T03:50:24.416204Z","shell.execute_reply.started":"2021-08-01T03:50:24.189006Z","shell.execute_reply":"2021-08-01T03:50:24.415264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions:\npredictions1 = classifier1.predict(x_test)\npredictions2 = classifier2.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.417846Z","iopub.execute_input":"2021-08-01T03:50:24.41854Z","iopub.status.idle":"2021-08-01T03:50:24.426078Z","shell.execute_reply.started":"2021-08-01T03:50:24.418494Z","shell.execute_reply":"2021-08-01T03:50:24.424935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print out the accuracy of our phishing detector models:\naccuracy1 = 100.0 * accuracy_score(y_test, predictions1)\naccuracy2 = 100.0 * accuracy_score(y_test, predictions2)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.428111Z","iopub.execute_input":"2021-08-01T03:50:24.429034Z","iopub.status.idle":"2021-08-01T03:50:24.437812Z","shell.execute_reply.started":"2021-08-01T03:50:24.428987Z","shell.execute_reply":"2021-08-01T03:50:24.43664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"The accuracy of your Logistic Regression on testing data is: \" +str(accuracy1))\nprint (\"The accuracy of your Decision Tree on testing data is: \" +str(accuracy2))","metadata":{"execution":{"iopub.status.busy":"2021-08-01T03:50:24.439642Z","iopub.execute_input":"2021-08-01T03:50:24.440437Z","iopub.status.idle":"2021-08-01T03:50:24.450927Z","shell.execute_reply.started":"2021-08-01T03:50:24.440389Z","shell.execute_reply":"2021-08-01T03:50:24.449743Z"},"trusted":true},"execution_count":null,"outputs":[]}]}