{"cells":[{"metadata":{},"cell_type":"markdown","source":"# In this Kernel I will conduct a rather simplified EDA at first, then cluster and predict the following aspects:\n\n* Gender (Male or Female)\n* Injury Severity (Uninjured, Minor, Moderate...)\n* Age (in groupes of 10 years - 20-30 / 30-40 / 40-50 etc..)\n\nChangelist commits -\n* 16.09 - First EDA & data cleaning\n* 22.09 - Clustering - First M/F, Second - Injury Severity !\n* 23.09 - Clustering second part - Injury Severity !\n* 26.10 - More complicated clustering - ADA Boost and Ensemble used !\n\nNext - \n* 27.10 - Age of the driver (in term of groups of 10 years)!"},{"metadata":{},"cell_type":"markdown","source":"First - some neccesary imports..."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, pairwise_distances\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, LabelEncoder\n\nprint(os.listdir(\"../input/nys-motor-vehicle-crashes-and-insurance-reduction\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the 2 relevant CSVs that could be read and compared hopefully via Vehicle ID"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_vehilce_information = pd.read_csv('../input/nys-motor-vehicle-crashes-and-insurance-reduction/motor-vehicle-crashes-vehicle-information-three-year-window.csv')\ndf_individual_information = pd.read_csv('../input/nys-motor-vehicle-crashes-and-insurance-reduction/motor-vehicle-crashes-individual-information-three-year-window.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Dropping some useless columns.."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_vehilce_information = df_vehilce_information.drop(columns=['Type / Axles of Truck or Bus', 'Direction of Travel', 'Fuel Type', 'State of Registration', 'Engine Cylinders', 'Contributing Factor 1', 'Contributing Factor 1 Description', 'Contributing Factor 2', 'Contributing Factor 2 Description', 'Event Type', 'Partial VIN'])\ndf_vehilce_information.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_vehilce_information.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_individual_information = df_individual_information.drop(columns=['Case Individual ID', 'Victim Status', 'License State Code', 'Transported By', 'Injury Descriptor', 'Injury Location'])\ndf_individual_information.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_individual_information.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Merging the two datasets using the Case Vehicle ID as the main Matching column and Year as cross Validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined = pd.merge(df_individual_information, df_vehilce_information, on='Case Vehicle ID', how='left')\nprint(df_combined.shape)\ndf_combined.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Validation of matching Case Vehicle IDs via comparing Year_x and Year_y"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_combined[df_combined.Year_x == df_combined.Year_y]['Case Vehicle ID']) / len(df_combined['Case Vehicle ID'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Perfect! Almost 100% identical matching! We can drop the unmatched and the additional Year"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined = df_combined[df_combined.Year_x == df_combined.Year_y]\ndf_combined = df_combined.drop(columns=['Year_y'])\ndf_combined.info(null_counts=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we have only around 2M data rows, lets not discard at this stage the existing Nans;\nQuick check for duplicates:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_no_dup = df_combined.drop_duplicates(subset='Case Vehicle ID').copy()\nprint(df_combined.shape)\ndf_combined_no_dup.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to understand why are the duplicates! Lets inspect a few:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined.sort_values(by='Case Vehicle ID').head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see a straight and a logical corelation between the number of occupants and the amount of Case Vehicle IDs that appear.\nNow lets drop cases where all the column values are the same..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined = df_combined.drop_duplicates()\ndf_combined.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA - first stage is complete ! \n(for every question we will add more EDA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers = df_combined[df_combined['Seating Position'] == 'Driver']\ndf_combined_motor_drivers = df_combined_drivers[df_combined_drivers['Role Type'] == 'Driver of a Motor Vehicle in Transport']\ndf_combined_drivers_m_or_f = df_combined_motor_drivers[df_combined_motor_drivers.Sex != 'U']\nprint(df_combined_drivers.shape)\nprint(df_combined_motor_drivers.shape)\nprint(df_combined_drivers_m_or_f.shape)\ndf_combined_drivers_m_or_f.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A bit more EDA - Lets select and remove from the data clear outliers for each column - \n1. Year_x - None;\t\n2. Case Vehicle ID - None;\n3. Role Type - Driver of a Motor Vehicle in Transport - only!;\n4. Seating Position - Driver - only!;\n5. Ejection\t- 49K Unknown - we need to decide what to do with those (3 categories - Not Ejected, Ejected, Partially Ejected)\n6. Sex - M or F only!\n7. Safety Equipment\t- 129k Unknown - we need to decide what to do with those (15 categories..)\n8. Injury Severity - all valid (6 categories)\n9. Age - No outliers (boxplot)\n10. Vehicle Body Type - 27k unknown + way to many categories...(62 categories..)\n11. Registration Class - 177K unknown... (69 categories..)\n12. Action Prior to Accident - 61k unknown.. (22 categories..)\t\n13. Vehicle Year - (boxplot), 11.5K outliers below 1993\t\n14. Number of Occupants\t- (boxplot), lets not include anything above normal buses (60 passengers max) = 29 vehicles excluded.. \n15. Vehicle Make - 1904 different makes! also has duplicate makes with diff names..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(df_combined_drivers_m_or_f.Ejection.value_counts())\n\n# print(df_combined_drivers_m_or_f['Safety Equipment'].value_counts())\n# print(df_combined_drivers_m_or_f['Safety Equipment'].nunique())\n\n# print(df_combined_drivers_m_or_f['Injury Severity'].value_counts())\n\nplt.figure(figsize=(3,6))\nsns.boxplot(y='Age', data=df_combined_drivers_m_or_f);\n\n# print(df_combined_drivers_m_or_f['Vehicle Body Type'].value_counts().head(20))\n# print(df_combined_drivers_m_or_f['Vehicle Body Type'].nunique())\n\n# print(df_combined_drivers_m_or_f['Registration Class'].value_counts())\n# print(df_combined_drivers_m_or_f['Registration Class'].nunique())\n\n# print(df_combined_drivers_m_or_f['Action Prior to Accident'].value_counts())\n# print(df_combined_drivers_m_or_f['Action Prior to Accident'].nunique())\n\nplt.figure(figsize=(3,6))\nsns.boxplot(y='Vehicle Year', data=df_combined_drivers_m_or_f);\n\n# print(df_combined_drivers_m_or_f['Vehicle Year'].quantile(.01))\n# print(df_combined_drivers_m_or_f[df_combined_drivers_m_or_f['Vehicle Year'] < 1993].shape)\n\nplt.figure(figsize=(3,6))\nsns.boxplot(y='Number of Occupants', data=df_combined_drivers_m_or_f);\n# print(df_combined_drivers_m_or_f['Number of Occupants'].quantile(.9999))\n# print(df_combined_drivers_m_or_f[df_combined_drivers_m_or_f['Number of Occupants'] > 60].shape)\n\n# print(df_combined_drivers_m_or_f['Vehicle Make'].value_counts().head(50))\n# print(df_combined_drivers_m_or_f['Vehicle Make'].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concluding for the F or M classification, lets choose the following features (based on simplification and logic at this stage): \n1. Year_x - not-relevant - not-used\t\n2. Case Vehicle ID - not-relevant - not-used\t\n3. Role Type - Driver of a Motor Vehicle in Transport - only!\n4. Seating Position - Driver - only!\n5. Ejection\t- 49K Unknown - we need to decide what to do with those (3 categories - Not Ejected, Ejected, Partially Ejected) - use \n6. Sex - M or F only!\n7. Safety Equipment\t- 129k Unknown - we need to decide what to do with those (15 categories..) - not-used for simplicity for now \n8. Injury Severity - all valid (6 categories) - use\n9. Age - No outliers (boxplot) - use\n10. Vehicle Body Type - 27k unknown + way to many categories...(62 categories..) - not-used for simplicity for now\n11. Registration Class - 177K unknown... (69 categories..) - not-used for simplicity for now\n12. Action Prior to Accident - 61k unknown.. (22 categories..) - not-used for simplicity for now\t\n13. Vehicle Year - (boxplot), 11.5K outliers below 1993\t- use\n14. Number of Occupants\t- (boxplot), not include anything above 60 passengers max => 29 vehicles excluded - use\n15. Vehicle Make - 1904 different makes! also has duplicate makes with diff names... - to many categories  - not-used"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f[['Ejection', 'Sex', 'Injury Severity', 'Age', 'Vehicle Year', 'Number of Occupants']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_combined_drivers_m_or_f_clustering.shape)\ndf_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f_clustering[df_combined_drivers_m_or_f_clustering['Ejection'].isin(['Not Ejected', 'Ejected', 'Partially Ejected'])]\nprint(df_combined_drivers_m_or_f_clustering.shape)\ndf_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f_clustering[df_combined_drivers_m_or_f_clustering['Number of Occupants'] < 60]\nprint(df_combined_drivers_m_or_f_clustering.shape)\ndf_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f_clustering[df_combined_drivers_m_or_f_clustering['Vehicle Year'] > 1993]\nprint(df_combined_drivers_m_or_f_clustering.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f_clustering.merge(pd.get_dummies(df_combined_drivers_m_or_f_clustering.Ejection, prefix='Ejection'), \n                                                                                    left_index=True, right_index=True)\ndf_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f_clustering.merge(pd.get_dummies(df_combined_drivers_m_or_f_clustering['Injury Severity'], prefix='Severity'), \n                                                                                    left_index=True, right_index=True)\ndf_combined_drivers_m_or_f_clustering.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f_clustering.drop(columns=['Ejection', 'Injury Severity'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering = df_combined_drivers_m_or_f_clustering.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering['Sex'] = df_combined_drivers_m_or_f_clustering.Sex.apply(lambda x: 1 if x == 'M' else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First Question - Prediction of Driver Male / Female\nNow we will perform the clustering: Creating a df without Sex F / M:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_combined_drivers_m_or_f_clustering[df_combined_drivers_m_or_f_clustering.columns[1:]]\ny = df_combined_drivers_m_or_f_clustering.Sex\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = LogisticRegression()\nclf2 = DecisionTreeClassifier(max_depth=7)\nclf3 = SVC(max_iter=200)\n\nclassifiers = [('LR', clf1), ('DT', clf2), ('SVM', clf3)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = y_train.to_frame()\nfor clf_name, clf in classifiers:\n    clf.fit(X_train, y_train)\n    results[clf_name] = clf.predict(X_train)\n    print (\"{:3} classifier:\\n \\\n        \\ttrain accuracy: {:.3f}\\n \\\n        \\ttest accuracy: {:.3f}\"\\\n        .format(clf_name, \n                clf.score(X_train, y_train), \n                clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results 1 !!!\n\nAll models are not very suited to cluster the current features between M and F, however the best classifier in terms of consistency between the Train and the Test splits are clearly the Decision Tree classifier. SVM classifier is especially unefective since the datasample size is larger than tens of thousands and this clearly shows that!\n\nIts accuracy is almost 0.60!"},{"metadata":{},"cell_type":"markdown","source":"# Second Question - Clustering of Injured / Uninjured !\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_injured = df_combined_drivers_m_or_f_clustering[df_combined_drivers_m_or_f_clustering.columns[:-6]]\ny_injured = df_combined_drivers_m_or_f_clustering.Severity_Uninjured\n\nX_train_injured, X_test_injured, y_train_injured, y_test_injured = train_test_split(X_injured, y_injured)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_injured.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_injured.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers_second = [('LR', clf1), ('DT', clf2)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_injured = y_train_injured.to_frame()\nfor clf_name_injured, clf_injured in classifiers_second:\n    clf_injured.fit(X_train_injured, y_train_injured)\n    results_injured[clf_name_injured] = clf_injured.predict(X_train_injured)\n    print (\"{:3} classifier:\\n \\\n        \\ttrain accuracy: {:.3f}\\n \\\n        \\ttest accuracy: {:.3f}\"\\\n        .format(clf_name_injured, \n                clf_injured.score(X_train_injured, y_train_injured), \n                clf_injured.score(X_test_injured, y_test_injured)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results 2 - half_way -\nThe best classifier in terms of consistency between the Train and the Test splits is again the Decision Tree classifier. \nIts accuracy is almost 0.80!!"},{"metadata":{},"cell_type":"markdown","source":"Finally - ADA boosting with a sample size of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_ada_base = DecisionTreeClassifier(max_depth=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f_clustering_sample_10 = df_combined_drivers_m_or_f_clustering.sample(frac = 0.1, random_state = 2)\nX_injured_sample_10 = df_combined_drivers_m_or_f_clustering_sample_10[df_combined_drivers_m_or_f_clustering_sample_10.columns[:-6]]\ny_injured_sample_10 = df_combined_drivers_m_or_f_clustering_sample_10.Severity_Uninjured\n\nX_train_injured_sample_10, X_test_injured_sample_10, y_train_injured_sample_10, y_test_injured_sample_10 = train_test_split(X_injured_sample_10, y_injured_sample_10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_adaboost = AdaBoostClassifier(base_estimator=clf_ada_base, n_estimators=120, learning_rate=0.01)\nclf_adaboost.fit(X_train_injured_sample_10, y_train_injured_sample_10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clf_adaboost.score(X_train_injured_sample_10, y_train_injured_sample_10))\nprint(clf_adaboost.score(X_test_injured_sample_10, y_test_injured_sample_10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Will different number of estimators or learning rate improve the score substantially?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('n_estimators=80, learning_rate=0.01')\nclf_adaboost = AdaBoostClassifier(base_estimator=clf_ada_base, n_estimators=80, learning_rate=0.01)\nclf_adaboost.fit(X_train_injured_sample_10, y_train_injured_sample_10)\nprint(clf_adaboost.score(X_train_injured_sample_10, y_train_injured_sample_10))\nprint(clf_adaboost.score(X_test_injured_sample_10, y_test_injured_sample_10))\n\nprint('n_estimators=100, learning_rate=0.01')\nclf_adaboost = AdaBoostClassifier(base_estimator=clf_ada_base, n_estimators=100, learning_rate=0.01)\nclf_adaboost.fit(X_train_injured_sample_10, y_train_injured_sample_10)\nprint(clf_adaboost.score(X_train_injured_sample_10, y_train_injured_sample_10))\nprint(clf_adaboost.score(X_test_injured_sample_10, y_test_injured_sample_10))\n\nprint('n_estimators=140, learning_rate=0.01')\nclf_adaboost = AdaBoostClassifier(base_estimator=clf_ada_base, n_estimators=140, learning_rate=0.01)\nclf_adaboost.fit(X_train_injured_sample_10, y_train_injured_sample_10)\nprint(clf_adaboost.score(X_train_injured_sample_10, y_train_injured_sample_10))\nprint(clf_adaboost.score(X_test_injured_sample_10, y_test_injured_sample_10))\n\nprint('n_estimators=140, learning_rate=0.02')\nclf_adaboost = AdaBoostClassifier(base_estimator=clf_ada_base, n_estimators=120, learning_rate=0.02)\nclf_adaboost.fit(X_train_injured_sample_10, y_train_injured_sample_10)\nprint(clf_adaboost.score(X_train_injured_sample_10, y_train_injured_sample_10))\nprint(clf_adaboost.score(X_test_injured_sample_10, y_test_injured_sample_10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADA Boosting appears to be even better than the simple DT classifier, however, in total we get a very similar performance. \n\n# Finally and lastly we will use ensamble voting method for the 3 methods previously chosen to find the best scores on the saple data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = LogisticRegression()\nclf2 = DecisionTreeClassifier(max_depth=5)\nclf3 = AdaBoostClassifier(base_estimator=clf2, n_estimators=100, learning_rate=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers_sampled = [('LR', clf1), ('DT', clf2), ('ADA_DT', clf3)]\nresults = y_train_injured_sample_10.to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for clf_name, clf in classifiers_sampled:\n    clf.fit(X_train_injured_sample_10, y_train_injured_sample_10)\n    results[clf_name] = clf.predict(X_train_injured_sample_10)\n    print(clf_name)\n    print(clf.score(X_train_injured_sample_10, y_train_injured_sample_10))\n    print(clf.score(X_test_injured_sample_10, y_test_injured_sample_10))\nresults.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_voting = VotingClassifier(estimators=classifiers_sampled, flatten_transform=True, voting='soft')\nclf_voting.fit(X_train_injured_sample_10, y_train_injured_sample_10)\nprint(clf_voting.score(X_train_injured_sample_10, y_train_injured_sample_10))\nprint(clf_voting.score(X_test_injured_sample_10, y_test_injured_sample_10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Results for question 2 - ADA DT boosting, DT and Ensemble methods are better than the LR model. Simplest decision here is to use the Decision Tree classifieng method because its cheaper and its results are as good as ADA DT boosting and Ensemble. "},{"metadata":{},"cell_type":"markdown","source":"# Part 3 and Results for Age predictions - \nfirst - lets try to increase the number of features in order to receive the best possible scores for the question"},{"metadata":{},"cell_type":"markdown","source":"After further EDA we see that there are still double Case Vehicle IDs for no reason. Deeper analysis showed duplicated cars for different age of the driver and a different year written - meaning a car that probably has been involved in an accident twice in different years."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First lets deal with the categorical features using OneHotEncoder method -\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn import feature_selection\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\nfrom sklearn.datasets import load_boston\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f = df_combined_drivers_m_or_f.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in df_combined_drivers_m_or_f.columns:\n    print(df_combined_drivers_m_or_f[name].value_counts().head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare = copy.copy(df_combined_drivers_m_or_f[['Ejection', 'Sex', 'Safety Equipment', 'Injury Severity', 'Age', 'Vehicle Body Type', 'Registration Class', 'Action Prior to Accident', 'Vehicle Year', 'Number of Occupants', 'Vehicle Make']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['Ejection', 'Sex', 'Safety Equipment', 'Injury Severity', 'Vehicle Body Type', 'Registration Class', 'Action Prior to Accident', 'Vehicle Make']:\n    print(i)\n    X_df_combined_drivers_m_or_f_rare.loc[X_df_combined_drivers_m_or_f_rare[i].value_counts()[X_df_combined_drivers_m_or_f_rare[i]].values < 5000, i] = \"RARE_VALUE\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in X_df_combined_drivers_m_or_f_rare.columns:\n    print(X_df_combined_drivers_m_or_f_rare[name].value_counts().head(20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We reduceted dramatically the number of the categorical features, and now we can label them."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare['Ejection'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Ejection'])\nX_df_combined_drivers_m_or_f_rare['Sex'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Sex'])\nX_df_combined_drivers_m_or_f_rare['Safety Equipment'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Safety Equipment'])\nX_df_combined_drivers_m_or_f_rare['Injury Severity'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Injury Severity'])\nX_df_combined_drivers_m_or_f_rare['Vehicle Body Type'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Vehicle Body Type'])\nX_df_combined_drivers_m_or_f_rare['Registration Class'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Registration Class'])\nX_df_combined_drivers_m_or_f_rare['Action Prior to Accident'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Action Prior to Accident'])\nX_df_combined_drivers_m_or_f_rare['Vehicle Make'] = le.fit_transform(X_df_combined_drivers_m_or_f_rare['Vehicle Make'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined_drivers_m_or_f.Age.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"50% of the people are above 40 and 50% are below 40. Lets cluster the age and between below 40 and above 40:"},{"metadata":{},"cell_type":"markdown","source":"Finally lets split age in between above 40 and below 40:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare['Age'] = X_df_combined_drivers_m_or_f_rare['Age'].apply(lambda x: 1 if x > 40 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets select the features using few feature selection methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"vt = feature_selection.VarianceThreshold(threshold=.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vt.fit_transform(X_df_combined_drivers_m_or_f_rare)\nvt.variances_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also see the correlations using a heat map"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = X_df_combined_drivers_m_or_f_rare.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor[\"Age\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.015]\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vehicle Make, Registration class and Injury severity had weak correlations to the Age of the driver.\nReducing Vehicle Make feature will allow a removal of a substantial amount features.\nFor the model we will use the following features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare[['Ejection', 'Sex', 'Safety Equipment', 'Vehicle Body Type', 'Action Prior to Accident', 'Vehicle Year', 'Number of Occupants', 'Age']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare_fin[X_df_combined_drivers_m_or_f_rare_fin['Number of Occupants'] < 60]\nprint(X_df_combined_drivers_m_or_f_rare_fin.shape)\nX_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare_fin[X_df_combined_drivers_m_or_f_rare_fin['Vehicle Year'] > 1993]\nprint(X_df_combined_drivers_m_or_f_rare_fin.shape)\nX_df_combined_drivers_m_or_f_rare_fin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare_fin.merge(pd.get_dummies(X_df_combined_drivers_m_or_f_rare_fin.Ejection, drop_first = True, prefix='Ejection'), left_index=True, right_index=True)\nX_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare_fin.merge(pd.get_dummies(X_df_combined_drivers_m_or_f_rare_fin['Safety Equipment'], drop_first = True, prefix='Safety_equip'), left_index=True, right_index=True)\nX_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare_fin.merge(pd.get_dummies(X_df_combined_drivers_m_or_f_rare_fin['Vehicle Body Type'], drop_first = True, prefix='Vehicle_Body_Type'), left_index=True, right_index=True)\nX_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare_fin.merge(pd.get_dummies(X_df_combined_drivers_m_or_f_rare_fin['Action Prior to Accident'], drop_first = True, prefix='Act_Prior_Acc'), left_index=True, right_index=True)\nX_df_combined_drivers_m_or_f_rare_fin = X_df_combined_drivers_m_or_f_rare_fin.drop(columns= ['Ejection', 'Safety Equipment', 'Vehicle Body Type', 'Action Prior to Accident'])\nX_df_combined_drivers_m_or_f_rare_fin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare_fin.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finally ready for modeling ! clustering according to Age groups - above 40 or below 40:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df_combined_drivers_m_or_f_rare_fin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_sample_100 = X_df_combined_drivers_m_or_f_rare_fin.sample(frac = 0.01, random_state = 222)\n\nX_age_sample_100 = age_sample_100.drop(columns=['Age'])\ny_age_sample_100 = age_sample_100.Age\n\nX_train_age_sample_100, X_test_age_sample_100, y_train_age_sample_100, y_test_age_sample_100 = train_test_split(X_age_sample_100, y_age_sample_100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = LogisticRegression()\nclf2 = DecisionTreeClassifier(max_depth=5)\nclf3 = AdaBoostClassifier(base_estimator=clf2, n_estimators=100, learning_rate=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers_sampled_age = [('LR', clf1), ('DT', clf2), ('ADA_DT', clf3)]\nresults = y_train_age_sample_100.to_frame()\nfor clf_name, clf in classifiers_sampled_age:\n    clf.fit(X_train_age_sample_100, y_train_age_sample_100)\n    results[clf_name] = clf.predict(X_train_age_sample_100)\n    print(clf_name)\n    print(clf.score(X_train_age_sample_100, y_train_age_sample_100))\n    print(clf.score(X_test_age_sample_100, y_test_age_sample_100))\nresults.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_voting = VotingClassifier(estimators=classifiers_sampled_age, flatten_transform=True, voting='soft')\nclf_voting.fit(X_train_age_sample_100, y_train_age_sample_100)\nprint(clf_voting.score(X_train_age_sample_100, y_train_age_sample_100))\nprint(clf_voting.score(X_test_age_sample_100, y_test_age_sample_100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADA_Boost appears to be the best classifier.\n\nLets check it for the whole dataset (long run)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_age = X_df_combined_drivers_m_or_f_rare_fin.drop(columns=['Age'])\ny_age = X_df_combined_drivers_m_or_f_rare_fin.Age\nX_train_age, X_test_age, y_train_age, y_test_age = train_test_split(X_age, y_age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers_age = [('LR', clf1), ('DT', clf2), ('ADA_DT', clf3)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = y_train_age.to_frame()\nfor clf_name, clf in classifiers_age:\n    clf.fit(X_train_age, y_train_age)\n    results[clf_name] = clf.predict(X_train_age)\n    print(clf_name)\n    print(clf.score(X_train_age, y_train_age))\n    print(clf.score(X_test_age, y_test_age))\nresults.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final scores for the large Dataset - all classifiers are very similar with ~ 0.56-0.575, however, suprisingly, the LR classifier has the best scores for both the training and the test datasets! "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}