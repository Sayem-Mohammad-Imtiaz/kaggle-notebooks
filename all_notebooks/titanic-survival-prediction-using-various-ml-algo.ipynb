{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center;color:blue\">Don't forget to Upvote if you like it.ðŸ˜Š</h1>"},{"metadata":{},"cell_type":"markdown","source":"# Overview\n\nThis is the original data from Titanic competition plus some changes that I applied to it to be better suited for binary logistic regression:\n\nMerged the train and test data.\n\nRemoved the 'ticket' and 'cabin' attributes.\n\nMoved the 'Survived' attribute to the last column.\n\nAdded extra zero columns for categorical inputs to be better suited for One-Hot-Encoding.\n\nSubstituted the values of 'Sex' and 'Embarked' attributes with binary and categorical values respectively.\n\nFilled the missing values in 'Age' and 'Fare' attributes with the median of the data."},{"metadata":{},"cell_type":"markdown","source":"# **Introduction**\n\n\nIn this kernal we will going through the whole process of creating a Machine Learning on the Titanic dataset. It provides us a glance over the fate of the passenger onboard the \"Unsinkable\" ship which sinked. The dataset categorizes the passanger based on their economic status, sex, age and their survival. In this kernel, we will be analyzing, cleaning and visulizing the data in different forms to obtain hidden insights. Also, we'll create different ML models and depending upon their accuracies, use the most suitable model for the prediction."},{"metadata":{},"cell_type":"markdown","source":"<center><h1>Importing Libraries</h1></center>"},{"metadata":{},"cell_type":"markdown","source":"**Numpy : Python Library used for working with arrays<br>\nMatplotlib : Used for data visualizations. ex: to plot the relations between various factors<br>\nSeaborn: used for data visualization like matplotlib<br>\nPandas: used for data analysis and manipulation<br>**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Importing Dataset</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/titanic/train_and_test2.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Data Preprocessing</h1>"},{"metadata":{},"cell_type":"markdown","source":"<h4>Remove unnecessary columns like zero.1,zero.2..... using pandas dropna() method<br>\nWe will rename '2urvived' column as 'Survived' using rename method</h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.drop(['Passengerid','zero','zero.1','zero.2','zero.3','zero.4','zero.5','zero.6','zero.7','zero.8','zero.9','zero.10','zero.11','zero.12','zero.13','zero.14','zero.15','zero.16','zero.17','zero.18'],axis=1,inplace=True)\ndf.rename(columns={'2urvived':'Survived'},inplace=True) \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Remove the rows having null values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Data Visualization</h1>"},{"metadata":{},"cell_type":"markdown","source":"**Heatmap of Co-Relation of various columns with each other\ndf.corr() shows the relation between various feature and we hence we can see the influence of the features on each other**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\n# we keep annot=True to make the values appear of df.corr() appear on the heatmap\nsns.heatmap(df.corr(),annot=True,cmap=plt.cm.plasma)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Below we use pairplot method from seaborn library. It is used to plot graphs between the various features.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's see the various columns in df**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Building and Training the Model**"},{"metadata":{},"cell_type":"markdown","source":"**We will split the data for training and testing using train_test_split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nX=df.drop(['Survived'],axis=1)\nY=df['Survived']\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>1)Logistic Regression</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(max_iter=300)\nlr.fit(X_train,y_train)\nyhat_lr=lr.predict(X_test)\nprint(\"Accuracy of Logistic Model is:\",accuracy_score(yhat_lr,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Let's visualize the data using confusion matrix</h3>\n<span style=\"color:red\"><b>For those who don't know about Confusion Matrix:<br><br> A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.</b></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nax=confusion_matrix(yhat_lr,y_test)\nsns.heatmap(ax,annot=True,cmap=plt.cm.plasma)\nplt.xlabel('Predict')\nplt.ylabel('Actual')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>2) K-Nearest Neighbor</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKN=KNeighborsClassifier(n_neighbors=5)\nKN.fit(X_train,y_train)\nyhat=KN.predict(X_test)\nprint(\"Accuracy of K-Nearest Neighbor Model is:\",accuracy_score(yhat,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>3) Decision Tree</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree=DecisionTreeClassifier(random_state=0)\ntree.fit(X_train,y_train)\nyhat=tree.predict(X_test)\nprint(\"Accuracy of Decision Tree Classifier Model is:\",accuracy_score(yhat,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4)Support Vector Machine(SVM) </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm=SVC(kernel='linear')\nsvm.fit(X_train,y_train)\nyhat=svm.predict(X_test)\nprint(\"Accuracy of Support Vector Machine Model is:\",accuracy_score(yhat,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>5)Random Forest Classifier</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=200,criterion='entropy')\nrfc.fit(X_train,y_train)\nyhat=rfc.predict(X_test)\nprint(\"Accuracy of Random Forest Classifier Model is:\",accuracy_score(yhat,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Best Model</h1>"},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"color:blue\">We see that the best model for the prediction is Support Vector Machine with a accuracy of 0.8396</h3>"},{"metadata":{},"cell_type":"markdown","source":"<center><h3>Thank you for reading my notebook and don't forget to upvote the notebook</h3></center>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}