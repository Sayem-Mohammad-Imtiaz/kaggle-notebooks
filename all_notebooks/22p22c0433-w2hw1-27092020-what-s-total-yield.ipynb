{"cells":[{"metadata":{},"cell_type":"markdown","source":"> Notebook นี้เป็นส่วนหนึ่งของโครงการ Super AI Engineer\n\n> Owner:\n> \n> 22p22c0433-ชลัช\n> \n> 22p22c0433-Chalat"},{"metadata":{},"cell_type":"markdown","source":"# Download Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install astral","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport lightgbm as lgb\n\nfrom pandas_profiling import ProfileReport\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_gen = pd.read_csv('/kaggle/input/solar-power-generation-data/Plant_1_Generation_Data.csv')\ndf_sensor = pd.read_csv('/kaggle/input/solar-power-generation-data/Plant_1_Weather_Sensor_Data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration & Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"## Generation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile_gen = ProfileReport(df_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile_gen.to_widgets()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile_gen.to_notebook_iframe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DATE_TIME"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\ndf_gen['DATE_TIME'] = df_gen['DATE_TIME'].apply(lambda x: datetime.strptime(x,'%d-%m-%Y %H:%M'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen['DATE_TIME'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen['DATE_TIME'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_gen['MONTH'] = df_gen['DATE_TIME'].dt.month\n\n# df_gen['DAY'] = df_gen['DATE_TIME'].dt.day\n\ndf_gen['HOUR'] = df_gen['DATE_TIME'].dt.hour\n\n# df_gen['MINUTE'] = df_gen['DATE_TIME'].dt.minute\n\ndf_gen['DATE'] = df_gen['DATE_TIME'].dt.date\n\ndf_gen['TIME'] = df_gen['DATE_TIME'].dt.time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PLANT_ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove PLANT_ID due to it has only 1 distinct value\n\ndf_gen = df_gen.drop('PLANT_ID', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SOURCE_KEY"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen['SOURCE_KEY'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} Inverters'.format(len(df_gen['SOURCE_KEY'].value_counts())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make it easier to read\n\ntemp_dict = {}\nfor index, source in enumerate(set(df_gen['SOURCE_KEY'])):\n    temp_dict[source] = index\n\ntemp_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen['SOURCE_KEY'] = df_gen['SOURCE_KEY'].map(temp_dict)\n\ndf_gen.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DC_POWER"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop due to high correlation with AC_POWER\n\ndf_gen = df_gen.drop('DC_POWER', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AC_POWER"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\n\nsns.lineplot(data=df_gen, x=\"DATE_TIME\", y='AC_POWER', hue='SOURCE_KEY')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DAILY_YIELD"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop due to TOTAL_YIELD we want to predict is accumulated from DAILY_YIELD\n\ndf_gen = df_gen.drop('DAILY_YIELD', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New feature: LIGHT_DURING_DAY"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nfrom astral import LocationInfo\nfrom astral.sun import sun\n\ndef light_during_day(date):\n    \n    # Lat, Long @ India \n    latitude = 78.9629\n    longitude = 20.5937\n    \n    city = LocationInfo(\"India\", latitude, longitude)\n    \n    year = date.year\n    month = date.month\n    day = date.day\n    \n    s = sun(city.observer, date=datetime.date(year, month, day))\n    seconds = (s['sunset'] - s['sunrise']).seconds    \n    minute = np.round(seconds/60,0)\n    \n    return minute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen['LIGHT_DURING_DAY'] = df_gen['DATE_TIME'].apply(lambda x: light_during_day(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Maximum time: {} minutes'.format(df_gen['LIGHT_DURING_DAY'].max()))\nprint('Minimum time: {} minutes'.format(df_gen['LIGHT_DURING_DAY'].min()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weather Sensor Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sensor.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile_sensor = ProfileReport(df_sensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile_sensor.to_widgets()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile_sensor.to_notebook_iframe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DATE_TIME"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_sensor['DATE_TIME'] = pd.to_datetime(df_sensor['DATE_TIME'])\n\nfrom datetime import datetime\n\ndf_sensor['DATE_TIME'] = df_sensor['DATE_TIME'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sensor['DATE_TIME'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sensor['DATE_TIME'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sensor.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PLANT_ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove PLANT_ID due to it has only 1 distinct value\n\ndf_sensor = df_sensor.drop('PLANT_ID', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sensor.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SOURCE_KEY"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove SOURCE_KEY due to it has only 1 distinct value\n\ndf_sensor = df_sensor.drop('SOURCE_KEY',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sensor.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AMBIENT_TEMPERATURE"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\n\nsns.lineplot(data=df_sensor, x=\"DATE_TIME\", y=\"AMBIENT_TEMPERATURE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MODULE_TEMPERATURE"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\n\nsns.lineplot(data=df_sensor, x=\"DATE_TIME\", y=\"MODULE_TEMPERATURE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### IRRADIATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\n\nsns.lineplot(data=df_sensor, x=\"DATE_TIME\", y=\"IRRADIATION\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## JOIN TABLE"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join = pd.merge(df_gen, df_sensor, left_on='DATE_TIME', right_on='DATE_TIME', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join[(df_join['AMBIENT_TEMPERATURE'].isna()) & df_join['AC_POWER'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\n\nsns.lineplot(data=df_join, x=\"DATE_TIME\", y='AMBIENT_TEMPERATURE', hue='SOURCE_KEY')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IMPUTE NULL VALUE"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join.iloc[38543:38549]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join.fillna(method='ffill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join.iloc[38543:38549]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add past 3 days ago data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_join['AMBIENT_TEMPERATURE_d-1'] = df_join.sort_values(by=['SOURCE_KEY','TIME','DATE'], ascending=False).shift(-1)['AMBIENT_TEMPERATURE']\n# df_join['AMBIENT_TEMPERATURE_d-2'] = df_join.sort_values(by=['SOURCE_KEY','TIME','DATE'], ascending=False).shift(-2)['AMBIENT_TEMPERATURE']\n# df_join['AMBIENT_TEMPERATURE_d-3'] = df_join.sort_values(by=['SOURCE_KEY','TIME','DATE'], ascending=False).shift(-3)['AMBIENT_TEMPERATURE']\n# df_join.drop('AMBIENT_TEMPERATURE_d-3', axis = 1, inplace = True)\n\ndef create_past_col(df, col_name, day_back):\n    for day in range(-day_back,0):\n        df[col_name + '_d' + str(day)] = df.sort_values(by=['SOURCE_KEY','TIME','DATE'], ascending=False).shift(day)[col_name]\n        print('Finish column: {}{}'.format(col_name,day))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_3day = df_join.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_past_col(df_join_3day, 'AMBIENT_TEMPERATURE', 3)\ncreate_past_col(df_join_3day, 'AC_POWER', 3)\ncreate_past_col(df_join_3day, 'TOTAL_YIELD', 3)\ncreate_past_col(df_join_3day, 'LIGHT_DURING_DAY', 3)\ncreate_past_col(df_join_3day, 'MODULE_TEMPERATURE', 3)\ncreate_past_col(df_join_3day, 'IRRADIATION', 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_3day.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_3day.sort_values(by=['SOURCE_KEY','TIME','DATE'], ascending=False).tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_3day.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_3day[df_join_3day['TOTAL_YIELD_d-1'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_join_3day = df_join_3day.dropna()\n\ndf_join_3day = df_join_3day.fillna(df_join_3day.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_to_drop = ['AMBIENT_TEMPERATURE','AC_POWER','LIGHT_DURING_DAY','MODULE_TEMPERATURE','IRRADIATION','DATE_TIME',\\\n              'SOURCE_KEY','DATE','TIME']\n\n\ndf_join_3day = df_join_3day.drop(col_to_drop, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_3day.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add past 7 days ago data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_7day = df_join.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_past_col(df_join_7day, 'AMBIENT_TEMPERATURE', 7)\ncreate_past_col(df_join_7day, 'AC_POWER', 7)\ncreate_past_col(df_join_7day, 'TOTAL_YIELD', 7)\ncreate_past_col(df_join_7day, 'LIGHT_DURING_DAY', 7)\ncreate_past_col(df_join_7day, 'MODULE_TEMPERATURE', 7)\ncreate_past_col(df_join_7day, 'IRRADIATION', 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_7day = df_join_7day.drop(col_to_drop, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_7day.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_7day.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_join_7day = df_join_7day.dropna()\n\ndf_join_7day = df_join_7day.fillna(df_join_7day.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Data & Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def modeling(X_train,Y_train,X_test,Y_test):\n    mse_list = []\n    rmse_list = []\n    mse_dict = {}\n    rmse_dict = {}\n    \n    ###############################\n    # Linear Regression\n    linear_regressor = LinearRegression()\n    linear_regressor.fit(X_train, Y_train)    \n    y_pred_lr = linear_regressor.predict(X_test)\n    \n    mse_lr = mean_squared_error(Y_test, y_pred_lr)\n    mse_list.append(mse_lr)\n    rmse_lr = sqrt(mse_lr)\n    rmse_list.append(rmse_lr)\n    mse_dict['Linear_Regression'] = mse_lr\n    rmse_dict['Linear_Regression'] = rmse_lr\n    \n    ###############################\n    # Polynomial Regression\n    poly_reg = PolynomialFeatures(degree = 3)\n    X_poly = poly_reg.fit_transform(X_train)\n\n    poly_regressor = LinearRegression()\n    poly_regressor.fit(X_poly, Y_train)\n\n    X_poly_test = poly_reg.fit_transform(X_test)\n    y_pred_pr = poly_regressor.predict(X_poly_test)\n    \n    mse_pr = mean_squared_error(Y_test, y_pred_pr)    \n    mse_list.append(mse_pr)\n    rmse_pr = sqrt(mse_pr)\n    rmse_list.append(rmse_pr)    \n    mse_dict['Polynomial_Regression'] = mse_pr\n    rmse_dict['Polynomial_Regression'] = rmse_pr\n    \n    ###############################\n    # Random Forest Regressor\n    rf_regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n    rf_regressor.fit(X_train, Y_train)\n    y_pred_rfr = rf_regressor.predict(X_test)\n    \n    mse_rfr = mean_squared_error(Y_test, y_pred_rfr)\n    mse_list.append(mse_rfr)\n    rmse_rfr = sqrt(mse_rfr)\n    rmse_list.append(rmse_rfr)    \n    mse_dict['Random_Forest_Regressor'] = mse_rfr\n    rmse_dict['Random_Forest_Regressor'] = rmse_rfr\n    \n    ###############################\n    # LGBM\n#     hyper_params = {\n#     'task': 'train',\n#     'boosting_type': 'gbdt',\n#     'objective': 'regression',\n#     'metric': ['rmse'],\n#     'learning_rate': 0.05,\n#     'feature_fraction': 0.9,\n#     'bagging_fraction': 0.7,\n#     'bagging_freq': 10,\n#     'verbose': -1,\n#     \"max_depth\": 8,\n#     \"num_leaves\": 128,  \n#     \"max_bin\": 256,\n#     \"num_iterations\": 50,\n#     \"n_estimators\": 1000\n#     }\n\n#     gbm = lgb.LGBMRegressor(verbose_eval=False, **hyper_params)\n\n#     gbm.fit(X_train, Y_train,\n#             eval_set=[(X_test, Y_test)],\n#             eval_metric='rmse',\n#             early_stopping_rounds=50)\n\n#     Y_pred_lgbm = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n    \n#     mse_lgbm = mean_squared_error(Y_test, Y_pred_lgbm)\n#     mse_list.append(mse_lgbm)\n#     rmse_lgbm = sqrt(mse_lgbm)\n#     rmse_list.append(rmse_lgbm)\n#     mse_dict['LightGBM'] = mse_lgbm\n#     rmse_dict['LightGBM'] = rmse_lgbm\n        \n    return mse_list, rmse_list, mse_dict, rmse_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_join_3day.iloc[0::10].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = df_join_3day.drop(df_join_3day.index[1::10]).drop('TOTAL_YIELD', axis = 1)\n# Y_train = df_join_3day.drop(df_join_3day.index[1::10], errors='ignore')['TOTAL_YIELD']\n\n# X_test = df_join_3day.iloc[1::10].drop('TOTAL_YIELD', axis = 1)\n# Y_test = df_join_3day.iloc[1::10]['TOTAL_YIELD']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## USE 3 DAYS AGO WITH TOTAL_YIELD"},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(10):\n\n    X_train = df_join_3day.drop(df_join_3day.index[k::10]).drop('TOTAL_YIELD', axis = 1)\n    Y_train = df_join_3day.drop(df_join_3day.index[k::10], errors='ignore')['TOTAL_YIELD']\n    \n    X_test = df_join_3day.iloc[k::10].drop('TOTAL_YIELD', axis = 1)\n    Y_test = df_join_3day.iloc[k::10]['TOTAL_YIELD']\n    \n    mse_list, rmse_list, mse_dict, rmse_dict = modeling(X_train,Y_train,X_test,Y_test)\n    \n    print('############################\\n')\n    print('fold: {}\\n'.format(k))\n    \n    print('MSE:')\n    print(mse_dict)\n    \n    print('RMSE:')\n    print(rmse_dict)\n    \n    print('\\n############################\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## USE 3 DAYS AGO WITHOUT TOTAL_YIELD"},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(10):\n\n\n    X_train = df_join_3day.drop(df_join_3day.index[k::10]).drop(['TOTAL_YIELD','TOTAL_YIELD_d-1','TOTAL_YIELD_d-2','TOTAL_YIELD_d-3'], axis = 1)\n    Y_train = df_join_3day.drop(df_join_3day.index[k::10], errors='ignore')['TOTAL_YIELD']\n    \n    X_test = df_join_3day.iloc[k::10].drop(['TOTAL_YIELD','TOTAL_YIELD_d-1','TOTAL_YIELD_d-2','TOTAL_YIELD_d-3'], axis = 1)\n    Y_test = df_join_3day.iloc[k::10]['TOTAL_YIELD']\n    \n    mse_list, rmse_list, mse_dict, rmse_dict = modeling(X_train,Y_train,X_test,Y_test)\n    \n    print('############################\\n')\n    print('fold: {}'.format(k))\n    \n    print('MSE:')\n    print(mse_dict)\n    \n    print('RMSE:')\n    print(rmse_dict)\n    \n    print('\\n############################\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## USE 7 DAYS AGO WITH TOTAL_YIELD"},{"metadata":{"trusted":true},"cell_type":"code","source":"def modeling_7days(X_train,Y_train,X_test,Y_test):\n    mse_list = []\n    rmse_list = []\n    mse_dict = {}\n    rmse_dict = {}\n    \n    ###############################\n    # Linear Regression\n#     linear_regressor = LinearRegression()\n#     linear_regressor.fit(X_train, Y_train)    \n#     y_pred_lr = linear_regressor.predict(X_test)\n    \n#     mse_lr = mean_squared_error(Y_test, y_pred_lr)\n#     mse_list.append(mse_lr)\n#     rmse_lr = sqrt(mse_lr)\n#     rmse_list.append(rmse_lr)\n#     mse_dict['Linear_Regression'] = mse_lr\n#     rmse_dict['Linear_Regression'] = rmse_lr\n    \n    ###############################\n    # Polynomial Regression\n#     poly_reg = PolynomialFeatures(degree = 3)\n#     X_poly = poly_reg.fit_transform(X_train)\n\n#     poly_regressor = LinearRegression()\n#     poly_regressor.fit(X_poly, Y_train)\n\n#     X_poly_test = poly_reg.fit_transform(X_test)\n#     y_pred_pr = poly_regressor.predict(X_poly_test)\n    \n#     mse_pr = mean_squared_error(Y_test, y_pred_pr)    \n#     mse_list.append(mse_pr)\n#     rmse_pr = sqrt(mse_pr)\n#     rmse_list.append(rmse_pr)    \n#     mse_dict['Polynomial_Regression'] = mse_pr\n#     rmse_dict['Polynomial_Regression'] = rmse_pr\n    \n    ###############################\n    # Random Forest Regressor\n    rf_regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n    rf_regressor.fit(X_train, Y_train)\n    y_pred_rfr = rf_regressor.predict(X_test)\n    \n    mse_rfr = mean_squared_error(Y_test, y_pred_rfr)\n    mse_list.append(mse_rfr)\n    rmse_rfr = sqrt(mse_rfr)\n    rmse_list.append(rmse_rfr)    \n    mse_dict['Random_Forest_Regressor'] = mse_rfr\n    rmse_dict['Random_Forest_Regressor'] = rmse_rfr\n    \n    ###############################\n    # LGBM\n#     hyper_params = {\n#     'task': 'train',\n#     'boosting_type': 'gbdt',\n#     'objective': 'regression',\n#     'metric': ['rmse'],\n#     'learning_rate': 0.05,\n#     'feature_fraction': 0.9,\n#     'bagging_fraction': 0.7,\n#     'bagging_freq': 10,\n#     'verbose': -1,\n#     \"max_depth\": 8,\n#     \"num_leaves\": 128,  \n#     \"max_bin\": 256,\n#     \"num_iterations\": 50,\n#     \"n_estimators\": 1000\n#     }\n\n#     gbm = lgb.LGBMRegressor(verbose_eval=False, **hyper_params)\n\n#     gbm.fit(X_train, Y_train,\n#             eval_set=[(X_test, Y_test)],\n#             eval_metric='rmse',\n#             early_stopping_rounds=50)\n\n#     Y_pred_lgbm = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n    \n#     mse_lgbm = mean_squared_error(Y_test, Y_pred_lgbm)\n#     mse_list.append(mse_lgbm)\n#     rmse_lgbm = sqrt(mse_lgbm)\n#     rmse_list.append(rmse_lgbm)\n#     mse_dict['LightGBM'] = mse_lgbm\n#     rmse_dict['LightGBM'] = rmse_lgbm\n        \n    return mse_list, rmse_list, mse_dict, rmse_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(10):\n\n    X_train = df_join_7day.drop(df_join_7day.index[k::10]).drop('TOTAL_YIELD', axis = 1)\n    Y_train = df_join_7day.drop(df_join_7day.index[k::10], errors='ignore')['TOTAL_YIELD']\n    \n    X_test = df_join_7day.iloc[k::10].drop('TOTAL_YIELD', axis = 1)\n    Y_test = df_join_7day.iloc[k::10]['TOTAL_YIELD']\n    \n    mse_list, rmse_list, mse_dict, rmse_dict = modeling_7days(X_train,Y_train,X_test,Y_test)\n    \n    print('############################\\n')\n    print('fold: {}'.format(k))   \n    \n    print('MSE:')    \n    print(mse_dict)\n    \n    print('RMSE:') \n    print(rmse_dict)\n    \n    print('\\n############################\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## USE 7 DAYS AGO WITHOUT TOTAL_YIELD"},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(10):\n\n    X_train = df_join_7day.drop(df_join_7day.index[k::10]).drop(['TOTAL_YIELD','TOTAL_YIELD_d-1','TOTAL_YIELD_d-2','TOTAL_YIELD_d-3',\\\n                                                                 'TOTAL_YIELD_d-4','TOTAL_YIELD_d-5','TOTAL_YIELD_d-6','TOTAL_YIELD_d-7'], axis = 1)\n    Y_train = df_join_7day.drop(df_join_7day.index[k::10], errors='ignore')['TOTAL_YIELD']\n    \n    X_test = df_join_7day.iloc[k::10].drop(['TOTAL_YIELD','TOTAL_YIELD_d-1','TOTAL_YIELD_d-2','TOTAL_YIELD_d-3',\\\n                                           'TOTAL_YIELD_d-4','TOTAL_YIELD_d-5','TOTAL_YIELD_d-6','TOTAL_YIELD_d-7'], axis = 1)\n    Y_test = df_join_7day.iloc[k::10]['TOTAL_YIELD']\n    \n    mse_list, rmse_list, mse_dict, rmse_dict = modeling_7days(X_train,Y_train,X_test,Y_test)\n    \n    print('############################\\n')\n    print('fold: {}'.format(k))\n    \n    print('MSE:')    \n    print(mse_dict)\n    \n    print('RMSE:')  \n    print(rmse_dict)\n    \n    print('\\n############################\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Ps. Remove LGBM model because its ruin this notebook. The output is too long and cannot suppress it (maybe some bug T-T)**\n> \n> **Ps2. Kaggle warning 'Your notebook tried to allocate more memory than is available' when I tried to fit Linear Regression Model of 7 DAYS AGO data. (Linear Regression in Sklearn use Normal Equation to fit the data and its use a lot of RAM). So, I decide to use only 1 model (Random Forest Regressor)**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}