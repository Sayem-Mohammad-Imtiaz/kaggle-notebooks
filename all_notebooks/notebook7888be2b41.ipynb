{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Credit Card Kaggle Anamoly Detection\n"},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom pylab import rcParams\nfrom statistics import mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 14, 8\nRANDOM_SEED = 42\nLABELS = [\"Normal\", \"Fraud\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import the credit card fraud data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/creditcard/creditcard.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot histograms for the frequency/number of fraudulent and non-fraudulent transactions against Amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get the Fraud and the normal dataset \n\nfraud = data[data['Class']==1]\n\nnormal = data[data['Class']==0]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Amount per transaction by class')\nbins = 50\nax1.hist(fraud.Amount, bins = bins)\nax1.set_title('Fraud')\nax2.hist(normal.Amount, bins = bins)\nax2.set_title('Normal')\nplt.xlabel('Amount ($)')\nplt.ylabel('Number of Transactions')\nplt.xlim((0, 20000))\nplt.yscale('log')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"shows that alot of fraduelent transcationsare few and focus on small amounts of money."},{"metadata":{},"cell_type":"markdown","source":"# Draw boxplots showing summary statistics for the Amount column\n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.boxplot(data.Amount)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shows that alot of the transaction are small amounts around 88, and there are still alot of large transaction as show by the box plot but most of transaction are small amounts."},{"metadata":{},"cell_type":"markdown","source":"# Generate a correlation matrix illustrating using a heatmap the relationship between the different variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1= data.sample(frac = 0.1,random_state=1)\nFraud = data1[data1['Class']==1]\n\nValid = data1[data1['Class']==0]\nstate = np.random.RandomState(42)\n\noutlier_fraction = len(Fraud)/float(len(Valid))\nstate = np.random.RandomState(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Correlation\nimport seaborn as sns\n#get correlations of each features in dataset\ncorrmat = data1.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate a scatterplot for Amount and V2 showing a line of best fit using the equation of a straight line is y = mx + c, where m is the slope of the line and c is the y intercept"},{"metadata":{"trusted":true},"cell_type":"code","source":"xs = data.V2\nys= data.Amount\n\ndef line_of_best(xs,ys):\n    m= (((mean(xs) * mean(ys)) - mean(xs*ys))/((mean(xs)*mean(xs))- mean(xs*xs)))\n    b= mean(ys)- m*mean(xs)\n    return m,b\n    ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"m,b= line_of_best(xs,ys)\nregression_line = [(m*x)+b for x in xs]\nplt.scatter(xs,ys)\nplt.plot(xs,regression_line)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again shows that the vast amount of transaction are of small amounts."},{"metadata":{},"cell_type":"markdown","source":"## Build an outlier detection model for your data using the Isolation Forest and the Local Outlier Factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create independent and Dependent Features\ncolumns = data1.columns.tolist()\n# Filter the columns to remove data we do not want \ncolumns = [c for c in columns if c not in [\"Class\"]]\n# Store the variable we are predicting \ntarget = \"Class\"\n# Define a random state \nstate = np.random.RandomState(42)\nX = data1[columns]\nY = data1[target]\nX_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))\n# Print the shapes of X & Y\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Define the outlier detection methods\n\nclassifiers = {\n    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X), \n                                       contamination=outlier_fraction,random_state=state, verbose=0),\n    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n                                              leaf_size=30, metric='minkowski',\n                                              p=2, metric_params=None, contamination=outlier_fraction)\n    \n   \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(classifiers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyze the models using Errors, Confusion Matrix, Accuracy Score and Classification Report to identify the strengths and weaknesses of the models"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_outliers = len(Fraud)\nfor i, (clf_name,clf) in enumerate(classifiers.items()):\n    #Fit the data and tag outliers\n    if clf_name == \"Local Outlier Factor\":\n        y_pred = clf.fit_predict(X)\n        scores_prediction = clf.negative_outlier_factor_\n\n    else:    \n        clf.fit(X)\n        scores_prediction = clf.decision_function(X)\n        y_pred = clf.predict(X)\n    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n    y_pred[y_pred == 1] = 0\n    y_pred[y_pred == -1] = 1\n    n_errors = (y_pred != Y).sum()\n    # Run Classification Metrics\n    print(\"{}: {}\".format(clf_name,n_errors))\n    print(\"Accuracy Score :\")\n    print(accuracy_score(Y,y_pred))\n    print(\"Classification Report :\")\n    print(classification_report(Y,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discuss as a conclusion the best model and how to use it in the future in identifying fraudulent credit card transactions."},{"metadata":{},"cell_type":"markdown","source":"- Isolation Forest detected 73 errors versus Local Outlier Factor detecting 97 errors \n\n- Isolation Forest has a 99.74% more accurate than LOF of 99.65%\n\n- the Isolation Forest performed much better than the LOF as we can see that the detection of fraud cases is around 27% versus LOF detection rate of just 2%\n\nComapnies should y run its transactions in real time through an isolation forest in order to better detect fradulent transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}