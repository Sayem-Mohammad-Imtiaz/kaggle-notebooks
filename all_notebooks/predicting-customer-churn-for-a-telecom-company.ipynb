{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Develop a Deep Learning Based Churn Prediction Engine\n"},{"metadata":{},"cell_type":"markdown","source":"### Import required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load & understand the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the data\ndata = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n\n# Look at a snapshot of data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the summary stats and frequency distribution of features\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets' see if there are any missing values\n\nprint (data.apply(lambda x: sum(x.isnull()),axis=0))\nprint (np.where(data.applymap(lambda x: x == ' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see if there is class imbalance in the target variable\nprint (data['Churn'].value_counts(ascending=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['TotalCharges'].replace(to_replace = ' ', value= np.nan, inplace = True)\ndata['TotalCharges'] = data['TotalCharges'].astype(float)\ndata.dropna(axis=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations:\n\n**On Type conversions:**\n\n- Columns like CustomerID can be removed from the analysis\n- We see that 'Tenure' and 'MonthlyCharges' are numeric columns present in the data, with the data close to normal distribution. \n- Along with them, 'TotalCharges' is also a numeric column but contains some info missing, but still is not a nan.\n- The column 'SeniorCitizen' is a categorical column by its nature with 'Yes' as 1, and No as 0. So it shuold be converted into Categorical type\n- All the categorical attribtues are strings. Hence there is need to convert them into numbers, by a way of encoding.\n- Among the categorical attribtues, majority of them have binary classes(2 levels). Label encoding would help assign labels 0,1 for the levels as appropriate.\n- But attributes like 'PaymentMethod', 'Contract', 'InternetService' are nominal and have more than 2 levels. So along with label encoding, we need to convert them into equidistant levels.\n\n**On Missingness of data:**\n The data is clean and there are no missing values in the data\n \n**On the class imbalance in the target attribute**\nThere are more instances where the customers din't churn than those that have custoemrs churned out. Class imbalance is clearly seen."},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Split the data into train and test sets\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = data['Churn']\nX = data.loc[:, data.columns != 'Churn']\n\nX_train, X_test, y_train, y_test =   train_test_split(X, y, test_size=0.20, random_state=111)\n\nprint(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Remove customerID\nX_train.drop(['customerID'], axis = 1, inplace=True)\nX_test.drop(['customerID'], axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute missing values, if any!. Check number of missing values\nprint(\"Num missing values before imputation:\")\nprint(pd.DataFrame(X_train['TotalCharges']).isnull().sum())\n\nprint(\"Num missing values before imputation:\")\nprint(pd.DataFrame(X_test['TotalCharges']).isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Type Conversions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert 'SeniorCitizen' column into categorical\nX_train['SeniorCitizen']=pd.Categorical(X_train['SeniorCitizen'])\nX_test['SeniorCitizen']=pd.Categorical(X_test['SeniorCitizen'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode target variables to 0, 1\ny_train = y_train.map(dict(Yes=1, No=0))\ny_test = y_test.map(dict(Yes = 1, No=0))\nprint(y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardizing numeric attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide the columns into 3 categories, one ofor standardisation, one for label encoding and one for one hot encoding\nnum_cols = [\"tenure\", 'MonthlyCharges', 'TotalCharges']\ncat_cols_ohe =['PaymentMethod', 'Contract', 'InternetService'] # those that need one-hot encoding\ncat_cols_le = list(set(X_train.columns)- set(num_cols) - set(cat_cols_ohe)) #those that need label encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler= StandardScaler()\n\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\nX_test[num_cols] = scaler.transform(X_test[num_cols])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.DataFrame(X_train)\nX_test= pd.DataFrame(X_test)\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nle = LabelEncoder()\nohe = OneHotEncoder()\n\nfor col in cat_cols_le:\n    le.fit(X_train[col])\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe.fit(X_train[cat_cols_ohe])\ntr_cols= ohe.transform(X_train[cat_cols_ohe])\nte_cols = ohe.transform(X_test[cat_cols_ohe])\n\nX_train.drop(columns=cat_cols_ohe, inplace=True)\nX_test.drop(columns=cat_cols_ohe, inplace=True)\n\nX_train = np.hstack((X_train,tr_cols.toarray()))\nX_test = np.hstack((X_test, te_cols.toarray()))\nprint(X_train.shape, X_test.shape)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.value_counts(), '\\n', y_test.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the ANN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing necessary modules\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 7\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\ninput_shape = X_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(32, input_dim=input_shape, kernel_initializer='uniform', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n\nmodel.fit(X_train, y_train,\n              epochs=25,\n          batch_size=24, class_weight={0:0.2, 1:0.8})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nscore = model.evaluate(X_test, y_test, batch_size=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(score)\nprint (\"Accuracy : %s\" % \"{0:.3%}\".format(score[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_pred_dl=model.predict_classes(X_train)\ntest_pred_dl=model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nmlp_conf_matrix = metrics.confusion_matrix(y_test, test_pred_dl)\nprint (mlp_conf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\naccuracy = metrics.accuracy_score(y_test,test_pred_dl)\n    \nprint (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n\n#Print Recall\nrecall = metrics.recall_score(y_test,test_pred_dl)\n    \nprint (\"Recall : %s\" % \"{0:.3%}\".format(recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MLP using features from AutoEncoders"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding_dim  = 32\n# this is our input placeholder\ninput_img = Input(shape=(input_shape,))\n\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(input_shape, activation='sigmoid')(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(inputs=input_img, outputs=decoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy') #optimizer = adam --- can also be used ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.fit(X_train, X_train,\n                epochs=50,\n                batch_size=24,\n                shuffle=True,\n                validation_data=(X_test, X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this model maps an input to its encoded representation\nencoder = Model(inputs=input_img, outputs=encoded)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_encoded = encoder.predict(X_train)\nx_test_encoded = encoder.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_encoded.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_encoded.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = Sequential()\n\nmodel2.add(Dense(64, input_dim = 32, kernel_initializer='uniform', activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(16, activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.compile(loss='binary_crossentropy',\n              optimizer='Adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_encoded.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(x_train_encoded, y_train, batch_size=32, epochs=25, class_weight={0:0.2, 1:0.8})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score2 = model2.evaluate(x_test_encoded, y_test)\nprint (score2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_pred_dlac=model2.predict_classes(x_train_encoded)\ntest_pred_dlac=model2.predict_classes(x_test_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dlac_conf_matrix = metrics.confusion_matrix(y_test, test_pred_dlac)\nprint (dlac_conf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\naccuracy = metrics.accuracy_score(y_test,test_pred_dlac)\n    \nprint (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n\n#Print Recall\nrecall = metrics.recall_score(y_test,test_pred_dlac)\n    \nprint (\"Recall : %s\" % \"{0:.3%}\".format(recall))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}