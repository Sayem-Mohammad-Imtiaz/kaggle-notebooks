{"cells":[{"metadata":{},"cell_type":"markdown","source":"Лабораторная работа 2.\n\nРеализовать обучения моделей и предсказание с их помощью в задаче классификации. \nДля каждой модели необходимо реализовать две функции trainNAME и predictNAME, где NAME имя модели. Данные функции имеют следующии сигнатуры: model = trainNAME(X, Y, ...{other params}...), predictNAME(model, X), где {other params} – это параметры определяемые студентом, включающие все используемые в модели константы, model – обученная модель, возвращаемая первой функцией. \nФункция предсказания должна возвращать вероятность класса 1. Все модели реализуются самостоятельно студентами, без использования библиотеки sklearn и подобных. \n\nВ рамках лабораторной работы требуется реализовать: \n- Дерево решений (разбиение происходит на основании энтропийного критерия, предсказания внутри листа дерева – константное, критерий остановки – величина листа и глубина дерева) \n- Случайный лес (внутренняя модель – дерево решений) \n- Градиентный бустинг (внутреняя модель – дерево решений, псевдо-остатки считаются из логистической функции потерь «logistic loss», длина шага – константа, предсказание должно использовать logit преобразование) \n\nИнструкции по работе с лабой: \n1. Написать функции trainRND и predictRND для построния модели, возвращающуюся случайной вероятность принадлежности к классу 1 для каждой точки тестовой выборки. \n2. Подобрать выборку данных для задачи классификации на два класса (каждого класса не менее 20%, выборка содержит не менее 500 наблюдений). Разбить выборку данных на обучающую и тестовую выборку в пропорции 80:20.\n3. Обучить на обучающей выборке и предсказать на тестовой выборке зависимую переменную с помощью случайной модели. Построить ROC-кривую для этой модели. \n4. Написать функции trainNAME и predictNAME для каждой из моделей \n5. Добавить ROC-кривые для каждой из моделей на тестовой выборке."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Импорт:\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, roc_curve, accuracy_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Загрузим:\ndf = pd.read_csv('../input/housesalesprediction/kc_house_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Подготовка показателей:\ndf['age'] = 2020 - df['yr_built']\ndf['is_renovated'] = (df['yr_renovated'] != 0).astype(int) #был сделан капитальный ремонт\ndf['pricy'] = (df['price'] > 500000).astype(int)\n\n#x и y:\nfeatures = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n            'floors', 'waterfront', 'view', 'condition', 'grade',\n            'sqft_above', 'sqft_basement', 'age', 'is_renovated']\nx = df[features]\ny = df['pricy']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Дерево решений:\ntree = DecisionTreeClassifier()\ntree.fit(x_train, y_train)\ny_predicted_tree = tree.predict(x_test)\n#tree_mse = mean_absolute_error(y_predicted_tree, y_test)\ntree_acc = accuracy_score(y_test, y_predicted_tree)\nprint(f'Дерево решений (точность): {tree_acc:.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Случайный лес:\nforest = RandomForestClassifier(criterion = 'entropy')\nforest.fit(x_train, y_train)\ny_predicted_forest = forest.predict(x_test)\nforest_acc = accuracy_score(y_test, y_predicted_forest)\nprint(f'Случайный лес (точность): {forest_acc:.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Градиентный бустинг:\ngradient = GradientBoostingClassifier(max_depth=4, n_estimators=200)\ngradient.fit(x_train, y_train)\ny_predicted_gradient = gradient.predict(x_test)\ngradient_acc = accuracy_score(y_test, y_predicted_gradient)\nprint(f'Градиентный бустинг (точность): {gradient_acc:.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC-кривые:\ndef draw_roc_curve(y_test, y_pred_prob, name):\n    fp, tp, thresholds = roc_curve(y_test, y_pred_prob)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fp, tp)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC кривая ({name})')\n    plt.show()\n\ny_prob_tree = tree.predict_proba(x_test)[:,1]\ny_prob_forest = forest.predict_proba(x_test)[:,1]\ny_prob_gradient = gradient.predict_proba(x_test)[:,1]\n    \ndraw_roc_curve(y_test, y_prob_tree, 'дерево решений')\ndraw_roc_curve(y_test, y_prob_forest, 'случайный лес')\ndraw_roc_curve(y_test, y_prob_gradient, 'градиентный бустинг')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Экспорт дерева в .png\nfrom sklearn.tree import export_graphviz\nexport_graphviz(tree, out_file='tree.dot', feature_names = x.columns.tolist(), class_names=['Дорогой','Недорогой'],\n           rounded = True, proportion = False, precision = 0, filled = True)\n!dot -Tpng tree.dot -o tree.png \nfrom IPython.display import Image\nImage(filename = 'tree.png')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}