{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Step 1: Reading and Understanding the Data\n\nLet us first import NumPy and Pandas and read the housing dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = pd.read_csv(r'/kaggle/input/housing-simple-regression/Housing.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the head of the dataset\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inspect the various aspects of the housing dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"housing.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Visualising the Data\n\nLet's now spend some time doing what is arguably the most important step - **understanding the data**.\n- If there is some obvious multicollinearity going on, this is the first place to catch it\n- Here's where you'll also identify if some predictors directly have a strong association with the outcome variable\n\nWe'll visualise our data using `matplotlib` and `seaborn`."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualising Numeric Variables\n\nLet's make a pairplot of all the numeric variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(housing)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualising Categorical Variables\n\nAs you might have noticed, there are a few categorical variables as well. Let's make a boxplot for some of these variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.violinplot(x = 'mainroad', y = 'price', data = housing)\nplt.subplot(2,3,2)\nsns.violinplot(x = 'guestroom', y = 'price', data = housing)\nplt.subplot(2,3,3)\nsns.violinplot(x = 'basement', y = 'price', data = housing)\nplt.subplot(2,3,4)\nsns.violinplot(x = 'hotwaterheating', y = 'price', data = housing)\nplt.subplot(2,3,5)\nsns.violinplot(x = 'airconditioning', y = 'price', data = housing)\nplt.subplot(2,3,6)\nsns.violinplot(x = 'furnishingstatus', y = 'price', data = housing)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also visualise some of these categorical features parallely by using the `hue` argument. Below is the plot for `furnishingstatus` with `airconditioning` as the hue."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 5))\nsns.violinplot(x = 'furnishingstatus', y = 'price', hue = 'airconditioning', data = housing)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"- You can see that your dataset has many columns with values as 'Yes' or 'No'.\n\n- But in order to fit a regression line, we would need numerical values and not string. Hence, we need to convert them to 1s and 0s, where 1 is a 'Yes' and 0 is a 'No'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of variables to map\n\nvarlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'yes': 1, \"no\": 0})\n\n# Applying the function to the housing list\nhousing[varlist] = housing[varlist].apply(binary_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the housing dataframe now\n\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dummy Variables"},{"metadata":{},"cell_type":"markdown","source":"The variable `furnishingstatus` has three levels. We need to convert these levels into integer as well. \n\nFor this, we will use something called `dummy variables`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the dummy variables for the feature 'furnishingstatus' and store it in a new variable - 'status'\nstatus = pd.get_dummies(housing['furnishingstatus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check what the dataset 'status' looks like\nstatus.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, you don't need three columns. You can drop the `furnished` column, as the type of furnishing can be identified with just the last two columns where â€” \n- `00` will correspond to `furnished`\n- `01` will correspond to `unfurnished`\n- `10` will correspond to `semi-furnished`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop the first column from status df using 'drop_first = True'\n\nstatus = pd.get_dummies(housing['furnishingstatus'], drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add the results to the original housing dataframe\n\nhousing = pd.concat([housing, status], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's see the head of our dataframe.\n\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 'furnishingstatus' as we have created the dummies for it\n\nhousing.drop(['furnishingstatus'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4: Splitting the Data into Training and Testing Sets\n\nAs you know, the first basic step for regression is performing a train-test split."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(housing, train_size = 0.75, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train.pop(\"price\")\nX_train = df_train\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test.pop(\"price\")\nX_test = df_test\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Any 5 Decison Trees used in the equation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nfor i in range(5):\n    sample_tree = rf.estimators_[i]\n    fig = plt.figure(figsize=(25,20))\n    _ = tree.plot_tree(sample_tree,\n                   feature_names=X_train.columns,\n                   filled=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score_rf_train=round(r2_score(y_train, rf.predict(X_train)),2)\nprint(\"R-squared Train:\",r2_score_rf_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score_rf_test=round(r2_score(y_test, rf.predict(X_test)),2)\nprint(\"R-squared Test:\",r2_score_rf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_df = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Imp\": rf.feature_importances_})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_df.sort_values(by=\"Imp\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'max_depth': [2,3,5,10,20],\n    'min_samples_leaf': [5,10,20,50,100,200],\n    'n_estimators': [10, 25, 50, 100]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search = GridSearchCV(estimator=rf,\n                           param_grid=params,\n                           cv=4,\n                           n_jobs=-1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_best = grid_search.best_estimator_\nrf_best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nfor i in range(5):\n    sample_tree = rf_best.estimators_[i]\n    fig = plt.figure(figsize=(25,20))\n    _ = tree.plot_tree(sample_tree,\n                   feature_names=X_train.columns,\n                   filled=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score_rf_train=round(r2_score(y_train,rf_best.predict(X_train)),2)\nprint(\"R-squared Train:\",r2_score_rf_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score_rf_test=round(r2_score(y_test, rf_best.predict(X_test)),2)\nprint(\"R-squared Test:\",r2_score_rf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_best.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_df = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Imp\": rf_best.feature_importances_})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_df.sort_values(by=\"Imp\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following Features which can be used focus to predict Housing Price keeping best R2 values for test & train:\n- area\n- bathrooms\n- airconditioning\n- prefarea\n- parking\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}