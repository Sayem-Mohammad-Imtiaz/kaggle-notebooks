{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    x = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(16, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(x, acc, label='training accuracy')\n    plt.plot(x, val_acc, label='validation accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, label='training loss')\n    plt.plot(x, val_loss, label='validation loss')\n    plt.title('Loss')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_newsgroup = pd.read_csv('/kaggle/input/20-newsgroup-preprocessed/20newsgroup_preprocessed.csv', sep=';', usecols=['target', 'text_cleaned'])\ndf_newsgroup.rename(columns={'text_cleaned' : 'text'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encode classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(df_newsgroup['target'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_newsgroup['target'] = le.transform(df_newsgroup['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Divide dataset in train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_newsgroup['text'].astype(str)\ny = tf.keras.utils.to_categorical(df_newsgroup['target'], num_classes=df_newsgroup['target'].nunique())\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df_newsgroup['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenize words"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(X_train)\n\nvocab_size = len(tokenizer.word_index) + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text to sentence"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_seq = tokenizer.texts_to_sequences(X_train)\ntest_seq = tokenizer.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Padding"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length = len(max(train_seq, key=len))\n\ntrain_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seq, maxlen=max_length, padding='post', truncating='post')\ntest_vector = tf.keras.preprocessing.sequence.pad_sequences(test_seq, maxlen=max_length, padding='post', truncating='post')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class StopTrainOnHighAccuracy(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        acc_threshold = 0.9\n        if logs.get('accuracy') > acc_threshold:\n            print(f\"\\nReached {acc_threshold} accuracy, cancelling training\")\n            self.model.stop_training = True\n\ndef model(vocab_size, max_length):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Embedding(vocab_size, 64, input_length=max_length),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(20, activation='softmax')\n    ])\n    \n    return model\n    \nmodel = model(vocab_size, max_length)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_vector, y_train, epochs=10, validation_data=(test_vector, y_test), callbacks=[StopTrainOnHighAccuracy()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(train_vector, y_train, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\n\nloss, accuracy = model.evaluate(test_vector, y_test, verbose=False)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(test_vector)\nground_truth = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_precision = []\nlist_recall = []\nlist_f1 = []\nfor precision, target_class in zip(precision_score(ground_truth, predictions, labels=le.transform(le.classes_), average=None), le.classes_):\n    list_precision.append({'target' : target_class, 'precision' : precision})\n    \nfor recall in recall_score(ground_truth, predictions, labels=le.transform(le.classes_), average=None):\n    list_recall.append(recall)\n    \nfor recall in f1_score(ground_truth, predictions, labels=le.transform(le.classes_), average=None):\n    list_f1.append(recall)\n        \ndf_metrics = pd.DataFrame(list_precision)\ndf_metrics['recall'] = list_recall\ndf_metrics['f1_score'] = list_f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_metrics = round(df_metrics, 2)\ndf_metrics.sort_values('f1_score', ascending=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}