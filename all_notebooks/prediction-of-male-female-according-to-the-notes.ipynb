{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Prediction Of Male - Female According To The Notes\n1. [Data Editing](#data_editing)\n2. [KNN Algorithm](#knn)\n    - [Train Test Split](#knn_train_test_split)\n    - [KNN Model](#knn_model)\n    - [Find K Value](#knn_find_k)\n    - [Accuracy](#knn_accuracy)\n3. [Support Vector Machine (SVM)](#svm)\n4. [Naive Bayes Classification](#nbc)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Editing <a id=\"data_editing\"></a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Here I will make the forecast based on the grades they received. Therefore, I do not need any data other than notes. That's why I delete those columns.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop([\"race/ethnicity\",\"parental level of education\",\"lunch\",\"test preparation course\"],axis=1) # axis = 1 => for columns\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If there is a line with a null value, let's delete it.\ndata = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Since I am guessing, I equate girls in the gender column to 0 and boys to 1.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# male = 0 | female = 1\nprint(\"gender: \", data.gender.value_counts())\ndata[\"gender\"] = [ 0 if each == \"male\" else 1 for each in data.gender]\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(data[data[\"gender\"] == 1][\"writing score\"],data[data[\"gender\"] == 1][\"reading score\"],color=\"blue\",label=\"famale\",alpha= 0.3)\nplt.scatter(data[data[\"gender\"] == 0][\"writing score\"],data[data[\"gender\"] == 0][\"reading score\"],color=\"red\",label=\"male\",alpha= 0.3)\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"texture_mean\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN Algorithm <a id=\"knn\"></a>\n> * In pattern recognition, the k-nearest neighbors algorithm is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. <br>\n> * You can read [this article](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761) for more information.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(url=\"https://i.ibb.co/KL2vG7W/knn2.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.gender.values\nx_data = data.drop([\"gender\"],axis=1)\nx_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\nx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split <a id=\"knn_train_test_split\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n\nprint(\"x_train\",x_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN MODEL <a id=\"knn_model\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(x_train,y_train)\n\nprediction = knn.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} nn score: {} \".format(5,knn.score(x_test,y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find K Value <a id=\"knn_find_k\"></a>\n> We can follow a method like the one below to find the appropriate n_neighbors value."},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = []\n\nfor each in range(20,40):\n    knn2 = KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(20,40),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen, the max point is the value 30. So the most optimal value is 30."},{"metadata":{},"cell_type":"markdown","source":"## KNN Algorithm Accuracy <a id=\"knn_accuracy\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=30)\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\n\nprint(\"{} KNN Score: {} \".format(30,knn.score(x_test,y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine (SVM) <a id=\"svm\"></a>\n> * A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems. After giving an SVM model sets of labeled training data for each category, they're able to categorize new text. So you're working on a text classification problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.gender.values\nx_data = data.drop([\"gender\"],axis=1)\n\n# normalization\nx = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\n\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=42)\nsvm.fit(x_train,y_train)\n\nprint(\"Accuracy of SVM Algo: \", svm.score(x_test,y_test)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Classification <a id=\"nbc\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(url=\"https://i.ibb.co/YpP7JY1/1-39-U1-Ln3t-Sd-Fqsf-Qy6ndx-OA.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.gender.values\nx_data = data.drop([\"gender\"],axis=1)\n\n# normalization\nx = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\n\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprint(\"Accuracy of Naive Bayes Algo:\",nb.score(x_test,y_test)*100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}