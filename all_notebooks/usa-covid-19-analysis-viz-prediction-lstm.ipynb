{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font face = \"Verdana\" size =\"6\">Analysis the spreading of COVID-19 in USA. </font>\n<br>\n\n<h1 id=\"Corona-Virus\">Corona Virus</h1>\n<ul>\n<li>Coronaviruses are <strong>zoonotic</strong> viruses (means transmitted between animals and people).  </li>\n<li>Symptoms include from fever, cough, respiratory symptoms, and breathing difficulties. </li>\n<li>In severe cases, it can cause pneumonia, severe acute respiratory syndrome (SARS), kidney failure and even death.</li>\n<li>Coronaviruses are also <strong>asymptomatic</strong>, means a person can be a carrier for the infection but experiences no symptoms</li>\n</ul>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n<font face = \"Verdana\" size =\"4\">\n    <br>Data: <a href='https://github.com/CSSEGISandData/COVID-19'>https://github.com/CSSEGISandData/COVID-19</a>\n    <br>Learn more from the <a href='https://www.who.int/emergencies/diseases/novel-coronavirus-2019'>WHO</a>\n    <br>Learn more from the <a href='https://www.cdc.gov/coronavirus/2019-ncov'>CDC</a>\n    <br>Map Visualizations from  <a href='https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6'>Johns Hopkins</a>   \n   <br>\n      Feel free to provide me with feedbacks. \n    <br> Last update: 07/07/2020 02:32 PM  \n    <br>\n    </font>\n   \n    \n <font face = \"Verdana\" size =\"1\">\n<center><img src='https://ichef.bbci.co.uk/images/ic/720x405/p086qbqx.jpg'>\n Source: https://ichef.bbci.co.uk/images/ic/720x405/p086qbqx.jpg </center> \n    \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Imports and Datasets\n<hr> \n* Pandas - for dataset handeling\n* Numpy - Support for Pandas and calculations \n* Matplotlib - for visualization (Platting graphas)\n* pycountry_convert - Library for getting continent (name) to from their country names\n* folium - Library for Map\n* keras - Prediction Models\n* plotly - for interative plots","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install pycountry-convert\n# ! pip install calmap\n# ! pip install -Uq watermark","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import torch\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport matplotlib.colors as mcolors\nfrom matplotlib import ticker \nimport pycountry_convert as pc\nimport folium\nimport branca\nfrom datetime import datetime, timedelta,date\nfrom scipy.interpolate import make_interp_spline, BSpline\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pylab import rcParams\n\nfrom matplotlib import rc\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pandas.plotting import register_matplotlib_converters\nfrom torch import nn, optim\n\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.graph_objs as gos\nfrom plotly.subplots import make_subplots\nimport matplotlib.colors as mcolors\nimport json, requests\n# import calmap\nimport operator \nimport folium\n\nfrom keras.layers import Input, Dense, Activation, LeakyReLU\nfrom keras import models\nfrom fbprophet import Prophet\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly, add_changepoints_to_plot\nfrom keras.optimizers import RMSprop, Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 14, 10\nregister_matplotlib_converters()\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Import Data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\ndeaths_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\nrecoveries_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\nlastupdate_data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/07-07-2020.csv')\nlatest_data = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_time.csv\",parse_dates=['Last_Update'])\nCountry_df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Read Top 2 Rows of latest_data \nlatest_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Read Top 2 Rows of deaths_df \ndeaths_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Read Top 2 Rows of deaths_df \nrecoveries_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Read Top 2 Rows of lastupdate_data\nlastupdate_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Read Top 2 Rows of confirmed_df \nconfirmed_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Read Top 2 Rows of Country_df \nCountry_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Rename Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_df = confirmed_df.rename(columns={\"Province/State\":\"state\",\"Country/Region\": \"country\"})\ndeaths_df = deaths_df.rename(columns={\"Province/State\":\"state\",\"Country/Region\": \"country\"})\nrecoveries_df = recoveries_df.rename(columns={\"Province/State\":\"state\",\"Country/Region\": \"country\"})\nCountry_df = Country_df.rename(columns={\"Country_Region\": \"country\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the conuntry names as required by pycountry_convert Lib\nconfirmed_df.loc[confirmed_df['country'] == \"US\", \"country\"] = \"USA\"\ndeaths_df.loc[deaths_df['country'] == \"US\", \"country\"] = \"USA\"\nCountry_df.loc[Country_df['country'] == \"US\", \"country\"] = \"USA\"\nrecoveries_df.loc[recoveries_df['country'] == \"US\", \"country\"] = \"USA\"\nlatest_data.loc[latest_data['Country_Region'] == \"US\", \"Country_Region\"] = \"USA\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dates1 = confirmed_df.columns[4:]\n\nconfirmed_df1 = confirmed_df.melt(id_vars=['state', 'country', 'Lat', 'Long'], \n                            value_vars=dates1, var_name='Date', value_name='Confirmed')\n\ndeaths_df1 = deaths_df.melt(id_vars=['state', 'country', 'Lat', 'Long'], \n                            value_vars=dates1, var_name='Date', value_name='Deaths')\n\nrecoveries_df1 = recoveries_df.melt(id_vars=['state', 'country', 'Lat', 'Long'], \n                            value_vars=dates1, var_name='Date', value_name='Recovered')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# getting all countries\ncountries = np.asarray(confirmed_df[\"country\"])\ncountries1 = np.asarray(Country_df[\"country\"])\n\n# Continent_code to Continent_names\ncontinents = {\n    'NA': 'North America',\n    'SA': 'South America', \n    'AS': 'Asia',\n    'OC': 'Australia',\n    'AF': 'Africa',\n    'EU' : 'Europe',\n    'na' : 'Others'\n}\n\n# Defininng Function for getting continent code for country.\ndef country_to_continent_code(country):\n    try:\n        return pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(country))\n    except :\n        return 'na'\n\n#Collecting Continent Information\nconfirmed_df.insert(2,\"continent\", [continents[country_to_continent_code(country)] for country in countries[:]])\ndeaths_df.insert(2,\"continent\",  [continents[country_to_continent_code(country)] for country in countries[:]])\nCountry_df.insert(1,\"continent\",  [continents[country_to_continent_code(country)] for country in countries1[:]])\nlatest_data.insert(1,\"continent\",  [continents[country_to_continent_code(country)] for country in latest_data[\"Country_Region\"].values])\n#recoveries_df.insert(2,\"continent\",  [continents[country_to_continent_code(country)] for country in countries[:]] )  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handaling Missing data\nconfirmed_df = confirmed_df.replace(np.nan, '', regex=True)\ndeaths_df = deaths_df.replace(np.nan, '', regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"Full_data = pd.merge(left=confirmed_df1, right=deaths_df1, how='left',\n                      on=['state', 'country', 'Date', 'Lat', 'Long'])\nFull_data = pd.merge(left=Full_data, right=recoveries_df1, how='left',\n                      on=['state', 'country', 'Date', 'Lat', 'Long'])\n# Active Case = confirmed - deaths - recovered\nFull_data['Active'] = Full_data['Confirmed'] - Full_data['Deaths'] - Full_data['Recovered']\nFull_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Handaling Missing data\nFull_data=Full_data.dropna(subset=['Long'])\nFull_data=Full_data.dropna(subset=['Lat'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# latest condensed\n#latest_grouped = lastupdate_data.groupby('Country_Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\nlatest_grouped = Country_df.groupby('country')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cols = confirmed_df.keys()\nconfirmed = confirmed_df.loc[:, cols[4]:cols[-1]]\ndeaths = deaths_df.loc[:, cols[4]:cols[-1]]\nrecoveries = recoveries_df.loc[:, cols[4]:cols[-1]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Get all the dates for the outbreak","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dates = confirmed.keys()\nworld_cases = []\ntotal_deaths = [] \nmortality_rate = []\nrecovery_rate = [] \ntotal_recovered = [] \ntotal_active = [] \nchina_cases = [] \nitaly_cases = []\nusa_cases = [] \nspain_cases = [] \n\nfor i in dates:\n    confirmed_sum = confirmed[i].sum()\n    death_sum = deaths[i].sum()\n    recovered_sum = recoveries[i].sum()\n    \n    # confirmed, deaths, recovered, and active\n    world_cases.append(confirmed_sum)\n    total_deaths.append(death_sum)\n    total_recovered.append(recovered_sum)\n    total_active.append(confirmed_sum-death_sum-recovered_sum)\n    \n    # calculate rates\n    mortality_rate.append(death_sum/confirmed_sum)\n    recovery_rate.append(recovered_sum/confirmed_sum)\n\n    # case studies \n    china_cases.append(confirmed_df[confirmed_df['country']=='China'][i].sum())\n    italy_cases.append(confirmed_df[confirmed_df['country']=='Italy'][i].sum())\n    usa_cases.append(confirmed_df[confirmed_df['country']=='USA'][i].sum())\n    spain_cases.append(confirmed_df[confirmed_df['country']=='Spain'][i].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Getting daily increases","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def daily_increase(data):\n    d = [] \n    for i in range(len(data)):\n        if i == 0:\n            d.append(data[0])\n        else:\n            d.append(data[i]-data[i-1])\n    return d \n\nworld_daily_increase = daily_increase(world_cases)\nchina_daily_increase = daily_increase(china_cases)\nitaly_daily_increase = daily_increase(italy_cases)\nusa_daily_increase = daily_increase(usa_cases)\nspain_daily_increase = daily_increase(spain_cases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"days_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1)\nworld_cases = np.array(world_cases).reshape(-1, 1)\ntotal_deaths = np.array(total_deaths).reshape(-1, 1)\ntotal_recovered = np.array(total_recovered).reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function to plot data.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Cases over time\ndef scatterPlotCasesOverTime(df, country):\n    plot = make_subplots(rows=2, cols=2, subplot_titles=(\"Comfirmed\", \"Deaths\", \"Recovered\", \"Active\"))\n\n    subPlot1 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Confirmed'],\n                    name=\"Confirmed\",\n                    line_color='orange',\n                    opacity=0.8)\n\n    subPlot2 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Deaths'],\n                    name=\"Deaths\",\n                    line_color='red',\n                    opacity=0.8)\n\n    subPlot3 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Recovered'],\n                    name=\"Recovered\",\n                    line_color='green',\n                    opacity=0.8)\n    \n    subPlot4 = gos.Scatter(\n                    x=df['Date'],\n                    y=df['Active'],\n                    name=\"Active\",\n                    line_color='blue',\n                    opacity=0.8)\n\n    plot.append_trace(subPlot1, 1, 1)\n    plot.append_trace(subPlot2, 1, 2)\n    plot.append_trace(subPlot3, 2, 1)\n    plot.append_trace(subPlot4, 2, 2)\n    plot.update_layout(template=\"ggplot2\", title_text = country + '<b> - Spread of the nCov Over Time</b>')\n\n    plot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Future forcasting\ndays_in_future = 10\nfuture_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forcast[:-10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis of Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Global Reported Cases till Date\nTotal number of confirmed cases, deaths reported, revoveries and active cases all across the world","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countries_cases = Country_df.copy().drop(['Lat','Long_','continent','Last_Update'],axis =1)\ndf_countries_cases.index = df_countries_cases[\"country\"]\ndf_countries_cases = df_countries_cases.drop(['country'],axis=1)\n\ndf_continents_cases = Country_df.copy().drop(['Lat','Long_','country','Last_Update'],axis =1)\ndf_continents_cases = df_continents_cases.groupby([\"continent\"]).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t = pd.DataFrame(pd.to_numeric(df_countries_cases.sum()),dtype=np.float64).transpose()\ndf_t[\"Mortality Rate (per 100)\"] = np.round(100*df_t[\"Deaths\"]/df_t[\"Confirmed\"],2)\ndf_t.style.background_gradient(cmap='Wistia',axis=1).format(\"{:.0f}\",subset=[\"Confirmed\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Country Wise Reported Cases\n#### Country Wise reported confirmed cases, recovered cases, deaths, active cases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For each single countries\nunique_countries =  list(Country_df['country'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"country_confirmed_cases = []\ncountry_death_cases = [] \ncountry_recovery_cases = []\ncountry_active_cases = []\ncountry_mortality_rate = [] \n\n\nno_cases = []\nfor i in unique_countries:\n    cases = Country_df[Country_df['country']==i]['Confirmed'].sum()\n    if cases > 0:\n        country_confirmed_cases.append(cases)\n    else:\n        no_cases.append(i)\n        \nfor i in no_cases:\n    unique_countries.remove(i)\n# sort countries by the number of confirmed cases\nunique_countries = [k for k, v in sorted(zip(unique_countries, country_confirmed_cases), key=operator.itemgetter(1), reverse=True)]\nfor i in range(len(unique_countries)):\n    country_confirmed_cases[i] = Country_df[Country_df['country']==unique_countries[i]]['Confirmed'].sum()\n    country_death_cases.append(Country_df[Country_df['country']==unique_countries[i]]['Deaths'].sum())\n    country_recovery_cases.append(Country_df[Country_df['country']==unique_countries[i]]['Recovered'].sum())\n    country_active_cases.append(Country_df[Country_df['country']==unique_countries[i]]['Active'].sum())\n    country_mortality_rate.append((country_death_cases[i]/country_confirmed_cases[i])*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_df = pd.DataFrame({'Country Name': unique_countries, 'Number of Confirmed Cases': country_confirmed_cases,\n                          'Number of Deaths': country_death_cases, 'Number of Recoveries' : country_recovery_cases,\n                           'Number of Active': country_active_cases, 'Mortality Rate': country_mortality_rate})\n\n# number of cases per country/region\ncountry_df.style.background_gradient(cmap=\"Wistia\", subset=['Number of Confirmed Cases'])\\\n                .background_gradient(cmap=\"Reds\", subset=['Number of Deaths'])\\\n                .background_gradient(cmap=\"summer\", subset=['Number of Recoveries'])\\\n                .background_gradient(cmap=\"OrRd\", subset=['Number of Active'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Graphical Analysis \n\n### Graphing the number of confirmed cases, active cases, deaths, recoveries, mortality rate, and recovery rate","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 1. No. of Coronavirus Cases Over Time","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"adjusted_dates = adjusted_dates.reshape(1, -1)[0]\nplt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, world_cases)\nplt.title('No. of Coronavirus Cases Over Time', size=25)\nplt.xlabel('Days Since 1/22/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. World Daily Increases in Confirmed Cases","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, world_daily_increase)\nplt.title('World Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1/22/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. World Daily Increases in Confirmed Cases","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, world_cases, color='b')\nplt.plot(adjusted_dates, total_deaths, color='r')\nplt.plot(adjusted_dates, total_recovered, color='green')\nplt.title('No. of Coronavirus Total cases vs Death cases vs Recovered Cases', size=25)\nplt.legend(['Cases','Death','Recoveries' ], loc='best', fontsize=20)\nplt.xlabel('Days Since 1/22/2020', size=30)\nplt.ylabel('No. of Cases', size=30)\nplt.xticks(size=20)\nplt.yticks(size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Mortality Rate of Coronavirus Over Time","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mean_mortality_rate = np.mean(mortality_rate)\nplt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, mortality_rate, color='orange')\nplt.axhline(y = mean_mortality_rate,linestyle='--', color='black')\nplt.title('Mortality Rate of Coronavirus Over Time', size=30)\nplt.legend(['mortality rate', 'y='+str(mean_mortality_rate)], prop={'size': 20})\nplt.xlabel('Days Since 1/22/2020', size=30)\nplt.ylabel('Mortality Rate', size=30)\nplt.xticks(size=20)\nplt.yticks(size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 10 countries (Confirmed Cases and Deaths)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Lets look at the Confirmed status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countries_cases.groupby('country')['Confirmed'].sum().sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\nout = \"\"\nplt.axes(axisbelow=True)\nplt.barh(df_countries_cases.sort_values('Confirmed')[\"Confirmed\"].index[-10:],df_countries_cases.sort_values('Confirmed')[\"Confirmed\"].values[-10:],color=\"deepskyblue\")\n#color=\"darkcyan\"\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Confirmed Cases\",fontsize=18)\nplt.title(\"Top 10 Countries Under Corona Confirmed Cases\",fontsize=20)\nplt.grid(alpha=0.3)\nplt.savefig(out+'Top 10 Countries (Confirmed Cases).png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Provinces where deaths have taken place","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countries_cases.groupby('country')['Deaths'].sum().sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_countries_cases.sort_values('Deaths')[\"Deaths\"].index[-10:],df_countries_cases.sort_values('Deaths')[\"Deaths\"].values[-10:],color=\"crimson\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Deaths Cases\",fontsize=18)\nplt.title(\"Top 10 Countries Under Corona Deaths Cases\",fontsize=20)\nplt.grid(alpha=0.3,which='both')\nplt.savefig(out+'Top 10 Countries (Deaths Cases).png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets also look at the Recovered status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countries_cases.groupby('country')['Recovered'].sum().sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_countries_cases.sort_values('Recovered')[\"Recovered\"].index[-10:],df_countries_cases.sort_values('Recovered')[\"Recovered\"].values[-10:],color=\"yellowgreen\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Recovered Cases\",fontsize=18)\nplt.title(\"Top 10 Countries Under Corona Recovered Cases\",fontsize=20)\nplt.grid(alpha=0.3,which='both')\nplt.savefig(out+'Top 10 Countries (Recovered Cases).png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Country Base Case Analysis\n#### 1.United State","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, usa_daily_increase)\nplt.title('US Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1/22/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. China","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, china_daily_increase)\nplt.title('China Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1/22/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Italy","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, italy_daily_increase)\nplt.title('Italy Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1/22/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Spain","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.bar(adjusted_dates, spain_daily_increase)\nplt.title('Spain Daily Increases in Confirmed Cases', size=25)\nplt.xlabel('Days Since 1/22/2020', size=25)\nplt.ylabel('No. of Cases', size=25)\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Coronavirus Cases for above four infected countries ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.plot(adjusted_dates, usa_cases)\nplt.plot(adjusted_dates, china_cases)\nplt.plot(adjusted_dates, italy_cases)\nplt.plot(adjusted_dates, spain_cases)\nplt.title('No. of Coronavirus Cases', size=25)\nplt.xlabel('Days Since 1/22/2020', size=22)\nplt.ylabel('No. of Cases', size=25)\nplt.legend(['US', 'China', 'Italy', 'Spain'], prop={'size': 20})\nplt.xticks(size=20)\nplt.yticks(size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization on Map","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Confirmed\nfig = px.choropleth(latest_grouped, locations=\"country\", \n                    locationmode='country names', color=np.log(latest_grouped[\"Confirmed\"]), \n                    hover_name=\"country\", hover_data=['Confirmed'],\n                    color_continuous_scale=\"Sunsetdark\", \n                    title='Countries with Confirmed Cases')\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Deaths\ntemp = latest_grouped[latest_grouped['Deaths']>0]\nfig = px.choropleth(temp, \n                    locations=\"country\", locationmode='country names',\n                    color=np.log(temp[\"Deaths\"]), hover_name=\"country\", \n                    color_continuous_scale=\"Peach\", hover_data=['Deaths'],\n                    title='Countries with Deaths Reported')\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"formated_gdf = Full_data.groupby(['Date', 'country'])['Confirmed', 'Deaths'].max().reset_index()\nformated_gdf['size'] = formated_gdf['Confirmed'].pow(0.2)\n\nfig = px.scatter_geo(formated_gdf, locations=\"country\", locationmode='country names', \n                     color=\"Confirmed\", size='size', hover_name=\"country\", \n                     range_color= [0, max(formated_gdf['Confirmed'])+2], animation_frame=\"Date\", \n                     title='Spread over time')\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"'''\n# World wide\n\nm = folium.Map(location=[0, 0], tiles='cartodbpositron',\n               min_zoom=1, max_zoom=4, zoom_start=1)\n\nfor i in range(0, len(Full_data)):\n    folium.Circle(\n        location=[Full_data.iloc[i]['Lat'], Full_data.iloc[i]['Long']],\n        color='crimson', \n        tooltip =   '<li><bold>Country : '+str(Full_data.iloc[i]['country'])+\n                    '<li><bold>Province : '+str(Full_data.iloc[i]['state'])+\n                    '<li><bold>Confirmed : '+str(Full_data.iloc[i]['Confirmed'])+\n                    '<li><bold>Deaths : '+str(Full_data.iloc[i]['Deaths']),\n        radius=int(Full_data.iloc[i]['Confirmed'])**1.1).add_to(m)\nm\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## COVID-19 : USA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa = lastupdate_data.loc[lastupdate_data[\"Country_Region\"]== \"US\"]\ndf_usa.head(2)\n#df_usa = df_usa.rename(columns={\"Admin2\":\"County\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_usa.sum()\ntotal.name = \"Total\"\npd.DataFrame(total).transpose().loc[:,[\"Confirmed\",\"Deaths\"]].style.background_gradient(cmap='Purples',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa.loc[:,[\"Confirmed\",\"Deaths\",\"Province_State\"]].groupby([\"Province_State\"]).sum().sort_values(\"Confirmed\",ascending=False).style.background_gradient(cmap='Blues',subset=[\"Confirmed\"]).background_gradient(cmap='Reds',subset=[\"Deaths\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Most Affected States: USA","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_usa.groupby([\"Province_State\"]).sum().sort_values('Confirmed')[\"Confirmed\"].index[-10:],df_usa.groupby([\"Province_State\"]).sum().sort_values('Confirmed')[\"Confirmed\"].values[-10:],color=\"salmon\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Confirmed Cases\",fontsize=18)\nplt.title(\"Top 10 States: USA (Confirmed Cases)\",fontsize=20)\nplt.grid(alpha=0.3)\nplt.savefig(out+'Top 10 States_USA (Confirmed Cases).png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f = plt.figure(figsize=(10,5))\nf.add_subplot(111)\n\nplt.axes(axisbelow=True)\nplt.barh(df_usa.groupby([\"Province_State\"]).sum().sort_values('Deaths')[\"Deaths\"].index[-10:],df_usa.groupby([\"Province_State\"]).sum().sort_values('Deaths')[\"Deaths\"].values[-10:],color=\"crimson\")\nplt.tick_params(size=5,labelsize = 13)\nplt.xlabel(\"Deaths\",fontsize=18)\nplt.title(\"Top 10 States: USA (Deaths Cases)\",fontsize=20)\nplt.grid(alpha=0.3)\nplt.savefig(out+'Top 10 States_USA (Deaths Cases).png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"Full_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa_data = Full_data.loc[Full_data[\"country\"]== \"USA\"]\n#df_usa_data['Last_Update'] =  pd.to_datetime(df_usa_data['Last_Update'])\n#df_usa_data['Last_Update'] = df_usa_data['Last_Update'].dt.date\n#df_usa_data = df_usa_data.rename(columns={\"Last_Update\":\"Date\"})\ndf1 =  df_usa_data[['Date','Confirmed','Deaths','Recovered','Active']]\ndf1.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# USA - Cases over time\nscatterPlotCasesOverTime(df1, \"<b>USA</b>\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization on US Map","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_usa = df_usa.rename(columns={\"Admin2\":\"County\"})\ndf_usa = df_usa.replace(np.nan, 0, regex=True)\nusa = folium.Map(location=[37, -102], tiles='cartodbpositron', min_zoom=4, max_zoom=8, zoom_start=4)\nfor i in np.int32(np.asarray(df_usa[df_usa['Confirmed'] > 0].index)):\n    folium.Circle(\n        location=[df_usa.loc[i]['Lat'], df_usa.loc[i]['Long_']],\n        tooltip = \"<h5 style='text-align:center;font-weight: bold'>\"+df_usa.loc[i]['Province_State']+\"</h5>\"+\n                    \"<div style='text-align:center;'>\"+str(np.nan_to_num(df_usa.loc[i]['County']))+\"</div>\"+\n                    \"<hr style='margin:10px;'>\"+\n                    \"<ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n        \"<li>Confirmed: \"+str(df_usa.loc[i]['Confirmed'])+\n        \"<li>Active:   \"+str(df_usa.loc[i]['Active'])+\n        \"<li>Recovered:   \"+str(df_usa.loc[i]['Recovered'])+     \n        \"<li>Deaths:   \"+str(df_usa.loc[i]['Deaths'])+\n        \"<li>Mortality Rate:   \"+str(np.round(df_usa.loc[i]['Deaths']/(df_usa.loc[i]['Confirmed']+1)*100,2))\n\n        ,\n        radius=int((np.log2(df_usa.loc[i]['Confirmed']+1))*6000),\n        color='yellowgreen',\n        fill_color='red',\n        fill=True).add_to(usa)\n\nusa\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_geo = requests.get('https://raw.githubusercontent.com/python-visualization/folium/master/examples/data/us-states.json').json()\ncounty_geo = requests.get('https://raw.githubusercontent.com/python-visualization/folium/master/examples/data/us_counties_20m_topo.json').json()\n# county_geo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Affected Counties : USA","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# binsurl = 'https://raw.githubusercontent.com/python-visualization/folium/master/examples/data'\n# county_data = f'{url}/us_county_data.csv'\n# county_geo = f'{url}/us_counties_20m_topo.json'\n\ndata_temp = df_usa.groupby([\"FIPS\"]).sum().reset_index().drop([\"Lat\",\"Long_\"],axis=1)\ndata_temp[\"Confirmed_log\"] = np.log10(data_temp[\"Confirmed\"]+1)\n\ndf_usa_series = data_temp.set_index('FIPS')['Confirmed_log']\ncolorscale = branca.colormap.linear.Reds_09.scale(0,data_temp[\"Confirmed_log\"].max()-1)\n# print(df_usa_series.max())\ndef style_function(feature):\n    employed = df_usa_series.get(int(feature['id'][-5:]), 0)\n    return {\n        'fillOpacity': 0.5,\n        'weight': 0,\n        'fillColor': '#black' if employed is None else colorscale(employed)\n    }\n\n\nm = folium.Map(\n    location=[37, -102],\n    tiles='cartodbpositron',\n    zoom_start=4,\n    min_zoom=3,\n    max_zoom=7\n)\n\nfolium.TopoJson(\n    county_geo,\n    'objects.us_counties_20m',\n    style_function=style_function\n).add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction Curve for USA\n# 1. Prophet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa1 = confirmed_df.loc[confirmed_df[\"country\"]== \"USA\"]\ndf_usa1.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_usa1.melt(value_vars=dates1, var_name='Date', value_name='Confirmed')\ntemp = temp.groupby('Date')['Confirmed'].sum().reset_index()\n#Full_data[['Date','Confirmed']]\npr_data = pd.DataFrame(temp)\n\npr_data.columns = ['ds','y']\npr_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=Prophet()\nm.fit(temp)\nfuture=m.make_future_dataframe(periods=10)\nforecast=m.predict(future)\nforecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnfrm = forecast.loc[:,['ds','trend']]\ncnfrm = cnfrm[cnfrm['trend']>0]\ncnfrm=cnfrm.tail(15)\ncnfrm.columns = ['Date','Confirm']\ncnfrm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_plotly(m, forecast)\npy.iplot(fig) \n\nfig = m.plot(forecast,xlabel='Date',ylabel='Confirmed Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure=m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.LSTM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Two things to note here:\n\n* The data contains a province, country, latitude, and longitude. We won't be needing those.\n* The number of cases is cumulative. We'll undo the accumulation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa1 = df_usa1.iloc[:, 5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_usa1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases = df_usa1.sum(axis=0)\ndaily_cases.index = pd.to_datetime(daily_cases.index)\ndaily_cases.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Daily cases For USA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases)\nplt.title(\"Cumulative daily cases\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases = daily_cases.diff().fillna(daily_cases[0]).astype(np.int64)\ndaily_cases.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.plot(daily_cases)\nplt.title(\"Daily cases\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cases gradually increasing with sparks in USA. This will certainly be a challenge for our model.\n\nLet's check the amount of data we have:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n#### We'll reserve the first 60 days for training and use the rest for testing:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=daily_cases.iloc[:int(len(daily_cases)*0.8)] \ntest_data=daily_cases.iloc[int(len(daily_cases)*0.8):]\n\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to scale the data (values will be between 0 and 1) if we want to increase the training speed and performance of the model. We'll use the MinMaxScaler from scikit-learn:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(train_data, axis=1))\n\ntrain_data = scaler.transform(np.expand_dims(train_data, axis=1))\n\ntest_data = scaler.transform(np.expand_dims(test_data, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split(daily_cases):\n    size=int(len(daily_cases)*0.8)\n    # for train data will be collected from each country's data which index is from 0-size (80%)\n    x_train =daily_cases.drop(columns=['TargetValue']).iloc[0:size] \n    # for test data will be collected from each country's  data which index is from size to the end (20%)\n    x_test = daily_cases.drop(columns=['TargetValue']).iloc[size:]\n    y_train=daily_cases['TargetValue'].iloc[0:size] \n    y_test=daily_cases['TargetValue'].iloc[size:] \n    return x_train, x_test,y_train,y_test\n# unique countries\ncountry=list(set(daily_cases.country))\n# loop each station and collect train and test data \nX_train=[]\nX_test=[]\nY_train=[]\nY_test=[]\nfor i in range(0,len(country)):\n    df=data[['country']==country[i]]\n    x_train, x_test,y_train,y_test=train_test_split(df)\n    X_train.append(x_train)\n    X_test.append(x_test)\n    Y_train.append(y_train)\n    Y_test.append(y_test)\n# concat each train data from each station \nX_train=pd.concat(X_train)\nY_train=pd.DataFrame(pd.concat(Y_train))\n# concat each test data from each station \nX_test=pd.concat(X_test)\nY_test=pd.DataFrame(pd.concat(Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_sequences(data, seq_length):\n    xs = []\n    ys = []\n\n    for i in range(len(data)-seq_length-1):\n        x = data[i:(i+seq_length)]\n        y = data[i+seq_length]\n        xs.append(x)\n        ys.append(y)\n\n    return np.array(xs), np.array(ys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length = 5\nX_train, y_train = create_sequences(train_data, seq_length)\nX_test, y_test = create_sequences(test_data, seq_length)\n\nX_train = torch.from_numpy(X_train).float()\ny_train = torch.from_numpy(y_train).float()\n\nX_test = torch.from_numpy(X_test).float()\ny_test = torch.from_numpy(y_test).float()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building a model\nWe'll encapsulate the complexity of our model into a class that extends from torch.nn.Module:","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class CoronaVirusPredictor(nn.Module):\n\n  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n    super(CoronaVirusPredictor, self).__init__()\n\n    self.n_hidden = n_hidden\n    self.seq_len = seq_len\n    self.n_layers = n_layers\n\n    self.lstm = nn.LSTM(\n      input_size=n_features,\n      hidden_size=n_hidden,\n      num_layers=n_layers,\n      dropout=0.5\n    )\n\n    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n\n  def reset_hidden_state(self):\n    self.hidden = (\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n    )\n\n  def forward(self, sequences):\n    lstm_out, self.hidden = self.lstm(\n      sequences.view(len(sequences), self.seq_len, -1),\n      self.hidden\n    )\n    last_time_step = \\\n      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n    y_pred = self.linear(last_time_step)\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Our CoronaVirusPredictor contains 3 methods:\n* constructor - initialize all helper data and create the layers\n* reset_hidden_state - we'll use a stateless LSTM, so we need to reset the state after each example\n* forward - get the sequences, pass all of them through the LSTM layer, at once. We take the output of the last time step and pass it through our linear layer to get the prediction.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Training\nLet's build a helper function for the training of our model (we'll reuse it later):","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def train_model(\n  model, \n  train_data, \n  train_labels, \n  test_data=None, \n  test_labels=None\n):\n  loss_fn = torch.nn.MSELoss(reduction='sum')\n\n  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n  num_epochs = 800   # if its time consuming then set it to 500 or 100\n  train_hist = np.zeros(num_epochs)\n  test_hist = np.zeros(num_epochs)\n\n  for t in range(num_epochs):\n    model.reset_hidden_state()\n\n    y_pred = model(X_train)\n\n    loss = loss_fn(y_pred.float(), y_train)\n\n    if test_data is not None:\n      with torch.no_grad():\n        y_test_pred = model(X_test)\n        test_loss = loss_fn(y_test_pred.float(), y_test)\n      test_hist[t] = test_loss.item()\n\n      if t % 1000 == 0:  \n        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n    elif t % 1000 == 0:\n      print(f'Epoch {t} train loss: {loss.item()}')\n\n    train_hist[t] = loss.item()\n    \n    optimiser.zero_grad()\n\n    loss.backward()\n\n    optimiser.step()\n  \n  return model.eval(), train_hist, test_hist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CoronaVirusPredictor(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, train_hist, test_hist = train_model(\n  model, \n  X_train, \n  y_train, \n  X_test, \n  y_test\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_hist, label=\"Training loss\")\nplt.plot(test_hist, label=\"Test loss\")\nplt.ylim((0, 60))\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting daily cases\nUse predicted values as input for predicting the next days:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n  test_seq = X_test[:1]\n  preds = []\n  for _ in range(len(X_test)):\n    y_test_pred = model(test_seq)\n    pred = torch.flatten(y_test_pred).item()\n    preds.append(pred)\n    new_seq = test_seq.numpy().flatten()\n    new_seq = np.append(new_seq, [pred])\n    new_seq = new_seq[1:]\n    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to reverse the scaling of the test data and the model predictions:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"true_cases = scaler.inverse_transform(\n    np.expand_dims(y_test.flatten().numpy(), axis=0)\n).flatten()\n\npredicted_cases = scaler.inverse_transform(\n  np.expand_dims(preds, axis=0)\n).flatten()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the results:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(\n  daily_cases.index[:len(train_data)], \n  scaler.inverse_transform(train_data).flatten(),\n  label='Historical Daily Cases'\n)\n\nplt.plot(\n  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n  true_cases,\n  label='Real Daily Cases'\n)\n\nplt.plot(\n  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n  predicted_cases, \n  label='Predicted Daily Cases'\n)\n\nplt.legend();\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, our model doesn't perform very well. That said, the predictions seem to be in the right ballpark (probably due to using the last data point as a strong predictor for the next).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Use all data for training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(daily_cases, axis=1))\n\nall_data = scaler.transform(np.expand_dims(daily_cases, axis=1))\n\nall_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all, y_all = create_sequences(all_data, seq_length)\n\nX_all = torch.from_numpy(X_all).float()\ny_all = torch.from_numpy(y_all).float()\n\nmodel = CoronaVirusPredictor(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, train_hist, _ = train_model(model, X_all, y_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting future cases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"DAYS_TO_PREDICT = 7\n\nwith torch.no_grad():\n  test_seq = X_all[:1]\n  preds = []\n  for _ in range(DAYS_TO_PREDICT):\n    y_test_pred = model(test_seq)\n    pred = torch.flatten(y_test_pred).item()\n    preds.append(pred)\n    new_seq = test_seq.numpy().flatten()\n    new_seq = np.append(new_seq, [pred])\n    new_seq = new_seq[1:]\n    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_cases = scaler.inverse_transform(\n  np.expand_dims(preds, axis=0)\n).flatten()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To create a cool chart with the historical and predicted cases, we need to extend the date index of our data frame:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases.index[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_index = pd.date_range(\n  start=daily_cases.index[-1],\n  periods=DAYS_TO_PREDICT + 1,\n  closed='right'\n)\n\npredicted_cases = pd.Series(\n  data=predicted_cases,\n  index=predicted_index\n)\n\nplt.plot(predicted_cases, label='Predicted Daily Cases')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases, label='Historical Daily Cases')\nplt.plot(predicted_cases, label='Predicted Daily Cases')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model thinks that things will level off. Note that the more you go into the future, the more you shouldn't trust your model predictions.\n\n# Conclusion\nWell done! You learned how to use PyTorch to create a Recurrent Neural Network that works with Time Series data. The model performance is not that great, but this is expected, given the small amounts of data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## References\n\n- [Sequence Models PyTorch Tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)\n- [LSTM for time series prediction](https://towardsdatascience.com/lstm-for-time-series-prediction-de8aeb26f2ca)\n- [Time Series Prediction using LSTM with PyTorch in Python](https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/)\n- [Stateful LSTM in Keras](https://philipperemy.github.io/keras-stateful-lstm/)\n- [Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE](https://github.com/CSSEGISandData/COVID-19)\n- [covid-19-analysis](https://github.com/AaronWard/covid-19-analysis)\n- [Worldometer COVID-19 Coronavirus Outbreak](https://www.worldometers.info/coronavirus/)\n- [Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications](https://www.researchers.one/article/2020-01-21)\n- [Creating the Keras LSTM data generators](https://adventuresinmachinelearning.com/keras-lstm-tutorial/)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Your Valuable Feedback is much APPRECIATED\n\n### Please UPVOTE if you LIKE this NOTEBOOK and COMMENT for any Advice/Suggestion","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}