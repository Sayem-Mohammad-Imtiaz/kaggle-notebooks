{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Update to transformers 2.8.0\n!pip install -q transformers --upgrade\n!pip install -q pandas --upgrade\n!pip show transformers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pickle\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, average_precision_score, roc_auc_score, f1_score, accuracy_score\nimport matplotlib.pyplot as plt\nimport transformers as trfm\nfrom transformers import AutoTokenizer, TFAutoModel, TFElectraModel, ElectraTokenizer\nfrom tqdm.notebook import tqdm\nfrom tokenizers import BertWordPieceTokenizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_reranker(tokenizer, model):\n    tokenizer.enable_padding()\n    \n    def rerank(question, answers):\n        pairs = list(zip([question] * len(answers), answers))\n\n        encs = tokenizer.encode_batch(pairs)\n        input_ids = np.array([enc.ids for enc in encs])\n        scores = model.predict(input_ids).squeeze()\n\n        return scores\n    \n    return rerank","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def touch_dir(dirname):\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n        print(f\"Created directory {dirname}.\")\n    else:\n        print(f\"Directory {dirname} already exists.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512, enable_padding=False):\n    \"\"\"\n    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \n    ---\n    Inputs:\n        tokenizer: the `fast_tokenizer` that we imported from the tokenizers library\n    \"\"\"\n    tokenizer.enable_truncation(max_length=maxlen)\n    if enable_padding:\n        tokenizer.enable_padding(max_length=maxlen)\n    \n    all_ids = []\n    \n    for i in tqdm(range(0, len(texts), chunk_size)):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_qa_ids(q_ids, a_ids, tokenizer, maxlen=512):\n    \"\"\"\n    Given two arrays of IDs (questions and answers) created by\n    `fast_encode`, we combine and pad them.\n    Inputs:\n        tokenizer: The original tokenizer (not the fast_tokenizer)\n    \"\"\"\n    combined_ids = []\n\n    for i in tqdm(range(q_ids.shape[0])):\n        ids = []\n        ids.append(tokenizer.cls_token_id)\n        ids.extend(q_ids[i])\n        ids.append(tokenizer.sep_token_id)\n        ids.extend(a_ids[i])\n        ids.append(tokenizer.sep_token_id)\n        ids.extend([tokenizer.pad_token_id] * (maxlen - len(ids)))\n\n        combined_ids.append(ids)\n    \n    return np.array(combined_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_qa(questions, answers, tokenizer, maxlen=512):\n    \"\"\"\n    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \"\"\"\n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(max_length=maxlen)\n    all_ids = []\n    \n    for i in tqdm(range(0, len(questions))):\n        q = questions[i]\n        a = answers[i]\n        \n        encs = tokenizer.encode(q, a)\n        all_ids.append(encs.ids)\n        if len(encs.ids) > 512:\n            return q, a\n    \n    return np.array(all_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(transformer, max_len=None):\n    \"\"\"\n    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \"\"\"\n    input_ids = L.Input(shape=(max_len, ), dtype=tf.int32)\n    \n    x = transformer(input_ids)[0]\n    x = x[:, 0, :]\n    x = L.Dense(1, activation='sigmoid', name='sigmoid')(x)\n    \n    # BUILD AND COMPILE MODEL\n    model = Model(inputs=input_ids, outputs=x)\n    model.compile(\n        loss='binary_crossentropy', \n        metrics=['accuracy'], \n        optimizer=Adam(lr=1e-5)\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model(sigmoid_dir, transformer_dir='transformer', architecture=\"electra\", max_len=None):\n    \"\"\"\n    Special function to load a keras model that uses a transformer layer\n    \"\"\"\n    sigmoid_path = os.path.join(sigmoid_dir,'sigmoid.pickle')\n    \n    if architecture == 'electra':\n        transformer = TFElectraModel.from_pretrained(transformer_dir)\n    else:\n        transformer = TFAutoModel.from_pretrained(transformer_dir)\n    model = build_model(transformer, max_len=max_len)\n    \n    sigmoid = pickle.load(open(sigmoid_path, 'rb'))\n    model.get_layer('sigmoid').set_weights(sigmoid)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = trfm.ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\nfast_tokenizer = BertWordPieceTokenizer('/kaggle/input/healthtap-joint-electra-small/vocab.txt', lowercase=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models['electra_ht_small'] = load_model(\n    sigmoid_dir='/kaggle/input/healthtap-joint-electra-small',\n    transformer_dir='/kaggle/input/healthtap-joint-electra-small/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_ht_small'].summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models['electra_ht_base'] = load_model(\n    sigmoid_dir='/kaggle/input/healthtap-joint-electra-base',\n    transformer_dir='/kaggle/input/healthtap-joint-electra-base/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_ht_base'].summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models['electra_se_small'] = load_model(\n    sigmoid_dir='/kaggle/input/stackexchange-finetune-electra-small/transformer',\n    transformer_dir='/kaggle/input/stackexchange-finetune-electra-small/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_se_small'].summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models['electra_se_base'] = load_model(\n    sigmoid_dir='/kaggle/input/stackexchange-finetune-electra-base/transformer',\n    transformer_dir='/kaggle/input/stackexchange-finetune-electra-base/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_se_base'].summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 512\n\ndf = pd.read_csv('/kaggle/input/covidqa/news.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_ids = encode_qa(df.question.values.astype(str), df.answer.values.astype(str), fast_tokenizer, maxlen=MAX_LEN)\nwrong_ids = encode_qa(df.question.values.astype(str), df.wrong_answer.values.astype(str), fast_tokenizer, maxlen=MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_ids = np.concatenate([correct_ids, wrong_ids])\n\nlabels = np.concatenate([\n    np.ones(correct_ids.shape[0]),\n    np.zeros(correct_ids.shape[0])\n]).astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compute Scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df = pd.concat([df[['source']]]*2)\n\nfor model_name, model in models.items():\n    %time score_df[model_name] = model.predict(input_ids, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df['labels'] = labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df.to_csv('news.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compute Prediction Results"},{"metadata":{},"cell_type":"markdown","source":"### Macro-Average"},{"metadata":{"trusted":true},"cell_type":"code","source":"overall = {}\n\nfor model_name in models.keys():\n    result = {}\n    labels = score_df['labels']\n    score = score_df[model_name]\n    pred = score.round().astype(int)\n    result['ap'] = average_precision_score(labels, score).round(4)\n    result['roc_auc'] = roc_auc_score(labels, score).round(4)\n    result['f1_score'] = f1_score(labels, pred).round(4)\n    result['accuracy'] = accuracy_score(labels, pred).round(4)\n    overall[model_name] = result\n\noverall_df = pd.DataFrame(overall)\noverall_df.to_csv(\"overall_results.csv\")\noverall_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(overall_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print(overall_df.to_markdown())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## By source"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_sources = {}\n\nfor source in df.source.unique():\n    source_results = {}\n    score_source_df = score_df[score_df.source == source]\n\n    for model_name in models.keys():\n        result = {}\n        labels = score_source_df['labels']\n        score = score_source_df[model_name]\n        pred = score.round().astype(int)\n        result['ap'] = average_precision_score(labels, score).round(4)\n        result['roc_auc'] = roc_auc_score(labels, score).round(4)\n        result['f1_score'] = f1_score(labels, pred).round(4)\n        result['accuracy'] = accuracy_score(labels, pred).round(4)\n        \n        source_results[model_name] = result\n    \n    all_sources[source] = pd.DataFrame(source_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Regular output"},{"metadata":{"trusted":true},"cell_type":"code","source":"for source, sdf in all_sources.items():\n    print(source)\n    print('-'*40)\n    print(sdf)\n    print('='*40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Latex output"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"for source, sdf in all_sources.items():\n    print(source)\n    print('-'*40)\n    print(sdf.to_latex())\n    print('='*40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Markdown output"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"for source, sdf in all_sources.items():\n    print(source)\n    print('-'*40)\n    print(sdf.to_markdown())\n    print('='*40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AP Score by source"},{"metadata":{"trusted":true},"cell_type":"code","source":"ap_df = pd.DataFrame({source: sdf.loc['ap'] for source, sdf in all_sources.items()}).T\nap_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print(ap_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print(ap_df.to_markdown())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Micro Scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"micro_df = (sum(all_sources.values()) / len(all_sources)).round(4)\nmicro_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"print(micro_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print(micro_df.to_markdown())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}