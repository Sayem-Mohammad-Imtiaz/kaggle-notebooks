{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n## pip install xgboost\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#import xgboost as xgb\n\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data  = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns\ndata.drop(['id','Unnamed: 32'],axis =1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['diagnosis'].unique()\ndata['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# standard code to check for null values in columns in data\nprint(data.isnull().any())\n# show how many null values there.\nprint(data.isnull().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.neighbors import KNeighborsClassifier\n#from xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n#from sklearn.ensemble import RandomForestClassifier\n#my_first_model = RandomForestClassifier()\n#neigh.fit(samples)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n### Automated Hyper parameter Tuning\n\n\n# A parameter grid for XGBoost\n\nparamGrid = { 'learning_rate': [0.1,0.001] , 'max_depth': [4,10],'n_estimators': [500,5000]}\n\n\"\"\"\nfit_params={\"early_stopping_rounds\":100, \n            \"eval_metric\" : \"mae\", \n            \"eval_set\" : [[testX, testY]]}\n\"\"\"\n\"\"\"\ncombination 1: \nmax_depth = 4 and n_estimator = 100\ncombination 2:\nmax_depth = 4 and n_estimator = 200\ncombination 3:\nmax_depth = 5 and n_estimator = 100\ncombination 4:\nmax_depth = 5 and n_estimator = 200\ncombination 5:\nmax_depth = 6 and n_estimator = 100\nmax_depth = 6 and n_estimator = 200\n\n\"\"\"\n\n# cv = None, default 3 fold cross validation\n#my_first_model = LGBMClassifier(max_depth=4,n_estimator=100)\nmy_algo =['xgboost','lightgbm']\n\nmy_first_model = LGBMClassifier()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n### calling \n#mysearch = GridSearchCV(my_first_model, paramGrid, verbose=1 ,cv=5)\nmysearch = RandomizedSearchCV(my_first_model, paramGrid, verbose=1 ,cv=5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mysearch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(my_first_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('diagnosis',axis =1)\ny = data['diagnosis']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pass features and dependent varaible\n# fit means model training\n#my_first_model.fit(X_train, y_train)\n\nmysearch.fit(X_train,y_train)\n\n\n# predict\nprediction = mysearch.best_estimator_.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mysearch.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mysearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction = my_first_model.predict(X_test)\nprint(prediction)\nprint(len(prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix , f1_score , precision_score, recall_score\n# pass actual values , predicted values\n# Validation accuracy\naccuracy_score(y_test,prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f1_score(y_test,prediction))\nprint(precision_score(y_test,prediction))\nprint(recall_score(y_test,prediction))\nprint(accuracy_score(y_test,prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importance = my_first_model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature_score = pd.DataFrame(list(zip(features,importance)),columns = ['features','importance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature_score.sort_values('importance',ascending = False)#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_prediction = my_first_model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_prediction\n# Acutal is y_test\n# training accuracy\n#accuracy_score(y_train,train_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Changing K value of algorithm is called Hyper parameter tuning\n\n## Algorith Used : KNN Classifier\n\n#Models:\n##### iteration 1: 0.9322 k = 2, model 1 \n##### iteration 2: 0.9298 K= 7, model 2\n#### iteration 3: 0.9181 K = 4,model 3\n\n### Random Forest : 0.953\n\n### Xgboost: 0.959\n### LightGBM:  0.959\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n\nSteps to follow:\n 1. Fetch data \n 2. Explore data/ Panda profiling\n 3. Decide the model type( regression or classification)\n 4.Feature importance ( train model and find best feature) apply model with all featues\n 5.Validate model - if not good remove / add more features and then re-validate.\n 6.Change and validate with different algorithm\n 7.Auto hyper paramter tuning ( grid search)- this gives += 2% increase maybe\n \n \n \n\n\n\n\n\n\n\n\n\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}