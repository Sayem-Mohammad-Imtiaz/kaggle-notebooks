{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import torch\nfrom torchvision import transforms, models, datasets\nimport torchvision\nfrom torch.autograd import Variable\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport time\nimport matplotlib.pyplot as plt\nplt.ion() \n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport os\nimport numpy as np\nfrom PIL import Image\nimport copy\nimport cv2\nimport math\nfrom PIL import Image\n\n\nimport helper\n\nfrom collections import OrderedDict\n\ntrain_on_gpu = torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66be55fb8b200db2370836fb0c0f99f17ee2f11c"},"cell_type":"code","source":"def resize_image(input_image_path,\n                 size):\n    original_image = Image.open(input_image_path)\n    resized_image = original_image.resize(size)\n    resized_image.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_dir = '../input/flowers-datasets/flowers_dataset/flower'\n\n\ntrain_dir = data_dir + '/train'\nvalid_dir = data_dir + '/valid'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c870c268762fa5d4a55046766345986d48a47314"},"cell_type":"code","source":"# number of subprocesses to use for data loading\n#num_workers = 0\n# how many samples per batch to load\nbatch_size = 16\n# percentage of training set to use as validation\n#test_size = 0.5\n\n\n# TODO: Define your transforms for the training and validation sets\ntrain_data_transforms = transforms.Compose([\n                                       transforms.RandomRotation(10),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\nvalid_data_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\n\n\n# TODO: Load the datasets with ImageFolder\ntrain_image_datasets = datasets.ImageFolder(train_dir,transform=train_data_transforms)\nvalid_image_datasets = datasets.ImageFolder(valid_dir,transform=valid_data_transforms)\n\n#print(valid_image_datasets.class_to_idx)\n# split the data into training - test set\n#n_train_image = len(train_image_datasets)\n#indices = list(range(n_train_image))\n#np.random.shuffle(indices)\n#split = int(np.floor(test_size * n_train_image))\n#train_idx, test_idx = indices[split:], indices[:split]\n\n#train_sampler = SubsetRandomSampler(train_idx)\n#test_sampler = SubsetRandomSampler(test_idx)\n# TODO: Using the image datasets and the trainforms, define the dataloaders\ntraindataloaders = torch.utils.data.DataLoader(train_image_datasets,batch_size=batch_size, shuffle=True)\nvaliddataloaders = torch.utils.data.DataLoader(valid_image_datasets,batch_size=batch_size)\n#testdataloaders  = torch.utils.data.DataLoader(train_image_datasets,batch_size=batch_size,sampler=test_sampler)\n\nclass_names = train_image_datasets.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"506acd4e95a7b04072ef760db4e21071db82b9c5"},"cell_type":"code","source":"def random_mini_batches(X, Y, mini_batch_size =16, seed = 0):\n\n    m = X.shape[0]                  # number of training examples\n    mini_batches = []\n    np.random.seed(seed)\n    \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[permutation,:,:,:]\n    shuffled_Y = Y[:,permutation]\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n        mini_batch_Y = shuffled_Y[:,k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n        mini_batch_Y = shuffled_Y[:,num_complete_minibatches * mini_batch_size : m]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f203f32073d37556d55742367b238c780c88bfa6"},"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dafce6bbb5da54c29a03bf589bbc5179c2edf736"},"cell_type":"code","source":"import json\n\nwith open('../input/pytorch-challange-flower-dataset/cat_to_name.json', 'r') as f:\n    \n    cat_to_name = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a2f519b3527051b0b7ccb53fc8b022aa2de9956"},"cell_type":"code","source":"classes_name = []\n\nfor i in range(len(cat_to_name)):\n    classes_name.append(cat_to_name[str(i+1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9d39beae5390570b0b863c8560de4f28095d611"},"cell_type":"code","source":"# obtain one batch of training images\ndataiter = iter(traindataloaders)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\n# display 20 images\nfor idx in np.arange(16):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(cat_to_name[str(labels[idx].item() + 1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"45c0f7b8bf6080d3a60cc9862f95c9b4a1c39939"},"cell_type":"code","source":"resnet_model = models.resnet152(pretrained=True)\ndeep_model = models.vgg19_bn(pretrained=True)\n#deep_model = models.resnet152(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc851d849e4645fda1530bee986fbc9d3e3f5d61"},"cell_type":"code","source":"deep_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f26937ebe51096bcc8fdaf03a59c86527ce35c98"},"cell_type":"code","source":"# Freeze training for all layers\nfor param in resnet_model.parameters():\n    param.require_grad = False\n    \nfor param in deep_model.parameters():\n    param.require_grad = False\n\nclassifier = nn.Sequential(nn.Linear(25088,4096),\n                             nn.ReLU(),\n                             nn.Dropout(p=0.5),\n                             nn.Linear(4096,4096),\n                             nn.ReLU(),\n                             nn.Dropout(p=0.5),\n                             nn.Linear(4096,102))\n# Newly created modules have require_grad=True by default\nnum_features = resnet_model.fc.in_features\nfeatures = list()\nfeatures.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\nresnet_model.fc = nn.Sequential(*features) # Replace the model classifier\ndeep_model.classifier = classifier # Replace the model classifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d9721846e8cc645247385494ed4b8b10fae4a1e"},"cell_type":"code","source":"deep_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9c63632b8c9da253fc8afbc7d56c3b7a2b2d2c3"},"cell_type":"code","source":"resnet_model.load_state_dict(torch.load('../input/models/first_model.pt'))\ndeep_model.load_state_dict(torch.load('../input/deep-model/second_model.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7d7c036638dfc3354fc9ae4ca09fdc99d629db0"},"cell_type":"code","source":"if train_on_gpu:\n    resnet_model.cuda() #.cuda() will move everything to the GPU side\n    deep_model.cuda()\n    \ncriterion = nn.CrossEntropyLoss()\ncriterion_deep = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(resnet_model.parameters(), lr=0.001,momentum=0.9,weight_decay=0.0005)\noptimizer_deep= optim.SGD(deep_model.parameters(), lr=0.001,momentum=0.9,weight_decay=0.0005)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\nexp_lr_scheduler_deep = lr_scheduler.StepLR(optimizer_deep, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"924c9fa9632feeec857d840f094b20d5b62bc2d1"},"cell_type":"code","source":"def train_model(resnet_model,deep_model,criterion, optimizer,optimizer_deep, scheduler,scheduler_deep, num_epochs=20):\n    \n    avg_loss_fisrt = 0\n    avg_acc_first = 0\n    avg_loss_second =0\n    avg_acc_second =0\n    avg_loss_val = 0\n    avg_acc_val = 0\n    \n    train_batches = len(traindataloaders)\n    val_batches = len(validdataloaders)\n\n    valid_loss_min = np.inf # track change in validation loss\n    falsh_predicted_images_first  =[]\n    falsh_predicted_labels_first  =[]\n    falsh_predicted_images_second =[]\n    falsh_predicted_labels_second =[]\n    \n    #train_images_data_without_dablicated = []\n    #train_labels_data_without_dablicated = []\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n        print('-' * 10)\n        \n        loss_train_first = 0\n        loss_train_second=0\n        loss_val = 0\n        \n        acc_train_first = 0\n        acc_train_second =0\n        acc_val = 0\n        \n        resnet_model.train(True)\n        deep_model.train(True)\n        \n        for i, data in enumerate(traindataloaders):\n            if i % 10 == 0:\n                print(\"\\rTraining batch {}/{}\".format(i, train_batches ), end='', flush=True)\n                \n            inputs, labels = data\n            inputs, labels = inputs.cpu().numpy(), labels.cpu().numpy()\n            \n            m = inputs.shape[0]\n            inputs_first, labels_first = inputs[:int(m/2),:,:,:], labels[:int(m/2)]   # numpy\n            inputs_second, labels_second = inputs[int(m/2):,:,:,:], labels[int(m/2):] # numpy\n            inputs_first, labels_first = torch.from_numpy(inputs_first), torch.from_numpy(labels_first)\n            inputs_second, labels_second = torch.from_numpy(inputs_second), torch.from_numpy(labels_second)\n\n            if train_on_gpu :\n                inputs_first, labels_first = inputs_first.cuda(), labels_first.cuda()\n                inputs_second, labels_second = inputs_second.cuda(), labels_second.cuda()\n            else:\n                inputs_first, labels_first = inputs_first, labels_first     \n                inputs_second, labels_second = inputs_second, labels_second\n            \n            if(np.array(falsh_predicted_images_second).shape[0]):\n                inputs_first = torch.cat(((torch.from_numpy(np.array(falsh_predicted_images_second))).cuda(),inputs_first),dim=0)\n                labels_first = torch.cat(((torch.from_numpy(np.array(falsh_predicted_labels_second))).cuda(),labels_first),dim=0) \n            optimizer.zero_grad()\n            outputs_first = resnet_model(inputs_first)\n            ps_first = torch.exp(outputs_first)\n            top_p_first, top_class_first = ps_first.topk(1, dim=1)\n            equals_first = top_class_first == labels_first.view(*top_class_first.shape)\n\n            for i in range(len(equals_first)):\n                if equals_first[i]==False :\n                    falsh_predicted_images_first.append(inputs_first[i].cpu().numpy())\n                    falsh_predicted_labels_first.append(labels_first[i].cpu().numpy()) \n\n            falsh_predicted_images_second[:] = []\n            falsh_predicted_labels_second[:] = []\n            if(np.array(falsh_predicted_images_first).shape[0]):\n                inputs_second = torch.cat(((torch.from_numpy(np.array(falsh_predicted_images_first))).cuda(),inputs_second),dim=0)\n                labels_second = torch.cat(((torch.from_numpy(np.array(falsh_predicted_labels_first))).cuda(),labels_second),dim=0)\n\n            optimizer_deep.zero_grad()\n            outputs_second = deep_model(inputs_second)\n\n            ps_second = torch.exp(outputs_second)\n            top_p_second, top_class_second = ps_second.topk(1, dim=1)\n            equals_second = top_class_second == labels_second.view(*top_class_second.shape)\n            for i in range(len(equals_second)):\n                if equals_second[i]==False :\n                    falsh_predicted_images_second.append(inputs_second[i].cpu().numpy())\n                    falsh_predicted_labels_second.append(labels_second[i].cpu().numpy())      \n                    \n            falsh_predicted_images_first[:] = []\n            falsh_predicted_labels_first[:] = []\n            outputs = torch.cat((outputs_first,outputs_second),dim=0)\n            labels  = torch.cat((labels_first,labels_second), dim=0)\n            #ps = torch.exp(outputs)\n            #ps_second = torch.exp(outputs_second)\n            #top_p, top_class = ps.topk(1, dim=1)\n            #top_p_second, top_class_second = ps_second.topk(1, dim=1)\n            #print(top_class_second.shape,\"top_class_second\")\n            #print(top_class_first.shape, \"top_class_first\")\n            #equals = top_class == labels.view(*top_class.shape)\n            equals = torch.cat((equals_first,equals_second), dim=0)\n            #equals_second = top_class_second == labels_second.view(*top_class_second.shape)\n            #equals = torch.cat((equals_first,equals_second),dim=0)\n            #print(equals.shape)\n            \n\n            acc_train_first += torch.mean(equals.type(torch.FloatTensor)).item()\n            \n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer_deep.step()\n            \n            loss_train_first += loss.item() \n\n        resnet_model.train(False)\n        deep_model.train(False)\n        resnet_model.eval()\n        deep_model.eval()\n        with torch.no_grad() :\n            \n            for i, data in enumerate(validdataloaders):\n                if i % 10 == 0:\n                    print(\"\\rValidation batch {}/{}\".format(i+1, val_batches), end='', flush=True)\n                inputs, labels = data\n                inputs, labels = inputs.cpu().numpy(), labels.cpu().numpy()\n            \n                m = inputs.shape[0]\n                inputs_first, labels_first = inputs[:int(m/2),:,:,:], labels[:int(m/2)]   # numpy\n                inputs_second, labels_second = inputs[int(m/2):,:,:,:], labels[int(m/2):] # numpy\n            \n                inputs_first, labels_first = torch.from_numpy(inputs_first), torch.from_numpy(labels_first)\n                inputs_second, labels_second = torch.from_numpy(inputs_second), torch.from_numpy(labels_second)                    \n                \n            \n                if train_on_gpu :\n                    inputs_first, labels_first = inputs_first.cuda(), labels_first.cuda()\n                    inputs_second, labels_second = inputs_second.cuda(), labels_second.cuda()\n                else:\n                    inputs_first, labels_first = inputs_first, labels_first     \n                    inputs_second, labels_second = inputs_second, labels_second\n\n            \n                optimizer.zero_grad()\n                optimizer_deep.zero_grad()\n                outputs_first = resnet_model(inputs_first)\n                outputs_second = deep_model(inputs_second)\n            \n                outputs = torch.cat((outputs_first,outputs_second),dim=0)\n                labels = torch.from_numpy(labels).cuda()\n                ps = torch.exp(outputs)\n                #ps_second = torch.exp(outputs_second)\n                top_p, top_class = ps.topk(1, dim=1)\n                #top_p_second, top_class_second = ps_second.topk(1, dim=1)\n                #print(top_class_second.shape,\"top_class_second\")\n                #print(top_class_first.shape, \"top_class_first\")\n                equals = top_class == labels.view(*top_class.shape)\n                #equals_second = top_class_second == labels_second.view(*top_class_second.shape)\n                #equals = torch.cat((equals_first,equals_second),dim=0)\n                #print(equals.shape)\n                acc_val += torch.mean(equals.type(torch.FloatTensor))\n                loss = criterion(outputs, labels)\n            \n                loss_val += loss.item()\n\n        avg_loss_val = loss_val / len(validdataloaders)\n        avg_acc_val = acc_val / len(validdataloaders)\n        avg_loss_first = loss_train_first  /  len(traindataloaders)\n        avg_acc_first = acc_train_first  / len(traindataloaders)\n        \n        #avg_loss_deep = loss_train_deep / len(mini_batches)\n        #avg_acc_deep  = acc_train_deep / len(mini_batches)\n        print()\n        print(\"Epoch {} result: \".format(epoch))\n        print(\"Avg loss (train): {:.4f}\".format(avg_loss_first))\n        print(\"Avg acc (train): {:.4f}\".format(avg_acc_first))\n        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n        #print(\"Avg loss (deep): {:.4f}\".format(avg_loss_deep))\n        #print(\"Avg acc (deep): {:.4f}\".format(avg_acc_deep))\n        print('-' * 10)\n        print()\n        if avg_loss_val <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            avg_loss_val))\n            torch.save(resnet_model.state_dict(), 'first_model_v3.pt')\n            torch.save(deep_model.state_dict(), 'second_model_v3.pt')\n            valid_loss_min = avg_loss_val\n\n    return resnet_model,deep_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7f81b2497ed2539de8c66f9b26282574a3fb8a9"},"cell_type":"markdown","source":"def train_model(resnet_model,deep_model,criterion, optimizer,optimizer_deep, scheduler,scheduler_deep, num_epochs=20):\n    \n    avg_loss = 0\n    avg_acc = 0\n    avg_loss_val = 0\n    avg_acc_val = 0\n    avg_loss_deep =0\n    avg_acc_deep =0\n    \n    train_batches = len(traindataloaders)\n    val_batches = len(validdataloaders)\n    valid_loss_min = 0.039 # track change in validation loss\n    falsh_predicted_images =[]\n    falsh_predicted_labels =[]\n    total_falsh_predicted_images =[]\n    total_falsh_predicted_labels =[]\n    daplicated_images_remove = []\n    daplicated_labels_remove = []\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n        print('-' * 10)\n        \n        loss_train = 0\n        loss_train_deep=0\n        loss_val = 0\n        acc_train = 0\n        acc_train_deep =0\n        acc_val = 0\n        \n        resnet_model.train(True)\n        \n        for i, data in enumerate(traindataloaders):\n            if i % 10 == 0:\n                print(\"\\rTraining batch {}/{}\".format(i, train_batches ), end='', flush=True)\n                \n                \n            inputs, labels = data\n            \n            if(len(total_falsh_predicted_images)):\n                inputs = inputs.numpy()\n                labels = labels.numpy()\n                for i in range(inputs.shape[0]):\n                    \n                    inp = np.sum(inputs[i])\n                    falsh_images = np.sum(np.sum(np.sum(np.array(total_falsh_predicted_images),axis=1),axis=1),axis=1)\n                    if inp in falsh_images :\n                        print(\"Ja\")\n                    else :\n                        daplicated_images_remove.append(inputs[i])\n                        daplicated_labels_remove.append(labels[i])\n                inputs = torch.from_numpy(np.array(daplicated_images_remove))\n                labels = torch.from_numpy(np.array(daplicated_labels_remove))\n                        \n            if train_on_gpu :\n                inputs, labels = inputs.cuda(), labels.cuda()\n            else:\n                inputs, labels = inputs , labels\n                \n                \n                    \n\n            \n            optimizer.zero_grad()\n            outputs = resnet_model(inputs)\n            ps = torch.exp(outputs)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.view(*top_class.shape)            \n            \n\n            for i in range(len(equals)):\n                if equals[i]==False :\n                    total_falsh_predicted_images.append(inputs[i].cpu().numpy())\n                    total_falsh_predicted_labels.append(labels[i].cpu().numpy())\n                    falsh_predicted_images.append(inputs[i].cpu().numpy())\n                    falsh_predicted_labels.append(labels[i].cpu().numpy())                    \n\n                \n                \n            acc_train += torch.mean(equals.type(torch.FloatTensor)).item()\n            \n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            loss_train += loss.item() \n            daplicated_images_remove = list(daplicated_images_remove)\n            daplicated_labels_remove = list(daplicated_labels_remove)\n            daplicated_images_remove[:] = []\n            daplicated_labels_remove[:] = []\n        falsh_predicted_images = np.array(falsh_predicted_images)\n        falsh_predicted_labels = np.array(falsh_predicted_labels).reshape(1,len(falsh_predicted_labels))\n        mini_batches=random_mini_batches(falsh_predicted_images, falsh_predicted_labels, mini_batch_size=10, seed=110)\n        for j in range(len(mini_batches)):\n            (mini_batch_x,mini_batch_y)=mini_batches[j]\n            falsh_predicted_images = torch.from_numpy(mini_batch_x)\n            falsh_predicted_labels = torch.from_numpy(mini_batch_y.reshape(mini_batch_y.shape[1]))\n            if train_on_gpu :\n                falsh_predicted_images, falsh_predicted_labels = falsh_predicted_images.cuda(), falsh_predicted_labels.cuda()\n            else:\n                inputs, labels = inputs , labels\n            optimizer_deep.zero_grad()\n            outputs_deep = deep_model(falsh_predicted_images)\n            ps_deep = torch.exp(outputs_deep)\n            top_p_deep, top_class_deep = ps_deep.topk(1, dim=1)\n            equals_deep = top_class_deep == falsh_predicted_labels.view(*top_class_deep.shape)\n            acc_train_deep += torch.mean(equals_deep.type(torch.FloatTensor)).item()\n            loss_deep = criterion_deep(outputs_deep, falsh_predicted_labels)  \n            loss_deep.backward()\n            optimizer_deep.step()\n            loss_train_deep += loss_deep.item() \n        \n        falsh_predicted_images = list(falsh_predicted_images.cpu().numpy())\n        falsh_predicted_labels = list(falsh_predicted_labels.cpu().numpy())\n        falsh_predicted_images[:] = []\n        falsh_predicted_labels[:] = []\n        \n        resnet_model.train(False)\n        resnet_model.eval()\n        with torch.no_grad() :\n            \n            for i, data in enumerate(validdataloaders):\n                if i % 10 == 0:\n                    print(\"\\rValidation batch {}/{}\".format(i+1, val_batches), end='', flush=True)\n                \n                inputs, labels = data\n            \n                if train_on_gpu:\n                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n                else:\n                    inputs, labels = Variable(inputs, volatile=True), Variable(labels)\n            \n                optimizer.zero_grad()\n            \n                outputs = resnet_model(inputs)\n            \n                ps = torch.exp(outputs)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                #for i in range(len(equals)):\n                    #if equals[i]==False :\n                        #print(inputs[i])\n                        #print(labels[i])\n                        #print(i)\n                        #imshow(inputs[i])\n                acc_val += torch.mean(equals.type(torch.FloatTensor))\n                loss = criterion(outputs, labels)\n            \n                loss_val += loss.item()\n\n        avg_loss_val = loss_val / len(validdataloaders)\n        avg_acc_val = acc_val / len(validdataloaders)\n        avg_loss = loss_train  /  len(traindataloaders)\n        avg_acc = acc_train  / len(traindataloaders)\n        \n        avg_loss_deep = loss_train_deep / len(mini_batches)\n        avg_acc_deep  = acc_train_deep / len(mini_batches)\n        print()\n        print(\"Epoch {} result: \".format(epoch))\n        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n        print(\"Avg loss (deep): {:.4f}\".format(avg_loss_deep))\n        print(\"Avg acc (deep): {:.4f}\".format(avg_acc_deep))\n        print('-' * 10)\n        print()\n        if avg_loss_val <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            avg_loss_val))\n            torch.save(resnet_model.state_dict(), 'resnet_model3_PyTorch_Challenge.pt')\n            valid_loss_min = avg_loss_val\n\n    return resnet_model,deep_model"},{"metadata":{"trusted":true,"_uuid":"6e260da31f1b6306d219824145f964573f450fc4"},"cell_type":"code","source":"resnet_model,deep_model = train_model(resnet_model,deep_model, criterion, optimizer_ft,optimizer_deep, exp_lr_scheduler,exp_lr_scheduler_deep, num_epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbcd131c96576aa575b3c104fb89dd773954b019"},"cell_type":"code","source":"torch.save(resnet_model.state_dict(), 'first_model_v2.pt')\ntorch.save(deep_model.state_dict(), 'second_model_v2.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1b7d74304dabd1a9a9d976008526ce95dcc4e7d"},"cell_type":"code","source":"def eval_model(resnet_model, criterion):\n    avg_loss = 0\n    avg_acc = 0\n    loss_test = 0\n    acc_test = 0\n    \n    test_batches = len(validdataloaders)\n    print(\"Evaluating model\")\n    print('-' * 10)\n    with torch.no_grad():\n        \n        for i, data in enumerate(validdataloaders):\n            if i % 10 == 0:\n                print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n\n            resnet_model.train(False)\n            resnet_model.eval()\n            inputs, labels = data\n\n            if train_on_gpu:\n                inputs, labels = inputs.cuda(), labels.cuda()\n            else:\n                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n\n            outputs = resnet_model(inputs)\n\n            ps = torch.exp(outputs)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.view(*top_class.shape)\n            for i in equals :\n                if not i:\n                    print(labels)\n                    print(top_class)\n            acc_test += torch.mean(equals.type(torch.FloatTensor))\n            loss = criterion(outputs, labels)\n            \n\n            loss_test += loss.item()\n\n        avg_loss = loss_test / len(validdataloaders)\n        avg_acc = acc_test / len(validdataloaders)\n    \n        print()\n        print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n        print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n        print('-' * 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d07869dba14d97352797633808a07a0dd6673dc9"},"cell_type":"code","source":"eval_model(resnet_model, criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3e895f59a3cb71a394ec13828cb783595f54d6e"},"cell_type":"code","source":"torch.save(resnet_model.state_dict(), 'resnet_model_final_PyTorch_Challenge.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9874727c171ad0b95910552e69e45746aa23eb2","_kg_hide-output":true},"cell_type":"code","source":"# track test loss\ntest_loss = 0.0\nclass_correct = list(0. for i in range(102))\nclass_total = list(0. for i in range(102))\n\nresnet_model.eval()\n# iterate over test data\nfor data, target in testdataloaders:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = resnet_model(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(len(list(target.data.shape))):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss/len(testdataloaders.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(102):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbb36322112f60d76ecfd92df606da22505bb325"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9811e654f6c08aa0473d0651a854a6deaa71aec"},"cell_type":"code","source":"# obtain one batch of test images\ndataiter = iter(testdataloaders)\nimages, labels = dataiter.next()\nimages.numpy()\n\n# move model inputs to cuda, if GPU available\nif train_on_gpu:\n    images = images.cuda()\n\n# get sample outputs\noutput = resnet_model(images)\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 10))\nfor idx in np.arange(16):\n    ax = fig.add_subplot(4, 8/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46e5c4bc9954ed5d8f16dd51ce41baa06af58c45"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef69a2ffa5fc17a65bf5aaa850b125d33f180047"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}