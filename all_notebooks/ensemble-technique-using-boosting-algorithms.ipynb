{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Dataset Description:\n\n- employee_id : Unique ID for employee\n- department : Department of employee\n- region : Region of employment (unordered)\n- education : Education Level\n- gender : Gender of Employee\n- recruitment_channel : Channel of recruitment for employee\n- no_of_trainings : no of other trainings completed in previous year on soft skills, technical skills etc.\n- age : Age of Employee\n- previous_year_rating : Employee Rating for the previous year\n- length_of_service : Length of service in years\n- KPIs_met >80% : if Percent of KPIs(Key performance Indicators) >80% then 1 else 0\n- awards_won? : if awards won during previous year then 1 else 0\n- avg_training_score : Average score in current training evaluations\n- is_promoted : (Target) Recommended for promotion"},{"metadata":{},"cell_type":"markdown","source":"**In this kernel I am going to use VotingClassifier as ensemble technique. And the algorithms used are XGBoost, LGBM and Catboost.**"},{"metadata":{},"cell_type":"markdown","source":"### Importing Basic libraries:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# loading training data and reading top 5 records\n\ndf = pd.read_csv('../input/hr-analytics-analytics-vidya/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Reading bottom 5 records\n\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are {} rows and {} columns in the training dataset.\".format(df.shape[0],df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To know the datatypes of the column\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are {} duplicate records.\".format(df.shape[0] - len(df['employee_id'].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping employee_id column as it doesnot provide any information\n\ndf.drop('employee_id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Name of the columns\n\nprint(\"Column Names: {}\".format(list(df.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Column names into list\n\ncol_name = df.columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# To find out number of unique values and unique vales of a perticular column\n\nfor i in col_name:\n    print(\"In the column - {}:\".format(i))\n    print(\"There are {0} Unique values\".format(len(df[i].unique())))\n    print(\"Unique vales in the column are - \\n{}\".format(list(df[i].unique())))\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix\n\nplt.figure(figsize=(10,5))\nsns.heatmap(df.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 'length_of_service' is highly correlated with 'age'\n- 'KPIs_met >80%' is slightly correlated with 'previous_year_rating'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of each values in column\nfor i in col_name:\n    plt.figure(figsize=(15,5))\n    plt.title(\"Count of each values in column '{}'\".format(i))\n    sns.countplot(df[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pair plot\n\nsns.pairplot(df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Finding missing values and imputing it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are totally {} missing values in the dataset.\".format(df.isnull().sum().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of missing values in column\n\nfor i in col_name:\n    if df[i].isnull().sum() > 0:\n        print(\"There are {} missing values in the '{}' column.\\n\".format(df[i].isnull().sum(),i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing missing values in column education with forwardfill\n\ndf['education'] = df['education'].ffill()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Value count for column \"length_of_service\" when \"previous_year_rating\" isnull\n\ndf[df[\"previous_year_rating\"].isnull() == True]['length_of_service'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing missing values in column \"previous_year_rating\" with \"0\" as length of service is 1 for missing values \n\ndf['previous_year_rating'] = df['previous_year_rating'].fillna(0.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Featuring Engineering:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binning the age column\n\ndf['age'] = pd.cut(x=df['age'], bins=[20, 29, 39, 49], \n                    labels=['20 to 30', '30 to 40', '40+']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing datatype 'category' to 'object'\n\ndf['age'] = df['age'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Spliting train data into Predictors(Independent) & Target(Dependent):"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('is_promoted',axis=1)\ny = df['is_promoted']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data encoding using OneHot encoding technique:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_encode = pd.get_dummies(X,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data scaling using RobustScalar:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing \n\nscaler = preprocessing.RobustScaler() \nX_standard = scaler.fit_transform(X_encode) \nX_standard = pd.DataFrame(X_standard, columns =X_encode.columns) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Not dividing train dataset to train_test_split as it gives less value of F-1 score."},{"metadata":{},"cell_type":"markdown","source":"### Creating Baseline ML Model for Binary Classification Problem:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\n\nClassifiers = {'0._XGBoost' : XGBClassifier(learning_rate =0.1, n_estimators=500, max_depth=5,subsample = 0.70,\n                                            verbosity = 0, scale_pos_weight = 2.5,updater =\"grow_histmaker\",\n                                            base_score  = 0.2),\n               \n               '1.CatBoost' : CatBoostClassifier(learning_rate=0.15, n_estimators=500, subsample=0.085, max_depth=5,\n                                                 scale_pos_weight=2.5),\n               \n               '2.LightGBM' : LGBMClassifier(subsample_freq = 2, objective =\"binary\",importance_type = \"gain\",verbosity = -1,\n                                             max_bin = 60,num_leaves = 300, boosting_type = 'dart',learning_rate=0.15, \n                                             n_estimators=500, max_depth=5, scale_pos_weight=2.5)}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Parameters values are taken from tuning and trail and error method."},{"metadata":{},"cell_type":"markdown","source":"### Improving Model with Voting Classifier with MODEL Evaluation METRIC - \"F1\" and Predict Target \"is_promoted\":"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nvc_model = VotingClassifier(estimators=[('XGBoost_Best', list(Classifiers.values())[0]), \n                                        ('CatBoost_Best', list(Classifiers.values())[1]),\n                                        ('LightGBM_Best', list(Classifiers.values())[2]),\n                                       ], \n                            voting='soft',weights=[2, 1, 3])\n\nvc_model.fit(X_standard,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Weights are taken from tuning."},{"metadata":{},"cell_type":"markdown","source":"## Scoring:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading test dataset\n\ndf1 = pd.read_csv('../input/hr-analytics-analytics-vidya/test.csv')\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing all the step on the unseen data that was performed on historical data\n\ndf2 = df1.copy()\n\ndf1.drop('employee_id',axis=1,inplace=True)\n\ndf1['education'] = df1['education'].ffill()\n\ndf1['previous_year_rating'] = df1['previous_year_rating'].fillna(0.0)\n\ndf1['age'] = pd.cut(x=df1['age'], bins=[20, 29, 39, 49], labels=['20 to 30', '30 to 40', '40+']) \ndf1['age'] = df1['age'].astype('object')\n\ndf1_encode = pd.get_dummies(df1,drop_first=True)\n\nscaler = preprocessing.RobustScaler() \ndf_standard = scaler.fit_transform(df1_encode) \ndf_standard = pd.DataFrame(df_standard, columns =df1_encode.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting and storing the submission file:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['is_promoted'] = vc_model.predict(df_standard)\n\ndf1=df2[['employee_id','is_promoted']]\ndf1.to_csv('Predict19.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}