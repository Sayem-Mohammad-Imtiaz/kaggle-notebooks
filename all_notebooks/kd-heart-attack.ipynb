{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/brsdincer/heart-attack-prediction-detailed-explanation\nimport numpy as np\nimport pandas as  pd\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom scipy.stats import levene\nfrom scipy.stats import shapiro\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, ShuffleSplit, GridSearchCV \nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATA SOURCE\nHeart = pd.read_csv('../input/heart-attack-analysis-prediction-dataset')\ndata = Heart.copy()\n\n# ここでのカテゴリー型への変換は、箱ひげ図やバーの表示時に役に立つ\ndataV  = data.copy()\ndataV['sex'] = pd.Categorical(dataV['sex'])              \ndataV['cp'] = pd.Categorical(dataV['cp'])\ndataV['fbs'] = pd.Categorical(dataV['fbs'])\ndataV['restecg'] = pd.Categorical(dataV['restecg'])\ndataV['exng'] = pd.Categorical(dataV['exng'])\ndataV['slp'] = pd.Categorical(dataV['slp'])\ndataV['caa'] = pd.Categorical(dataV['caa'])\ndataV['thall'] = pd.Categorical(dataV['thall'])\ndataV['output'] = pd.Categorical(dataV['output'])\n\ndf = data.select_dtypes(include=['float64', 'int64', 'int32'])     # 指定したタイプのデータを抽出","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.Categorical()     # category型に変換\n\"\"\"\n例\npd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'])\n['a', 'b', 'c', 'a', 'b', 'c']\nCategories (3, object): ['a', 'b', 'c']\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# INFORMATIONS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nAbout dataset\nAge : Age of the patient\n\nSex : Sex of the patient\n\nexang: exercise induced angina (1 = yes; 0 = no)\n\nca: number of major vessels (0-3)\n\ncp : Chest Pain type chest pain type\n\nValue 1: typical angina\nValue 2: atypical angina\nValue 3: non-anginal pain\nValue 4: asymptomatic\ntrtbps : resting blood pressure (in mm Hg)\n\nchol : cholestoral in mg/dl fetched via BMI sensor\n\nfbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n\nrest_ecg : resting electrocardiographic results\n\nValue 0: normal\nValue 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\nValue 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\nthalach : maximum heart rate achieved\n\ntarget : 0= less chance of heart attack 1= more chance of heart attack\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\nprint('------'*20)\nprint(data.columns)\nprint('------'*20)\nprint(data.info())\nprint('------'*20)\nprint(data.describe())\nprint('------'*20)\nprint(data.corr())      # 各列の間の相関係数が算出される (heatmapで可視化可能(seaborn))\nprint('------'*20)\nprint(data['sex'].value_counts())      # value_counts(): それぞれの値の出現回数をカウントしてくれる。\nprint('------'*20)\nprint(data['cp'].value_counts())    \nprint('------'*20)\nprint(data['fbs'].value_counts())\nprint('------'*20)\nprint(data['restecg'].value_counts())\nprint('------'*20)\nprint(data['exng'].value_counts())\nprint('------'*20)\nprint(data['slp'].value_counts())\nprint('------'*20)\nprint(data['caa'].value_counts())\nprint('------'*20)\nprint(data['thall'].value_counts())\nprint('------'*20)\nprint(data['output'].value_counts())\nprint('------'*20)\nprint(data.groupby(['sex', 'output']).mean(['trtbps']))    # resting blood pressure (in mm Hg)\nprint('------'*20)\nprint(data.groupby(['sex', 'output']).mean(['chol']))     # cholestoral in mg/dl fetched via BMI sensor\nprint('------'*20)\nprint(data.groupby(['sex', 'output']).mean(['thalachh']))   # maximum heart rate achieved\nprint('------'*20)\nprint(data.groupby(['sex', 'output']).mean(['oldpeak']))\nprint('------'*20)\nprint(data.isnull().sum())     # Nanの数を調べている","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CORRELATION - NORMALITY - HOMOGENEITY\ncorrPearson = data.corr(method='pearson')    # ピアソンの積率相関係数の無相関検定を行う(関係は線形)\ncorrSpearman = data.corr(method='spearman')   # スピアマンの順位相関係数の無相関検定を行う(単調（スピアマン）関係)\n\n# 上記の違い: https://support.minitab.com/ja-jp/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/correlation-and-covariance/a-comparison-of-the-pearson-and-spearman-correlation-methods/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 無相関検定  :   https://liginc.co.jp/305968\n\"\"\"\nある標本をとって、その相関係数を求めたときに、その相関係数に意味があるのかどうかを決めることを「無相関検定」\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PEARSON CORRELATION\nfigure = plt.figure(figsize=(10, 8))  # 幅、高さ\nsns.heatmap(corrPearson, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)  # annotで数値を表示するかを指定。vmin, vmax でカラーの幅を指定\nplt.title('PEARSON')\nplt.xlabel('COLUMNS')\nplt.ylabel('COLUMNS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SPEARMAN CORRELATION\nfigure = plt.figure(figsize=(10, 8))\nsns.heatmap(corrSpearman, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('SPEARMAN')\nplt.xlabel('COLUMNS')\nplt.ylabel('COLUMNS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NORMALITY\nfor i in data.columns:\n    print('-----'*10)\n    print('%.3f - %.3f' % shapiro(data[i]))    #シャピロ–ウィルク検定:  統計学において、標本 x1, ..., xn が正規分布に従う母集団からサンプリングされたものであるという帰無仮説を検定する検定\n    \n# 検定統計量, p値","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HOMOGENEITY  : いくつかの群の分散が等しいかどうかを検定すること。検定統計量がF分布に従うのでF検定とも呼ばれる\nprint('%.4f - %.4f' % levene(data[\"age\"],data[\"sex\"],data[\"cp\"],data[\"trtbps\"],data[\"chol\"],\n                             data[\"fbs\"],data[\"restecg\"],data[\"thalachh\"],data[\"exng\"],data[\"oldpeak\"],\n                             data[\"slp\"],data[\"caa\"],data[\"thall\"],data[\"output\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"levene(data[\"age\"],data[\"sex\"],data[\"cp\"],data[\"trtbps\"],data[\"chol\"],\n                             data[\"fbs\"],data[\"restecg\"],data[\"thalachh\"],data[\"exng\"],data[\"oldpeak\"],\n                             data[\"slp\"],data[\"caa\"],data[\"thall\"],data[\"output\"])\n# F値, P値","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VISUALIZATION\n# HIST\ndata.hist(figsize=(20, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BOX\nfigure = plt.figure(figsize=(20, 8))\nsns.boxplot(x='trtbps', y='output', data=dataV)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20,8))\nsns.boxplot(x='chol', y='output', data=dataV)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.boxplot(x='thalachh', y='output', data=dataV)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.boxplot(x='oldpeak', y='output', data=dataV)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.boxplot(x='age', y='output', data=dataV)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data=dataとしたケース\nfigure = plt.figure(figsize=(20, 8))\nsns.boxplot(x='age', y='output', data=data)\nplt.show()\n\n# こうなる原因はoutputの列が数値として認識され、数値の幅を考慮して出してしまうからと考えられる。(category型にする必要あり(非連続的な値として認識させるため))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BAR\nfigure = plt.figure(figsize=(20, 8))\nsns.barplot(x='sex', y='output', data=data)      # data=dataVだと、数値ではないとしてエラーとなる(category型のためと思われる)\n# sns.barplot(): xごとにyの平均値を表示\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.barplot(x='cp', y='output', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20,8))\nsns.barplot(x='fbs', y='output', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20,8))\nsns.barplot(x='restecg', y='output', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.barplot(x='exng', y='output', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.barplot(x='slp', y='output', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.barplot(x='caa', y='output', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(20, 8))\nsns.barplot(x='thall', y='output', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LINE\nrand = 0\nfor i in data.columns:\n    rand += 1\n    if rand < len(data.columns):    #outputのコラムを除くすべてのコラムに対して行うという意味\n        figure = plt.figure(figsize=(20, 8))\n        sns.lineplot(x='output', y=i, data=data)\n        plt.show()\n    else:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3D\n#%matplotlib inline\n#%matplotlib nbagg\nfig = plt.figure(figsize=(10, 10))\nax = Axes3D(fig)\nax.set_xlabel('OUTPUT', fontsize=20)\nax.set_ylabel('TRTBPS', fontsize=20)\nax.set_zlabel('CHOL', fontsize=20)\nax.scatter(xs=dataV['output'], ys=dataV['trtbps'], zs=dataV['chol'], c='red', s=20, alpha=0.5)   # sで点の大きさを指定, alphaで点の濃さを指定\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nax = Axes3D(fig)\nax.set_xlabel('OUTPUT', fontsize=20)\nax.set_ylabel('THALACHH', fontsize=20)\nax.set_zlabel('OLDPEAK', fontsize=20)\nax.scatter3D(dataV['output'], dataV['thalachh'], dataV['oldpeak'], c='green', s=20, alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AGAINST VALUES\nDataForA = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LocalOutlierFactor()   # 外れ値検知  in detail: https://hktech.hatenablog.com/entry/2018/09/04/002034\nclf.fit_predict(DataForA)\n\n# 1は外れ値でないサンプル(inlier)、-1は外れ値(outlier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = clf.negative_outlier_factor_\nscoresorted = np.sort(score)\nprint(scoresorted[:30])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"point = scoresorted[12]\nprint(DataForA[score == point])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"against = DataForA < point\nprint(DataForA[against].notna().sum())     # notna()で欠損値を調べる(NanであればFalse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values = DataForA > point\nprint(DataForA[values].notna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MODELS\n# X & Y FOR MODELS\nx = data.drop(['output'], axis=1)\ny = data['output']\n\nxTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size= 0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# REGRESSION MODELS\nlm = LinearRegression().fit(xTrain, yTrain)\npls = PLSRegression().fit(xTrain, yTrain)     # https://punhundon-lifeshift.com/pca_pls :サンプルサイズが小さかったり、多重共線性が考えられる場合に有効な分析方法の一つ\nridge =  Ridge().fit(xTrain, yTrain)   #https://qiita.com/K_Noguchi/items/3f5cf527d6f6d46767fb#:~:text=%E3%83%AA%E3%83%83%E3%82%B8%E5%9B%9E%E5%B8%B0%E3%81%A8%E3%81%AF%E9%81%8E,%E4%B8%80%E3%81%A4%E3%81%A8%E3%82%82%E8%A8%80%E3%81%88%E3%81%BE%E3%81%99%E3%80%82 過学習を抑える手法の一つ \nlasso = Lasso().fit(xTrain, yTrain)   # いらない特徴量を削る\nelasticnet = ElasticNet().fit(xTrain, yTrain)    # https://leck-tech.com/machine-learning/elastic-net#Lasso Ridge回帰とLasso回帰のハイブリッドのような形を取っているElasticNet\nknnr = KNeighborsRegressor().fit(xTrain, yTrain)   # k最近傍法\ncartr = DecisionTreeRegressor(random_state=42).fit(xTrain, yTrain)   # 決定木の回帰木\nbaggr = BaggingRegressor(random_state=42, bootstrap_features=True, verbose=False).fit(xTrain, yTrain)\nrfr = RandomForestRegressor(random_state=42, verbose=False).fit(xTrain, yTrain)     # https://qiita.com/yshi12/items/6d30010b353b084b3749\ngbmr = GradientBoostingRegressor(verbose=False).fit(xTrain, yTrain)       # https://qiita.com/nazoking@github/items/51a46256ecda598b60dd  勾配ツリーブースト または勾配ブースト回帰ツリー（GBRT）は、任意の微分可能な損失関数にブーストする一般化\nxgbr = XGBRegressor().fit(xTrain, yTrain)    # http://tekenuko.hatenablog.com/entry/2016/09/22/220814\nlgbmr = LGBMRegressor().fit(xTrain, yTrain)    # https://www.codexa.net/lightgbm-beginner/  \ncatbr = CatBoostRegressor(verbose=False).fit(xTrain, yTrain)   # https://ryucoding.com/programming/catboost-beginner  カテゴリー変数に強い","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COMPARISON\nmodels = [lm, pls, ridge, lasso, knnr, cartr, baggr, rfr, gbmr, xgbr, lgbmr, catbr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    name = model.__class__.__name__\n    R2CV = cross_val_score(model, xTest, yTest, cv=10, scoring='r2').mean()  # https://docs.pyq.jp/python/machine_learning/glossary/cross_validation.html  クロスバリデーション\n    error = -cross_val_score(model, xTest, yTest, cv=10, scoring='neg_mean_squared_error').mean()\n    print(name + ':')\n    print('-'*10)\n    print(R2CV)          # クロスバリデーションの決定係数（Ｒ2CV）は普通０〜１の範囲の値をとり、値が大きいほどモデルが適切にデータを表現できている\n    print(np.sqrt(error))    # np.sqrt   平方根\n    print('-'*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = pd.DataFrame(columns=['MODELS', 'R2CV'])\nfor model in models:\n    name = model.__class__.__name__\n    R2CV = cross_val_score(model, xTest, yTest, cv=10, scoring='r2').mean()\n    result = pd.DataFrame([[name, R2CV*100]], columns=['MODELS', 'R2CV'])\n    r = r.append(result)\n    \nfigure = plt.figure(figsize=(20, 8))\nsns.barplot(x='R2CV', y='MODELS', data=r, color='k')\nplt.xlabel('R2CV', fontsize=20)\nplt.ylabel('MODELS', fontsize=20)\nplt.xlim(-50, 100)\nplt.title('MODEL ACCURACY COMPARISON')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SPECIAL REGRESSION MODELS\n# OLS\nols = sm.OLS(yTrain, xTrain).fit()\nols.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PCA\npca = PCA()      # https://qiita.com/maskot1977/items/082557fcda78c4cdb41f  多変量解析手法のうち次元削減手法としてよく用いられる手法の一種\nxRTrain = pca.fit_transform(scale(xTrain))\nxRTest = pca.fit_transform(scale(xTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lmP = LinearRegression().fit(xRTrain, yTrain)\nR2CV = cross_val_score(lmP, xRTest, yTest, cv=10, scoring='r2').mean()\nerror = -cross_val_score(lmP, xRTest, yTest, cv=10, scoring='neg_mean_squared_error').mean()\nprint(R2CV)\nprint('-----'*10)\nprint(np.sqrt(error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lmP = LinearRegression().fit(xRTrain, yTrain)\nR2CV = cross_val_score(lmP, xRTest, yTest, cv=10, scoring='r2').mean()\nerror = -cross_val_score(lmP, xRTest, yTest, cv=10, scoring='neg_mean_squared_error').mean()\nprint(R2CV)\nprint('-----'*10)\nprint(np.sqrt(error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpr = MLPRegressor().fit(xRTrain, yTrain)\n\nR2CV = cross_val_score(mlpr, xRTest, yTest, cv=10, scoring='r2').mean()\nerror = -cross_val_score(mlpr, xRTest, yTest, cv=10, scoring='neg_mean_squared_error').mean()\n\nprint(R2CV)\nprint('-----'*10)\nprint(np.sqrt(error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CLASSIFICATION MODELS\nlj = LogisticRegression(solver='liblinear').fit(xTrain, yTrain)\ngnb = GaussianNB().fit(xTrain,  yTrain)\nknnc = KNeighborsClassifier().fit(xTrain, yTrain)\ncartc = DecisionTreeClassifier(random_state=42).fit(xTrain, yTrain)\nrfc = RandomForestClassifier(random_state=42, verbose=False).fit(xTrain, yTrain)\ngbmc = GradientBoostingClassifier(verbose=False).fit(xTrain, yTrain)\nxgbc = XGBClassifier().fit(xTrain, yTrain)\nlgbmc = LGBMClassifier().fit(xTrain, yTrain)\ncatbc = CatBoostClassifier(verbose=False).fit(xTrain, yTrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COMPARISON\nmodelsc = [lj, gnb, knnc, cartc, rfc, gbmc, xgbc, lgbmc, catbc]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in modelsc:\n    name = model.__class__.__name__\n    predict = model.predict(xTest)\n    R2CV = cross_val_score(model, xTest, yTest, cv=10, verbose=False).mean()\n    error = -cross_val_score(model, xTest, yTest, cv=10, scoring='neg_mean_squared_error', verbose=False).mean()\n    print(name + ':')\n    print('-'*10)\n    print(accuracy_score(yTest, predict))\n    print(R2CV)\n    print(np.sqrt(error))\n    print('-'*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = pd.DataFrame(columns=['MODELS', 'R2CV'])\nfor model in modelsc:\n    name = model.__class__.__name__\n    R2CV = cross_val_score(model, xTest, yTest, cv=10, verbose=False).mean()\n    result = pd.DataFrame([[name, R2CV*100]], columns=['MODELS', 'R2CV'])\n    r = r.append(result)\n    \nfigure = plt.figure(figsize=(20, 8))\nsns.barplot(x='R2CV', y='MODELS', data=r, color='k')\nplt.xlabel('R2CV', fontsize=20)\nplt.ylabel('MODELS', fontsize=20)\nplt.xlim(0, 100)\nplt.title('MODEL ACCURACY COMPARISON')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LGBMClassifier is the best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SPECIAL CLASSIFICATION MODELS\n# ANN C MODELS & ERROR & TUNING & PREDICT\nscaler = StandardScaler().fit(xTrain, yTrain)\nxRTrain = scaler.transform(xTrain)\nxRTest = scaler.transform(xTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpc = MLPClassifier().fit(xRTrain, yTrain)\npredict = mlpc.predict(xRTest)\n\nR2CV = cross_val_score(mlpc, xRTest, yTest, cv=10).mean()\nprint(R2CV)\nerror = mean_squared_error(yTest, predict)\nprint(np.sqrt(error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TUNING FOR BEST MODEL\nparams = {\"n_estimators\": [100, 500, 1000, 2000],\n          \"subsample\": [0.6, 0.8, 1.0],\n          \"max_depth\": [3, 4, 5, 6],\n          \"learning_rate\": [0.1, 0.01, 0.02, 0.05],\n          \"min_child_samples\": [5, 10, 20]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = GridSearchCV(lgbmc, params, cv=10, verbose=False, n_jobs=-1).fit(xTrain, yTrain)\nprint(cv.best_params_)\nprint(cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FINAL MODEL\nlgbmctuned = LGBMClassifier(learning_rate=0.01, max_depth=5, min_child_samples=10, \n                            n_estimators=100, subsample=0.6).fit(xTrain, yTrain)\n\nR2CVtuned = cross_val_score(lgbmctuned, xTest, yTest, cv=10).mean()\nprint(R2CVtuned)\nerrortuned = -cross_val_score(lgbmctuned, xTest, yTest, cv=10, scoring='neg_mean_squared_error').mean()\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}