{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem statement","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:02:49.973204Z","start_time":"2021-04-04T03:02:48.803997Z"}}},{"cell_type":"markdown","source":"##### Implement a KNN model to classify the animals and predict they are of which animal type. The 7 Class Types are: Mammal, Bird, Reptile, Fish, Amphibian, Bug and Invertebrate\n","metadata":{}},{"cell_type":"markdown","source":"# Importing the libraries","metadata":{}},{"cell_type":"code","source":"from pandas import read_csv\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nimport seaborn as sn\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nimport numpy as np\nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import StandardScaler","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:56:46.264956Z","start_time":"2021-04-05T07:56:46.251951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset","metadata":{}},{"cell_type":"code","source":"zoo = pd.read_csv('../input/zoo-animal-classification/zoo.csv')\n","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:13:32.396046Z","start_time":"2021-04-04T03:13:32.372575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zoo.head(5)","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:13:48.897779Z","start_time":"2021-04-04T03:13:48.866719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can just peek into few data points by using head function of pandas. By default, head function return top 5 values ","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:14:02.288646Z","start_time":"2021-04-04T03:14:02.266995Z"}}},{"cell_type":"markdown","source":"# Data Insights","metadata":{}},{"cell_type":"code","source":"zoo.shape","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:14:32.041433Z","start_time":"2021-04-04T03:14:32.019813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zoo.info()","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:14:41.641564Z","start_time":"2021-04-04T03:14:41.60902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations :-","metadata":{}},{"cell_type":"markdown","source":"##### We can see there are no null values in our dataset. There are 16 variables with various traits to describe the animals. The traits are hair, feathers, eggs, milk, .......domestic,catsize.\n\n\n##### The purpose for this dataset is to be able to predict the classification(type) of the animals, based upon the variables.\n","metadata":{}},{"cell_type":"code","source":"zoo[zoo.duplicated()]","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:19:11.487772Z","start_time":"2021-04-04T03:19:11.461241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### There are no duplicate values in our data","metadata":{}},{"cell_type":"markdown","source":"# Summary statistics ","metadata":{}},{"cell_type":"code","source":"zoo.describe()","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:21:07.59534Z","start_time":"2021-04-04T03:21:07.478771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We could see that all the feature attributes are encoded into 0 and 1 except legs. So we will use encoding technique on legs attribute as well.\n\n##### As all the other attributes are encoded using dummy encoding, we will use the same encoding for legs as well.","metadata":{}},{"cell_type":"code","source":"zoo = pd.get_dummies(zoo,columns=['legs'])","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:54:39.46676Z","start_time":"2021-04-04T03:54:39.419188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zoo.head()","metadata":{"ExecuteTime":{"end_time":"2021-04-04T03:54:50.727334Z","start_time":"2021-04-04T03:54:50.68516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understanding the target variable","metadata":{}},{"cell_type":"markdown","source":"##### Our main objective is to be able to predict the classification(type) of the animals, based upon the variables.\n\n##### value_counts() method shows how many samples it is for the animal type. \n","metadata":{}},{"cell_type":"code","source":"zoo['class_type'].value_counts()","metadata":{"ExecuteTime":{"end_time":"2021-04-04T09:06:06.902791Z","start_time":"2021-04-04T09:06:06.889858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We could see that the type 1 counts is very high and there is huge difference between the next highest count wich is 20 for type 2. The sets of data in which classes are not evenly distributed are called imbalanced datasets.The imbalance dataset can cause high/low accuracy value of the model due to a certain class.","metadata":{}},{"cell_type":"code","source":"sn.set(style = 'whitegrid', font_scale = 1.4)\nplt.subplots(figsize = (12,7))\nsn.countplot(x = 'class_type', data = zoo, palette = 'Pastel1')","metadata":{"ExecuteTime":{"end_time":"2021-04-04T09:11:04.525477Z","start_time":"2021-04-04T09:11:04.228864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We can see the count of type 1 is very high","metadata":{}},{"cell_type":"markdown","source":"# Separating feature data and Label data  and train-test split","metadata":{}},{"cell_type":"markdown","source":"##### We will separate the class label data (type) and features data as Y and X respectively. Also, we will split the dataset into training and test data. The animal_name column is not required for classification as it is not a feature, so we will drop that column as well.","metadata":{}},{"cell_type":"code","source":"Y = zoo['class_type']\nY.head()","metadata":{"ExecuteTime":{"end_time":"2021-04-04T09:18:55.186817Z","start_time":"2021-04-04T09:18:55.168832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = zoo.drop('animal_name',axis=1)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T06:48:34.14283Z","start_time":"2021-04-05T06:48:34.1055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X.drop('class_type',axis=1)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T06:49:17.936527Z","start_time":"2021-04-05T06:49:17.922984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T06:49:28.751631Z","start_time":"2021-04-05T06:49:28.727207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2, random_state = 30, stratify = Y)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T06:57:56.994462Z","start_time":"2021-04-05T06:57:56.959629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:00:07.584839Z","start_time":"2021-04-05T07:00:07.55699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:00:13.167891Z","start_time":"2021-04-05T07:00:13.137267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train.head()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:00:18.773767Z","start_time":"2021-04-05T07:00:18.760559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test.head()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:00:23.872048Z","start_time":"2021-04-05T07:00:23.855262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grid search for Algorithm Tuning","metadata":{}},{"cell_type":"code","source":"n_neighbors = np.array(range(1,40))\nparam_grid = dict(n_neighbors=n_neighbors)\nparam_grid","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:01:40.465122Z","start_time":"2021-04-05T07:01:40.455778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = KNeighborsClassifier()\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=10)\ngrid.fit(X_train, Y_train)\nprint(grid.best_params_)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:01:58.424691Z","start_time":"2021-04-05T07:01:55.107681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### After applying GridSearch, we got the best K (n_neighbors) value as 1, so we will be using the k= 1 for KNN Classifier algorithm","metadata":{}},{"cell_type":"markdown","source":"### Visualizing CV results","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \n%matplotlib inline\n# choose k between 1 to 41\nk_range = range(1, 41)\nk_scores = []\n# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, Y_train, cv=10)\n    k_scores.append(scores.mean())\n# plot to see clearly\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:03:03.24088Z","start_time":"2021-04-05T07:02:59.544774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We could see that the model accuracy is very good for k values smaller than 5 and as the value increases the accuracy goes on decreasing","metadata":{}},{"cell_type":"markdown","source":"# Using KNN Classifier for prediction","metadata":{}},{"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors =1).fit(X_train,Y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)\nprint(accuracy)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:06:50.809963Z","start_time":"2021-04-05T07:06:50.791862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We can see that the accuracy score which we have got for our model is 0.76 which is 76%. It is decent accuracy score. But the accuracy score can be misleading for imbalanced data. So we will use confusion matrix and classification report metrics further","metadata":{}},{"cell_type":"code","source":"confusion_matrix = confusion_matrix(Y_test,y_pred)\nprint (confusion_matrix)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:07:37.477243Z","start_time":"2021-04-05T07:07:37.44338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test,y_pred))","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:07:47.792296Z","start_time":"2021-04-05T07:07:47.774259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The precison and f1 score for type 5 is  low. Since the data is imbalanced, we can see the precision values are affected. We will use oversamping technique as the data is very less and undersampling will cause data loss","metadata":{}},{"cell_type":"markdown","source":"# Using Over Sampling for balancing the data","metadata":{}},{"cell_type":"markdown","source":"##### We will use RandomOverSampler (ROS) for sampling the the data to balance our data","metadata":{}},{"cell_type":"code","source":"ros = RandomOverSampler(random_state = 30)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T08:08:15.745446Z","start_time":"2021-04-05T08:08:15.736469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Fitting the data using ROS ","metadata":{}},{"cell_type":"code","source":"x_resample, y_resample = ros.fit_resample(X, Y)\ny_df = pd.DataFrame(y_resample)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:58:46.147312Z","start_time":"2021-04-05T07:58:46.095917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_df.value_counts()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T07:59:20.706126Z","start_time":"2021-04-05T07:59:20.689803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We could see the data is resampled now and all the type values are 41 now. Previously only type 1 was 41. We will split the resampled data into training and test data and build a KNN model","metadata":{}},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(x_resample, y_resample, test_size = .2, random_state = 30, stratify = y_resample)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T08:00:00.459969Z","start_time":"2021-04-05T08:00:00.448854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using GridSearch for Algorithm Tuning after resampling","metadata":{}},{"cell_type":"code","source":"n_neighbors = np.array(range(1,40))\nparam_grid = dict(n_neighbors=n_neighbors)\n\nmodel = KNeighborsClassifier()\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=10)\ngrid.fit(X_train, Y_train)\nprint(grid.best_params_)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T08:00:19.801464Z","start_time":"2021-04-05T08:00:17.07548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### After applying GridSearch, we got the best K (n_neighbors) value as 1, so we will be using the k= 1 for KNN Classifier algorithm","metadata":{}},{"cell_type":"markdown","source":"### Visualizing the accuracy with different k values on sampled data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \n%matplotlib inline\n# choose k between 1 to 41\nk_range = range(1, 41)\nk_scores = []\n# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, Y_train, cv=10)\n    k_scores.append(scores.mean())\n# plot to see clearly\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2021-04-05T08:00:34.842303Z","start_time":"2021-04-05T08:00:31.955728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The accuracy value is high for low values of k (less than 5) and it descreases as we increase values of k","metadata":{}},{"cell_type":"markdown","source":"# Using KNN with k=1 for model classification ","metadata":{}},{"cell_type":"markdown","source":"##### We had identified the k=1 is best parameter with GridSearch so using k as 1","metadata":{}},{"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors =1).fit(X_train,Y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)\nprint(accuracy)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T08:00:58.736258Z","start_time":"2021-04-05T08:00:58.70825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The accuracy is 1 which is 100% after applying sampling.  We will use confusion matrix and classification report to further check our accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(Y_test,y_pred)\nprint (confusion_matrix)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T08:01:12.728776Z","start_time":"2021-04-05T08:01:12.722424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test,y_pred))","metadata":{"ExecuteTime":{"end_time":"2021-04-05T08:01:28.337149Z","start_time":"2021-04-05T08:01:28.323445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We could see the precision and recall values is 1 for all 7 types which is an excellent score. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}