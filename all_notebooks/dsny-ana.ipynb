{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-30T13:43:15.269149Z","iopub.execute_input":"2021-08-30T13:43:15.269786Z","iopub.status.idle":"2021-08-30T13:43:15.282302Z","shell.execute_reply.started":"2021-08-30T13:43:15.269748Z","shell.execute_reply":"2021-08-30T13:43:15.281428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime,timedelta\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  # default='warn'\nplt.style.use('bmh')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:15.283849Z","iopub.execute_input":"2021-08-30T13:43:15.284364Z","iopub.status.idle":"2021-08-30T13:43:15.296399Z","shell.execute_reply.started":"2021-08-30T13:43:15.284329Z","shell.execute_reply":"2021-08-30T13:43:15.29541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataDSNY = pd.read_csv('/kaggle/input/dsny-20152017/311-DSNY-20151017.csv')\ndf = dataDSNY\n\n\n# Data size\nprint(df.shape)\nprint(df.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:15.298394Z","iopub.execute_input":"2021-08-30T13:43:15.299047Z","iopub.status.idle":"2021-08-30T13:43:26.06265Z","shell.execute_reply.started":"2021-08-30T13:43:15.298924Z","shell.execute_reply":"2021-08-30T13:43:26.061594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:26.064224Z","iopub.execute_input":"2021-08-30T13:43:26.064533Z","iopub.status.idle":"2021-08-30T13:43:27.44152Z","shell.execute_reply.started":"2021-08-30T13:43:26.064495Z","shell.execute_reply":"2021-08-30T13:43:27.440383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above informations we can already see that some features won't be relevant in our exploratory analysis as there are too much missing values (such as LAndmark, Vehicle Type, Road Ramp,Taxi Pick Up Location,Taxi Company Borough ...). It is better to concentrate on the features which can give us real insights. Let's just remove Unique Key and the features with 30% or less NaN values.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:27.443031Z","iopub.execute_input":"2021-08-30T13:43:27.443346Z","iopub.status.idle":"2021-08-30T13:43:27.733951Z","shell.execute_reply.started":"2021-08-30T13:43:27.443315Z","shell.execute_reply":"2021-08-30T13:43:27.732849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.count() does not include NaN values\ndf2 = df[[column for column in df if df[column].count() / len(df) >= 0.3]]\ndel df2['Unique Key']\nprint(\"List of dropped columns:\", end=\" \")\nfor c in df.columns:\n    if c not in df2.columns:\n        print(c, end=\", \")\nprint('\\n')\ndf = df2","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:27.735332Z","iopub.execute_input":"2021-08-30T13:43:27.735643Z","iopub.status.idle":"2021-08-30T13:43:29.216701Z","shell.execute_reply.started":"2021-08-30T13:43:27.735613Z","shell.execute_reply":"2021-08-30T13:43:29.215695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the possibility of missing Created Dates:","metadata":{}},{"cell_type":"code","source":"print(df['Created Date'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:29.218058Z","iopub.execute_input":"2021-08-30T13:43:29.21836Z","iopub.status.idle":"2021-08-30T13:43:29.282115Z","shell.execute_reply.started":"2021-08-30T13:43:29.218329Z","shell.execute_reply":"2021-08-30T13:43:29.280946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate the time difference between the close data and created date for each incident in minutes to be able to predict this time using other features. ","metadata":{}},{"cell_type":"code","source":"createdDate = df['Created Date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M:%S %p') if type(x)==str else np.NaN)\nclosedDate = df['Closed Date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M:%S %p') if type(x)==str else np.NaN)\ndeltaTime = pd.to_datetime(closedDate, errors = 'coerce')-pd.to_datetime(createdDate, errors = 'coerce')\ndf['minDifference'] = deltaTime.abs().astype('timedelta64[m]')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:29.286141Z","iopub.execute_input":"2021-08-30T13:43:29.286468Z","iopub.status.idle":"2021-08-30T13:43:48.750326Z","shell.execute_reply.started":"2021-08-30T13:43:29.286435Z","shell.execute_reply":"2021-08-30T13:43:48.749407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the minutes\ndf['minDifference'] = deltaTime.abs().dt.total_seconds()/60","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:48.752032Z","iopub.execute_input":"2021-08-30T13:43:48.752488Z","iopub.status.idle":"2021-08-30T13:43:48.787137Z","shell.execute_reply.started":"2021-08-30T13:43:48.752454Z","shell.execute_reply":"2021-08-30T13:43:48.786063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove Nans from dependent variable","metadata":{}},{"cell_type":"code","source":"print(df['minDifference'].isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:48.788678Z","iopub.execute_input":"2021-08-30T13:43:48.789139Z","iopub.status.idle":"2021-08-30T13:43:48.796767Z","shell.execute_reply.started":"2021-08-30T13:43:48.789089Z","shell.execute_reply":"2021-08-30T13:43:48.795644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check to see if there are missing closing dates and it means these cases are still open:","metadata":{}},{"cell_type":"code","source":"print(df['Closed Date'].isnull().sum())\nprint(df['minDifference'].max())\nprint(df['minDifference'].min())\n\ndf['minDifference'].replace({0: 11})\nprint(df['minDifference'].min())","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:48.798399Z","iopub.execute_input":"2021-08-30T13:43:48.798727Z","iopub.status.idle":"2021-08-30T13:43:48.876106Z","shell.execute_reply.started":"2021-08-30T13:43:48.798696Z","shell.execute_reply":"2021-08-30T13:43:48.87449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replace the missing time difference values with a large number to predict the cases that are still open","metadata":{}},{"cell_type":"code","source":"df['minDifference'].fillna(10000000,inplace = True)\n\ndf['minDifference'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:48.878156Z","iopub.execute_input":"2021-08-30T13:43:48.878655Z","iopub.status.idle":"2021-08-30T13:43:48.891211Z","shell.execute_reply.started":"2021-08-30T13:43:48.878599Z","shell.execute_reply":"2021-08-30T13:43:48.889975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transformation to scale the output values","metadata":{}},{"cell_type":"code","source":"# Histogram of time difference \ndf['logTime'] = np.log(df['minDifference'].replace(0, np.nan))\nplt.hist(df['logTime'])\nplt.title('Frequency Distribution of closing time')\nplt.ylabel('Number', fontsize=12)\nplt.xlabel('log time difference', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:48.893183Z","iopub.execute_input":"2021-08-30T13:43:48.893663Z","iopub.status.idle":"2021-08-30T13:43:49.15954Z","shell.execute_reply.started":"2021-08-30T13:43:48.893614Z","shell.execute_reply":"2021-08-30T13:43:49.158494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Month and year of the created date should be two important features for the modeling. We extracted them here. ","metadata":{}},{"cell_type":"code","source":"df['year'] = pd.to_datetime(createdDate, errors = 'coerce').dt.year.astype(int)\ndf['month'] = pd.to_datetime(createdDate, errors = 'coerce').dt.month.astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:49.160934Z","iopub.execute_input":"2021-08-30T13:43:49.161461Z","iopub.status.idle":"2021-08-30T13:43:49.443757Z","shell.execute_reply.started":"2021-08-30T13:43:49.161389Z","shell.execute_reply":"2021-08-30T13:43:49.442913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cityCount = df['City'].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(cityCount.index, cityCount.values, alpha=0.9)\nplt.title('Frequency Distribution of City')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('City', fontsize=12)\nplt.show()\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:49.445076Z","iopub.execute_input":"2021-08-30T13:43:49.445584Z","iopub.status.idle":"2021-08-30T13:43:50.448033Z","shell.execute_reply.started":"2021-08-30T13:43:49.445526Z","shell.execute_reply":"2021-08-30T13:43:50.446944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Label Encoding for Categorical Variables that should be important features as input to the predictive model. ","metadata":{}},{"cell_type":"code","source":"df['City'] = df['City'].astype('category')\ndf['City_code'] = df['City'].cat.codes\n\ndf['Complaint Type'] = df['Complaint Type'].astype('category')\ndf['Complaint Type_code'] = df['Complaint Type'].cat.codes\n\ndf['Location'] = df['Location'].astype('category')\ndf['Location_code'] = df['Location'].cat.codes\n\ndf['Community Board'] = df['Community Board'].astype('category')\ndf['Community Board_code'] = df['Community Board'].cat.codes\n\n\n\ndf['Agency Name'] = df['Agency Name'].astype('category')\ndf['Agency Name_code'] = df['Agency Name'].cat.codes\n\ndf['Open Data Channel Type'] = df['Open Data Channel Type'].astype('category')\ndf['Open Data Channel Type_code'] = df['Open Data Channel Type'].cat.codes\n\ndf['Borough'] = df['Borough'].astype('category')\ndf['Borough_code'] = df['Borough'].cat.codes\n\ndf['Park Borough'] = df['Park Borough'].astype('category')\ndf['Park Borough_code'] = df['Park Borough'].cat.codes\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:50.449472Z","iopub.execute_input":"2021-08-30T13:43:50.449842Z","iopub.status.idle":"2021-08-30T13:43:53.325892Z","shell.execute_reply.started":"2021-08-30T13:43:50.449793Z","shell.execute_reply":"2021-08-30T13:43:53.324616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Defining the input and output variables for the modeling","metadata":{}},{"cell_type":"code","source":"# columns of the final dataframe\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:53.330151Z","iopub.execute_input":"2021-08-30T13:43:53.330474Z","iopub.status.idle":"2021-08-30T13:43:53.342214Z","shell.execute_reply.started":"2021-08-30T13:43:53.330444Z","shell.execute_reply":"2021-08-30T13:43:53.340665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Features = ['year', 'month', 'City_code',\n       'Complaint Type_code', 'Location_code', 'Community Board_code',\n       'Borough_code', 'Park Borough_code', 'Agency Name_code',\n       'Open Data Channel Type_code']\nX = df[Features]\ny = df[['logTime']]","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:53.345013Z","iopub.execute_input":"2021-08-30T13:43:53.345589Z","iopub.status.idle":"2021-08-30T13:43:53.398728Z","shell.execute_reply.started":"2021-08-30T13:43:53.345527Z","shell.execute_reply":"2021-08-30T13:43:53.39774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"Impute missing data for modeling","metadata":{}},{"cell_type":"code","source":"#Impute missing data\nimputer = SimpleImputer(missing_values = np.nan, strategy = 'mean',verbose=0)\nimputer = imputer.fit(y)\ny = imputer.transform(y)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:53.400256Z","iopub.execute_input":"2021-08-30T13:43:53.40068Z","iopub.status.idle":"2021-08-30T13:43:53.423598Z","shell.execute_reply.started":"2021-08-30T13:43:53.400625Z","shell.execute_reply":"2021-08-30T13:43:53.422436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Deviding data to training and test sets for testing the performances of several modeling techniques","metadata":{}},{"cell_type":"code","source":" X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:53.425003Z","iopub.execute_input":"2021-08-30T13:43:53.425326Z","iopub.status.idle":"2021-08-30T13:43:53.500927Z","shell.execute_reply.started":"2021-08-30T13:43:53.425295Z","shell.execute_reply":"2021-08-30T13:43:53.499787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:53.502422Z","iopub.execute_input":"2021-08-30T13:43:53.502748Z","iopub.status.idle":"2021-08-30T13:43:53.651884Z","shell.execute_reply.started":"2021-08-30T13:43:53.502714Z","shell.execute_reply":"2021-08-30T13:43:53.650849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Linear Regression\n\nregr = linear_model.LinearRegression()\nregr.fit(X_train, y_train)\ny_pred = regr.predict(X_test)\n\n\nprint('Coefficients: \\n', regr.coef_)\n# The mean squared error\n\nprint('Mean squared error: %.2f'\n      % mean_squared_error(y_test, y_pred))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, y_pred))\n\n# Plot outputs\nplt.scatter(y_test, y_pred,  color='black')\nplt.xticks(())\nplt.yticks(())\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:53.653354Z","iopub.execute_input":"2021-08-30T13:43:53.653671Z","iopub.status.idle":"2021-08-30T13:43:54.337688Z","shell.execute_reply.started":"2021-08-30T13:43:53.653637Z","shell.execute_reply":"2021-08-30T13:43:54.336628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# identify outliers in the training dataset\niso = IsolationForest(contamination=0.1)\nyhat = iso.fit_predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:43:54.340756Z","iopub.execute_input":"2021-08-30T13:43:54.341087Z","iopub.status.idle":"2021-08-30T13:44:23.111316Z","shell.execute_reply.started":"2021-08-30T13:43:54.341056Z","shell.execute_reply":"2021-08-30T13:44:23.110309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# identify outliers in the training dataset (Second method)\nlof = LocalOutlierFactor()\nyhat = lof.fit_predict(X_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:44:23.11288Z","iopub.execute_input":"2021-08-30T13:44:23.113356Z","iopub.status.idle":"2021-08-30T13:44:35.320029Z","shell.execute_reply.started":"2021-08-30T13:44:23.113312Z","shell.execute_reply":"2021-08-30T13:44:35.318954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select all rows that are not outliers\nmask = yhat != -1\nprint(len(mask))\nprint(len(X_train))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:44:35.321409Z","iopub.execute_input":"2021-08-30T13:44:35.321735Z","iopub.status.idle":"2021-08-30T13:44:35.328587Z","shell.execute_reply.started":"2021-08-30T13:44:35.321702Z","shell.execute_reply":"2021-08-30T13:44:35.327281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train[mask]\nX_train = X_train[mask]","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:44:35.330007Z","iopub.execute_input":"2021-08-30T13:44:35.330319Z","iopub.status.idle":"2021-08-30T13:44:35.357937Z","shell.execute_reply.started":"2021-08-30T13:44:35.33029Z","shell.execute_reply":"2021-08-30T13:44:35.356805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize the shape of the updated training dataset\nprint(X_train.shape, y_train.shape)\n# fit the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n# evaluate the model\nyhat = model.predict(X_test)\n# evaluate predictions\nmae = mean_absolute_error(y_test, yhat)\nprint('MAE: %.3f' % mae)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:44:35.359272Z","iopub.execute_input":"2021-08-30T13:44:35.359598Z","iopub.status.idle":"2021-08-30T13:44:35.456031Z","shell.execute_reply.started":"2021-08-30T13:44:35.359568Z","shell.execute_reply":"2021-08-30T13:44:35.454552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot outputs\nplt.scatter(y_test, yhat,  color='blue')\nplt.xticks(())\nplt.yticks(())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:44:35.458049Z","iopub.execute_input":"2021-08-30T13:44:35.458518Z","iopub.status.idle":"2021-08-30T13:44:35.865004Z","shell.execute_reply.started":"2021-08-30T13:44:35.458465Z","shell.execute_reply":"2021-08-30T13:44:35.863679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Outlier removal was not helpful for linear modeling","metadata":{}},{"cell_type":"markdown","source":"Linear regression doesn't show a good performance for this model. So, let's try Random Forest as a non linear regression technique ","metadata":{}},{"cell_type":"code","source":"# RAndorm Forest Regression\nregressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nregressor.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:44:35.866371Z","iopub.execute_input":"2021-08-30T13:44:35.86678Z","iopub.status.idle":"2021-08-30T13:44:57.177853Z","shell.execute_reply.started":"2021-08-30T13:44:35.866743Z","shell.execute_reply":"2021-08-30T13:44:57.176669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the forest's predict method on the test data\npredictions = regressor.predict(X_test)\n# Calculate the absolute errors\nerrors = abs(predictions - y_test)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'min.')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T13:44:57.179463Z","iopub.execute_input":"2021-08-30T13:44:57.179784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimportance = regressor.feature_importances_\nimportance = pd.DataFrame(importance, index=pd.Index(Features),columns=[\"Importance\"])\nimportance[\"Std\"] = numpy.std([tree.feature_importances_\n                            for tree in clf_RF.estimators_], axis=0)\n\n#x = range(importance.shape[0])\n#    x = df.columns\nx = pd.Index(features)\ny = importance.iloc[:, 0]\nyerr = importance.iloc[:, 1]\nplt.figure(figsize=(10,7))\nplt.barh(x, y, align=\"center\")\nplt.gca().invert_yaxis()\nplt.title('Feature importance')\nplt.xlabel('Importance')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}