{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Questions to be answered:\n1. Find correlation between months and forest fire occurence?\n2. Can we omit the day column?\n3. Perform statistical analysis of the variable count spilt between fire and non-fire area\n<br>*Not useful since range of each feature varies*\n4. Does multi-dimensional visualization of the columns provide any insight?\n<br>*PCA or Parallel Coordinates do not provide insight into classification between fire and non-fire areas*\n5. Can forest fire occurence be modelled using only [temp, rain, RH, area]?\n<br>*Done*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fires = pd.read_csv('../input/forest-forest-dataset/forestfires.csv')\nfires['areaclass'] = [0 if val==0.0 else 1 for val in fires['area']]\nfires.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt \n\ny = fires['areaclass']\nx = fires.drop(['areaclass','area','month','day','X','Y'],axis=1)\n\nxnorm = (x - x.min()/x.max()-x.min())\n\n# 2-dimensional PCA\npca = PCA(n_components=2)\ntrans = pd.DataFrame(pca.fit_transform(xnorm))\n\nplt.scatter(trans[y==0][0], trans[y==0][1], label='non-fire area', c='green')\nplt.scatter(trans[y==1][0], trans[y==1][1], label='fire area', c='blue')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Find the features having the highest magnitude in the Principal Components ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(x)\nx = scaler.transform(x)\n\npca = PCA()\nxnew = pca.fit_transform(x)\n\ndef myplot(score,coeff,labels=None):\n    xs = score[:,0]\n    ys = score[:,1]\n    n = coeff.shape[0]\n    scalex = 1.0/(xs.max() - xs.min())\n    scaley = 1.0/(ys.max() - ys.min())\n    plt.scatter(xs * scalex,ys * scaley, c = y)\n    for i in range(n):\n        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.2)\n        if labels is None:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n        else:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')\n\nplt.xlim(-1,1)\nplt.ylim(-1,1)\nplt.xlabel(\"PC{}\".format(1))\nplt.ylabel(\"PC{}\".format(2))\nplt.grid()\n\n#Call the function. Use only the 2 PCs.\nmyplot(xnew[:,0:2],np.transpose(pca.components_[0:2, :]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_\n# print(abs( pca.components_ ))\n# np.transpose(pca.components_[0:2, :]).shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Out of the 8 principal components, the first 4 account for close to 77% variability in the model. Therefore, let's try to fit a linear regresion model using the features contributing the most to the first 4 principal components.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = PCA(n_components=4).fit(x)\nX_pc = model.transform(x)\n\n# number of components\nn_pcs= model.components_.shape[0]\n\n# get the index of the most important feature on EACH component\n# LIST COMPREHENSION HERE\nmost_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n\ninitial_feature_names = ['FFMC','DMC','DC','ISI','temp','RH','wind','rain']\n# get the names\nmost_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n\n# LIST COMPREHENSION HERE AGAIN\ndic = {'PC{}'.format(i): most_important_names[i] for i in range(n_pcs)}\n\n# build the dataframe\ndf = pd.DataFrame(dic.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the first 4 principal components, the features having largest absolute coefficients in the projected axis are **temp**(PC1), **RH**(PC2), **wind**(PC3), **rain**(PC4).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Parallel Coordinates ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import parallel_coordinates\n\nplotcols = ['temp','RH','wind','rain','FFMC','DMC','DC','ISI']\ndata_norm = pd.concat([xnorm[plotcols],y],axis=1)\nparallel_coordinates(data_norm,'areaclass')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\n\n# considering only relevant columns\nlinearcols = ['month','temp','RH','wind','rain','FFMC','DMC','DC','ISI']\ndatafires = fires[linearcols]\n\n# label encoding for 'month' column\nle = LabelEncoder()\nxdata = datafires.apply(le.fit_transform)\nxreg = xdata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score, recall_score\n\nyreg = fires['area']\n\nxtrain, xtest, ytrain, ytest = train_test_split(xreg,yreg)\n\n#fittiing the model\nregressor = LinearRegression(fit_intercept=False)\nregressor.fit(xtrain,ytrain)\nyregpred = regressor.predict(xtest)\n\n#results\nprint('Coefficient of determination r^2: %.2f' % r2_score(ytest,yregpred))\nprint('RMSE: %.2f' % mean_squared_error(ytest,yregpred,squared=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrresults = pd.DataFrame(yregpred,ytest)\nlrresults.reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression using Polynomial Basis Functions ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\npoly_model = make_pipeline(PolynomialFeatures(5),LinearRegression())\npoly_model.fit(xtrain,ytrain)\nypolyfit = poly_model.predict(xtest)\n\nplt.plot(xtest,ypolyfit)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression with log(forest_fire_area)  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fires['logarea'] = np.log10(fires['area'])\nfires.replace([np.inf,-np.inf],0.0,inplace=True)\n\nylog = fires['logarea']\nxlog = xdata\n\nxltrain,xltest,yltrain,yltest = train_test_split(xlog,ylog)\nlogregressor = LinearRegression()\nlogregressor.fit(xltrain,yltrain)\nylogpred = logregressor.predict(xltest)\n\n#results\nprint('Coefficient of determination r^2: %.2f' % r2_score(yltest,ylogpred))\nprint('RMSE: %.2f' % mean_squared_error(yltest,ylogpred,squared=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression using columns *temp, RH, wind, rain* to predict log(forest_fire_area)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pcacols = ['temp','RH','wind','rain']\ndatax = fires[pcacols]\ndatay = fires['logarea']\n\npcaxtrain, pcaxtest, pcaytrain, pcaytest = train_test_split(datax,datay)\npcaregressor = LinearRegression()\npcaregressor.fit(pcaxtrain,pcaytrain)\npcaypred = pcaregressor.predict(pcaxtest)\n\n#results\nprint('Coefficient of determination r^2: %.2f' % r2_score(pcaytest,pcaypred))\nprint('RMSE: %.2f' % mean_squared_error(pcaytest,pcaypred,squared=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Coefficients: \\n',pcaregressor.coef_)\nprint('Intercept: \\n',pcaregressor.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multidimensional Visualization with *temp, RH* features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['temp','RH']\nX = fires[cols].values.reshape(-1,2)\nY = fires['logarea']\nxvtrain,xvtest,yvtrain,yvtest = train_test_split(X,Y)\n\nx = xvtrain[:,0]\ny = xvtrain[:,1]\nz = yvtrain\n\nxx_pred, yy_pred = np.meshgrid(xvtest[:,0], xvtest[:,1])\nmodel_viz = np.array([xx_pred.flatten(), yy_pred.flatten()]).T\n\nols = LinearRegression()\nmodel = ols.fit(xvtrain, yvtrain)\npredicted = model.predict(model_viz)\n\n############################################ Evaluate ############################################\n\nr2 = model.score(xvtrain, yvtrain)\n\n############################################## Plot ################################################\n\nplt.style.use('default')\n\nfig = plt.figure(figsize=(12, 4))\n\nax1 = fig.add_subplot(131, projection='3d')\nax2 = fig.add_subplot(132, projection='3d')\nax3 = fig.add_subplot(133, projection='3d')\n\naxes = [ax1, ax2, ax3]\n\nfor ax in axes:\n    ax.plot(x, y, z, color='k', zorder=15, linestyle='none', marker='o', alpha=0.5)\n    ax.scatter(xx_pred.flatten(), yy_pred.flatten(), predicted, facecolor=(0,0,0,0), s=20, edgecolor='#70b3f0')\n    ax.set_xlabel('Temperature', fontsize=12)\n    ax.set_ylabel('Relative Humidity', fontsize=12)\n    ax.set_zlabel('log(forest fire area)', fontsize=12)\n    ax.locator_params(nbins=4, axis='x')\n    ax.locator_params(nbins=5, axis='x')\n\nax1.view_init(elev=28, azim=120)\nax2.view_init(elev=4, azim=114)\nax3.view_init(elev=60, azim=165)\n\nfig.suptitle('$R^2 = %.2f$' % r2, fontsize=20)\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Conclusion \nUsing only *temp, RH* features to model the data is not efficient, as it captures only 50% of variability in the data. Thus, *linear regression* is unable to capture the potentially non-linear relationship between the features and the forest fire area.\n\nAlso, *temp* and *RH* are inversely correlated (refer correlation matrix below). Hence, this may a cause for collinearity which may suggest poor performance of the model with *temp, RH* predicting the forest fire area.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\ndf = fires.iloc[:,4:-3]\n\ncorr = df.corr(method='spearman')\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(6, 5))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True, sep=100)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0, linewidths=.5)\n\nfig.suptitle('Correlation matrix of features', fontsize=10)\nfig.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}