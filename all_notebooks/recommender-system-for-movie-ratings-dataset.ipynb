{"cells":[{"metadata":{},"cell_type":"markdown","source":"# WHAT'S THIS NOTEBOOK ABOUT?\n\n\nThis notebook is a practical introduction to the main Recommender System (RecSys) techniques. The objective of a RecSys is to recommend relevant items for users, based on their preference. Preference and relevance are subjective, and they are generally inferred by items users have consumed previously.\n\nthe dataset i'm using is a popular one called [movielens100k](https://www.kaggle.com/rajmehra03/movielens100k) that contains 3 tables: movies,ratings,tags.\n\nsince the data is **explicit**, for simplicity we will use the python package [Surprise](http://http://surpriselib.com/)\n\nfirst, we will explore our data just to get an idea about it. We will define a class to evaluate our models and finally, we will train every model and compare them at then end."},{"metadata":{"_uuid":"782de0ec-0942-436f-a0ed-b441ee213ff4","_cell_guid":"ca276370-1380-4bf2-970a-d0f9b981d7f9","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn import preprocessing\nimport scipy\nimport random\n\nfrom surprise import AlgoBase, Reader\nfrom surprise import Dataset\nfrom surprise.model_selection import cross_validate,train_test_split, GridSearchCV\n\nfrom sklearn.model_selection import train_test_split as sklearn_train_test_split\n\n# models\nfrom surprise import KNNWithZScore, SVD\n\n\npd.set_option('display.max_colwidth', None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c45fab9-5b50-49ab-bb84-76943893456f","_cell_guid":"a7f3ddc4-d3f7-468f-b081-5546b5df4e12","trusted":true},"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS"},{"metadata":{"_uuid":"bf2d2b35-9514-4904-89c0-e89fe5d40e78","_cell_guid":"3fb3631e-82b7-42ab-ab63-d9ad7f3ddba7","trusted":true},"cell_type":"markdown","source":"## THE MOVIES DATASET\n\nlets start exploring our movies dataset.\nfirst we check if there's any NaN value."},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_data = pd.read_csv(\"../input/movielens100k/movies.csv\")\nmovies_data.drop_duplicates(subset =\"title\",keep='first',inplace=True,ignore_index=True) \nmovies_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78be2b26-ef22-4fe9-b9bb-1b55c370a4aa","_cell_guid":"2e5ed1e3-ee5e-4833-924d-5d811c8d96a6","trusted":true},"cell_type":"code","source":"# we check if there's empty values\nplt.figure(figsize=(8,4))\nsns.heatmap(movies_data.isna(), cbar=False, yticklabels=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d4f4102-edf3-439a-9aad-cea127661441","_cell_guid":"4a4379c9-341a-40b1-bf7e-f97cf078324d","trusted":true},"cell_type":"code","source":"# we remove ('no genre listed') from the genres list.\nNO_GENRE_LISTED = \"(no genres listed)\"\nmovies_data[\"genres\"] = movies_data[\"genres\"].apply(lambda genres: [ genre for genre in genres.split('|') if genre != NO_GENRE_LISTED ])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45397a33-e73b-4b81-8277-38ef31f80622","_cell_guid":"74c5d409-7bb9-418a-9e0a-69bc2a3ac9c7","trusted":true},"cell_type":"code","source":"# we drop rows with na values.\nmovies_data = movies_data.dropna()\nmovies_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c5126e9-1b8b-4eaa-b8d4-5a787d630c07","_cell_guid":"b77c05ab-995f-4b5b-88d3-13cf9f316375","trusted":true},"cell_type":"code","source":"genres_merged = movies_data[\"genres\"].apply(lambda genres: \" \".join(genres))\ngenres_vectorizer = CountVectorizer(token_pattern=\"(?u)\\\\b[\\\\w-]+\\\\b\")\ngenres_count_matrix = genres_vectorizer.fit_transform(genres_merged.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"319b7f17-9d41-41ed-b3a2-6c49d139aa12","_cell_guid":"ff4124f2-d034-44ba-976c-d0422f7abb24","trusted":true},"cell_type":"code","source":"print(\"there are {} genres of movies\".format(len(genres_vectorizer.vocabulary_)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fc2680e-80be-4180-ad88-69998f1b34bc","_cell_guid":"12602ed4-f233-4d8e-9db1-bc237e7634dc","trusted":true},"cell_type":"code","source":"summed_movie_genres = genres_vectorizer.vocabulary_\nplt.figure(figsize=(40,10))\nplt.bar(summed_movie_genres.keys(), summed_movie_genres.values())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c381800-93ae-4e6f-8cca-efe3397db1c8","_cell_guid":"ae789718-432b-4d92-9abb-cea709ea532a","trusted":true},"cell_type":"markdown","source":"## THE RATINGS DATASET\n\nlet's explore the ratings data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_data = pd.read_csv(\"../input/movielens100k/ratings.csv\")\nratings_data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fcda14a-7a23-484a-8e17-4ec83027d103","_cell_guid":"e374a9e4-31cc-4e03-9748-7b82e744822d","trusted":true},"cell_type":"code","source":"ratings_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a98b6d4-726b-4663-a6e9-0619c1428f1e","_cell_guid":"d90d03ec-6685-46ee-9bf8-c6470bece4f0","trusted":true},"cell_type":"code","source":"ratings_data = ratings_data[ratings_data[\"movieId\"].isin(movies_data[\"movieId\"])]\nratings_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88574400-a7dd-411e-86a2-260873a94d37","_cell_guid":"bb7964ca-80a8-43f5-8233-1ddc94310906","trusted":true},"cell_type":"markdown","source":"let's see the distribution of mean ratings in our dataset"},{"metadata":{"_uuid":"3461e19c-f5f4-4abe-bc0a-e6bdcc5f389b","_cell_guid":"1c22a4a2-fdd7-4b7b-aeb9-10db0e2b4c65","trusted":true},"cell_type":"code","source":"movies_mean_ratings = ratings_data.groupby(['movieId'],as_index=False)[\"rating\"].mean()\nplt.figure(figsize=(12, 6))\nsns.distplot(movies_mean_ratings[\"rating\"], bins=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22890aa7-e2a1-42f0-9210-fe2f06c96bd2","_cell_guid":"83ccb956-a900-42f6-b840-3ddb650a4390","trusted":true},"cell_type":"markdown","source":"as we can see, most of the movies are rated between 3 and 4.\n\nlet's finish this data analysis by exploring user's interactions distribution."},{"metadata":{"_uuid":"33b0f953-8ea6-4017-83dc-27bb9e335b07","_cell_guid":"fcd53587-7f51-44f5-b39c-8a96e4f1897c","trusted":true},"cell_type":"code","source":"user_interactions = pd.DataFrame(columns=['userId','interactions'])\n\nuser_interactions[\"userId\"] = ratings_data[\"userId\"]\nuser_interactions[\"interactions\"] = 0\n\nuser_interactions = user_interactions.groupby(['userId'],as_index=False).agg({ 'userId' : 'first' , 'interactions': 'count' }) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ec3a138-65eb-4940-b16d-7e97e9e4c5d1","_cell_guid":"bed874f4-6b39-4670-9e03-141fb866fd60","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.distplot(user_interactions[\"interactions\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1fb5d0d-9eb3-4c77-8d10-ea69714baf49","_cell_guid":"dcb33eda-7f6a-40d0-9f05-18fe917a17b0","trusted":true},"cell_type":"markdown","source":"# EVALUATING OUR MODELS, HOW?"},{"metadata":{"_uuid":"d8b6020d-4bba-4d9f-9d5b-b441ef07088e","_cell_guid":"3bae34fc-393f-4548-b0b5-49377c08077e","trusted":true},"cell_type":"markdown","source":"to evaluate recommender systems, we will use the **Recall@N** evaluation metric used in this [paper](https://www.researchgate.net/publication/221141030_Performance_of_recommender_algorithms_on_top-N_recommendation_tasks)\n\nthis is how will we proceed:\n\n```\n- for each user\n\n    - for each item rated as \"good\" from our test set\n    \n        - sample X other items the user has never interacted with ( we assume that they are irrelevant).\n        - we merge the X items and the targeted item in one list.\n        - using the model, we rank our X+1 items.\n        - we form top-N recommendations.\n        - if our target item belongs to the top-N recommendation, it's a hit, otherwise it's a miss.\n    \n    - calculate the metric for the user\n    \n- calculate the mean metric of all users.\n\n```\n\nlet's code our evaluator class"},{"metadata":{"_uuid":"08698866-8f61-41af-95cc-be89f4d49096","_cell_guid":"dab4760b-8a3b-4d5c-98a6-e17a4156a3ec","trusted":true},"cell_type":"code","source":"EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 50\n\nclass RecallEvaluator:\n    \n    def __init__(self,items,trainset,testset):\n        self.items = items\n        self.trainset = trainset\n        self.testset = testset\n        \n    def get_favorite_items_from_testset(self,user_id):\n        \n        # calculate them mean rating of the user from the test set.\n        mean_rating = np.mean([rating for (_,rating) in self.trainset.ur[user_id]])\n        return [item for (user,item,rating) in self.testset if rating > mean_rating and user == user_id]\n\n    def get_interacted_items_from_testset(self,user_id):\n        return [item for (user,item,_) in testset if user == user_id]\n    \n    def get_interacted_items_from_trainset(self,user_id):\n        return [item for (item,_) in trainset.ur[user_id]]\n    \n    def get_not_interacted_items(self, user_id, size, seed=42):\n            \n        interacted_items = self.get_interacted_items_from_testset(user_id)\n        non_interacted_items = list(set(self.items) - set(interacted_items))\n        random.seed(seed)\n        non_interacted_items = random.sample(non_interacted_items,size)\n        return set(non_interacted_items)\n    \n    def verify_top_n_hits(self, item_id, recommendations, topn):    \n            try:\n                index = recommendations.index(item_id)\n            except:\n                index = -1\n            hit = int(index in range(0, topn))\n            return hit\n    \n    def recommend_to_evaluate(self,user_id,model):\n         \n            # get all the items that the user didn't interact with YET from the full item list\n            non_interacted_items = list(set(self.items) - set(self.get_interacted_items_from_trainset(user_id)))\n            recommendations = [model.predict(user_id,item) for item in non_interacted_items]\n            recommendations.sort(key=lambda x: x.est, reverse=True)\n            return recommendations\n            \n    \n    def evaluate_model_for_user(self,user_id,model,topn):\n        \n        #Getting the items in test set that the user \"like\"\n        favorite_items_testset = self.get_favorite_items_from_testset(user_id)\n        \n        favorite_items_count_testset = len(favorite_items_testset)\n        \n        if favorite_items_count_testset == 0:\n            return [(0,0,0)] * len(topn)\n        \n        user_recommendations = [prediction.iid for prediction in self.recommend_to_evaluate(user_id,model)]        \n        \n        # we initialize our hits count\n        hits_count = [0] * len(topn)\n        \n        #For each item the user likes in the test set\n        for item_id in favorite_items_testset:\n            \n            # we generate a random sample of #EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS movies that the user didn't interact with.\n            non_interacted_items = self.get_not_interacted_items(user_id,size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS,seed=item_id%(2**32))\n            \n            # we combine them with the relevant item.\n            items_to_filter_recs = non_interacted_items.union(set([item_id]))\n            \n            # we recommend movies to the user, these recommendations are sorted, we pick only the X+1 items.\n            valid_recommendations = [recommended_item for recommended_item in user_recommendations if recommended_item in items_to_filter_recs]\n                        \n            #Verifying if the current interacted item is among the Top-N recommended items\n            hits = [self.verify_top_n_hits(item_id,valid_recommendations,t) for t in topn]\n            hits_count = np.add(hits_count, hits)\n            \n            \n        recall = [hit_count/float(favorite_items_count_testset) for hit_count in hits_count]\n        return [(rec,hit_count,favorite_items_count_testset) for rec,hit_count in zip(recall,hits_count)]\n    \n    \n    def evaluate_model(self,model,topn,model_name):\n            \n        #key names of the user metrics\n        keys = ['recall@{}'.format(t) for t in topn]\n        users_metrics = []\n        users_in_testset = set([user for (user,_,_) in self.testset])\n        \n        for user_id in tqdm(users_in_testset,total=len(users_in_testset)-1):\n          \n            user_metrics = [user_id] + self.evaluate_model_for_user(user_id,model,topn)  \n            users_metrics.append(user_metrics)\n            \n        user_recalls = pd.DataFrame(users_metrics,columns=[\"user_id\"] + keys)\n        \n        global_recall = {}\n        \n        for key in keys:\n            \n            hits_sum = np.sum([hit_count for _,(_,hit_count,_) in user_recalls[key].items()])\n            interaction_counts = np.sum([interaction_count for _,(_,_,interaction_count) in user_recalls[key].items()])\n            global_recall[key] = hits_sum / float(interaction_counts)\n            \n        global_metrics = {**{'model': model_name}, **global_recall} \n        return global_metrics, user_recalls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RECOMMENDATIONS MODELS AND EVALUATIONS"},{"metadata":{},"cell_type":"markdown","source":"## SPLITTING THE DATA\n\nlet's first split our data using the surprise built-in method **train_test_split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"reader = Reader(rating_scale=(1, 5))\ndata = Dataset.load_from_df(ratings_data[['userId', 'movieId', 'rating']], reader)\n\ntraindf, testdf = sklearn_train_test_split(ratings_data[['userId', 'movieId', 'rating']],\n                                   stratify=ratings_data['userId'], \n                                   test_size=0.25,\n                                   random_state=42)\n\n\ntrain = Dataset.load_from_df(traindf, reader)\ntest = Dataset.load_from_df(testdf, reader)\n\ntrainset = train.build_full_trainset()\n_,testset = train_test_split(test,train_size=None)\n\nmovies_id = movies_data[\"movieId\"].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we then initialize our evaluator."},{"metadata":{"trusted":true},"cell_type":"code","source":"recall_evaluator = RecallEvaluator(movies_id,trainset,testset)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"683c91e6-2fe7-443b-a613-010cb2bc9b83","_cell_guid":"3baa497d-612a-4454-a09e-5d75ac71e0e2","trusted":true},"cell_type":"markdown","source":"# POPULARITY BASED MODEL"},{"metadata":{"_uuid":"42c79697-f52e-4d77-80f6-ecb4cf2ea755","_cell_guid":"b23b572b-a038-4a7f-8a2e-c3a70eb5e616","trusted":true},"cell_type":"markdown","source":"this model recommends the most popular movies to all users."},{"metadata":{"trusted":true},"cell_type":"code","source":"class PopularRecSys(AlgoBase):\n\n    def __init__(self):\n        AlgoBase.__init__(self)\n\n    def fit(self, trainset):\n        \n        AlgoBase.fit(self, trainset)\n        # we compute the ratings mean for each item.\n        # the results are stored in a top_rating attribute\n        \n        self.popular = {}  # a tuple where the key is the item raw id, the value is the views count\n        \n        for item_id in trainset.all_items():\n\n            views = len(trainset.ir[item_id])\n            self.popular[item_id] = views\n\n        return self\n\n    def estimate(self, u, i):\n\n        if self.trainset.knows_item(i):\n            return self.popular[i]\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"popularRecSys = PopularRecSys()\npopularRecSys.fit(trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"popularRecSys_metrics,_ = recall_evaluator.evaluate_model(topn=[5,8,10],model=popularRecSys,model_name='popular')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(popularRecSys_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since this model doesn't estimate ratings, we won't show the accuracy."},{"metadata":{"_uuid":"5e7eb1e2-77c5-4b8b-97d3-76dc54b66898","_cell_guid":"5d773693-37d0-484e-bce7-ce3fdffe16c1","trusted":true},"cell_type":"markdown","source":"# TOP-RATED BASED MODEL"},{"metadata":{"_uuid":"863528da-2f0b-4f4e-ae0e-ef755d2bc940","_cell_guid":"34e84c52-1b4b-4537-83e4-07e0373abb7f","trusted":true},"cell_type":"markdown","source":"how the top rating model works?\n\n```\n- we get the top rating movies and we recommend them to the user\n\n- to get the top rated movies:\n    - we calculate the adjusted average.\n    - we rank them.\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TopRatedRecSys(AlgoBase):\n\n    def __init__(self):\n        AlgoBase.__init__(self)\n\n    def fit(self, trainset):\n        \n        AlgoBase.fit(self, trainset)\n        # we compute the ratings mean for each item.\n        # the results are stored in a top_rating attribute\n        \n        self.top_rating = {}  # a tuple where the key is the item raw id, the value is the estimated rating\n        \n        for item_id in trainset.all_items():\n\n            adjusted_mean = (np.sum([r for (_,r) in trainset.ir[item_id]]) + 5) / (len([r for (_,r) in trainset.ir[item_id]]) + 5)\n            self.top_rating[item_id] = adjusted_mean\n\n        return self\n\n    def estimate(self, u, i):\n\n        if self.trainset.knows_item(i) and self.trainset.knows_user(u) :\n            return self.top_rating[i]\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topRatedRS = TopRatedRecSys()\ntopRatedRS.fit(trainset)\ntopRatedRS_metrics , _ = recall_evaluator.evaluate_model(topn=[5,8,10],model=topRatedRS,model_name='top rated')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(topRatedRS_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topRatedRS_cv = cross_validate(topRatedRS, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COLLABORATIVE FILTERING\n\n\nbased on this [website](https://www.sciencedirect.com/topics/computer-science/collaborative-filtering) there are 2 CF RecSys approaches ( memory-based & model-based )"},{"metadata":{},"cell_type":"markdown","source":"## MEMORY-BASED CF\n\nwe will implement 2 types of memory based CF : user-to-user and item-to-item. both are based on the K-NN with rating means. you check about it in this [article](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)"},{"metadata":{},"cell_type":"markdown","source":"let's start with the user to user method. to calculate similarity/distance we will use cosine."},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_options_ub = {'name': 'cosine','user_based': True}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNNWithZscore_ub = KNNWithZScore(k=4,min_k=3,sim_options=sim_options_ub)\nKNNWithZscore_ub.fit(trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNNWithZscore_ub_metrics , _ = recall_evaluator.evaluate_model(topn=[5,8,10],model=KNNWithZscore_ub,model_name='K-NN with z-score [user-based]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(KNNWithZscore_ub_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNNWithZscore_ub_cv = cross_validate(KNNWithZscore_ub, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now, let's implement the item-to-item model"},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_options_ib = {'name': 'cosine','user_based': False}\nKNNWithZscore_ib = KNNWithZScore(k=4,min_k=3,sim_options=sim_options_ib)\nKNNWithZscore_ib.fit(trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNNWithZscore_ib_metrics , _ = recall_evaluator.evaluate_model(topn=[5,8,10],model=KNNWithZscore_ib,model_name='K-NN with z-score [item-based]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(KNNWithZscore_ib_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNNWithZscore_ib_cv = cross_validate(KNNWithZscore_ib, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"as we can see, the user-based CF performed better than the item-based one."},{"metadata":{},"cell_type":"markdown","source":"## MODEL-BASED CF\n\none the most popular model-based algorithms is SVD. more information about this algorithm [here](https://developers.google.com/machine-learning/recommendation/collaborative/matrix)\n\nthanks to the surprise library, we can test with different parameters and pick the best."},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'n_epochs': [10,20,30], 'lr_all': [0.002, 0.005]}\ngrid_search = GridSearchCV(SVD, param_grid,measures=['MAE','RMSE'],cv=3,refit=True)\ngrid_search.fit(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svd_metrics , _ = recall_evaluator.evaluate_model(topn=[5,8,10],model=grid_search,model_name='SVD')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(svd_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"as we can see, the SVD algorithm performed better than both versions of KNN with 63% of recall@8 and 68% recall@10"},{"metadata":{},"cell_type":"markdown","source":"# FINAL RESULTS\n\nlet's plot the algorithms along with their recall values"},{"metadata":{"trusted":true},"cell_type":"code","source":"global_metrics = pd.DataFrame([popularRecSys_metrics,topRatedRS_metrics,KNNWithZscore_ub_metrics,KNNWithZscore_ib_metrics,svd_metrics]).set_index('model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nax = global_metrics.transpose().plot(kind='bar', figsize=(15,8))\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION\n\nin this notebook we explored different algorithms using the **surprise** library and we concluded that:\n\n- K-NN algorithms performed poorly.\n- the top-rating algorithm has the highest recall because we have a small dataset (only 9k movies and 100k).\n\nwhat to do now?\n\n- create a content-based model and compare it to others\n- create a hybrid model by combining different algorithms\n- take rating time into consideration ( time-aware RecSys ). more infos on this [paper](https://www.scitepress.org/Papers/2017/63126/63126.pdf)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}