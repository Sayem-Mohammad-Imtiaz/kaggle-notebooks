{"cells":[{"metadata":{},"cell_type":"markdown","source":"ESPECIALIZAÇÃO EM INTELIGÊNCIA ARTIFICIAL\nMÓDULO: FUNDAMENTOS DE INTELIGÊNCIA ARTIFICIAL\nProf. Tatiana Tavares\n\n# Entrega final\n\nInstruções: em dupla - entrega dia 19/Março – apresentar 08/03 na última aula\nModos de entrega - enviar para: tatitavares8@gmail.com ou \nlink do googledrive com dados e jupyter ou link do git com dados e jupyter.\n\nEm sala utilizamos sklearn. Utilizando a toolbox de sua preferência, realize o treinamento de uma rede neural artificial do tipo Perceptron Multicamadas para resolver um problema de classificação multiclasses ou uma ML do tipo k-means para a clusterização.\n\nAlém do conjunto de treinamento, considere um conjunto de teste para avaliação final do método. \n\nDescreva as características dos dados, descreva as características da ML (dimensão, número de camadas, números de clusters), forma de divisão dos dados para treinamento, validação e teste e discuta aspectos de desempenho (porcentagem de classificação correta, matriz de confusão). \n\nEscolher um banco de dados de qualquer natureza (imagem, série temporal, dados de comércio, dados bancários, etc); \n\nFazer pré-processamento (se necessário); \n\nClassificação ou Clusterização com um dos algoritmos estudados.\n\nUsar validação cruzada para separar dados de treino e validação e matriz de confusão para cálculo das métricas.\n\nIMPORTANTÍSSIMO: \n\nContextualizar sua classificação ou clusterização, qual o problema a ser solucionado com os seus resultados?\n\nLevantar as dificuldades, limitações, inconsistências e imprecisões nas soluções propostas.\n\nSugerir futuras implementações.\n\nPara o seu banco de dados existem outros trabalhos de classificação na literatura? \n\t\n"},{"metadata":{},"cell_type":"markdown","source":"O banco de dados do Human Activity Recognition foi construído a partir das gravações de 30 participantes do estudo realizando atividades de vida diária (AVD) enquanto carregavam um smartphone montado na cintura com sensores inerciais embutidos. O objetivo é classificar as atividades em uma das seis atividades realizadas.\n\nDescrição do experimento\nOs experimentos foram realizados com um grupo de 30 voluntários em uma faixa etária de 19 a 48 anos. Cada pessoa realizou seis atividades (ANDAR, subir escadas, descer escadas, SENTAR, FICAR EM PÉ, DEITADO) usando um smartphone (Samsung Galaxy S II) na cintura. Usando seu acelerômetro e giroscópio embutidos, capturamos a aceleração linear 3-axial e a velocidade angular 3-axial a uma taxa constante de 50Hz. Os experimentos foram gravados em vídeo para rotular os dados manualmente. O conjunto de dados obtido foi particionado aleatoriamente em dois conjuntos, onde 70% dos voluntários foram selecionados para gerar os dados de treinamento e 30% os dados de teste.\n\nOs sinais do sensor (acelerômetro e giroscópio) foram pré-processados ​​pela aplicação de filtros de ruído e, em seguida, amostrados em janelas deslizantes de largura fixa de 2,56 seg e sobreposição de 50% (128 leituras / janela). O sinal de aceleração do sensor, que tem componentes gravitacionais e de movimento corporal, foi separado por meio de um filtro passa-baixo Butterworth na aceleração e gravidade do corpo. A força gravitacional é considerada como tendo apenas componentes de baixa frequência, portanto, um filtro com frequência de corte de 0,3 Hz foi usado. De cada janela, um vetor de características foi obtido pelo cálculo de variáveis ​​do domínio do tempo e da frequência.\n\nInformação de atributo\nPara cada registro no conjunto de dados, o seguinte é fornecido:\n\nAceleração triaxial do acelerômetro (aceleração total) e a aceleração corporal estimada.\n\nVelocidade angular triaxial do giroscópio.\n\nUm vetor de 561 recursos com variáveis ​​de domínio de tempo e frequência.\n\nSeu rótulo de atividade.\n\nUm identificador do sujeito que realizou o experimento."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input/naive-bayes/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.datasets import load_iris\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nfrom sklearn.metrics import plot_confusion_matrix\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/activity-recognition-smartphone-merged-dataset/Human_Activity_Recognition_Using_Smartphones_Data.csv',delimiter=\",\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df.iloc[:,561]\ny.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,0:561]\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#iris_data = load_iris()\n#X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n#y = iris_data.target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient Descent Based Algorithms\nMachine learning algorithms like linear regression, logistic regression, neural network, etc. that use gradient descent as an optimization technique require data to be scaled. Take a look at the formula for gradient descent below:\n\nGradient descent formula\n\nThe presence of feature value X in the formula will affect the step size of the gradient descent. The difference in ranges of features will cause different step sizes for each feature. To ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features, we scale the data before feeding it to the model.\n\nHaving features on a similar scale can help the gradient descent converge more quickly towards the minima.\n\nhttps://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size=0.2)\nsc_X = StandardScaler()\nX_trainscaled=sc_X.fit_transform(X_train)\nX_testscaled=sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainscaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_testscaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MLPClassifier(hidden_layer_sizes=(256,128,64,32),activation=\"relu\",random_state=1).fit(X_trainscaled, y_train)\ny_pred=clf.predict(X_testscaled)\nprint(clf.score(X_testscaled, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"Setosa\",\"Versicolor\",\"Virginica\"])\nfig=plot_confusion_matrix(clf, X_testscaled, y_test)\nfig.figure_.suptitle(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Organiza aleatoriamente matrizes \nfrom sklearn.utils import shuffle\nfrom time import process_time\nfrom sklearn.metrics import confusion_matrix\n# validação cruzada\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_scaled=sc.fit_transform(X)\nsinal = X_scaled\nlabel = y.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def precisao(matriz,lista):\n    soma = []\n    total = matriz.sum(axis=0)\n    for i in range(len(lista)):\n        soma.append(100 * matriz[i,i] / total[i])\n    return soma","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Você deve consultar a documentação de cada classificador para ter uma noção geral de seus principais parâmetros.\n# classificadores\n\nNclass = 2\n# epocas = 1000\nepocas = 10\nk = 10 # para validação cruzada\n\n# definir arquitetura da PMC - com uma camada intermediária\nmlp = MLPClassifier(hidden_layer_sizes=(256,), activation='relu', max_iter=epocas, alpha=1e-4,\n                     solver='sgd', verbose=10, tol=1e-10, random_state=1, learning_rate_init=.01)\n\n#com o k folds definidos, separa dados de validação e treinamento - repetir k vezes (folds)\n\ntime_train_mlp =[]\n#acuracia_mlp = []\nprecisao_mlp = []\n#score_mlp = []\nacuracia_mlp = []\n\n# Validação cruzada com k folds\nskf = StratifiedKFold(n_splits=k, random_state=None)\n\nfor train_index, test_index in skf.split(sinal,label): \n\n    print(\"Train:\", train_index, \"Validation:\", test_index) \n    \n    sinais_treinamento, sinais_validacao = sinal[train_index], sinal[test_index] \n    labels_treinamento, labels_validacao = label[train_index], label[test_index]\n    \n    # para garantir serem randomicos\n    x_treinamento, y_treinamento = shuffle(sinais_treinamento, labels_treinamento, random_state = 42)\n    x_validacao, y_validacao = shuffle(sinais_validacao, labels_validacao, random_state = 42)\n\n    # Aqui fazer um treinamento de x épocas e uma validacao da MLP\n    start = process_time()\n    mlp.fit(x_treinamento, y_treinamento) # são 10 treinamentos - no final faz a média\n    end = process_time()\n    time_mlp = end - start\n\n    # Métricas da validacão mlp\n    preds_val_mlp = mlp.predict(x_validacao)  # E 10 validações - no final faz a média\n    cm_val_mlp = confusion_matrix(y_validacao, preds_val_mlp)\n    acuracia_mlp_ = accuracy_score(y_validacao, preds_val_mlp, normalize=False)\n\n    print(f'Acurácia: {100*acuracia_mlp_/y_validacao.shape[0]:.2f}%')\n    print(f'Nr linhas de validação: {y_validacao.shape[0]}')\n    print(f'Nr de linhas de predicao: {preds_val_mlp.shape[0]}')  \n    \n\n    precisao_mlp_ = precisao(cm_val_mlp,mlp.classes_)\n\n    \n    time_train_mlp.append(time_mlp)\n    acuracia_mlp.append(100*acuracia_mlp_/y_validacao.shape[0])\n    precisao_mlp.append(precisao_mlp_)\n\n\n\nmedia_time_train_mlp = sum(time_train_mlp) / float(len(time_train_mlp))\nmedia_acuracia_mlp = sum(acuracia_mlp) / float(len(acuracia_mlp))\n\n\nprint('Tempo médio de treinamento MLP com ' + str(k) + ' kfold ' + str (media_time_train_mlp))\nprint('Médias das Validações com ' + str(k) + ' folds')\nprint('Acurácia_mlp: ' + str(media_acuracia_mlp))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculo da precisão para as classes de saida\nsoma_colunas_precisao_mlp = np.sum(precisao_mlp,axis=0)\nnumero_de_linhas_de_precisao_mlp = len(precisao_mlp)\nmedia_de_precisao_mlp = soma_colunas_precisao_mlp/numero_de_linhas_de_precisao_mlp\nrotulos_matriz_confusao = mlp.classes_\nindice_rotulo_laying = np.where(mlp.classes_ == 'LAYING')[0][0]\nindice_rotulo_sitting = np.where(mlp.classes_ == 'SITTING')[0][0]\nindice_rotulo_standing = np.where(mlp.classes_ == 'STANDING')[0][0]\nindice_rotulo_walking = np.where(mlp.classes_ == 'WALKING')[0][0]\nindice_rotulo_walking_downstairs = np.where(mlp.classes_ == 'WALKING_DOWNSTAIRS')[0][0]\nindice_rotulo_walking_upstairs = np.where(mlp.classes_ == 'WALKING_UPSTAIRS')[0][0]\nmedia_precisao_mlp_laying = media_de_precisao_mlp[indice_rotulo_laying]\nmedia_precisao_mlp_sitting = media_de_precisao_mlp[indice_rotulo_sitting]\nmedia_precisao_mlp_standing = media_de_precisao_mlp[indice_rotulo_standing]\nmedia_precisao_mlp_walking = media_de_precisao_mlp[indice_rotulo_walking]\nmedia_precisao_mlp_walking_upstairs = media_de_precisao_mlp[indice_rotulo_walking_upstairs]\nmedia_precisao_mlp_walking_downstairs = media_de_precisao_mlp[indice_rotulo_walking_downstairs]\nprint(f'Precisão para LAYING: {media_precisao_mlp_laying:.2f}%')\nprint(f'Precisão para SITTING: {media_precisao_mlp_sitting:.2f}%')\nprint(f'Precisão para STANDING: {media_precisao_mlp_standing:.2f}%')\nprint(f'Precisão para WALKING: {media_precisao_mlp_walking:.2f}%')\nprint(f'Precisão para WALKING_DOWNSTAIRS: {media_precisao_mlp_walking_upstairs:.2f}%')\nprint(f'Precisão para WALKING_UPSTAIRS: {media_precisao_mlp_walking_downstairs:.2f}%')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(np.sum(precisao_mlp,axis=0)/len(precisao_mlp))[np.where(mlp.classes_ == 'STANDING')[0][0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" mlp.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acuracia_mlp_","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}