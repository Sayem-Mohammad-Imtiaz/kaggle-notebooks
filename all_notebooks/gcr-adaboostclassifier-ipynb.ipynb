{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>**Preprocessing on German Credit Risk data set**</h1>"},{"metadata":{},"cell_type":"markdown","source":"## 1.) Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom numpy import mean\nfrom numpy import std\nimport pandas as pd\n\nfrom scipy import stats \nimport math\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import BayesianRidge\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report, f1_score, precision_score, recall_score\nfrom sklearn.metrics import roc_curve, precision_recall_curve\nfrom sklearn.preprocessing import label_binarize\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.feature_selection import RFE\nfrom sklearn.pipeline import Pipeline\n\n#from colorsetup import colors, palette","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.) Read the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data = pd.read_csv(\"../input/german-credit-data-with-risk/german_credit_data.csv\", index_col=0)\n#gcr_data = pd.read_csv(\"gcr_data_imputed.csv\")\n#gcr_data = pd.read_csv(\"gcr_processed.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data['Checking account'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Credit Amount means the maximum amount that Lender is committed to lend"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = [x for x in gcr_data.columns if x!='Risk']\nX = gcr_data[feature_cols]\ny = gcr_data['Risk']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.) Visualize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(gcr_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Job\", y=\"Credit amount\", hue=\"Sex\", data=gcr_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Sex\", y=\"Credit amount\", hue=\"Risk\", data=gcr_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x=\"Housing\", y=\"Duration\", hue=\"Sex\", data=gcr_data,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_tar = (gcr_data['Risk']=='good').astype(int)\ncorrelations = gcr_data[list(gcr_data.columns[:-1])].corrwith(y_tar)\ncorrelations.sort_values(inplace=True)\ncorrelations","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sns.set_context('talk')\n#sns.set_palette(palette)\nsns.set_style('white')\n\nsns.pairplot(gcr_data, hue='Risk')"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='pearson correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4).Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"### Label encoding categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = gcr_data.columns[gcr_data.dtypes == 'O']\nnum_cols = gcr_data.columns[gcr_data.dtypes == 'int']\n#ordinal_cols = [ 'Housing', 'Saving accounts', 'Checking account'] \n\n#nominal_cols = ['Purpose']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_map = {'Housing': {'free': 1, 'rent': 2, 'own': 3}}\ngcr_data.replace(replace_map, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_map = {'Saving accounts': {'little': 1, 'moderate': 2, 'quite rich': 3, 'rich': 4}}\ngcr_data.replace(replace_map, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_map = {'Checking account': {'little': 1, 'moderate': 2, 'rich': 3}}\ngcr_data.replace(replace_map, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cols = ['Sex', 'Risk']\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nfor column in binary_cols:\n    gcr_data[column] = le.fit_transform(gcr_data[column])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nominal_cols = ['Housing', 'Saving accounts', 'Checking account', 'Purpose']\n\ngcr_data = pd.get_dummies(gcr_data, columns=nominal_cols, drop_first=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Categorical Missing Values Imputation</h2>\n"},{"metadata":{},"cell_type":"markdown","source":"### 1) SimpleImputer"},{"metadata":{},"cell_type":"markdown","source":"from sklearn.impute import SimpleImputer\n\nvalues = gcr_data.values \nimputer = SimpleImputer(missing_values= np.nan, strategy='constant', fill_value='missing') \ntransformed_values = imputer.fit_transform(values) "},{"metadata":{},"cell_type":"markdown","source":"gcr_data_imputed = pd.DataFrame(transformed_values, columns=gcr_data.columns)"},{"metadata":{},"cell_type":"markdown","source":"gcr_data_imputed[\"Credit amount\"] = gcr_data_imputed[\"Credit amount\"].astype(int)\ngcr_data_imputed[\"Duration\"] = gcr_data_imputed[\"Duration\"].astype(int)\ngcr_data_imputed[\"Job\"] = gcr_data_imputed[\"Job\"].astype(int)\ngcr_data_imputed[\"Age\"] = gcr_data_imputed[\"Age\"].astype(int)"},{"metadata":{},"cell_type":"markdown","source":"outputfile = 'gcr_data_imputed.csv'\ngcr_data_imputed.to_csv(outputfile, index=False)"},{"metadata":{},"cell_type":"markdown","source":"### 2) IterativeImputer"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = [x for x in gcr_data.columns if x!='Risk']\nX = gcr_data[feature_cols]\ny = gcr_data['Risk']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define imputer\nimputer = IterativeImputer(estimator=BayesianRidge(), n_nearest_features=None, imputation_order='ascending')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit on the dataset\nimputer.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the dataset\nXtrans = imputer.transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(Xtrans, columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Log transforming skew variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#num_cols = X.columns[X.dtypes == 'float']\nnum_cols = X.columns\nnum_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skew_vals = X[num_cols].skew()\n\nskew_limit = 0.75\nskew_cols = (skew_vals.\n            sort_values(ascending=False)\n            .to_frame()\n            .rename(columns={0:'Skew'})\n            .query('abs(Skew) > {}'.format(skew_limit)))\nskew_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in skew_cols.index.values:\n    X[col] =X[col].apply(np.log1p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data_imputed = pd.concat([X, y], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputfile = 'gcr_data_imputed2.csv'\ngcr_data_imputed.to_csv(outputfile, index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>**AdaBoost Classifier on German Credit Risk data set**</h1>"},{"metadata":{},"cell_type":"markdown","source":"# Tables of Content:\n\n**1. [Introduction](#intro_abc)** <br>\n    - Information about the data set <br>\n**2. [Reason for using this model](#reasons_abc)** <br>\n    - The purpose of this specific model <br>\n**3. [Libraries](#libraries_abc)** <br>\n    - Importing Libraries <br>\n    - Importing Dataset <br>\n**4. [Preprocess](#preprocessing_abc)** <br>\n    - 4.1 Separating feature and target variables <br>\n    - 4.2 [Feature Selection](#feature_selection_abc)<br>\n    - 4.3 [Spliting the X and Y in train and test](#split_abc)<br>\n**5. [Models](#modelling_abc)**<br>\n    - 5.1 AdaBoostClassifier with GridSearchCV<br>\n    - 5.2 [Metrics](#metrics_abc)<br>\n    - 5.3 [Confusion Matrix and Classification Report](#conmat_abc)<br>\n    - 5.4 ROC curve and Precision Recall curve<br>\n**6. [Conclusion and Benefits of the model](#summary_abc)** <br>\n    The summary of the model implementation"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"intro_abc\"></a> <br>\n# **1. Introduction:** \n<h2>Context</h2>\nThe original dataset contains 1000 entries with 9 feature variables. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes.\n\n<h2>Content</h2>\nI have cleaned and preprocessed the data already and also I have created a more relevant feature from two of the most important feature in the data set i.e. Credit amount and Duration. The preprocessed data set is already saved in a CSV file and we are going to use that file for our model training and testing purposes. The selected variables from the orginal data set are:\n\n<b>Age </b>(numeric)<br>\n<b>Sex </b>(text: male, female)<br>\n<b>Job </b>(numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)<br>\n<b>Housing</b> (text: own, rent, or free)<br>\n<b>Saving accounts</b> (text - little, moderate, quite rich, rich)<br>\n<b>Checking account </b>(numeric, in DM - Deutsch Mark)<br>\n<b>Credit amount</b> (numeric, in DM)<br>\n<b>Duration</b> (numeric, in month)<br>\n<b>Purpose</b>(text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others<br>\n<b>Risk </b> (Value target - Good or Bad Risk)<br>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resons_abc\"></a> <br>\n# **2. Reason for using this model**\n<h2>Our goal is to: </h2>\n\n- Implement AdaBoostClassifier with GridSearchCV.\n- Moreover, we are going to assess various metrics for the model and plot area-under-curve and precision-recall curve.\n- We are going to estimate the best estimator i.e. the best hyperparameters for our model.\n- False Positive Rate are calculated using confusion matrix to better understand the potentiality of losses which will incur due to giving loans to the person who will default."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"libraries_abc\"></a> <br>\n# **3. Libraries**"},{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom numpy import mean\nfrom numpy import std\nimport pandas as pd\n\nfrom scipy import stats \nimport math\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report, f1_score, precision_score, recall_score\nfrom sklearn.metrics import roc_curve, precision_recall_curve\nfrom sklearn.preprocessing import label_binarize\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.feature_selection import RFE\nfrom sklearn.pipeline import Pipeline\n\n#from colorsetup import colors, palette","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data = pd.read_csv(\"gcr_data_imputed2.csv\")\n#gcr_data = pd.read_csv(\"gcr_data_imputed.csv\")\n#gcr_data = pd.read_csv(\"gcr_processed.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data['Credit_amount/duration'] = gcr_data['Credit amount']/gcr_data['Duration']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcr_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"preprocessing_abc\"></a> <br>\n# **4. Preprocess**"},{"metadata":{},"cell_type":"markdown","source":"<h2>4.1 Separating feature and target</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = gcr_data.drop(['Risk','Credit_amount/duration'], axis=1)\n#X = gcr_data.drop(['Risk', 'Credit amount'], axis=1)\nX = gcr_data.drop(['Risk'], axis=1)\n\ny = gcr_data['Risk']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"feature_selection_abc\"></a>\n<h2>4.2 Feature Selection</h2>"},{"metadata":{},"cell_type":"markdown","source":"### 1. Univariate Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply SelectKBest class to extract top 5 best features\nbestfeatures = SelectKBest(score_func=chi2, k=6)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns, dfscores], axis=1)\nfeatureScores.columns = ['Specs', 'Score']  #naming the dataframe columns\nprint(featureScores.nlargest(10, 'Score'))  #print best features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = gcr_data[featureScores.nlargest(23, 'Score')['Specs'].values]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\nmodel_fi = ExtraTreesClassifier()\nmodel_fi.fit(X,y)\n#print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model_fi.feature_importances_, index=X.columns)\nfeat_importances.sort_values(ascending=True).nlargest(14).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate a give model using cross-validation\ndef evaluate_model(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n\nmodel_eval = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n\nresults = list()\nfor i in range(1,X.shape[1]+1):\n        scores = evaluate_model(model_eval, X[feat_importances.nlargest(i).index], y)\n        results.append(scores)\n        print('> %s) %.3f (%.3f)' % (i, mean(scores), std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_features = [str(i) for i in range(1,X.shape[1]+1)]\n# plot model performance for comparison\nplt.figure(figsize=(8,6))\nplt.boxplot(results, labels=no_of_features, showmeans=True)\nplt.xticks(rotation=75)\nplt.title('No. of features vs. Average Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Correlation Matrix with Heatmap"},{"metadata":{},"cell_type":"raw","source":"#get correlations of each features in dataset\ncorrmat = gcr_data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n\n#plot heat map\ng=sns.heatmap(gcr_data[top_corr_features].corr(), annot=False, cmap=\"RdYlGn\")"},{"metadata":{},"cell_type":"markdown","source":"### 4. RFE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get a list of models to evaluate\ndef get_models():\n    models = dict()\n    # lr\n    rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n    models['lr'] = Pipeline(steps=[('s',rfe),('m',model)])\n    \n    # perceptron\n    rfe = RFE(estimator=Perceptron(), n_features_to_select=5)\n    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n    models['per'] = Pipeline(steps=[('s',rfe),('m',model)])\n    \n    # cart\n    rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n    models['cart'] = Pipeline(steps=[('s',rfe),('m',model)])\n    \n    # rf\n    rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=5)\n    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n    models['rf'] = Pipeline(steps=[('s',rfe),('m',model)])\n    \n    # gbm\n    rfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)\n    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n    models['gbm'] = Pipeline(steps=[('s',rfe),('m',model)])\n    return models\n \n# evaluate a give model using cross-validation\ndef evaluate_model(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    print('>%s) %.3f (%.3f)' % (name, mean(scores), std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot model performance for comparison\nplt.boxplot(results, labels=names, showmeans=True)\nplt.title('RFE Estimator vs. Average Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get a list of models to evaluate\ndef best_estimator():\n    models = dict()\n    for i in range(2, X.shape[1]+1):\n        rfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=i)\n        model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n    return models\n\n# evaluate a give model using cross-validation\ndef evaluate_model(model, X, y):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n\n# get the models to evaluate\nmodels = best_estimator()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    print('> %s) %.3f (%.3f)' % (name, mean(scores), std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot model performance for comparison\nplt.figure(figsize=(8,6))\nplt.boxplot(results, labels=names, showmeans=True)\nplt.xticks(rotation=75)\nplt.title('No. of features vs. Average Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define RFE\nrfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=8)\n# fit RFE\nrfe.fit(X, y)\n# summarize all features\nfor i in range(X.shape[1]):\n    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"split_abc\"></a>\n<h2>4.3 StratifiedShuffleSplit</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = gcr_data[feat_importances.nlargest(12).index]\nX = gcr_data[X.columns[rfe.support_]]\n\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nstrat_shuf_split = StratifiedShuffleSplit(n_splits=1, \n                                          test_size=0.3, \n                                          random_state=42)\n\ntrain_idx, test_idx = next(strat_shuf_split.split(X, gcr_data.Risk))\n\n# Create the dataframes\nX_train = X.loc[train_idx, X.columns]\ny_train = gcr_data.loc[train_idx, 'Risk']\n\nX_test  = X.loc[test_idx, X.columns]\ny_test  = gcr_data.loc[test_idx, 'Risk']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"modelling_abc\"></a> <br>\n# **5. Models**"},{"metadata":{},"cell_type":"markdown","source":"#### Suppressing any warnings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Suppress warnings about too few trees from the early models\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>5.1 AdaBoostClassifier with GridSearchCV</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n#ABC = AdaBoostClassifier(n_estimators=100, base_estimator= None,learning_rate=1, random_state = 1)\n\nparam_grid = {'n_estimators': [100, 150, 200],\n              'learning_rate': [0.01, 0.001]}\n\nABC_GCV = GridSearchCV(ABC,\n                      param_grid=param_grid, \n                      scoring='accuracy',\n                      n_jobs=-1)\n\nABC_GCV = ABC_GCV.fit(X_train, y_train)\n\n# The best model\nprint(ABC_GCV.best_estimator_)\n\nABC_GCV = AdaBoostClassifier(n_estimators=100, base_estimator= DecisionTreeClassifier(max_depth=1),learning_rate=0.01)\nABC_GCV = ABC_GCV.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"metrics_abc\"></a>\n<h2>5.2 Metrics</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = list()\ny_prob = list()\n\nlabels = ['ABC_GCV']\nmodels = [ABC_GCV]\n\nfor lab,mod in zip(labels, models):\n    y_pred.append(pd.Series(mod.predict(X_test), name=lab))\n    y_prob.append(pd.Series(mod.predict_proba(X_test).max(axis=1), name=lab))\n    \ny_pred = pd.concat(y_pred, axis=1)\ny_prob = pd.concat(y_prob, axis=1)\n\nmetrics = list()\ncm = dict()\n\nfor lab in labels:\n\n    # Precision, recall, f-score from the multi-class support function\n    precision, recall, fscore, _ = score(y_test, y_pred[lab], average='weighted')\n    \n    # The usual way to calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred[lab])\n    \n    # ROC-AUC scores can be calculated by binarizing the data\n    auc = roc_auc_score(label_binarize(y_test, classes=[0,1]),\n              label_binarize(y_pred[lab], classes=[0,1]), \n              average='weighted')\n    \n    # Last, the confusion matrix\n    cm[lab] = confusion_matrix(y_test, y_pred[lab])\n    \n    metrics.append(pd.Series({'precision':precision, 'recall':recall, \n                              'fscore':fscore, 'accuracy':accuracy,\n                              'auc':auc}, \n                             name=lab))\n\nmetrics = pd.concat(metrics, axis=1)\n\nmetrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conmat_abc\"></a>\n<h2>5.4 Confusion Matrix and Classification Report</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_context('talk')\n\nfig, axList = plt.subplots(nrows=1, ncols=2)\naxList = axList.flatten()\nfig.set_size_inches(10, 4)\n\naxList[-1].axis('off')\n\nfor ax,lab in zip(axList, labels):\n    sns.heatmap(cm[lab], ax=ax, annot=True, fmt='d');\n    ax.set(title=lab);\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, f1_score\n\nprint('#'*60)\n\ny_pred_gb = ABC_GCV.predict(X_test)\nprint('AdaBoostClassifier')\nprint(classification_report(y_test, y_pred_gb))\nprint('Accuracy score: ', round(accuracy_score(y_test, y_pred_gb), 3))\nprint('F1 Score: ', round(f1_score(y_test, y_pred_gb), 3))\n\nprint('\\n')\nprint('#'*60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>5.5 ROC curve and Precision-Recall curve</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_context('talk')\n\nfig, axList = plt.subplots(nrows=1, ncols=2)\nfig.set_size_inches(10, 5)\n\n# Plot the ROC-AUC curve\n\nax = axList[0]\nfpr, tpr, thresholds = roc_curve(y_test, y_prob[lab])\nax.plot(fpr, tpr, linewidth=5)\n\n# It is customary to draw a diagonal dotted line in ROC plots.\n# This is to indicate completely random prediction. Deviation from this\n# dotted line towards the upper left corner signifies the power of the model.\nax.plot([0, 1], [0, 1], ls='--', color='black', lw=.3)\nax.set(xlabel='FPR',\n       ylabel='TPR',\n       xlim=[-.01, 1.01], ylim=[-.01, 1.01],\n       title='ROC curve: {}'.format(lab))\nax.grid(True)\n\n# Plot the precision-recall curve\n\nax = axList[1]\nprecision, recall, _ = precision_recall_curve(y_test, y_prob[lab])\nax.plot(recall, precision, linewidth=5)\nax.set(xlabel='Recall', ylabel='Precision',\n       xlim=[-.01, 1.01], ylim=[-.01, 1.01],\n       title='Precision-Recall curve: {}'.format(lab))\nax.grid(True)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"summary_abc\"></a> <br>\n# **6. Conclusion and Benefits of the model**\n\n- The AdaBoostClassifier with GridSearchCV gives the FPR of 20% and 71.0% accuracy.\n- Changing the number of important features does not affect the metrics."},{"metadata":{},"cell_type":"markdown","source":"########################################################################################################################################"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}