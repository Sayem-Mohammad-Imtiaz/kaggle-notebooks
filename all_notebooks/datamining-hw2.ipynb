{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EE226 - Coding 2\n## Streaming algorithm & Locality Sensitive Hashing","metadata":{}},{"cell_type":"markdown","source":"### Streaming: DGIM","metadata":{"_uuid":"6010a3a8-f893-494d-afb5-3bb780d9180b","_cell_guid":"1ecdad90-be26-48b5-8bfc-cd51d50e312b","trusted":true}},{"cell_type":"markdown","source":"DGIM is an efficient algorithm in processing large streams. When it's infeasible to store the flowing binary stream, DGIM can estimate the number of 1-bits in the window. In this coding, you're given the *stream_data.txt* (binary stream), and you need to implement the DGIM algorithm to count the number of 1-bits. Write code and ask the problems below.","metadata":{"_uuid":"bd360953-2cc2-4756-8214-edc58b18e0bd","_cell_guid":"29c68422-bc9c-4bee-aeaf-5c449c8fe94d","trusted":true}},{"cell_type":"markdown","source":"### Your task","metadata":{"_uuid":"4a302760-863a-43a7-b7f4-ba2c85aea2bb","_cell_guid":"7e47650c-5bfe-4523-a5a2-cbee3e21be9a","trusted":true}},{"cell_type":"markdown","source":"1. Set the window size to 1000, and count the number of 1-bits in the current window.","metadata":{"_uuid":"0517bdd0-0dbe-49a8-a263-debcf6c6d5e1","_cell_guid":"0e59f99e-b518-4af6-bfae-cbabf208edd1","trusted":true}},{"cell_type":"code","source":"import math\nimport time\n\n\nDGIM_res = []\nfile = '../input/coding2/stream_data.txt'\nwindow = 1000\nnowstamp = 0\n\nsizes = [int(math.pow(2, i)) for i in range(int(math.log(window, 2))+1)]\nDGIM_container = {i: [] for i in sizes}\n\ndef add_one(stamp):\n    global DGIM_container\n    DGIM_container[sizes[0]].append(stamp)\n    \ndef update():\n    global DGIM_container\n    for i in sizes:\n        if len(DGIM_container[i]) > 2:\n            DGIM_container[i].pop(0)\n            stamp = DGIM_container[i].pop(0)\n            if not (i == sizes[-1]):\n                DGIM_container[i * 2].append(stamp)\n\ndef display():\n    cnt = 0\n    firststamp = 0\n    for key in sizes:\n        if len(DGIM_container[key]) > 0:\n            firststamp = DGIM_container[key][0]\n    for key in sizes:\n        for stamp in DGIM_container[key]:\n            if stamp != firststamp:\n                cnt += key\n            else:\n                cnt += 0.5 * key\n    print('In the window of', str(window), 'bits, there are', \\\n          str(cnt), 'ones')\n    DGIM_res.append(int(cnt))\n    \n    \ntime11 = time.process_time()\nindex = 0\nwith open(file, 'r') as f:\n    while 1:\n        char = f.read(1)\n        if not char:\n            break\n        if char == '\\t':\n            continue\n            \n        nowstamp = (nowstamp+1) % window\n        for k in sizes:\n            for itemstamp in DGIM_container[k]:\n                if itemstamp == nowstamp:\n                    DGIM_container[k].remove(nowstamp)\n\n        if char == \"1\":\n            DGIM_container[1].append(nowstamp)\n            update()\n            \n        index = (index + 1) % window\n        if index == 0:\n            display()\ntime12 = time.process_time()","metadata":{"_uuid":"872d4f34-9659-4ede-9840-76a0c9eb980d","_cell_guid":"fc1b74d1-5281-4c44-a338-e9effe9dffdf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Write a function that accurately counts the number of 1-bits in the current window, and compare the difference between its running time and space and the DGIM algorithm.","metadata":{"_uuid":"a20fccec-bf1c-448b-b4c1-c12e5cca8711","_cell_guid":"031e9e8d-e26a-42ab-ac76-685c92c773e0","trusted":true}},{"cell_type":"code","source":"from collections import deque\nindex2 = 0\n\nNORMAL_container = deque()\nNORMAL_res = []\ntime21 = time.process_time()\nwith open('../input/coding2/stream_data.txt', 'r') as f:\n    while 1:\n        char = f.read(1)\n        if not char:\n            break\n        if char == '\\t':\n            continue\n\n        if len(NORMAL_container) >= window:\n            NORMAL_container.popleft()\n        NORMAL_container.append(int(char)) \n            \n        index2 = (index2 + 1) % window\n        if index2 == 0:\n            print('In the window of', str(window), 'bits, there are', \\\n              str(sum(NORMAL_container)), 'ones')\n            NORMAL_res.append(sum(NORMAL_container))\n            \ntime22 = time.process_time()","metadata":{"_uuid":"8d0edecc-3d04-4465-8261-2586e9c68ffa","_cell_guid":"3af700fe-3817-4925-86cd-a8eb5ebecdb9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/coding2/stream_data.txt', 'r') as f:\n    data = f.read()\ndata = data.split(\"\\t\")\nprint(sum([int(data[i]) for i in range(1000)]))","metadata":{"_uuid":"5aa59ad9-f696-46d3-808d-b27dd744e554","_cell_guid":"68d7b51b-90ca-4679-86f2-8d14cde770af","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"index\".ljust(5, \" \"),end=\"|\")\nprint(\"DGIM\".ljust(10, \" \"),end=\"|\")\nprint(\"NORMAL\".ljust(10, \" \"),end=\"|\")\nprint(\"ERROR RATE\".ljust(10,\" \"))\n\nfor i in range(len(DGIM_res)):\n    print(str(i).ljust(5, \" \"),end=\"|\")\n    print(str(DGIM_res[i]).ljust(10, \" \"),end=\"|\")\n    print(str(NORMAL_res[i]).ljust(10, \" \") ,end=\"|\")\n    print(str(round(100 * abs(DGIM_res[i] - NORMAL_res[i]) / NORMAL_res[i], 5)) + '%'.ljust(10, \" \"))\n    \nprint(\"*\"*45)\nprint('sum'.ljust(5, \" \"),end=\"|\")\nprint(str(sum(DGIM_res)).ljust(10, \" \"),end=\"|\")\nprint(str(sum(NORMAL_res)).ljust(10, \" \"), end=\"|\")\nprint(str(round(100 * abs(sum(DGIM_res) - sum(NORMAL_res)) / sum(NORMAL_res), 5)) + '%'.ljust(10, \" \"))","metadata":{"_uuid":"3517566d-9855-4870-b82b-0ff4807db044","_cell_guid":"57a29cf9-8c0f-4bd7-b2ef-5e50f6dc304a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Time difference:')\nprint('DGIM:', '%s ms' % ((time12 - time11)*1000))\nprint('NORMAL:', '%s ms' % ((time22 - time21)*1000))\nprint('',end='\\n'+\"*\"*30 + '\\n')\n\nprint(\"Space difference:\")\nprint('DGIM:', '%s' % (sum([len(i) for i in DGIM_container.values()])))\nprint('NORMAL:', '%s' % ((len(NORMAL_container))))","metadata":{"_uuid":"fabdf955-f022-4a1e-8838-0842d6820a8d","_cell_guid":"75b675e7-a999-4758-a857-0413ee81a68a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Locality Sensitive Hashing","metadata":{"_uuid":"1d5173fa-ce14-41fd-9a3b-7cf917e80263","_cell_guid":"8bbbb9d4-67d3-46a8-bb54-bc1b4e2620b5","trusted":true}},{"cell_type":"markdown","source":"The locality sensitive hashing (LSH) algorithm is efficient in near-duplicate document detection. In this coding, you're given the *docs_for_lsh.csv*, where the documents are processed into set of k-shingles (k = 8, 9, 10). *docs_for_lsh.csv* contains 201 columns, where column 'doc_id' represents the unique id of each document, and from column '0' to column '199', each column represents a unique shingle. If a document contains a shingle ordered with **i**, then the corresponding row will have value 1 in column **'i'**, otherwise it's 0. You need to implement the LSH algorithm and ask the problems below.","metadata":{"_uuid":"de163ab4-7b8b-41a5-9aa6-e8af75aadee4","_cell_guid":"17c90f58-51ef-4acd-a44a-d38a6a352224","trusted":true}},{"cell_type":"markdown","source":"### Your task","metadata":{"_uuid":"7442888d-ffcc-4cf3-8a49-98fc4283bd1f","_cell_guid":"8bab5cf9-2ac9-40bb-9c13-02e1138aa95b","trusted":true}},{"cell_type":"markdown","source":"Use minhash algoirthm to create signature of each document, and find 'the most similar' documents under Jaccard similarity. \nParameters you need to determine:\n1) Length of signature (number of distinct minhash functions) *n*. Recommanded value: n > 20.\n\n2) Number of bands that divide the signature matrix *b*. Recommanded value: b > n // 10.","metadata":{"_uuid":"9dfb7a23-b2dd-4a18-bcf5-0fd89d65c193","_cell_guid":"9811bf8d-3c53-48f4-8263-9c088abf0327","trusted":true}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/coding2/docs_for_lsh.csv',index_col=0)\n\ndf.head()","metadata":{"_uuid":"f977f59b-502d-4a66-b113-a8eae6603c92","_cell_guid":"92159c2f-1e8e-419f-8102-8ca32466b377","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nimport hashlib\n\n\ndef signMatrixGenerate(matrix, n):\n\n    final = []\n\n    for i in range(n):\n\n        seq = [i for i in range(matrix.shape[0])]\n        result_one = [-1 for i in range(matrix.shape[1])]\n        cnt = 0\n\n        while len(seq) > 0:\n            randomSeed = random.sample(seq, 1)[0]\n            for i in range(matrix.shape[1]):\n\n                if result_one[i] == -1 and matrix[randomSeed][i] != 0:\n                    result_one[i] = randomSeed\n                    cnt += 1\n\n            if cnt == matrix.shape[1]:\n                break\n\n            seq.remove(randomSeed)\n        final.append(result_one)\n\n    return np.array(final)\n\ndef minHash(matrix, b=30, r=5):\n    n = b * r\n    signMatrix = signMatrixGenerate(matrix, n)\n    begin, end = 0, r\n    cnt = 0\n\n    while end <= signMatrix.shape[0]:\n        cnt += 1\n        for col in range(signMatrix.shape[1]):\n\n            hashObj = hashlib.md5()\n            band = str(signMatrix[begin: begin + r, col]) + str(cnt)\n            hashObj.update(band.encode())\n            hash_tag = hashObj.hexdigest()\n            if hash_tag not in bucket:\n                bucket[hash_tag] = []\n            if col not in bucket[hash_tag]:\n                bucket[hash_tag].append(col)\n        begin += r\n        end += r","metadata":{"_uuid":"d5c20703-4c18-43d9-a5b3-b143c1c7bcb2","_cell_guid":"4cc3439b-9305-416e-8822-f14998dd2543","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bucket= {}\ninput_matrix = np.array(df).T\nminHash(input_matrix, 30, 5)\nprint(len(bucket))","metadata":{"_uuid":"e24b5e27-9c23-47b4-b814-e437eac88402","_cell_guid":"80e6279e-8dd7-426e-9e40-9519a30aa3c5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _search(searched):\n    result = set()\n    for key in bucket:\n        if searched in bucket[key]:\n            for i in bucket[key]:\n                result.add(i)\n\n    result.remove(searched)\n    return result","metadata":{"_uuid":"d32cdd73-9a5a-4ef0-a86a-61e121c1a9ad","_cell_guid":"d74ad823-d390-4131-b5af-51ebd1092de5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def myJaccard(a, b):\n    a = np.array(a)[0]\n    b = np.array(b)[0]\n    num = den = 0\n    for i in range(len(a)):\n        if a[i] == b[i] == 1:\n            num += 1\n            den += 1\n        elif not (a[i] == b[i] == 0):\n            den += 1\n    return num / den\n\nall_doc = [i for i in range(df.shape[0])]\n\n# We only show a part of the final results.\nfor doc in all_doc:\n    if doc >= 30:\n        break\n    print('doc{}: {}'.format(doc, max([i for i in _search(doc) if i != doc], \n                                      key=lambda i: myJaccard(df.iloc[doc:doc+1], df.iloc[i:i+1]))))\n\n# We only show a part of the final results.\nprint(\"......(not all)\")","metadata":{"_uuid":"8e749e50-eab3-4e28-b8e6-c37e401410f1","_cell_guid":"e1e1319c-578a-4993-b36b-b16c3fec6576","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Problem: For document 0 (the one with id '0'), list the **30** most similar document ids (except document 0 itself). You can valid your results with the [sklearn.metrics.jaccard_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html) function.\n\nTips: You can adjust your parameters to hash the documents with similarity *s > 0.8* into the same bucket.","metadata":{"_uuid":"9fb47afe-201d-4342-a469-bb680065bdc6","_cell_guid":"38e7b26e-e064-40aa-90b4-a83631ea67d6","trusted":true}},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score\n\n\nnowDoc = 0\nfind_in_bucket = _search(nowDoc)\nnowDoc_res = sorted([i for i in find_in_bucket if i != nowDoc], \n                    key=lambda i: myJaccard(df.iloc[nowDoc:nowDoc+1], df.iloc[i:i+1]),\n                   reverse=True)[:30]\nprint('My result: doc{} \\n{}'.format(nowDoc, \n                                          '\\n'.join([str(i)+('('+ str(myJaccard(df.iloc[nowDoc:nowDoc+1], \\\n                                                               df.iloc[i:i+1]))+')').ljust(10, ' ')  \\\n                                                                for i in nowDoc_res])))\n\nprint(\"-\"*50)\n# ----------------------Validation----------------------\nnowDoc_res = sorted([i for i in all_doc if i != nowDoc], \n                    key=lambda i: jaccard_score(np.array(df.iloc[nowDoc:nowDoc+1])[0],np.array(df.iloc[i:i+1])[0]),\n                   reverse=True)[:30]\nprint('Validation: doc{} \\n{}'.format(nowDoc , \n                                          '\\n'.join([str(i)+('('+ \\\n        str(jaccard_score(np.array(df.iloc[nowDoc:nowDoc+1])[0],np.array(df.iloc[i:i+1])[0])) +')').ljust(10, ' ') \\\n                                                                for i in nowDoc_res])))","metadata":{"_uuid":"a6da534c-4b2c-49da-9410-0b1e864cef00","_cell_guid":"13dd2b5f-a4a2-4e6d-9d8d-55222128ac8f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}