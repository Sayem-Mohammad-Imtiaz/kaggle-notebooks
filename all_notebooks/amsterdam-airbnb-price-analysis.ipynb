{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction"},{"metadata":{},"cell_type":"markdown","source":"Amsterdam is the capital and most popular city of the Netherlands. It is colloquially referred to as the \"Venice of the North\", attributed by the large number of canals which form a UNESCO World Heritage Site(https://en.wikipedia.org/wiki/Amsterdam). Amsterdam is the heaven of art because of its high-density distribution of museums and art galleries. It has large amount of collections of Vincent Willem van Gogh and Rembrandt Harmenszoon van Rijn. Amsterdam is also famous of its open culture to sex and cannabis. According to https://www.dw.com/en/how-amsterdam-is-fighting-mass-tourism/a-47806959, there were 19 million tourists visiting Amsterdam in 2019 which brings the high demands of hotels.  \n\nAirbnb is an online marketplace for arranging or offering lodging, primarily homestays, or tourism experiences (https://en.wikipedia.org/wiki/Airbnb). More and more people choose to stay in a local house when they are travelling. The prices of the houses vary a lot depending on the location, the size, the service or the surroundings of the houses."},{"metadata":{},"cell_type":"markdown","source":"So, in this project, I would like to use the data science techniques to solve the following question:\n\n**Which factors of the property could affect the rental price on Airbnb?**\n\nWhich factors of the property could affect the rental price on Airbnb?\nThe answer of this question can be useful for people from Amsterdam who wants to start renting their properties on Airbnb, or tourists who are going to visit Amsterdam and want to estimate the cost of accommodation."},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium # map rendering library\nimport requests # library to handle requests\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data"},{"metadata":{},"cell_type":"markdown","source":"The data we will use are:\n* The data of Airbnb properties in Amsterdam\n* The venue information provided by Foursquare API\n* The coordinate of Amsterdam center provided by Google Map"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The coordinates of Amsterdam center\nlatitude = 52.372952\nlongitude = 4.906080","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Airbnb data of Amsterdam was retrieved from Kaggle (https://www.kaggle.com/erikbruin/airbnb-amsterdam).The dataset includes the following files:\n* calendar.csv: The calendar has 365 records for each listing. It specifies the whether the listing is available on a particular day (365 days ahead), and the price on that day.\n* listings.csv: A listing is basically an advertisement. This file holds the most useful variables that can be used visualizations.\n* listings_details.csv: This file holds the same variables as the listing file plus 80 additional variables.\n* neighbourhood.csv: Simple file with the Dutch names of the neighbouhoods\n* reviews.csv: This is a simple file that can be used to count the number of reviews by listing (for a specific period).\n* reviews_details.csv: This file holds the full details of all reviews, and can also be used for instance for text mining.\n* neighbourhoods.geojson: This is the shape file that can be used in conjunction with interactive maps (such as Leaflet for R of the Python folium package)."},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Airbnb Amsterdam data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use the data from listings_details.csv to describ the airbnb properties."},{"metadata":{"trusted":true},"cell_type":"code","source":"ab_data = pd.read_csv('/kaggle/input/airbnb-amsterdam/listings_details.csv')\nprint(ab_data.shape)\nab_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each property in the dataset, it has following information:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ab_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Amsterdam Neighbourhoods Coordinates"},{"metadata":{},"cell_type":"markdown","source":"We use neighbourhoods.geojson to get the longitude and latitude of the center of each neighbourhood."},{"metadata":{"trusted":true},"cell_type":"code","source":"import geopandas as gpd\ngeo_ams = gpd.read_file('/kaggle/input/airbnb-amsterdam/neighbourhoods.geojson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geo_ams[\"longitude\"] = geo_ams.centroid.x\ngeo_ams[\"latitude\"] = geo_ams.centroid.y\ngeo_ams.drop('neighbourhood_group', axis=1, inplace=True)\ngeo_ams","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Foursquare data"},{"metadata":{},"cell_type":"markdown","source":"We will use the FourSquare API (www.foursquare.com) to explore the venues of each neighbourhood in Amsterdam. Given a pair of coordinates, the Foursquare explore function can be used to retrieve the venues nearby. The categories and the number of venues can describe how conveninent living in a place."},{"metadata":{},"cell_type":"markdown","source":"# 3. Metrology"},{"metadata":{},"cell_type":"markdown","source":"In this section, we will explore the data we use. Data cleaning and feature engineering methods will be used to prepare the data that is ready to fit into the model."},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Airbnb data cleaning"},{"metadata":{},"cell_type":"markdown","source":"There are 96 columns in the airbnb data. But there are columns not valuable for our analysis such as listing_url, scrape_id. So, we can firstly filter some columns that are not describing the property."},{"metadata":{"trusted":true},"cell_type":"code","source":"ab_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['id', 'name',\n       'neighbourhood_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates',\n       'bathrooms', 'bedrooms', 'beds', 'bed_type', 'square_feet',\n       'price', 'cleaning_fee', 'guests_included', 'extra_people', \n       'minimum_nights', 'maximum_nights', \n       'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', \n       'number_of_reviews', 'review_scores_rating',\n       'review_scores_accuracy', 'review_scores_cleanliness',\n       'review_scores_checkin', 'review_scores_communication',\n       'review_scores_location', 'review_scores_value', 'instant_bookable',\n       'is_business_travel_ready', 'cancellation_policy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns = ab_data[columns]\nprint(data_columns.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, there are 35 columns left."},{"metadata":{},"cell_type":"markdown","source":"### 3.1.1 Drop the unavaliable samples"},{"metadata":{},"cell_type":"markdown","source":"We would like to focus on the properties that are available regularly. So, we can remove remove the properties are not availiable in the past recent months."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data_columns = data_columns[data_columns['has_availability'] == 't']\ndata_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns = data_columns[data_columns['availability_30'] != 0]\ndata_columns = data_columns[data_columns['availability_60'] != 0]\ndata_columns = data_columns[data_columns['availability_90'] != 0]\ndata_columns = data_columns[data_columns['availability_365'] != 0]\ndata_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns.drop(['has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365'], axis=1, inplace=True)\ndata_columns.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.2 Drop the samples missing information"},{"metadata":{},"cell_type":"markdown","source":"Also, we would like to focus on the valid property only which means the property has a valid price and reviews from previous guests to verify the authenticity."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns = data_columns[data_columns['price'] != 0]\ndata_columns = data_columns[data_columns['number_of_reviews'] != 0]\ndata_columns = data_columns[data_columns['review_scores_rating'].notnull()]\ndata_columns.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.3 Examine the missing values"},{"metadata":{},"cell_type":"markdown","source":"Then, let's deal with the missing values in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def examine_missing_values(data):\n    data_na= data.isnull().sum().sort_values(ascending=False)\n    data_na_percent = (data.isnull().sum()/len(data)*100).sort_values(ascending=False)\n    missing_data = pd.concat([data_na, data_na_percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data = examine_missing_values(data_columns)\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop the feature having too many missing values"},{"metadata":{},"cell_type":"markdown","source":"More than 97% of properties do not have the square feet recorded. So, we remove the square_feet from the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns.drop(['square_feet'], axis=1, inplace=True)\ndata_columns.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fill the missing sub-reviews by corresponding review_scores_rating"},{"metadata":{},"cell_type":"markdown","source":"If a review score for a sub-catogery is missing, we fill it by its average review score which is review_score_rating."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns['review_scores_value'].fillna(data_columns['review_scores_rating'], inplace=True)\ndata_columns['review_scores_location'].fillna(data_columns['review_scores_rating'], inplace=True)\ndata_columns['review_scores_communication'].fillna(data_columns['review_scores_rating'], inplace=True)\ndata_columns['review_scores_checkin'].fillna(data_columns['review_scores_rating'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fill the missing bathrooms, bedrooms, beds by 0"},{"metadata":{},"cell_type":"markdown","source":"If the values of bathrooms, bedrooms, beds are missing, we can understand there is no bathroom, bedroom, bed in this property. So, we fill them by 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns['bathrooms'].fillna(0, inplace=True)\ndata_columns['bedrooms'].fillna(0, inplace=True)\ndata_columns['beds'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fill the missing cleaning fee by mode"},{"metadata":{},"cell_type":"markdown","source":"We fill the missing cleaning fee by mode."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns['cleaning_fee'].fillna(data_columns['cleaning_fee'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Examine missing values again"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data = examine_missing_values(data_columns)\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, there is no more missing value in our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.4 Convert the type of some features"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = list(data_columns.dtypes[data_columns.dtypes != 'object'].index)\nnumeric_features.remove('id')\nnumeric_features.remove('latitude')\nnumeric_features.remove('longitude')\nnumeric_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_features = list(data_columns.dtypes[data_columns.dtypes == 'object'].index)\ncategory_features.remove('name')\ncategory_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see there are some features related to price that should be numerical rather than categorical, such as price, cleaning_fee, extra_people. That is because the money data is recorded as a string in the format of '50$'. So we convert these money-related features to numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns['price'] = data_columns['price'].apply(lambda x:x.lstrip('$'))\ndata_columns['price'] = data_columns['price'].apply(lambda x:x.replace(',',''))\ndata_columns['price'] = data_columns['price'].astype('float')\ndata_columns['cleaning_fee'] = data_columns['cleaning_fee'].apply(lambda x:x.lstrip('$'))\ndata_columns['cleaning_fee'] = data_columns['cleaning_fee'].astype('float')\ndata_columns['extra_people'] = data_columns['extra_people'].apply(lambda x:x.lstrip('$'))\ndata_columns['extra_people'] = data_columns['extra_people'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We then add cleaning_fee and exra_people to numeric features list. Since price is our predicting value, we won't put it in the feature list."},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features.extend(['cleaning_fee', 'extra_people'])\nnumeric_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, excluding the above features from the category features list."},{"metadata":{"trusted":true},"cell_type":"code","source":"category_features.remove('price')\ncategory_features.remove('cleaning_fee')\ncategory_features.remove('extra_people')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We rename the neighbourhood_cleansed to neighbourhood for better understanding."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns.columns = ['neighbourhood' if x=='neighbourhood_cleansed' else x for x in data_columns.columns]\nfeatures = data_columns\nprint(features.shape)\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_features.remove('neighbourhood_cleansed')\ncategory_features.append('neighbourhood')\ncategory_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.5 Correct highly skewed numerical features"},{"metadata":{},"cell_type":"markdown","source":"The skewed distribution has the following disadvantages:\n* Highly skewed distributions are difficult to examine because most of the observations are confined to a small part of the range of the data.\n* Outlying values in the direction of the skew are brought in toward the main body of the data when the distribution is made more symmetric. \n\nFor the features with high skewness, I uesed box-cox transformation to correct the non-normal distribution while maintaining the information."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import skew, boxcox_normmax\nfrom scipy.special import boxcox1p\nskew_features = features[numeric_features].apply(lambda x: skew(x)).sort_values(ascending=False)\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nfor i in skew_index:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.6 Get dummy categorical features"},{"metadata":{},"cell_type":"markdown","source":"We use one hot encoder to encode the categorical features."},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_encode(data, columns):\n    onehot = pd.get_dummies(data[columns])\n    onehot['id'] = data['id']\n    # move id column to the first column\n    fixed_columns = [onehot.columns[-1]] + list(onehot.columns[:-1])\n    onehot = onehot[fixed_columns]\n    return onehot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_onehot = one_hot_encode(features, category_features)\nfeatures_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Examine the distribution of price"},{"metadata":{},"cell_type":"markdown","source":"Let's examine the normality of the price distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\ndef check_dist(price):\n    print('Checking the statistical distribution of prices')\n    print(price.describe())\n    \n    print('Fitting the prices into normal distribution')\n    sns.distplot(price, fit=norm)\n\n    # Get the fitted parameters used by the function\n    (mu, sigma) = norm.fit(price)\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n    #Now plot the distribution\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n                loc='best')\n    plt.ylabel('Frequency')\n    plt.title('Price distribution')\n\n    #Get also the QQ-plot\n    fig = plt.figure()\n    res = stats.probplot(price, plot=plt)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_dist(features['price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can the distribution of price is highly skewed. Also, there are several outlier when the price is above 2000. We firstly remove outliers and then correct the distribution the price by log function."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = features[features['price']<2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correct_dist(price):\n    price = np.log1p(price)\n\n    #Check the new distribution \n    sns.distplot(price , fit=norm);\n\n    # Get the fitted parameters used by the function\n    (mu, sigma) = norm.fit(price)\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n    #Now plot the distribution\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n                loc='best')\n    plt.ylabel('Frequency')\n    plt.title('Price distribution')\n\n    #Get also the QQ-plot\n    fig = plt.figure()\n    res = stats.probplot(price, plot=plt)\n    plt.show()\n    return price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['corrected_price'] = correct_dist(features['price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3 Neighbourhoods Exploration\nFirstly, let's see the number of properities of neighbourhoods."},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_count = pd.DataFrame({'neighbourhood': features['neighbourhood'].value_counts().index, \n                                    'count': features['neighbourhood'].value_counts().values})\nneighbourhood_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_ams_count = folium.Map(location=[latitude, longitude], zoom_start=12)\nmap_ams_count.choropleth(\n    geo_data=r'/kaggle/input/airbnb-amsterdam/neighbourhoods.geojson',\n    data=neighbourhood_count,\n    columns=['neighbourhood', 'count'],\n    key_on='feature.properties.neighbourhood',\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='The number of properites',\n    reset=True\n)\nmap_ams_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The neighbourhood closer to the center, the more properites it has. The top 3 neighbourhoods are Oud-West, Centrum-West, De Pijp - Rivierenbuurt, Centrum-Oost, Zuid.\n\nThen, let's see how the median of the prices distributied in different neighbourhoods."},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_price = features.groupby('neighbourhood').median()['price']\nneighbourhood_price = pd.DataFrame({'neighbourhood':neighbourhood_price.index, 'price': neighbourhood_price.T.values})\nneighbourhood_price.sort_values('price', ascending=False, inplace=True)\nneighbourhood_price.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_ams_price = folium.Map(location=[latitude, longitude], zoom_start=12)\nmap_ams_price.choropleth(\n    geo_data=r'/kaggle/input/airbnb-amsterdam/neighbourhoods.geojson',\n    data=neighbourhood_price,\n    columns=['neighbourhood', 'price'],\n    key_on='feature.properties.neighbourhood',\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='The average_price',\n    reset=True\n)\nmap_ams_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same, the neighbourhood closer to the center, the higher median of the prices it has. Top 2 neighbourhoods are Centrum-Oost, Centrum-West."},{"metadata":{},"cell_type":"markdown","source":"## 3.4 Venues Exploration"},{"metadata":{},"cell_type":"markdown","source":"Foursquare requires client id, client secret and version for accessing their API."},{"metadata":{"trusted":true},"cell_type":"code","source":"CLIENT_ID = 'H201PLIGMNTAP5ZKN2DZK1QSDVTSZNLH4SGVA0VBPFO00MFT' # your Foursquare ID\nCLIENT_SECRET = 'JAPGNRKSTAJEQUKPATJJCNFETSEJQBAQRPDODZDNU1CN1MLP' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each venue provided by Foursquare belongs to a category and a sub_category, and each category has an unique ID (https://developer.foursquare.com/docs/build-with-foursquare/categories/).   \nFoursquare has main 10 categories: \n* 'Arts & Entertainment': '4d4b7104d754a06370d81259', \n* 'College & University': '4d4b7105d754a06372d81259', \n* 'Event': '4d4b7105d754a06373d81259', \n* 'Food': '4d4b7105d754a06374d81259',\n* 'Nightlife Spot': '4d4b7105d754a06376d81259',\n* 'Outdoors & Recreation': '4d4b7105d754a06377d81259',\n* 'Professional & Other Places': '4d4b7105d754a06375d81259',\n* 'Residence': '4e67e38e036454776db1fb3a',\n* 'Shop & Service': '4d4b7105d754a06378d81259',\n* 'Travel & Transport': '4d4b7105d754a06379d81259'}\n\n\nThe sub_category gives more detailed description. For example, the type of restaurant, such as Chinese restaurant.  \n\nIn our case, the 10 main categories would be enough for us to understand the type of venues nearby. The more detailed categories are not very helpful for us to define a location. For example, we can say a place is suitable for people who has requirement for food if there are more than 20 restaurants nearby. It is not necessary to know whether there it's a Chinese restaurant or Italy restaurant.\n\nThere are three categories in the 10 main categories usually won't affect the choices of people when they are in travel: College \\& University, Professional \\& Other Places, Residence. So we won't consider the venues belonging to these there categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"# categories = {'Arts & Entertainment': '4d4b7104d754a06370d81259', \n#                   'College & University': '4d4b7105d754a06372d81259', \n#                   'Event': '4d4b7105d754a06373d81259', \n#                   'Food': '4d4b7105d754a06374d81259',\n#                   'Nightlife Spot': '4d4b7105d754a06376d81259',\n#                   'Outdoors & Recreation': '4d4b7105d754a06377d81259',\n#                   'Professional & Other Places': '4d4b7105d754a06375d81259',\n#                   'Residence': '4e67e38e036454776db1fb3a',\n#                   'Shop & Service': '4d4b7105d754a06378d81259',\n#                   'Travel & Transport': '4d4b7105d754a06379d81259'}\ncategories = {'Arts & Entertainment': '4d4b7104d754a06370d81259', \n                  'Event': '4d4b7105d754a06373d81259', \n                  'Food': '4d4b7105d754a06374d81259',\n                  'Nightlife Spot': '4d4b7105d754a06376d81259',\n                  'Outdoors & Recreation': '4d4b7105d754a06377d81259',\n                  'Shop & Service': '4d4b7105d754a06378d81259',\n                  'Travel & Transport': '4d4b7105d754a06379d81259'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Given a pair of coordinate, Foursquare explore function can be used to return the venues nearby with the restriction of radius 1km and limit 100. In our case, we would like to know the number of venues of each main category founded near a location."},{"metadata":{"trusted":true},"cell_type":"code","source":"def getNearbyVenues(data, categories, radius=500, limit=10):\n    \n    venues_list=[]\n    print('Obtaining venues around the neighbourhoods: ', end='')\n    for name, lat, lng in zip(data['neighbourhood'], data['latitude'], data['longitude']):\n        print('.', end='')\n        # create the API request URL\n        venues = {'neighbourhood':name}\n        for category, category_id in categories.items():\n            url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&radius={}&limit={}'.format(\n                CLIENT_ID, \n                CLIENT_SECRET, \n                VERSION, \n                lat, \n                lng, \n                category_id,\n                radius, \n                limit)\n\n            # make the GET request\n            results = requests.get(url).json()[\"response\"]['groups'][0]['items'] \n            venues[category] = len(results)\n        venues_list.append(venues)\n\n    venues_list = pd.DataFrame(venues_list)\n    return venues_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unfortunately, because there are too many properties in the data and Foursquare has its limitation for the number of daily requests, it is impossible to explore the venues of every property. Alternatively, I assume the venue distribution of properties in the same neighbourhood can be similar, so I use the data of each neighbourhood center to represent the properties belonging to each neighbourhood."},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_venues = getNearbyVenues(geo_ams, categories, radius=1000, limit=100)\nprint()\nprint(neighbourhood_venues.shape)\nneighbourhood_venues.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We scale the number of venues of different categories by their percentage."},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_venues.iloc[:, 1:] = neighbourhood_venues.iloc[:, 1:].apply(lambda x: x/x.sum(), axis=1)\nneighbourhood_venues.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_venues.fillna(0, inplace=True)\nneighbourhood_venues.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.5 Merge Features"},{"metadata":{},"cell_type":"markdown","source":"Now, we have all of the features we need. Let's merge all of them."},{"metadata":{},"cell_type":"markdown","source":"### Merge all the features we have now."},{"metadata":{},"cell_type":"markdown","source":"Merge the propoerty features with neighbourhood venues by their corresponding neighbourhood."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_merged = pd.merge(features, neighbourhood_venues)\nfeatures_merged.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge the features with dummy features by IDs of properties."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_merged_dummy = pd.merge(features_merged, features_onehot)\nfeatures_merged_dummy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop the duplicate categorical features that have already been encoded."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_merged_dummy.drop(category_features, axis=1, inplace=True)\nfeatures_merged_dummy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The price of the property is the target we are going to predict.\nAnd remove all the unnecessary information of the properties,"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = features_merged_dummy['corrected_price']\nX = features_merged_dummy.drop(['id', 'name', 'latitude', 'longitude', 'price', 'corrected_price'], axis=1)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop overfitting features"},{"metadata":{},"cell_type":"markdown","source":"Drop the features that have more than 95% same values for all the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"overfit = []\nfor i in X.columns:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros / len(X) * 100 > 95:\n        overfit.append(i)\noverfit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(overfit, axis=1, inplace=True)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.6 Regression Modelling"},{"metadata":{},"cell_type":"markdown","source":"Given the information of the property, we would like to predict its price. In this section, we are going to fit our data into multiple common regression models and compare their performance on price prediction.  \n\nTo evaluate the performance of models, we firstly separate the data into training set and test set. The training set will be used to select and train the model, and the test set will be used to test the performance of the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6.1 Evaluation Matrix"},{"metadata":{},"cell_type":"markdown","source":"We use the root of mean-squared-error (rmse) to measure how close the prediction to the actual price. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html.\nThe lower rmse, the model is better."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\n# Root Mean Squared Logarithmic Error ，RMSLE\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\n#\ndef cv_rmse(model):\n    rmse = np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10))\n    return (rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6.2 Regression Models"},{"metadata":{},"cell_type":"markdown","source":"We will fit out data into the following regression models:\n* Lasso\n* Ridge\n* ElasticNet\n* GradientBoostingRegressor\n* XGBoosting regresoor\n* LightGBM regressor\n\nWe use the model from sklearn. https://scikit-learn.org/stable/supervised_learning.html#supervised-learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ridge\nridge = Ridge()\n\n#lasso\nlasso = Lasso()\n\n#elastic net\nelasticnet = ElasticNet()\n\n#GradientBoosting\ngbr = GradientBoostingRegressor(n_estimators=3000)\n\n\n#lightgbm\nlightgbm = LGBMRegressor(\n    objective='regression',\n    num_leaves=4,\n    learning_rate=0.01,\n    n_estimators=5000)\n\n#xgboost（\nxgb = XGBRegressor(learning_rate=0.01, \n                   booster='gbtree',\n                   objective='reg:linear',\n                   eval_metric='rmse',\n                   max_depth=3,\n                   min_child_weight=0,\n                   n_estimators=3000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6.3 Model Comparison\nWe use the cross validation to compare the performance of models,"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('TEST score')\n\nscore = cv_rmse(ridge) \nprint(\"Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()) ) \n\nscore = cv_rmse(lasso)\nprint(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()) ) \n\nscore = cv_rmse(elasticnet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = cv_rmse(lightgbm)\nprint(\"Lightgbm score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = cv_rmse(gbr)\nprint(\"GradientBoosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = cv_rmse(xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see boosting models (Gradient boosting, xgboosting, lightgm) show much better results than the other models. Ridge also works great and Ridge runs much fast than boosting models. So we will not consider lasso and elastinet models anymore.\n\n### 3.6.4 Model fitting\n\nLet's fit the whole training data to the remaining models."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('START Fit')\nprint('ridge')\nridge_model_full_data = ridge.fit(X_train, y_train)\nprint('GradientBoosting')\ngbr_model_full_data = gbr.fit(X_train, y_train)\nprint( 'xgboost')\nxgb_model_full_data = xgb.fit(X_train, y_train)\nprint('lightgbm')\nlgb_model_full_data = lightgbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rmsle scores on the training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('ridge', rmsle(y_train, ridge_model_full_data.predict(X_train)))\nprint('gbr', rmsle(y_train, gbr_model_full_data.predict(X_train)))\nprint('xgb', rmsle(y_train, xgb_model_full_data.predict(X_train)))\nprint('lgb', rmsle(y_train, lgb_model_full_data.predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6.5 Model Prediction\n\nTo get a better and robust model, we linearly blend the models. We give higher weights to boosting models due to their good performance and robustness."},{"metadata":{"trusted":true},"cell_type":"code","source":"def blend_models_predict(X):\n    return ((0.1 * ridge_model_full_data.predict(X)) + \n            (0.3 * gbr_model_full_data.predict(X)) + \n            (0.3 * xgb_model_full_data.predict(X)) + \n            (0.3 * lgb_model_full_data.predict(X)) )\n            \nprint('RMSLE score on train data:')\nprint(rmsle(y_train, blend_models_predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict the prices of test set using trained blend_models"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = blend_models_predict(X_test)\nrmsle(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Results"},{"metadata":{},"cell_type":"markdown","source":"The above rmsle score shows our model can accurately predict the price given the information data of the property. Once we have the trained model, more importantly, we would like to know which factor effect the price most. This can be done by examining the coef_ attribute of linear regression model or the feature_importances_ attribute of boosting regression model which represent the importance scores of all features."},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_model_list = {'ridge': ridge_model_full_data}\nnonlinear_model_list = {'GradientBoosting': gbr_model_full_data,\n                       'XGBoosting': xgb_model_full_data,\n                       'Lightgbm': lgb_model_full_data}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = []\nfor model_name, model in linear_model_list.items():\n    feature_importance.append(model.coef_)\nfor model_name, model in nonlinear_model_list.items():\n    feature_importance.append(model.feature_importances_)\nfeature_importance = pd.DataFrame(feature_importance, columns=X_train.columns)\nfeature_importance.index = list(linear_model_list.keys()) + list(nonlinear_model_list.keys())\nfeature_importance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We would like to know the top 10 most important features given by the models."},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_most_important_features(features_importance, top):\n    features_sorted = features_importance.sort_values(ascending=False)\n    return features_sorted.index.values[0:top]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_sorted = []\nfor ind in np.arange(feature_importance.shape[0]):\n    features_sorted.append(return_most_important_features(feature_importance.iloc[ind, :], top=10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_columns(top):\n    indicators = ['st', 'nd', 'rd']\n\n    columns = []\n    for ind in np.arange(top):\n        try:\n            columns.append('{}{} Important Feature'.format(ind+1, indicators[ind]))\n        except:\n            columns.append('{}th Important Feature'.format(ind+1))\n    return columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_sorted = pd.DataFrame(features_sorted, columns=return_columns(top=10))\nfeatures_sorted.index = feature_importance.index\nfeatures_sorted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the above table, there is no surprise that the number of accommodates, the number of bedrooms and the room type are top 3 most important features to the price. Bigger house can accommodate more people therefore can be more expensive. Other related factors are the number of beds and the number of bathrooms.\n\nOn the other hand, reviews also affect the price. People tend to book the property that has more reviews and higher reviews. The number of reviews can describe the opening years and the popularity of the property and the review scores can reflect the condition and reliability of the property. The two most important reviews are for checkin and location. \n\nLocation is definitely another important factor to the price. The review scores for location can reflect the neighbourhood the property locates and the how convenience the public transportation nearby. Property locating in the centrum neighbourhood can be more expensive than the others. This can by verified by the previous visualization of the medians of the prices of different neighbourhoods."},{"metadata":{"trusted":true},"cell_type":"code","source":"map_ams_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that it is true that the properties locating in Centrum-Oost and Centrum-West are more expensive than the others. It is worthy to mention these two neighbourhoods are the places where many famous places locate such as Anne Frank house, Red light district, Amsterdam museum. Also, it is interesting to see that IJburg - Zeeburgereiland also shows the high price even though it is not very close to the center. A reason could be the nice seaside scenery when living on the island. "},{"metadata":{},"cell_type":"markdown","source":"Back to the previous feature importance table, model Lightgbm shows a kind of different result than the other three models. It says cleaning_fee and fee for extra people can also effect the price. If the host doesnt charge for the fee for cleaning, that might means the fee has already included in the price. On the other hand, if the extra guest is allowed, the average cost per person might won't be very high even the fee for extra people is charged.\n\nNext, let's look at the venues features only."},{"metadata":{"trusted":true},"cell_type":"code","source":"venues_sorted = []\nfor model_name, model_feature_importance in feature_importance.iterrows():\n    venues_sorted.append(return_most_important_features(model_feature_importance[list(categories.keys())], top=7))\nvenues_sorted = pd.DataFrame(venues_sorted, columns=return_columns(top=7))\nvenues_sorted.index = feature_importance.index\nvenues_sorted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can find something that is interesting that whether there is a nightlife spot nearby can affect the price a most. A proper  interpretation could be that the nightlife spots usually locate the centrum neighbourhoods so that the location is the actual influential factor. \n\nIt is not surprising that Food and Shop & Service are two important venues. Tourists might don't want to spend a lot of time on finding restaurants or shopping places. What really surprises me is that Travel & Transport is ranked as the least important feature by three models. If we compare the area of Amsterdam and other famous tourism cities in the world, for instance, new york, the area of New york is three times larger that Amsterdam. Amsterdam has intense public transportation network including bus, metro, tram, ship. And bicycling is a fashion way in the Netherlands to go out. So, people can always find a convenient way to go out no matter where they live."},{"metadata":{},"cell_type":"markdown","source":"# 5. Discussion"},{"metadata":{},"cell_type":"markdown","source":"According to the our analysis, the price of the proper on Airbnb in Amsterdam mostly varies based on the number of accommodates/the number of bedrooms, the location and the extra fee (cleaning fee/fee for extra people). Bigger house and house close to city center or public transportation can be more expensive than the other. And the price can be higher if the extra fee is included in the price. Also, properties that locate near nightlife spots can be more expensive.\n\nHere are my recommendations:\n\nIf you want to rent your house in Amsterdam on Airbnb:\n* If you have a house in the popular neighbourhoods, then congratulations, you can rent your house in a good price.\n* Ask for reviews from your guests. People trust on the previous review than your description and pictures. Showing on time when checking-in, being honest and providing good service (such as allowing extra guest) can really helpful on gaining higher review scores.\n\nIf you are going to visit Amsterdam and want to live in a local house:\n* The more bedrooms and bathrooms in the house, the price can be more expensive. If you can find more travelling partners who don't mind sharing bedrooms or bathrooms with you, the average price per person can be very fair.\n* It is always expensice to live in the center. If you really care about living close to center, I recommend to live in the neighbourhood of Oud-West which has the most number of houses but the median price ranks the 5th expensive neighbourhood. If you have an empty wallet, considering the mature public transportation network of Amsterdam, I recommend to live in the neighourhood far away from the center. Even if you live the suburb, a less than 30-minutes train can take you to the center.\n* Places having many restaurants and shopping places nearby can be expensive. You can choose other places if you don't necessarily eat or shop near the place you live.\n* If you are a night owl and a lover to night clubs of Amsterdam, unfortunately, you might need to prepare more budgets on accommodation.\n\nThere are might be other factors can effect the price such as the decoration of the property and the service the host can provide. Unfortunately, we can't go through the influence of all of possible factors due to the unavailability of the data. However, I believe my analysis is extremely valuable for the hosts from Amsterdam who wants to define the price of their proprieties or tourists who want to have a estimate of the accommodation cost based on their requirements and budgets. This analysis can also be applied to any other city in the world."},{"metadata":{},"cell_type":"markdown","source":"# 6. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"In this project, I analyzed the Airbnb houses in Amsterdam using the Airbnb data and the venue information of neighbourhoods provided by Foursquare API. I used several classic regression models to predict the price of the properties and analyzed the most important factors to the price of a property. Based on the above analysis, several recommendations were proposed to people who want to rent their house on Airbnb and people who to live in a local place in Amsterdam. This analysis can be adapted to any other city's Airbnb house price analysis.\n\nThis is the final project of my IBM professional certificate course on Coursera. I would like to thanks to myself for consisting motivating myself to explore better solution, and I also would like to thanks to the time of the person who is reviewing this work. Hope everyone can by happy and safe."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}