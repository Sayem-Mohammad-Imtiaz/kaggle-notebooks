{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Analysis on Sales of summer clothes in E-commerce Wish\n### This notebook is open for improvement\n\n#### Goal of this notebook is to have a clear understanding of the data set and help people build their own notebooks","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data\n\n* **pd.read_csv** function reads the .csv (Comma seperated value) file and turns it into a data table.\n* **data.head()** function shows the top 5 rows from this data table.\n\n#### You can copy filepath directly from the box which shows up when you hover your mouse on a certain file\n#### Paste this filepath between quotes to make pd.read_csv function load your data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/summer-products-and-sales-in-ecommerce-wish/summer-products-with-rating-and-performance_2020-08.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categories","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Loading data about categories\n\nUsing the **head(100)** function to get top 100 columns, which containts the %69 of the sales.\nWe will use this data to manipulate tags of the original data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categoryData = pd.read_csv(\"../input/summer-products-and-sales-in-ecommerce-wish/unique-categories.sorted-by-count.csv\")\ncategoryData['count'].head(100).sum()/categoryData['count'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importantTags = categoryData.keyword.head(100).str.lower().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection & Generation\n**data.columns** shows us the names of the columns, if we put this info into len() functions, it will tell us the number of columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are \",len(data.columns), \" columns in this dataset.\\nColumns:\\n\",data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Storing important tags (Those tags contains %69 percent of all sales, don't forget about these, we will use them later!)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importantTags = categoryData.keyword.head(20).str.lower().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping unnecessary columns\n\n### Title and Title_orig\n**Title** column is language dependent, while **title_orig** column is english, so we will drop **title**\n\nColumns **title** and **title_orig** definitely have an effect on the units sold, but it would require NLP and semantic analysis to turn this data into meaningful categories (Sentiment, theme or maybe word popularity in the title can effect the sales), so these two columns will be dropped.\n\n**data.drop** function helps us to drop specific columns. We pass the columns we want to drop to the columns= parameter of this function. A new data table without these columns will be generated, you can store this new data table in different variables to preserve your original data table.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures = data.drop(columns=['title','title_orig'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What does ID's represent\nAs It can bee seen below, a product gets it's ID based on it's merchant, in other words, two EXACT same products have different ID's on different merchants, therefore we cannot use product ID to calculate a certain product's success, therefore we will be dropping that column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pid_dt = selectedFeatures['product_id']\nmid_dt = selectedFeatures['merchant_id']\nprint(len(pid_dt), len(mid_dt))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Other unnecessary columns\n* **merchant_id** is a data which doesn't mean anything to humans, but we could use the merchant's popularity, but code above shows us not even a single merchant is selling more than one item, so this column is unnecessary. So we will drop this and all other columns which are related to merchant\n* **product_id** read the explanation above,this will be dropped\n* **product_url** should not have an effect on sales numbers, but who knows, I *COULD* buy anything from an URL which consists ***THE BATMAN***, anyways we will drop this column too, it is not relevant.\n* **product_picture** column carries the link info, not the picture itself, we could also use the picture itself to define some kind of feature, but we cannot do this using the link of the picture.\n* **urgency_text** this column has info about the product but it is not categorical data, merchant can write anything he/she likes to describe the urgency of the product, so the distribution is scattered to extract any valuable info from this column\n* **shipping_option_name** can vary from language to language, therefore we will be interested in shipping price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures=selectedFeatures.drop(columns=['merchant_id','merchant_title',\n                                                'merchant_name','merchant_profile_picture',\n                                                'merchant_info_subtitle','product_id','product_url',\n                                                'product_picture','shipping_option_name','urgency_text'])\nselectedFeatures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing other columns\nWe will be analyzing the columns which we did not drop yet, after analyzing we will be generating new features from those.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### price to retail_price","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Does retail price compared to price have an effect on the total sales? As you can see below, people on Wish doesn't really care about the price they pay. Our newly generated column \"ret_to_price_ratio\" represents the retail price ratio to real price.\n\nVariable named **rptp** is short for \"retail price to price\", selectedFeatures[[COLUMNS]] returns a data table with specified columns. In our case, these columns are \"price\" and \"retail_price\", then we generate a new column on selectedFeatures data table and name it \"ret_to_price_ratio\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rptp = selectedFeatures[['price','retail_price']]\nselectedFeatures['ret_to_price_ratio'] = rptp['retail_price']/rptp['price']\nselectedFeatures[['ret_to_price_ratio','units_sold']].sort_values(by=['units_sold'],ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rating to sales ratio means anything?\nAs you can see in the plot below, there is a negative correlation between rating/rating count to sales\n\n# Overfitting example\nI wanted to show an overfitting example and bad feature extracting practise.\nAs you can see below, we are assigning the units_sold/rating and units_sold/rating_count as new columns. This is a bad practise and doesn't mean that you developed a \"good\" model. This means you cheated. Do not use the value you are going to predict to generate new values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rtrc_columns = selectedFeatures[['rating','rating_count','units_sold']]\nrtrc = rtrc_columns['rating']/(rtrc_columns['rating_count']+1) # +1 is in order to deflect infinity\n#These two lines will cause overfitting!!!!!\nselectedFeatures['sales_to_rating'] = rtrc_columns['units_sold']/rtrc_columns['rating'] #Overfitting 1\nselectedFeatures['sales_to_rating_count'] = rtrc_columns['units_sold']/(rtrc_columns['rating_count']+1) #Overfitting 2\n#Change the two lines marked as \"Overfitting\"!!!!!\nselectedFeatures['rating_to_rating_count'] = rtrc\nmatplotlib.pyplot.scatter(rtrc_columns['units_sold'],rtrc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Currency\nDoes currency of the buyer have an effect on the total sales? There is only one currency in this data table, as you can see below, which provides nothing to our analysis so it will be dropped","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(selectedFeatures['currency_buyer'].unique())\nselectedFeatures = selectedFeatures.drop(columns=['currency_buyer'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### uses_ad_boosts\nDoes using ad boosts really effect the number of sales? Lets see. As you can see below, using ad boosts doesn't have a meaningful effect on the sales number.\n\nWe select two necessary columns in line 1\nThen groupping data we got under unique values of \"uses_ad_boosts\", using the mean of the \"units_sold\"\nThen we drop this column in selectedFeatures because it does not provide any valuable information\n\nMean units sold for ad boost users is 4167.13\nMean units sold for non ad boost users is 4470.21","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ad_boost_success = selectedFeatures[['uses_ad_boosts','units_sold']]\nad_boost_success = ad_boost_success.groupby(['uses_ad_boosts']).mean().sort_values(by=['units_sold'], ascending = False)\nad_boost_success","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rating and rating_count\nRating is between 1-5, which seems small but because of the float data it carries, the range is too high, so it will be converted into categorical data. You can see the positive correlation between categorical rating and units sold in the graph.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"conditions = [(selectedFeatures['rating']<2),\n              ((selectedFeatures['rating']>=2) & (selectedFeatures['rating']<3)),\n              ((selectedFeatures['rating']>=3) & (selectedFeatures['rating']<4)),\n              ((selectedFeatures['rating']>=4) & (selectedFeatures['rating']<=5))]\ntags = ['tag_1','tag_2','tag_3','tag_4']\nselectedFeatures = selectedFeatures.assign(categorical_rating = np.select(conditions,tags))\n#selectedFeatures['categorical_rating'] = round(selectedFeatures['rating'],1)\n\n#These three lanes are for generating the plot and will be repeated frequently\nrating_to_sales = selectedFeatures[['units_sold','categorical_rating']]\nrating_to_sales = rating_to_sales.groupby(['categorical_rating']).mean().sort_values(by=['categorical_rating'])\nrating_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see in the print statement below, rating counts range from 0 to 20744 with mean of 890. This means that the data is not uniformly distributed and likely have too many outliers, my solution to this is converting this data into categorical data. Again, you can observe the positive correlation in the graph below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Min: \", min(selectedFeatures['rating_count']),\"\\nMax: \", max(selectedFeatures['rating_count']),\"\\nMean: \",selectedFeatures['rating_count'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"low = selectedFeatures['rating_count'].quantile(0.3)\nmid = selectedFeatures['rating_count'].quantile(0.6)\nhigh = selectedFeatures['rating_count'].quantile(0.9)\n\nconditions = [(selectedFeatures['rating_count']<low),\n              ((selectedFeatures['rating_count']>=low) & (selectedFeatures['rating_count']<mid)),\n              ((selectedFeatures['rating_count']>=mid) & (selectedFeatures['rating_count']<high)),\n              (selectedFeatures['rating_count']>=high)\n             ]\ntags = ['tag0_low','tag2_mid','tag4_high','tag5_extreme']\nselectedFeatures = selectedFeatures.assign(categorical_rating_count = np.select(conditions,tags))\nrating_count_to_sales = selectedFeatures[['units_sold','categorical_rating_count']]\nrating_count_to_sales = rating_count_to_sales.groupby(['categorical_rating_count']).mean().sort_values(by=['categorical_rating_count'])\nrating_count_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to convert \"rating_five_count\" into categorical data, just copy-paste and edit the code above\nThis also have a positive correlation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"low =selectedFeatures['rating_five_count'].quantile(0.3)\nmid = selectedFeatures['rating_five_count'].quantile(0.6)\nhigh = selectedFeatures['rating_five_count'].quantile(0.9)\n\nconditions = [(selectedFeatures['rating_five_count']<low),\n              ((selectedFeatures['rating_five_count']>=low) & (selectedFeatures['rating_five_count']<mid)),\n              ((selectedFeatures['rating_five_count']>=mid) & (selectedFeatures['rating_five_count']<high)),\n              (selectedFeatures['rating_five_count']>=high)\n             ]\ntags = ['tag0_low','tag2_mid','tag4_high','tag5_extreme']\nselectedFeatures = selectedFeatures.assign(categorical_rating_five_count = np.select(conditions,tags))\nrating5_count_to_sales = selectedFeatures[['units_sold','categorical_rating_five_count']]\nrating5_count_to_sales = rating5_count_to_sales.groupby(['categorical_rating_five_count']).mean().sort_values(by=['categorical_rating_five_count'])\nrating5_count_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Repeat the same process for the other star counts","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Four stars: Still positive correlation, lets check if this trend changes when ratings get lower.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"low =selectedFeatures['rating_four_count'].quantile(0.3)\nmid = selectedFeatures['rating_four_count'].quantile(0.6)\nhigh = selectedFeatures['rating_four_count'].quantile(0.9)\n\nconditions = [(selectedFeatures['rating_four_count']<low),\n              ((selectedFeatures['rating_four_count']>=low) & (selectedFeatures['rating_four_count']<mid)),\n              ((selectedFeatures['rating_four_count']>=mid) & (selectedFeatures['rating_four_count']<high)),\n              (selectedFeatures['rating_four_count']>=high)\n             ]\ntags = ['tag0_low','tag2_mid','tag4_high','tag5_extreme']\nselectedFeatures = selectedFeatures.assign(categorical_rating_four_count = np.select(conditions,tags))\n\nrating4_count_to_sales = selectedFeatures[['units_sold','categorical_rating_four_count']]\nrating4_count_to_sales = rating4_count_to_sales.groupby(['categorical_rating_four_count']).mean().sort_values(by=['categorical_rating_four_count'])\nrating4_count_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Three stars: Trend still goes on.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"low =selectedFeatures['rating_three_count'].quantile(0.3)\nmid = selectedFeatures['rating_three_count'].quantile(0.6)\nhigh = selectedFeatures['rating_three_count'].quantile(0.9)\n\nconditions = [(selectedFeatures['rating_three_count']<low),\n              ((selectedFeatures['rating_three_count']>=low) & (selectedFeatures['rating_three_count']<mid)),\n              ((selectedFeatures['rating_three_count']>=mid) & (selectedFeatures['rating_three_count']<high)),\n              (selectedFeatures['rating_three_count']>=high)\n             ]\ntags = ['tag0_low','tag2_mid','tag4_high','tag5_extreme']\nselectedFeatures = selectedFeatures.assign(categorical_rating_three_count = np.select(conditions,tags))\nrating3_count_to_sales = selectedFeatures[['units_sold','categorical_rating_three_count']]\nrating3_count_to_sales = rating3_count_to_sales.groupby(['categorical_rating_three_count']).mean().sort_values(by=['categorical_rating_three_count'])\nrating3_count_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two stars:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"low =selectedFeatures['rating_two_count'].quantile(0.3)\nmid = selectedFeatures['rating_two_count'].quantile(0.6)\nhigh = selectedFeatures['rating_two_count'].quantile(0.9)\n\nconditions = [(selectedFeatures['rating_two_count']<low),\n              ((selectedFeatures['rating_two_count']>=low) & (selectedFeatures['rating_two_count']<mid)),\n              ((selectedFeatures['rating_two_count']>=mid) & (selectedFeatures['rating_two_count']<high)),\n              (selectedFeatures['rating_two_count']>=high)\n             ]\ntags = ['tag0_low','tag2_mid','tag4_high','tag5_extreme']\nselectedFeatures = selectedFeatures.assign(categorical_rating_two_count = np.select(conditions,tags))\nrating2_count_to_sales = selectedFeatures[['units_sold','categorical_rating_two_count']]\nrating2_count_to_sales = rating2_count_to_sales.groupby(['categorical_rating_two_count']).mean().sort_values(by=['categorical_rating_two_count'])\nrating2_count_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One star:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"low =selectedFeatures['rating_one_count'].quantile(0.3)\nmid = selectedFeatures['rating_one_count'].quantile(0.6)\nhigh = selectedFeatures['rating_one_count'].quantile(0.9)\n\nconditions = [(selectedFeatures['rating_one_count']<low),\n              ((selectedFeatures['rating_one_count']>=low) & (selectedFeatures['rating_one_count']<mid)),\n              ((selectedFeatures['rating_one_count']>=mid) & (selectedFeatures['rating_one_count']<high)),\n              (selectedFeatures['rating_one_count']>=high)\n             ]\ntags = ['tag0_low','tag2_mid','tag4_high','tag5_extreme']\nselectedFeatures = selectedFeatures.assign(categorical_rating_one_count = np.select(conditions,tags))\nrating1_count_to_sales = selectedFeatures[['units_sold','categorical_rating_one_count']]\nrating1_count_to_sales = rating1_count_to_sales.groupby(['categorical_rating_one_count']).mean().sort_values(by=['categorical_rating_one_count'])\nrating1_count_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it can be observed above, number of the ratings is more important than positive ratings, Quantity > Quality in this case.\n\n\nNow we have replacements for \"rating\", \"rating count\", and all \"rating X count\" colums, therefore we no longer need them, we can drop it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures = selectedFeatures.drop(columns=['rating','rating_count','rating_five_count','rating_four_count',\n                                                  'rating_three_count','rating_two_count','rating_one_count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have to convert the rating of the merchant into categorical data. The graph is nearly linear and has positive tangent. Which means positive correlation between merchant rating and units sold.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"conditions = [(selectedFeatures['merchant_rating']<2),\n              ((selectedFeatures['merchant_rating']>=2) & (selectedFeatures['merchant_rating']<3)),\n              ((selectedFeatures['merchant_rating']>=3) & (selectedFeatures['merchant_rating']<4)),\n              ((selectedFeatures['merchant_rating']>=4) & (selectedFeatures['merchant_rating']<=5))]\ntags = ['tag_1','tag_2','tag_3','tag_4']\n#selectedFeatures['categorical_merchant_rating'] = round(selectedFeatures['merchant_rating'],1)\nselectedFeatures = selectedFeatures.assign(categorical_merchant_rating = np.select(conditions,tags))\n\n\nm_rating_to_sales = selectedFeatures[['units_sold','categorical_merchant_rating']]\nm_rating_to_sales = m_rating_to_sales.groupby(['categorical_merchant_rating']).mean().sort_values(by=['categorical_merchant_rating'])\nm_rating_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now rating count of the merchant. Again positive correlation, I wonder if we can find anything BAD.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"low = selectedFeatures['merchant_rating_count'].quantile(0.3)\nmid = selectedFeatures['merchant_rating_count'].quantile(0.6)\nhigh = selectedFeatures['merchant_rating_count'].quantile(0.9)\n\nconditions = [(selectedFeatures['merchant_rating_count']<low),\n              ((selectedFeatures['merchant_rating_count']>=low) & (selectedFeatures['merchant_rating_count']<mid)),\n              ((selectedFeatures['merchant_rating_count']>=mid) & (selectedFeatures['merchant_rating_count']<high)),\n              (selectedFeatures['merchant_rating_count']>=high)\n             ]\nselectedFeatures = selectedFeatures.assign(categorical_merchant_rating_count = np.select(conditions,tags))\n\nm_rating_count_to_sales = selectedFeatures[['units_sold','categorical_merchant_rating_count']]\nm_rating_count_to_sales = m_rating_count_to_sales.groupby(['categorical_merchant_rating_count']).mean().sort_values(by=['categorical_merchant_rating_count'])\nm_rating_count_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop data related to merchants rating, we already replaced them with categorical data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures = selectedFeatures.drop(columns=['merchant_rating_count','merchant_rating'])\nselectedFeatures","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Origin country\nEven though some countries have small sample size (AT and VE), we can see that some countries are more successful, but because we have nearly no info on other countries, we will drop this column. You can see this in the pie chart below, more than 3/4 of the units sold belongs to two countries.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"origin_country_success = selectedFeatures[['origin_country','units_sold']]\norigin_country_success = origin_country_success.groupby(['origin_country']).mean().sort_values(by=['units_sold'], ascending = False)\nselectedFeatures = selectedFeatures.drop(columns=['origin_country'])\norigin_country_success.plot.pie(subplots=True, figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Theme\nThe only theme is \"summer\" so dropping this will help the performance of our model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"themes = selectedFeatures['theme']\nprint(themes.unique())\nselectedFeatures = selectedFeatures.drop(columns=['theme'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Duplicate data\nWe have to drop them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(selectedFeatures.duplicated().sum())\nselectedFeatures.drop_duplicates(inplace=True)\nselectedFeatures = selectedFeatures.reset_index(drop=True)\nselectedFeatures.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoding\nWe will convert data shown as \"object\" into integers or floats to ease our model defining and training process.\nWe cannot encode \"product_color\" and \"product_variation_size_id\" columns so we have to drop them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures = selectedFeatures.drop(columns=['product_variation_size_id','product_color'])\n\nencoder = LabelEncoder() #From sklearn.preprocessing library\n\nselectedFeatures['categorical_merchant_rating_count'] = encoder.fit_transform(selectedFeatures['categorical_merchant_rating_count'])\nselectedFeatures['categorical_merchant_rating'] = encoder.fit_transform(selectedFeatures['categorical_merchant_rating'])\n\nselectedFeatures['categorical_rating_five_count'] = encoder.fit_transform(selectedFeatures['categorical_rating_five_count'])\nselectedFeatures['categorical_rating_four_count'] = encoder.fit_transform(selectedFeatures['categorical_rating_four_count'])\nselectedFeatures['categorical_rating_three_count'] = encoder.fit_transform(selectedFeatures['categorical_rating_three_count'])\nselectedFeatures['categorical_rating_two_count'] = encoder.fit_transform(selectedFeatures['categorical_rating_two_count'])\nselectedFeatures['categorical_rating_one_count'] = encoder.fit_transform(selectedFeatures['categorical_rating_one_count'])\n\nselectedFeatures['categorical_rating_count'] = encoder.fit_transform(selectedFeatures['categorical_rating_count'])\nselectedFeatures['categorical_rating'] = encoder.fit_transform(selectedFeatures['categorical_rating'])\nselectedFeatures['crawl_month'] = encoder.fit_transform(selectedFeatures['crawl_month'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to convert float64 values into float32, because our model does not support float64","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures['ret_to_price_ratio'] = np.float32(selectedFeatures['ret_to_price_ratio'])\nselectedFeatures['sales_to_rating'] = np.float32(selectedFeatures['sales_to_rating'])\nselectedFeatures['price'] = np.float32(selectedFeatures['price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"has_urgency_banner column have NaN values, so I have to convert it manually","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nselectedFeatures = selectedFeatures.assign(has_urgency = (data['has_urgency_banner']==1.0).astype(int))\nselectedFeatures = selectedFeatures.drop(columns=['has_urgency_banner','crawl_month'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets check our data table and columns\n.T operation means \"Transpose of the matrix/datatable\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tags\nTags are just list of strings, we will create new columns using the important tags, and drop this column, then we calculate the weighted tags, which gives the most weight to most popular tag.\n\nAs you can see below, there is no visible correlation between weighted tags and units sold","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weightedTags = []\nfor i in range(len(selectedFeatures['tags'])):\n    count = 0\n    weight = 100\n    for j in range(len(importantTags)):\n        if importantTags[j] in selectedFeatures['tags'][i]:\n            count+=weight\n        weight-=5\n    weightedTags.append(count)\n    \ndf = pd.DataFrame({'weightedTags':weightedTags})\nselectedFeatures['weightedTags'] = df['weightedTags']\nselectedFeatures = selectedFeatures.drop(columns=['tags'])\n\nweighted_tags_to_sales = selectedFeatures[['units_sold','weightedTags']]\nweighted_tags_to_sales = weighted_tags_to_sales.groupby(['weightedTags']).mean().sort_values(by=['weightedTags'])\nweighted_tags_to_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selectedFeatures.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining and training the model\nSeperating the data table into two data tables; one contains the features to predict sales, other holds the sales","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = selectedFeatures.drop(columns=['units_sold'])\nsales = selectedFeatures['units_sold']\n\nfeature_train,feature_test,sale_train,sale_test=train_test_split(features,sales,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Training a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor=RandomForestRegressor(n_estimators=10000)\nregressor.fit(feature_train,sale_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make predictions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Do not trust this prediction score, because as I stated previously, this data means nothing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_pred=regressor.predict(feature_test)\nprint(\"Prediction score: \", r2_score(sale_pred,sale_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Your Turn\n\nCan you improve this notebook by defining new feautres or improving the features that we generated already?\nGo on, copy this notebook and work on it!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}