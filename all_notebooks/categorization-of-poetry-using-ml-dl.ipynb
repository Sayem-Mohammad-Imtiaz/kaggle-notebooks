{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing Library"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport string\nimport matplotlib.pyplot as plt\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score,precision_score,recall_score\nfrom sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/all.csv')   #importing csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #showing the first 5 content","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing empty data\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('type').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content = df['content'].tolist()[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(content)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = 'Love', 'Mythology & Folklore', 'Nature'\nsizes = [326, 58, 187]\n\n\nfig1, ax1 = plt.subplots(figsize=(5,5))\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=False, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert Data into Feature**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.content.str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove list in the document\nremove_list=[\"A\",\n\"An\",\n\"The\",\n\"Aboard\",\n\"About\",\n\"Above\",\n\"Absent\",\n\"Across\",\n\"After\",\n\"Against\",\n\"Along\",\n\"Alongside\",\n\"Amid\",\n\"Among\",\n\"Amongst\",\n\"Anti\",\n\"Around\",\n\"As\",\n\"At\",\n\"Before\",\n\"Behind\",\n\"Below\",\n\"Beneath\",\n\"Beside\",\n\"Besides\",\n\"Between\",\n\"Beyond\",\n\"But\",\n\"By\",\n\"Circa\",\n\"Concerning\",\n\"Considering\",\n\"Despite\",\n\"Down\",\n\"During\",\n\"Except\",\n\"Excepting\",\n\"Excluding\",\n\"Failing\",\n\"Following\",\n\"For\",\n\"From\",\n\"Given\",\n\"In\",\n\"Inside\",\n\"Into\",\n\"Like\",\n\"Minus\",\n\"Near\",\n\"Of\",\n\"Off\",\n\"On\",\n\"Onto\",\n\"Opposite\",\n\"Outside\",\n\"Over\",\n\"Past\",\n\"Per\",\n\"Plus\",\n\"Regarding\",\n\"Round\",\n\"SO\",\n\"Save\",\n\"Since\",\n\"Than\",\n\"Through\",\n\"To\",\n\"Toward\",\n\"Towards\",\n\"Under\",\n\"Underneath\",\n\"Unlike\",\n\"Until\",\n\"Up\",\n\"Upon\",\n\"Versus\",\n\"Via\",\n\"With\",\n\"Within\",\n\"Without\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace those words with space\nfor  value in remove_list:\n    df.content=df.content.str.replace(value,\" \")\ndf.content","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to remove punctuation\ndef removePunctuation(x):\n    x = x.lower()\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    x = x.replace('\\r','')\n    x = x.replace('\\n','')\n    x = x.replace('  ','')\n    x = x.replace('\\'','')\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)\n\n#getting stop words\nfrom nltk.corpus import stopwords\n\nstops = set(stopwords.words(\"english\")) \n\n\n#function to remove stopwords\ndef removeStopwords(x):\n    filtered_words = [word for word in x.split() if word not in stops]\n    return \" \".join(filtered_words)\n\n\ndef processText(x):\n    x= removePunctuation(x)\n    x= removeStopwords(x)\n    return x\n\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nX= pd.Series([word_tokenize(processText(x)) for x in df['content']])\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# regular expression, using stemming: try to replace tail of words like ies to y \nimport re\n\ndf.content = df.content.str.replace(\"ing( |$)\", \" \")\ndf.content = df.content.str.replace(\"[^a-zA-Z]\", \" \")\ndf.content = df.content.str.replace(\"ies( |$)\", \"y \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert Sentences into List of words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sent_to_words(content):\n    return [np.array([x.split() for x in poem.split()]) for poem in content]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poem = sent_to_words(content)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert Char to Number Mapping**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_dict(poem):\n    dictionary = {}\n    rev_dict = {}\n    count = 0\n    for content in poem:\n        for i in content:\n            if i[0] in dictionary:\n                pass\n            else:\n                dictionary[i[0]] = count\n                count += 1\n    rev_dict = dict(zip(dictionary.values(), dictionary.keys()))\n    return dictionary, rev_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary, rev_dict = build_dict(poem)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tensor Starts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.contrib import rnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters\nlearning_rate = 0.0001\ntraining_iters = 1600\ndisplay_step = 200\nn_input = 9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of units in RNN cell\nn_hidden = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf Graph input\ntf.device(\"/device:GPU:0\")\nx = tf.placeholder(\"float\", [None, n_input, 1])\ny = tf.placeholder(\"float\", [None, vocab_size])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RNN output node weights and biases\nweights = {\n    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n}\nbiases = {\n    'out': tf.Variable(tf.random_normal([vocab_size]))\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RNN(x, weights, biases):\n\n    # reshape to [1, n_input]\n    x = tf.reshape(x, [-1, n_input])\n\n    # Generate a n_input-element sequence of inputs\n    # (eg. [had] [a] [general] -> [20] [6] [33])\n    x = tf.split(x,n_input,1)\n\n    # 2-layer LSTM, each layer has n_hidden units.\n    # Average Accuracy= 95.20% at 50k iter\n    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n    # generate prediction\n    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n    # there are n_input outputs but\n    # we only want the last output\n    return tf.matmul(outputs[-1], weights['out']) + biases['out']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = RNN(x, weights, biases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model evaluation\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"saver = tf.train.Saver()\ninit = tf.global_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = sent_to_words(content)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j = 0\nfor i in df_train:\n    if i.shape[0] <= n_input:\n        df_train = np.delete(df_train, (j), axis = 0)\n        j -= 1\n    j += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as session:\n    session.run(init)\n    step = 0\n    end_offset = n_input + 1\n    acc_total = 0\n    loss_total = 0\n    while step < training_iters:\n        acc_total = 0\n        loss_total = 0\n        j = 0\n        for training_data in df_train:\n            m = training_data.shape[0]\n            windows = m - n_input\n            acc_win = 0\n            for window in range(windows):\n                batch_x = training_data[window : window + n_input]\n                batch_y = training_data[window + n_input]\n                symbols_in_keys = [dictionary[i[0]] for i in batch_x]\n                symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n        \n                symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n                symbols_out_onehot[dictionary[batch_y[0]]] = 1.0\n                symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n\n                _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n                loss_total += loss\n                acc_win += acc\n            acc_total += float(acc_win) / m\n        acc_total /= len(df_train)\n        if (step+1) % display_step == 0:\n            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n                  \"{:.2f}%\".format(100*acc_total))\n        step += 1\n    print(\"Optimization Finished!\")\n    save_path = saver.save(session, \"../working/model.ckpt\")\n    print(\"Model saved in path: %s\" % save_path)\n    while True:\n        prompt = \"%s words: \" % n_input\n        sentence = 'When I Queen Mab within my fancy viewed, My'\n        sentence = sentence.strip()\n        words = sentence.split(' ')\n        if len(words) != n_input:\n            continue\n        try:\n            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n            for i in range(64):\n                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n                onehot_pred = session.run(pred, feed_dict={x: keys})\n                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n                sentence = \"%s %s\" % (sentence,rev_dict[onehot_pred_index])\n                symbols_in_keys = symbols_in_keys[1:]\n                symbols_in_keys.append(onehot_pred_index)\n            print(sentence)\n            break\n        except:\n            print(\"Word not in dictionary\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}