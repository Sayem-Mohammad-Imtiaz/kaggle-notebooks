{"cells":[{"cell_type":"markdown","source":"This is the first Kernel that I have ever published on Kaggle. Took me 3 months of learning to finally pluck up the courage and post my intital work on this reputed site. I really hope the Kernel helps novice Data Scientists/Machine Learning engineers like me understand the basic concepts of Machine Learning. Feedback would be HIGHLY appreciated, and would help me become a better coder :) Thank you for taking the time out in reading this.","metadata":{"_cell_guid":"8dbf1fa6-5991-474d-a5f1-d17b06a7f31b","_uuid":"571b46418e7f3d2208517a65a2a8bc8f6e31c296"}},{"cell_type":"markdown","source":"I have used the following algortihms and calculated the AUC and accuracy for each of the Supervised learning algos. I am still a noob in the Unsupervised learning section, but I feel I'm making progress! :) \nSupevised Learning - Logistic Regression, Naive Bayes, Decision Trees, Random Forests\nUnsupervised Learning - Principal Component Analysis (PCA), KMeans (Flat Clustering), MeanShift (Hierarchical Clustering)","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"e8470ca1-60d2-49b4-baa0-da3e49b3d7b8","_uuid":"e510a0f95576f84819a659820df3d67682a160ac","scrolled":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_cell_guid":"760f1cf3-79a5-4e10-87de-aafc38d34864","collapsed":true,"_uuid":"39b1bb755d60a11008fed718ff25848c2231d418"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data = pd.read_csv(\"../input/mushrooms.csv\")","metadata":{"_cell_guid":"0de6c318-5617-491d-a936-765a455b9f7f","collapsed":true,"_uuid":"72cb4082b72505bef1b76c6961f356ca2512dac0"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data.shape","metadata":{"_cell_guid":"3d734c58-8e48-4968-8531-be2e13644262","_uuid":"4313ebcc3aec6e8d2563cda066428d498e9b4fa4"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data.head()","metadata":{"_cell_guid":"1dabb02e-6b96-4948-a5e6-eab454047a6f","_uuid":"622742b42183b641a32997d6beaf1c8296bdcc63"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#ALl the variables are in string format. Convert categorical variables to integer using label encoder\nfrom sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder()","metadata":{"_cell_guid":"fac98efd-a096-4ec9-a3c8-db2d5b6ad7c9","collapsed":true,"_uuid":"8839463b9d1f7558392c311787d264684e9d3509"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"for col in data.columns:\n    data[col]=lbl.fit_transform(data[col])    ","metadata":{"_cell_guid":"1dcd54d4-1e9b-4e90-8226-181748b6c0cf","collapsed":true,"_uuid":"826f2652aaa961541fea4f6b99eed3142eceb0c8"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#check the data after label encoding\ndata.head()","metadata":{"_cell_guid":"440aeaba-519d-49a4-8430-413e438e45cc","_uuid":"5e52c663f5e2f97543d3514815bd74d371fc5c3e"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#split the x and y variables\ny=data['class']\nx=data.iloc[:,1:23]","metadata":{"_cell_guid":"8636fb59-cb29-4efb-a6b2-6b80b9b8963d","collapsed":true,"_uuid":"8d61d2e60b170614ff1e02027783f12bc5d432b5"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#check shape of new variables\nx.shape","metadata":{"_cell_guid":"9a6e1c86-0220-44cd-9e48-0fcab2812860","_uuid":"0214927c649b003d193f8a21cd3c17322bd8ea0d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"y.shape","metadata":{"_cell_guid":"8e897f37-25dc-4175-8f10-dc63533970be","_uuid":"20cf483e11c7c436f8334a5bf087858441019c3f","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#check data\nx.head","metadata":{"_cell_guid":"159e1abb-65ab-44c2-babb-566f39d58738","_uuid":"c81a9d104278a2bab30c9b63f2ce9ddadcd5a9ba","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"y.head","metadata":{"_cell_guid":"860022c1-66ce-4ba4-8dfa-328221b62109","_uuid":"8e6e6f3894f3981a88fbcdaf9bb10f97d77e2760","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#I want to use PCA on this data. First normalise the data using StandardScalar so that the data is now between -1 and 1\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx = sc.fit_transform(x)","metadata":{"_cell_guid":"18b0dc23-0983-435b-a266-c6857d9369d2","collapsed":true,"_uuid":"0742a935a01c912febeb33f1583568f5cd7f675b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#see the Standardised data\nprint(x)","metadata":{"_cell_guid":"6444e659-de06-45ee-ad17-a4f858888707","_uuid":"401f9b6ae549583e5152f4c857d9a78011911b15","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#using principal component analysis\n#Even though the number of variables is not too high, I would still like to use PCA to see which variables describe the maximum variance in data\nfrom sklearn.decomposition import PCA\npca = PCA()\nx_pca = pca.fit_transform(x)","metadata":{"_cell_guid":"ddba50df-e861-42da-b3f7-6c5f650fc79a","collapsed":true,"_uuid":"05c6b69586b6dd84f909d0f73c3b33db113a357a"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#plot a Scree plot of the Principal Components\nplt.figure(figsize=(16,11))\nplt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\nplt.grid()","metadata":{"_cell_guid":"40c54a61-0d32-4da0-a893-6b47da2bcd41","_uuid":"df0611b5cef00da8b56c4120efd3a187a265bbca","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#from the graph, first 17 components describe the maximum variance(more than 90% of the data). We shall use them for our subsequent analysis.\nnew_pca = PCA(n_components=17)","metadata":{"_cell_guid":"15ec35a4-0580-4bbc-b587-49176a9d951c","collapsed":true,"_uuid":"7a5187338e5cdf1f0935b144a9328699405dbd42"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"x_new = new_pca.fit_transform(x)","metadata":{"_cell_guid":"766f6c61-f454-45ac-9017-a6e8f55e6bb7","collapsed":true,"_uuid":"d2e81f4996afac4be51a237b3b8a68870a4dcf7a"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#using KMeans to plot the clusters. We know that we habe 2 classes of the target variable. So n_clusters=2\nfrom sklearn.cluster import KMeans\nk_means = KMeans(n_clusters=2)","metadata":{"_cell_guid":"b89cb3d2-29a9-44fd-9b38-aba759b5f0ff","collapsed":true,"_uuid":"74a5db049ab143b3808df626e414a77b23196dc7"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"k_means.fit_predict(x_new )","metadata":{"_cell_guid":"30d89dfb-45c3-4956-98b4-d48a1296a6e7","_uuid":"2d42e2ff3a74600bfc865d1b9012d868be88f001"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#plot the clusters.\ncolors = ['r','g']\nfor i in range(len(x_new)):\n    plt.scatter(x_new[i][0], x_new[i][1], c=colors[k_means.labels_[i]], s=10)\nplt.show()","metadata":{"_cell_guid":"95f06d95-7433-4697-9a69-dd7f97376c78","_uuid":"df74248f2678e45bec9fbb4feb4d0dd53f588740","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#2 distinct clusters are created. Data points are far apart \nx_new.shape","metadata":{"_cell_guid":"65394a09-e6ea-4ef8-a868-6e67bd29cd11","_uuid":"238804507d1ecd5ef5352e40fe16e917f1cc325a"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#separate the train and test data\nfrom sklearn.cross_validation import train_test_split","metadata":{"_cell_guid":"85f22f03-5072-40af-ab8b-a1673a863188","_uuid":"9a59d9581389fd2e19a66f005e3958b95e40d732"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size = 0.25, random_state = 6)","metadata":{"_cell_guid":"e92036ac-f982-4cfe-833c-021259d1926c","collapsed":true,"_uuid":"6961b5f77ff9b553de56fe5603a9284d0e0d8ce0"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","metadata":{"_cell_guid":"6fe63e76-6864-4f36-9b68-200b02873ed6","_uuid":"f964208e12f39c442de3242a40836f8e3be5d1b8"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#using Logistic regression to build the first model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\nlr_predict =lr.predict(x_test)","metadata":{"_cell_guid":"2320472d-14b5-4f52-9525-42faac49fe47","collapsed":true,"_uuid":"e4342de9e19bf37a869614401c0b7bdd3d34c45c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"lr_predict_prob = lr.predict_proba(x_test)","metadata":{"_cell_guid":"b30e7f45-932e-44af-8469-8cb9b4108ce8","collapsed":true,"_uuid":"6c0c1df27abab1b24a51f97702ad56b2c9e86644"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(lr_predict)\nprint(lr_predict_prob[:,1])","metadata":{"_cell_guid":"4343ffe9-86f9-4c01-a5b4-85ada68080c4","_uuid":"286201b7504657b2ef1c252654b1ca43bdfbb7fe"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score","metadata":{"_cell_guid":"1fee39d0-0c13-4f90-9eea-e45a20662e44","collapsed":true,"_uuid":"9125b135d2433af828a1aa7a90c7178a2d2867e5"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"lr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_accuracy = accuracy_score(y_test, lr_predict)","metadata":{"_cell_guid":"6636cfef-d3a1-4bda-8997-060f9c843690","collapsed":true,"_uuid":"d9931bb229238717bab09dafe2ba6f63018d47d1"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(lr_conf_matrix)\nprint(lr_accuracy)","metadata":{"_cell_guid":"9e4b4e2a-c7a2-4528-9699-c376bc6b5a27","_uuid":"e59e8a61cb7d3a2e1af44eca9d971549635484cf"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#roc curve\nfrom sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test,lr_predict_prob[:,1] )","metadata":{"_cell_guid":"111826e9-24fd-4f94-9108-c782e86deeb1","collapsed":true,"_uuid":"718b3f67dea139b94f7fa2d3ebe60a37165f2683"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#auc score\nfrom sklearn.metrics import auc\nlr_auc = auc(fpr, tpr)\nprint(lr_auc)","metadata":{"_cell_guid":"097a38b6-65a8-4395-ba45-637603859828","_uuid":"c070213d64b3b1ec50c4b6b249d17b2c314d8a8c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#plotting ROC curve\nplt.figure(figsize=(10,9))\nplt.plot(fpr, tpr, label = 'AUC= %0.2f' % lr_auc )\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.legend()","metadata":{"_cell_guid":"7c06dd6a-74ad-4b54-b8db-12f6900233d3","_uuid":"e99dbe0ac850d865b50a02f9eab6091ff91f4522","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#Using Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(x_train, y_train)\ngnb_predict = gnb.predict(x_test)\ngnb_predict_prob = gnb.predict_proba(x_test)","metadata":{"_cell_guid":"334020ac-394d-4d6a-8cad-8d4abbc68853","collapsed":true,"_uuid":"27d013638a18468622e9fb75999a7174d11d7c74"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(gnb_predict)\nprint(gnb_predict_prob)","metadata":{"_cell_guid":"13ff2a83-78fc-4af9-b230-f902aa1ea317","_uuid":"364f8452caeeb25c750e920b8aa213ad90f73635","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"gnb_conf_matrix = confusion_matrix(y_test, gnb_predict)\ngnb_accuracy_score = accuracy_score(y_test, gnb_predict)","metadata":{"_cell_guid":"33aff1d0-08ae-48a6-b8f0-5fcfbdb49804","collapsed":true,"_uuid":"58d20998e743ec135fce745a5a161575cab3a764"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(gnb_conf_matrix)\nprint(gnb_accuracy_score)","metadata":{"_cell_guid":"db6fa55e-048a-491e-aecb-c0fdfc315035","_uuid":"a4f168d92ed87cfc24706fde0aa32aba404eeb9d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#calculate ROC and AUC\nfpr, tpr, thresholds = roc_curve(y_test, gnb_predict_prob[:,1])\n#print auc\ngnb_auc = auc(fpr, tpr)\nprint(gnb_auc)","metadata":{"_cell_guid":"0b592dd1-629d-4e14-9b7e-7c1aa847879f","_uuid":"b292e814be866c3a1dc48c03c8ce9f3ebc190510"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#plot ROC curve\nplt.figure(figsize=(10,9))\nplt.plot(fpr, tpr, label = 'AUC %0.2f' % gnb_auc)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.legend()","metadata":{"_cell_guid":"64887edf-c472-4d71-b516-9fa8fc518d6b","_uuid":"1c7a450de068a1590d4ba47549707ef3fc7521d7","_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#lets use Decision Trees to classify \n#use the number of trees as 10 first\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(max_depth=10)","metadata":{"_cell_guid":"547cc7fd-b6fa-4d02-9b13-29025f6ebc3d","collapsed":true,"_uuid":"456dfd033d0bc81df919e2099b1ccbffa62b4429"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"dt.fit(x_train,y_train)\ndt_predict = dt.predict(x_test)\ndt_predict_prob = dt.predict_proba(x_test)","metadata":{"collapsed":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.metrics import confusion_matrix, accuracy_score","metadata":{"collapsed":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"dt_conf_matrix = confusion_matrix(y_test, dt_predict)\ndt_accuracy_score = accuracy_score(y_test, dt_predict)","metadata":{"collapsed":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(dt_conf_matrix)\nprint(dt_accuracy_score)","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#calculate auc and plot roc\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, thresholds = roc_curve(y_test, dt_predict_prob[:,1])\ndt_auc = auc(fpr, tpr)\nprint(dt_auc)","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#plot ROC curve\nplt.figure(figsize=(10,9))\nplt.plot(fpr, tpr, label = 'AUC %0.2f' % dt_auc)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend()\nplt.grid()\n","metadata":{"_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#using random forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(max_depth=10) #10 trees\nrf.fit(x_train, y_train)\nrf_predict = rf.predict(x_test)\nrf_predict_prob = rf.predict_proba(x_test)","metadata":{"collapsed":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"rf_conf_matrix = confusion_matrix(y_test,rf_predict)\nrf_accuracy_score = accuracy_score(y_test, rf_predict)","metadata":{"collapsed":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(rf_conf_matrix)\nprint(rf_accuracy_score)\n#random forest has a higher accuracy score than the decision tree\n#Decision tree = 99.3\n#Random forest = 99.9","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"fpr, tpr, thresholds = roc_curve(y_test, rf_predict_prob[:,1])\nrf_auc = auc(fpr, tpr)\nprint(rf_auc)","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#plot the ROC curve\nplt.figure(figsize=(10,9))\nplt.plot(fpr, tpr, label = 'AUC: %0.2f' % rf_auc)\nplt.plot([1,0],[1,0], linestyle = '--')\nplt.legend(loc=0)\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.grid()","metadata":{}},{"cell_type":"markdown","source":"Let's try some Hierarchical unsupervised learning technique to see how many clusters the algorithm predicts.\nI will be using MeanShift algorithm.\nPS - This is just for knowledge's sake - a method that I am utilising to help me understand basic machine learning techniques.","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#how would an unsupervised algo like MeanShift or DBScan work? Let's find out\nfrom sklearn.cluster import MeanShift\nms = MeanShift()\nms.fit(x_new)","metadata":{"_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#print the labels and the cluster centers (I will be calling them centroids)\nms_labels = ms.labels_\nms_centroids = ms.cluster_centers_\nprint(ms_labels)\nprint(ms_centroids)","metadata":{"_kg_hide-output":true}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#np.unique will give us one count of each label. \nn_clusters = len(np.unique(ms_labels))\nprint(n_clusters)","metadata":{}},{"cell_type":"markdown","source":"hmmm so unsupervised learning with MeanShift gives us 3 clusters! Interesting!","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#let's plot the clusters and see how different they are from our original cluster of KMeans'\nplt.figure(figsize=(10,9))\ncolors = ['r','g','y','b']\nfor i in range(len(x_new)):\n    plt.scatter(x_new[i][0], x_new[i][1], c=colors[ms_labels[i]], s=5)\n#print cluster centers\n#Cluster centers are x's in blue\nplt.scatter(ms_centroids[:,0], ms_centroids[:,1], marker='x')\nplt.show()\n#Considerably different!","metadata":{}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"","metadata":{"collapsed":true}}],"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":1}