{"cells":[{"metadata":{"_uuid":"0c2308a77eac156b6c11dc5e68aaa7220d1b9bc6"},"cell_type":"markdown","source":"# Cihan Yatbaz\n###  03 / 11 / 2018\n\n\n\n1.  [Introduction:](#0)\n2. [Exploratory Data Analysis (EDA) :](#1)\n3. [K-NEAREST NEIGHBORS ( KNN ) :](#2)\n    1. [KNN  :](#3)\n    2. [Model Complexity  :](#4)  \n4. [REGRESSION :](#5)\n5. [Support Vector Machine ( SVM) :](#6)\n6. [Naive Bayes :](#7)\n7. [Decission Tree :](#8)\n8. [Random Forest :](#9)\n9. [Confusion Matrix :](#10)\n10. [CONCLUSION :](#11)\n"},{"metadata":{"_uuid":"d017b279126b27ff3a12480fd32a51e251efd367"},"cell_type":"markdown","source":"<a id=\"0\"></a> <br>\n# 1) Introduction\n\nWe will be working on this kernel Biomechanical features of orthopedic patients data. This kernel will do some inspections with KNN. Firstly we will examine dataset. Let's start "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport warnings\n#ignore warnings\nwarnings.filterwarnings(\"ignore\")\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf-8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# read csv(comma separated value) into data\ndata = pd.read_csv(\"../input/column_2C_weka.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cc59799507cd17620997cf7365634ad75e91058"},"cell_type":"code","source":"data.columns  #Columns in our data ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d6d745df63e5f769371b15702717fdd105e69f4"},"cell_type":"markdown","source":"We have Abnormal and Normal values in our data and let's see them now"},{"metadata":{"trusted":true,"_uuid":"07217d5bbdffc77260657bf07a2e357aedd00ff1"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cd4ea070a3cde1c26ec8aaf0ed7a3d94a610d45"},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55a973aea995ba724e3f5744d53a0eb21ee1bd1a"},"cell_type":"code","source":"#Now let's look at the data of our data\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb6b37b0af6580d04a2da88f8ca1db6a23a51e5f"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea864e2de70d88c57bc84c8c1d88f01564da86eb"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# 2) Exploratory Data Analysis (EDA)"},{"metadata":{"_uuid":"511600968fb52f25704e63a9da3cb1331a257d34"},"cell_type":"markdown","source":"### Scatter Matrix Plot"},{"metadata":{"trusted":true,"_uuid":"acf3401fd41072e70191c7587687c971abebe25e"},"cell_type":"code","source":"colors = ['cyan' if i == 'Normal' else 'orange' for i in data.loc[:,'class']]\npd.plotting.scatter_matrix(data.loc[:, data.columns !='class'],\n                                       c = colors,\n                                       figsize =[15,15],\n                                       diagonal ='hist',    # histogram of each features\n                                       alpha = 0.5,\n                                       s = 200,\n                                       marker = '*',\n                                       edgecolor=\"black\"\n                          )\nplt.savefig('graph4.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cf2bde27c2a17fd6074774c5d2d08676bf8e298"},"cell_type":"markdown","source":"### Count plot\nNow let's see how many of our Normal and Abnormal values exist"},{"metadata":{"trusted":true,"_uuid":"0b2be714149e289d3a6dd220ee23c89834b7dda8"},"cell_type":"code","source":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eea034b0b5669f2f9891144624cb84ffd0a591ae"},"cell_type":"markdown","source":"### Which value belongs to the selected point?"},{"metadata":{"trusted":true,"_uuid":"d4615bd265b73a1a7218fb8478b10be5c9465352"},"cell_type":"code","source":"# We list them separately according to 'Abnormal' and 'Normal' properties\nN = data[data['class']==\"Normal\"]\nA = data[data['class']==\"Abnormal\"]\nprint(\"NORMAL\")\nN.info()\nprint()\nprint(\"ABNORMAL\")\nA.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fd030d66546841ea8c384a0d89ae8fdde60d09b"},"cell_type":"code","source":"# Scatter Plot\nplt.figure(figsize=[12,8])\nplt.scatter(N.pelvic_radius, N.pelvic_incidence, color=\"cyan\", label=\"Normal\")\nplt.scatter(A.pelvic_radius, A.pelvic_incidence, color=\"orange\", label=\"Abnormal\")\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"pelvic_incidence\")\nplt.legend() # To show labels\nplt.savefig('graph3.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bcab3899eb511a3093d0dbcff131a7fae8c2c5aa"},"cell_type":"markdown","source":"### In the figure above, how can we predict whether a point we want to find is Normal or Abnormal? Let's learn together.\n* First we set a point.\n* Then we choose the value 3 closest to this point.\n* If the Abnormal number is higher in these values, it is Abnormal in your new value. If the number of Normals is high, our new value becomes normal.\n"},{"metadata":{"_uuid":"1412a8f76103531b762300231e602604a26bdf6d"},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n# 3) K-NEAREST NEIGHBORS ( KNN )"},{"metadata":{"_uuid":"47aa16316094c27d43bb88822debf999f220e207"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n## A) KNN"},{"metadata":{"trusted":true,"_uuid":"52d90f14e25940fbc88b68c3ad876005ac3225b3"},"cell_type":"code","source":"data['class'] = [1 if each=='Normal' else 0 for each in data['class']]\ndata_class = data['class']   # This is what we do for convenience\ny = data_class.values\nx_d = data.drop([\"class\"], axis=1)   # We will use other features except Class","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6927a4937a774dcc8a78ab5bbbbdbe20ddd32949"},"cell_type":"markdown","source":"* Now we are doing normalization. Because if some of our columns have very high values, they will suppress other columns and do not show much.\n* Formulel : (x- min(x)) / (max(x) - min(x))"},{"metadata":{"trusted":true,"_uuid":"27ead81cf0adf94f948effe38d8f8367c96cce51"},"cell_type":"code","source":"# Normalization\nx = (x_d - np.min(x_d)) / (np.max(x_d) - np.min(x_d))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f889ef92f54486f8b3ae0cdac0f00e359405a99"},"cell_type":"markdown","source":"* Now we reserve 70% of the values as 'train' and 30% as 'test'."},{"metadata":{"trusted":true,"_uuid":"fe0b27aa2d483ef1d6a796ae93a9ab30993b9952"},"cell_type":"code","source":"#train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cc8218b8ab3ef3f49d7d2b8b81172c65eaae3e1"},"cell_type":"markdown","source":"Let's create our KNN model\n* n_neighbours = k  ----->   We determine the k value and try to increase the accuracy of the result"},{"metadata":{"trusted":true,"_uuid":"ed28bd3a8ede5626b3b7d8d84856189ad6a03396"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=22)\nknn.fit(x_train, y_train)\nprediction = knn.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"394f3134279a60c863ea852618cf011cc8762898"},"cell_type":"code","source":"print(\" {} nn score : {}\".format(22, knn.score(x_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e03e0648e0968fb2133f5b7dc5ee688bb4d01505"},"cell_type":"markdown","source":"### Let's try to find the best k value with loop now"},{"metadata":{"trusted":true,"_uuid":"b4cfa5361bce20f76e9e47bad654373cd880e7d6"},"cell_type":"code","source":"score_list = []\nfor each in range(1,30):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n#Plot\nplt.figure(figsize=[13,8])\nplt.plot(range(1,30),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.savefig('graph2.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f582563e6afcc0a64ff32e4a408f1b803b07e190"},"cell_type":"markdown","source":"### If k value has a value of 22 or 26, our test results will give the best result."},{"metadata":{"_uuid":"17cd9eaecc2fe6ffee7d58e8ebb14f0d1f0fb602"},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n## B) Model Complexity\n* We can use Model Complexity to find the best value.  This way we can easily find the best result by comparing the Value and Accuracy."},{"metadata":{"trusted":true,"_uuid":"93f1b7b7f3faa3781311d0a7ede3cf281c153082"},"cell_type":"code","source":"# Model complexity\nrand = np.arange(1,30)\ntrain_accuracy = []\ntest_accuracy = []\n# Loop over different values of k\nfor i, k in enumerate(rand):\n    # k from 1 to 30(exclude)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # fit with knn\n    knn.fit(x_train, y_train)\n    train_accuracy.append(knn.score(x_train, y_train))           # train accuracy\n    test_accuracy.append(knn.score(x_test, y_test))              # test accuracy\n\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(rand, test_accuracy, label='Testing Accuracy' , color='red')\nplt.plot(rand, train_accuracy, label='Training Accuracy', color='black')\nplt.legend()\nplt.title(' K Value vs Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('K Values')\nplt.xticks(rand)\nplt.savefig('graph.png')\nplt.show()\n\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy), 1+test_accuracy.index(np.max(test_accuracy))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b59440a12762bfc2ccb33522b5afc4942e1402a"},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n# 4) REGRESSION \n* Let's create data1 that includes pelvic_incidence that is feature and sacral_slope that is target variable"},{"metadata":{"trusted":true,"_uuid":"110166f5444f43959ef4acce99fd9fbe15bb9b02"},"cell_type":"code","source":"data1 = A  # We have previously defined A to Class Abnormal.\nx = np.array(data1.loc[:, 'pelvic_incidence']).reshape(-1,1)\ny = np.array(data1.loc[:, 'sacral_slope']).reshape(-1,1)\n\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x, y=y)\nplt.xlabel(\"pelvic incidence\")\nplt.ylabel(\"sacral slope\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79325e51f0e4b329be47494ad6b3b7be3a5c828a"},"cell_type":"code","source":"# LinearRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score    \n#Regression\nreg = LinearRegression()\n# Fit\nreg.fit(x,y)\n\n# Prediction: \npred_space = np.linspace(min(x), max(x)).reshape(-1,1)\ny_head = reg.predict(pred_space)\n\n# r2 score with LinearRegression\nprint('R^2 score: ',reg.score(x, y))\n# r2 score with metrics\nprint('R^2 score metrics: ', r2_score(y, reg.predict(x)))\n\n# Plot regression line and scatter\nplt.subplots(figsize=(12,10))\nplt.plot(pred_space, y_head, color='red', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.savefig('graph6.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd26a2bf7945a07e2235bcba5712b68b93fc4dee"},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n# 5) Support Vector Machine ( SVM)\n*  Specifies the line that will pass between 2 values in the table and tries to keep margin highest"},{"metadata":{"trusted":true,"_uuid":"cbe14e7f6c21bcbe9ec10f89249512433a4a6a4b"},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(x_train, y_train)\n\n#test\nprint(\"Accuracy of SVM Score : \", svm.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf0013772bbc2507ed69358fe290b3248ca0abad"},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n# 6) Naive Bayes\n* Determines the probability that the point in the selected circle can be A or B."},{"metadata":{"trusted":true,"_uuid":"345633840fcc6ac4a060b407dd708ff7a2082070"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train, y_train)\n#test\nprint(\"Accuracy of Naive Score : \", nb.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56a4ee4888e31e84d6cea25f05562f2793d12745"},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\n# 7) Decission Tree\n* It allows us to differentiate between different classes with Splits"},{"metadata":{"trusted":true,"_uuid":"c7d8bc072e34cfe86e7256de0656038a22f8cb78"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\n#test\nprint(\"Accuracy of Decision Tree Score : \", dtc.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2f3b20db56d778092df10b32d4c0d6f9a9579be"},"cell_type":"markdown","source":"<a id=\"9\"></a> <br>\n# 8) Random Forest\n* We have multiple decision trees in a random forest and Random forest giving us the most correct results by doing the transaction with decision tree while we process.\n* As a result, it improves the accuracy and reliability of the model"},{"metadata":{"trusted":true,"_uuid":"45e4a0cdbaea2bb88bf59b7cb38c639729df2fe5"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators = 100, random_state=1)\n#n_estimators =100 -> Determines how many trees we have\nrfc =rfc.fit(x_train, y_train)\n#test\nprint(\"Random Forest Score\", rfc.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68b24cca95d8d8247cef184118aae179099de65c"},"cell_type":"markdown","source":"<a id=\"10\"></a> <br>\n# 9) Confusion Matrix\n* Confusion Matrix : With the result, it shows how many mistakes we have from A and B.\n* Confusion Matrix enables us to visualize these results"},{"metadata":{"trusted":true,"_uuid":"dd86cfc45c2c2fa02d82e538600c0940a21643cd"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred = rfc.predict(x_test)\ny_true = y_test\n\ncm = confusion_matrix(y_true, y_pred)\n\n# confusion matrix visualization\n\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cm, annot = True, linewidths = 0.5, linecolor = 'green', fmt=\".0f\", ax=ax)\nplt.savefig('graph7.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5689a907c141166eea9eaa38f08a5993b89b2755"},"cell_type":"markdown","source":"#### 0 = Abnormal values       &      1 = Normal values\n* In our test, there are 60 true, 6 false results for Abnormal.\n* In our test, there are 20 true, 7 false results for Normal."},{"metadata":{"_uuid":"77d788c29eeb0c19ed36351f381e6091e1bacc30"},"cell_type":"markdown","source":"<a id=\"11\"></a> <br>\n> # CONCLUSION                                                                                                                                                      \nThank you for your votes and comments                                                                                                                                              \n<br>**If you have any suggest, May you write for me, I will be happy to hear it.**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}