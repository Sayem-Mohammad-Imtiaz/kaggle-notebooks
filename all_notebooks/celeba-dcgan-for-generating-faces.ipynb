{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nPIC_DIR = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/'\nlen(os.listdir(PIC_DIR))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom tqdm import tqdm\n\nIMAGES_COUNT = 10000\n\nORIG_WIDTH = 178\nORIG_HEIGHT = 208\ndiff = (ORIG_HEIGHT - ORIG_WIDTH) // 2\n\nWIDTH = 128\nHEIGHT = 128\n\ncrop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\n\nimages = []\nfor pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n    pic = Image.open(PIC_DIR + pic_file).crop(crop_rect)\n    pic.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n    images.append(np.uint8(pic))\n\nimages = np.array(images) / 255\nimages.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.figure(1, figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Input\nfrom keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop\n\nLATENT_DIM = 32\nCHANNELS = 3\n\ndef create_generator():\n    gen_input = Input(shape=(LATENT_DIM, ))\n    \n    x = Dense(128 * 16 * 16)(gen_input)\n    x = LeakyReLU()(x)\n    x = Reshape((16, 16, 128))(x)\n    \n    x = Conv2D(256, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(CHANNELS, 7, activation='tanh', padding='same')(x)\n    \n    generator = Model(gen_input, x)\n    return generator\n\ndef create_discriminator():\n    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n    \n    x = Conv2D(256, 3)(disc_input)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n    \n    x = Dense(1, activation='sigmoid')(x)\n    discriminator = Model(disc_input, x)\n    \n    optimizer = RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\n    \n    discriminator.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy'\n    )\n    \n    return discriminator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = create_generator()\ndiscriminator = create_discriminator()\ndiscriminator.trainable = False\n\ngan_input = Input(shape=(LATENT_DIM, ))\ngan_output = discriminator(generator(gan_input))\ngan = Model(gan_input, gan_output)\n\noptimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=optimizer, loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\niters = 20000\nbatch_size = 16\n\nRES_DIR = 'res2'\nFILE_PATH = '%s/generated_%d.png'\nif not os.path.isdir(RES_DIR):\n    os.mkdir(RES_DIR)\n\nCONTROL_SIZE_SQRT = 6\ncontrol_vectors = np.random.normal(size=(CONTROL_SIZE_SQRT**2, LATENT_DIM)) / 2\n\nstart = 0\nd_losses = []\na_losses = []\nimages_saved = 0\nfor step in range(iters):\n    start_time = time.time()\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    generated = generator.predict(latent_vectors)\n    \n    real = images[start:start + batch_size]\n    combined_images = np.concatenate([generated, real])\n    \n    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n    labels += .05 * np.random.random(labels.shape)\n    \n    d_loss = discriminator.train_on_batch(combined_images, labels)\n    d_losses.append(d_loss)\n    \n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    misleading_targets = np.zeros((batch_size, 1))\n    \n    a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n    a_losses.append(a_loss)\n    \n    start += batch_size\n    if start > images.shape[0] - batch_size:\n        start = 0\n    \n    if step % 50 == 49:\n        gan.save_weights('gan.h5')\n        \n        print('%d/%d: d_loss: %.4f,  a_loss: %.4f.  (%.1f sec)' % (step + 1, iters, d_loss, a_loss, time.time() - start_time))\n        \n        control_image = np.zeros((WIDTH * CONTROL_SIZE_SQRT, HEIGHT * CONTROL_SIZE_SQRT, CHANNELS))\n        control_generated = generator.predict(control_vectors)\n        for i in range(CONTROL_SIZE_SQRT ** 2):\n            x_off = i % CONTROL_SIZE_SQRT\n            y_off = i // CONTROL_SIZE_SQRT\n            control_image[x_off * WIDTH:(x_off + 1) * WIDTH, y_off * HEIGHT:(y_off + 1) * HEIGHT, :] = control_generated[i, :, :, :]\n        im = Image.fromarray(np.uint8(control_image * 255))\n        im.save(FILE_PATH % (RES_DIR, images_saved))\n        images_saved += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(12, 8))\nplt.subplot(121)\nplt.plot(d_losses)\nplt.xlabel('epochs')\nplt.ylabel('discriminant losses')\nplt.subplot(122)\nplt.plot(a_losses)\nplt.xlabel('epochs')\nplt.ylabel('adversary losses')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import imageio\nimport shutil\n\nimages_to_gif = []\nfor filename in os.listdir(RES_DIR):\n    images_to_gif.append(imageio.imread(RES_DIR + '/' + filename))\nimageio.mimsave('trainnig_visual.gif', images_to_gif)\nshutil.rmtree(RES_DIR)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}