{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Heart Attack EDA and Prediction\n","metadata":{"_kg_hide-input":false}},{"cell_type":"markdown","source":"This notebook aims at exploring the dataset and making predictions on whether a person will have heart attack or not.","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n\n\n* <a href='#di'> Dataset Info </a>\n* <a href='#pw'> Preparing Workspace </a>\n\t- <a href='#il'> Importing Libraries </a>\n\t- <a href='#sp'> Setting Params </a>\n\t- <a href='#ld'> Loading Data </a>\n* <a href='#pa'> Preliminary Analysis </a>\n\t- <a href='#sotd'> Shape of the dataset </a>\n\t- <a href='#pwotd'> Preview of the dataset </a>\n\t- <a href='#mv'> Missing Values </a>\n\t- <a href='#cac'> Categorical and Continous </a>\n\t- <a href='#gs'> General Stats </a>\n* <a href='#eda'> Exploratory Data Analysis </a>\n\t- <a href='#ua'> Univariate Analysis </a>\n\t\t+ <a href='#vpfcv'> Voilin plot for continous variables </a>\n\t\t+ <a href='#cpfcf'> Count plot for categorical features </a>\n\t- <a href='#ba'> Bivariate Analysis </a>\n\t\t+ <a href='#socvwto'> Seperation of categorical variables w.r.t to output </a>\n\t\t+ <a href='#ccvfcv'> Corrected Cramer's V for categorical variables </a>\n\t\t+ <a href='#pfcvwo'> Plots for continous variables w.r.t output <a>\n\t\t+ <a href='#kwht'> Kruskal-Wallis H-test </a>\n\t\t+ <a href='#cfmc'> Check for Multi-Collinearity: Correlation of variables among themselves </a>\n\t\t+ <a href='#pp'> Pair plot - One plot to rule them all <a>\n\t- <a href='#edac'> Conclusion </a>\n* <a href='#md'> Model Development </a>\n\t- <a href='#ll'> Loading Libraries </a>\n\t- <a href='#fe'> Feature Engineering </a>\n\t- <a href='#tmagr'> Training Models and Getting Results </a>\n\t- <a href='#secm'> Stacking </a>\n\t- <a href='#pos'> Plot of Scores </a>\n* <a href='#fcc'> Conclusion </a>\n* <a href='#ty'> Thank you! </a>","metadata":{}},{"cell_type":"markdown","source":"# Dataset Info <span id='di'/>","metadata":{}},{"cell_type":"markdown","source":"`age` - Age of the patient\n\n`sex` - Sex of the patient\n\n`cp` - Chest pain type ~ 0 = Typical Angina, 1 = Atypical Angina, 2 = Non-anginal Pain, 3 = Asymptomatic\n\n`trtbps` - Resting blood pressure (in mm Hg)\n\n`chol` - Cholestoral in mg/dl fetched via BMI sensor\n\n`fbs` - (fasting blood sugar > 120 mg/dl) ~ 1 = True, 0 = False\n\n`restecg` - Resting electrocardiographic results ~ 0 = Normal, 1 = ST-T wave normality, 2 = Left ventricular hypertrophy\n\n`thalachh` - Maximum heart rate achieved\n\n`oldpeak` - Previous peak\n\n`slp` - Slope\n\n`caa` - Number of major vessels\n\n`thall` - Thalium Stress Test result ~ (0,3)\n\n`exng` - Exercise induced angina ~ 1 = Yes, 0 = No\n\n`output` - Target variable","metadata":{}},{"cell_type":"markdown","source":"# Preparing Workspace <span id='pw'/>","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries <span id='il'/>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport scipy.stats as ss\n\nprint('Libraries are imported')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:00.934339Z","iopub.execute_input":"2021-06-12T07:14:00.934765Z","iopub.status.idle":"2021-06-12T07:14:00.940967Z","shell.execute_reply.started":"2021-06-12T07:14:00.934715Z","shell.execute_reply":"2021-06-12T07:14:00.940004Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting Params <span id='sp'/>","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\nsns.set_palette('deep')\nsns.set_color_codes()\nsns.set_style('dark')\n\nprint('Parameters are set')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:00.948067Z","iopub.execute_input":"2021-06-12T07:14:00.948431Z","iopub.status.idle":"2021-06-12T07:14:00.959862Z","shell.execute_reply.started":"2021-06-12T07:14:00.948397Z","shell.execute_reply":"2021-06-12T07:14:00.958783Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data <span id='ld'/>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')\nprint('Data is Loaded')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:00.961861Z","iopub.execute_input":"2021-06-12T07:14:00.96245Z","iopub.status.idle":"2021-06-12T07:14:00.986706Z","shell.execute_reply.started":"2021-06-12T07:14:00.962406Z","shell.execute_reply":"2021-06-12T07:14:00.985567Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preliminary Analysis <span id='pa'/>","metadata":{}},{"cell_type":"markdown","source":"## Shape of the dataset <span id='sotd'/>","metadata":{}},{"cell_type":"code","source":"print(f'Shape of the Dataset is: {df.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T07:14:00.988363Z","iopub.execute_input":"2021-06-12T07:14:00.988908Z","iopub.status.idle":"2021-06-12T07:14:00.994016Z","shell.execute_reply.started":"2021-06-12T07:14:00.988873Z","shell.execute_reply":"2021-06-12T07:14:00.993198Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preview of the dataset <span id='pwotd'/>","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T07:14:00.995417Z","iopub.execute_input":"2021-06-12T07:14:00.995908Z","iopub.status.idle":"2021-06-12T07:14:01.038455Z","shell.execute_reply.started":"2021-06-12T07:14:00.995873Z","shell.execute_reply":"2021-06-12T07:14:01.03766Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing Values <span id='mv'/>","metadata":{}},{"cell_type":"code","source":"df.isna().apply(pd.value_counts, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T07:14:01.04023Z","iopub.execute_input":"2021-06-12T07:14:01.040683Z","iopub.status.idle":"2021-06-12T07:14:01.071478Z","shell.execute_reply.started":"2021-06-12T07:14:01.040638Z","shell.execute_reply":"2021-06-12T07:14:01.070288Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical and Continous <span id='cac'/>","metadata":{}},{"cell_type":"code","source":"categorical = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'thall', 'caa', 'slp']\ncontinous = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nprint('Categorical Variables are:', ', '.join(categorical))\nprint('Continous Variables are:', ', '.join(continous))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:01.073579Z","iopub.execute_input":"2021-06-12T07:14:01.073906Z","iopub.status.idle":"2021-06-12T07:14:01.081195Z","shell.execute_reply.started":"2021-06-12T07:14:01.073876Z","shell.execute_reply":"2021-06-12T07:14:01.079896Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## General Stats <span id='gs'/>","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T07:14:01.083175Z","iopub.execute_input":"2021-06-12T07:14:01.083764Z","iopub.status.idle":"2021-06-12T07:14:01.144794Z","shell.execute_reply.started":"2021-06-12T07:14:01.083669Z","shell.execute_reply":"2021-06-12T07:14:01.143866Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis <span id='eda'/>","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Univariate Analysis <span id='ua'/>","metadata":{}},{"cell_type":"markdown","source":"### Voilin plot for continous variables <span id='vpfcv'/>","metadata":{}},{"cell_type":"code","source":"chart_count = len(continous) + 1\n\nfig = plt.figure(figsize=(20, 17))\naxes = [fig.add_subplot(3, 3, i) for i in range(1, chart_count + 1)]\nfig.tight_layout(pad=7)\nfig.patch.set_facecolor('#eaeaf2')\n\naxes[0].spines[\"bottom\"].set_visible(False)\naxes[0].spines[\"left\"].set_visible(False)\naxes[0].spines[\"top\"].set_visible(False)\naxes[0].spines[\"right\"].set_visible(False)\naxes[0].tick_params(left=False, bottom=False)\naxes[0].set_xticklabels([])\naxes[0].set_yticklabels([])\naxes[0].text(0.5, 0.5,\n             'Violin plot for the\\n continous features\\n_________________',\n             horizontalalignment='center', verticalalignment='center',\n             fontsize=20, fontweight='bold', fontfamily='serif')\n\nfor i in range(1, chart_count):\n    var = continous[i - 1]\n    ax = axes[i]\n    ax.grid(axis='y', linestyle=':')\n    ax.text(0.5, 1.05, var.title(),\n            horizontalalignment='center', verticalalignment='center',\n            fontsize=14, fontweight='bold', transform=ax.transAxes)\n    color = sns.color_palette('deep')[i - 1]\n    sns.violinplot(data=df, y=var, ax=ax, color=color)\n    ax.set_xlabel('')\n    ax.set_ylabel('')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:01.148713Z","iopub.execute_input":"2021-06-12T07:14:01.149263Z","iopub.status.idle":"2021-06-12T07:14:02.229481Z","shell.execute_reply.started":"2021-06-12T07:14:01.149223Z","shell.execute_reply":"2021-06-12T07:14:02.228005Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion\n\n* `chol`, `trtbps`, and `oldpeak` have *decent amount of outliers* that could affect certain models sensitive to them.\n\n* `oldpeak` and `chol` (moderately) are *not uniformly distributed*. This could affect models or analysis with uniform distribution as requirement. ","metadata":{}},{"cell_type":"markdown","source":"### Count plot for categorical features <span id='cpfcf'/>","metadata":{}},{"cell_type":"code","source":"chart_count = len(categorical) + 1\n\nfig = plt.figure(figsize=(20, 17))\naxes = [fig.add_subplot(3, 3, i) for i in range(1, chart_count + 1)]\nfig.tight_layout(pad=7)\nfig.patch.set_facecolor('#eaeaf2')\n\naxes[0].spines[\"bottom\"].set_visible(False)\naxes[0].spines[\"left\"].set_visible(False)\naxes[0].spines[\"top\"].set_visible(False)\naxes[0].spines[\"right\"].set_visible(False)\naxes[0].tick_params(left=False, bottom=False)\naxes[0].set_xticklabels([])\naxes[0].set_yticklabels([])\naxes[0].text(0.5, 0.5,\n             'Count plot for the\\n categorical features\\n_________________',\n             horizontalalignment='center', verticalalignment='center',\n             fontsize=20, fontweight='bold', fontfamily='serif')\n\nfor i in range(1, chart_count):\n    var = categorical[i - 1]\n    ax = axes[i]\n    ax.text(0.5, 1.05, var.title(),\n            horizontalalignment='center', verticalalignment='center',\n            fontsize=14, fontweight='bold', transform=ax.transAxes)\n    sns.countplot(data=df, x=var, ax=ax)\n    ax.set_xlabel('')\n    ax.set_ylabel('')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:02.231367Z","iopub.execute_input":"2021-06-12T07:14:02.23168Z","iopub.status.idle":"2021-06-12T07:14:03.688979Z","shell.execute_reply.started":"2021-06-12T07:14:02.23165Z","shell.execute_reply":"2021-06-12T07:14:03.687485Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion\n\n* `Restecg`, `Thall`, `Caa`, `Slp` are *likely to impact few models sensitive to data distribution* because value counts for some values is extremely low. \n\n* `Fbs` and `Cp` could *possibly affect models sensitive to data distribution* because their value counts is also not ideal. ","metadata":{}},{"cell_type":"markdown","source":"## Bivariate Analysis <span id='ba'/>","metadata":{}},{"cell_type":"markdown","source":"### Seperation of categorical variables w.r.t to output <span id='socvwto'/>","metadata":{}},{"cell_type":"code","source":"chart_count = len(categorical) + 1\n\nfig = plt.figure(figsize=(20, 17))\naxes = [fig.add_subplot(3, 3, i) for i in range(1, chart_count + 1)]\nfig.tight_layout(pad=7)\nfig.patch.set_facecolor('#eaeaf2')\n\naxes[0].spines[\"bottom\"].set_visible(False)\naxes[0].spines[\"left\"].set_visible(False)\naxes[0].spines[\"top\"].set_visible(False)\naxes[0].spines[\"right\"].set_visible(False)\naxes[0].tick_params(left=False, bottom=False)\naxes[0].set_xticklabels([])\naxes[0].set_yticklabels([])\naxes[0].text(0.5, 0.5,\n             'Seperation of categorical \\nvariables w.r.t to output\\n_________________',\n             horizontalalignment='center', verticalalignment='center',\n             fontsize=20, fontweight='bold', fontfamily='serif')\n\nfor i in range(1, chart_count):\n    var = categorical[i - 1]\n    ax = axes[i]\n    ax.text(0.5, 1.05, var.title(),\n            horizontalalignment='center', verticalalignment='center',\n            fontsize=14, fontweight='bold', transform=ax.transAxes)\n    colorIndex = (2*(i - 1)) % 10\n    color1 = sns.color_palette('deep')[colorIndex]\n    color2 = sns.color_palette('deep')[colorIndex + 1]\n    sns.countplot(data=df, x=var, ax=ax, hue='output',\n                  palette=[color1, color2])\n    ax.set_xlabel('')\n    ax.set_ylabel('')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:03.69063Z","iopub.execute_input":"2021-06-12T07:14:03.69102Z","iopub.status.idle":"2021-06-12T07:14:05.565125Z","shell.execute_reply.started":"2021-06-12T07:14:03.690987Z","shell.execute_reply":"2021-06-12T07:14:05.563005Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion\n\n* `Fbs` *doesn't seem to be related* at all to output\n\n* `Sex`, `Restecg` seem to be *somewhat correlated* to output\n\n* Others have a *fair correlation* w.r.t to output","metadata":{}},{"cell_type":"markdown","source":"### Corrected Cramer's V for categorical variables <span id='ccvfcv'/>","metadata":{}},{"cell_type":"code","source":"def cramers_corrected_stat(x, y):\n    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n        uses correction from Bergsma and Wicher, \n        Journal of the Korean Statistical Society 42 (2013): 323-328\n    \"\"\"\n    result = -1\n\n    conf_matrix = pd.crosstab(x, y)\n\n    if conf_matrix.shape[0] == 2:\n        correct = False\n    else:\n        correct = True\n\n    chi2, p = ss.chi2_contingency(conf_matrix, correction=correct)[0:2]\n\n    n = sum(conf_matrix.sum())\n    phi2 = chi2/n\n    r, k = conf_matrix.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n    rcorr = r - ((r-1)**2)/(n-1)\n    kcorr = k - ((k-1)**2)/(n-1)\n    result = np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n    return round(result, 6), round(p, 6)\n\n\nfor var in categorical:\n    x = df[var]\n    y = df['output']\n    cramersV, p = cramers_corrected_stat(x, y)\n    print(f'For variable {var}, Cramer\\'s V: {cramersV} and p value: {p}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:05.567547Z","iopub.execute_input":"2021-06-12T07:14:05.568032Z","iopub.status.idle":"2021-06-12T07:14:05.713038Z","shell.execute_reply.started":"2021-06-12T07:14:05.567986Z","shell.execute_reply":"2021-06-12T07:14:05.711827Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion\n\nThe stats seem to agree with the conclusions we drew previously from graph along with a measure of the correlation.\n\n* `Fbs` is *not related* at all\n\n* `Sex`, `Restecg` have *very weak correlation*\n\n* `Sp`, `Thall` seem to have a *moderately strong correlation*\n\n* `Exng`, `Caa`, `Slp` have *decent correlation*","metadata":{}},{"cell_type":"markdown","source":"### Plots for continous variables w.r.t output <span id='pfcvwo'>","metadata":{}},{"cell_type":"code","source":"chart_count = len(continous) + 1\n\nfig = plt.figure(figsize=(20, 17))\naxes = [fig.add_subplot(3, 3, i) for i in range(1, chart_count + 1)]\nfig.tight_layout(pad=7)\nfig.patch.set_facecolor('#eaeaf2')\n\naxes[0].spines[\"bottom\"].set_visible(False)\naxes[0].spines[\"left\"].set_visible(False)\naxes[0].spines[\"top\"].set_visible(False)\naxes[0].spines[\"right\"].set_visible(False)\naxes[0].tick_params(left=False, bottom=False)\naxes[0].set_xticklabels([])\naxes[0].set_yticklabels([])\naxes[0].text(0.5, 0.5,\n             'Violin plot for the\\n continous features\\ndiffering by output\\n_________________',\n             horizontalalignment='center', verticalalignment='center',\n             fontsize=20, fontweight='bold', fontfamily='serif')\n\nfor i in range(1, chart_count):\n    var = continous[i - 1]\n    ax = axes[i]\n    ax.grid(axis='y', linestyle=':')\n    ax.text(0.5, 1.05, var.title(),\n            horizontalalignment='center', verticalalignment='center',\n            fontsize=14, fontweight='bold', transform=ax.transAxes)\n    colorIndex = (2*(i - 1)) % 10\n    color1 = sns.color_palette('deep')[colorIndex]\n    color2 = sns.color_palette('deep')[colorIndex + 1]\n    sns.violinplot(data=df, y=var, x='output', ax=ax, palette=[color1, color2])\n    ax.set_xlabel('')\n    ax.set_ylabel('')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:05.717344Z","iopub.execute_input":"2021-06-12T07:14:05.717693Z","iopub.status.idle":"2021-06-12T07:14:06.934034Z","shell.execute_reply.started":"2021-06-12T07:14:05.717662Z","shell.execute_reply":"2021-06-12T07:14:06.933218Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chart_count = len(continous) + 1\n\nfig = plt.figure(figsize=(20, 15))\naxes = [fig.add_subplot(3, 3, i) for i in range(1, chart_count + 1)]\nfig.tight_layout(pad=7)\nfig.patch.set_facecolor('#eaeaf2')\n\naxes[0].spines[\"bottom\"].set_visible(False)\naxes[0].spines[\"left\"].set_visible(False)\naxes[0].spines[\"top\"].set_visible(False)\naxes[0].spines[\"right\"].set_visible(False)\naxes[0].tick_params(left=False, bottom=False)\naxes[0].set_xticklabels([])\naxes[0].set_yticklabels([])\naxes[0].text(0.5, 0.5,\n             'Distribution of continous\\n variables by output\\n_________________',\n             horizontalalignment='center', verticalalignment='center',\n             fontsize=20, fontweight='bold', fontfamily='serif')\n\nfor i in range(1, chart_count):\n    var = continous[i - 1]\n    ax = axes[i]\n    ax.grid(axis='y', linestyle=':')\n    ax.text(0.5, 1.05, var.title(),\n            horizontalalignment='center', verticalalignment='center',\n            fontsize=14, fontweight='bold', transform=ax.transAxes)\n    colorIndex = (2*(i - 1)) % 10\n    color1 = sns.color_palette('deep')[colorIndex]\n    color2 = sns.color_palette('deep')[colorIndex + 1]\n    sns.kdeplot(data=df, x=var, hue='output', ax=ax, fill=True,\n                palette=[color1, color2])\n    ax.set_xlabel('')\n    ax.set_ylabel('')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:06.9353Z","iopub.execute_input":"2021-06-12T07:14:06.935685Z","iopub.status.idle":"2021-06-12T07:14:08.441325Z","shell.execute_reply.started":"2021-06-12T07:14:06.935653Z","shell.execute_reply":"2021-06-12T07:14:08.440381Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion\n\n* `Trtbps` and `Chol` are not likely to have correlation\n* `Age` and `Thalachh` might have weak correlation\n* `Oldpeak` is likely to be correlated. ","metadata":{}},{"cell_type":"markdown","source":"### Kruskal-Wallis H-test <span id='kwht'/>\n\nSince the distribution for some variables is non-Gaussian we would be using non-parametric test--specifically Kruskal-Wallis H Test ","metadata":{}},{"cell_type":"code","source":"for var in continous:\n    gp = df[[var, 'output']].groupby(['output'])\n    gp_array = [group[var].to_numpy() for name, group in gp]\n    kstat, p = ss.kruskal(*gp_array)\n    kstat, p = round(kstat, 6), round(p, 6)\n    print(f'For variable {var}, Kruskal-Wallis H-test: {kstat} and p value: {p}')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T07:14:08.442721Z","iopub.execute_input":"2021-06-12T07:14:08.443159Z","iopub.status.idle":"2021-06-12T07:14:08.4676Z","shell.execute_reply.started":"2021-06-12T07:14:08.443126Z","shell.execute_reply":"2021-06-12T07:14:08.466262Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion\n\nSuprisingly, all variables have correlation. Although `chol` and `trtpbs` cut very close to our alpha (which is 0.05). ","metadata":{}},{"cell_type":"markdown","source":"### Check for Multi-Collinearity: Correlation of variables among themselves <span id='cfmc'/>","metadata":{}},{"cell_type":"code","source":"sns.set_style('white')\nfig = plt.figure(figsize=(12, 8))\nax = fig.add_subplot(111)\n\ncorr_matrix = df[continous].corr()\n\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\nsns.heatmap(corr_matrix, cmap='Blues', annot=True, mask=mask, ax=ax)\nfig.text(0.5, 1.05,\n         'Correlation of Continous variables (Pearson)',\n         horizontalalignment='center', verticalalignment='center',\n         fontsize=14, fontweight='bold', transform=ax.transAxes)\nsns.set_style('dark')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T07:14:08.46919Z","iopub.execute_input":"2021-06-12T07:14:08.469494Z","iopub.status.idle":"2021-06-12T07:14:09.031439Z","shell.execute_reply.started":"2021-06-12T07:14:08.469464Z","shell.execute_reply":"2021-06-12T07:14:09.030159Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('white')\nfig = plt.figure(figsize=(12, 8))\nax = fig.add_subplot(111)\n\ncorr_matrix = df[continous].corr(method=lambda x, y:\n                                 cramers_corrected_stat(x, y)[0])\n\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\nsns.heatmap(corr_matrix, cmap='Blues', annot=True, mask=mask, ax=ax)\nfig.text(0.5, 1.05,\n         'Correlation of Categorical variables (Corrected Cramers\\' V)',\n         horizontalalignment='center', verticalalignment='center',\n         fontsize=14, fontweight='bold', transform=ax.transAxes)\nsns.set_style('dark')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T07:14:09.033311Z","iopub.execute_input":"2021-06-12T07:14:09.033754Z","iopub.status.idle":"2021-06-12T07:14:09.812618Z","shell.execute_reply.started":"2021-06-12T07:14:09.03369Z","shell.execute_reply":"2021-06-12T07:14:09.811565Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion\n\nVariables do *not have strong correlation* and are *weakly correlated*","metadata":{}},{"cell_type":"markdown","source":"### Pair plot - One plot to rule them all <span id='pp'/>","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df, hue='output');","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-12T07:14:09.81467Z","iopub.execute_input":"2021-06-12T07:14:09.815184Z","iopub.status.idle":"2021-06-12T07:14:56.788659Z","shell.execute_reply.started":"2021-06-12T07:14:09.815147Z","shell.execute_reply":"2021-06-12T07:14:56.787816Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion <span id='edac'/>\n\nHere's the conclusion from the entire EDA:\n\n**Feature Insights**\n\n* `chol`, `trtbps`, and `oldpeak` have *decent amount of outliers.* This could affect certain models sensitive to them.\n\n* `oldpeak` and `chol` (moderately) are *not uniformly distributed*. This could affect models or analysis with uniform distribution as requirement. \n\n* `Restecg`, `Thall`, `Caa`, `Slp` are *likely to impact few models sensitive to data distribution* because value counts for some values is extremely low. \n\n* `Fbs` and `Cp` could *possibly affect models sensitive to data distribution* because their value counts is also not ideal.\n\n\n**Relation to target variable**\n\n* All categorical variables *except* `Fbs` are related to output, albeit to varying degrees. Especially, `Restecg` and `sex` have very weak relation.\n\n* All continous variables are related to output \n\n**Multi-collinearity**\n* Variables do *not have strong correlation* and are *weakly correlated*","metadata":{}},{"cell_type":"markdown","source":"# Model Development <span id='md'/>","metadata":{}},{"cell_type":"markdown","source":"## Loading Libraries <span id='ll'/>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, confusion_matrix\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\nprint('Libraries are Loaded')","metadata":{"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-12T07:14:56.789845Z","iopub.execute_input":"2021-06-12T07:14:56.790246Z","iopub.status.idle":"2021-06-12T07:14:57.969229Z","shell.execute_reply.started":"2021-06-12T07:14:56.790215Z","shell.execute_reply":"2021-06-12T07:14:57.967963Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering <span id='fe'/>","metadata":{}},{"cell_type":"markdown","source":"We would get out X as the values we determined to have an impact, Standardize them, and get One-hot encoding for categorical variables.","metadata":{}},{"cell_type":"code","source":"X = df[['sex', 'restecg', 'cp', 'exng', 'thall', 'caa', 'slp', 'age',\n        'trtbps', 'chol', 'thalachh', 'oldpeak']]\ny = df['output']\n\nscaler = StandardScaler()\nX[continous] = scaler.fit_transform(X[continous])\n\nencode_columns = categorical.copy()\nencode_columns.remove('fbs')\n\nX = pd.get_dummies(X, columns=encode_columns)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n                                                    random_state=65)\n\nprint('Done Pre-processing')\nprint('Final No. of features: ', X.shape[1])","metadata":{"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-12T07:14:57.970934Z","iopub.execute_input":"2021-06-12T07:14:57.971258Z","iopub.status.idle":"2021-06-12T07:14:58.002322Z","shell.execute_reply.started":"2021-06-12T07:14:57.971229Z","shell.execute_reply":"2021-06-12T07:14:58.001162Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Models and Getting Results <span id='tmagr'/>","metadata":{}},{"cell_type":"code","source":"models = {\n          'SVM': SVC(),\n          'Decision Tree': DecisionTreeClassifier(),\n          'Random Forest': RandomForestClassifier(),\n          'Logistic Regression': LogisticRegression(),\n          'K-Nearest Neighbors': KNeighborsClassifier(),\n          'Gradient Boosting': GradientBoostingClassifier(),\n          'AdaBoost Classifier': AdaBoostClassifier(learning_rate=0.15, n_estimators=25),\n         }\n\naccuracy_dict, precision_dict, recall_dict, f1_dict = dict(), dict(), dict(), dict()\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_hat = model.predict(X_test)\n    print('---------------------------------------------------\\n',\n          name,\n          '\\n---------------------------------------------------')\n\n    acc = accuracy_score(y_test, y_hat)\n    precision, recall, f1, support = precision_recall_fscore_support(y_test, y_hat, average='binary')\n    acc, precision, recall, f1 = round(acc, 5), round(precision, 5), round(recall, 5), round(f1, 5)\n    \n    accuracy_dict[name] = acc\n    precision_dict[name] = precision\n    recall_dict[name] = recall\n    f1_dict[name] = f1\n\n    print(f'Accuracy: {acc}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')\n\n    cm = confusion_matrix(y_test, y_hat)\n    df_cm = pd.DataFrame(cm)\n    sns.heatmap(df_cm, annot=True, cmap='Blues', linewidths=2)\n    plt.title(f'Confusion Matrix for {name}', fontsize=15)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()","metadata":{"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-12T07:14:58.004054Z","iopub.execute_input":"2021-06-12T07:14:58.004356Z","iopub.status.idle":"2021-06-12T07:15:00.217702Z","shell.execute_reply.started":"2021-06-12T07:14:58.004326Z","shell.execute_reply":"2021-06-12T07:15:00.216323Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacking <span id='secm'/>","metadata":{}},{"cell_type":"code","source":"level0 = [(name, model) for name, model in models.items()]\nlevel1 = LogisticRegression()\nstacked = StackingClassifier(estimators=level0, final_estimator=level1, n_jobs=-1)\nstacked.fit(X_train, y_train)\ny_hat = stacked.predict(X_test)\n\nname = 'Stacked Classifier'\nprint('---------------------------------------------------\\n',\n      name,\n      '\\n---------------------------------------------------')\n\nacc = accuracy_score(y_test, y_hat)\nprecision, recall, f1, support = precision_recall_fscore_support(y_test, y_hat, average='binary')\nacc, precision, recall, f1 = round(acc, 5), round(precision, 5), round(recall, 5), round(f1, 5)\n\naccuracy_dict[name] = acc\nprecision_dict[name] = precision\nrecall_dict[name] = recall\nf1_dict[name] = f1\n\nprint(f'Accuracy: {acc}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')\n\ncm = confusion_matrix(y_test, y_hat)\ndf_cm = pd.DataFrame(cm)\nsns.heatmap(df_cm, annot=True, cmap='Blues', linewidths=2)\nplt.title(f'Confusion Matrix for {name}', fontsize=15)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-12T07:15:00.220393Z","iopub.execute_input":"2021-06-12T07:15:00.220801Z","iopub.status.idle":"2021-06-12T07:15:04.597751Z","shell.execute_reply.started":"2021-06-12T07:15:00.220671Z","shell.execute_reply":"2021-06-12T07:15:04.59697Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot of Scores <span id='pos'/>","metadata":{}},{"cell_type":"code","source":"scores_dicts = {\n                'Accuracy': accuracy_dict,\n                'Precision': precision_dict,\n                'Recall': recall_dict,\n                'F1 Score': f1_dict,\n              }\n\nfor name, scores_dict in scores_dicts.items():\n    index, values = zip(*scores_dict.items())\n    acc_df = pd.DataFrame(data=values, index=index, columns=[name])\n    plt.figure(figsize=(9, 10))\n    sns.barplot(y=acc_df.index, x=acc_df[name])\n    plt.title(f'Plot of {name} Score')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-12T07:15:04.598966Z","iopub.execute_input":"2021-06-12T07:15:04.599411Z","iopub.status.idle":"2021-06-12T07:15:05.671493Z","shell.execute_reply.started":"2021-06-12T07:15:04.59938Z","shell.execute_reply":"2021-06-12T07:15:05.670792Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion <span id='fcc'/>\n\n* We started with tabular data and performed EDA and got crucial information\n* We did some feature engineering by performing Standardization and One-Hot Encoding\n* We created several models and got their results. The best ones were Ensemble Methods (Gradient Boost, AdaBoost) and Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"# Thank you! <span id='ty' />\n\nThanks for reading up to this far. \n\nIf you liked the notebook, please consider upvoting. \n\nAlso, thanks to my bro [Naman Manchanda](https://www.kaggle.com/namanmanchanda) for his tips on visualizations. ","metadata":{}}]}