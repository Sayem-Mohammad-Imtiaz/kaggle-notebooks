{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read in data: "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_directory = \"../input/\"\ndata = pd.read_csv(data_directory + '/spam.csv', encoding='latin-1') \ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate tesing and trainning data set to 25% to 75%: "},{"metadata":{"trusted":true},"cell_type":"code","source":"text_train, text_test, tag_train, tag_test = train_test_split(data.v2,data.v1, test_size=0.25,random_state=0) \nprint(text_train.shape, text_test.shape,tag_train.shape,tag_test.shape)\nprint()\nprint(\"After Spliting:\")\nprint(text_train.head())\nprint()\nprint(tag_train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vectorized Counts of words: \n\n    fit() : used for generating learning model parameters from training data\n\n    transform() : parameters generated from fit() method,applied upon model to generate transformed data set.\n\n    fit_transform() : combination of fit() and transform() api on same data set\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer()\n\ntext_train_count = vectorizer.fit_transform(text_train)\ntext_test_count  = vectorizer.transform(text_test)\n# print ('Summary:')\n# print (text_train_count.shape)\n# print (text_test_count.shape)\n# print (vectorizer.vocabulary_)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate Frequncy Table: "},{"metadata":{},"cell_type":"markdown","source":"np.sum([[0, 1], [0, 5]], axis=0) -->>\narray([0, 6])\n\nnp.sum([[0, 1], [0, 5]], axis=1) -->>\narray([1, 5])"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Occurrences take data_train_count to become a matrix like 2d array, then use sum with axis = 0 to add value from each columns vertically to get an array that each contains the \n# total sume of each letter\nwordFreqeuncy = pd.DataFrame({'Word': vectorizer.get_feature_names(), 'occurrences':text_train_count.toarray().sum(axis=0)})\n# print(data_train_count.toarray().sum(axis=0))\nwordFreqeuncy['frequency'] = wordFreqeuncy['occurrences']/np.sum(wordFreqeuncy['occurrences'])\nplt.plot(wordFreqeuncy.occurrences) # plot occurance with occurance id\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To sort the table based on occurrences from high to low :"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordFreqeuncySort = wordFreqeuncy.sort_values(by=['occurrences'], ascending=False)\nwordFreqeuncySort.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trainning the Model Based on Naive Bayes algorithm: \n*        We use SkLearn's MultinomialNB model to implements NB Algorithm."},{"metadata":{},"cell_type":"markdown","source":"    Naive Bayes algorithm: (sources: https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/)\n        It is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\n        Equation: \n            P(c | x) = P( x | c) * P(c) / P (x)\n            \n            P(c|x) is the posterior probability of class (c, target) given predictor (x, attributes).\n            P(c) is the prior probability of class.\n            P(x|c) is the likelihood which is the probability of predictor given class.\n            P(x) is the prior probability of predictor.\n","attachments":{}},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MultinomialNB()\nclf.fit(text_train_count, tag_train)\npredictions = clf.predict(text_test_count)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluate The Model: "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare tag_test with our prediction: \nprint (\"accuracy_score: \",accuracy_score(tag_test, predictions))\nprint()\nprint(\"classification_report\")\nprint (classification_report(tag_test, predictions))\nprint()\nprint(\"confusion_matrix\")\nprint (confusion_matrix(tag_test, predictions))\nprint()\nprint(\"cross_val_score\")\ncross_val = cross_val_score(clf, text_train_count, tag_train, cv=20, scoring='accuracy')\nprint (cross_val)\nprint()\nprint(\"Mean of cross_val_score: \",np.mean(cross_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* accuracy_score is fiarly high for our model considers accuracy_score = Total number of correct prediction / Total number of prediction\n* classification_report:\n    * precision is the ability of a classiifer not to label an instance positive that is actually negative. “for all instances classified positive, what percent was correct?”, we gets a fairly high one.\n    * Recall is the ability of a classifier to find all positive instances.“for all instances that were actually positive, what percent was classified correctly?”. We gets a very high score on Recall.\n    * The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, and we have a fairly high score.\n    * Support is the number of actual occurrences of the class in the specified dataset.\n* Confusion Matrix: \n    *   We have relative large number of prediction are matched with what we have\n* Cross val score: \n    *   These scores gave us percentage of corectness for each cases.\n    *   We take mean of all of them and get approximately 98% of our observations are correctly predicted. \n "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}