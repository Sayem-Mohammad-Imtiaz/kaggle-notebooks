{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"004e4b3e3cc92fe780927ea32ff433005b3ae5f2"},"cell_type":"markdown","source":" Author: Michael Zhou   \n ID:1337316"},{"metadata":{"trusted":true,"_uuid":"d608977be2e67cd373989909d31bc93035c6e2a6"},"cell_type":"code","source":"breastData = pd.read_csv('../input/wisconsin_breast_cancer.csv')\nbreastData = breastData.fillna(0)\nbreastData.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a2b728cd663793f86eac5c79933d3c58d1f8a53"},"cell_type":"markdown","source":"Load data from input file and fill any null value in the dataset with 0, display the first 5 rows in the dataset"},{"metadata":{"trusted":true,"_uuid":"07365c0a59ca1eedbd91ef6a630a62f32b85f98d"},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(data=breastData,hue='class',palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9710a8861c019ac8242587daceb8776bade9383"},"cell_type":"markdown","source":"import seaborn and use pairplot to visualising the data with hue of class"},{"metadata":{"trusted":true,"_uuid":"c1dcabc726a78e7ccc419b3344c980584bd22f52"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx = breastData.iloc[:,1:9]\ny = breastData.iloc[:,10]\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=123)\nprint(x_train.shape,y_train.shape)\nfrom sklearn.svm import SVC\nmodel=SVC()\nmodel.fit(x_train, y_train)\npred = model.predict(x_test)\nprint(pred[:5])\nprint(y_test[:5])\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, pred))\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6a9baa8d73ac651978d857f1e0fbe4b2fee3d98"},"cell_type":"markdown","source":"Import train and test split and combine all features as x and class as y, split data into train and test set, pairplot digrams seems has quite a few outlier which is different from the iris dataset, which means the predict result may be vary to the Iris's dataset, then train the training set with svc algorithms, use the model to predict the x_test data and check for a few prediction manually and building a matrix between result of prediction and real result. Last we build a report based on the prediction to show the statistics of the data"},{"metadata":{"_uuid":"6a6916fede545cc3fc41ada57b9794f13e75fd43"},"cell_type":"markdown","source":"The result matrix shows there are 84 people got the right prediction with no cancer, 1 person with no cancer but result in cancer which is an error. On the other side, there are 55 people who have cancer predicted to have cancer with no error. It seems the result of this SVG algorthm is pretty good"},{"metadata":{"trusted":true,"_uuid":"acd9e8ec40452663267f7443da688e8ff4998429","scrolled":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXsub = breastData.iloc[:,[1,3,5,7]]\nxsub_train, xsub_test,y_train2,y_test2 = train_test_split(Xsub,y,test_size=0.2, random_state=123)\n\nfrom sklearn.svm import SVC\nmodel2=SVC()\nmodel2.fit(xsub_train,y_train2)\npred2 = model2.predict(xsub_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test2, pred2))\nprint(classification_report(y_test2, pred2))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b92d7644c9f3e73164fbbe3a483f500791c98c9"},"cell_type":"markdown","source":"I have chosen row 1,3,5 and 7 as x beacause it seems that if these four features have the higher values, the higher chances to get a cancer. Then I split it into train and test dataset, print out the shape of the data to see if things are going right, and using SVC algorithms to train the sub data again, Predict the sub test set and print out some prediction. Create a matrix based on the sub test. Print out the report for sub set's prediction. The matrix show there are 2 predicted error in the whole prediction which is 1 extra error compare to the last test. Therefore I will say that the first test with all features is better than the four feature's test"},{"metadata":{"trusted":true,"_uuid":"a79a3e278f83b922d80a0944282bb3a5e51a8cb0","scrolled":true},"cell_type":"code","source":"\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel3 = KNeighborsClassifier(n_neighbors=1)\nmodel3.fit(x_train, y_train)\npred3 = model3.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test,pred3))\nprint(classification_report(y_test, pred3))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dd3df69849fae42ffc5a48ee966988712bb1c3d"},"cell_type":"markdown","source":"Import knn function and let k = 1, train the data and predict it with x_test, display some output. Genrate a report based on the knn =1 dataset. The result of the matrix show there are 6 errors in the whole test which is less accurate compare to SVC algorithm test"},{"metadata":{"trusted":true,"_uuid":"5a6e9ea4e11c4f012abd98c19efb6e6dfe2fa1aa","scrolled":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel4 = KNeighborsClassifier(n_neighbors=5)\nmodel4.fit(x_train, y_train)\npred4 = model4.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(\"Here is the matrix when k=5\")\nprint(confusion_matrix(y_test, pred4))\nprint(classification_report(y_test,pred4))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"015e0ed936511d5076d54335452ef054879f68f3"},"cell_type":"markdown","source":"From the result of the matrix, it shows there are 4 errors in the whole test which is better than the previous KNN test when k = 1, but still less accurate compare to SVC test. Therefore I will say that SVC with all features is the best out of those four tests, which means for this data, SVC is the better algorithm than KNN"},{"metadata":{"_uuid":"5ee945f4b32d3dd97e64ceeacf4625899b279c65"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}