{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Bangalore House Price Prediction","metadata":{}},{"cell_type":"markdown","source":"### Import the Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib \nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"../input/bangalorehouseprices/bengaluru_house_prices.csv\")\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count of Each `type of area_type`","metadata":{}},{"cell_type":"code","source":"df1['area_type'].value_counts()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Cleaning","metadata":{}},{"cell_type":"code","source":"df1['area_type'].value_counts()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = df1.drop(['area_type' , 'society' , 'balcony' , 'availability'] , axis = 'columns')\ndf2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the dataset has 13,000 rows and the na values are small in number, we can drop it. else we can use median, std deviation","metadata":{}},{"cell_type":"code","source":"df3 = df2.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3['size'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\ndf3.bhk.unique()\n# code basically removes the duplicates","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3['bhk'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3[df3['bhk']>20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.total_sqft.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert the SQFT with hyphens to numbers","metadata":{}},{"cell_type":"code","source":"# Check whether the value is float or not\ndef is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.total_sqft.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Looking at Values where it is valid float**","metadata":{}},{"cell_type":"code","source":"df3[df3['total_sqft'].apply(is_float)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Above shows that total_sqft can be a range (e.g. 2100-2850). For such case we can just take average of min and max value in the range. There are other cases such as 34.46Sq. Meter which one can convert to square ft using unit conversion. I am going to just drop such corner cases to keep things simple**\n\n","metadata":{}},{"cell_type":"markdown","source":"**Convert to averages**","metadata":{}},{"cell_type":"code","source":"def convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if(len(tokens)) == 2:\n        return ((float(tokens[0]) + float(tokens[1]))/2)\n    try:\n        return float(x)\n    except:\n        return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_sqft_to_num('2000 - 4000')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4 = df3.copy() #deep copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4['total_sqft'] = df4[\"total_sqft\"].apply(convert_sqft_to_num)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4 = df4[df4.total_sqft.notnull()]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.total_sqft.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"df5 = df4.copy()\ndf5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\ndf5.head()\n#Price is in Lakhs Thus we multiply by 100000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5.location.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df5.location.unique())\n#Lot of Locations\n#Since we have lot of locations, this is called dimensionality curse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We will use Dimensionality Reduction to reduce the numbeer of Locations**","metadata":{}},{"cell_type":"markdown","source":"**Here dimensionality is a categorical variable**","metadata":{}},{"cell_type":"code","source":"df5.location = df5.location.apply(lambda x: x.strip())\n# Remove the leading spaces","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"location_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"location_stats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**To reduce the number of locations, we can say that any location that has less than 10 data points is called other location**","metadata":{}},{"cell_type":"code","source":"len(location_stats[location_stats < 10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"location_stas_less_than_10 = location_stats[location_stats < 10]\nlocation_stas_less_than_10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df5.location.unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5.location = df5.location.apply(lambda x : 'other' if x in location_stas_less_than_10 else x)\n# all the locations less than 10 data points will be converted to 'other'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df5.location.unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outlier Detection","metadata":{}},{"cell_type":"markdown","source":"Outliers are not errors but really large or small values which make no sense in the data. For example a 2 bedroom apartment cannot be 5000 sq feet","metadata":{}},{"cell_type":"markdown","source":"**As a data scientist when you have a conversation with your business manager (who has expertise in real estate), he will tell you that normally square ft per bedroom is 300 (i.e. 2 bhk apartment is minimum 600 sqft. If you have for example 400 sqft apartment with 2 bhk than that seems suspicious and can be removed as an outlier. We will remove such outliers by keeping our minimum thresold per bhk to be 300 sqft**\n\n","metadata":{}},{"cell_type":"code","source":"df5[df5.total_sqft/df5.bhk<300].head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check above data points. We have 6 bhk apartment with 1020 sqft. Another one is 8 bhk and total sqft is 600. These are clear data errors that can be removed safely**\n\n","metadata":{}},{"cell_type":"code","source":"df6 = df5[~(df5.total_sqft/df5.bhk<300)]\ndf6.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df6.price_per_sqft.describe()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**clearly the minimum value of square feet cannot be 267 rupees and maximum cannot be 176470**","metadata":{}},{"cell_type":"markdown","source":"**Now we can remove these extreme cases based on Standard Deviation**","metadata":{}},{"cell_type":"markdown","source":"**Basically what the below function does is take the data points per location and filter out the data points that have standard deviation that is greater than 1**","metadata":{}},{"cell_type":"code","source":"def remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('location'):\n        m = np.mean(subdf.price_per_sqft)\n        st = np.std(subdf.price_per_sqft)\n        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n    return df_out\ndf7 = remove_pps_outliers(df6)\ndf7.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**the remove_pps_outliers function is looping thorough the subgroups of locations. For. eg. a subdf could be  all data points with \"jayanagar\" as a location. It calculates mean and std of the rows in jayanagar location and then selects all points in that are within m-st and m-st of jayanagar  and adds that to the df_out.**\n","metadata":{}},{"cell_type":"markdown","source":"Now our data points are reduced by almost 2000 points","metadata":{}},{"cell_type":"markdown","source":"**One more thing that we have to check is that if the price of a two bhk apt is greater than 3bhk apt for the same square foot area**","metadata":{}},{"cell_type":"markdown","source":"We are going to plot a scatter plot which will tell us how many of these types of points we have","metadata":{}},{"cell_type":"code","source":"def plot_scatter_chart(df,location):\n    bhk2 = df[(df.location==location) & (df.bhk==2)]\n    bhk3 = df[(df.location==location) & (df.bhk==3)]\n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50) # s is the marker size\n    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(df7,\"Rajaji Nagar\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"for around 1700 sq foot area the two bedroom apt price is higher than 3 bedroom","metadata":{}},{"cell_type":"code","source":"plot_scatter_chart(df7,\"Hebbal\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We should also remove properties where for same location, the price of (for example) 3 bedroom apartment is less than 2 bedroom apartment (with same square ft area). What we will do is for a given location, we will build a dictionary of stats per bhk, i.e.\n\n{ <br>\n    '1' : { <br>\n        'mean': 4000,<br>\n        'std: 2000,<br>\n        'count': 34<br>\n    },  <br>\n    '2' : {<br>\n        'mean': 4300,<br>\n        'std: 2300,<br>\n        'count': 22<br>\n    },    \n}<br>\nNow we can remove those 2 BHK apartments whose price_per_sqft is less than mean price_per_sqft of 1 BHK apartment\n\n","metadata":{}},{"cell_type":"code","source":"def remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n    return df.drop(exclude_indices,axis='index')\ndf8 = remove_bhk_outliers(df7)\ndf8.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nInner for loop will iterate for every possible group of no. of bedrooms of that respective  location group. (of outer for loop)\n\n\nFirst inner for loop will store information about mean , std and no of data points( no of values present in a group of bedroom) in the already created dictionary in the outer for loop with key as the respective bedroom no. group. i.e (bhk_stats[2] stores info about 2 bedroom group values)\n\n\nSecond inner for loop performs the main functionality,\nstats = bhk_stats.get(bhk-1)\n\n\nhere it will fetch the value for the previous no. of bedroom group.\nFor example, for 1 bedroom group it will be None , as there is no possibe value stored for 0 bedroom group, simply because there is not any value like that in dataframe.\n\n\nalso for 3 bedroom group, it will fetch information about 2 bedroom group ( so that we can check the mean value )\n\n\nif stats and stats['count']>5:\nit checks if there is dictionary present ( we didn't have for 1 bedroom group ) because None value will throw error. It also checks if it has more than 5 values or not. Because we cannot decide to discard something without comparing it with substantial data values.\n\n\nexclude_indices = np.append(exclude_indices,\nbhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\nthis will finally store the index of the current bedroom group's element if it is lower than the previous bedroom's mean value. Then they are dropped \n","metadata":{}},{"cell_type":"code","source":"plot_scatter_chart(df8,\"Rajaji Nagar\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot same scatter chart again to visualize price_per_sqft for 2 BHK and 3 BHK properties\n\n","metadata":{}},{"cell_type":"code","source":"plot_scatter_chart(df8,\"Hebbal\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df8.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")\n#Normal Distribution","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df8.bath.unique()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(df8.bath,rwidth = 0.8)\nplt.xlabel(\"Number of bathrooms\")\nplt.ylabel(\"Count\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df8[df8.bath>10]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df8[df8.bath>df8.bhk+2]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df9 = df8[df8.bath>df8.bhk+2]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df9","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df9 = df8[df8.bath<df8.bhk+2]\ndf9.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df9.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df10 = df9.drop(['size','price_per_sqft'],axis='columns')\ndf10.head(3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**size and price_per_sqft can be dropped because they were used only for outlier detection. Now the dataset is neat and clean and we can go for machine learning training**","metadata":{}},{"cell_type":"code","source":"df10.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One Hot Encoding and Machine Learning Model","metadata":{}},{"cell_type":"code","source":"\ndummies = pd.get_dummies(df10.location)\ndummies.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')\ndf11.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Building","metadata":{}},{"cell_type":"code","source":"df12 = df11.drop('location',axis = 'columns')\ndf12.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df12.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df12.drop(['price'],axis='columns')\nX.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df12.price\ny.head(3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train,y_train)\nlr_clf.score(X_test,y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}