{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Topic Modeling with LDA"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gensim\nfrom gensim import corpora, models\nimport pandas as pd\nimport pyLDAvis.gensim\nimport nltk\nfrom nltk import pos_tag\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import stopwords \nimport string\nfrom gensim.models import CoherenceModel\nimport math\nfrom nltk.corpus import wordnet\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets analyze dataset with most upvoted Kaggle datasets. Using datasets' description we will try to understand for every document which topics it consists of. Latent Dirichlet Allocation will be used as a method to find out topics."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/voted-kaggle-dataset/voted-kaggle-dataset.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Out of all columns we will use only last one - Description."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we remove all empty values."},{"metadata":{"trusted":true},"cell_type":"code","source":"descriptions = df[df['Description'].notnull()]['Description']\ndescriptions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Data preparation</h3>\nNow we want to clean the data. All punctuation is be removed as well as numbers. Words are lemmatized and lowecased."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_wordnet_pos(treebank_tag):\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"documents = []\ntexts = []\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english')).union({'data', 'dataset', 'model'})\ndigits = set(string.digits)\nfor description in descriptions.iteritems():\n    document_str = str(description[1]).lower()\n    document_str = document_str.translate(str.maketrans('', '', string.punctuation))\n    token_words = word_tokenize(document_str)\n    pos_tagged = pos_tag(token_words)\n    tokens = [(token, get_wordnet_pos(tag)) for token, tag in pos_tagged]\n    lemma_tokens = [lemmatizer.lemmatize(token, tag) for token, tag in tokens]\n    document = [w for w in lemma_tokens if (not w in stop_words) and (not w.isdigit()) ]\n    documents.append(document)\n    texts.append(' '.join(document))\nprint(documents[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having array that consists of array of tokens. We use it to build a dictionary. After that a document-term matrix is built."},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = corpora.Dictionary(documents)\n\ndocument_term = [dictionary.doc2bow(document) for document in documents]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Creating a model</h3>\nAfter adjusting number of topics using coherence score I decided to have 20 topics for LDA model. Given number of topics, document-term matrix and dictionary we create LDA model using genism****."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldamodel = models.ldamodel.LdaModel(document_term, num_topics=20, id2word = dictionary)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now have a brief look at 5 most popular words for each topic."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldamodel.print_topics(num_words=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Visualization</h3>\nUsing pyLDAvis we can look at this nice interactive plot below. Using either hover or buttons we can see how do words appear in all our topics."},{"metadata":{"trusted":true},"cell_type":"code","source":"pyLDAvis.enable_notebook()\npyLDAvis.gensim.prepare(ldamodel, document_term, dictionary)\n# pyLDAvis.display(visualization)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For example for topic 2 the most used word is 'restaurant'. And for topic three there are 'game', 'player', 'team' and so on."},{"metadata":{},"cell_type":"markdown","source":"<h3>Calculating metrics</h3>\nAfter looking at visualizations we may want to have some numeric values that can show quality of our topic model. For example we could compare it with other models and so on. Here we calculate Perplexity and Coherence score."},{"metadata":{"trusted":true},"cell_type":"code","source":"log_perplexity = ldamodel.log_perplexity(document_term)\nprint('Perplexity:', math.exp(log_perplexity))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coherence_model_lda = CoherenceModel(model=ldamodel, texts=documents, dictionary=dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('Coherence score:', coherence_lda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}