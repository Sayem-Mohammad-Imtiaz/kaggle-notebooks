{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"nbconvert_exporter":"python","version":"3.6.3","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python"}},"cells":[{"source":"** Objective: ** \n** To develop a statistical model for predicting whether questions will be upvoted, downvoted, or closed based on their text. ** \n** To predict how long questions will take to answer. **\n\n** Authors: Rachit Rawat, Rudradeep Guha, Vineet Nandkishore **","metadata":{"_cell_guid":"8f4aa826-8c88-4323-86f5-623ec4cfb9c1","_uuid":"e04c72c962d9cdfc604a61b1ee23bd46f53661a7"},"cell_type":"markdown"},{"source":"# 0. Setup Environment","metadata":{"_cell_guid":"68edf668-861d-40f3-b0b6-d09ceb866a13","_uuid":"315c15cd0dd3ccc54e4446934916313068ada317"},"cell_type":"markdown"},{"source":"# load required packages\n\n# for creating dataframes from csv datasets\nimport pandas as pd\n\n# for regular expressions\nimport re\n\n# for stripping stop words\nfrom nltk.corpus import stopwords\n\n# for TF-IDF\nfrom textblob import TextBlob as tb\n\n# for jaccard score\nfrom sklearn.metrics import jaccard_similarity_score\n\n# for removing HTML tags from text body\nfrom html.parser import HTMLParser\n\n# for counting\nimport collections\n\n# for scientific computing\nimport numpy as np\nimport math\n\n# for plotting graphs\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n# magic function\n%matplotlib inline\n\n# kaggle - data set files are available in the \"../input/\" directory\ndataset_dir = \"../input/\"\ndataset_dir_questions = \"Questions.csv\"\ndataset_dir_answers = \"Answers.csv\"\ndataset_dir_tags = \"Tags.csv\"\n\n# for offline run\n# dataset_dir = \"/home/su/Downloads/stacksample\"\n\n# list the files in the dataset directory\nfrom subprocess import check_output\nprint(check_output([\"ls\", dataset_dir]).decode(\"utf8\"))\n\ncachedStopWords = stopwords.words(\"english\")\n\n","metadata":{"_cell_guid":"2f3cc812-f944-6471-f7a3-cc2894482010","_active":false,"_uuid":"738b617fca8b49b678e3b9c70f7b272564eff0b2"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"** 0.1 HTML tags Stripper class **","metadata":{"_cell_guid":"bf416f93-b382-45f4-8d8f-7665d2e56ba8","_uuid":"daa792f1113572ee69d54458edc6308f281a61c9"},"cell_type":"markdown"},{"source":"class MLStripper(HTMLParser):\n    def __init__(self):\n        self.reset()\n        self.strict = False\n        self.convert_charrefs= True\n        self.fed = []\n    def handle_data(self, d):\n        self.fed.append(d)\n    def get_data(self):\n        return ''.join(self.fed)\n\ndef strip_tags(html):\n    s = MLStripper()\n    s.feed(html)\n    return s.get_data()","metadata":{"_cell_guid":"bddb2f84-5616-4abd-90b0-5211e6c3ab05","collapsed":true,"_uuid":"9e8575730117592534ae5bb427eb71f5b64dcca0"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"** 0.2 TF-IDF helper fucntions **","metadata":{"_cell_guid":"5f92be6e-b5f6-4c3c-a66c-ead9a1d91838","_uuid":"b6c01c8410eea1077cab7bb41980f59b453af8ee"},"cell_type":"markdown"},{"source":"# tf(word, blob) computes \"term frequency\" which is the number of times \n# a word appears in a document blob,normalized by dividing by \n# the total number of words in blob. \n# We use TextBlob for breaking up the text into words and getting the word counts.\ndef tf(word, blob):\n    return blob.words.count(word) / len(blob.words)\n\n# n_containing(word, bloblist) returns the number of documents containing word.\n# A generator expression is passed to the sum() function.\ndef n_containing(word, bloblist):\n    return sum(1 for blob in bloblist if word in blob.words)\n\n# idf(word, bloblist) computes \"inverse document frequency\" which measures how common \n# a word is among all documents in bloblist. \n# The more common a word is, the lower its idf. \n# We take the ratio of the total number of documents \n# to the number of documents containing word, then take the log of that. \n# Add 1 to the divisor to prevent division by zero.\ndef idf(word, bloblist):\n    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n\n# tfidf(word, blob, bloblist) computes the TF-IDF score. \n# It is simply the product of tf and idf.\ndef tfidf(word, blob, bloblist):\n    return tf(word, blob) * idf(word, bloblist)","metadata":{"_cell_guid":"bbc860ac-d845-47eb-9492-50d7cd2cf56b","collapsed":true,"_uuid":"0f25bcb2bbaeed423173739009723f46c0f23106"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"** 0.3 Normalizer function **\n* strip HTML tags\n* strip stop words and symbols \n* convert to lowercase\n* strip single characters\n* strip words that are all numbers ","metadata":{"_cell_guid":"44554c34-04bb-42c7-b694-ed203fd3e8f9","_uuid":"f53ca9faab54e28f4c1a4cb78d90a707cf19d078"},"cell_type":"markdown"},{"source":"def normalize(str):\n    return ' '.join([word for word in re.sub(r'[^\\w]', ' ', strip_tags(str)).lower().split() if word not in cachedStopWords and len(word) > 1 and not word.isdigit()])\n","metadata":{"_cell_guid":"c4b5fa6f-ba9b-4ea8-9794-7769225fe757","collapsed":true,"_uuid":"b959a2fd60e3ad44df3b35fb16a40efebe1df60e"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"# 1. Preprocessing\n**1.1 pandas - load CSV into dataframe **\n","metadata":{"_cell_guid":"4bb24fa7-fa47-c351-bebe-d6ca025696fb","_active":true,"_uuid":"dc0f25079efd80085f22006b059b99291f50c974"},"cell_type":"markdown"},{"source":"# Read CSV\n\n# Original Dimensionality - (rows, columns)\n\n# (1264216, 7) \n# Columns (Id, OwnerUserId, CreationDate, ClosedDate, Score, Title, Body)\n# frame every 1000th question (resource restraints)\nquestions_df = pd.read_csv(dataset_dir+dataset_dir_questions, encoding='latin1').iloc[::10000, :]\n\n# (2014516, 6)\n# Columns (Id, OwnerUserId, CreationDate, ParentId, Score, Body)\n# frame every 1000th answer (resource restraints)\nanswers_df = pd.read_csv(dataset_dir+dataset_dir_answers, encoding='latin1').iloc[::1000, :]\n\n# (3750994, 2)\n# Columns (Id, Tag)\n# frame every 1000th tag (resource restraints)\ntags_df = pd.read_csv(dataset_dir+dataset_dir_tags, encoding='latin1').iloc[::1000, :]","metadata":{"_active":false,"_cell_guid":"6443555a-49dd-1457-22cf-6e09fe9a6798","collapsed":true,"_uuid":"a422f0c759254e4c9068ae062ef186df73947bb6"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"**1.2 Sample dataframe**","metadata":{"_cell_guid":"2416fd35-bbb8-46e2-8396-425103b3b1dd","_uuid":"aa9597f19c27e04d29c58839c540c1c4ce697ace"},"cell_type":"markdown"},{"source":"# Calculate dimensionality\n# questions_df.shape \n# answers_df.shape \n# tags_df.shape \n\n# Sample dataframe - uncomment to view\nquestions_df.head(10)\n# answers_df.head(10)\n# tags_df.head(10) ","metadata":{"_cell_guid":"eb9d8dcb-e632-4e7c-a4a7-e94ae5cc5f24","_uuid":"3a88a894ab1d157e272ed7c27728d06ff44b5ad7"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"**1.3 Sample dataframe before normalization **","metadata":{"_cell_guid":"f55dafc0-9c39-4779-9284-c353fbe60502","_uuid":"02ffa6c0c8ffa27470fd4db06f3e249127425818"},"cell_type":"markdown"},{"source":"# Calculate dimensionality\n# questions_df.shape \n# answers_df.shape \n# tags_df.shape \n\n# Sample dataframe - uncomment to view\nquestions_df.head(10).loc[:, 'Title':'Body']\n# answers_df.head(10).loc[:, 'Body':]\n# tags_df.head(10) ","metadata":{"_cell_guid":"a45e1e38-9442-41dd-8b6d-27fe8a228b1a","_uuid":"50860684ebdf70a683f969ab09dcb69f591f803d"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"**1.4 Normalize text**","metadata":{"_cell_guid":"e11c5eb7-3399-48e4-8c19-9bc073390272","_uuid":"fd95a0589a0bdf22c03b7f3fdb0efbf707fb0cd8"},"cell_type":"markdown"},{"source":"# Normalize question body and title\nfor index, row in questions_df.iterrows():\n    questions_df.at[index, 'Body']= normalize(row[6])\n    questions_df.at[index, 'Title']= normalize(row[5])\n\n# Normalize answer body\nfor index, row in answers_df.iterrows():\n    answers_df.at[index, 'Body']= normalize(row[5]) ","metadata":{"_cell_guid":"91d123fe-3d1b-45a3-907e-d1eca1925d6c","collapsed":true,"_uuid":"5723a2e056bc00fc2973e5928f212ad74bbd07a8"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"**1.5 Sample dataframe after normalization **","metadata":{"_cell_guid":"44c8687c-7b3b-48c8-81c9-0038d4a672a8","_uuid":"7913ddfa6a5c335641a4311189509e17368e1fe5"},"cell_type":"markdown"},{"source":"# Calculate dimensionality\n# questions_df.shape \n# answers_df.shape \n# tags_df.shape \n\n# Sample dataframe - uncomment to view\nquestions_df.head(10).loc[:, 'Title':'Body']\n# answers_df.head(10).loc[:, 'Body':]\n# tags_df.head(10) ","metadata":{"_cell_guid":"acc88448-90fa-4fdd-a95e-af538becaeea","_uuid":"45c5fb411d16418c06c0e1ee04edee51cac9295f"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"** 1.6 Calculate TF-IDF of words ** <br>\nMake a dictionary { word (key), posting list (value) } pair.  <br>\nPosting lists of a word contains its TF-IDF along with question ID.","metadata":{"_cell_guid":"f482bde7-a597-46aa-93e1-a12a3de0f3d9","_uuid":"0f5ab582a29b7b8363ba062acd23e9d8456a568d"},"cell_type":"markdown"},{"source":"tfidf_dict={}\nqID_dict={}\nbloblist=[]\nidlist=[]\n\nfor index, row in questions_df.iterrows():\n    # also append title to text body\n    bloblist.append(tb(row[6]+\" \"+row[5]))\n    idlist.append(row[0])\n\nfor i, blob in enumerate(bloblist):\n    if i < 5:\n        print(\"Top words in question ID {}\".format(idlist[i]))\n    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n    for word, score in sorted_words[:5]:\n        if i < 5:\n            print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n            \n        # word dict    \n        if word in tfidf_dict:\n            tfidf_dict[word].append([idlist[i],round(score, 5)])\n        else:\n            tfidf_dict[word] = [[idlist[i],round(score, 5)]]\n        \n        # qID dict\n        if idlist[i] in qID_dict:\n            qID_dict[idlist[i]].append(word)\n        else:\n            lst=[]\n            lst.append(word)\n            qID_dict[idlist[i]]=lst\n","metadata":{"_cell_guid":"3fee662f-5d5b-4e04-b956-a2657753fbd7","_uuid":"8e79d9a90ca959d77ce7b368e750999b6ed2dd45"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"**1.7 Sample dictionary **","metadata":{"_cell_guid":"249a37ec-c8b1-42b2-bf91-1c6d34ef933b","_kg_hide-output":true,"_uuid":"f625c48f7a026b75f682034b5a2c3519c3e3e18c"},"cell_type":"markdown"},{"source":"i = 1\nfor k, v in tfidf_dict.items():\n    print(k, v)\n    if i == 10:\n        break\n    i+=1\n    \n# i = 1\n# for k, v in qID_dict.items():\n#     print(k, v)\n#     if i == 10:\n#         break\n#     i+=1","metadata":{"_cell_guid":"2c274b47-d85d-4480-b0cb-ea4c9e67bc0c","_uuid":"072ba4261308b5b8db96a9b639cec8a31ccf8fac"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"** Duplicate predictor function **","metadata":{"_cell_guid":"6386ac58-5aee-4527-af80-76050c6d4108","_kg_hide-output":true,"_uuid":"2fd119b2dacb196a0f1ef62a5d000152d64d5840"},"cell_type":"markdown"},{"source":"def predict_duplicate(query):\n    \n    def top_words(text):\n        counts = collections.Counter(text.split())\n        return [elem for elem, _ in counts.most_common(5)]\n\n    termList=top_words(query)\n    \n    for k, v in qID_dict.items():\n        if jaccard_similarity_score(termList, qID_dict[k]) >= 0.75:\n            print(\"Duplicate Question. Question exists with qID: \" + k)\n            return\n    \nprint(\"Not a Duplicate Question.\")\n                ","metadata":{"_cell_guid":"0e77f88e-07d1-4d48-983c-e6f0d18a1fbd","_uuid":"2111173b35fb4c71fd47a0a0324b0cfc725ab008"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"inputQ_title=\"What is the most efficient way to deep clone an object in JavaScript?\"\ninputQ_body=\"\"\"What is the most efficient way to clone a JavaScript object? \nI've seen obj = eval(uneval(o)); being used, \nbut that's non-standard and only supported by Firefox.\nI've done things like obj = JSON.parse(JSON.stringify(o)); but question the efficiency. \nI've also seen recursive copying functions with various flaws. \nI'm surprised no canonical solution exists.\"\"\"\ninputQ_tags=\"javascript, json, object\"\n\n# normalize\nnormalized_query=normalize(inputQ_title + \" \" + inputQ_body+ \" \" + inputQ_tags)\n\n# predict whether duplicate question\npredict_duplicate(normalized_query)","metadata":{"_cell_guid":"b0d7dc85-95d5-4bd4-a7c0-444a8e71a003","collapsed":true,"_uuid":"6059baf7775a02288825132d1c9f896e2f883f9e"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"# Initial analysis","metadata":{"_cell_guid":"174e62d1-6369-4536-af85-c84bb7f6e97e","_uuid":"4caebf00dc4249f61318851ebbb22a8fc57b7718"},"cell_type":"markdown"},{"source":"** Top 10 most common tags **","metadata":{"_cell_guid":"37fb0317-3045-463b-98fb-35c18792c318","_uuid":"abcb6de413b8679b885d089778b4d162866988a8"},"cell_type":"markdown"},{"source":"tags_tally = collections.Counter(tags_df['Tag'])\n\n# x = tag name, y = tag frequency\nx, y = zip(*tags_tally.most_common(10))\n\ncolormap = plt.cm.gist_ncar #nipy_spectral, Set1,Paired  \ncolors = [colormap(i) for i in np.linspace(0, 0.8,50)]   \n\narea = [i/3 for i in list(y)]   # 0 to 15 point radiuses\nplt.figure(figsize=(8,8))\nplt.ylabel(\"Frequency\")\nplt.title(\"Top 10 most common tags\")\nfor i in range(len(y)):\n        plt.plot(i,y[i], marker='v', linestyle='',ms=area[i],label=x[i])\n\nplt.legend(numpoints=1)\nplt.show()","metadata":{"_cell_guid":"d399d256-b1d6-97ff-7f95-512fcee92649","_active":false,"_uuid":"9bbee08860c0f9d90c58025987af029a6c726316"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"**Distribution  - number of answers per question**","metadata":{"_cell_guid":"72d35361-c7e9-f368-0989-9da02ebaa7e9","_active":false,"_uuid":"f83fa0af87b86bd4c477a4b3aef619c366b92a15"},"cell_type":"markdown"},{"source":"ans_per_question = collections.Counter(answers_df['ParentId'])\nanswerid,noAnswers= zip(*ans_per_question.most_common())\n\nN=50\nplt.bar(range(N), noAnswers[:N], align='center', alpha=0.7)\n#plt.xticks(y_pos, objects)\n\nplt.ylabel('Number of Answers per Question')\nplt.xlabel('Question Id')\nplt.title('Distribution of Answers per question ')\nplt.text(10,1.5,\"Average answers per question: \"+str(math.floor((np.mean(noAnswers)))))\n\nplt.show()","metadata":{"_cell_guid":"e4dd12dd-e038-38e6-946c-5c0c0c6db5b8","_active":false,"_uuid":"be9ca5370b1c4f2a473132de7128b3ff2b1b8347"},"execution_count":null,"outputs":[],"cell_type":"code"},{"source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Nov  3 19:57:17 2017\n\n@author: RudradeepGuha\n\"\"\"\n\nfrom sklearn.naive_bayes import GaussianNB\nimport numpy as np\nimport pandas as pd\n\ndata = questions_df\n\nX = np.zeros((12643, 2), dtype=int)\nY = np.zeros((12643, 1), dtype=int)\nt = data.Title\ncounter = 0\n\n# For all titles, we count the number of characters and add that to X and depending on the length\n# classify them as 0(less likely to be upvoted) or 1(more likely to be upvoted) \nfor i in t:\n    f1 = len(i) - i.count(\" \")\n    f2 = data.loc[data['Title'] == i, 'OwnerUserId'].iloc[0]\n    X[counter] = np.array([f1, f2])\n    score = data.loc[data['Title'] == i, 'Score'].iloc[0]\n    if score < 20:\n        Y[counter] = 0\n    else:\n        Y[counter] = 1\n\nprint(X)\nprint(Y)\n\nmodel = GaussianNB()\n\nmodel.fit(X, Y)\n\nprint(model.predict_proba(np.array([[180, 345768]])))","metadata":{"_cell_guid":"39365a7b-46a8-4ca3-9a14-c628da376738","_uuid":"138270c6206af50b9516d3693afbd6100a8d70cf"},"execution_count":null,"outputs":[],"cell_type":"code"}],"nbformat":4,"nbformat_minor":1}