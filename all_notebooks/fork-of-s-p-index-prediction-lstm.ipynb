{"nbformat":4,"cells":[{"execution_count":null,"cell_type":"code","outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport math, time\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"097f5265553924519b9f3c7b9ab5f0365c6d3f8d","_cell_guid":"c44f7cd5-e2f9-4fd7-b733-47a31b9e6be0"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"#The point of this is to fit a RNN to the dataset to generate the next close price of the S&P Index\ndf = pd.read_csv(\"../input/SPIndex.csv\",index_col=0)\ndf[\"adj close\"] = df.adjclose # Moving close to the last column\ndf.drop(['close','adjclose'], 1, inplace=True) # Moving close to the last column\ndf.head()","metadata":{"_uuid":"d8fbd3fc3c76a34f26e83d2c93a61418171d0648","_cell_guid":"af3d0eea-8b8e-4fc9-8adc-b27f5bac33eb"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def normalize_data(df):\n    \"\"\" Normalize the data in the input dataframe\"\"\"\n    min_max_scaler = preprocessing.MinMaxScaler()\n    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n    return df","metadata":{"_uuid":"5cd061ffa42397626ba664fcf09abf1d20110893","_cell_guid":"f333423e-c4b3-4f60-9dc7-f1b9565ef685"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Normalize the data so that all the features are on the same scale\ndf = normalize_data(df)","metadata":{"_uuid":"d4d1f50956519c6cf055411cc552720a5ea4f754","_cell_guid":"662a86f4-b70a-4bb1-898b-ccd3633a4c66"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def load_data(stock, seq_len):\n    \"\"\" Generate Sequential data from the dataset with the given sequence length\"\"\"\n    amount_of_features = len(stock.columns) # 5\n    data = stock.as_matrix() \n    sequence_length = seq_len + 1 # index starting from 0\n    result = []\n    \n    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n        result.append(data[index: index + sequence_length]) # index : index + 22days\n    \n    result = np.array(result)\n    row = round(0.9 * result.shape[0]) # 90% split\n    train = result[:int(row), :] # 90% data, all features\n    x_train = train[:, :-1] \n    y_train = train[:, -1][:,-1]\n    x_test = result[int(row):, :-1] \n    y_test = result[int(row):, -1][:,-1]\n\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n    return [x_train, y_train, x_test, y_test]","metadata":{"_uuid":"37c3bada15526c2bb6471b7a4f74b382ca1c6509","_cell_guid":"fdadd964-87c3-4509-ad49-efbef3863472","collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"window = 22\nX_train, y_train, X_test, y_test = load_data(df, window)\nprint (X_train[0], y_train[0])","metadata":{"_uuid":"6c5e34c7abda1e901a749d5a3ad0b26316b9b648","_cell_guid":"285678d7-bad6-41ba-9f44-b2ee15953dd9"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def build_model(layers):\n    \"\"\" Build the LSTM RNN model \"\"\"\n    d = 0.2\n    model = Sequential()\n    model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=True))\n    model.add(Dropout(d))\n    model.add(LSTM(64, input_shape=(layers[1], layers[0]), return_sequences=False))\n    model.add(Dropout(d))\n    model.add(Dense(16,kernel_initializer='uniform',activation='relu'))        \n    model.add(Dense(1,kernel_initializer='uniform',activation='linear'))\n    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n        \n    start = time.time()\n    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n    print(\"Compilation Time : \", time.time() - start)\n    return model","metadata":{"_uuid":"48d70571343e7f8bbdeaabc297cbee1a8160e626","_cell_guid":"87fc5ef8-17c8-41c9-b538-baf6ecd2a3f8","collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"model = build_model([5,window,1])\n#Fit model with history to check for overfitting\nhistory = model.fit(X_train,y_train,epochs=90,validation_data=(X_test,y_test),shuffle=False)\n","metadata":{"_uuid":"7d1420dd367b89623cc6e67ec36c3765cf76f186","_cell_guid":"2d25c23f-9755-4135-9ea0-d81838967c17"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def denormalize(df, normalized_value): \n    df = df['adj close'].values.reshape(-1,1)\n    normalized_value = normalized_value.reshape(-1,1)\n    \n    #return df.shape, p.shape\n    min_max_scaler = preprocessing.MinMaxScaler()\n    a = min_max_scaler.fit_transform(df)\n    new = min_max_scaler.inverse_transform(normalized_value)\n    return new\n\n","metadata":{"_uuid":"19a4574e6bea042beee51d225c84e6bdfdad51d5","_cell_guid":"ab6a9f4a-7007-4a79-9805-32c8c7aab3c3","collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def model_score(model, X_train, y_train, X_test, y_test):\n    trainScore = model.evaluate(X_train, y_train, verbose=0)\n    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n\n    testScore = model.evaluate(X_test, y_test, verbose=0)\n    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n    return trainScore[0], testScore[0]","metadata":{"_uuid":"fdc8f93eac1891651dbe69a52b59c6c0f7b1551e","_cell_guid":"846d1d44-1f2f-4ff0-b373-35d74b18968b","collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"diff=[]\nratio=[]\np = model.predict(X_test)\nprint (p.shape)\n# for each data index in test data\nfor u in range(len(y_test)):\n    # pr = prediction day u\n    pr = p[u][0]\n    # (y_test day u / pr) - 1\n    ratio.append((y_test[u]/pr)-1)\n    diff.append(abs(y_test[u]- pr))\n\nnewp = denormalize(df, p)\nnewy_test = denormalize(df, y_test)\n\nmodel_score(model, X_train, y_train, X_test, y_test)\n\nplt.plot(newp,color='red', label='Prediction')\nplt.plot(newy_test,color='blue', label='Actual')\nplt.legend(loc='best')\nplt.show()","metadata":{"_uuid":"0275d0762cd0328228ecd38b15150f40274f6fda","_cell_guid":"e8339310-bdd1-4af0-9d6b-11d82b5aa886"}}],"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"}}}