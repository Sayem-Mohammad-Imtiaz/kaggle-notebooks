{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset) - look_back - 1):\n        a = dataset[i: (i + look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fixing random seed for reproducibility\nnp.random.seed(42)\n\n# load the dataset\nfilepath = '/kaggle/input/air-passengers/AirPassengers.csv'\n\ndf = pd.read_csv(filepath)\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'#Passengers':'passengers'}, inplace=True)\ndata = df['passengers']\ndata = np.array(data).reshape(-1,1)\n# Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n\n# data = df.astype('float32')\n\n# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndata = scaler.fit_transform(data)\n\n# split into train and tst sets\ntrain_size = int(len(data) * 0.67)\ntest_size = len(data) - train_size\ntrain, test = data[0:train_size, :], data[train_size: len(data), :]\n# print(len(train), len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape into X=t and y=t+1\nlook_back = 1\ntrain_X, train_y = create_dataset(train, look_back)\ntest_X, test_y = create_dataset(test, look_back)\n\n# reshape inputs to be [samples, time-steps, features]\ntrain_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\ntest_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n\n# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(train_X, train_y, epochs=100, batch_size=1, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\ntrain_preds = model.predict(train_X)\ntest_preds = model.predict(test_X)\n\n# invert predictions\ntrain_preds = scaler.inverse_transform(train_preds)\ntrain_y = scaler.inverse_transform([train_y])\ntest_preds = scaler.inverse_transform(test_preds)\ntest_y = scaler.inverse_transform([test_y])\n\n# calculate root mean squared error\ntrain_score = math.sqrt(mean_squared_error(train_y[0], train_preds[:, 0]))\nprint('Train Score: %.2f RMSE' % (train_score))\ntest_score = math.sqrt(mean_squared_error(test_y[0], test_preds[:, 0]))\nprint('Test Score: %.2f RMSE' % (test_score))\n\n# Train Score: 22.90 RMSE\n# Test Score: 50.20 RMSE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(data)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_preds) + look_back, :] = train_preds\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(data)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_preds) + (look_back * 2) + 1:len(data) - 1, :] = test_preds\n\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(data))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}