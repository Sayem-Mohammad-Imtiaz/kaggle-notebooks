{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.pipeline import Pipeline\nimport seaborn as sns\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, learning_curve\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom skmultilearn.problem_transform import ClassifierChain, LabelPowerset\nfrom sklearn.metrics import f1_score\n\nfrom matplotlib.pyplot import figure, show\nplt.style.use('ggplot')\nfrom seaborn import countplot, kdeplot\n\npd.set_option('display.max_rows', 150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# got this code from here https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\ndef plot_learning_curve(estimator, \n                        title, \n                        X, \n                        y,\n                        ylim=None, \n                        cv=None,\n                        n_jobs=None, \n                        train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(estimator,\n                                                            X,\n                                                            y,\n                                                            cv=cv,\n                                                            scoring=\"f1_macro\",\n                                                            n_jobs=n_jobs,\n                                                            train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mpst-movie-plot-synopses-with-tags/mpst_full_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análise Exploratória"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"tags\"].str.split(\",\").head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\ntags = mlb.fit_transform(df[\"tags\"].str.split(\", \"))\ncategories = mlb.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, pd.DataFrame(tags, columns=mlb.classes_)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Número de sinopses por categoria"},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = []\ncategories = mlb.classes_\nfor i in categories:\n    counts.append((i, df[i].sum()))\ndf_stats = pd.DataFrame(counts, columns=['category', 'number_of_synopsis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stats.sort_values('number_of_synopsis', ascending=False).plot(x='category', y='number_of_synopsis', kind='bar', legend=False, grid=True, figsize=(24, 6))\nplt.title(\"Total de sinopses por categoria\")\nplt.ylabel('Quantidade', fontsize=12)\nplt.xlabel('categoria', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quantidade de tags por sinopse"},{"metadata":{"trusted":true},"cell_type":"code","source":"rowsums = df.iloc[:,6:].sum(axis=1)\nx = rowsums.value_counts()\n\nplt.figure(figsize=(12,6))\nax = sns.barplot(x.index, x.values)\nplt.title(\"Tags por sinopse\")\nplt.ylabel('Quantidade', fontsize=12)\nplt.xlabel('Total de categorias', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribuição do tamanho do texto"},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(figsize=(12,6))\nkdeplot(df[\"plot_synopsis\"].str.len())\nshow()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As sinopses apresentam textos extensos com muitas palavras."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Numero de dados faltantes nas sinopses:')\nsum(df['plot_synopsis'].isna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Não existe dados faltantes nas sinopses."},{"metadata":{},"cell_type":"markdown","source":"\n# Feature Selection\n\nO intuito desta etapa é remover as categorias que não tem número suficiente para se criar modelo preditivo. O corte aconteceu em tags com menos de 400 ocorrências "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df.columns))\ncategories = df_stats.loc[df_stats[\"number_of_synopsis\"] > 400, \"category\"].tolist()\ndf.drop(df_stats.loc[df_stats[\"number_of_synopsis\"] < 400, \"category\"].tolist(), axis=1, inplace=True)\nlen(df.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df.sum(axis=1) != 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelagem\n\nPara lidar com o problema multi-label foi escolhido o ClassifierChain e para classificação textual foi utilizado o SVM com kernel linear. Já a vetorização foi realizada com a técnica BOW(Bag-of-Words) com TF-IDF."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[(df[\"split\"] == \"train\") | (df[\"split\"] == \"val\")]\ntest = df[df[\"split\"] == \"test\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.plot_synopsis\nX_test = test.plot_synopsis\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe= Pipeline(steps=[(\"preprocessing\", TfidfVectorizer(stop_words=stop_words, min_df=10, max_features=15000, max_df=.8)),\n                      (\"classifier\", ClassifierChain())])\n\n\nsearch_space = [{\"classifier__classifier\": [(LinearSVC(max_iter=3000))],\n                 \"classifier__classifier__C\": [0.1, 1, 10, 100]}]\n\ngridsearch = GridSearchCV(pipe, \n                          search_space, \n                          cv=5, \n                          n_jobs=-1, \n                          scoring = 'f1_macro') \n\ngridsearch.fit(X_train, train[categories])\n\nmodel = gridsearch.best_estimator_\n\n\n\nprint(gridsearch.best_estimator_)\nprint(gridsearch.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resultados"},{"metadata":{"trusted":true},"cell_type":"code","source":"title = \"Learning Curves SVM\"\n\nlc_svm = plot_learning_curve(model, title, X_train, train[categories], ylim=(0.0,1.0), cv=5, n_jobs=-1)\nlc_svm.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(test[categories], predictions, average=\"macro\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Teste Final"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_synopsis(series_synopsis, model, categories):\n    tags = pd.DataFrame(gridsearch.predict(series_synopsis).todense(), columns=categories) \n    return tags.loc[:,(tags == 1.0).values.tolist()[0]].columns.tolist()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = predict_synopsis(pd.Series(test.iloc[96][\"plot_synopsis\"]), model, categories)\n\ntags","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}