{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Prediction using Decision Tree Algorithm\n### By Rutwik V Jangam\n### GRIPDEC20\nDataset : https://bit.ly/3kXTdox"},{"metadata":{},"cell_type":"markdown","source":"### Importing and Understanding Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/iris-data/Iris.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We drop the ID Variable since it is unique in nature and would not give us any insights."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our final dependent variable i.e. Species is categorical we can encode it to 1,2 and 3 for simplicity.\n- 1 for Iris-setosa\n- 2 for Iris-versicolor\n- 3 for Iris-virginica\n- For this we use the label encoder."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\ndf_categorical = df.select_dtypes(include=['object'])\nle = preprocessing.LabelEncoder()\ndf_categorical = df_categorical.apply(le.fit_transform)\ndf_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Merge the encoded variable back into the original data frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(df_categorical.columns, axis=1)\ndf = pd.concat([df, df_categorical], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Species.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We now proceed to build a decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy=df.copy()\n# Putting feature variable to X\nX = df.drop('Species',axis=1)\n\n# Putting response variable to y\ny = df['Species']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n# Fitting the decision tree with default hyperparameters\ndt_1 = DecisionTreeClassifier()\ndt_1.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualizing the Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install dtreeviz","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from dtreeviz.trees import dtreeviz\n\nviz = dtreeviz(dt_1, X, y,\n                target_name=\"Species\",\n                feature_names=X.columns,\n                class_names=list(le.classes_))\n\nviz ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can now feed any new/test data to this classifer and it would be able to predict the right class accordingly.\n- We can check by building a new model and dividing the data set into test and train datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Putting feature variable to X\nX = df_copy.drop('Species',axis=1)\n\n# Putting response variable to y\ny = df_copy['Species']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing train-test-split \nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state = 99)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_2 = DecisionTreeClassifier()\ndt_2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing classification report and confusion matrix from sklearn metrics\nfrom sklearn.metrics import accuracy_score\n\n# Making predictions\ny_pred = dt_2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Accuracy and Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see that we have a very good accuracy score."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# classification metrics\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see that we have a very good precision score as well."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}