{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Load and preprocess the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/bbc-text.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the preprocessing steps in a function\n\nimport re\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nstop_words = ['in', 'of', 'at', 'a', 'the']\n\ndef pre_process(text):\n    \n    # lowercase\n    text=str(text).lower()\n    \n    # remove numbers followed by dot (like, \"1.\", \"2.\", etc)\n    text=re.sub('((\\d+)[\\.])', '', text)\n    \n    #remove tags\n    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n    \n    # correct some misspellings if there are any you can spot\n    text=text.replace('dont', \"don't\")\n    \n    # remove special characters except spaces, apostrophes and dots\n    text=re.sub(r\"[^a-zA-Z0-9.']+\", ' ', text)\n    \n    # remove stopwords\n    '''\n    Don't include this in the beginning. \n    First check if there are some patterns that may be lost if we remove stopwords.\n    '''\n    text=[word for word in text.split(' ') if word not in stop_words]\n    \n    # lemmatize\n    lmtzr = WordNetLemmatizer()\n    text = ' '.join((lmtzr.lemmatize(i)) for i in text)\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply the preprocessing function to each row of text in the dataset\nfor i in range(len(df)):\n    df.text[i] = pre_process(df.text[i])\n    \ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the distribution of categories\nimport matplotlib.pyplot as plt\nfig = plt.figure(figsize=(10,6))\ndf.groupby('category').text.count().plot.bar(ylim=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Representation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Divide the data into 75% training and 25% testing data\ntrain_data = df.text[0:int(0.75*len(df))]\ntest_data = df.text[int(0.75*len(df))+1:]\ntrain_target = df.category[0:int(0.75*len(df))]\ntest_target = df.category[int(0.75*len(df))+1:]\n\n# convert the text into numeric form, so that the ML algos can be applied to them\nstop_words = ['in', 'of', 'at', 'a', 'the']\nngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\nngram_vectorizer.fit(train_data)\nX_train = ngram_vectorizer.transform(train_data)\nX_test = ngram_vectorizer.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model, and check its accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nmodel = LogisticRegression() # play around with the parameters in Logisticregression() to find the optimal parameters\nmodel.fit(X_train, train_target)\n\n# make predictions on the test data with the model, and check its accuracy\ntest_acc = accuracy_score(test_target, model.predict(X_test))\nprint('Test accuracy: {0:.2f}%'.format(100*test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(df.category[int(0.75*len(df))+1:], model.predict(X_test))\nfig, ax = plt.subplots(figsize=(10,8))\nsns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=df.category.unique(), yticklabels=df.category.unique())\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(test_target, model.predict(X_test), target_names=df.category.unique()))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"}},"nbformat":4,"nbformat_minor":1}