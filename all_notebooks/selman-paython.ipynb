{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras . datasets import mnist\nfrom keras . models import Sequential\nfrom keras . layers import Dense , Dropout\nfrom keras import regularizers\nfrom keras . utils import to_categorical\nimport matplotlib . pyplot as plt\n\n( X_training , y_training ) , ( X_test , y_test ) = mnist . load_data ()\n# Reshape and normalize the images\nX_training = X_training . reshape ((60000 , 28 * 28) )\nX_training = X_training . astype ('float32') / 255\nX_test = X_test . reshape ((10000 , 28 * 28) )\nX_test = X_test . astype ('float32') / 255\n# categoricaling all labels\ny_train = to_categorical ( y_training )\ny_test = to_categorical ( y_test )\n# define validation images and labels number :20000\nx_train = X_training [:40000]\nx_validation = X_training [40000:]\nx_labels = y_training [:40000]\ny_validation = y_training [40000:]\nmodel1 = Sequential ()\nmodel1 . add ( Dense (512 , activation ='relu', input_shape =(28 * 28 ,) ) )\nmodel1 . add ( Dense (64 , activation = 'relu') )\nmodel1 . add ( Dense (10 , activation ='softmax'))\nmodel1.compile ( optimizer ='adam', loss ='categorical_crossentropy', metrics =['accuracy'])\nhistory1 = model1.fit( x_train , y_train , validation_data =( x_validation ,y_validation ) , epochs =10 , batch_size =128)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thisdict = {'x': 10, 'y': 15, 'z': 20}\nprint(\"An item: %d\" % thisdict['x'])\nthisdict ['x']=4\n\nprint( thisdict['x'])\nprint(thisdict.keys())\nprint( thisdict.values())\nfor i in thisdict.keys():\n    print (thisdict[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print “Hello, World!” \nprint(\"Hello, !\")\n\nA = 22\nb = 3\nprint(A)\nA = 90.09 +b\nprint(A)\n\n\nA = 'Hello, World!'\nprint(A[0])\nprint(len(A))\nprint(A)\nx, y , z = 'her'\nprint(x)\nprint(y)\nprint (z)\n\nx,y,z=20,30,40\nprint(x,y,z)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nmyData = np.array([3, 5, 7])\n\nplt.plot(myData)\nplt.xlabel('data specification for x axis')\nplt.ylabel('data specification for y axis')\nplt.show()\n\nprint(\"----------2-------------\")\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nmyData1 = np.array([2, 4, 6])\nmyData2 = np.array([1, 3, 5])\nplt.scatter(myData1, myData2)\nplt.xlabel('data specification for x axis')\nplt.ylabel('data specification for y axis')\nplt.show()\n\nprint(\"----------3 Pandas-------------\")\n\nimport numpy as np\nimport pandas as pd\nmyData = np.array([[0, 2, 4], [1, 3, 5]])\nrow_names = ['row 1', 'row 2']\ncol_names = ['first', 'second', 'third']\ndataframe = pd.DataFrame(myData, index=row_names, columns=col_names)\nprint(dataframe)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nmyData = open(myFilename, 'rb')\ndata = np.loadtxt(myData, delimiter=\",\")\nprint(data.shape)\n\nprint(\"------------------------\")\n\nimport numpy as np\nfrom urllib import urlopen\nurl = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nmyData = urlopen(url)\ndata = np.loadtxt(myData, delimiter=\",\")\nprint(data.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"---------5 ds panda------\")\n\nimport pandas as pd\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\nprint(myData.shape)\n\nprint(\"---------6 ds panda------\")\nimport pandas as pd\nurl = 'https://www.kaggle.com/pavansanagapati/pima-diabetes'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(url, names=names)\nprint(myData.shape)\n\nprint(\"---------7 ds panda------\")\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\npeek = myData.head(10)\nprint(peek)\n\nprint(\"---------8--------\")\n\nimport pandas as pd\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ntypes = myData.dtypes\nprint(types)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"---------9------------\")\nimport pandas as pd\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\noutcome_counts = myData.groupby('outcome').size()\nprint(outcome_counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom pandas import set_option\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\nset_option('display.width', 100)\nset_option('precision', 3)\ncorrelations = myData.corr(method='pearson')\nprint(correlations)\n\nprint(\"-----------------------\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\nmyData.plot.hist()\n# data.hist()\n# plt.show()\n\nprint(\"--------10---------\")\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\nmyData.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"--------11---------\")\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ncorrelations = myData.corr()\n# plot correlation matrix\nmyfig = plt.figure()\naxis = myfig.add_subplot(111)      # There is only one subplot or graph; \n# \"111\" means \"1x1 grid, first subplot\"\ncax = axis.matshow(correlations, vmin=-1, vmax=1)\nmyfig.colorbar(cax)\nticks = np.arange(0,9,1)   # np.arange(start, stop,  step); the interval does not include stop value\naxis.set_xticks(ticks)\naxis.set_yticks(ticks)\naxis.set_xticklabels(names)\naxis.set_yticklabels(names)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom numpy import set_printoptions\nfrom sklearn.preprocessing import MinMaxScaler\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ndata = myData.values\n# separate array into input and output components\nX = data[:,0:8]\nY = data[:,8]\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX = scaler.fit_transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(rescaledX[0:5,:])\n\nprint(\"--------------------13-----------\")\n\nfrom sklearn.preprocessing import Normalizer\nimport pandas as pd\nfrom numpy import set_printoptions\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ndata = myData.values\n# separate array into input and output components\nX = data[:,0:8]\nY = data[:,8]\nscaler = Normalizer().fit(X)\nnormalizedX = scaler.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(normalizedX[0:5,:])\n\nprint(\"--------------------14\")\nfrom sklearn.preprocessing import Binarizer\nimport pandas as pd\nfrom numpy import set_printoptions\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ndata = myData.values\n# separate array into input and output components\nX = data[:,0:8]\nY = data[:,8]\nbinarizer = Binarizer(threshold=0.0).fit(X)\nbinaryX = binarizer.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(binaryX[0:5,:])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\n# load data\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ndata = myData.values\nX = data[:,0:8]\nY = data[:,8]\n# feature extraction\nmodel = ExtraTreesClassifier()\nmodel.fit(X, Y)\nprint(model.feature_importances_)\n\n\nprint(\"------------\")\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ndata = myData.values\nX = data[:,0:8]\nY = data[:,8]\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import Normalizer\nimport pandas as pd\nfrom numpy import set_printoptions\n\nmyFilename = '../input/pima-diabetes/pimaindians-diabetes.data.csv'\nnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\nmyData = pd.read_csv(myFilename, names=names)\ndata = myData.values\n# separate array into input and output components\nX = data[:,0:8]\nY = data[:,8]\nscaler = Normalizer().fit(X)\nnormalizedX = scaler.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(normalizedX[0:5,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras . datasets import mnist\nfrom keras . models import Sequential\nfrom keras . layers import Dense , Dropout\nfrom keras import regularizers\nfrom keras . utils import to_categorical\nimport matplotlib . pyplot as plt\n( X_training , y_training ) , ( X_test , y_test ) = mnist . load_data ()\n# Reshape and normalize the images\nX_training = X_training . reshape ((60000 , 28 * 28) )\nX_training = X_training . astype ('float32') / 255\nX_test = X_test . reshape ((10000 , 28 * 28) )\nX_test = X_test . astype ('float32') / 255\n# categoricaling all labels\ny_train = to_categorical ( y_training )\ny_test = to_categorical ( y_test )\n# define validation images and labels number :20000\nx_train = X_training [:40000]\nx_validation = X_training [40000:]\nx_labels = y_training [:40000]\ny_validation = y_training [40000:]\nmodel1 = Sequential ()\nmodel1 . add ( Dense (512 , activation ='relu', input_shape =(28 * 28 ,) ) )\nmodel1 . add ( Dense (64 , activation = 'relu') )\nmodel1 . add ( Dense (10 , activation ='softmax'))\nmodel1.compile ( optimizer ='adam', loss ='categorical_crossentropy', metrics =['accuracy'])\nhistory1 = model1.fit( x_train , y_train , validation_data =( x_validation ,y_validation ) , epochs =10 , batch_size =128)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = np. array (X[:, -1])\nprint (y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = preprocessing.MinMaxScaler()\nx = scaler . fit_transform ( x )\n\nX_train , X_test , y_train , y_test = train_test_split (x, y, test_size =0.2)\n\ny_train = to_categorical ( y_train )\ny_test = to_categorical ( y_test )\n\nmodel = Sequential ()\nmodel . add ( Dense (20 , activation ='relu', input_shape =(9 ,)))\nmodel . add ( Dense (27 , activation ='relu'))\nmodel . add ( Dense (54 , activation ='relu'))\nmodel . add ( Dense (20 , activation ='relu'))\nmodel . add ( Dense (2, activation ='sigmoid'))\nmodel . compile ( optimizer ='Adam', loss ='mean_squared_logarithmic_error',\nmetrics =['accuracy'])\nmodel.fit( X_train , y_train , batch_size =10 , epochs =5, verbose =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential ()\nmodel . add ( Dense ( 20 , activation ='relu', input_shape =(9,) ) )\nmodel . add ( Dense ( 27 , activation ='relu', kernel_regularizer = regularizers. l2 ( 0.001 ) ) )\nmodel . add ( Dropout ( 0.5 ) )\nmodel . add ( Dense ( 54 , activation ='relu', kernel_regularizer = regularizers. l2 ( 0.001 ) ) )\nmodel . add ( Dropout ( 0.5 ) )\nmodel . add ( Dense ( 20 , activation ='relu', kernel_regularizer = regularizers. l2 ( 0.001 ) ) )\nmodel . add ( Dense (2 , activation ='sigmoid') )\nmodel . compile ( optimizer ='Adam', loss =' mean_squared_logarithmic_error',\nmetrics =['accuracy'])\nmodel . fit ( X_train , y_train , batch_size =10 , epochs =5 , verbose =1 )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp. random . seed (0)\nfrom tensorflow . random import set_seed\nset_seed (0)\nimport pandas as pd\nfrom sklearn . preprocessing import StandardScaler\nfrom sklearn . decomposition import PCA\n\nfrom keras import layers\nfrom sklearn . metrics import accuracy_score , confusion_matrix\nimport matplotlib . pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits . mplot3d import Axes3D\nactual_df = pd.read_csv ('../input/gene-expression/actual.csv')\nactual_df.head ()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig  ax = plt . subplots ( ncols =2 , figsize =( 15 , 5 ) )\nsns . distplot ( np . concatenate ( X_train . values ) , ax=ax[0]) . set_title ('Original Data')\nsns . distplot ( np . concatenate ( X_train_scaled ) , ax=ax[1]) . set_title ('Scaled Data')\nplt . tight_layout\nplt . show ()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA ( n_components = 0.95 )\nX_train_pca = pca . fit_transform ( X_train_scaled )\nX_test_pca = pca . transform ( X_test_scaled )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca3 = PCA ( n_components = 3 ) . fit_transform ( X_train )\ncolors = np . where ( y_train ==0 , 'red', 'blue')\nplt . clf ()\nFigure = plt . figure (1 , figsize =( 10 , 6 ) )\naxes = Axes3D ( fig , elev =-150 , azim =110 ,)\naxes . scatter ( pca3 [:, 0], pca3 [:, 1], pca3 [:, 2], c= colors , cmap = plt . cm\n. Paired , linewidths =10 )\naxes . set_title (\" First three PCA directions \")\naxes . set_xlabel (\"PC1\")\naxes . w_xaxis . set_ticklabels ([])\naxes . set_ylabel (\"PC2\")\naxes . w_yaxis . set_ticklabels ([])\naxes . set_zlabel (\"PC3\")\naxes . w_zaxis . set_ticklabels ([])\nplt . show ()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NN_model = Sequential ([\nDense ( 32 , activation ='relu ', input_shape = X_train_pca [1]. shape ) ,\nDense ( 16 , activation ='relu ') ,\nDense (1 , activation ='sigmoid ') ,\n])\nNN_model . compile (\nloss =' binary_crossentropy ',\noptimizer ='adam ',\nmetrics =[' binary_accuracy ']\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras . callbacks . EarlyStopping (\npatience =5 ,\nmin_delta =0 . 005 ,\nrestore_best_weights =True ,\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_history = NN_model . fit (X_train_pca , y_train ,validation_data =( X_test_pca , y_test ) ,batch_size = 8 ,epochs = 200 ,callbacks =[ early_stopping ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = NN_model . predict_classes ( X_test_pca )\nprint ('Neural Network accuracy : ', round ( accuracy_score ( y_test , pred ) ,3 ) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_nn = confusion_matrix ( y_test , pred )\nax = plt . subplot ()\nsns . heatmap ( cm_nn , annot =True , ax = ax , fmt ='g', cmap ='Greens ')\n# Labels , title and ticks\nax . set_xlabel ('Predicted labels ')\nax . set_ylabel ('True labels ')\nax . set_title ('Neural Network Confusion Matrix ')\nax . xaxis . set_ticklabels ( labels )\nax . yaxis . set_ticklabels ( labels , rotation = 360 ) ;","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}