{"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.1","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"cells":[{"source":"Predicting the Cellular Localization Sites of Proteins\nAnalysing and visualizing dataset and its features,feature selection, various Machine Learning Classification models/estimators including ensembles. And Deep Learning Multilayer Perceptron architecture(Artificial Neural Network) model. All trained/fitted with Cross Validation. ","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"5147f336-86d0-4d28-b9b1-ba824e21c234","_uuid":"759e625530e24a65be9639d8e9ba4c6b8a92bd56"},"source":"import numpy\nimport pandas\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n\nimport matplotlib.pyplot as plt\nfrom pandas.tools.plotting import scatter_matrix\n\n\nfrom sklearn import cross_validation\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.utils import np_utils\n#from sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.constraints import maxnorm\n\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"source":"# load dataset\ndataframe = pandas.read_csv(\"../input/ecoli.csv\", delim_whitespace=True)\n\n# Assign names to Columns\ndataframe.columns = ['seq_name', 'mcg', 'gvh', 'lip', 'chg', 'aac', 'alm1', 'alm2', 'site']\n\ndataframe = dataframe.drop('seq_name', axis=1)\n\n# Encode Data\ndataframe.site.replace(('cp', 'im', 'pp', 'imU', 'om', 'omL', 'imL', 'imS'),(1,2,3,4,5,6,7,8), inplace=True)\n"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"print(\"Head:\", dataframe.head())"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"print(\"Statistical Description:\", dataframe.describe())"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"print(\"Shape:\", dataframe.shape)\n\nprint(\"Data Types:\", dataframe.dtypes)"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"print(\"Correlation:\", dataframe.corr(method='pearson'))"},{"source":"'mcg'(McGeoch's method for signal sequence recognition) has the highest correlation with the 'site'(Protein localization site) (which is a positive correlation), followed by 'gvh'(von Heijne's method for signal sequence recognition)\n which is also a positive correlation, 'alm2'(score of ALOM program after excluding putative cleavable signal regions from the sequence) has the least correlation ","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"source":"dataset = dataframe.values\n\n\nX = dataset[:,0:7]\nY = dataset[:,7] "},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"#Feature Selection\nmodel = LogisticRegression()\nrfe = RFE(model, 3)\nfit = rfe.fit(X, Y)\n\nprint(\"Number of Features: \", fit.n_features_)\nprint(\"Selected Features: \", fit.support_)\nprint(\"Feature Ranking: \", fit.ranking_) \n\n"},{"source":" 'mcg', 'gvh' and 'alm1'(score of the ALOM membrane spanning region prediction program) were top 3 selected features/feature combination for predicting 'Income'\n using Recursive Feature Elimination, the 1st and 2n are atually the two attributes with the highest correlation with the \n 'site' classes","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"plt.hist((dataframe.site))\n"},{"source":"\n# Most of the dataset's samples fall within the 'cp'(cytoplasm), 'im'(inner membrane without signal sequence) and 'pp'(perisplasm) output classes in that order","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"dataframe.plot(kind='density', subplots=True, layout=(3,4), sharex=False, sharey=False)"},{"source":"Majority of the attibutes have positive skews except 'mcg' and 'aac' in that order","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"dataframe.plot(kind='box', subplots=True, layout=(3,4), sharex=False, sharey=False)"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"fig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(dataframe.corr(), vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = numpy.arange(0,7,1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(dataframe.columns)\nax.set_yticklabels(dataframe.columns)\n"},{"source":"'mcg' has the highest positive corelation as expected","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"\nnum_instances = len(X)\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\nmodels.append(('L_SVM', LinearSVC()))\nmodels.append(('ETC', ExtraTreesClassifier()))\nmodels.append(('RFC', RandomForestClassifier()))\n\n# Evaluations\nresults = []\nnames = []\n\nfor name, model in models:\n    # Fit the model\n    model.fit(X, Y)\n    \n    predictions = model.predict(X)\n    \n    # Evaluate the model\n    kfold = cross_validation.KFold(n=num_instances, n_folds=10, random_state=seed)\n    cv_results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"   \n#boxplot algorithm Comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()"},{"source":"'Naive Bayes' and 'Linear Discriminant Analysis' are the best estimators/models for this dataset, they can be further explored and their hyperparameters tuned","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"# Define 10-fold Cross Valdation Test Harness\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\ncvscores = []\nfor train, test in kfold.split(X, Y):\n\n    # create model\n    model = Sequential()\n    model.add(Dense(20, input_dim=7, init='uniform', activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(10, init='uniform', activation='relu', kernel_constraint=maxnorm(3)))\n    model.add(Dropout(0.2))\n    model.add(Dense(5, init='uniform', activation='relu'))\n    model.add(Dense(1, init='uniform', activation='relu'))\n\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n\n    # Fit the model\n    model.fit(X[train], Y[train], epochs=200, batch_size=10, verbose=0)\n\n    # Evaluate the model\n    scores = model.evaluate(X[test], Y[test], verbose=0)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\ncvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n\n"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"source":""},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"source":""},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"source":""},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"source":""},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"source":""}]}