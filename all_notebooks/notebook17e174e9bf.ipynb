{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Загрузим библиотеки","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom scipy.stats import norm\nfrom scipy import stats\n\nfrom datetime import datetime\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matplotlib.rcParams.update({'font.size': 14})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Подгружаем данные","metadata":{}},{"cell_type":"code","source":"TRAIN_DATASET_PATH = '../input/inputhttpswwwkagglecomevgeniyyudakov/train.csv'\nTEST_DATASET_PATH = '../input/inputhttpswwwkagglecomevgeniyyudakov/test.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\n\ntrain_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(TEST_DATASET_PATH)\n\ntest_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Уменьшаем размер данных для лучшей работы модели","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(train_df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = train_df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in train_df.columns:\n        col_type = train_df[col].dtype\n        \n        if col_type != object:\n            c_min = train_df[col].min()\n            c_max = train_df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    train_df[col] = train_df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    train_df[col] = train_df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    train_df[col] = train_df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    train_df[col] = train_df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    train_df[col] = train_df[col].astype(np.float32)\n                else:\n                    train_df[col] = train_df[col].astype(np.float64)\n        else:\n            train_df[col] = train_df[col].astype('category')\n\n    end_mem = train_df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(test_df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = test_df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in test_df.columns:\n        col_type = test_df[col].dtype\n        \n        if col_type != object:\n            c_min = test_df[col].min()\n            c_max = test_df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    test_df[col] = test_df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    test_df[col] = test_df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    test_df[col] = test_df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    test_df[col] = test_df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    test_df[col] = test_df[col].astype(np.float32)\n                else:\n                    test_df[col] = test_df[col].astype(np.float64)\n        else:\n            test_df[col] = test_df[col].astype('category')\n\n    end_mem = test_df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Проверим тип данных","metadata":{}},{"cell_type":"code","source":"train_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Мы видим признаки id и District id, мы их учитывать не будем, поэтому меняем тип данных на str","metadata":{}},{"cell_type":"code","source":"train_df['Id'] = train_df['Id'].astype(str)\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_fix_room(train_df):\n    info_by_district_id = train_df.groupby(['DistrictId', 'HouseYear'], as_index=False).agg(\n        {'Rooms': 'sum', 'Square': 'sum'}).rename(\n        columns={'Rooms': 'sum_roos_dr', 'Square': 'sum_square_dr'})\n\n    info_by_district_id['mean_square_per_room_in_dr'] = info_by_district_id['sum_square_dr'] \\\n        / info_by_district_id['sum_roos_dr']\n    info_by_district_id.drop(\n        ['sum_square_dr', 'sum_roos_dr'], axis=1, inplace=True)\n\n    train_df = pd.merge(train_df, info_by_district_id, on=[\n                  'DistrictId', 'HouseYear'], how='left')\n\n    train_df['mean_square_per_room_in_dr'] = train_df['mean_square_per_room_in_dr'].fillna(\n        train_df['mean_square_per_room_in_dr'].mean())\n\n    train_df.loc[train_df['Rooms'] > 6, 'Rooms'] \\\n        = (train_df.loc[train_df['Rooms'] > 6, 'Square']\n           // train_df.loc[train_df['Rooms'] > 6, 'mean_square_per_room_in_dr']).astype('int')\n\n    train_df.loc[df['Rooms'] == 0, 'Rooms'] \\\n        = (train_df.loc[train_df['Rooms'] == 0, 'Square']\n           // train_df.loc[train_df['Rooms'] == 0, 'mean_square_per_room_in_dr']).astype('int')\n\n    train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = 1\n    return train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Проверим выполнение","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Проведём анализ данных и приведём их к нормальному виду","metadata":{}},{"cell_type":"markdown","source":"### Начнём с Rooms","metadata":{}},{"cell_type":"code","source":"train_df['Rooms'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### В Rooms мы видим значения равные 0. Будем считать эти значение как признак обозначающий квартиру \"Студия\". Для правильной работы модели заменим 0 на 1\n#### Также мы видим, что в таблице имеются позиции со сверх количеством комнат(Например 19). Для правильной работы модели отредактируем это значение","metadata":{}},{"cell_type":"code","source":"train_df['Rooms_outlier'] = 0\ntrain_df.loc[(train_df['Rooms'] == 0) | (train_df['Rooms'] >= 6), 'Rooms_outlier'] = 1\ntrain_df.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = 1\ntrain_df.loc[train_df['Rooms'] >= 6, 'Rooms'] = train_df['Rooms'].median()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Rooms'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Теперь проверим Square. Для анализа будем использовать boxplot. Это способ покажет нам данные выходящие за рамки.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16,3))\nsns.boxplot(train_df['Square'], whis = 1.5)\nplt.xlabel('Square')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### На графике мы видим выбросы, если эти данные оставить как есть, то мы получим некорректный max and min. ","metadata":{}},{"cell_type":"code","source":"train_df.describe() ### Серийный 100 квартирный дом предусматривает 6 комнатные квартиры до 270 м2, а минимальная площадь примерно равна 16 м2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['Square'] > 270].nlargest(30, 'Square')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,3))\nsns.boxplot(train_df['Square'], whis = 1.5)\nplt.xlabel('Square')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['Square'] >= 271, 'Square'] = train_df.loc[train_df['Square'] > 271, 'Square'] / 3 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['Square'] <= 16, 'Square'] = (train_df.loc[train_df['Square'] <= 16, 'Square'] * 10) + 6 \n\n# Где 6 - это минимальная площадь кухни","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,3))\nsns.boxplot(train_df['Square'], whis = 1.5)\nplt.xlabel('Square')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe() ### Серийный 100 квартирный дом предусматривает 6 комнатные квартиры до 270 м2, а минимальная площадь примерно равна 16 м2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Посчитаем и заполним сразу KitchenSquare, так как мы ранее зафиксировали, что минимальная площадь кухни будет 6м2 и по стандартам сама KitchenSquare должна занимать 20% - 30% от всей Square. Остальное отдадим LifeSquare.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\n\ntrain_df['LifeSquare'].hist(bins=30)\nplt.ylabel('Count')\nplt.xlabel('LifeSquare')\n\nplt.title('LifeSquare')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# minLifeSquare\nOptimum = train_df['LifeSquare'].median()\ntrain_df['LifeSquare'].fillna(Optimum, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['LifeSquare'].isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['LifeSquare'] < 11, 'LifeSquare'] = 11","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# maxLifeSquare ограничим 150, так как это значение составляет 30% от maxSquare\n\ntrain_df.loc[train_df['LifeSquare'] >= 150, 'LifeSquare'] = train_df.loc[train_df['LifeSquare'] >= 150, 'LifeSquare'] / 70 \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,3))\nsns.boxplot(train_df['LifeSquare'], whis = 1.5)\nplt.xlabel('LifeSquare')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Проработав выбросы и заменив Nan  в LifeSquare получаем beatifull boxplot)","metadata":{}},{"cell_type":"code","source":"train_df['KitchenSquare'].quantile(.975), train_df['KitchenSquare'].quantile(.025)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"condition = (train_df['KitchenSquare'].isna()) \\\n             | (train_df['KitchenSquare'] > train_df['KitchenSquare'].quantile(.975))\n        \ntrain_df.loc[condition, 'KitchenSquare'] = train_df['KitchenSquare'].median()\n\ntrain_df.loc[train_df['KitchenSquare'] < 5, 'KitchenSquare'] = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Теперь проверим пропуски","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Выгрузим данные для проверки работы модели","metadata":{}},{"cell_type":"code","source":"train_df[['Rooms','Square', 'LifeSquare', 'KitchenSquare']].head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Чтобы не проверять все данные обезапасим себя","metadata":{}},{"cell_type":"code","source":"def prepare_lifesquare(train_df):\n    train_df.loc[train_df['Square'] < train_df['LifeSquare'],\n           'LifeSquare'] = train_df.loc[df['Square'] < train_df['LifeSquare'], 'Square']\n    return train_df\n\n\ndef fillna_life_square(train_df):\n    train_df['LifeSquare'] = train_df['LifeSquare'].fillna(train_df['LifeSquare'].mean())\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Т.е. если в нашей таблице в столбце Square будет больше чем в столбце LifeSquare, то произойдёт замена данных.","metadata":{}},{"cell_type":"markdown","source":"### HouseYear слишком большой и имеет некорректные данные. Приведём их к нормальному виду","metadata":{}},{"cell_type":"code","source":"train_df.loc[train_df['HouseYear'] > 2020]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['HouseYear'] == 20052011, 'HouseYear'] = int((2005 + 2011) / 2)\ntrain_df.loc[train_df['HouseYear'] == 4968, 'HouseYear'] = 1968","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Просмотрев данные видим зависимость признаков друг от друга. Попробуем её найти","metadata":{}},{"cell_type":"code","source":"train_df.loc[train_df['Healthcare_1'] == 1046]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,3))\nsns.boxplot(train_df['Healthcare_1'], whis = 1.5)\nplt.xlabel('Healthcare_1')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### По признаку Healthcare_1 мы видим, что все значения идут в порядке от 0 до 5","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16,3))\nsns.boxplot(train_df['Helthcare_2'], whis = 1.5)\nplt.xlabel('Helthcare_2')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"По признаку Healthcare_2 мы также видим, что все значения идут в порядке от 0 до 5","metadata":{}},{"cell_type":"markdown","source":"Тогда получается, что есть некие подуровни/зоны здравохранения от 0 до 5. Преобразуем Healthcare_1 и Healthcare_2","metadata":{}},{"cell_type":"code","source":"Healthcare = train_df['Healthcare_1'].median()\ntrain_df['Healthcare_1'].fillna(Healthcare, inplace = True)\ntrain_df['Healthcare_1'] = round((train_df['Healthcare_1'] // 100),0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Healthcare_1'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['Healthcare_1'] >= 6, 'Healthcare_1'] = round((train_df.loc[train_df['Healthcare_1'] >= 6, 'Healthcare_1'] // 10),0) \ntrain_df['Healthcare_1'] = train_df['Healthcare_1'].astype(np.int64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,3))\nsns.boxplot(train_df['Healthcare_1'], whis = 1.5)\nplt.xlabel('Healthcare_1')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['Helthcare_2'] >= 5, 'Helthcare_2'] = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Helthcare_2'] = train_df['Helthcare_2'].astype(np.int64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ecology_1 Доля площади земель лесного фонда от площади Social","metadata":{}},{"cell_type":"code","source":"train_df['Ecology_1'] = round(train_df['Ecology_1']*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['Ecology_1', 'Healthcare_1', 'Social_1','Rooms','Square', 'Price']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['HouseFloor'].sort_values().unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Floor'].sort_values().unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_df['Floor'] > train_df['HouseFloor']).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['HouseFloor_outlier'] = 0\ntrain_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['Floor'] > train_df['HouseFloor'], 'HouseFloor_outlier'] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor'] = train_df['HouseFloor'].median()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\nfloor_outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor']\\\n                                                .apply(lambda x: random.randint(1, x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_df['Floor'] > train_df['HouseFloor']).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataPreprocessing:\n    \"\"\"Подготовка исходных данных\"\"\"\n\n    def __init__(self):\n        \"\"\"Параметры класса\"\"\"\n        self.medians=None\n        self.kitchen_square_quantile = None\n        \n        \n    def fit(self, X):\n        \"\"\"Сохранение статистик\"\"\"       \n        # Расчет медиан\n        self.medians = X.median()\n        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.975)\n        \n        \n    \n    def transform(self, X):\n        \"\"\"Трансформация данных\"\"\"\n\n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']\n        \n        \n        # KitchenSquare\n        condition = (X['KitchenSquare'].isna()) \\\n                    | (X['KitchenSquare'] > self.kitchen_square_quantile)\n        \n        X.loc[condition, 'KitchenSquare'] = self.medians['KitchenSquare']\n\n        X.loc[X['KitchenSquare'] < 5, 'KitchenSquare'] = 5\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        \n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\\\n                                            .apply(lambda x: random.randint(1, x))\n        \n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        Healthcare = self.medians['Healthcare_1']\n        X['Healthcare_1'].fillna(Healthcare, inplace = True)\n        X['Healthcare_1'] = round((X['Healthcare_1'] // 100),0)\n        X.loc[train_df['Healthcare_1'] >= 6, 'Healthcare_1'] = round((X.loc[train_df['Healthcare_1'] >= 6, 'Healthcare_1'] // 10),0) \n        X['Healthcare_1'] = X['Healthcare_1'].astype(np.int64)\n            \n        # Ecology_1\n        X['Ecology_1'] = round(X['Ecology_1']*100)\n        \n        # Square\n        X.loc[train_df['Square'] >= 271, 'Square'] = X.loc[X['Square'] > 271, 'Square'] / 3\n        X.loc[train_df['Square'] <= 16, 'Square'] = (X.loc[X['Square'] <= 16, 'Square'] * 10) + 6 \n            \n        # LifeSquare\n        Optimum = self.medians['LifeSquare']\n        X['LifeSquare'].fillna(Optimum, inplace = True)\n        X.loc[X['LifeSquare'] < 11, 'LifeSquare'] = 11\n        X.loc[X['LifeSquare'] >= 150, 'LifeSquare'] = X.loc[X['LifeSquare'] >= 150, 'LifeSquare'] / 70\n        \n        \n        X.fillna(self.medians, inplace=True)\n        \n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Построение новых признаков ","metadata":{}},{"cell_type":"code","source":"binary_to_numbers = {'A': 0, 'B': 1}\n\ntrain_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)\ntrain_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)\ntrain_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"district_size = train_df['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n\ndistrict_size.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.merge(district_size, on='DistrictId', how='left')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['IsDistrictLarge'] = (train_df['DistrictSize'] > 100).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"med_price_by_district = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                            .rename(columns={'Price':'MedPriceByDistrict'})\n\nmed_price_by_district.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.merge(med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def floor_to_cat(X):\n\n    X['floor_cat'] = 0\n\n    X.loc[X['Floor'] <= 3, 'floor_cat'] = 1  \n    X.loc[(X['Floor'] > 3) & (X['Floor'] <= 5), 'floor_cat'] = 2\n    X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3\n    X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4\n    X.loc[X['Floor'] > 15, 'floor_cat'] = 5\n\n    return X\n\n\ndef floor_to_cat_pandas(X):\n    bins = [0, 3, 5, 9, 15, X['Floor'].max()]\n    X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n    \n    X['floor_cat'].fillna(-1, inplace=True)\n    return X\n\n\ndef year_to_cat(X):\n\n    X['year_cat'] = 0\n\n    X.loc[X['HouseYear'] <= 1941, 'year_cat'] = 1\n    X.loc[(X['HouseYear'] > 1941) & (X['HouseYear'] <= 1945), 'year_cat'] = 2\n    X.loc[(X['HouseYear'] > 1945) & (X['HouseYear'] <= 1980), 'year_cat'] = 3\n    X.loc[(X['HouseYear'] > 1980) & (X['HouseYear'] <= 2000), 'year_cat'] = 4\n    X.loc[(X['HouseYear'] > 2000) & (X['HouseYear'] <= 2010), 'year_cat'] = 5\n    X.loc[(X['HouseYear'] > 2010), 'year_cat'] = 6\n\n    return X\n\n\ndef year_to_cat_pandas(X):\n    bins = [0, 1941, 1945, 1980, 2000, 2010, X['HouseYear'].max()]\n    X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n    \n    X['year_cat'].fillna(-1, inplace=True)\n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins = [0, 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins, labels=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins = [0, 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = year_to_cat(train_df)\ntrain_df = floor_to_cat(train_df)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"med_price_by_floor_year = train_df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\nmed_price_by_floor_year.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.merge(med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeatureGenetator():\n    \"\"\"Генерация новых фич\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        self.med_price_by_floor_year = None\n        self.house_year_max = None\n        self.floor_max = None\n        self.district_size = None\n\n\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # DistrictID\n        self.district_size = X['DistrictId'].value_counts().reset_index() \\\n                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n                \n        # Target encoding\n        ## District, Rooms\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            \n            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                                            .rename(columns={'Price':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()\n            \n        ## floor, year\n        if y is not None:\n            self.floor_max = df['Floor'].max()\n            self.house_year_max = df['HouseYear'].max()\n            df['Price'] = y.values\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\n            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()\n        \n\n        \n    def transform(self, X):\n        \n        \n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # DistrictId, IsDistrictLarge\n        X = X.merge(self.district_size, on='DistrictId', how='left')\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1\n        \n        X['DistrictSize'].fillna(5, inplace=True)\n        \n        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)  # + столбец floor_cat\n        X = self.year_to_cat(X)   # + столбец year_cat\n        \n        # Target encoding\n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\n            X.fillna(self.med_price_by_district_median, inplace=True)\n            \n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n            X.fillna(self.med_price_by_floor_year_median, inplace=True)\n        \n        return X\n    \n    def floor_to_cat(self, X):\n        bins = [0, 3, 5, 9, 15, self.floor_max]\n        X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n\n        X['floor_cat'].fillna(-1, inplace=True) \n        return X\n     \n    def year_to_cat(self, X):\n        bins = [0, 1941, 1945, 1980, 2000, 2010, self.house_year_max]\n        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n\n        X['year_cat'].fillna(-1, inplace=True)\n        return X\n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = ['DistrictId', 'Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3', \n                 'Helthcare_2', 'Shops_1', 'Shops_2'] \n\nnew_feature_names = ['Rooms_outlier'] \n\ntarget_name = 'Price'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\nX = train_df.drop(columns=target_name)\ny = train_df[target_name]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=21)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = DataPreprocessing()\npreprocessor.fit(X_train)\n\nX_train = preprocessor.transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ntest_df = preprocessor.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_gen = FeatureGenetator()\nfeatures_gen.fit(X_train, y_train)\n\nX_train = features_gen.transform(X_train)\nX_valid = features_gen.transform(X_valid)\ntest_df = features_gen.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train[feature_names + new_feature_names]\nX_valid = X_valid[feature_names + new_feature_names]\ntest_df = test_df[feature_names + new_feature_names]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import GradientBoostingRegressor\n# from sklearn.ensemble import BaggingRegressor\n\ngb = GradientBoostingRegressor(\n                               max_depth=4,\n                               min_samples_leaf=20,\n                               random_state=21,  \n                               n_estimators=150\n                              )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrf = RandomForestRegressor(\n    random_state=21, \n    max_depth=40,  # gridsearch\n    criterion='mse',\n    min_samples_leaf=5,  # gridsearch\n    n_jobs=-1,\n    n_estimators=1000  # gridsearch\n)\n# rf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrf2 = RandomForestRegressor(\n    random_state=21, \n    max_depth=17, \n    criterion='mse',\n    max_features=7, \n    n_jobs=-1,\n    n_estimators=200  \n)\n# rf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrf3 = RandomForestRegressor(\n    max_depth=20,\n    random_state=21, \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrf4 = RandomForestRegressor(\n    random_state=21, \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport xgboost as xgb\n\nxg=xgb.XGBRegressor(\n                  random_state=21,\n                  n_estimators=5, \n                  n_jobs=-1,\n                  subsample=0.5,\n                  colsample_bynode=0.5,\n                  num_parallel_tree=100,\n                  learning_rate=0.5,\n                  max_depth=3\n                  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import StackingRegressor\n\nstack = StackingRegressor([\n                           ('rf', rf),\n                           ('rf2', rf2),\n#                            ('rf3', rf3),\n                           ('rf4', rf4),\n                           ('gb', gb), \n                           ('xg', xg),\n                          ],\n                          cv=5,\n                          n_jobs=-1,\n                          final_estimator=GradientBoostingRegressor(\n                               \n                               max_depth=1,\n                               random_state=21,  \n                               n_estimators=85,\n                               \n                          )\n                         )\n                             \nstack.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = stack","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ny_train_preds = final_model.predict(X_train)\ny_test_preds = final_model.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape, test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('../input/sample/sample_submission.csv')\nsubmit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = final_model.predict(test_df)\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['Price'] = predictions\nsubmit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('rf_submit.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}