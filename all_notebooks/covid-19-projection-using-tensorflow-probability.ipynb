{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ncovid_19_clean_complete = pd.read_csv(\"../input/corona-virus-report/covid_19_clean_complete.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_19_clean_complete['Date'] = pd.to_datetime(covid_19_clean_complete['Date'], format=\"%m/%d/%y\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = covid_19_clean_complete['Country/Region'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_series = {c:covid_19_clean_complete[covid_19_clean_complete['Country/Region'] == c].groupby('Date').agg('sum').drop(['Lat', 'Long'], axis=1) for c in countries}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.log10(country_series['Mainland China']['Confirmed'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_confirmed = {c:(country_series[c]['Confirmed'] + 1).pct_change(fill_method='bfill').fillna(0) for c in countries}\nc_deaths = {c:(country_series[c]['Deaths'] + 1).pct_change(fill_method='bfill').fillna(0) for c in countries}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_probability as tfp\nimport tensorflow.keras as tfk\nimport tensorflow.keras.layers as tfkl\ntfpl = tfp.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SpreadModel(tfk.Model):\n    \n    def __init__(self,\n                 n_outputs,\n                 **kwargs):\n        \n        super(SpreadModel, self).__init__(**kwargs)\n        self.input_layer = tfkl.Dense(n_outputs)\n        self.lstms = [tfkl.LSTM(256, return_sequences=True, return_state=True) for i in range(4)]\n        event_shape = [n_outputs]\n        num_components = 20\n        params_size = tfpl.MixtureSameFamily.params_size(\n            num_components,\n            component_params_size=tfpl.IndependentNormal.params_size(event_shape))\n        self.output_dense = tfkl.Dense(params_size, activation=None)\n        self.output_layer = tfpl.MixtureSameFamily(num_components, tfpl.IndependentNormal(event_shape))\n        \n        \n    def call(self, inputs, hidden_states=None, training=None):\n        \n        x = self.input_layer(inputs, training=training)\n        \n        next_hidden_states = []\n        if hidden_states is not None:\n            \n            for rnn, hs in zip(self.lstms, hidden_states):\n                x, fms, fcs = rnn(x, training=training, initial_state=hs)\n                next_hidden_states.append((fms, fcs))\n        else:\n            for rnn in self.lstms:\n                x, fms, fcs = rnn(x, training=training)\n                next_hidden_states.append((fms, fcs))\n        dist_params = self.output_dense(x)\n        return self.output_layer(dist_params, training=training), next_hidden_states\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spreadModel = SpreadModel(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n\n#Remove countries that aren't testing\n\nfilter_countries = set([\n    'China',\n    'Japan',\n    'Hong Kong',\n    'Singapore',\n    'Italy',\n    'France',\n    'UK',\n    'Iceland',\n    'Japan',\n    'Switzerland',\n    'South Korea',\n    'Taiwan',\n    'Spain',\n    'Australia',\n    'Finland',\n    'Sweden',\n    'Norway',\n    'Germany',\n    'Canada',\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_filtered = {k:v for k,v in c_confirmed.items() if k in filter_countries}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_confirmed.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.clip(np.expand_dims(np.asarray([vs.values for vs in data_filtered.values()]), axis=-1).astype(np.float32), 0., 1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_x = data[:,:-1,:]\ndata_y = data[:,1:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = tf.data.Dataset.from_tensor_slices((data_x, data_y))\nds = ds.batch(64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tfk.optimizers.Adam(1e-6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(data):\n    \n    with tf.GradientTape() as g:\n        \n        inputs, targets = data\n        \n        pred_dist, _ = spreadModel(inputs, training=True)\n        \n        loss = tf.reduce_mean(-pred_dist.log_prob(targets))\n        \n    grads = g.gradient(loss, spreadModel.trainable_variables)\n    grads, _ = tf.clip_by_global_norm(grads, 1.0)\n    opt.apply_gradients(zip(grads, spreadModel.trainable_variables))\n    \n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(5000):\n    it = iter(ds)\n    for i, data in enumerate(it):\n        #print(data)\n        loss = train_step(data).numpy()\n        if loss < 0.0001:\n            break\n    if epoch % 100 == 0:\n        print(loss)\n    if loss < 0.0001:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_next_month(country):\n    dist, states = spreadModel(np.expand_dims(np.expand_dims(c_confirmed[country].values, axis=0), axis=-1), training=False)\n    smpls = dist.sample()\n    #print(smpls)\n    #raise Exception()\n    #am = tf.argmax(dist.log_prob(smpls)[...,-1])[0].numpy()\n    #good_sample = smpls[am, 0, -1]\n    nxt_sample = tf.expand_dims(tf.expand_dims(tf.expand_dims(smpls[0,-1,0], axis=-1),axis=0),axis=0)\n    nxt_sample\n    steps = [nxt_sample]\n    \n    for i in range(29):\n        dist, states = spreadModel(nxt_sample, training=False, hidden_states=states)\n        smpls = dist.sample()\n        #raise Exception()\n        #good_sample = smpls[am, 0, -1]\n        #nxt_sample = tf.expand_dims(tf.expand_dims(good_sample, axis=0),axis=-1)\n        steps.append(smpls)\n        \n    return country_series[country]['Confirmed'][-1] * np.cumprod(1 + np.clip(tf.squeeze(tf.concat(steps, axis=1)).numpy().astype(np.float128), 0., 10.))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample_multi_next_month(country, samples=20):\n    smpls = []\n    for i in range(samples):\n        r = predict_next_month(country)\n        smpls.append(r)\n    return smpls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PREDICTIONS!"},{"metadata":{"trusted":true},"cell_type":"code","source":"futures = sample_multi_next_month('US')\nfuture_means = np.stack(futures, axis=0).mean(axis=0).astype(np.int32).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('USA confirmed coming month:\\n', pd.Series(data=future_means, index=pd.date_range(c_confirmed['Sweden'].reset_index()['Date'].tolist()[-1] + pd.Timedelta('1 day'), periods=30, freq='D')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"futures = sample_multi_next_month('Sweden')\nfuture_means = np.stack(futures, axis=0).mean(axis=0).astype(np.int32).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Sweden confirmed coming month:\\n', pd.Series(data=future_means, index=pd.date_range(c_confirmed['Sweden'].reset_index()['Date'].tolist()[-1] + pd.Timedelta('1 day'), periods=30, freq='D')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}