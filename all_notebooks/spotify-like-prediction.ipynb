{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom mlxtend.classifier import StackingClassifier\nfrom IPython.display import display\nimport warnings\n\nwarnings.simplefilter(\"ignore\")\nSEED = 42","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/spotifyclassification/data.csv\")\ndata.drop('Unnamed: 0', axis =1, inplace=True)\nprint(display(data.head()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.info())\nprint('Дубликатов:', data.duplicated().sum())\nprint(display(data.describe()))\n    \nfor column in data:\n    if data[column].dtype == 'object':\n        print('Признак:', column)\n        print('Уникальные:', data[column].value_counts().count())\n        print()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= data.drop_duplicates().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ranking(y, title='', xlabel='', ylabel=''):\n    y_pos = np.arange(len(y),0,-1)\n    plt.figure(figsize=(5,5))\n    cmap = ListedColormap(sns.color_palette(\"GnBu_d\"))\n    bar_colors = cmap(y.values)\n    plt.barh(y_pos, width=y, height=0.6, left=None, align='center', color=bar_colors, alpha = 0.8)\n    plt.yticks(y_pos, y.index)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    for p, c, ch in zip(y_pos, y.index, round(y,4)):\n        plt.annotate(str(ch), xy=(ch if ch>0 else 0, p), va='center')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ranking(data.corr()['target'].sort_values(ascending = False), 'Correlation of target with other features', 'Correlation', 'Features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def range_col(data,parameter, begin, end, step):\n\n  rangecol = []\n  \n  for row in data.values:\n    row[parameter] = float(row[parameter])\n    \n    if row[parameter] < begin:\n      rangecol.append(\"<\" + str(round(begin,2)))\n    elif row[parameter] >= end:\n      rangecol.append(\">=\" + str(round(end,2)))\n    else:\n      for r in np.arange(begin,end,step).round(2):\n        if r <= row[parameter] < min((r+step, end)):\n          rangecol.append(str(round(r,2))+\"-\"+str(round(min(r+step, end),2)))\n          break\n        \n  \n     \n  return rangecol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_modified = data.copy()\ndata_modified['acousticness'] = range_col(data_modified, 0, 0, 1, 0.1)\ndata_modified['danceability'] = range_col(data_modified, 1, 0, 1, 0.1)\ndata_modified['duration_ms'] = range_col(data_modified, 2, 50000, 1000000, 50000)\ndata_modified['energy'] = range_col(data_modified, 3, 0, 1, 0.1)\ndata_modified['instrumentalness'] = range_col(data_modified, 4, 0, 1, 0.1)\ndata_modified['liveness'] = range_col(data_modified, 6, 0, 1, 0.1)\ndata_modified['loudness'] = range_col(data_modified, 7, -34, 0, 2)\ndata_modified['speechiness'] = range_col(data_modified, 9, 0, 1, 0.1)\ndata_modified['tempo'] = range_col(data_modified, 10, 40, 220, 10)\ndata_modified['valence'] = range_col(data_modified, 12, 0, 1, 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(display(data_modified.head()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_encoded = pd.get_dummies(data_modified.drop('song_title', axis = 1), dummy_na=False, drop_first=True)\nprint(data_encoded.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data_encoded.drop('target', axis =1)\ntarget = data_encoded['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train_val, features_test, target_train_val, target_test = train_test_split(features, target, test_size=0.20, random_state=SEED)\nfeatures_train, features_val, target_train, target_val = train_test_split(features_train_val, target_train_val, test_size=0.25, random_state=SEED)\nprint(features_train.shape, features_val.shape, features_test.shape, target_train.shape, target_val.shape, target_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = LogisticRegression(random_state = SEED)\nclf2 = GradientBoostingClassifier(random_state = SEED)\nlr = LogisticRegression(random_state = SEED)\nsclf = StackingClassifier(classifiers=[clf1, clf2], \n                          use_probas=True,\n                          meta_classifier=lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param1 = ({'C': list(np.arange(1, 10)), 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},    \n              {'C': list(np.arange(1, 10)), 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']})\n\nparam2 = ({'learning_rate': (0.01, 0.05, 0.1, 0.5),\n                  'n_estimators': (50, 100, 200),\n                  'min_samples_split': (2, 3),\n                  'max_depth': (2, 3, 5)\n                                                   \n                 })\nparam_sclf = ({})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scorer = make_scorer(roc_auc_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_table = pd.DataFrame(columns = ['model', 'params', 'accuracy_score', 'roc_auc'])\ni=0\nfor clf, label, param in zip([clf1, clf2,sclf], \n                      ['Logistic Regression', \n                       'Gradient Boosting',\n                       'Stacking Classifier'], \n                       [param1, param2, param_sclf]):\n    \n    grid = model_selection.GridSearchCV(clf, param_grid=param,scoring=scorer)\n    grid.fit(features_train, target_train)\n    scores = grid.score(features_val, target_val)\n    print(label)\n    print(grid.best_params_)\n    print(\"accuracy score = %0.4f\" \n          % (scores))\n    probabilities = grid.predict_proba(features_test)\n    probabilities_ones = probabilities[:,1]\n    auc_roc = roc_auc_score(target_test, probabilities_ones)\n    print('roc_auc = {:0.4f}'.format(auc_roc)) \n    print()\n    if clf == clf1:\n      clf1.set_params(**grid.best_params_)\n    if clf == clf2:\n      clf2.set_params(**grid.best_params_)\n    score_table.loc[i, 'model'] = label\n    score_table.loc[i, 'params'] = [grid.best_params_]\n    score_table.loc[i, 'accuracy_score'] = scores\n    score_table.loc[i, 'roc_auc'] = auc_roc\n\n    i+=1\n\n\n    train_sizes, train_scores, test_scores, fit_times, _ = model_selection.learning_curve(clf, features_train, target_train, return_times=True, scoring=scorer)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    _, axes = plt.subplots(1, 1, figsize=(6, 6))\n\n    axes.set_title(label)\n    axes.set_xlabel(\"Training examples\")\n    axes.set_ylabel(\"Score\")\n    axes.grid()\n    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"g\")\n    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n    axes.legend(loc=\"best\")    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ranking(score_table.groupby(['model'])['roc_auc'].aggregate('max').sort_values(ascending = False), 'Рейтинг моделей', 'Метрика roc_auc', 'Модель')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = LogisticRegression(random_state = SEED)\nparams = score_table[score_table['model']=='Logistic Regression']['params']\nclf1.set_params(**params[0][0])\n\nclf2 = GradientBoostingClassifier(random_state = SEED)\nparams = score_table[score_table['model']=='Gradient Boosting']['params']\n\nclf2.set_params(**params[1][0])\n\nlr = LogisticRegression(random_state = SEED)\nmodel = StackingClassifier(classifiers=[clf1, clf2], \n                          use_probas=True,\n                          meta_classifier=lr)\nmodel.fit(features_train_val, target_train_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_predict = model.predict(features_test)\naccuracy = accuracy_score(target_test, target_predict)\nprint('Best model:')\nprint(\"accuracy score = %0.4f\" % (accuracy))\nprobabilities = model.predict_proba(features_test)\nprobabilities_ones = probabilities[:,1]\nauc_roc = roc_auc_score(target_test, probabilities_ones)\nprint('roc_auc = {:0.4f}'.format(auc_roc))    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dummy = DummyClassifier()\nmodel_dummy.fit(features_train_val, target_train_val)\ntarget_predict_d = model_dummy.predict(features_test)\naccuracy_d = accuracy_score(target_test, target_predict_d)\nprint('Dummy classifier:')\nprint(\"accuracy score = %0.4f\" % (accuracy_d))\nprobabilities_d = model_dummy.predict_proba(features_test)\nprobabilities_ones_d = probabilities_d[:,1]\nauc_roc_d = roc_auc_score(target_test, probabilities_ones_d)\nprint('roc_auc = {:0.4f}'.format(auc_roc_d))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(target_test, probabilities_ones)\nfpr_d, tpr_d, thresholds_d = roc_curve(target_test, probabilities_ones_d)\nplt.figure(figsize = (8,8))\nplt.plot(fpr, tpr, color='darkorange', label='Ensemble ROC curve (area = %0.3f)' % auc_roc)\n\nplt.plot(fpr_d, tpr_d, color='navy', linestyle='--', label = 'Dummy classifier ROC curve (area = %0.3f)' % auc_roc_d)\n\n\nfor point,flag in zip([0.10, 0.20, 0.30, 0.50, 0.70, 0.90], [0,0,0,0,0,0]):\n  i=0\n  for fp in fpr:\n    if round(fp, 1) == point and flag ==0:\n      plt.plot(fpr[i], tpr[i], color='red', marker=\"o\")\n      plt.annotate(\"threshold = {}\".format(point), xy=(fpr[i], tpr[i]), xytext=(fpr[i]+0.04, tpr[i]-0.05),  arrowprops={'width':0.3,'headwidth':7,'color':'#333333'})\n      flag=1\n    i+=1\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_idx = np.argmax(tpr - fpr)\noptimal_threshold = thresholds[optimal_idx]\nprint(\"Optimal threshold = %0.2f\" %optimal_threshold)\npreds = [1 if pr>optimal_threshold else 0 for pr in probabilities_ones]\nprint(\"accuracy score = %0.4f\" %(accuracy_score(target_test, preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('threshold =', 0.25)\npreds = [1 if pr>0.25 else 0 for pr in probabilities_ones]\nprint(\"accuracy score = %0.4f\" %(accuracy_score(target_test, preds)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}