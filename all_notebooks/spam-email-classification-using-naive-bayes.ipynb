{"cells":[{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nemails = pd.read_csv(\"../input/spam-filter/emails.csv\")\nemails","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails['spam'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails.notnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails[\"text\"] = emails[\"text\"].str.lower()\nemails.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nPUNCT_TO_REMOVE = string.punctuation\ndef remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\nemails[\"text\"] = emails[\"text\"].apply(lambda text: remove_punctuation(text))\nemails['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\nSTOPWORDS.add('subject')\ndef remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n\nemails[\"text\"] = emails[\"text\"].apply(lambda text: remove_stopwords(text))\nemails['text']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n\nemails[\"text\"] = emails[\"text\"].apply(lambda text: lemmatize_words(text))\nemails.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = emails['text']\ny = emails['spam']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tfidf vectorization of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\nX_train = vectorizer.fit_transform(X_train)\nX_test = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## multinomial naive bayes for classifying data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\ntrainacc = accuracy_score(y_train, y_pred)\ntrainf1 = f1_score(y_train, y_pred)\nprint(trainacc)\nprint(trainf1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testacc = accuracy_score(y_test, y_pred_test)\nf1test = f1_score(y_test, y_pred_test)\nprint(testacc)\nprint(f1test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrix for train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sn\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_train, y_pred)\nsn.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrix for test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm1 = confusion_matrix(y_test, y_pred_test)\nsn.heatmap(cm1, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyper parameter tuning to find best alpha"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import MultinomialNB\nparams_KNN = {'alpha': [0.00000001,0.0000001, 0.000001,0.00001,0.0001,0.001,0.01,0.1,1,2,3,4,5,6,7,8,9,10,15,20,25,30,40,50]}\ngs_KNN = GridSearchCV(estimator=MultinomialNB(),\n                      param_grid=params_KNN, \n                      verbose=1,  # verbose: the higher, the more messages\n                      scoring='f1', \n                      return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_KNN.fit(X_train, y_train)\nbest_parameters = gs_KNN.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MultinomialNB(alpha= 0.01)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrainacc = accuracy_score(y_train, y_pred)\ntrainf1 = f1_score(y_train, y_pred)\nprint(trainacc)\nprint(trainf1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = clf.predict(X_test)\ntestacc = accuracy_score(y_test, y_pred_test)\ntestf1 = f1_score(y_test, y_pred_test)\nprint(testacc)\nprint(testf1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrix for test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sn\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_train, y_pred)\nsn.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrix for test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm1 = confusion_matrix(y_test, y_pred_test)\nsn.heatmap(cm1, annot=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}