{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://www.dataquest.io/blog/introduction-to-ensembles/"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\nUSECOLS = [\"cand_pty_affiliation\",\n           \"cand_office_st\",\n           \"cand_office\",\n           \"cand_office_district\",\n           \"cand_status\",\n           \"rpt_tp\",\n           \"transaction_pgi\",\n           \"transaction_tp\",\n           \"entity_tp\",\n           \"state\",\n           \"classification\",\n           \"transaction_amt\",\n           \"cycle\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delcols = ['cand_office_district', 'transaction_pgi']\nusecols = [col for col in USECOLS if col not in delcols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = '/kaggle/input/science-federal-giving/science_federal_giving.csv'\ndf = pd.read_csv(f, usecols=usecols, low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop NaNs\ndf.dropna(inplace=True)\nif \"cand_office_district\" in df.columns:\n    df.cand_office_district = df.cand_office_district.astype(\"object\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if \"cycle\" in df.columns:\n    df.loc[:, \"cycle\"] = df.loc[:, \"cycle\"].astype(\"object\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter out minor parties and negative contributions\ndf = df.loc[df.cand_pty_affiliation.apply(lambda x: x in [\"DEM\", \"REP\"]), :]\ndf = df.loc[df.transaction_amt > 0, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 222\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = np.random.permutation(df.shape[0])\ndf = df.iloc[idx, :]\ndf.reset_index(drop=True, inplace=True)\nnum = 100000\ndf = df.iloc[:num, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('input.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n### Import data\n# Always good to set a seed for reproducibility\nSEED = 222\nnp.random.seed(SEED)\n\n# df = pd.read_csv('input.csv')\n\n### Training and test set\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\ndef get_train_test(test_size=0.95):\n    \"\"\"Split Data into train and test sets.\"\"\"\n    y = 1 * (df.cand_pty_affiliation == \"REP\")\n    X = df.drop([\"cand_pty_affiliation\"], axis=1)\n    X = pd.get_dummies(X)\n#     X = pd.get_dummies(X, sparse=True)\n    X.drop(X.columns[X.std() == 0], axis=1, inplace=True)\n    return train_test_split(X, y, test_size=test_size, random_state=SEED)\n\nxtrain, xtest, ytrain, ytest = get_train_test()\n\n# A look at the data\nprint(\"\\nExample data:\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.cand_pty_affiliation.value_counts(normalize=True).plot(\n   kind=\"bar\", title=\"Share of No. donations\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pydotplus  # you can install pydotplus with: pip install pydotplus \nfrom IPython.display import Image\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\ndef print_graph(clf, feature_names):\n    \"\"\"Print decision tree.\"\"\"\n    graph = export_graphviz(\n           clf,\n           label=\"root\",\n           proportion=True,\n           impurity=False, \n           out_file=None, \n           feature_names=feature_names,\n           class_names={0: \"D\", 1: \"R\"},\n           filled=True,\n           rounded=True\n       )\n    graph = pydotplus.graph_from_dot_data(graph)  \n    return Image(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t1 = DecisionTreeClassifier(max_depth=1, random_state=SEED)\nt1.fit(xtrain, ytrain)\np = t1.predict_proba(xtest)[:, 1]\n\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\nprint_graph(t1, xtrain.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t2 = DecisionTreeClassifier(max_depth=3, random_state=SEED)\nt2.fit(xtrain, ytrain)\np = t2.predict_proba(xtest)[:, 1]\n\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\nprint_graph(t2, xtrain.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop = [\"transaction_amt\"]\n\nxtrain_slim = xtrain.drop(drop, 1)\nxtest_slim = xtest.drop(drop, 1)\n\nt3 = DecisionTreeClassifier(max_depth=3, random_state=SEED)\nt3.fit(xtrain_slim, ytrain)\np = t3.predict_proba(xtest_slim)[:, 1]\n\n\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\nprint_graph(t3, xtrain_slim.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = t2.predict_proba(xtest)[:, 1]\np2 = t3.predict_proba(xtest_slim)[:, 1]\n\npd.DataFrame({\"full_data\": p1,\"red_data\": p2}).corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = t2.predict_proba(xtest)[:, 1]\np2 = t3.predict_proba(xtest_slim)[:, 1]\np = np.mean([p1, p2], axis=0)\nprint(\"Average of decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(\n   n_estimators=10,\n   max_features=3,\n   random_state=SEED\n)\n\nrf.fit(xtrain, ytrain)\np = rf.predict_proba(xtest)[:, 1]\nprint(\"Average of decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A host of Scikit-learn models\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.kernel_approximation import Nystroem\nfrom sklearn.kernel_approximation import RBFSampler\nfrom sklearn.pipeline import make_pipeline\n\n\ndef get_models():\n    \"\"\"Generate a library of base learners.\"\"\"\n    nb = GaussianNB()\n    svc = SVC(C=100, probability=True)\n    knn = KNeighborsClassifier(n_neighbors=3)\n    lr = LogisticRegression(C=100, random_state=SEED)\n    nn = MLPClassifier((80, 10), early_stopping=False, random_state=SEED)\n    gb = GradientBoostingClassifier(n_estimators=100, random_state=SEED)\n    rf = RandomForestClassifier(n_estimators=10, max_features=3, random_state=SEED)\n\n    models = {'svm': svc,\n              'knn': knn,\n              'naive bayes': nb,\n              'mlp-nn': nn,\n              'random forest': rf,\n              'gbm': gb,\n              'logistic': lr,\n              }\n\n    return models\n\n\ndef train_predict(model_list):\n    \"\"\"Fit models in list on training set and return preds\"\"\"\n    P = np.zeros((ytest.shape[0], len(model_list)))\n    P = pd.DataFrame(P)\n\n    print(\"Fitting models.\")\n    cols = list()\n    for i, (name, m) in enumerate(models.items()):\n        print(\"%s...\" % name, end=\" \", flush=False)\n        m.fit(xtrain, ytrain)\n        P.iloc[:, i] = m.predict_proba(xtest)[:, 1]\n        cols.append(name)\n        print(\"done\")\n\n    P.columns = cols\n    print(\"Done.\\n\")\n    return P\n\n\ndef score_models(P, y):\n    \"\"\"Score model in prediction DF\"\"\"\n    print(\"Scoring models.\")\n    for m in P.columns:\n        score = roc_auc_score(y, P.loc[:, m])\n        print(\"%-26s: %.3f\" % (m, score))\n    print(\"Done.\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = get_models()\nP = train_predict(models)\nscore_models(P, ytest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You need ML-Ensemble for this figure: you can install it with: pip install mlens\nfrom mlens.visualization import corrmat\n\ncorrmat(P.corr(), inflate=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat(P.apply(lambda pred: 1*(pred >= 0.5) - ytest.values).corr(), inflate=False)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Ensemble ROC-AUC score: %.3f\" % roc_auc_score(ytest, P.mean(axis=1)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\ndef plot_roc_curve(ytest, P_base_learners, P_ensemble, labels, ens_label):\n    \"\"\"Plot the roc curve for base learners and ensemble.\"\"\"\n    plt.figure(figsize=(10, 8))\n    plt.plot([0, 1], [0, 1], 'k--')\n\n    cm = [plt.cm.rainbow(i)\n      for i in np.linspace(0, 1.0, P_base_learners.shape[1] + 1)]\n\n    for i in range(P_base_learners.shape[1]):\n        p = P_base_learners[:, i]\n        fpr, tpr, _ = roc_curve(ytest, p)\n        plt.plot(fpr, tpr, label=labels[i], c=cm[i + 1])\n\n    fpr, tpr, _ = roc_curve(ytest, P_ensemble)\n    plt.plot(fpr, tpr, label=ens_label, c=cm[0])\n\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(frameon=False)\n    plt.show()\n\n\nplot_roc_curve(ytest, P.values, P.mean(axis=1), list(P.columns), \"ensemble\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = P.apply(lambda x: 1*(x >= 0.5).value_counts(normalize=True))\np.index = [\"DEM\", \"REP\"]\np.loc[\"REP\", :].sort_values().plot(kind=\"bar\")\nplt.axhline(0.25, color=\"k\", linewidth=0.5)\nplt.text(0., 0.23, \"True share republicans\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"include = [c for c in P.columns if c not in [\"mlp-nn\"]]\nprint(\"Truncated ensemble ROC-AUC score: %.3f\" % roc_auc_score(ytest, P.loc[:, include].mean(axis=1)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_learners = get_models()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmeta_learner = GradientBoostingClassifier(\n    n_estimators=1000,\n    loss=\"exponential\",\n    max_features=4,\n    max_depth=3,\n    subsample=0.5,\n    learning_rate=0.005,\n    random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_base, xpred_base, ytrain_base, ypred_base = train_test_split(\n    xtrain, ytrain, test_size=0.5, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_base_learners(base_learners, inp, out, verbose=True):\n    \"\"\"\n    Train all base learners in the library.\n    \"\"\"\n    if verbose: print(\"Fitting models.\")\n    for i, (name, m) in enumerate(base_learners.items()):\n        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n        m.fit(inp, out)\n        if verbose: print(\"done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_base_learners(base_learners, xtrain_base, ytrain_base)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_base_learners(pred_base_learners, inp, verbose=True):\n    \"\"\"\n    Generate a prediction matrix.\n    \"\"\"\n    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n\n    if verbose: print(\"Generating base learner predictions.\")\n    for i, (name, m) in enumerate(pred_base_learners.items()):\n        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n        p = m.predict_proba(inp)\n        # With two classes, need only predictions for one class\n        P[:, i] = p[:, 1]\n        if verbose: print(\"done\")\n\n    return P","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P_base = predict_base_learners(base_learners, xpred_base)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_learner.fit(P_base, ypred_base)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ensemble_predict(base_learners, meta_learner, inp, verbose=True):\n    \"\"\"\n    Generate predictions from the ensemble.\n    \"\"\"\n    P_pred = predict_base_learners(base_learners, inp, verbose=verbose)\n    return P_pred, meta_learner.predict_proba(P_pred)[:, 1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P_pred, p = ensemble_predict(base_learners, meta_learner, xtest)\nprint(\"\\nEnsemble ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import clone\n\ndef stacking(base_learners, meta_learner, X, y, generator):\n    \"\"\"Simple training routine for stacking.\"\"\"\n\n    # Train final base learners for test time\n    print(\"Fitting final base learners...\", end=\"\")\n    train_base_learners(base_learners, X, y, verbose=False)\n    print(\"done\")\n\n    # Generate predictions for training meta learners\n    # Outer loop:\n    print(\"Generating cross-validated predictions...\")\n    cv_preds, cv_y = [], []\n    for i, (train_idx, test_idx) in enumerate(generator.split(X)):\n\n        fold_xtrain, fold_ytrain = X[train_idx, :], y[train_idx]\n        fold_xtest, fold_ytest = X[test_idx, :], y[test_idx]\n\n        # Inner loop: step 4 and 5\n        fold_base_learners = {name: clone(model)\n                              for name, model in base_learners.items()}\n        train_base_learners(\n            fold_base_learners, fold_xtrain, fold_ytrain, verbose=False)\n\n        fold_P_base = predict_base_learners(\n            fold_base_learners, fold_xtest, verbose=False)\n\n        cv_preds.append(fold_P_base)\n        cv_y.append(fold_ytest)\n        print(\"Fold %i done\" % (i + 1))\n\n    print(\"CV-predictions done\")\n\n    # Be careful to get rows in the right order\n    cv_preds = np.vstack(cv_preds)\n    cv_y = np.hstack(cv_y)\n\n    # Train meta learner\n    print(\"Fitting meta learner...\", end=\"\")\n    meta_learner.fit(cv_preds, cv_y)\n    print(\"done\")\n\n    return base_learners, meta_learner","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\n# Train with stacking\ncv_base_learners, cv_meta_learner = stacking(\n    get_models(), clone(meta_learner), xtrain.values, ytrain.values, KFold(2))\n\nP_pred, p = ensemble_predict(cv_base_learners, cv_meta_learner, xtest, verbose=False)\nprint(\"\\nEnsemble ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlens.ensemble import SuperLearner\n\n# Instantiate the ensemble with 10 folds\nsl = SuperLearner(\n    folds=10,\n    random_state=SEED,\n    verbose=2,\n    backend=\"multiprocessing\"\n)\n\n# Add the base learners and the meta learner\nsl.add(list(base_learners.values()), proba=True)\nsl.add_meta(meta_learner, proba=True)\n\n# Train the ensemble\nsl.fit(xtrain, ytrain)\n\n# Predict the test set\np_sl = sl.predict_proba(xtest)\n\nprint(\"\\nSuper Learner ROC-AUC score: %.3f\" % roc_auc_score(ytest, p_sl[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(ytest, p.reshape(-1, 1), P.mean(axis=1), [\"Simple average\"], \"Super Learner\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}