{"cells":[{"metadata":{},"cell_type":"markdown","source":"## What Treatments Are Being Tried?\n\nAssociated with the task: 'What do we know about therapeutics?' is the specific subtask:\n'Clinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocyclinethat that may exert effects on viral replication'.\n\nThis notebook uncovers two to three hundred papers detailing treatment efforts with specific drugs and compounds.\n\n### Methodology\n\nWe used a RandomForest Classifier to classify documents as relevant to the task above.  First a train,test data set was built utilizing abstracts containing drug and antiviral names.  After training, the classifier achieved precision of 84% and recall of 82%.  Sample reading of the final output shows similar precision.\n\nThe articles are displayed interactively below with links and a separate csv file is available for download."},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom functools import reduce\nimport pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import recall_score,precision_score,f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom IPython.core.display import display, HTML","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read a list of 200 common drugs\ndrugs = pd.read_html('https://clincalc.com/DrugStats/Top200Drugs.aspx')[0]\n# add known interesting theraputics\npromising = pd.Series(['chloroquine','hydrochloroquine','remdesivir','quercetin']).to_frame()\npromising.columns =  ['Drug Name']\npromising['Rank'] = np.nan\npromising['Total Prescriptions (2017)'] = np.nan\npromising['Annual Change'] = np.nan\ndrugs = drugs.append(promising,ignore_index=True,sort=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### List of 200 common drugs with Covid-19 specific additions"},{"metadata":{"trusted":true},"cell_type":"code","source":"drugs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read the Covid-19 dataset metadata"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\ndisplay(HTML(f'meta data shape: {metadata.shape}'))\nhas_abstract = metadata.abstract.apply(lambda x: str(x)!='nan')\nmetadata = metadata.iloc[has_abstract.values,:]\ndisplay(HTML(f'meta data shape after dropping docs without abstracts: {metadata.shape}'))\nmetadata.head(n=2).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build the train, test sets and train classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"def has_word(text_string,filter_words):\n    def has_this_word(has_one,word):\n        if has_one:\n            return True\n        else:\n            if word in text_string:\n                return True\n            else:\n                return False\n    return reduce(has_this_word,filter_words,False)\n\nFILTER_WORDS = ['SARS','MERS','corona','Cov','COV'] #keyword strings used to filter titles\n\n# filter to titles with covid words\nhave_filter_word = metadata.abstract.apply(lambda x: has_word(x,FILTER_WORDS)) \nmetadata_has_corona = metadata[have_filter_word]\n\n# filter to drug words\nhave_filter_word = metadata.abstract.apply(lambda x: has_word(x,drugs['Drug Name']))  \nmetadata_has_drug = metadata[have_filter_word]\n\n# filter to theraputics\ntheraputic_words = ['anti-viral','antiviral']\nhave_filter_word = metadata.abstract.apply(lambda x: has_word(x,theraputic_words))  \nmetadata_has_theraputic = metadata[have_filter_word]\n\n# filter for antivirals and arb_blockers\ndef regex_search(string,pattern):\n    return True if re.search(pattern,string) else False\n\nhave_filter_word = metadata.abstract.apply(lambda x: regex_search(x,'[a-zA-Z]+vir ')) \nmetadata_has_antiviral = metadata[have_filter_word]\n\n# filter for arb blockers\nhave_filter_word = metadata.abstract.apply(lambda x: regex_search(x,'[a-zA-Z]+sartan ')) \nmetadata_has_arb_blocker = metadata[have_filter_word]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build positives\nX1 = metadata_has_drug.append(metadata_has_antiviral)\nX2 = X1.append(metadata_has_arb_blocker)\n\n#build negatives \nnegatives_index = np.random.choice(metadata.index,size=1000,replace=False)\nnegatives_index = [x for x in negatives_index if x not in X2.index]\nX = X2.append(metadata.loc[negatives_index]).abstract\n\n# build ground truth\ny = pd.Series([1]*len(X2) + [0]*(len(X) - len(X2)))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\ntfidf = TfidfVectorizer(ngram_range=(1,1),stop_words='english',max_df=.75,min_df=1)\nbow = pd.DataFrame((tfidf.fit_transform(X_train).todense()))\ndisplay(HTML( f'Bag of Words shape {bow.shape}'))\n\nrf = RandomForestClassifier(n_estimators=300,\n    min_samples_leaf=5,\n    oob_score=True)\nrf.fit(bow,y_train)\ndisplay(HTML(f'RandomForest Out-of-Bag Score: {rf.oob_score_}'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Examine classifier performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_test = pd.DataFrame((tfidf.transform(X_test).todense()))\ny_prob = rf.predict_proba(bow_test)[:,1]\ny_pred = [1 if x > .5 else 0 for x in y_prob]\n_ = plt.hist(y_prob[y_test==1],bins=20,label='Positives',alpha=.5)\n_ = plt.hist(y_prob[y_test==0],bins=20,label='Negatives',alpha=.5)\nplt.legend(loc='upper right')\n_ = plt.title('Class Probability Distribution')\nplt.gcf().set_size_inches((8,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh = .5  # adjust to tune precision, recall\ny_pred = pd.Series([1 if x > thresh else 0 for x in y_prob])\ndisplay(HTML('Confusion Matrix' ))\ndisplay_df = pd.DataFrame(confusion_matrix(y_test,y_pred))\ndisplay_df.columns = ['Predicted 0','Predicted 1']\ndisplay_df.index = ['True 0','True 1']\ndisplay(HTML(display_df.to_html()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(HTML(f'Recall {recall_score(y_test,y_pred)}'))\ndisplay(HTML(f'Precision {precision_score(y_test,y_pred)}'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Classify COVID papers"},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_covid = tfidf.transform(metadata_has_corona.abstract)\ny_prob = rf.predict_proba(bow_covid)[:,1]\ny_pred = [True if x > thresh else False for x in y_prob]\ndisplay(HTML( f'Bag of Words shape {bow_covid.shape}'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sample output for quality review\nReadings of several samples of 20 docs shows precision consistent with the test set precision score."},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_sample(docs,n=20):\n    for d in docs[0:n]:\n        print(d + '\\n')\n\nprint_sample(metadata_has_corona.abstract.loc[y_pred])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display papers classified as showing therapeutic efforts\n\n\nThese are availables as as csv file as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(HTML(f'Found {np.sum(y_pred)} papers'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s = metadata_has_corona.loc[y_pred,['title','abstract','doi']]\n#convert to html\ndf_s['title'] = '<span style=\"float: left; width: 100%; text-align: left;\">' + df_s['title'] + '</span>'\ndf_s['abstract'] = '<span style=\"float: left; width: 80%; text-align: left;\">' + df_s['abstract'] + '</span>'\ndf_s['doi'] = '<a href = \"https://doi.org' + df_s['doi'] + '\" target=\"_blank\">link</a>'\nresult = HTML(df_s.to_html(escape=False))\ndisplay(result)\ndisplay(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ideas for further work\n\n* increase training set size\n* improve text preprocessing e.g add stemming, elimnate noise e.g standalone numbers\n* rerun classifier on most important features\n* try other classifiers. e.g. FastText\n* summarize key findings\n* show stats on drugs e.g. number of mentions\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save file\nmetadata_has_corona.loc[y_pred].to_csv('/kaggle/working/theraputics_compounds_alh.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}