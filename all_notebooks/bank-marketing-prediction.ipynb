{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ML Project - Bank Marketing Prediction\n\nBy - A.Yash Kumar Rao"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, we'll import pandas,numpy , a data processing and CSV file I/O library\nimport pandas as pd\nimport numpy as np\n\n# We'll also import seaborn, a Python graphing library\nimport warnings # current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\", color_codes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Next, we'll load the Iris flower dataset, which is in the \"../input/\" directory\ndf = pd.read_csv(r\"../input/banckingmarket/bank.csv\") # the iris dataset is now a Pandas DataFrame\n\n# Let's see what's in the iris data - Jupyter notebooks print the result of the last thing you do\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = [column for column in df.columns[:-1] if df[column].dtype == \"O\"]\nprint(categorical_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in categorical_columns:\n    print(\"Unique values in\",column,\"are\", df[column].unique() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Describe the pdays column, make note of the mean, median and minimum values. Anything fishy in the values?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pdays'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean of the pdays column is\", df['pdays'].mean())\nprint(\"Median of the pdays column is\", df['pdays'].median())\nprint(\"Min of the pdays column is\", df['pdays'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__\"pdays\" column signifies No. of days passed after the client was contacted from previous campaign.\nIf value is -1 i.e. It is an outlier because no. of days passed can't be negative.__"},{"metadata":{},"cell_type":"markdown","source":"### Describe the pdays column again, this time limiting yourself to the relevant values of pdays. How different are the mean and the median values?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean of pdays column after eliminating -1 values is\", df[df['pdays'] != -1]['pdays'].mean() )\nprint(\"Median of pdays column after eliminating -1 values is\", df[df['pdays'] != -1]['pdays'].median() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__After skipping the outlier -1 mean and median values are changed to a much extent.__"},{"metadata":{},"cell_type":"markdown","source":"### Plot a horizontal bar graph with the median values of balance for each education level value. Which group has the highest median?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import *\ndf.groupby('education')['balance'].median().plot.barh(color='green')\nplt.ylabel('Balance')\nplt.title('Education wise Median of Balance');\nplt.ylabel('Education')\nplt.xlabel('Balance')\nplt.title('Grouping Education based on balance');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Tertiary education level has the highest median.__"},{"metadata":{},"cell_type":"markdown","source":"### Make a box plot for pdays. Do you see any outliers?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.pdays, orient='v');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Yes, there are lot of outliers in pdays column.__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__There are no null values.__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.response.replace({'no':0,'yes':1} ,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.response.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__We have successfully handled the Target variable i.e Response columns.__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(),annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['education'],hue=df['response']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['education'],df['age'],hue=df['response']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Are pdays and poutcome associated with the target?"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.pairplot(df,hue='response');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Associations of categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='response', data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y='job', data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='marital', data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y='education', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Are the features about the previous campaign data useful?"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for column in categorical_columns:\n    pd.crosstab(df[column],df['response']).plot.bar()\n    plt.title(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df['poutcome'],df['response']).plot.bar()\nplt.title('poutcome');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__'poutcome' column is not assosciated with target column because it has more than 80% missing values.__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('poutcome',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pdays'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['previous'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### how do you handle the pdays column with a value of -1 where the previous campaign data is missing?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pdays_no_contact'] = np.where(df['pdays']==-1,1,0)\ndf['pdays_no_contact'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__We created a new column since majority of users were not previously contacted. We are capturing importance of missing values.__ "},{"metadata":{},"cell_type":"markdown","source":"### Handling Missing Values in Categorical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in categorical_columns[:-1]:\n    print(df[column].value_counts(),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Missing Values are represented as Unknown which is better way to handle missing data by becoming a new category itself rather than imputing it with the mode of the particular column.__"},{"metadata":{},"cell_type":"markdown","source":"### Handling Outliers in the Data."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_columns = [col for col in df.columns if col not in categorical_columns]\nprint(num_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist=df.hist(figsize=(12,10)) # display numerical feature distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Assuming Age follows A Gaussian Distribution we will calculate the boundaries which differentiates the outliers\n\nupper_boundary = df['age'].mean() + 3* df['age'].std()\nlower_boundary = df['age'].mean() - 3* df['age'].std()\nprint(lower_boundary), print(upper_boundary),print(df['age'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = df[(df['age']>upper_boundary) | (df['age']<lower_boundary)].index\ndf.drop(index=index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['age']>upper_boundary) | (df['age']<lower_boundary)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Assuming Balance follows A Gaussian Distribution we will calculate the boundaries which differentiates the outliers\n\n#### Lets compute the Interquantile range to calculate the boundaries\nIQR=df.balance.quantile(0.75)-df.balance.quantile(0.25)\n\nlower_bridge = df['balance'].quantile(0.25)-(IQR*1.5)\nupper_bridge = df['balance'].quantile(0.75)+(IQR*1.5)\nprint(lower_bridge)\nprint(upper_bridge)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['balance']>upper_bridge) | (df['balance']<lower_bridge)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = df[(df['balance']>upper_bridge) | (df['balance']<lower_bridge)].index\ndf.drop(index=index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['balance']>upper_bridge) | (df['balance']<lower_bridge)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['balance'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Outliers are handled now.__"},{"metadata":{},"cell_type":"markdown","source":"## Handling Categorical columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('index',axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['month'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary={'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12\n}\n\ndf['month']=df['month'].map(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['month'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.copy()\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.get_dummies(df1,drop_first=True)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.loc[df1['pdays']==-1,'pdays']=0\ndf1['pdays'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import ExtraTreesClassifier\n# import matplotlib.pyplot as plt\n# model=ExtraTreesClassifier()\n# model.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(10,10))\n# ranked_features=pd.Series(model.feature_importances_,index=X.columns)\n# ranked_features.nlargest(32).plot(kind='barh');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling Imbalanced Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the percentage of 0 to 1\nNo_sub = len(df[df['response'] == 0])\nSub = len(df[df['response'] == 1])\npercent_No_sub = (No_sub/len(df['response'])) * 100\npercent_sub = (Sub/len(df['response'])) * 100\n\nprint('Percentage of subsription : ',percent_sub)\nprint('Percentage of no subscription : ', percent_No_sub)\n\n\ndf['response'].value_counts().plot.bar();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df1.drop('response',axis=1)\ny = df1['response']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\nos=SMOTETomek(1)\nX_ns,y_ns = os.fit_sample(X,y)\nprint(\"The number of classes before fit {}\".format(Counter(y)))\nprint(\"The number of classes after fit {}\".format(Counter(y_ns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ns.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ns.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ns.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection for model development"},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_ns.drop(['job_management', 'job_technician', 'job_entrepreneur',\n#        'job_blue-collar', 'job_unknown', 'job_retired', 'job_admin.',\n#        'job_services', 'job_self-employed', 'job_unemployed',\n#        'job_housemaid', 'job_student'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"job = 'job_'+df['job'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"job","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ns.drop(['job_management', 'job_technician', 'job_entrepreneur',\n       'job_blue-collar', 'job_unknown', 'job_retired',\n       'job_services', 'job_self-employed', 'job_unemployed',\n       'job_housemaid', 'job_student'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'marital_'+df['marital'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ns.drop(['marital_married', 'marital_single'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ns.drop(['targeted_yes', 'default_yes'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ns.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ns.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### standarisation: We use the Standardscaler from sklearn library\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()\n### fit vs fit_transform\nscaler.fit_transform(X_ns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaled = pd.DataFrame(scaler.fit_transform(X_ns),columns=X_ns.columns)\nX_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Development"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test= train_test_split(X_scaled, y_ns, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(lr,X_scaled,y_ns,cv=15)\n\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=20, random_state=0)\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(confusion_matrix(y_test,y_pred))  \nprint(classification_report(y_test,y_pred))  \nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt','log2']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 1000,15)]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10,14]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,6,8]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n              'criterion':['entropy','gini']}\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_randomcv = RandomizedSearchCV(estimator=clf,param_distributions=random_grid,n_iter=100,cv=3,verbose=2,\n                               random_state=100,n_jobs=-1)\n### fit the randomized model\nclf_randomcv.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_randomcv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_randomcv.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_randomcv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_best_random = clf_randomcv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf_best_random.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(confusion_matrix(y_test,y_pred))  \nprint(classification_report(y_test,y_pred))  \nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Fold cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(clf_best_random,X_scaled,y_ns,cv=15)\n\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Random Forest Performs much better as its average accuracy score is 87.3% to that of Logistic regression which has an accuracy of 85.8%.__"},{"metadata":{},"cell_type":"markdown","source":"__I have used Accuracy as a metric to compare because I have handled the imbalanced data, would it be imbalanced I should have used F1-score.__"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}