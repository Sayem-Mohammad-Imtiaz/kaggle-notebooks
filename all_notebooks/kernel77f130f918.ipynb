{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-global-forecasting-week-1/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-1/train.csv\")\ndisplay(train.describe())\nprint(\"Number of Country: \", train['Country/Region'].nunique())\nprint(\"Dates from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\nprint(\"Countries with Province informed: \", train[train['Province/State'].isna()==False]['Country/Region'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_stats = train.groupby([\"Country/Region\", \"Date\"])[[\"ConfirmedCases\", \"Fatalities\"]].sum().reset_index()\nprint(\"# of Entries:\", country_stats.shape[0])\nprint(\"# of Non-Zero Entries:\", country_stats[country_stats.ConfirmedCases > 0].shape[0])\nprint(\"# of Countries:\", country_stats[\"Country/Region\"].nunique())\nprint(\"# of Countries with confirmed cases:\", country_stats[country_stats.ConfirmedCases > 0][\"Country/Region\"].nunique())\ncountry_stats.sample(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_total_date = train.groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date = train.groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Globally confirmed cases\", size=15)\nax1.set_ylabel(\"Number of cases\", size=15)\nax1.set_xlabel(\"Date\", size=15)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=15)\nax2.set_ylabel(\"Number of cases\", size=15)\nax2.set_xlabel(\"Date\", size=15)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"confirmed_total_date_woChina = train[train['Country/Region']!='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_woChina = train[train['Country/Region']!='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_woChina = confirmed_total_date_woChina.join(fatalities_total_date_woChina)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\ntotal_date_woChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=15)\nax1.set_ylabel(\"Number of cases\", size=15)\nax1.set_xlabel(\"Date\", size=15)\nfatalities_total_date_woChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=15)\nax2.set_ylabel(\"Number of cases\", size=15)\nax2.set_xlabel(\"Date\", size=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_total_date_China = train[train['Country/Region']=='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_China = train[train['Country/Region']=='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\ntotal_date_China.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date_China.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ppl_italy = 60486683.\nppl_spain = 46749696.\n\nconfirmed_Italy = train[train['Country/Region']=='Italy'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_Italy = train[train['Country/Region']=='Italy'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_Italy = confirmed_Italy.join(fatalities_Italy)\nconfirmed_Spain = train[train['Country/Region']=='Spain'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_Spain = train[train['Country/Region']=='Spain'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_Spain = confirmed_Spain.join(fatalities_Spain)\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\nplt.subplot(2, 2, 2)\ntotal_Spain.plot(ax=plt.gca(), title='Spain')\n\ntotal_Italy.ConfirmedCases = total_Italy.ConfirmedCases/ppl_italy*100.\ntotal_Italy.Fatalities = total_Italy.ConfirmedCases/ppl_italy*100.\ntotal_Spain.ConfirmedCases = total_Spain.ConfirmedCases/ppl_spain*100.\ntotal_Spain.Fatalities = total_Spain.ConfirmedCases/ppl_spain*100.\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_Italy.ConfirmedCases.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.06)\n\nplt.subplot(2, 2, 2)\ntotal_Spain.ConfirmedCases.plot(ax=plt.gca(), title='Spain')\nplt.ylim(0, 0.06)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ppl_India = 1376400726.\nppl_US = 330489477.\n\nconfirmed_India = train[train['Country/Region']=='India'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_India = train[train['Country/Region']=='India'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_India = confirmed_India.join(fatalities_India)\nconfirmed_US = train[train['Country/Region']=='US'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_US = train[train['Country/Region']=='US'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_US = confirmed_US.join(fatalities_US)\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_India.plot(ax=plt.gca(), title='India')\nplt.ylabel(\"Confirmed infection cases\", size=15)\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_US.plot(ax=plt.gca(), title='USA')\nplt.ylabel(\"Confirmed infection cases\", size=15)\n\ntotal_India.ConfirmedCases = total_India.ConfirmedCases/ppl_India*100.\ntotal_India.Fatalities = total_India.ConfirmedCases/ppl_India*100.\ntotal_US.ConfirmedCases = total_US.ConfirmedCases/ppl_US*100.\ntotal_US.Fatalities = total_US.ConfirmedCases/ppl_US*100.\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_India.ConfirmedCases.plot(ax=plt.gca(), title='India')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.06)\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_US.ConfirmedCases.plot(ax=plt.gca(), title='USA')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.06)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"confirmed_Italy = train[(train['Country/Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_Italy = train[(train['Country/Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_Italy = confirmed_Italy.join(fatalities_Italy)\n\nconfirmed_Spain = train[(train['Country/Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_Spain = train[(train['Country/Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_Spain = confirmed_Spain.join(fatalities_Spain)\n\nconfirmed_India = train[(train['Country/Region']=='India') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_India = train[(train['Country/Region']=='India') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_India = confirmed_India.join(fatalities_India)\n\nconfirmed_US = train[(train['Country/Region']=='US') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_US = train[(train['Country/Region']=='US') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_US = confirmed_US.join(fatalities_US)\n\nconfirmed_China = train[(train['Country/Region']=='China') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_China = train[(train['Country/Region']=='China') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_China = confirmed_China.join(fatalities_China)\n\n\nitaly = [i for i in total_Italy.ConfirmedCases['sum'].values]\nitaly_30 = italy[0:50] \nspain = [i for i in total_Spain.ConfirmedCases['sum'].values]\nspain_30 = spain[0:50] \nUS = [i for i in total_US.ConfirmedCases['sum'].values]\nUS_30 = US[0:50] \nIndia = [i for i in total_India.ConfirmedCases['sum'].values]\nIndia_30 = India[0:50] \nChina = [i for i in total_China.ConfirmedCases['sum'].values]\nChina_30 = China[0:50] \n\nplt.figure(figsize=(12,6))\nplt.plot(italy_30)\nplt.plot(spain_30)\nplt.plot(US_30)\nplt.plot(India_30)\nplt.plot(China_30)\nplt.legend([\"Italy\", \"Spain\", \"US\", \"India\", \"China\"], loc='upper left')\nplt.title(\"COVID-19 infections from the first confirmed case\", size=20)\nplt.xlabel(\"Days\", size=20)\nplt.ylabel(\"Infected cases\", size=20)\nplt.ylim(0, 100000)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Susceptible equation\ndef fa(N, a, b, beta):\n    fa = -beta*a*b\n    return fa\n\n# Infected equation\ndef fb(N, a, b, beta, gamma):\n    fb = beta*a*b - gamma*b\n    return fb\n\n# Recovered/deceased equation\ndef fc(N, b, gamma):\n    fc = gamma*b\n    return fc\n\n# Runge-Kutta method of 4rth order for 3 dimensions (susceptible a, infected b and recovered r)\ndef rK4(N, a, b, c, fa, fb, fc, beta, gamma, hs):\n    a1 = fa(N, a, b, beta)*hs\n    b1 = fb(N, a, b, beta, gamma)*hs\n    c1 = fc(N, b, gamma)*hs\n    ak = a + a1*0.5\n    bk = b + b1*0.5\n    ck = c + c1*0.5\n    a2 = fa(N, ak, bk, beta)*hs\n    b2 = fb(N, ak, bk, beta, gamma)*hs\n    c2 = fc(N, bk, gamma)*hs\n    ak = a + a2*0.5\n    bk = b + b2*0.5\n    ck = c + c2*0.5\n    a3 = fa(N, ak, bk, beta)*hs\n    b3 = fb(N, ak, bk, beta, gamma)*hs\n    c3 = fc(N, bk, gamma)*hs\n    ak = a + a3\n    bk = b + b3\n    ck = c + c3\n    a4 = fa(N, ak, bk, beta)*hs\n    b4 = fb(N, ak, bk, beta, gamma)*hs\n    c4 = fc(N, bk, gamma)*hs\n    a = a + (a1 + 2*(a2 + a3) + a4)/6\n    b = b + (b1 + 2*(b2 + b3) + b4)/6\n    c = c + (c1 + 2*(c2 + c3) + c4)/6\n    return a, b, c\n\ndef SIR(N, b0, beta, gamma, hs):\n    \n    \"\"\"\n    N = total number of population\n    beta = transition rate S->I\n    gamma = transition rate I->R\n    k =  denotes the constant degree distribution of the network (average value for networks in which \n    the probability of finding a node with a different connectivity decays exponentially fast\n    hs = jump step of the numerical integration\n    \"\"\"\n    # Initial condition\n    a = float(N-1)/N -b0\n    b = float(1)/N +b0\n    c = 0.\n\n    sus, inf, rec= [],[],[]\n    for i in range(10000): # Run for a certain number of time-steps\n        sus.append(a)\n        inf.append(b)\n        rec.append(c)\n        a,b,c = rK4(N, a, b, c, fa, fb, fc, beta, gamma, hs)\n\n    return sus, inf, rec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters of the model\nN = 7800*(10**6)\nb0 = 0\nbeta = 0.7\ngamma = 0.2\nhs = 0.1\n\nsus, inf, rec = SIR(N, b0, beta, gamma, hs)\n\nf = plt.figure(figsize=(8,5)) \nplt.plot(sus, 'b.', label='susceptible');\nplt.plot(inf, 'r.', label='infected');\nplt.plot(rec, 'c.', label='recovered/deceased');\nplt.title(\"SIR model\")\nplt.xlabel(\"time\", fontsize=10);\nplt.ylabel(\"Population\", fontsize=10);\nplt.legend(loc='best')\nplt.xlim(0,1000)\nplt.savefig('SIR')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ppl_China= 1437857876;\npopulation = float(ppl_China)\ncountry_df = total_China[9:]\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\n\nydata = [i for i in country_df.ConfirmedCases['sum'].values]\nxdata = country_df.day_count\nydata = np.array(ydata, dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model to global infected cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population = float(ppl_italy)\ncountry_df = total_Italy[9:]\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\n\nydata = [i for i in country_df.ConfirmedCases['sum'].values]\nxdata = country_df.day_count\nydata = np.array(ydata, dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model to global infected cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population = float(ppl_spain)\ncountry_df = total_Spain[9:]\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\n\nydata = [i for i in country_df.ConfirmedCases['sum'].values]\nxdata = country_df.day_count\nydata = np.array(ydata, dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model to global infected cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population = float(ppl_India)\ncountry_df = total_India[9:]\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\n\nydata = [i for i in country_df.ConfirmedCases['sum'].values]\nxdata = country_df.day_count\nydata = np.array(ydata, dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model to global infected cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge train and test, exclude overlap\ndates_overlap = ['2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18','2020-03-19','2020-03-20','2020-03-21','2020-03-22']\ntrain2 = train.loc[~train['Date'].isin(dates_overlap)]\nall_data = pd.concat([train2, test], axis = 0, sort=False)\n\n# Double check that there are no informed ConfirmedCases and Fatalities after 2020-03-11\nall_data.loc[all_data['Date'] >= '2020-03-12', 'ConfirmedCases'] = np.nan\nall_data.loc[all_data['Date'] >= '2020-03-12', 'Fatalities'] = np.nan\nall_data['Date'] = pd.to_datetime(all_data['Date'])\n\n# Create date columns\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year\n\n# Fill null values given that we merged train-test datasets\nall_data['Province/State'].fillna(\"None\", inplace=True)\nall_data['ConfirmedCases'].fillna(0, inplace=True)\nall_data['Fatalities'].fillna(0, inplace=True)\nall_data['Id'].fillna(-1, inplace=True)\nall_data['ForecastId'].fillna(-1, inplace=True)\n\n# Aruba has no Lat nor Long. Inform it manually\nall_data.loc[all_data['Lat'].isna()==True, 'Lat'] = 12.510052\nall_data.loc[all_data['Long'].isna()==True, 'Long'] = -70.009354\n\ndisplay(all_data)\ndisplay(all_data.loc[all_data['Date'] == '2020-03-12'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missings_count = {col:all_data[col].isnull().sum() for col in all_data.columns}\nmissings = pd.DataFrame.from_dict(missings_count, orient='index')\nprint(missings.nlargest(30, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_trend(df, lag_list, column):\n    for lag in lag_list:\n        trend_column_lag = \"Trend_\" + column + \"_\" + str(lag)\n        df[trend_column_lag] = (df[column]-df[column].shift(lag, fill_value=-999))/df[column].shift(lag, fill_value=0)\n    return df\n\n\ndef calculate_lag(df, lag_list, column):\n    for lag in lag_list:\n        column_lag = column + \"_\" + str(lag)\n        df[column_lag] = df[column].shift(lag, fill_value=0)\n    return df\n\n\nts = time.time()\nall_data = calculate_lag(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_lag(all_data, range(1,7), 'Fatalities')\nall_data = calculate_trend(all_data, [1], 'ConfirmedCases')\nall_data = calculate_trend(all_data, [1], 'Fatalities')\nall_data.replace([np.inf, -np.inf], 0, inplace=True)\nall_data.fillna(0, inplace=True)\nprint(\"Time spent: \", time.time()-ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data['Country/Region']=='Spain'].iloc[40:50][['Id', 'Province/State', 'Country/Region', 'Lat', 'Long', 'Date',\n       'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num', 'ConfirmedCases_1', 'ConfirmedCases_2', 'ConfirmedCases_3', 'Fatalities_1', 'Fatalities_2',\n       'Fatalities_3']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load countries data file\nworld_population = pd.read_csv(\"../input/population-by-country-2020/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Replace United States by US\nworld_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n\n# Remove the % character from Urban Pop values\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\nprint(\"Cleaned country details dataset\")\ndisplay(world_population)\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country/Region', right_on='Country (or dependency)', how='left')\nall_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\ndisplay(all_data)\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country (or dependency)', inplace=True, axis=1)\nall_data['Country/Region'] = le.fit_transform(all_data['Country/Region'])\nnumber_c = all_data['Country/Region']\ncountries = le.inverse_transform(all_data['Country/Region'])\ncountry_dict = dict(zip(countries, number_c)) \nall_data['Province/State'] = le.fit_transform(all_data['Province/State'])\nnumber_p = all_data['Province/State']\nprovince = le.inverse_transform(all_data['Province/State'])\nprovince_dict = dict(zip(province, number_p)) \ndisplay(all_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n# Day_num = 38 is March 1st\ny1 = all_data[(all_data['Lat']==40.0) & (all_data['Long']==-4.0) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']]\nx1 = range(0, len(y1))\nax1.plot(x1, y1, 'bo--')\nax1.set_title(\"Spain ConfirmedCases between days 39 and 49 (last 10 days)\")\nax1.set_xlabel(\"Days\")\nax1.set_ylabel(\"ConfirmedCases\")\n\ny2 = all_data[(all_data['Lat']==40.0) & (all_data['Long']==-4.0) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']].apply(lambda x: np.log(x))\nx2 = range(0, len(y2))\nax2.plot(x2, y2, 'bo--')\nax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49 (last 10 days)\")\nax2.set_xlabel(\"Days\")\nax2.set_ylabel(\"Log ConfirmedCases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter selected features\ndata = all_data.copy()\nfeatures = ['Id', 'ForecastId', 'Country/Region', 'Province/State', 'ConfirmedCases', 'Fatalities', \n       'Day_num', 'Day', 'Month', 'Year', 'Long', 'Lat']\ndata = data[features]\n\n# Apply log transformation to all ConfirmedCases and Fatalities columns, except for trends\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log(x))\n\n# Replace infinites\ndata.replace([np.inf, -np.inf], 0, inplace=True)\n\n\n# Split data into train/test\ndef split_data(data):\n    \n    # Train set\n    x_train = data[data.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n    y_train_1 = data[data.ForecastId == -1]['ConfirmedCases']\n    y_train_2 = data[data.ForecastId == -1]['Fatalities']\n\n    # Test set\n    x_test = data[data.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n\n    # Clean Id columns and keep ForecastId as index\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    index = x_test['ForecastId'].astype('int32')\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test, index\n\n\n# Linear regression model\ndef lin_reg(X_train, Y_train, X_test):\n    # Create linear regression object\n    regr = linear_model.LinearRegression()\n\n    # Train the model using the training sets\n    regr.fit(X_train, Y_train)\n\n    # Make predictions using the testing set\n    y_pred = regr.predict(X_test)\n    \n    return regr, y_pred\n\n\n# Submission function\ndef get_submission(index, df):\n    \n    prediction_1 = data_pred['Predicted_ConfirmedCases']\n    prediction_2 = data_pred['Predicted_Fatalities']\n\n    # Submit predictions\n    prediction_1 = [int(item) for item in list(map(round, prediction_1))]\n    prediction_2 = [int(item) for item in list(map(round, prediction_2))]\n    \n    submission = pd.DataFrame({\n        \"ForecastId\": df['ForecastId'].astype('int32'), \n        \"ConfirmedCases\": prediction_1, \n        \"Fatalities\": prediction_2\n    })\n    submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\nday_start = 39\ndata2 = data.loc[data.Day_num >= day_start]\n\n# Set the dataframe where we will update the predictions\ndata_pred = data[data.ForecastId != -1][['Country/Region', 'Province/State', 'Day_num', 'ForecastId']]\ndata_pred = data_pred.loc[data_pred['Day_num']>=day_start]\ndata_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\ndata_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n    \nprint(\"Currently running Logistic Regression for all countries\")\n\n# Main loop for countries\nfor c in data2['Country/Region'].unique():\n    \n    # List of provinces\n    provinces_list = data2[data2['Country/Region']==c]['Province/State'].unique()\n        \n    # If the country has several Province/State informed\n    if len(provinces_list)>1:\n        for p in provinces_list:\n            data_cp = data2[(data2['Country/Region']==c) & (data2['Province/State']==p)]\n            X_train, Y_train_1, Y_train_2, X_test, index = split_data(data_cp)\n            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n            data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n            data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_Fatalities'] = pred_2\n\n    # No Province/State informed\n    else:\n        data_c = data2[(data2['Country/Region']==c)]\n        X_train, Y_train_1, Y_train_2, X_test, index = split_data(data_c)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n        data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_Fatalities'] = pred_2\n\n# Aplly exponential transf. and clean potential infinites due to final numerical precision\ndata_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.exp(x))\ndata_pred.replace([np.inf, -np.inf], 0, inplace=True) \n\nget_submission(index, data_pred)\n\nprint(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\n# Set the dataframe where we will update the predictions\ndata_pred = data[data.ForecastId != -1][['Country/Region', 'Province/State', 'Day_num', 'ForecastId']]\ndata_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\ndata_pred['Predicted_Fatalities'] = [0]*len(data_pred)\nhow_many_days = test.Date.nunique()\n    \nprint(\"Currently running Logistic Regression for all countries\")\n\n# Main loop for countries\nfor c in data['Country/Region'].unique():\n    \n    # List of provinces\n    provinces_list = data2[data2['Country/Region']==c]['Province/State'].unique()\n        \n    # If the country has several Province/State informed\n    if len(provinces_list)>1:\n        \n        for p in provinces_list:\n            # Only fit starting from the first confirmed case in the country\n            train_countries_no0 = data.loc[(data['Country/Region']==c) & (data['Province/State']==p) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n            test_countries_no0 = data.loc[(data['Country/Region']==c) & (data['Province/State']==p) &  (data.ForecastId!=-1)]\n            data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n            # If there are no previous cases, predict 0\n            if len(train_countries_no0) == 0:\n                data_pred.loc[((data_pred['Country/Region']==c) & (data_pred['Province/State']==p)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n                data_pred.loc[((data_pred['Country/Region']==c) & (data_pred['Province/State']==p)), 'Predicted_Fatalities'] = [0]*how_many_days\n                \n            # Else run LinReg\n            else: \n                data_cp = data2[(data2['Country/Region']==c) & (data2['Province/State']==p)]\n                X_train, Y_train_1, Y_train_2, X_test, index = split_data(data_cp)\n                model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n                model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n                data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n                data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_Fatalities'] = pred_2\n\n    # No Province/State informed\n    else:\n        # Only fit starting from the first confirmed case in the country\n        train_countries_no0 = data.loc[(data['Country/Region']==c) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n        test_countries_no0 = data.loc[(data['Country/Region']==c) &  (data.ForecastId!=-1)]\n        data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n        # If there are no previous cases, predict 0\n        if len(train_countries_no0) == 0:\n            data_pred.loc[((data_pred['Country/Region']==c)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n            data_pred.loc[((data_pred['Country/Region']==c)), 'Predicted_Fatalities'] = [0]*how_many_days\n        \n        # Else, run LinReg\n        else:\n            data_c = data2[(data2['Country/Region']==c)]\n            X_train, Y_train_1, Y_train_2, X_test, index = split_data(data_c)\n            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n            data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n            data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_Fatalities'] = pred_2\n\n# Aplly exponential transf. and clean potential infinites due to final numerical precision\ndata_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.exp(x))\ndata_pred.replace([np.inf, -np.inf], 0, inplace=True) \n\n#get_submission(index, data_pred)\n\nprint(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}