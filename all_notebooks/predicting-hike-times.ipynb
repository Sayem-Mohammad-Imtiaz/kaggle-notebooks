{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29f1d135eee2bb2727eca4cd7e23cf1a4110686d"},"cell_type":"code","source":"df = pd.read_csv('../input/gpx-tracks-from-hikr.org.csv')\ndf.head(n=2)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"66789a2b1a79ecaabe3c661d3ce553df802d0968"},"cell_type":"markdown","source":"## Adding additional features\nThe difficulty rating can be changed to a numeric value for easier processing.\nMany estimators and models won't work with text values. We can simply extract the second letter which results in an ordinal encoding. Our values For categorical data which cannot be transformed that easily you may want to look into some builtin helpers like http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.CategoricalEncoder.html. Keras also has a util for one-hot-encoding https://keras.io/utils/#to_categorical"},{"metadata":{"trusted":true,"_uuid":"2ff6c14a363d0bea8d3cf8c458f0075aad8de2d2"},"cell_type":"code","source":"df['avg_speed'] = df['length_3d']/df['moving_time']\ndf['difficulty_num'] = df['difficulty'].map(lambda x: int(x[1])).astype('int32')","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"2fff0b664563dc3ce755461771da00f111b9f8bb"},"cell_type":"markdown","source":"## Removing Outliers"},{"metadata":{"trusted":true,"_uuid":"25cb3d57bc27430f69941cdfac9dc6a7da78ca87"},"cell_type":"code","source":"df.describe()","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"dfa9d084f8b21c5c2db3a9ffaefedf430c3103dd"},"cell_type":"markdown","source":"### Suspicious speed values\nLooking at min and max values it is apparent that there are some tracks which we want to exclude from our data set. An infinite average speed, or a min elevation of more than 30km below see level just don't seem right. We can remove the extremes at both sides and remove all rows where there are null values."},{"metadata":{"trusted":true,"_uuid":"c01a6b3ae863a6706f700197dc6da1b13d387e1b"},"cell_type":"code","source":"# drop na values\ndf.dropna()\ndf = df[df['avg_speed'] < 2.5] # an avg of > 2.5m/s is probably not a hiking activity","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"5c811b99788e1044f7e384cba08a97a2322ab1a3"},"cell_type":"markdown","source":"### Min elevation\nA min elevation of -32km doesn't seem right."},{"metadata":{"trusted":true,"_uuid":"864bff3a3158df026815c498e3265c329ad8ea38"},"cell_type":"code","source":"def retain_values(df, column, min_quartile, max_quartile):\n    q_min, q_max = df[column].quantile([min_quartile, max_quartile])\n    print(\"Keeping values between {} and {} of column {}\".format(q_min, q_max, column))\n    return df[(df[column] > q_min) & (df[column] < q_max)]\n\n# drop elevation outliers\ndf = retain_values(df, 'min_elevation', 0.01, 1)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"6acbe6a60fb722b37c1b2f3d767bf57f81ecb7ad"},"cell_type":"markdown","source":"## Correlations\nWe expect altitude and distance to be highly correlated with the moving time as these two features are used in most estimation formulas in use [citation needed]."},{"metadata":{"trusted":true,"_uuid":"bbccb80d617a584345d6da680b1f7b496d5f8eb9"},"cell_type":"code","source":"df.corr()","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"2d8698dfa928cd224dbf4a08419083b30b9a4e47"},"cell_type":"markdown","source":"As expected, changes in altitude and the distance have the highest correlations with the moving time. Max elevation also shows low correlation as the terrain in higher altitudes can be more challenging than in lower altitudes. Interestingly the difficulty score doesn't seem to correlate as much with the moving time. This might be due to several reasons: The difficulty score of a whole tour is based on the most difficult section, it is set by users and thus varies due to subjectivity, a difficult track may be exposed and only for experienced hikers, but it is not automatically terrain which slows one down.\n\n## Building the models\n\n### A strong baseline\nBefore putting too much time into a sophisticated model it is important to develop a simple baseline which serves as an anchor point to benchmark any other model against it. For many problems these simple baselines are already hard to beat and allow to identify approaches which can be discarded early. Given the nature of the problem, we will use a linear regression model to predict the moving time based on the most correlated fields (`length_3d`, `uphill`, `downhill` and `max_elevation`)"},{"metadata":{"trusted":true,"_uuid":"377b7ba2177ef36285ed9aaa12f0c863e85dc2bd"},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Normalizer\n\ny = df.reset_index()['moving_time']\nx = df.reset_index()[['downhill', 'uphill', 'length_3d', 'max_elevation']]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n\nlasso = Lasso()\nlasso.fit(x_train, y_train)\nprint(\"Coefficients: {}\".format(lasso.coef_))","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"baad8de6bffa2d2840afd1a428a24bfb69fc3a43"},"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\ny_pred_lasso = lasso.predict(x_test)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08544c762275daf84f9d7b0f4906129345b4ebce"},"cell_type":"code","source":"r2 = r2_score(y_test, y_pred_lasso)\nmse = mean_squared_error(y_test, y_pred_lasso)\n\nprint(\"r2:\\t{}\\nMSE: \\t{}\".format(r2, mse))","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"8ceb3fd128d8060d8228a70e6c6f5390805167af"},"cell_type":"markdown","source":"### GradientBoostingRegressor"},{"metadata":{"trusted":true,"_uuid":"169b9e57bdae86e4da2accb64b2ebceb098b473b"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbr = GradientBoostingRegressor()\ngbr.fit(x_train, y_train)\ny_pred_gbr = gbr.predict(x_test)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1ef9a9dd25675ca7117dd91e666ab2aebab9df8"},"cell_type":"code","source":"r2 = r2_score(y_test, y_pred_gbr)\nmse = mean_squared_error(y_test, y_pred_gbr)\n\nprint(\"r2:\\t{}\\nMSE: \\t{}\".format(r2, mse))","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"93bb9c875a3db193aa8e4d4ec629a585d2f6feb0"},"cell_type":"markdown","source":"### Regression with Keras"},{"metadata":{"trusted":true,"_uuid":"45f8e63232ec70f846e08bced28ba52dc7509cd4"},"cell_type":"code","source":"from keras import Sequential\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nmodel = Sequential()\nmodel.add(Dense(12, input_shape=(4,)))\nmodel.add(Dense(5, input_shape=(4,)))\nmodel.add(Dense(1))\nmodel.compile(optimizer=Adam(0.001), loss='mse')","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ad2f606966e0cd2ada7b0d1331f269dc9dd96fe"},"cell_type":"code","source":"hist = model.fit(x_train, y_train, epochs=50, batch_size=10, validation_split=0.15, \n          callbacks=[\n            ModelCheckpoint(filepath='./keras-model.h5', save_best_only=True),\n            EarlyStopping(patience=2),\n            ReduceLROnPlateau()\n          ],\n          verbose=1\n)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fff499c0a7fc5c67559ec1f7ad329a76adb85773"},"cell_type":"code","source":"model.load_weights(filepath='./keras-model.h5')\ny_pred_keras = model.predict(x_test)\n\nr2 = r2_score(y_test, y_pred_keras)\nmse = mean_squared_error(y_test, y_pred_keras)\n\nprint(\"r2:\\t{}\\nMSE: \\t{}\".format(r2, mse))","execution_count":54,"outputs":[]},{"metadata":{"_uuid":"dd3b0a97f43689541bfcbbb153a5c769129d7cca"},"cell_type":"markdown","source":"## Ensemble results"},{"metadata":{"trusted":true,"_uuid":"d6a996caa99215dbac6c5422c226e1a9025875b7"},"cell_type":"code","source":"import numpy as np\n\ncombined = (y_pred_keras[:,0] + y_pred_gbr * 2) / 3.0\nr2 = r2_score(y_test, combined)\nmse = mean_squared_error(y_test, combined)\n\nprint(\"r2:\\t{}\\nMSE: \\t{}\".format(r2, mse))","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2952ca702c4a3ddc148ad057da53c61b04fea9b1"},"cell_type":"code","source":"c = pd.DataFrame([combined, y_pred_keras[:,0], y_pred_lasso, y_pred_gbr, y_test]).transpose()\nc.columns = ['combined', 'keras', 'lasso', 'tree', 'test']\nc['diff_minutes'] = (c['test'] - c['combined']) / 60\nc.describe()","execution_count":63,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}