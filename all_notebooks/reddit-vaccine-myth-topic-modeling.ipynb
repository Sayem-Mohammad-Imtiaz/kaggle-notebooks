{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport warnings\npd.options.mode.chained_assignment = None\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-24T21:21:26.26413Z","iopub.execute_input":"2021-06-24T21:21:26.264516Z","iopub.status.idle":"2021-06-24T21:21:26.276576Z","shell.execute_reply.started":"2021-06-24T21:21:26.264485Z","shell.execute_reply":"2021-06-24T21:21:26.275515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/reddit-vaccine-myths/reddit_vm.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:26.278225Z","iopub.execute_input":"2021-06-24T21:21:26.278645Z","iopub.status.idle":"2021-06-24T21:21:26.318854Z","shell.execute_reply.started":"2021-06-24T21:21:26.278604Z","shell.execute_reply":"2021-06-24T21:21:26.317902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-processing","metadata":{}},{"cell_type":"markdown","source":"In order to get gain a better understanding of the content, the title and the body columns are combined into a single value","metadata":{}},{"cell_type":"code","source":"df['gp_sent'] = ''\nfor i, row in df.iterrows():\n    if row['title'] == 'Comment':\n        df['gp_sent'][i] =(row['body'])\n    elif row['body']!='':\n        df['gp_sent'][i] =(str(row['title']) + ' ' + str(row['body']))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:26.321117Z","iopub.execute_input":"2021-06-24T21:21:26.321794Z","iopub.status.idle":"2021-06-24T21:21:27.206449Z","shell.execute_reply.started":"2021-06-24T21:21:26.321746Z","shell.execute_reply":"2021-06-24T21:21:27.205704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing 'nan' values and rows which are empty\nindex = []\nfor i, row in df.iterrows():\n    sent = re.sub('nan', '', row['gp_sent'])\n    if not sent:\n        index.append(i)     ","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:27.208112Z","iopub.execute_input":"2021-06-24T21:21:27.208696Z","iopub.status.idle":"2021-06-24T21:21:27.347938Z","shell.execute_reply.started":"2021-06-24T21:21:27.208643Z","shell.execute_reply":"2021-06-24T21:21:27.346962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:27.349222Z","iopub.execute_input":"2021-06-24T21:21:27.349515Z","iopub.status.idle":"2021-06-24T21:21:27.354807Z","shell.execute_reply.started":"2021-06-24T21:21:27.349487Z","shell.execute_reply":"2021-06-24T21:21:27.353901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no empty rows in the dataset","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import words\nfrom nltk.corpus import stopwords\nfrom nltk import WordNetLemmatizer\nfrom spellchecker import SpellChecker\nfrom datetime import datetime\n\nlemmatizer = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:27.355975Z","iopub.execute_input":"2021-06-24T21:21:27.356245Z","iopub.status.idle":"2021-06-24T21:21:27.369276Z","shell.execute_reply.started":"2021-06-24T21:21:27.356218Z","shell.execute_reply":"2021-06-24T21:21:27.368224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing websites \n\ndf['processed'] ='' \nwebsite_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\nfor i, row in df.iterrows():\n    df['processed'][i] = ' '.join([re.sub(website_pattern,'',sent) for sent in re.split(\"[\\(\\[\\)\\]\\\\\\n]\", row['gp_sent'])])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:27.370897Z","iopub.execute_input":"2021-06-24T21:21:27.371378Z","iopub.status.idle":"2021-06-24T21:21:28.290348Z","shell.execute_reply.started":"2021-06-24T21:21:27.371332Z","shell.execute_reply":"2021-06-24T21:21:28.289199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since reddit is an informal platform, usage of colloquial spelling/abbreviation is normal. Hence, it is important to rectify such words","metadata":{}},{"cell_type":"code","source":"#identify unique words\n\ndf['cleansed']=''\nstop_words=stopwords.words('english')\n\nunique_words = []\n\nfor i, row in df.iterrows():\n    #check punctuations\n    sent  = re.sub(r'[.]*|[,]*|:|[\\n]*|nan|\\?|\"|[\\*]*|[\\t]*|[\\r]*|&|#|!|<|>|%|[\\^]*|', '', row['processed'])\n    sent = sent.replace('-',' ')\n    # remove numbers\n    sent  = re.sub(r'\\d', '', sent)\n    for word in sent.lower().split(' '):\n        if lemmatizer.lemmatize(word) not in unique_words and len(word)>2 and word not in stop_words:\n            unique_words.append(word)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:28.291931Z","iopub.execute_input":"2021-06-24T21:21:28.292413Z","iopub.status.idle":"2021-06-24T21:21:33.55707Z","shell.execute_reply.started":"2021-06-24T21:21:28.292362Z","shell.execute_reply":"2021-06-24T21:21:33.55604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(unique_words)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:33.562Z","iopub.execute_input":"2021-06-24T21:21:33.562475Z","iopub.status.idle":"2021-06-24T21:21:33.567942Z","shell.execute_reply.started":"2021-06-24T21:21:33.562429Z","shell.execute_reply":"2021-06-24T21:21:33.567008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using spell checker to map mis-spelled words to a similar word of highest weightage\n\nmisspelled_map ={}\nspell_checker = SpellChecker()\n\n#adding frequently used new words that didn't exist previously\n#with more research other new terms can also be added \nspell_checker.word_frequency.load_words(['covid', 'coronavirus', 'corona', 'astrazeneca','pfizer'])\nmisspelled_words = spell_checker.unknown(unique_words)\nlen(misspelled_words)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:33.570021Z","iopub.execute_input":"2021-06-24T21:21:33.570653Z","iopub.status.idle":"2021-06-24T21:21:33.821081Z","shell.execute_reply.started":"2021-06-24T21:21:33.570612Z","shell.execute_reply":"2021-06-24T21:21:33.820143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Of *7672* unique words, *1264* words are misspelled","metadata":{}},{"cell_type":"code","source":"#correct misspelled words\n# takes a long time to match and identify correct word. So to log progress we have a counter\n\ncount =1\nfor word in misspelled_words:\n    misspelled_map[word] = spell_checker.correction(word)\n    count = count+1\n    if count%100==0:\n        print(count)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:21:33.822577Z","iopub.execute_input":"2021-06-24T21:21:33.823162Z","iopub.status.idle":"2021-06-24T21:27:11.113337Z","shell.execute_reply.started":"2021-06-24T21:21:33.82311Z","shell.execute_reply":"2021-06-24T21:27:11.112287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace misspelled words\n\nfor i, row in df.iterrows():\n    df['cleansed'][i] = ' '.join([' '.join([misspelled_map[word] if word in misspelled_words else word for word in sent.split('-')]) for sent in row['processed'].lower().split(' ')])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:11.114452Z","iopub.execute_input":"2021-06-24T21:27:11.114733Z","iopub.status.idle":"2021-06-24T21:27:12.120147Z","shell.execute_reply.started":"2021-06-24T21:27:11.114706Z","shell.execute_reply":"2021-06-24T21:27:12.118983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting timestamp into date-time format\ndf['timestamp'] = df['timestamp'].apply(lambda x: datetime.strptime(x[0:10], '%Y-%m-%d'))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:39:33.043622Z","iopub.execute_input":"2021-06-24T21:39:33.043996Z","iopub.status.idle":"2021-06-24T21:39:33.07079Z","shell.execute_reply.started":"2021-06-24T21:39:33.043962Z","shell.execute_reply":"2021-06-24T21:39:33.069819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nsid = SentimentIntensityAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:12.161015Z","iopub.execute_input":"2021-06-24T21:27:12.161343Z","iopub.status.idle":"2021-06-24T21:27:12.326744Z","shell.execute_reply.started":"2021-06-24T21:27:12.161313Z","shell.execute_reply":"2021-06-24T21:27:12.325684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['polarity_scores'] = df['cleansed'].map(lambda x: sid.polarity_scores(x))\ndf['comp_score'] = df['polarity_scores'].map(lambda x: x['compound'])\ndf['polarity'] = df['comp_score'].map(lambda x: 'pos' if x>0 else ('neu' if x==0 else 'neg'))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:12.32808Z","iopub.execute_input":"2021-06-24T21:27:12.328468Z","iopub.status.idle":"2021-06-24T21:27:13.460176Z","shell.execute_reply.started":"2021-06-24T21:27:12.328432Z","shell.execute_reply":"2021-06-24T21:27:13.45928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.drop(['title','id','url', 'body', 'gp_sent','processed'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:39:37.336343Z","iopub.execute_input":"2021-06-24T21:39:37.336883Z","iopub.status.idle":"2021-06-24T21:39:37.344051Z","shell.execute_reply.started":"2021-06-24T21:39:37.336837Z","shell.execute_reply":"2021-06-24T21:39:37.343123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets visualize how the polarity has changed with score and comments and overtime","metadata":{}},{"cell_type":"code","source":"colors = [ \"#007000\", \"#D20005\", \"#FFBF00\"]\ncustomPalette = sns.set_palette(sns.color_palette(colors))\nfig, ax = plt.subplots(1, 2, figsize=(15,7))\nsns.histplot(x='comms_num', hue='polarity', data=data[data['comms_num']>0],palette=customPalette, ax=ax[0])\nax[0].set_xlim(1,50)\n\ncolors = [ \"#007000\", \"#FFBF00\",\"#D20005\"]\ncustomPalette = sns.set_palette(sns.color_palette(colors))\n#Change of score wrt polarity\nsns.histplot(x='score', hue='polarity', data=data,palette=customPalette, ax=ax[1])\nax[1].set_xlim(-5,30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:13.46997Z","iopub.execute_input":"2021-06-24T21:27:13.470393Z","iopub.status.idle":"2021-06-24T21:27:47.461643Z","shell.execute_reply.started":"2021-06-24T21:27:13.470362Z","shell.execute_reply":"2021-06-24T21:27:47.460445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, neg polarity is quite prominent garnering more comments and score.","metadata":{}},{"cell_type":"code","source":"# quanitfying the change in score and comments with polarity \n\nnew = data[['score','comms_num','polarity']].groupby('polarity')\nnew.mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:47.463358Z","iopub.execute_input":"2021-06-24T21:27:47.46378Z","iopub.status.idle":"2021-06-24T21:27:47.481652Z","shell.execute_reply.started":"2021-06-24T21:27:47.463735Z","shell.execute_reply":"2021-06-24T21:27:47.480134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see than more than tweets with positive and neutral polarity, those with *negative polarity has been more active* and based on its score, *producing a higher impact.*","metadata":{}},{"cell_type":"code","source":"#fig, ax = plt.subplots(figsize=(10,10))\n#sns.lineplot(x=\"timestamp\",hue=\"polarity\",data=data)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:42:40.506622Z","iopub.execute_input":"2021-06-24T21:42:40.507007Z","iopub.status.idle":"2021-06-24T21:42:40.510973Z","shell.execute_reply.started":"2021-06-24T21:42:40.506969Z","shell.execute_reply":"2021-06-24T21:42:40.509839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NMF Topic Model - Negative Tweets","metadata":{}},{"cell_type":"markdown","source":"Starting with processing negative tweets, to understand better the reason for the apprehensions towards vaccines","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import WordPunctTokenizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF;\n \n#Using WordPunctTokenizer since it accomodates separating punctuations from words\ntokenizer = WordPunctTokenizer()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:47.48317Z","iopub.execute_input":"2021-06-24T21:27:47.483485Z","iopub.status.idle":"2021-06-24T21:27:47.488493Z","shell.execute_reply.started":"2021-06-24T21:27:47.483455Z","shell.execute_reply":"2021-06-24T21:27:47.487557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_tweets(df):\n    processed =[]\n    for i, row in df.iterrows():\n        #remove numbers\n        tweet  = re.sub(r'\\d', '', row['cleansed'])\n        #tokenize the text\n        tweet = tokenizer.tokenize(tweet)\n        #remove punctuations and empty string\n        tweet = [word for word in tweet if len(word)>2 and ' ' not in word and 'nan' not in word]\n        #remove stop words\n        tweet = [word for word in tweet if word not in stop_words]\n        # Lemmatize words\n        processed.append([lemmatizer.lemmatize(word) for word in tweet])\n    return processed","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:47.489812Z","iopub.execute_input":"2021-06-24T21:27:47.490149Z","iopub.status.idle":"2021-06-24T21:27:47.505327Z","shell.execute_reply.started":"2021-06-24T21:27:47.490116Z","shell.execute_reply":"2021-06-24T21:27:47.504202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vectorize(tweet_list):\n    tfidf_vectorizer = TfidfVectorizer(min_df=3, max_df=0.85, max_features=5000,ngram_range=(1, 2), preprocessor=' '.join)\n    tfidf = tfidf_vectorizer.fit_transform(tweet_list)\n    return tfidf, tfidf_vectorizer","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:47.506999Z","iopub.execute_input":"2021-06-24T21:27:47.507432Z","iopub.status.idle":"2021-06-24T21:27:47.517234Z","shell.execute_reply.started":"2021-06-24T21:27:47.507384Z","shell.execute_reply":"2021-06-24T21:27:47.516214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nmf_topics(model, n_top_words, tfidf_vectorizer):\n    \n    feat_names = tfidf_vectorizer.get_feature_names()\n    \n    word_dict = {};\n    for i in range(n_top_words):\n        words_ids = model.components_[i].argsort()[:-15 - 1:-1]\n        words = [feat_names[key] for key in words_ids]\n        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n    \n    return pd.DataFrame(word_dict);","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:47.518816Z","iopub.execute_input":"2021-06-24T21:27:47.519256Z","iopub.status.idle":"2021-06-24T21:27:47.533Z","shell.execute_reply.started":"2021-06-24T21:27:47.519218Z","shell.execute_reply":"2021-06-24T21:27:47.531983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modeling with fixed k=5","metadata":{}},{"cell_type":"code","source":"#processing negative tweets\nneg_tweets_df = data[data[\"polarity\"] == \"neg\"]\nneg_list = process_tweets(neg_tweets_df)\nprint(neg_list[0:2])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:47.534556Z","iopub.execute_input":"2021-06-24T21:27:47.534885Z","iopub.status.idle":"2021-06-24T21:27:47.870194Z","shell.execute_reply.started":"2021-06-24T21:27:47.534853Z","shell.execute_reply":"2021-06-24T21:27:47.869062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Running a sample model wit k as 5, before choosing the optimal components\nmodel_neg = NMF(n_components=5, init='nndsvd');\ntfidf_neg, tfidf_vectorizer_neg = vectorize(neg_list)\nmodel_neg.fit_transform(tfidf_neg)\nnmf_df_neg = get_nmf_topics(model_neg, 5,tfidf_vectorizer_neg )\nnmf_df_neg[0:10]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:47.871761Z","iopub.execute_input":"2021-06-24T21:27:47.872221Z","iopub.status.idle":"2021-06-24T21:27:48.106926Z","shell.execute_reply.started":"2021-06-24T21:27:47.872173Z","shell.execute_reply":"2021-06-24T21:27:48.105827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use Coherence score to identify the optimal number of components","metadata":{}},{"cell_type":"code","source":"from gensim.models.coherencemodel import CoherenceModel\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.nmf import Nmf\nfrom operator import itemgetter","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:48.108474Z","iopub.execute_input":"2021-06-24T21:27:48.109208Z","iopub.status.idle":"2021-06-24T21:27:48.114915Z","shell.execute_reply.started":"2021-06-24T21:27:48.109159Z","shell.execute_reply":"2021-06-24T21:27:48.113889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def coherence_model(tweets):\n    topic_nums = list(np.arange(3,63,3))\n    coherence_scores =[]\n    \n    #get corpus\n    dictionary = Dictionary(tweets)\n    dictionary.filter_extremes(no_below=3,no_above=0.85,keep_n=5000)\n    corpus = [dictionary.doc2bow(word) for word in tweets]\n    \n    #compute coherence model\n    for num in topic_nums:\n        nmf = Nmf(corpus=corpus,num_topics=num,id2word=dictionary,chunksize=2000,passes=5,kappa=.1,\n                  minimum_probability=0.01,w_max_iter=300,w_stop_condition=0.0001,h_max_iter=100,\n                  h_stop_condition=0.001,eval_every=10,normalize=True,random_state=42)\n        cm = CoherenceModel(model=nmf, texts=tweets, dictionary=dictionary, coherence='c_v')\n        coherence_scores.append(round(cm.get_coherence(), 5))\n        if(num%9==0):\n            print(num)\n    return list(zip(topic_nums, coherence_scores))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:48.116885Z","iopub.execute_input":"2021-06-24T21:27:48.117695Z","iopub.status.idle":"2021-06-24T21:27:48.133261Z","shell.execute_reply.started":"2021-06-24T21:27:48.117642Z","shell.execute_reply":"2021-06-24T21:27:48.131758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neg_scores = coherence_model(neg_list)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:27:48.138236Z","iopub.execute_input":"2021-06-24T21:27:48.139105Z","iopub.status.idle":"2021-06-24T21:29:24.068762Z","shell.execute_reply.started":"2021-06-24T21:27:48.13905Z","shell.execute_reply":"2021-06-24T21:29:24.067632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neg_df  = pd.DataFrame(neg_scores)\nidmax = neg_df.iloc[:,1].idxmax(axis=1)\nbest_cv_neg, cv_neg = int(neg_df.loc[idmax][0]), neg_df.loc[idmax][1]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:29:24.070521Z","iopub.execute_input":"2021-06-24T21:29:24.070853Z","iopub.status.idle":"2021-06-24T21:29:24.078711Z","shell.execute_reply.started":"2021-06-24T21:29:24.07082Z","shell.execute_reply":"2021-06-24T21:29:24.077451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best k:{} and cv_score:{}'.format(best_cv_neg, cv_neg))\n\nfig, ax = plt.subplots(figsize=(8,7))\nsns.lineplot(data=neg_df, x=0, y=1)\nplt.xlabel('Num of components')\nplt.ylabel('CV score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:29:24.080143Z","iopub.execute_input":"2021-06-24T21:29:24.08048Z","iopub.status.idle":"2021-06-24T21:29:24.316055Z","shell.execute_reply.started":"2021-06-24T21:29:24.080449Z","shell.execute_reply":"2021-06-24T21:29:24.314888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_opt_neg = NMF(n_components=best_cv_neg, init='nndsvd');\ntfidf_opt_neg, tfidf_vectorizer_opt_neg = vectorize(neg_list)\nmodel_opt_neg.fit_transform(tfidf_opt_neg)\nnmf_df_opt_neg = get_nmf_topics(model_opt_neg, best_cv_neg,tfidf_vectorizer_opt_neg )\nnmf_df_opt_neg","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:32:30.926661Z","iopub.execute_input":"2021-06-24T21:32:30.927072Z","iopub.status.idle":"2021-06-24T21:32:31.615111Z","shell.execute_reply.started":"2021-06-24T21:32:30.927034Z","shell.execute_reply":"2021-06-24T21:32:31.614126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nEach topic gives an understanding of the reasons behind the negativeness towards vaccines.\n\nFor example,\nTopic 1 can be categorized as 'mercury(thimerosal), sodium content'\nTopic 3 : no trust\nTopic 4 : Cause Autism\nTopic 10 : death fatalities \n.\n.\netc","metadata":{}},{"cell_type":"markdown","source":"Analysing the content of each topic by manually perusal of human beings can be extremely challenging. Methods such as identifying the most important topics based on *residuals* can be adopted to overcome the disadvantage of high time consumption","metadata":{}},{"cell_type":"markdown","source":"This model can be used to gain an idea about the negatives surrounding vaccinations among the general public.","metadata":{}},{"cell_type":"markdown","source":"The same can be replicated with postive tweetsto help understand and amplify the positive opinions on vaccinations","metadata":{}}]}