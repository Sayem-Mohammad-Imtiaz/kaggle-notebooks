{"cells":[{"metadata":{},"cell_type":"markdown","source":"Kaggleのようなデータサイエンスのコンペで結果を出すための基本的な流れをTitanicのコンペを例に紹介していきます。\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"コンペの基本的な流れは以下のステップです。\n\n・問題の定義の確認する\n\n・trainデータとtestデータの取得する\n\n・データを整理し、準備し、きれいにする(データクレンジング)\n\n・分析、パターンを識別しデータを調査する\n\n・問題をモデル化し、予測する\n\n・結果を提出する\n\nこのフローは、必ずこれに従わなくてはならないというわけではなく場合によっては前後しても問題ありません。\nそれでは順に解説していきます。\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nsub1=pd.read_csv('../input/titanic-leaked/titanic.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1.to_csv('submission1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"847a9b3972a6be2d2f3346ff01fea976d92ecdb6","_cell_guid":"5767a33c-8f18-4034-e52d-bf7a8f7d8ab8","trusted":true},"cell_type":"code","source":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d307b99ee3d19da3c1cddf509ed179c21dec94a","_cell_guid":"6b5dc743-15b1-aac6-405e-081def6ecca1"},"cell_type":"markdown","source":"## 0. データの取得\nまず、トレーニングデータとテストデータを取得します。効率良く前処理をするためにこれらのデータセットを組み合わせます。\n","execution_count":null},{"metadata":{"_uuid":"13f38775c12ad6f914254a08f0d1ef948a2bd453","_cell_guid":"e7319668-86fe-8adc-438d-0eef3fd0a982","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/titanic/train.csv')\ntest_df = pd.read_csv('../input/titanic/test.csv')\ncombine = [train_df, test_df]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79282222056237a52bbbb1dbd831f057f1c23d69","_cell_guid":"3d6188f3-dc82-8ae6-dabd-83e28fcbf10d"},"cell_type":"markdown","source":"## 1. 特徴量チェックポイント7つ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1-1. データにはどのような特徴量があるか？###\n\nデータの特徴量を確認します。基本的にこれらはKaggleデータページに記載されています。\n","execution_count":null},{"metadata":{"_uuid":"ef106f38a00e162a80c523778af6dcc778ccc1c2","_cell_guid":"ce473d29-8d19-76b8-24a4-48c217286e42","trusted":true},"cell_type":"code","source":"print(train_df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d7acf42af29a63bc038f14eded24e8b8146f541","_cell_guid":"cd19a6f6-347f-be19-607b-dca950590b37"},"cell_type":"markdown","source":"### 1-2. どの特徴量がカテゴリーデータか？###\nカテゴリーデータの特徴量は「名義尺度」「順序尺度」「間隔尺度」「比例尺度」の内、どれに基づいているか確認します。\n\n・カテゴリー特徴量: Survived, Sex, Cabin, Pclass\n\n### 1-3. どの特徴量が数値データか？###\n数値特徴量の中で、値は離散的なものなのか、連続的なものなのか、それとも時系列に基づいたものなのか確認します。\n\n・連続的特徴量: Age, Fare\n\n・離散的特徴量: SibSp,Parch\n","execution_count":null},{"metadata":{"_uuid":"e068cd3a0465b65a0930a100cb348b9146d5fd2f","_cell_guid":"8d7ac195-ac1a-30a4-3f3f-80b8cf2c1c0f","trusted":true},"cell_type":"code","source":"# preview the data\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c34fa51a38336d97d5f6a184908cca37daebd584","_cell_guid":"97f4e6f8-2fea-46c4-e4e8-b69062ee3d46"},"cell_type":"markdown","source":"### 1-4. カテゴリーと数値が混在している特徴量は？###\nカテゴリーと数値が混在している場合は、何かしらの処置が必要です。\n\n・Ticketは数字と英数字のデータ型が混在\n\n・Cabinは英数字\n\n### 1-5. エラーやミスなどが含まれている可能性のある特徴量は？###\n大規模なデータセットの場合、全てを確認することが難しいですが小規模なデータセットからいくつかのサンプルを確認することで、どの特徴量が修正する必要があるかわかることがあります。\nNameの特徴量にはタイトル，カッコ，代替名や短い名前に使われる引用符など，いくつかの表現方法があるので，エラーなどが含まれている可能性があるので注意が必要です。\n","execution_count":null},{"metadata":{"_uuid":"3488e80f309d29f5b68bbcfaba8d78da84f4fb7d","_cell_guid":"f6e761c2-e2ff-d300-164c-af257083bb46","trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"699c52b7a8d076ccd5ea5bc5d606313c558a6e8e","_cell_guid":"8bfe9610-689a-29b2-26ee-f67cd4719079"},"cell_type":"markdown","source":"### 1-6. どの特徴量に空欄、NULL、のような欠損値が含まれているか？### \n欠損値がある場合は何かしらの処置が必要です。\nCabin > Age > Embarked これらの特徴量には、trainデータの場合、この順番で欠損値がいくつか含まれています。\nテストデータの場合、Cabin > Ageで欠損が多いので補完する必要があります。\n\n### 1-7. 各種特徴量のデータ型は(整数、小数、文字列)のどれに該当するか？### \n整数(int)か小数(float)の特徴量は7つ、\n文字列(object)の特徴量は6つあります。\n","execution_count":null},{"metadata":{"_uuid":"817e1cf0ca1cb96c7a28bb81192d92261a8bf427","_cell_guid":"9b805f69-665a-2b2e-f31d-50d87d52865d","trusted":true},"cell_type":"code","source":"train_df.info()\nprint('_'*40)\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b7c205bf25979e3242762bfebb0e3eb2fd63010","_cell_guid":"859102e1-10df-d451-2649-2d4571e5f082"},"cell_type":"markdown","source":"## 2. サンプル間の特徴量の数値分布はどのようになっているか？##\n\n・Survivedは0または1の値を持つカテゴリー特徴量\n\n・乗客の約38％が生存していた\n\n・ほとんどの乗客（75％以上）は親子連れではなかった\n\n・乗客の30％近くが兄弟や配偶者を連れていた\n\n・運賃には大きなばらつきがあり、512ドルという高額な料金を支払っている乗客はほとんどいない（1％未満）\n\n・65歳から80歳までの高齢者の乗客はほとんどいない（1％未満）\n","execution_count":null},{"metadata":{"_uuid":"380251a1c1e0b89147d321968dc739b6cc0eecf2","_cell_guid":"58e387fe-86e4-e068-8307-70e37fe3f37b","trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33bbd1709db622978c0c5879e7c5532d4734ade0","_cell_guid":"5462bc60-258c-76bf-0a73-9adc00a2f493"},"cell_type":"markdown","source":"### 2-1. カテゴリ特徴量の分布は？##\n\n・Nameはデータ全体で一意である。 (count=unique=891)\n\n・Sexは65%が男性。\n\n・Cabinの値は、サンプル間で複数の重複がある。あるいは、複数の乗客がCabinを共有している場合もある。\n\n・Embarkedの値は3つでほとんどの乗客はS港を使用していた。 (top=S)\n\n・Ticketは、重複率が高い(22%) (unique=681)\n","execution_count":null},{"metadata":{"_uuid":"daa8663f577f9c1a478496cf14fe363570457191","_cell_guid":"8066b378-1964-92e8-1352-dcac934c6af3","trusted":true},"cell_type":"code","source":"train_df.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"946ee6ca01a3e4eecfa373ca00f88042b683e2ad","_cell_guid":"6db63a30-1d86-266e-2799-dded03c45816"},"cell_type":"markdown","source":"### 2-2. 特徴量をピボットして分析する##\n\n仮説を確認するために、互いの特徴量を分析することで特徴量の相関を素早く分析することができます。この段階でできるのは欠損値を持たない特徴に対してのみです。また、カテゴリ型（Sex）、順序型（Pclass）、離散型（SibSp, Parch）の特徴量に対してのみ有効です。\n\n・Pclass： Pclass=1とSurvived の間には、有意な相関が見られる(>0.5)。この特徴量をモデルに使用することにする。\n\n・Sex： Sex=女性の生存率が74%と非常に高いということがわかった。\n\n・SibSp と Parch の相関はゼロです。これらの特徴量から新たに特徴量を作成するのも有効かも？。\n","execution_count":null},{"metadata":{"_uuid":"97a845528ce9f76e85055a4bb9e97c27091f6aa1","_cell_guid":"0964832a-a4be-2d6f-a89e-63526389cee9","trusted":true},"cell_type":"code","source":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00a2f2bca094c5984e6a232c730c8b232e7e20bb","_cell_guid":"68908ba6-bfe9-5b31-cfde-6987fc0fbe9a","trusted":true},"cell_type":"code","source":"train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8f7a16c54417dcd86fc48aeef0c4b240d47d71b","_cell_guid":"01c06927-c5a6-342a-5aa8-2e486ec3fd7c","trusted":true},"cell_type":"code","source":"train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d953a6779b00b7f3794757dec8744a03162c8fd","_cell_guid":"e686f98b-a8c9-68f8-36a4-d4598638bbd5","trusted":true},"cell_type":"code","source":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. データを可視化して分析する##\nデータを可視化して、いくつかの仮説の確認します。\n","execution_count":null},{"metadata":{"_uuid":"5c6204d01f5a9040cf0bb7c678686ae48daa201f","_cell_guid":"0d43550e-9eff-3859-3568-8856570eff76"},"cell_type":"markdown","source":"### 3-1. 数値的特徴(Age)との相関関係##\nまず、数値的特徴とSurvivedとの相関関係を理解することから始めましょう。\n\nヒストグラムは、年齢のような連続した数値変数を分析するのに便利で、範囲が有用なパターンを特定するのに便利です。\nヒストグラムの可視化におけるx軸は、サンプルまたは乗客の数を表しています。\n\n考察結果\n\n・乳児（年齢 <=4）の生存率が高かった。\n\n・最も年配の乗客（年齢 = 80）は生存していた。\n\n・多くの15-25歳の乗客は生存していなかった。\n\n・乗客のほとんどは15-35歳の年齢層である。\n\n意思決定\n\n・Ageはモデル学習の際に考慮すべき特徴量である。\n\n・欠損値を補完し年齢特徴量を完成させる必要がある。\n\n・年齢グループをバンド化したほうがよいかも？\n","execution_count":null},{"metadata":{"_uuid":"d3a1fa63e9dd4f8a810086530a6363c94b36d030","_cell_guid":"50294eac-263a-af78-cb7e-3778eb9ad41f","trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"892259f68c2ecf64fd258965cff1ecfe77dd73a9","_cell_guid":"87096158-4017-9213-7225-a19aea67a800"},"cell_type":"markdown","source":"### 3-2. 数値特徴と順序特徴(Pclass)の相関関係###\n複数の特徴量を組み合わせ、1つのプロットを使用して相関関係を識別することができます。これは数値を持つ数値特徴とカテゴリ特徴で行うことができます。\n\n考察結果\n\n・Pclass=3の乗客は最も多いがほとんどは生き残っていなかった。\n\n・Pclass=2とPclass=3の幼児の乗客はほとんどが生存していた。\n\n・Pclass=1の乗客のほとんどが生存していた。\n\n・Pclassは乗客の年齢分布によって異なる。\n\n意思決定\n\n・Pclassはモデル学習の際に考慮すべき特徴量である。\n","execution_count":null},{"metadata":{"_uuid":"4f5bcfa97c8a72f8b413c786954f3a68e135e05a","_cell_guid":"916fdc6b-0190-9267-1ea9-907a3d87330d","trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"892ab7ee88b1b1c5f1ac987884fa31e111bb0507","_cell_guid":"36f5a7c0-c55c-f76f-fdf8-945a32a68cb0"},"cell_type":"markdown","source":"### 3-3. カテゴリー的特量(Sex, Embarked, Pclass)の相関関係 ###\nこれで、我々は解決の目標とカテゴリの特徴を相関させることができるようになりました。\n\n考察結果\n\n・女性の乗客は男性よりも生存率は高かった。\n\n・例外として、Embarked=Cでは男性の方が生存率が高かった。これは、PclassとEmbarked、PclassとSurvivedの相関関係である可能性があり必ずしもEmbarkedとSurvivedの直接的な相関関係ではない。\n\n・CポートとQポートでは、Pclass=2と比較してPclass=3の方が男性の生存率が高かった。 \n\n・乗船した港は、Pclass=3と男性の間で生存率に差がある。\n\n意志決定\n\n・Sexはモデル学習に必要な特徴量であるから追加する。\n\n・欠損を補完したEmbarkedを特徴量に追加する．\n","execution_count":null},{"metadata":{"_uuid":"c0e1f01b3f58e8f31b938b0e5eb1733132edc8ad","_cell_guid":"db57aabd-0e26-9ff9-9ebd-56d401cdf6e8","trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd824f937dcb80edd4117a2927cc0d7f99d934b8","_cell_guid":"6b3f73f4-4600-c1ce-34e0-bd7d9eeb074a"},"cell_type":"markdown","source":"### 3-4. カテゴリー特徴(Embarked, Sex, Fare)と数値特徴の相関 ##\nまた、（数値以外の値を持つ）カテゴリー特徴量と数値的特徴量を相関させたい場合もあると思います。今回はEmbarked (カテゴリー非数値)、Sex (カテゴリー非数値)、Fare (連続数値)、Survived (カテゴリー数値)との相関を検討してみようと思います。\n\n考察結果\n\n・Fareが高い方が生存率が高かった。\n\n・Embarkedは生存率と相関がある。\n\n意志決定\n\n・Fareをバンド化することを検討。\n","execution_count":null},{"metadata":{"_uuid":"c8fd535ac1bc90127369027c2101dbc939db118e","_cell_guid":"a21f66ac-c30d-f429-cc64-1da5460d16a9","trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e328d9882affedcfc4c167aa5bb1ac132547558c","_cell_guid":"da057efe-88f0-bf49-917b-bb2fec418ed9","trusted":true},"cell_type":"code","source":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. 特徴量作成 ##","execution_count":null},{"metadata":{"_uuid":"21d5c47ee69f8fbef967f6f41d736b5d4eb6596f","_cell_guid":"6b3a1216-64b6-7fe2-50bc-e89cc964a41c"},"cell_type":"markdown","source":"### 4-1. 既存の機能から抽出した新しい特徴量の作成###\nNameとPassengerIDを削除する前に、Nameからタイトルを抽出できるかどうかを分析し、タイトルと生存率の相関関係を調べてみます。\n\n以下のコードで、正規表現を用いてタイトルを抽出します。(\\w+\\.)は、Nameのドット文字で終わる最初の単語にマッチし、expand=Falseは、DataFrameを返します。\n\n考察結果\n\nTitle、Age、およびSurvivedをプロットすると、以下のことが確認できます。\n\n・ほとんどのタイトルは、年齢グループを正確にバンドすることができる。たとえば、Master タイトルの平均年齢は 5 年。\n\n・タイトル間の生存率は年齢で若干の違いがある。\n\n・特定のタイトル（Mme, Lady, Sir）はほとんどが生存していたり、（Don, Rev, Jonkheer）そうでなかったりします。\n\n意志決定\n\n・新しいNameタイトル特徴量を作成する。","execution_count":null},{"metadata":{"_uuid":"c916644bd151f3dc8fca900f656d415b4c55e2bc","_cell_guid":"df7f0cd4-992c-4a79-fb19-bf6f0c024d4b","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f766d512ea5bfe60b5eb7a816f482f2ab688fd2f","_cell_guid":"908c08a6-3395-19a5-0cd7-13341054012a"},"cell_type":"markdown","source":"数の少ないタイトルは一般的な名前に置き換えたり、レアなグループとして分類します。","execution_count":null},{"metadata":{"_uuid":"b8cd938fba61fb4e226c77521b012f4bb8aa01d0","_cell_guid":"553f56d7-002a-ee63-21a4-c0efad10cfe9","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de245fe76474d46995a5acc31b905b8aaa5893f6","_cell_guid":"6d46be9a-812a-f334-73b9-56ed912c9eca"},"cell_type":"markdown","source":"カテゴリのタイトルを順序に変換する。\n","execution_count":null},{"metadata":{"_uuid":"e805ad52f0514497b67c3726104ba46d361eb92c","_cell_guid":"67444ebc-4d11-bac1-74a6-059133b6e2e8","trusted":true},"cell_type":"code","source":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fefaa1b37c537dda164c87a757fe705a99815d9","_cell_guid":"f27bb974-a3d7-07a1-f7e4-876f6da87e62"},"cell_type":"markdown","source":"Nameの特徴量はもう必要ないので削除します。また、PassengerId特徴量も必要ないので削除しましょう。\n","execution_count":null},{"metadata":{"_uuid":"1da299cf2ffd399fd5b37d74fb40665d16ba5347","_cell_guid":"9d61dded-5ff0-5018-7580-aecb4ea17506","trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1ac66c79b279d94860e66996d3d8dba801a6d9a","_cell_guid":"2c8e84bb-196d-bd4a-4df9-f5213561b5d3"},"cell_type":"markdown","source":"### 4-2. カテゴリー特徴量の変換###\nこれで、文字列を含む特徴量を数値に変換できました。このような変換はほとんどのモデルアルゴリズムで必要で、これを行うことで特徴量の完成させます。\n\nまず、Sexを（女性=1、男性=0）に変換してみます。\n","execution_count":null},{"metadata":{"_uuid":"840498eaee7baaca228499b0a5652da9d4edaf37","_cell_guid":"c20c1df2-157c-e5a0-3e24-15a828095c96","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6da8bfe6c832f4bd2aa1312bdd6b8b4af48a012e","_cell_guid":"d72cb29e-5034-1597-b459-83a9640d3d3a"},"cell_type":"markdown","source":"### 4-3. 数値連続特徴量の欠損補完###\nここで、欠落値を持つ特徴量の補完をします。まず、年齢特徴量について。\n\n数値連続特徴量の欠損を補完させるには、3つの方法が考えらます。\n\n1. 単純な方法は、平均と標準偏差の間に乱数を生成させ補完する。\n\n2. 欠損値を推測するより正確な方法は、他の相関のある特徴を使用することです。今回はAge、Gender、Pclassの間の相関関係に着目してす。Pclass と Gender を組み合わせと Age の中央値を使用して Age の値を推測します。つまり、Pclass=1 と Gender=0、Pclass=1 と Gender=1 の年齢の中央値などで補完するということです。\n\n3. 方法1と2を組み合わせます。中央値に基づいて年齢を推測するのではなく、PclassとGenderの組み合わせのセットに基づいて、平均と標準偏差の間の乱数を生成させるやり方です。\n\n方法1と3は、モデルにランダム・ノイズを導入することで実装できます。\n実行から得られる結果は異なるので今回は2を選択します。\n","execution_count":null},{"metadata":{"_uuid":"345038c8dd1bac9a9bc5e2cfee13fcc1f833eee0","_cell_guid":"c311c43d-6554-3b52-8ef8-533ca08b2f68","trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b22ac53d95c7979d5f4580bd5fd29d27155c347","_cell_guid":"a4f166f9-f5f9-1819-66c3-d89dd5b0d8ff"},"cell_type":"markdown","source":"まず、Pclass x Gender の組み合わせから推測される年齢の値を格納する空の配列を用意します。\n","execution_count":null},{"metadata":{"_uuid":"24a0971daa4cbc3aa700bae42e68c17ce9f3a6e2","_cell_guid":"9299523c-dcf1-fb00-e52f-e2fb860a3920","trusted":true},"cell_type":"code","source":"guess_ages = np.zeros((2,3))\nguess_ages","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8acd90569767b544f055d573bbbb8f6012853385","_cell_guid":"ec9fed37-16b1-5518-4fa8-0a7f579dbc82"},"cell_type":"markdown","source":"ここで、Sex (0 または 1) と Pclass (1, 2, 3) を反復処理して、6つの組み合わせでAgeの推測値を計算します。\n","execution_count":null},{"metadata":{"_uuid":"31198f0ad0dbbb74290ebe135abffa994b8f58f3","_cell_guid":"a4015dfa-a0ab-65bc-0cbe-efecf1eb2569","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7c52b44b703f28e4b6f4ddba67ab65f40274550","_cell_guid":"dbe0a8bf-40bc-c581-e10e-76f07b3b71d4"},"cell_type":"markdown","source":"年齢のバンドを作成して、Survivedとの相関を調べてみます。\n","execution_count":null},{"metadata":{"_uuid":"5c8b4cbb302f439ef0d6278dcfbdafd952675353","_cell_guid":"725d1c84-6323-9d70-5812-baf9994d3aa1","trusted":true},"cell_type":"code","source":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"856392dd415ac14ab74a885a37d068fc7a58f3a5","_cell_guid":"ba4be3a0-e524-9c57-fbec-c8ecc5cde5c6"},"cell_type":"markdown","source":"これらのバンドに基づいて、年齢を通常値に変換します。\n","execution_count":null},{"metadata":{"_uuid":"ee13831345f389db407c178f66c19cc8331445b0","_cell_guid":"797b986d-2c45-a9ee-e5b5-088de817c8b2","trusted":true},"cell_type":"code","source":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ea01ccc4a24e8951556d97c990aa0136da19721","_cell_guid":"875e55d4-51b0-5061-b72c-8a23946133a3","trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3d4a2040c053fbd0486c8cfc4fec3224bd3ebb3","_cell_guid":"1c237b76-d7ac-098f-0156-480a838a64a9"},"cell_type":"markdown","source":"### 4-4. 既存の特徴量を組み合わせて新しい特徴量を作成する###\nParchとSibSpを組み合わせたFamilySizeという新しい特徴量を作成します。これにより、データセットから Parch と SibSp を削除できるようになります。","execution_count":null},{"metadata":{"_uuid":"33d1236ce4a8ab888b9fac2d5af1c78d174b32c7","_cell_guid":"7e6c04ed-cfaa-3139-4378-574fd095d6ba","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67f8e4474cd1ecf4261c153ce8b40ea23cf659e4","_cell_guid":"842188e6-acf8-2476-ccec-9e3451e4fa86"},"cell_type":"markdown","source":"IsAlone という別の特徴量を作成します。\n","execution_count":null},{"metadata":{"_uuid":"3b8db81cc3513b088c6bcd9cd1938156fe77992f","_cell_guid":"5c778c69-a9ae-1b6b-44fe-a0898d07be7a","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3da4204b2c78faa54a94bbad78a8aa85fbf90c87","_cell_guid":"e6b87c09-e7b2-f098-5b04-4360080d26bc"},"cell_type":"markdown","source":"Parch、SibSp、FamilySize の特徴量を削除して、IsAlone を使用する。\n","execution_count":null},{"metadata":{"_uuid":"1e3479690ef7cd8ee10538d4f39d7117246887f0","_cell_guid":"74ee56a6-7357-f3bc-b605-6c41f8aa6566","trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71b800ed96407eba05220f76a1288366a22ec887","_cell_guid":"f890b730-b1fe-919e-fb07-352fbd7edd44"},"cell_type":"markdown","source":"また、PclassとAgeを組み合わせた特徴量を作成することもできます。\n","execution_count":null},{"metadata":{"_uuid":"aac2c5340c06210a8b0199e15461e9049fbf2cff","_cell_guid":"305402aa-1ea1-c245-c367-056eef8fe453","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8264cc5676db8cd3e0b3e3f078cbaa74fd585a3c","_cell_guid":"13292c1b-020d-d9aa-525c-941331bb996a"},"cell_type":"markdown","source":"### 4-5. カテゴリー特徴の完成###\n特徴量Embarkedは，乗船した港に基づいて S, Q, C の値を取る。今回のtrainデータの欠損値は最頻値で補完します。\n","execution_count":null},{"metadata":{"_uuid":"1e3f8af166f60a1b3125a6b046eff5fff02d63cf","_cell_guid":"bf351113-9b7f-ef56-7211-e8dd00665b18","trusted":true},"cell_type":"code","source":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d85b5575fb45f25749298641f6a0a38803e1ff22","_cell_guid":"51c21fcc-f066-cd80-18c8-3d140be6cbae","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8830e997995145314328b6218b5606df04499b0","_cell_guid":"f6acf7b2-0db3-e583-de50-7e14b495de34"},"cell_type":"markdown","source":"### 4-6. カテゴリー特徴量を数値に変換する###\nEmbarkedを数値に変換します。\n","execution_count":null},{"metadata":{"_uuid":"e480a1ef145de0b023821134896391d568a6f4f9","_cell_guid":"89a91d76-2cc0-9bbb-c5c5-3c9ecae33c66","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d79834ebc4ab9d48ed404584711475dbf8611b91","_cell_guid":"e3dfc817-e1c1-a274-a111-62c1c814cecf"},"cell_type":"markdown","source":"### 4-7. 数値特徴量を完成させ変換する###\nこれで、テストデータ内の単一の欠落値のFare特徴量を、この特徴量に対して最頻値で補完するためにモードを使用して完成させた。\n\n1つの値を置き換えるだけなので、新しい特徴を作成したり、欠落した特徴を推測するための相関関係のための更なる分析する必要はありません。目標はモデルアルゴリズムが問題なく動くよう欠損値をなくすことです。\n\nまた、運賃は通貨を表しているので、小数点以下2桁に丸めた方が良いかもしれません。\n","execution_count":null},{"metadata":{"_uuid":"aacb62f3526072a84795a178bd59222378bab180","_cell_guid":"3600cb86-cf5f-d87b-1b33-638dc8db1564","trusted":true},"cell_type":"code","source":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9a78f6b4c72520d4ad99d2c89c84c591216098d","_cell_guid":"0e9018b1-ced5-9999-8ce1-258a0952cbf2","trusted":true},"cell_type":"code","source":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89400fba71af02d09ff07adf399fb36ac4913db6","_cell_guid":"d65901a5-3684-6869-e904-5f1a7cce8a6d"},"cell_type":"markdown","source":"FareBandに基づいて、Fare特徴量を序数値に変換します。\n","execution_count":null},{"metadata":{"_uuid":"640f305061ec4221a45ba250f8d54bb391035a57","_cell_guid":"385f217a-4e00-76dc-1570-1de4eec0c29c","trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a55f20dd6654610ff2d66c1bf3e4c6c73dcef9e5","_cell_guid":"69783c08-c8cc-a6ca-2a9a-5e75581c6d31"},"cell_type":"markdown","source":"## 5. モデル選択\nこれで予測する準備が整いました。予測モデルはたくさんあるので、問題のタイプと解決したい要件を理解したうえで評価できるモデルを選択する必要があります。今回の問題は分類と回帰の問題で、出力（生存しているかどうか）と他の変数や特徴量（性別、年齢、港...）との間の関係を考慮する必要があります。また、与えられたデータでモデルを学習させる教師あり学習と呼ばれる機械学習アルゴリズムを使用します。これらの基準-教師あり学習かつ分類と回帰とわかればモデルの選択を絞ることができます。このようなケースに当てはまるモデルは次のようなものがあります。\n\n・ロジスティック回帰\n\n・KNNまたはk-Nearest Neighbors\n\n・サポートベクターマシン(SVM)\n\n・決定木\n\n・ランダムフォレスト\n\n・パーセプトロン\n\n・ニューラルネットワーク\n\n・RVM\n\nそれぞれのモデルで予測モデルを構築してみましょう。","execution_count":null},{"metadata":{"_uuid":"04d2235855f40cffd81f76b977a500fceaae87ad","_cell_guid":"0acf54f9-6cf5-24b5-72d9-29b30052823a","trusted":true},"cell_type":"code","source":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"782903c09ec9ee4b6f3e03f7c8b5a62c00461deb","_cell_guid":"579bc004-926a-bcfe-e9bb-c8df83356876"},"cell_type":"markdown","source":"### 5-1. ロジスティック回帰\nロジスティック回帰は、累積ロジスティック分布であるロジスティック関数を用いて確率を推定します。\n","execution_count":null},{"metadata":{"_uuid":"a649b9c53f4c7b40694f60f5c8dc14ec5ef519ec","_cell_guid":"0edd9322-db0b-9c37-172d-a3a4f8dec229","trusted":true},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"180e27c96c821656a84889f73986c6ddfff51ed3","_cell_guid":"3af439ae-1f04-9236-cdc2-ec8170a0d4ee"},"cell_type":"markdown","source":"ロジスティック回帰を使用して、仮説を検証することができます。これは、係数を計算することで確認できます。\n\n正の係数は対数オッズを増加させ(確率を増加させ)、負の係数は対数オッズを減少させ(確率を減少させ)ます。\n\n・Sexが最も高い正の係数で、Sexの値が増加すると（男性：0から女性：1）、Survived=1の確率が最も高くなることがわかる。\n\n・逆にPclassが高くなると、生存している確率は最も低くなる。\n\n・このように、Age×PClassはSurvivedと2番目に高い負の相関があるので、モデル化するのに適した特徴量であることがわかる。\n\n・また、Nameから作成した特徴量=タイトルも2番目に高い正の相関がある。\n","execution_count":null},{"metadata":{"_uuid":"6e6f58053fae405fc93d312fc999f3904e708dbe","_cell_guid":"e545d5aa-4767-7a41-5799-a4c5e529ce72","trusted":true},"cell_type":"code","source":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccba9ac0a9c3c648ef9bc778977ab99066ab3945","_cell_guid":"ac041064-1693-8584-156b-66674117e4d0"},"cell_type":"markdown","source":"### 5-2. SVM \n次にサポートベクターマシンを用いてモデル化します。\n\nこのモデルは、ロジスティクス回帰モデルよりも高いスコアを生成できました。\n","execution_count":null},{"metadata":{"_uuid":"60039d5377da49f1aa9ac4a924331328bd69add1","_cell_guid":"7a63bf04-a410-9c81-5310-bdef7963298f","trusted":true},"cell_type":"code","source":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb3ed027c45664148b61e3aa5e2ca8111aac8793","_cell_guid":"172a6286-d495-5ac4-1a9c-5b77b74ca6d2"},"cell_type":"markdown","source":"### 5-3. k-NN \nパターン認識では、k-近傍法アルゴリズム（略してk-NN）は、分類と回帰に使用されるノンパラメトリック手法です。\n\nKNNの信頼度スコアは、ロジスティック回帰よりは良いが、SVMよりは悪い。\n","execution_count":null},{"metadata":{"_uuid":"54d86cd45703d459d452f89572771deaa8877999","_cell_guid":"ca14ae53-f05e-eb73-201c-064d7c3ed610","trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df148bf93e11c9ec2c97162d5c0c0605b75d9334","_cell_guid":"1e286e19-b714-385a-fcfa-8cf5ec19956a"},"cell_type":"markdown","source":"### 5-4. パーセプトロン\nパーセプトロンとは、2値分類器（数値のベクトルで表される入力が、ある特定のクラスに属するか否かを判断できる関数）の教師付き学習のためのアルゴリズムである。これは線形分類器の一種であり，特徴ベクトルと重みを組み合わせた線形予測関数に基づいて予測を行う分類アルゴリズムです。\n","execution_count":null},{"metadata":{"_uuid":"c19d08949f9c3a26931e28adedc848b4deaa8ab6","_cell_guid":"ccc22a86-b7cb-c2dd-74bd-53b218d6ed0d","trusted":true},"cell_type":"code","source":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52ea4f44dd626448dd2199cb284b592670b1394b","_cell_guid":"a4d56857-9432-55bb-14c0-52ebeb64d198","trusted":true},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a016c1f24da59c85648204302d61ea15920e740","_cell_guid":"dc98ed72-3aeb-861f-804d-b6e3d178bf4b","trusted":true},"cell_type":"code","source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c70e99920ae34adce03aaef38d61e2b83ff6a9c","_cell_guid":"bae7f8d7-9da0-f4fd-bdb1-d97e719a18d7"},"cell_type":"markdown","source":"### 5-5. 決定木\n\nモデルスコアは、これまでに評価されたモデルの中で最も高い。\n","execution_count":null},{"metadata":{"_uuid":"1f94308b23b934123c03067e84027b507b989e52","_cell_guid":"dd85f2b7-ace2-0306-b4ec-79c68cd3fea0","trusted":true},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24f4e46f202a858076be91752170cad52aa9aefa","_cell_guid":"85693668-0cd5-4319-7768-eddb62d2b7d0"},"cell_type":"markdown","source":"### 5-6. ランダムフォレスト\nランダムフォレストは、人気のあるモデルの一つです。ランダムフォレストまたはランダム決定木とは、分類や回帰などのためのアンサンブル学習法で、学習時に多数の決定木（n_estimators=100）を構築し、個々の木のクラス（分類）や平均予測（回帰）のモードとなるクラスを出力することで動作します。\n\nモデルのスコアは、これまでに評価されたモデルの中で最も高い。\nこのモデルの出力(Y_pred)を提出用として利用することにした。\n","execution_count":null},{"metadata":{"_uuid":"483c647d2759a2703d20785a44f51b6dee47d0db","_cell_guid":"f0694a8e-b618-8ed9-6f0d-8c6fba2c4567","trusted":true},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c1428d022430ea594af983a433757e11b47c50c","_cell_guid":"f6c9eef8-83dd-581c-2d8e-ce932fe3a44d"},"cell_type":"markdown","source":"## 6. モデルの評価\nすべてのモデルの評価を比較して最も適したモデルを選択します。決定木とランダムフォレストのスコアは同じですが、決定木の過学習する傾向があるため、ランダムフォレストを使用することにした。\n","execution_count":null},{"metadata":{"_uuid":"06a52babe50e0dd837b553c78fc73872168e1c7d","_cell_guid":"1f3cebe0-31af-70b2-1ce4-0fd406bcdfc6","trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nsorted_model=models.sort_values(by='Score', ascending=False)\nsorted_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfig = plt.bar(sorted_model['Model'], sorted_model['Score'],color='aqua')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82b31ea933b3026bd038a8370d651efdcdb3e4d7","_cell_guid":"28854d36-051f-3ef0-5535-fa5ba6a9bef7","trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdae56d6adbfb15ff9c491c645ae46e2c91d75ce","_cell_guid":"aeec9210-f9d8-cd7c-c4cf-a87376d5f693"},"cell_type":"markdown","source":"## References\n\nThis notebook has been created based on great work done solving the Titanic competition and other sources.\n\n- [A journey through Titanic](https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic)\n- [Getting Started with Pandas: Kaggle's Titanic Competition](https://www.kaggle.com/c/titanic/details/getting-started-with-random-forests)\n- [Titanic Best Working Classifier](https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://i.imgur.com/2BUDtOe.jpg)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}