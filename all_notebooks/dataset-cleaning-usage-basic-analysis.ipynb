{"cells":[{"metadata":{},"cell_type":"markdown","source":"The purpose of this kernel is to show how to load the data, and perform basic analysis. Let's get started."},{"metadata":{},"cell_type":"markdown","source":"**Note:** I use Altair for the visualizations for this kernel. On the public side, it seems that the plots don't render. You might have to fork and run the kernel yourself to see all of the plots."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy as sp\nimport altair as alt\nimport matplotlib.pyplot as plt\nimport time\nimport pandasql as ps\n\nimport os\nos.chdir(\"/kaggle/input\")\nprint(os.listdir())\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Lets make our console outputs more nice, by applying some settings.\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nalt.renderers.enable('notebook')\nalt.data_transformers.enable('default', max_rows=None)\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Support functions for the analysis go here:\n#Solution comes from: https://stackoverflow.com/questions/34122395/reading-a-csv-with-a-timestamp-column-with-pandas\ndef date_parser(string_list):\n    return [time.ctime(float(x)) for x in string_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#First, lets load the data:\n#The header throws off our parser, so just ignore and write manually.\nacroDF = pd.read_csv(\"./reddit-scitech-acronyms/acronyms.csv\",skiprows=1,parse_dates=[1],date_parser=date_parser,\n                     names=[\"commID\",\"time\",\"user\",\"subreddit\",\"acronym\"])\n\n#Nice date formats!\nacroDF.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acroDF.dropna(inplace=True) #There are some NA acronyms.\nacroDF.count() #Now every row is fully defined. \nacroDF.describe() #Some basic information.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 142965 acronyms, and 13212 are unique. There are 55 subreddits, and 51538 users logged in the \ntable. Timestamps are almost unique. There are >1000 of them that are not considered unique by our descriptor\nfunction. Lets check this out first.\n\nWe construct a query to find timestamps that are not unique, to see their associated information."},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = \"\"\"SELECT t1.time,t1.user,t2.user FROM acroDF AS t1 INNER JOIN acroDF AS t2 ON (t1.time = t2.time) AND (t1.commID != t2.commID) \"\"\"\ntimeQueryDF = ps.sqldf(q1, locals())\ntimeQueryDF.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly, two users can both post acronyms within a 1s interval. Also, since the timestamp is mined from the posting of the comment itself, any user that posts more than one acronym in the same post will also show up in the dataset above."},{"metadata":{},"cell_type":"markdown","source":"Lets make a quick histogram of the total acronyms per subreddit. First, lets make an aggregated dataframe, \nfollowed by an altair plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"subredCount = acroDF.groupby(\"subreddit\",as_index=False).count()\nsubredCount.drop([\"commID\",\"time\",\"user\"],axis=1,inplace=True)\nsubredCount.head(5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"srList = (subredCount.sort_values(\"acronym\", ascending=False))[\"subreddit\"].tolist()\nalt.Chart(subredCount).mark_bar().encode(\nalt.X('subreddit:N',sort=srList),\nalt.Y('acronym:Q'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The BitcoinMarkets and Hardware subreddits have abnormally high counts. \n\nAre the users just prone to acronym dropping? \n\nWhat factors would affect an acronym being mentioned in a random post? \n\nFirst, lets assume that there are no causal factors, and that we have a random phenomenon with some underlying distribution. The distribution of a random acronym appearing in the next comment is p(X), where X ~ Poisson($\\lambda$), with lambda being a very small number. Then three factors would matter for the **total number of acronyms observed.** \n\n1) Age of subreddits: if an acronym is randomly dropped in conversation, then over a long time frame we should see more of them.\n\n2) Number of Subscribers: for similar reasons, if more subscribers can issue more comments, then we would see higher total counts.\n\n3) Number of Posts: '' ''\n\nNote that we can get (1) and (2) for each subreddit using the PRAW library, but it is not easy to get (3). To access submissions, you need to use a ListingGenerator. We would have to exhaust a listing generator to get an estimate for this, which we won't attempt here. I have gathered (1) and (2) for each subreddit, outside this kernel. The dataset is loaded below, and a ratio column is derived and appended to the dataframe:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#will put things in alphabetical order, by default\nsubredDF = acroDF.groupby(by=\"subreddit\",as_index=False).count()\n#dont need these columns.\nsubredDF.drop([\"commID\",\"time\",\"user\"],axis=1,inplace=True)\n#subredDF = subredDF.sort_values(by=\"user\",ascending=False)\n\nsrStatDF = pd.read_csv(\"./subredditstats/subredditstats.csv\",skiprows=1,parse_dates=[2],\n                     date_parser=date_parser,names=[\"subreddit\",\"subscribers\",\"utc_created\"])\n\nsrStatDF.sort_values(\"subreddit\",ascending=True,inplace=True)\n\n#when we add columns, they are series. So entries will be matched by indices. Looking at the two columns above,\n#one has non-ascending indices, so lets reset them\nsrStatDF.reset_index(drop=True,inplace=True)\n\nsrStatDF[\"acroCount\"] = subredDF[\"acronym\"]\n#add the acronym count column.\n#derive  an acronym ratio.\ndef f(x,y): #assume we dont have y=0!\n    return (x/y)\n#we use the clever unpacking notation (*x), because x is typed as a 2ple. we do this down the columns\nsrStatDF['acroRatio'] = srStatDF[['acroCount','subscribers']].apply(lambda x: f(*x), axis=1)\n#display the full datatable\nsrStatDF.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now lets make some Altair charts. Lets plot histograms by subscriber counts, and acroRatio."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets make our altair histogram for this.\n#We need to sort our chart in altair by counts.\n#I can't seem to get the chart sorted correctly, so we will have to provide a list of subreddits explicitly,\n#as per: https://altair-viz.github.io/user_guide/encoding.html?highlight=alt%20order#ordering-marks\n#srStatDF.sort_values(\"subscribers\", ascending=False).head(5)\nsrList = (srStatDF.sort_values(\"subscribers\", ascending=False))[\"subreddit\"].tolist()\n\nalt.Chart(srStatDF, title=\"Number of Subscribers per Subreddit\").mark_bar().encode(\nx=alt.X('subreddit:N',sort=srList),\ny=alt.Y('subscribers:Q'))\n\nsrList = (srStatDF.sort_values(\"acroRatio\", ascending=False))[\"subreddit\"].tolist()\nalt.Chart(srStatDF, title=\"Ratio of Acronyms to Subscribers, per Subreddit\").mark_bar().encode(\nx=alt.X('subreddit:N',sort=srList),\ny=alt.Y('acroRatio:Q'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see a huge range in number of subscribers (a few hundred to 20M+). Our acronym ratio column reveals that some subreddits have high numbers of acronyms, relative to their size. This debunks the \"Poisson Distribution\" idea - we should see fairly constant ratios if it were true. \n\nThis indicates that the (i) individual subscribers, (ii) their intereactions, and (iii) the topic of the subreddit probably has something to do with acronym counts. \n\n(iii) Is the easiest to tackle. The topics in question just happen to involve a lot of acronyms. Looking at the Suppliments and Programming Languages subreddits, one can easily confirm this by eye. Its not enriching to ask \"why do the topics of QuantumPhysics and Suppliments have so many acronyms\" - there are just a lot of complicated terms and acronyms are used to make conversation more brief.\n\nOur dataset doesn't say much about (i) and (ii) however. \n"},{"metadata":{},"cell_type":"markdown","source":"Next, let's look at acronyms per subreddit. Lets choose three subreddits: genetics, neuralnetworks and Nootropics"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Support local function: our chained calls are too long.\n\ndef getcountdf(aDF,subreddit):\n    temp = aDF.groupby(\"acronym\",as_index=False).count()\n    return temp.sort_values(\"subreddit\",ascending=False).reset_index(drop=True)\n\nacroFocus = acroDF.copy(deep=True) #leave intact for now.\nacroFocus.drop(['commID','time',\"user\"], axis=1, inplace=True)\nacroGroup = acroFocus.groupby(\"subreddit\",as_index=False)\n\n#Dict -> subDF return type.\n#DataFrame -> Group -> DataFrame -> Dataframe\ngeneticsCountDF = getcountdf(acroGroup.get_group(\"genetics\"), \"genetics\")\nbtcCountDF = getcountdf(acroGroup.get_group(\"BitcoinMarkets\"), \"BitcoinMarkets\")\nnnCountDF = getcountdf(acroGroup.get_group(\"neuralnetworks\"), \"neuralnetworks\")\n\ngeneticsCountDF.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualization: Bar Chart with top 75 acronyms for each subreddit.\n#Same sorting issues as last time, lets do an explicit encoding.\n\nnameList = (geneticsCountDF.sort_values(\"subreddit\", ascending=False))[\"acronym\"].tolist()\nlimit = 30\n\ngenChart = alt.Chart(geneticsCountDF[0:limit],title=\"Top Acronyms for Genetics Subreddit\").mark_bar().encode(\ny=alt.Y(\"acronym:N\",sort=nameList[0:limit]),\nx=alt.X(\"subreddit:Q\")).properties(width=300)\n\nnameList = (btcCountDF.sort_values(\"subreddit\", ascending=False))[\"acronym\"].tolist()\n\nbtcChart = alt.Chart(btcCountDF[0:limit],title=\"Top Acronyms for BitcoinMarkets Subreddit\").mark_bar().encode(\ny=alt.Y(\"acronym:N\",sort=nameList[0:limit]),\nx=alt.X(\"subreddit:Q\")).properties(width=300)\n\nnameList = (nnCountDF.sort_values(\"subreddit\", ascending=False))[\"acronym\"].tolist()\n\nnnChart = alt.Chart(nnCountDF[0:limit],title=\"Top Acronyms for Neural Networks Subreddit\").mark_bar().encode(\ny=alt.Y(\"acronym:N\",sort=nameList[0:limit]),\nx=alt.X(\"subreddit:Q\")).properties(width=300)\n\n#Here we see the power of the grammar of graphics and Altair :)\ngenChart | btcChart | nnChart","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So above, we see the most popular terms in a given subreddit. You might have noticed some of the words (particularly in the BitcoinMarkets Chart) are not acronyms. Terms like \"IMO\" , \"LOL\" are general abbreviations that are *not topic specific*. Also, people may write words in all caps out of anger, or to express a strong opinion. "},{"metadata":{},"cell_type":"markdown","source":"**In summary:** before a subset of this data is taken, a list of general acronyms and other small words (including conjunctions, prepositions, articles, pejoratives...) needs to be supplied to filter out non-topic specific terms.  "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"END"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}