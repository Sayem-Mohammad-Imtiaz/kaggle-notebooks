{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://lh3.googleusercontent.com/proxy/9c4hGTphlM6oF-ZLuK0X4g6rsEH2bDMXW4fo9tWLpUAneJersmRFs14cbrM0TQbJsDVIO6EIbu9etambTn3zLvlkvfYJgU5z5uzkPIkV-teGFh4Tw680-o6PIyVP8LHwi8IjaCJzRJWTrrd88YN9NmM)\n\n# **Bruno Dutra e Diogo Ceddia**\n# **Inteligência Artificial** \n# **Trabalho 3 - Aprendizado de Máquina**\n\n\nInicialmente, esse dataset fora escolhido devido ao seu tamanho (quase um milhão de linhas e 45 colunas). Dessa forma, é possível que possamos filtrar e preprocessar à vontade, sem que haja preocupação em reduzir demasiadamente o dataset. Inicialmente, o dataset foi divulgado com o intuito de realizar a predição do diâmetro do asteróide. Entretanto, foi de interesse da dupla proceder predição classificatória, e não regressiva, visto que nossa pouca experiência somente contemplou análise regressiva. Buscamos implementar algo que nunca haviamos tentado implementar.\n\nhttps://www.kaggle.com/basu369victor/prediction-of-asteroid-diameter/tasks"},{"metadata":{},"cell_type":"markdown","source":"# 1 - Inicialização do modelo"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ndata = pd.read_csv('/kaggle/input/asteroid-dataset/dataset.csv', low_memory=False)\n\npd.set_option('display.max_columns', 500)\n\nprint(f'Quantidade de linhas da matriz: {data.shape[0]} \\nQuantidade de colunas na matriz: {data.shape[1]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para reduzir o tamanho da matriz, assim como definir o escopo da predição:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data['class'].isin(['IMB', 'MCA', 'APO', 'AMO', 'TJN', 'TNO'])].reset_index(drop=True)\n\nprint(f'Quantidade de linhas da matriz: {data.shape[0]} \\nQuantidade de colunas na matriz: {data.shape[1]}')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deletando colunas de ID/strings de identificação que não são úteis para predição."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['id','spkid','full_name','name','orbit_id','equinox','pdes','prefix'],axis=1)\n\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Identificando colunas que tem muitos valores faltando, colunas com mais de 80% serão removidas pois não tem como tratar esses valores de forma razoável."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_rows = data.shape[0]\nmissing_values_columns = [];\n\nprint(\"Colunas a serem removidas: \\n\")\n\nfor column in data:\n    \n    not_na = (1 - (data[column].count() / total_rows)) * 100\n    \n    if(not_na > 80):\n        missing_values_columns.append(column)\n        print(column,': %.2f' % not_na)\n    else:\n        data = data[data[column].notna()]\n        \ndata = data.drop(missing_values_columns, axis='columns', inplace=False) \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataInfo = data.shape\n\nprint('Quantidade de Linhas: ', dataInfo[0])\nprint('Quantidade de Colunas: ', dataInfo[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 - Pré-Processamento"},{"metadata":{},"cell_type":"markdown","source":"Identificando as colunas que não estão representadas de forma númerica e vão precisar ser categorizadas para serem entendidas pelo modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorial_columns = []\nnumerical_columns = []\n\nfor column in data:\n    if(data[column].dtypes != \"float64\" and data[column].dtypes != \"int64\"):\n        categorial_columns.append(column)\n    else:\n        numerical_columns.append(column)\n\n# Removendo a coluna 'class' pois o modelo irá predizer esse valor\ncategorial_columns.remove('class')\n\nprint(\"Colunas a serem categorizadas: \", categorial_columns)\nprint(\"Colunas a serem scaladas: \", numerical_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Realização do data split, utilizando 10% para treinamento e 90% para validação. Como o dataset é desbalanceado, utilizamos o comando stratity para realizar uma amostragem estratificada proporcional."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Separando dataset de teste\n\nX=data.drop(['class'], axis=1)\ny=data['class']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.1, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definição das métricas para avaliação do desempenho dos modelos"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nfrom sklearn import metrics \n\nwarnings.filterwarnings('always')\n\ndef metricCalculation(classifier, y_test, pred, best_params):\n    \n    precision_metric = metrics.precision_score(y_test, pred, average = \"macro\")\n    recall_metric = metrics.recall_score(y_test, pred, average = \"macro\")\n    accuracy_metric = metrics.balanced_accuracy_score(y_test, pred)\n    f1_metric = metrics.f1_score(y_test, pred, labels=np.unique(pred), average = \"macro\")\n\n    return {\n        'classifier': str(classifier).split('(')[0],\n        'precision': round(precision_metric, 2),\n        'recall': round(recall_metric, 2),\n        'accuracy': round(accuracy_metric, 4),\n        'f1-score': round(f1_metric, 2)\n    }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3 - Execução Pipeline"},{"metadata":{},"cell_type":"markdown","source":"Nessa etapa, elencamos 4 modelos relevantes para comparação:\n\n**DecisionTreeClassifier**: que é somenteuma árvore de decisão classificatória;\n\n**ExtraTreeClassifier**: que é similar ao RandomForest, porém possivelmente mais rápido computacionalmente e insere possivelmente mais ruído na predição;\n\n**RandomForestClassifier**: que consiste na utilização de várias árvores de decisão simultaneamente;\n\n**XGBClassifier**: que são árvores de decisão com gradiente aumentado projetadas para velocidade e desempenho.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier, DecisionTreeRegressor\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\n\nfrom xgboost import XGBClassifier\n\nfrom operator import itemgetter\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import RocCurveDisplay\n\n# Compondo os pré-processadores\n\npreprocessor = ColumnTransformer(transformers=[\n    ('scaler', MinMaxScaler(), numerical_columns),\n    ('one-hot', OneHotEncoder(sparse = False), categorial_columns)    \n])\n\n#Classifier Parameters\n\nparameters = [ \n                { \n                    'clf': [DecisionTreeClassifier()],\n                    'clf__max_depth': [None, 3, 4, 5], \n                    'clf__criterion': ['gini', 'entropy'],\n                    'clf__min_samples_split': [None, 100, 1000, 10000],\n                    'clf__max_features': [ None , \"sqrt\", \"log2\"],\n                    'clf__class_weight': [None, \"balanced\"]\n                    \n                },{ \n                    'clf': [ExtraTreeClassifier()],\n                    'clf__max_depth': [None, 3, 4, 5], \n                    'clf__criterion': ['gini', 'entropy'],\n                    'clf__min_samples_split': [None, 100, 1000, 10000],\n                    'clf__max_features': [ None , \"sqrt\", \"log2\"],\n                    'clf__class_weight': [None, \"balanced\"]\n                },{\n                    'clf': [RandomForestClassifier()],\n                    'clf__random_state': [None, 100, 100, 1000],\n                    'clf__criterion': ['gini', 'entropy']\n                }, {\n                    'clf': [XGBClassifier()]\n                }\n\n]\n\nresult=[]\nmetrics_result=[]\n\nfor params in parameters:\n\n    \n    #classifier\n    clf = params['clf'][0]\n\n    #getting arguments by\n    #popping out classifier\n    params.pop('clf')\n\n    #pipeline\n    steps = [\n                ('preprocessor', preprocessor), \n                ('clf', clf)\n    ]\n    \n    kfold = KFold(n_splits=3, shuffle=True)\n\n    grid = GridSearchCV(Pipeline(steps), param_grid=params, cv=kfold, n_jobs=-1, refit=True)\n    grid.fit(X_train, y_train)\n\n    y_pred = grid.best_estimator_.predict(X_valid)\n    \n    metrics_result.append(metricCalculation(clf, y_valid, y_pred, grid.best_params_))\n    \n    #storing result\n    result.append({\n                'grid': grid,\n                'classifier': grid.best_estimator_,\n                'best score': grid.best_score_,\n                'best params': grid.best_params_,\n                'cv': grid.cv\n    })\n\n#sorting result by best score\nbest_result = sorted(result, key=itemgetter('best score'),reverse=True)\n\n#saving best classifier\nbest_grid = best_result[0]['grid']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4 - Métricas"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_results = pd.DataFrame(metrics_result)\n\nm_results = m_results.sort_values(by=['precision',\n                                      'accuracy',\n                                      'recall',\n                                      'f1-score'\n                                     ], ascending=False)\n\nm_results[0:6]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Portanto, analisamos que os modelos convergem em acurácia, e as features são capazes de explicar com muita precisão o target."},{"metadata":{},"cell_type":"markdown","source":"# 5 - Matrix de Confusão"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix\n\nfig, axn = plt.subplots(2, 2, figsize=(30, 8))\n\nplt.subplots_adjust(top=12, bottom=10)\n\nfor i, ax in enumerate(axn.flat):\n    k = result[i]\n    \n    estimator_ = k['grid'].best_estimator_\n    \n    plot_confusion_matrix(estimator_ , X_train, y_train).plot(ax=ax)\n    ax.set_title(str(estimator_['clf']).split('(')[0] ,fontsize=12)\n    \n    plt.close()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"A matriz confusão, como esperado, apresenta praticamente exclusivamente valores na diagonal principal. Isso significa que os valores preditos foram assertivos."},{"metadata":{},"cell_type":"markdown","source":"# 6 - Curva ROC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.preprocessing import label_binarize\n\nfig, axn = plt.subplots(2, 2, figsize=(30, 8))\n\nplt.subplots_adjust(top=12, bottom=10)\n\nfor i, ax in enumerate(axn.flat):\n    k = result[i]\n    \n    estimator_ = k['grid'].best_estimator_\n    \n    y_pred_ = estimator_.predict(X_valid)\n    \n    y_pred_ = label_binarize(y_pred_, classes = estimator_.classes_)\n    y_valid_ = label_binarize(y_valid, classes = estimator_.classes_)\n    \n    fpr, tpr, _ = roc_curve(y_valid_[:,1], y_pred_[:,1])\n    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n    \n    roc_display.plot(ax = ax)\n    ax.set_title(str(estimator_['clf']).split('(')[0] ,fontsize=12)\n    \n    #plt.close()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7 - Importância das Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ = best_grid.best_estimator_\nfeature_names = pipeline_['preprocessor'].transformers_[1][1].get_feature_names(categorial_columns)\n\nfeature_names = list(feature_names)\n\nfor n in numerical_columns: \n    feature_names.append(n)\n\nfeatures_imp = []\n\n\nfor r in result:\n    \n    pipeline_ = r['grid'].best_estimator_\n     \n    if hasattr(pipeline_['clf'], 'feature_importances_'):\n        \n        \n        clf_imp = pipeline_['clf']\n        \n        f_imp = pd.DataFrame(clf_imp.feature_importances_,index=feature_names, columns = [str(clf_imp).split('(')[0]])\n        features_imp.append(f_imp)\n\ndt_features_imp = pd.concat(features_imp, axis=1).sort_values(by=['RandomForestClassifier', 'XGBClassifier'], ascending=False)\n\ndt_features_imp['DecisionTreeClassifier'] = dt_features_imp['DecisionTreeClassifier'].replace({0:np.nan})\ndt_features_imp['ExtraTreeClassifier']    = dt_features_imp['ExtraTreeClassifier'].replace({0:np.nan})\ndt_features_imp['RandomForestClassifier'] = dt_features_imp['RandomForestClassifier'].replace({0:np.nan})\ndt_features_imp['XGBClassifier']          = dt_features_imp['XGBClassifier'].replace({0:np.nan})\n\ndt_features_imp[0:30]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De acordo com a análise de feature importance, observamos que a maioria das features possui baixa relevância para o sucesso do modelo, sendo possível realizar uma redução de dimensão das features. No caso do XGBClassifier, por exemplo, 3 features (epoch_mjd, i, epoch) somaram mais de 99% de importância.\n\nProcedendo somente com esse modelo (devido a ser considerado um state-of-the-art model, vencedor de diversas competições kaggle inclusive), resolvemos proceder redução de features, utilizando as 11 features mais importantes para o modelo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat((data['epoch_mjd'],\n               data['i'],\n               data['epoch'],\n               data['tp'],\n               data['H'],\n               data['epoch_cal'],\n               data['q'],\n               data['sigma_e'],\n               data['sigma_i'],\n               data['per'],\n               data['sigma_ma']\n              ),axis=1)\ny = data['class']\n\nmodel = XGBClassifier()\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0,\n                                                        train_size=0.1, stratify=y)\n        \nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_valid)\ny_pred = pd.DataFrame(y_pred,columns=['class'])\n\nprecisao = metrics.balanced_accuracy_score(y_valid, y_pred)\nprint(f'\\nA precisão do modelo é de {(precisao*100).round(3)}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Podemos concluir, então, que 11 features explicam com precisão praticamente igual ao modelo com 34 features. Essa redução de quantidade de features reduz o tempo computacional.\n\nOutro fato interessante é que utilizando comente 10% do dado para treinamento, o que dá precedente para a possibilidade de redução de linhas do dataset, com a mesma finalidade de redução de tempo computacional."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}