{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/crimes-in-boston/offense_codes.csv', encoding = 'latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#offense codes table\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv('/kaggle/input/crimes-in-boston/crime.csv', encoding = 'latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#incidents table\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop all unnecessary columns\n\ndf2.drop(['INCIDENT_NUMBER','OFFENSE_CODE','SHOOTING','YEAR','MONTH','DAY_OF_WEEK','HOUR','UCR_PART','Lat','Long','Location','STREET'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop OFFENSE_DESCRIPTION as its just a descriptive form of OFFENSE_CODE_GROUP\ndf2.drop(['OFFENSE_DESCRIPTION'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you know what...\n# lets first do it for the entire city and not district wise\n# so drop DISTRICT and REPORTING_AREA as well\n\ndf2.drop(['DISTRICT','REPORTING_AREA'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OCCURED_ON_DATE is in DATETIME \n# we are concerned only with DATE so...keep only DATE\n\ndf2['DATE'] = pd.to_datetime(df2['OCCURRED_ON_DATE']).dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# self explanatory\n\ndf2.drop(['OCCURRED_ON_DATE'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df2['OFFENSE_CODE_GROUP'].unique().tolist()) # => 67 unique types of offenses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see if all are valid ..\n# no Nan exists\n\ndf2['OFFENSE_CODE_GROUP'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#everything is valid...Gr8 !\n\n# use this if Nan exists -> df2.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#D14_dates = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = pd.pivot_table(df2, index=['DATE'], aggfunc='count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GET IT ??","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dates)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a list of all dates \nidx = pd.date_range('2015-06-15', '2018-09-03')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Luckily for us crime in a daily affair in BOSTON\n\n# Just in case it wasn't use this \n\ndates = dates.reindex(idx, fill_value = 0)\n\ndates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove column\ndates = dates.rename(columns={'OFFENSE_CODE_GROUP':'OCCURENCES'})  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\n\n# lets visualize the data over the entire available time period\n\ndates.plot()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import autocorrelation_plot\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nplot_acf(dates, lags = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pacf(dates, lags = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\nmodel = ARIMA(dates, order=(1,1,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit = model.fit(disp=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residuals = pd.DataFrame(model_fit.resid)\nresiduals.plot()\npyplot.show()\nresiduals.plot(kind='kde')\npyplot.show()\nprint(residuals.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nD = dates.values\nsize = int(len(D) * 0.66)\ntrain, test = D[0:size], D[size:len(D)]\nhistory = [x for x in train]\npredictions = list()\n\nfor t in range(len(test)):\n    model = ARIMA(history, order=(1,1,7))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)\n    print('predicted= %f, expected = %f' %(yhat,obs))\n    \nerror = mean_squared_error(test, predictions)\nprint(' Test MSE : %3f' %error)\n\n\npyplot.plot(test)\npyplot.plot(predictions, color= 'red')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}