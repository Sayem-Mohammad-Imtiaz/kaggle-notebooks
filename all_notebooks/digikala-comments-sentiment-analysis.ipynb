{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom spacy.lang.fa import stop_words\nfrom string import punctuation, printable, digits\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load & Explore","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/digikala-comments-persian-sentiment-analysis/data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by='Score').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# column 'Suggestion' is not needed\ndf = df.drop(['Suggestion'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Score'] = (df['Score']/10).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter only extreme cases, cases in betweem are a combination of pos and neg reviews\ndf = df.loc[(df['Score']<6) | (df['Score']>7)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:,'label'] = df['Score'].apply(lambda score: 1 if score>7 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(['Positive','Negative'], df['label'].value_counts()/df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we see that the dataset is not much balanced","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# train and test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, test_X, train_y, test_y = train_test_split(df['Text'].values, df['label'].values, stratify=df['label'])\ntrain_X.shape, train_y.shape, test_X.shape, test_y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_stopwords():\n    f = open(\"/kaggle/input/farsi-stopwords/fa_stop_words.txt\", \"r\", encoding='utf8')\n    stopwords = f.read()\n    stopwords = stopwords.split('\\n')\n    stopwords = set(stopwords)\n    custom_stop_words = {'آنكه','آيا','بدين','براين','بنابر','میشه','میکنه','باشه','سلام','میکشه','اونی',''}\n    stopwords = stopwords | stop_words.STOP_WORDS | custom_stop_words\n    # excluding space\n    stopwords = list(stopwords)[1:]\n    unwanted_num = {'خوش','بهتر','بد','خوب','نیستم','عالی','نیست','فوق','بهترین'} \n    stopwords = [ele for ele in stopwords if ele not in unwanted_num] \n    return stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we make a transformer so that we can use it in a pipeline\nclass Preprocess(BaseEstimator, TransformerMixin):\n    def __init__(self, stop_words):\n        self.stop_words = stop_words\n    def fit(self, X, y=None):\n        return self\n    def transform(self, corpus):\n        res = []\n        for data in corpus:\n            if not self.stop_words:\n                self.stop_words = set([])\n            ## ensure working with string\n            doc = str(data)\n            # First remove punctuation form string\n            PUNCT_DICT = {ord(punc): None for punc in punctuation+'،'}\n            doc = doc.translate(PUNCT_DICT)\n            # remove numbers\n            doc = doc.translate({ord(k): None for k in digits})\n            tokens = doc.split()\n            tokens = [t for t in tokens if len(t) > 1]\n            res.append(' '.join(w for w in tokens if w not in self.stop_words))\n        return res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's see how the preprocessing turns out","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 10\nprint(train_X[idx])\nPreprocess(load_stopwords()).transform([train_X[idx]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text_clf = Pipeline([\n    ('prep', Preprocess(load_stopwords())),\n    ('vect', CountVectorizer()),\n    ('clf', MultinomialNB()),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_clf.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(train_y, text_clf.predict(train_X)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = text_clf.predict(test_X)\nprint(classification_report(test_y, test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check classifier mistakes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(test_X)[test_pred!=test_y][10:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}