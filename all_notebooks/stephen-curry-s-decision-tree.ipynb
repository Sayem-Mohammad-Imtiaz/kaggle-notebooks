{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"67727ec4-1b39-5020-8996-4dd924c6a5e9"},"source":"On the occasion of the 2017 playoffs:\n\n 1. Can we predict Stephen Curry's shot outcome?\n 2. If so - can we build a model that would help Stephen improve is field goals?\n 3. Or, alternatively, can we give the basic guidelines for a naive AI basketball player for when to shot?\n 4. And would the Warriors redeem themselves this year?\n\nI will try to answer questions 1-3 in this script.\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee9ba1f0-05eb-ff5a-73b2-36cfc5eda4f0"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nmatplotlib.style.use('fivethirtyeight')\n\nfrom sklearn import tree\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"d3b4ea61-e27e-fa20-c394-9054646fcfae"},"source":"Read the Data and calculate Curry's field goals:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc3f2cc2-9455-35dc-b6cc-12e901b1f9d6"},"outputs":[],"source":"shots = pd.read_csv('../input/shot_logs.csv')\nplayer_name = 'stephen curry'\nplayer_df = shots[shots.player_name == player_name]\nprint(np.true_divide(len(player_df[player_df.FGM == 1]),len(player_df)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"aa797acd-7691-ece1-c86c-297a487a5a1f"},"source":"Curry's field goals percents are 48%, which means the most naive classifier that would assume all Curry's shot are out (and what a mistake that would be) would acheive an accuracy of 52%. Let's see how a decision tree is compared to this benchmark\n\nLet's also visualize the tree using the great graphviz library:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a2ae016d-d7a6-dff8-9722-7dfedf8b3254"},"outputs":[],"source":"player_df['LOCATION'][player_df.LOCATION == 'H'] = 1\nplayer_df['LOCATION'][player_df.LOCATION == 'A'] = 0\n\nplayer_df = player_df.drop(['GAME_ID','MATCHUP','W','FINAL_MARGIN','SHOT_RESULT', 'CLOSEST_DEFENDER_PLAYER_ID','GAME_CLOCK','player_name','player_id','PTS','CLOSEST_DEFENDER'], axis = 1)\nplayer_df = player_df[~np.isnan(player_df.SHOT_CLOCK) == True ]\n\nX_train, X_test, y_train, y_test = train_test_split(\n     player_df.drop(['FGM'], axis = 1), player_df.FGM, test_size=0.33, random_state=42)\n\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 3,min_samples_leaf = 5)\ndecision_tree.fit(X_train, y_train)\n\n\ny_pred = decision_tree.predict(X_test)\n\ndiff = y_pred - y_test\nprint(np.true_divide(len(diff[diff == 0]),len(y_test)))\n\n\nwith open(\"tree1.dot\", 'w') as f:\n     f = tree.export_graphviz(decision_tree,\n                              out_file=f,\n                              max_depth = 5,\n                              impurity = False,\n                              feature_names = X_test.columns.values,\n                              class_names = ['No', 'Yes'],\n                              rounded = True,\n                              filled= True )\n        \n#Convert .dot to .png to allow display in web notebook\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n\n# Annotating chart with PIL\nimg = Image.open(\"tree1.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"0ab13eab-e4f3-d4eb-7d58-cea729409fda"},"source":"There are a few leafs/buckets with low gini coefficient:\n\n - for shot distance<5.95 feet, with touch time longer than 0.95 seconds\n   and closest defender <2.65 feet\n - for shot distance > 5.95 feet and closest defender distance < 0.95\n   feet. **This is also by far the most common case**\n\nThese cases accounts for 509 of the training data shots. \n\nThe other 121 shots are easier to predict. That is:\n\n 1. When the shot is from close distance with a short touch time (probably meaning that someone spotted Curry free under the rim and passed him the ball) - it would probably go in\n 2. When the shot is from close distance, after a long touching time and the closest defender is far away (porobably a fast break) - it would probably go in\n 3. When the shot is from far away and the closest defender is very close - it would probably go out\n4. When the shot is from middle range and the closest defender is not necessarily very close - it would probably go in\n5. When the distance is very large, it would probably go out (there are very few shots like that, which means this might be the end-of-the-quarter shot from distance)\n\nLet's explore the features importance:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"178bad10-0b5a-9a39-e5f2-b159b6a651e8"},"outputs":[],"source":"plt.bar(range(len(X_test.columns.values)), decision_tree.feature_importances_)\nplt.xticks(range(len(X_test.columns.values)),X_test.columns.values, rotation= 45)\nplt.title('Feature Importance')"},{"cell_type":"markdown","metadata":{"_cell_guid":"b61ab07e-e719-7eef-86da-e8549d07be66"},"source":"It seems that the classifier primarily uses the shot distance, as well as the distance from the closest defender, which makes sense. Let's see how much we can improve the classifier by increasing the depth and using more features, before we start to overfit:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b44afe1-4dfc-e927-f69e-ad7928b8de91"},"outputs":[],"source":"train_score = []\ntest_score = []\nfor depth in np.arange(1,20):\n    decision_tree = tree.DecisionTreeClassifier(max_depth = depth,min_samples_leaf = 5)\n    decision_tree.fit(X_train, y_train)\n    train_score.append(decision_tree.score(X_train,y_train))\n    test_score.append(decision_tree.score(X_test,y_test))\n\nplt.plot(np.arange(1,20),train_score)\nplt.plot(np.arange(1,20),test_score)\nplt.legend(['Training Accuracy','Validation Accuracy'])\nplt.xlabel('Depth')\nplt.ylabel('Accuracy')"},{"cell_type":"markdown","metadata":{"_cell_guid":"50de0dbe-3ab9-7125-2b36-d56a943df1b1"},"source":"Max depth of 5 looks like a reasonable choice. Let's explore the feature importance with this configuration:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30527850-74ec-dd18-06a2-d62fca89adf5"},"outputs":[],"source":"player_name = 'stephen curry'\nplayer_df = shots[shots.player_name == player_name]\n\nplayer_df['LOCATION'][player_df.LOCATION == 'H'] = 1\nplayer_df['LOCATION'][player_df.LOCATION == 'A'] = 0\n\nplayer_df = player_df.drop(['GAME_ID','MATCHUP','W','FINAL_MARGIN','SHOT_RESULT', 'CLOSEST_DEFENDER_PLAYER_ID','GAME_CLOCK','player_name','player_id','PTS','CLOSEST_DEFENDER'], axis = 1)\nplayer_df = player_df[~np.isnan(player_df.SHOT_CLOCK) == True ]\n\nX_train, X_test, y_train, y_test = train_test_split(\n     player_df.drop(['FGM'], axis = 1), player_df.FGM, test_size=0.33, random_state=42)\n\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 5,min_samples_leaf = 5)\ndecision_tree.fit(X_train, y_train)\n\n\ny_pred = decision_tree.predict(X_test)\n\ndiff = y_pred - y_test\nprint(np.true_divide(len(diff[diff == 0]),len(y_test)))\n\nplt.bar(range(len(X_test.columns.values)), decision_tree.feature_importances_)\nplt.xticks(range(len(X_test.columns.values)),X_test.columns.values, rotation= 45)\nplt.title('Feature Importance')"},{"cell_type":"markdown","metadata":{"_cell_guid":"53aff561-f53c-9ac7-a327-80536b7fd846"},"source":"Using this very simple model we can improve the accuracy up to 60%. Which still doesn't look like a huge improvement from the random guess. \n\nThe most important features in our model are:\n\n 1. Shot distance\n 2. Closest defender distance\n 3. Touch time\n 4. Shot number (this maybe interesting from the famous \"Hot Hand\" perspective)\n 5. Number of dribbles\n 6. Shot clock"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}