{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verificação da estrutura de dados\npd.read_csv('/kaggle/input/congressional-voting-records/house-votes-84.csv').head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A opção na_valeus define as respostas registradas como '?' como valores nulos\ndf = pd.read_csv('/kaggle/input/congressional-voting-records/house-votes-84.csv',na_values=['?'])\n# usando a função raplace do pandas para alterar as resposas para binarios\ndf.replace(('y', 'n'), (1, 0), inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# avaliação da estutura dos dados e os dados faltantes \ndf.info()\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# analise sobre as respostas \n# é interessandte avaliar que as opiniões são divergentes o que separa bem os as classes \nindice = df.drop('Class Name', axis=1).columns \nz = 0\nfig, axes = plt.subplots(4, 4, figsize=(30, 15))# define uma tabela de 10 X 10 são 10 elementos para cada tipo de elemento \nfor i in range(4): # renge de 0 até 4\n    #indice = np.where(y_train == i)[0] # seleciona as imagens de cada tipo para ser plotada no grafico.\n    for j in range(4): # plotar 4 elementos de cada ponto        \n        sns.countplot(x = indice[z+j], hue='Class Name', data=df, palette='RdBu', ax=axes[i][j])\n        # retirar as escalas e cordenadas da imagem \n        axes[i][j].set_yticks([])\n    z = z + j + 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# usando a função raplace do pandas para alterar o label para 0 e 1\ndf.replace(('democrat', 'republican'), (0, 1), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dividindo as feature de analise e resposta\ny = df['Class Name'].values\nX = df.drop('Class Name', axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# para trabalhar como os dados faltantes\n# função aplica os valores mais frequentes de cada coluna nos valores faltantes\nimp = SimpleImputer(strategy=\"most_frequent\")\nX = imp.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# avaliação base de alguns modelos de classificação\ndef evaluate_model(X, y, model):\n    K = 5\n    R = 3\n    # validação cruzada\n    cv = RepeatedStratifiedKFold(n_splits=K, n_repeats=R, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    return scores\n\n# seleção de modelos \ndef get_models():\n    models, names = list(), list()\n    # SVM\n    models.append(LogisticRegression())\n    names.append('LG')\n    \n    models.append(KNeighborsClassifier())\n    names.append('KNN')\n    \n    models.append(RandomForestClassifier(n_estimators=1000))\n    names.append('RF')\n    \n    models.append(ExtraTreesClassifier(n_estimators=1000))\n    names.append('ET')\n    \n    return models, names\n\n# avaiação do modelo AUC\ndef evaluate(model, test_features, test_labels):\n    probs_votos = model.predict_proba(test_features)\n    accuracy = roc_auc_score(test_labels, probs_votos[:,1])\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Avaliação dos modelos \nmodels, names = get_models()\n\nresults = list()\n\nfor i in range(len(models)):\n    scores = evaluate_model(X, y, models[i])\n    results.append(scores)\n    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# após avaliação inicial vamos realizar um ajuste dos hiperparâmetros dos dois melhores modelos atráves do GridSearch\n# divisão dos dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#grid search do random forest\n# definição de cada paramentro\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\n# Criação do grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state = 42)\n# avaliação cruzada utilizando 3 folds, \nrf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n                              n_iter = 100, scoring='neg_mean_absolute_error', \n                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n                              return_train_score=True)\n\n# Fit\nrf_random.fit(X_train, y_train)\nprint('Melhores parametros:',rf_random.best_params_)\n# seleção do melhor modelo e avaliação da acuracia do modelo \nbest_random = rf_random.best_estimator_\n#fazendo a predição nos arquivos de teste\ny_pred = best_random.predict(X_test)\n# avaliação da acuracia do modelo\nacc_vote = accuracy_score(y_test, y_pred)\nprint(\"acuracia: \",acc_vote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#metirca de avaliação da curva roc\nprint(\"AUC:\" ,evaluate(best_random, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# definindo hiperparâmetros do grid\ngrid = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\nprint(grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Regreção logistica para classificação \n# definindo hiperparâmetros do grid\ngrid = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\nlogreg = LogisticRegression()\nlogreg_cv = GridSearchCV(logreg,grid,cv=10)\nlogreg_cv.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"melhores parametros :\",logreg_cv.best_params_)\nprint(\"acurácia com dados de treino:\",logreg_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecionando o melhor modelo, fazendo a predição e \nbest_lot = logreg_cv.best_estimator_\ny_pred_log = best_lot.predict(X_test)\nacc_log_vote = accuracy_score(y_test, y_pred_log)\nprint(\"accuracy_score:\",acc_log_vote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#metirca de avaliação da curva roc\nprint(\"AUC:\" ,evaluate(best_lot, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os dois modelos performaram muito bem, pois a divergencia de ideias entre os grupos divide muito bem os dados faciliando a criação de um modelo com boa acurácia.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}