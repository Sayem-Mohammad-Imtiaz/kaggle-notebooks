{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Regression Challenge\n\nBy: Muhammad Alwy Shihab (Fresh Graduate of Statistics, Unpad)\n\nPredicting the selling price of a residential property depends on a number of factors, including the property age, availability of local amenities, and location.\n\nIn this challenge, you will use a dataset of real estate sales transactions to predict the price-per-unit of a property based on its features. The price-per-unit in this data is based on a unit measurement of 3.3 square meters.\n\n> **Citation**: The data used in this exercise originates from the following study:\n>\n> *Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.*\n>\n> It was obtained from the UCI dataset repository (Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository]([http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science).\n\n## Review the data\n\nRun the following cell to load the data and view the first few rows."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# load the training dataset\ndata = pd.read_csv('../input/microsoftchallenge2/real_estate.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data consists of the following variables:\n\n- **transaction_date** - the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\n- **house_age** - the house age (in years)\n- **transit_distance** - the distance to the nearest light rail station (in meters)\n- **local_convenience_stores** - the number of convenience stores within walking distance\n- **latitude** - the geographic coordinate, latitude\n- **longitude** - the geographic coordinate, longitude\n- **price_per_unit** house price of unit area (3.3 square meters)\n\n## Train a Regression Model\n\nYour challenge is to explore and prepare the data, identify predictive features that will help predict the **price_per_unit** label, and train a regression model that achieves the lowest Root Mean Square Error (RMSE) you can achieve (which must be less than **7**) when evaluated against a test subset of data.\n\nAdd markdown and code cells as required to create your solution."},{"metadata":{},"cell_type":"markdown","source":"## Use the Trained Model\n\nSave your trained model, and then use it to predict the price-per-unit for the following real estate transactions:\n\n| transaction_date | house_age | transit_distance | local_convenience_stores | latitude | longitude |\n| ---------------- | --------- | ---------------- | ------------------------ | -------- | --------- |\n|2013.167|16.2|289.3248|5|24.98203|121.54348|\n|2013.000|13.6|4082.015|0|24.94155|121.50381|"},{"metadata":{},"cell_type":"markdown","source":"## ANSWER"},{"metadata":{},"cell_type":"markdown","source":"### Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\ndata.boxplot(column='price_per_unit',vert=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Outlier\ndata = data[data['price_per_unit'] < 70]\ndata.boxplot(column='price_per_unit',vert=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train a Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = data[data.columns[1:-1]].values, data[data.columns[-1]].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\nprint ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### ORDINARY LEAST SQUARE ###\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(X_train, y_train)\nprint('intercept:', model.intercept_)\nprint('slope:', model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate the Trained Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\nnp.set_printoptions(suppress=True)\nprint('Predicted labels: ', np.round(predictions)[:10])\nprint('Actual labels   : ', y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actual')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\n\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\n\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Try Another Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"### LASSO ###\nfrom sklearn.linear_model import Lasso\nmodel = Lasso().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### DECISSION TREE ###\n\nfrom sklearn.tree import DecisionTreeRegressor\nmodel = DecisionTreeRegressor().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### RANDOM FOREST ###\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### GRADIENT BOOSTING ###\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nmodel = GradientBoostingRegressor().fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### GRADIENT BOOSTING (WITH GRID SEARCH APPROACH) ###\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, r2_score\n\nalg = GradientBoostingRegressor()\n\nparams = {\n 'learning_rate': [0.1, 0.5, 1.0],\n 'n_estimators' : [50, 100, 150]\n}\n\nscore = make_scorer(r2_score)\ngridsearch = GridSearchCV(alg, params, scoring=score, cv=3, return_train_score=True)\ngridsearch.fit(X_train, y_train)\nprint(\"Best parameter combination:\", gridsearch.best_params_, \"\\n\")\n\nmodel = gridsearch.best_estimator_\n\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, predictions)\nprint(\"R2:\", r2)\n\nplt.scatter(y_test, predictions)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nplt.title('Predictions vs Actuals')\n\nz = np.polyfit(y_test, predictions, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='magenta')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setelah mencoba beberapa model, diperoleh model dengan **Gradient Boosting (with Grid Search Approach)** memiliki nilai RMSE paling kecil, yakni 5.98, dan R2 paling besar, yakni 69%. Sehingga model tersebut akan digunakan untuk memprediksi data baru."},{"metadata":{},"cell_type":"markdown","source":"### Predict New Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new = np.array([[16.2,289.3248,5,24.98203,121.54348],\n                  [13.6,4082.015,0,24.94155,121.5038]])\npredict = model.predict(X_new)\nprint('Predictions:')\nfor prediction in predict:\n    print(round(prediction,2))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}