{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T19:32:16.408502Z","iopub.execute_input":"2021-08-04T19:32:16.408948Z","iopub.status.idle":"2021-08-04T19:32:16.414284Z","shell.execute_reply.started":"2021-08-04T19:32:16.408908Z","shell.execute_reply":"2021-08-04T19:32:16.413243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '../input/bitcoin-tweets/Bitcoin_tweets.csv'\n\ndf = pd.read_csv(file_path, sep=',')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:32:22.412708Z","iopub.execute_input":"2021-08-04T19:32:22.413162Z","iopub.status.idle":"2021-08-04T19:32:31.16724Z","shell.execute_reply.started":"2021-08-04T19:32:22.413125Z","shell.execute_reply":"2021-08-04T19:32:31.165997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's limit the tweets to the following sources : Twitter Web App, Twitter Android, Twitter iPhone\nsources = ['Twitter Web App', 'Twitter for Android ', 'Twitter for iPhone']\ndf = df[df.source.isin(sources)]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:32:38.560704Z","iopub.execute_input":"2021-08-04T19:32:38.56117Z","iopub.status.idle":"2021-08-04T19:32:38.726992Z","shell.execute_reply.started":"2021-08-04T19:32:38.561134Z","shell.execute_reply":"2021-08-04T19:32:38.725671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's format the user_verified column : convert to string & replace by 1 if true and 0 otherwise\nfunc = lambda x: 1 if x=='True' else 0\n\ndf['user_verified'] = df['user_verified'].map(lambda x:func(str(x)))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:32:41.040187Z","iopub.execute_input":"2021-08-04T19:32:41.04061Z","iopub.status.idle":"2021-08-04T19:32:41.446321Z","shell.execute_reply.started":"2021-08-04T19:32:41.040577Z","shell.execute_reply":"2021-08-04T19:32:41.444909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.user_verified.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:32:45.391242Z","iopub.execute_input":"2021-08-04T19:32:45.391615Z","iopub.status.idle":"2021-08-04T19:32:45.403341Z","shell.execute_reply.started":"2021-08-04T19:32:45.391585Z","shell.execute_reply":"2021-08-04T19:32:45.402189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['is_retweet','user_friends','user_favourites','source'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:32:51.034113Z","iopub.execute_input":"2021-08-04T19:32:51.034557Z","iopub.status.idle":"2021-08-04T19:32:51.137399Z","shell.execute_reply.started":"2021-08-04T19:32:51.03452Z","shell.execute_reply":"2021-08-04T19:32:51.136169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"### Let's explore the user descriptions, their tweets and hashtags. Let's limit the exploration to the verified users","metadata":{}},{"cell_type":"code","source":"df_verified = df[df.user_verified==1]\ncols = ['user_description', 'text', 'hashtags']\npd.set_option('max_colwidth', None)\ndf_verified[df_verified.user_verified==1][cols]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:34:03.045695Z","iopub.execute_input":"2021-08-04T19:34:03.046132Z","iopub.status.idle":"2021-08-04T19:34:03.079739Z","shell.execute_reply.started":"2021-08-04T19:34:03.046096Z","shell.execute_reply":"2021-08-04T19:34:03.078611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's preprocess the tweets\n\nimport re \nimport nltk\n\n# Import nltk stopwords and customize it to add common crypto words that don't add too much information \nstopwords = nltk.corpus.stopwords.words('english')\ncrypto_words = ['btc','bitcoin','eth','etherum','crypto']\n\nstopwords = stopwords + crypto_words\n\ndef preprocess_tweet(tweet, stopwords):\n    \n    tweet = tweet.lower()\n    \n    tweet = tweet.replace('\\n\\n',' ')\n    \n    # remove english stopwords\n    tweet = ' '.join([word for word in tweet.split() if word not in stopwords])\n    \n    # regular expression that preprocess tweets\n    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", tweet).split())\n    \n    return tweet","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:34:09.071842Z","iopub.execute_input":"2021-08-04T19:34:09.07223Z","iopub.status.idle":"2021-08-04T19:34:09.080493Z","shell.execute_reply.started":"2021-08-04T19:34:09.072197Z","shell.execute_reply":"2021-08-04T19:34:09.07948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_verified['preprocess_tweets'] = df_verified['text'].map(lambda x:preprocess_tweet(x, stopwords=stopwords))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:34:12.5795Z","iopub.execute_input":"2021-08-04T19:34:12.580315Z","iopub.status.idle":"2021-08-04T19:34:13.025943Z","shell.execute_reply.started":"2021-08-04T19:34:12.580257Z","shell.execute_reply":"2021-08-04T19:34:13.024883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef words_cloud(df, col):\n    \n    text = ' '.join(str(comment) for comment in df[col])\n    \n    wordcloud = WordCloud(stopwords=stopwords, width=800, height=400, background_color=\"white\",max_words=70).generate(text)\n    \n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.rcParams['figure.figsize'] = (20, 20)\n    plt.axis(\"off\")\n    plt.show()\n\nwords_cloud(df_verified, 'preprocess_tweets')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:34:43.257183Z","iopub.execute_input":"2021-08-04T19:34:43.257737Z","iopub.status.idle":"2021-08-04T19:34:44.541661Z","shell.execute_reply.started":"2021-08-04T19:34:43.257693Z","shell.execute_reply":"2021-08-04T19:34:44.540837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef vocab(df, col, nb_words, stopwords):\n    \n    vocab = df[col].str.split(expand=True).stack().value_counts().head(50).to_dict()\n    \n    vocab_sw = {key:value for (key,value) in vocab.items() if key not in stopwords}\n   \n    return dict(itertools.islice(vocab_sw.items(), nb_words))\n   \n   \n   \ndef plot_words(vocab):\n    \n    plt.rcParams['figure.figsize'] = (20, 10)\n    plt.show()\n\n    plt.xlim(0,len(vocab))\n    plt.xticks(rotation=90,fontsize=14)\n    plt.bar(vocab.keys(), vocab.values(), width=0.3, color='g')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:34:56.613146Z","iopub.execute_input":"2021-08-04T19:34:56.613804Z","iopub.status.idle":"2021-08-04T19:34:56.62197Z","shell.execute_reply.started":"2021-08-04T19:34:56.613631Z","shell.execute_reply":"2021-08-04T19:34:56.620848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_words(vocab(df_verified, 'preprocess_tweets', 40, stopwords))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:34:58.195825Z","iopub.execute_input":"2021-08-04T19:34:58.196395Z","iopub.status.idle":"2021-08-04T19:34:58.752138Z","shell.execute_reply.started":"2021-08-04T19:34:58.196348Z","shell.execute_reply":"2021-08-04T19:34:58.751106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sentiment Analysis\n\nLet's use the transformers pretrained model","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline('sentiment-analysis')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:35:07.850633Z","iopub.execute_input":"2021-08-04T19:35:07.851387Z","iopub.status.idle":"2021-08-04T19:35:14.60922Z","shell.execute_reply.started":"2021-08-04T19:35:07.851328Z","shell.execute_reply":"2021-08-04T19:35:14.607842Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test on a single tweet\nclassifier('Ark Invest believes Teslaâ€™s purchase of billions in bitcoin is a tipping point for the digital asset as it relates')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:35:17.748348Z","iopub.execute_input":"2021-08-04T19:35:17.74874Z","iopub.status.idle":"2021-08-04T19:35:17.843132Z","shell.execute_reply.started":"2021-08-04T19:35:17.748706Z","shell.execute_reply":"2021-08-04T19:35:17.841353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sentiment_score(tweet):\n    return classifier(tweet)[0]['score']\n\ndef get_sentiment_label(tweet):\n    return classifier(tweet)[0]['label']\n\ndf_verified['sentiment_score'] = df_verified['preprocess_tweets'].map(lambda x:get_sentiment_score(x))\ndf_verified['sentiment_label'] = df_verified['preprocess_tweets'].map(lambda x:get_sentiment_label(x))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:35:38.936835Z","iopub.execute_input":"2021-08-04T19:35:38.937432Z","iopub.status.idle":"2021-08-04T19:42:05.848307Z","shell.execute_reply.started":"2021-08-04T19:35:38.937376Z","shell.execute_reply":"2021-08-04T19:42:05.846911Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_verified[['preprocess_tweets','sentiment_score','sentiment_label']]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:45:23.721593Z","iopub.execute_input":"2021-08-04T19:45:23.722175Z","iopub.status.idle":"2021-08-04T19:45:23.741536Z","shell.execute_reply.started":"2021-08-04T19:45:23.722132Z","shell.execute_reply":"2021-08-04T19:45:23.740369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_verified.sentiment_score.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:42:57.085994Z","iopub.execute_input":"2021-08-04T19:42:57.086423Z","iopub.status.idle":"2021-08-04T19:42:57.109138Z","shell.execute_reply.started":"2021-08-04T19:42:57.086385Z","shell.execute_reply":"2021-08-04T19:42:57.107946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_verified.sentiment_label.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:45:58.307577Z","iopub.execute_input":"2021-08-04T19:45:58.308073Z","iopub.status.idle":"2021-08-04T19:45:58.319794Z","shell.execute_reply.started":"2021-08-04T19:45:58.308031Z","shell.execute_reply":"2021-08-04T19:45:58.318778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}