{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\n### In this notebook we use for Land Cover Classfication from Satellite Imagery using [DeepGlobe Land Cover Classification Dataset](https://www.kaggle.com/balraj98/deepglobe-land-cover-classification-dataset) using fastai Datablock API"},{"metadata":{},"cell_type":"markdown","source":"We begin by importing the requisite libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from fastai.vision.all import *\nfrom fastai.data.all import *\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The structure of this dataset is a bit strange. It has 'train', 'test' and 'valid' datasets but only train dataset has the '.png' masks. I think the idea is to create masks from the '.jpg'images in 'test' and 'valid' folders but for the purpose of this notebook, I am using only the train dataset and splitting it into train valid. The 'train' folder has 1606 images files, 803 of them are '.jpg' and 803 are '.png'. The '.jpg' are the images and '.png' are the masks which classify the pixels into different classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/deepglobe-land-cover-classification-dataset/train')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The class_dict.csv file has the rgb values for each class of the masks. The values are as follows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/deepglobe-land-cover-classification-dataset/class_dict.csv')\ncodes = df1['name']\n\ncodes=array(codes, dtype=str)\n\ndf1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FastAI Datablock API has a PILMask.create method which prepares the masks for segmentation. This method opens the 3 channel '.png'image file using 'L' mode of the [PIL module](https://pillow.readthedocs.io/en/4.1.x/reference/Image.html). This mode calculates the luminance using the rgb values, maps the luminance values onto a 1 channel image. The luminance values are calculated in the 'pixel_value' column of the dataframe below. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['pixel_value'] =  round(df1['r'] * 299/1000 + df1['g'] * 587/1000 + df1['b'] * 114/1000,0).astype(int, copy=False)\ndf1.sort_values(by='pixel_value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I far as I understand from [This notebook](https://colab.research.google.com/github/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/07_Binary_Segmentation.ipynb#scrollTo=9SuB5y-DIZuT), FastAI does not work with the non-consecutive values for the segmentation classes. So, These values have to be mapped on to a list of correponding consecutive values. For this, I created a dictionary 'p2d' as follows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"vals = [0,29,105,150,179,226,255]\np2d = dict()\nfor i, val in enumerate(vals):\n    p2d[val] = i\np2d","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the '.jpg' files are collected as the items and the corresponding '.png' files are collected as masks. "},{"metadata":{"trusted":true},"cell_type":"code","source":"items = partial(get_files, extensions='.jpg')\ndef masks(o): return path/f'{o.stem[:-4]}_mask.png'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The get_msk function maps the pixel values in tensors of the masks to the cosecutive pixels as defined in the p2d dictionary above. The datablock API can then link the consecutive numerical pixel values to the segmentation class names as shown in the 'names' column of the dataframe df1."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_y(clas_dic):\n    def get_msk(fn):\n        mask = masks(fn)\n        mask_img=PILMask.create(mask)\n        mask_tensor = tensor(mask_img)\n        for i in vals:\n            mask_tensor[mask_tensor == i] = clas_dic[i]\n        return mask_tensor\n    return get_msk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_split(pct):\n    def fn(name_list):\n        train_x,valid_x = RandomSplitter(valid_pct=0.1)(name_list)\n        np.random.shuffle(train_x)\n        train_idx = int(len(train_x)*pct)\n        train_ = train_x[0:train_idx]\n        return train_, valid_x\n    return fn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dblock = DataBlock(blocks=(ImageBlock, MaskBlock(codes=codes)),\n                    get_items = items,\n                    get_y = get_y(p2d),\n                    splitter = custom_split(0.5),\n                    item_tfms=[Resize(128)],\n                    batch_tfms =[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dsets = dblock.datasets(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dsets.train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = dblock.dataloaders(path, bs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls.show_batch(max_n = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls.vocab = codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name2id = {v:k for k,v in enumerate(codes)}\nvoid_code= name2id['unknown']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = unet_learner(dls, resnet34)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(2, lr_max=3.9e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.export(fname = Path(\"/kaggle/working/export.pkl\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}