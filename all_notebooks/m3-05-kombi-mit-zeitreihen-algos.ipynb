{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport m3utils\nfrom sklearn.ensemble import RandomForestRegressor\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True) # falls plotly mal nichts anzeigt, diese Zelle wieder ausführen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pmdarima","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = m3utils.load_covid_19_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_predict(features):\n    df = features.copy()\n    df['Country/Region'] = df['Country/Region'].cat.codes\n    df['date'] = m3utils.date_to_days(df['date'])\n    \n    result = m3utils.train_predict(df, 7, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', RandomForestRegressor(), ['date'])\n    \n    result['date'] = m3utils.days_to_date(result['date'])\n    result['Country/Region'] = features['Country/Region'].cat.categories[result['Country/Region'].astype('int')]\n    return result\n\nm3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kombination mit klassischen Zeitreihen-Verfahren\nDieses Notebook zeigt, wie klassische Zeitreihen-Verfahren in Kombination mit den üblichen Machine-Learning-Algorithmen genutzt werden können. Die klassischen Zeitreihen-Verfahren haben einige Vorteile.\n\n<img src=\"https://i.ibb.co/bPnPnT8/tsalgos.jpg\" border=\"0\"/>\n\n- Trend und Saisonalität: sind direkt eingebaute Konzepte\n- Datensparsamkeit: pressen aus wenigen Daten alles raus, z.B. reichen 2 Jahre Daten, um die jährliche Saisonalität zu bestimmen\n- Flexibilität: wenn z.B. ein neues Produkt kommt und dafür noch keine Saisonalität bekannt ist, können wir auf die Saisonalität vom Gesamtmarkt oder einem ähnlichen Produkt ausweichen\n- Extrapolation: anders als die baumbasierten-Verfahren sind die Zeitreihen-Verfahren sehr gut darin zu extrapolieren – also einen Trend in die Zukunft fortzusetzen.\n\nDie Pakete [statsmodels](https://www.statsmodels.org) und [pmdarima](http://alkaline-ml.com/pmdarima/) enthalten viele gängige Zeitreihen-Verfahren.\n\n## Dekomposition der Zeitreihe in Trend, Saisonalität und Residuum\n\nDie Methode `seasonal_decompose` nimmt die Dekomposition einer Zeitreihe in Trend, Saisonalität und Residuum vor. Das Standardmodell ist additiv: $Y_t=T_t+S_t+R_t$\n\nFür die Dekomposition wird zuerst die Trend-Komponente bestimmt. Im Standardfall passiert dies mit einem gleitenden Durchschnitt über ein Fenster der Größe der Periode der Zeitreihe. Die Periode der Zeitreihe wird aus der zeitlichen Auflösung der Zeitreihe und dem saisonalen Muster bestimmt:\n\n* **monatliche Daten, jährliche Saisonalität** (Monate sind jedes Jahr ähnlich): `period=12`\n* **tägliche Daten, wöchentliche Saisonalität** (Tage sind jede Woche ähnlich): `period=7`\n* **quartalsweise Daten, jährliche Saisonalität** (Quartale sind jedes Jahr ähnlich): `period=4`\n* **stündliche Daten, tägliche Saisonalität** (Stunden sind jeden Tag ähnlich): `period=24`\n* **tägliche Daten, jährliche Saisonalität** (Tage sind jedes Jahr ähnlich): `period=?` (Schaltjahre sind doof)\n* **wöchentliche Daten, jährliche Saisonalität** (Wochen sind jedes Jahr ähnlich): `period=?` (Arithmetik mit Kalenderwochen ist auch doof)","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndf2 = df.set_index('date')\ns = df2.loc[df2['Country/Region']=='Germany', 'value_daily']\n\ndecomp = seasonal_decompose(s, period=7)\nplot_df = pd.DataFrame({'date': s.index, 'original': s, 'trend': decomp.trend, 'seasonal': decomp.seasonal, 'residuals': decomp.resid}).melt(id_vars='date')\n\nfig = px.line(plot_df, x='date', y='value', facet_row='variable')\nfig.update_yaxes(matches=None)\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1]))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Das wöchentliche Muster in der Zeitreihe ist gut in der Saisonalitätskomponente zu erkennen. Problematisch ist, dass das Residuum ein klares Muster bei niedrigen Levels der Zeitreihe aufweist und die Varianz des Residuums bei hohen Levels steigt. Das additive Modell, das wir für die Dekomposition genutzt haben passt in diesem Fall nicht und wahrscheinlich ist ein multiplikativer Ansatz besser: $Y_t=T_t \\cdot S_t \\cdot R_t$ ","metadata":{}},{"cell_type":"code","source":"decomp = seasonal_decompose(s+1, model='m', period=7) # im Multiplikativen Modell sind keine Werte=0 erlaubt\nplot_df = pd.DataFrame({'date': s.index, 'original': s, 'trend': decomp.trend, 'seasonal': decomp.seasonal, 'residuals': decomp.resid}).melt(id_vars='date')\n\nfig = px.line(plot_df, x='date', y='value', facet_row='variable')\nfig.update_yaxes(matches=None)\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1]))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Slippery when wet: Data Leakage\n\nDie statistischen Verfahren operieren auf der gesamten Zeitreihe. Dadurch kann es dazu kommen, dass wir beim Feature Engineering Informationen aus der Zukunft nutzen, was wir ja dringend vermeiden möchten. Ein Beispiel dafür...","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nts = df.loc[df['Country/Region']=='Germany', 'value_daily']\ntrend = seasonal_decompose(ts, model='additive', two_sided=True, period=7).trend\n\nts.loc[1797:] = 0\n\ntrend_with_break = seasonal_decompose(ts, model='additive', two_sided=True, period=7).trend # ändern auf two_sided=False\n\nfig = px.line(pd.DataFrame({'original': trend, 'with break': trend_with_break}))\n\nfig.add_vline(x=1797, line_dash=\"dash\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Beispiel für eine Vorhersage mit ARIMA\n\nFür die Vorhersagen von Zeitreihen können wir z.B. ein ARIMA-Modell benutzen. Die Klasse [`AutoARIMA`](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.AutoARIMA.html) aus pmdarima ermittelt automatisch die am besten passenden Hyperparameter für uns.\n","metadata":{}},{"cell_type":"code","source":"%%time\nimport pmdarima as pm\n\nts = df.loc[df['Country/Region']=='Germany', 'value_daily']\n# Laufzeit ca. 1-2 Minute\n#arima = pm.auto_arima(ts, error_action='ignore', suppress_warnings=True, maxiter=10, seasonal=True, m=7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Weil die Methode aber eine Weile braucht, können wir die passenden Parameter auch selber an die Klasse [ARIMA](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.ARIMA.html) übergeben und mit der Methode `fit` das Training auslösen.","metadata":{}},{"cell_type":"code","source":"arima = pm.arima.ARIMA((5,1,5),(2,0,2,7), with_intercept=False, suppress_warnings=True)\narima.fit(ts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Die Methode `predict` auf dem trainierten Objekt macht dann die Vorhersage","metadata":{}},{"cell_type":"code","source":"prediction = arima.predict(7)\nprediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecast_date = df['date'].max()\n\nresult = pd.DataFrame()\nresult['date'] = m3utils.days_to_date(pd.Series(range(1,7+1)), forecast_date)\nresult['Country/Region'] = 'Germany'\nresult['Country/Region'] = result['Country/Region'].astype(df['Country/Region'].dtype)\nresult['value_daily_predicted'] = prediction\nresult\n\nresult = result.append(df.loc[(df['date'] <= forecast_date) & (df['Country/Region']=='Germany')][['Country/Region', 'date', 'value_daily']])\nresult\n\npx.line(result,\n        x='date', y=['value_daily_predicted', 'value_daily'],\n        title='Vorhersage mit ARIMA-Modell', labels=dict(date='Datum', value=''))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Weiterführende Informationen zu den Zeitreihen-Algos\n\nhttps://otexts.com/fpp3/\n\n<img src=\"https://otexts.com/fpp3/figs/fpp2_cover.jpg\"/>\n\n# Übung","metadata":{}},{"cell_type":"markdown","source":"## 1. Aufgabe - Vorhersage mit ARIMA\n\nWir starten damit, das Du eine Validierung der Vorhersagen mit ARIMA machst. Schreibe dafür eine Methode `train_predict_arima`, die die Daten annimmt und dann für jedes Land (`Country/Region`) ein ARIMA-Modell fitted und die Vorhersage macht. Du kannst die Hyperparameter für das ARIMA-Modell von oben übernehmen. Die Methode `train_predict_arima` sollte einen DataFrame zurückliefern mit den Spalten `date`, `Country/Region` und `value_daily_predicted`. **Eine gute Vorlage dafür ist der Code von oben, der für den Plot der Vorhersage genutzt wurde.**\n\nErstelle zuerst den Code für die Vorhersage eines Landes, dann für mehrere Länder und verpacke erst dann den Code die Methode und mache eine Crossvalidation.","metadata":{}},{"cell_type":"code","source":"# Hier ausprobieren","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_predict_arima(features):\n    # Dein Code hier\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hier validieren\n#m3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict_arima, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Aufgabe - Saisonalität außerhalb vom ML-Modell [optional]\n\nUm die Vorhersagen von ARIMA mit einem ML-Modell zu kombinieren, brauchen wir Ensemble-Techniken, die wir noch nicht vorgestellt haben. Es gibt aber eine andere Möglichkeit von den statistischen Verfahren zu profitieren. Du kannst die Saisonalität, die wir oben mit der Methode `seasonal_decompose` aus den Daten entfernen bevor Du das ML-Modell trainierst und die Saisonalität dann wieder den Vorhersagen hinzufügen.","metadata":{}},{"cell_type":"code","source":"# hier ausprobieren","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_predict_decompose(features):\n    df = features.copy()\n    df['Country/Region'] = df['Country/Region'].cat.codes\n    df['date'] = m3utils.date_to_days(df['date'])\n    \n    df['seasonal'] = 1 # hier statt 1 die Saisonalität je Gruppe mit Pandas apply und seasonal_decompose ermitteln\n    # hier die Saisonalität aus value_daily entfernen\n    \n    result = m3utils.train_predict(df, 7, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', RandomForestRegressor(), ['date', 'seasonal'])\n    \n    # hier die Saisonalität je Gruppe wieder hinzufügen, Idee: die letzten 7 aus df mit Pandas GroupBy.tail(7) ermitteln\n    \n    result['date'] = m3utils.days_to_date(result['date'])\n    result['Country/Region'] = features['Country/Region'].cat.categories[result['Country/Region'].astype('int')]\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hier validieren\n#m3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict_arima, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Musterlösung: 1. Aufgabe - Vorhersage mit ARIMA","metadata":{}},{"cell_type":"code","source":"def train_predict_arima(df):\n    forecast_date = df['date'].max()\n    arima = pm.arima.ARIMA((5,1,5),(2,0,2,7), with_intercept=False, suppress_warnings=True)\n\n    result = pd.DataFrame()\n\n    countries = df['Country/Region'].unique()\n    for country in countries:\n        arima.fit(df.loc[df['Country/Region']==country]['value_daily'])\n        prediction = arima.predict(7)\n\n        tmp = pd.DataFrame()\n        tmp['date'] = m3utils.days_to_date(pd.Series(range(1,7+1)), forecast_date)\n        tmp['Country/Region'] = country\n        tmp['Country/Region'] = tmp['Country/Region'].astype(df['Country/Region'].dtype)\n        tmp['value_daily_predicted'] = prediction\n        result = result.append(tmp)\n    return(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict_arima, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Musterlösung: 2. Aufgabe - Saisonalität außerhalb vom ML-Modell [optional]","metadata":{}},{"cell_type":"code","source":"def train_predict_decompose(features):\n    df = features.copy()\n    df['Country/Region'] = df['Country/Region'].cat.codes\n    df['date'] = m3utils.date_to_days(df['date'])\n    \n    df['seasonal'] = df.groupby('Country/Region', observed=True)['value_daily'].apply(lambda x: seasonal_decompose(x+1, model='m', period=7).seasonal)\n    df['value_daily'] = df['value_daily']/df['seasonal']\n    \n    result = m3utils.train_predict(df, 7, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', RandomForestRegressor(), ['date'])\n    \n    seasonal = df[['Country/Region', 'date', 'seasonal']].groupby('Country/Region', observed=True).tail(7).copy()\n    seasonal['date'] = seasonal['date'] + 7\n    result = result.merge(seasonal, on=['Country/Region', 'date'])\n    result['value_daily_predicted_unadjusted'] = result['value_daily_predicted']\n    result['value_daily_predicted'] = result['value_daily_predicted'] * result['seasonal']\n    \n    result['date'] = m3utils.days_to_date(result['date'])\n    result['Country/Region'] = features['Country/Region'].cat.categories[result['Country/Region'].astype('int')]\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict_decompose, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}