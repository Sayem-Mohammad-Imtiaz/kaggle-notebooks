{"cells":[{"metadata":{"trusted":true,"_uuid":"daa0256d71b9880b5db9a91e2a92710a884c0b4c"},"cell_type":"code","source":"rm ./celeba_clf.keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b983378cb22f8fe99a35901a9d80ac669c055e0"},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tempfile, sys, os\nsys.path.insert(0, os.path.abspath('..'))\n\n# CNN\nimport keras\nfrom keras.models import Sequential, Model, load_model \nfrom keras.layers import Dense, Dropout, Flatten, Activation\n\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import Adam, SGD\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2\nfrom sklearn.model_selection import train_test_split\nnp.random.seed(3)\n\n# plot function\nfrom skimage import feature, transform\nimport matplotlib as mp\nimport matplotlib.pyplot as plt\n\n#   hyper params\nCLASS_NUM=2\nEPOCHS = 3\nBATCH_SIZE = 32\nLR = 0.01\n\nIMG_ROW = 218\nIMG_COL = 178\nCH = 3\n\nDATA_PATH = '../input'\nIMG_PATH = os.path.join(DATA_PATH,'img_align_celeba', 'img_align_celeba')\nCSV_PATH = os.path.join(DATA_PATH,'list_attr_celeba.csv')\nTRAIN_CNT = 10000\nTEST_CNT  = 1000\n\nATTR_SHOW = 8\n\ndef data_preprocess():\n    data = pd.read_csv(CSV_PATH)[['image_id', 'Male']]\n    sample_data = data.sample(frac=1).reset_index(drop=True)\n\n    test_dataframe = sample_data[:TEST_CNT]\n    train_dataframe = sample_data[TEST_CNT:TRAIN_CNT]\n\n    train_dataframe = train_dataframe.reset_index(drop=True)\n\n    test_dataframe.to_csv('./test_data.csv', encoding='utf-8')\n    train_dataframe.to_csv('./train_data.csv', encoding='utf-8')\n\ndef load_gen(train_df, test_df):    \n    datagen = ImageDataGenerator(rescale=1./255)\n    train_gen = datagen.flow_from_dataframe(dataframe=train_df, directory=IMG_PATH,\n                                            x_col='image_id', y_col='Male',\n                                            has_ext=True, class_mode=\"categorical\",\n                                            target_size=(IMG_ROW, IMG_COL), batch_size=BATCH_SIZE)\n\n    test_gen = datagen.flow_from_dataframe(dataframe=test_df, directory=IMG_PATH,\n                                           x_col='image_id', y_col='Male',\n                                           has_ext=True, class_mode=\"categorical\",\n                                           target_size=(IMG_ROW, IMG_COL), batch_size=BATCH_SIZE)\n\n    return train_gen, test_gen\n\ndef createLayers():\n    model = Sequential()\n    model.add(Conv2D(filters=32,\n                     kernel_size=5,\n                     input_shape=(IMG_ROW, IMG_COL, CH),\n                     padding='same',\n                     activation='relu',\n                     kernel_constraint=maxnorm(3)))\n    model.add(MaxPooling2D(pool_size=(4, 4)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_constraint=maxnorm(3)))\n    model.add(Dropout(0.5))\n    model.add(Dense(CLASS_NUM, activation='softmax'))\n\n    decay = LR / EPOCHS\n    sgd = SGD(lr=LR, momentum=0.9, decay=decay, nesterov=False)\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    print(model.summary())\n    return model\n\ndef train(train_gen, test_gen, step_size_train, step_size_valid):\n    model = createLayers()\n    model.fit_generator(generator=train_gen,\n                    steps_per_epoch=step_size_train,\n                    validation_data=test_gen,\n                    validation_steps=step_size_valid,\n                    epochs=EPOCHS)\n\n    model.save('celeba_clf.keras')\n\ndata_preprocess()\n\ntest_df = pd.read_csv('./test_data.csv')\ntrain_df = pd.read_csv('./train_data.csv')\n\n# the data, shuffled and split between train and test sets\ntrain_gen, test_gen = load_gen(train_df, test_df)\n\nstep_size_train = train_gen.n // train_gen.batch_size\nstep_size_valid = test_gen.n // test_gen.batch_size\n\nif not os.path.isfile(\"./celeba_clf.keras\"):\n    train(train_gen, test_gen, step_size_train, step_size_valid)\n\nmodel = load_model(\"./celeba_clf.keras\")\n\nr_batch = np.random.randint(low=0, high=len(test_gen))\nx_test_batch, y_test_batch = test_gen[r_batch]\n\nshow_cnt = ATTR_SHOW if ATTR_SHOW < BATCH_SIZE else BATCH_SIZE\n\nx_m_input = x_test_batch[:show_cnt]\nlast_conv_layer = model.layers[-5] # last layer until FC (Dense).\n\n# Plot\nn_cols = 4\nn_rows = int(show_cnt / 2)\nfig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(3*n_cols, 3*n_rows))\nfig_loop = 0\nfor x in x_m_input:\n    row, col= divmod(fig_loop,2)\n    x_extend = np.expand_dims(x, axis=0)\n    preds = model.predict(x_extend)\n\n    class_idx = np.argmax(preds[0])\n    class_output = model.output[:, class_idx]\n    \n    \n    grads = K.gradients(class_output, last_conv_layer.output)[0] # get gradients\n    pooled_grads = K.mean(grads, axis=(0, 1, 2)) # get average value\n    # NOTE: 1 batch = 1 data in decoding time\n    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n    pooled_grads_value, conv_layer_output_value = iterate([x_extend])\n\n    # loop # of filters.(See conv.func)\n    for i in range(32):\n        # NOTE: This code prevents 'divided by zero' problem\n        # If you want, you can comment out this codes\n        filter_mat = np.zeros(dtype=np.float32, shape=conv_layer_output_value.shape[0:2])\n        filter_mat = conv_layer_output_value[:, :, i] * pooled_grads_value[i]\n        if np.maximum(np.sum(filter_mat),0).all() == 0: \n            conv_layer_output_value[:, :, i] = 0 # deactivate filter.\n            continue \n        # comment END\n        conv_layer_output_value[:, :, i] *= pooled_grads_value[i] # a^c_k * A^k\n        \n    heatmap = np.sum(conv_layer_output_value, axis=-1) # sigma_{k}\n    heatmap = np.maximum(heatmap, 0)  # ReLU\n    heatmap /= np.max(heatmap)        # normalize\n    \n    # resize heatmap\n    heatmap = cv2.resize(heatmap, (IMG_COL, IMG_ROW))\n    x = (x*255).astype(np.uint8)\n    axes[row, col*2].imshow(x)\n    axes[row, col*2].axis('off')\n    heatmap = np.uint8(255 * heatmap)\n    axes[row, col*2+1].imshow(heatmap, cmap='gist_heat_r')\n    axes[row, col*2+1].axis('off')\n    fig_loop += 1\n    \nfig.savefig('full_figure.png')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}