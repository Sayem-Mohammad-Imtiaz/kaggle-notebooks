{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Important Links*\n\n**Text Classification**\n\n[Learn More](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)\n\n**Data Handling**\n\n[Python and Numpy](http://cs231n.github.io/python-numpy-tutorial/)\n\n[Pandas](https://www.guru99.com/python-pandas-tutorial.html)\n\n**Data Visualization**\n\n[Seaborn](https://www.journaldev.com/18583/python-seaborn-tutorial)\n\n[Matplotlib](https://www.edureka.co/blog/python-matplotlib-tutorial/)\n\n**Processing**\n\n[Pre-Processing](https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908)\n\n[NLTK](https://www.guru99.com/nltk-tutorial.html)\n\n[RegEx](https://www.w3schools.com/python/python_regex.asp)"},{"metadata":{},"cell_type":"markdown","source":"**Loading the Data**\nPandas is Python library providing high-performance, easy-to-use data structures and data analysis tools."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing the pandas library\nimport numpy as np\nimport pandas as pd\n\n# loading the data\npath = \"/kaggle/input/bbc-fulltext-and-category/bbc-text.csv\"\ndata = pd.read_csv(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**About the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing out few elements\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic details about the dataset\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = data['category'].unique()\nprint(\"Different Categories:\",classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the matplotlib plots\nimport seaborn as sns\n\nsns.countplot(x='category',data = data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Pre-Processing**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport nltk\nimport re\nfrom nltk.corpus import stopwords \nfrom nltk.stem.porter import PorterStemmer \nfrom nltk.stem import WordNetLemmatizer ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the stop words list, stemmer and lemmatizer\nstop_words = set(stopwords.words(\"english\")) \nstemmer = PorterStemmer() \nlemmatizer = WordNetLemmatizer() \nprint(stop_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# methods to perform preprocessing\ndef process_words(text):\n    # tokenize the text\n    words = text.split()\n    new_words_list = []\n    \n    for word in words:\n        # only add words which are not stop words\n        if word not in stop_words:\n            word = stemmer.stem(word)\n            word = lemmatizer.lemmatize(word, pos ='v')\n            new_words_list.append(word)\n    \n    # concatenate the string\n    return \" \".join(new_words_list)\n\n\ndef preprocess(text):\n    # convert to lower case\n    text = text.lower()\n    \n    # replace non-alphabets with null\n    text = re.sub('[^a-zA-Z ]','',text)\n    \n    #remove stop words\n    text = process_words(text)\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = data['text'][50]\n\nprint(\"Sample Text before Pre-Processing:\\n\",sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_sample = preprocess(sample)\nprint(\"Sample Text after Pre-Processing:\\n\",pre_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply preprocessing on entire dataset\nx = data['text'].apply(lambda x:preprocess(x))\nprint(x[:1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the input text to suitable features\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\ncount_vectorizer = CountVectorizer()\ntfidf_vectorizer = TfidfVectorizer()\n\nx_counts = count_vectorizer.fit_transform(x)\nx_tfidf = tfidf_vectorizer.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_x = x_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create labels for target\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder \n\n\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform( data['category'] )\nprint(\"Label Encodings:\",y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(new_x,y,test_size=0.15)\nprint(\"Size of Training data:\",x_train.shape[0])\nprint(\"Size of Testing data:\",x_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating the models using scikit-learn**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the libraires\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_model = MultinomialNB()\nlogistic_model = LogisticRegression()\ndec_tree_model = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training the model\nnb_model.fit(x_train,y_train)\nlogistic_model.fit(x_train,y_train)\ndec_tree_model.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Validating the Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_accuracy(model,x_test,y_test):\n    total = x_test.shape[0]\n    count =  0\n    res = model.predict(x_test)\n    for i in range(total):\n        y_true = y_test[i]\n        if y_true == res[i]:\n            count+=1\n    return count/total\n\nprint(\"Naive Bayes Accuracy:\",check_accuracy(nb_model,x_test,y_test))\nprint(\"Logistic Regression Accuracy:\",check_accuracy(logistic_model,x_test,y_test))\nprint(\"Desicion Tree Accuracy:\",check_accuracy(dec_tree_model,x_test,y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_data = \"actor injured while shooting and the movie got cancelled\"\nprocessed_data = preprocess(sample_data)\nx_sample = count_vectorizer.transform([processed_data])\n\n# get results\nnb_result =  nb_model.predict(x_sample)\nlog_result = logistic_model.predict(x_sample)\ntree_result = dec_tree_model.predict(x_sample)\n\n# get labels\nnb_result = label_encoder.inverse_transform(nb_result)\nlog_result = label_encoder.inverse_transform(log_result)\ntree_result = label_encoder.inverse_transform(tree_result)\n\nprint(\"Naive Bayes Result:\",nb_result)\nprint(\"Logistic Regession Result:\",log_result)\nprint(\"Decision Tree Result:\",tree_result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating the models with Keras**"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = x_train[0].shape[1]\noutput_shape = 5\nprint(\"Input Shape:\",input_shape)\nprint(\"Output Shape:\",output_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create one hot encoding's for the labels\nonehotencoder = OneHotEncoder() \nonehotencoder.fit(y.reshape(-1, 1))\nlabels = onehotencoder.transform(y.reshape(-1, 1)).toarray()\nprint(\"One hot Vector:\\n\",labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(new_x,labels,test_size=0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import library\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense( 1024 , activation='sigmoid',  input_dim = input_shape  ))\nmodel.add(Dropout(0.2))\nmodel.add(Dense( 512  , activation='sigmoid' ))\nmodel.add(Dropout(0.2))\nmodel.add(Dense( 256   , activation='sigmoid'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128   , activation='sigmoid'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense( 64   , activation='sigmoid'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense( 5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train,y_train, epochs = 10, batch_size=32, validation_data = (x_test,y_test)  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nh = history\nplt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.show()\n\nplt.plot(h.history['loss'])\nplt.plot(h.history['val_loss'])\nplt.title('Model Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_data = \"actor injured while shooting and the movie got cancelled\"\nprocessed_data = preprocess(sample_data)\nx_sample = count_vectorizer.transform([processed_data])\n\n# get results\nmodel_result = list(model.predict(x_sample)[0])\n\nprint(model_result)\n\n# get labels\nmax_ = max(model_result)\nindex = model_result.index(max_)\nresult = label_encoder.inverse_transform([index])\n\nprint(\"Model Result:\",result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_data = \"Issues in china after the government tries to introduce a new law system \"\nprocessed_data = preprocess(sample_data)\nx_sample = count_vectorizer.transform([processed_data])\n\n# get results\nmodel_result = list(model.predict(x_sample)[0])\n\nprint(model_result)\n\n# get labels\nmax_ = max(model_result)\nindex = model_result.index(max_)\nresult = label_encoder.inverse_transform([index])\n\nprint(\"Model Result:\",result)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}