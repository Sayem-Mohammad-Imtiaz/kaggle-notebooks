{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem: \n\n**Şirketi terk edecek müşterileri tahmin edebilecek bir makine öğrenmesi modeli geliştirebilir misiniz?**\n\n- Amaç bir bankanın müşterilerinin bankayı terk etme ya da terk etmeme durumunun tahmin edilmesidir.\n\n- Müşteri terkini tanımlayan olay müşterinin banka hesabını kapatmasıdır.\n\n**Veri Seti Hikayesi:**\n\n- 10000 gözlemden ve 12 değişkenden oluşmaktadır. \n- Bağımsız değişkenler müşterilere ilişkin bilgiler barındırmaktadır.\n- Bağımlı değişken müşteri terk durumunu ifade etmektedir.\n\n**Değişkenler:**\n\n- Surname : Soy isim\n- CreditScore : Kredi skoru\n- Geography : Ülke (Germany/France/Spain)\n- Gender : Cinsiyet (Female/Male)\n- Age : Yaş\n- Tenure : Kaç yıllık müşteri\n- Balance : Bakiye\n- NumOfProducts : Kullanılan banka ürünü\n- HasCrCard : Kredi kartı durumu (0=No,1=Yes)\n- IsActiveMember : Aktif üyelik durumu (0=No,1=Yes)\n- EstimatedSalary : Tahmini maaş\n- Exited : Terk mi değil mi? (0=No,1=Yes)\n"},{"metadata":{},"cell_type":"markdown","source":"#### Kütüphane Import İşlemleri ve Kütüphane Ayarları"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.base import clone\n\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.neighbors import KNeighborsClassifier  \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \nwarnings.simplefilter(action = \"ignore\") \n\n%config InlineBackend.figure_format = 'retina'\n\n\n# to display all columns and rows:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);\npd.set_option('display.float_format', lambda x: '%.4f' % x)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Metod Tanımlamaları"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data() :\n    df = pd.read_csv(\"../input/churn-predictions-personal/Churn_Predictions.csv\")\n    df = df.drop([\"RowNumber\",\"Surname\",\"CustomerId\"], axis = 1)\n    return df\n\ndef convert_bool(df,cols):\n    for c in cols:\n        df[c] = df[c].astype('bool')\n    return df\n\ndef cat_countplot(fig,axarr,boyut,cols,hue):    \n    for i in boyut :\n        for j in boyut :\n            for c in cols :\n                sns.countplot(x = c, hue = hue, data = df, ax=axarr[i][j])\n                cols.remove(c)\n                break\n                \ndef churn_countplot():\n    fig, axarr = plt.subplots(2, 2, figsize=(20, 12))\n    boyut = [0,1]\n    cols = [\"Geography\",\"Gender\",\"HasCrCard\",\"IsActiveMember\"]\n    cat_countplot(fig,axarr,boyut,cols,\"Exited\")\n    \ndef num_boxplot(fig,axarr,boyut,cols,hue):\n    for i in boyut :\n        for j in boyut :\n            for c in cols :\n                if j != 2 :\n                    sns.boxplot(y=c, x = hue, hue = hue, data = df, ax=axarr[i][j])\n                    cols.remove(c)\n                    break\n\ndef churn_boxplot():\n    fig, axarr = plt.subplots(3, 2, figsize=(20, 12))\n    boyut = [0,1,2]\n    cols = [\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"EstimatedSalary\"]\n    num_boxplot(fig,axarr,boyut,cols,\"Exited\")\n\ndef feature_engineering(df):\n    df['BalanceBySalary'] = df.Balance/df.EstimatedSalary\n    df['BalanceByTenure'] = df.Balance/(df.Tenure + 0.01)\n    df['TenureByAge'] = df.Tenure/df.Age\n    df['CreditScoreByAge'] = df.CreditScore/df.Age\n    df['CreditScoreByTenure'] = df.CreditScore/(df.Tenure + 0.01)\n    return df\n\ndef get_catvar(df) :\n    cat_col = [col for col in df.columns if ( (df[col].dtype == 'object') | (df[col].dtype == 'bool'))]\n    kat_df = pd.DataFrame(df[cat_col], index = df[cat_col].index)\n    df = df.drop(cat_col, axis = 1)\n    return df, kat_df, cat_col\n\ndef get_numvar(cat_col,df):\n    num_col = [c for c in df.columns if c not in cat_col]\n    num_df = pd.DataFrame(df[num_col], index = df[num_col].index)\n    df = df.drop(num_col, axis = 1)\n    return df, num_df, num_col\n\ndef data_encoding(kat_df,columns) :\n    kat_df=pd.get_dummies(kat_df,columns = columns, drop_first = True)\n    return kat_df\n\ndef one_hot_encoding(kat_df):\n    columns = ['Gender', 'Geography']\n    kat_df = data_encoding(kat_df, columns)\n    return kat_df\n\ndef get_outlier_col(num_df) :\n    outlier_col = []\n    for feature in num_df:\n\n        Q1 = num_df[feature].quantile(0.05)\n        Q3 = num_df[feature].quantile(0.95)\n        IQR = Q3-Q1\n        lower = Q1- 1.5*IQR\n        upper = Q3 + 1.5*IQR\n\n        if num_df[(num_df[feature] > upper)].any(axis=None):\n            outlier_col.append(feature)\n            \n    return outlier_col\n\ndef outlier_boxplot(fig,axarr,boyut,num_df,aykiri_cols) :\n    for i in boyut :\n        for c in aykiri_cols :\n            sns.boxplot(x = num_df[c], ax = axarr[i])\n            aykiri_cols.remove(c)\n            break\n            \ndef draw_outlier_boxplot(num_df,aykiri_cols):\n    fig, axarr = plt.subplots(3, 1, figsize=(10, 15))\n    boyut = [0,1,2]\n    outlier_boxplot(fig,axarr,boyut,num_df,aykiri_cols)\n    \ndef handle_outlier(outlier_cols,num_df) : \n    for c in outlier_cols :\n        Q1 = num_df[c].quantile(0.05)\n        Q3 = num_df[c].quantile(0.95)\n        IQR = Q3-Q1\n        upper = Q3 + 1.5*IQR\n        num_df.loc[num_df[c] > upper, c] = upper\n    return num_df\n\ndef eliminate_outlier_via_lof(num_df):\n    clf = LocalOutlierFactor(n_neighbors = 20, contamination = 0.1)\n    clf.fit_predict(num_df)\n    df_scores = clf.negative_outlier_factor_\n    esik_deger = np.sort(df_scores)[11]\n    aykiri_olmayan = df_scores>esik_deger\n    aykirilar = num_df[~aykiri_olmayan]\n    num_df = num_df[aykiri_olmayan]\n    return aykirilar.index, num_df\n\ndef standardization(num_df):\n    X = num_df\n    Rscaler = RobustScaler().fit(X)\n    scaled_cols=Rscaler.transform(X)\n    scaled_cols=pd.DataFrame(scaled_cols, columns=X.columns, index = X.index)\n    num_df = scaled_cols\n    return num_df\n\ndef show_classification_ratio(gecici_df):\n    print(gecici_df[\"Exited\"].value_counts()*100/len(gecici_df))\n    print(sns.countplot(x = 'Exited', data = gecici_df))\n    \ndef handle_imbalanced_data(gecici_df):\n    y = gecici_df[\"Exited\"]\n    gecici_df = gecici_df.drop(\"Exited\", axis = 1)\n    X = gecici_df\n    oversample = SMOTE(random_state = 23456)\n    X, y = oversample.fit_resample(X, y)\n    return X,y\n\ndef create_model_object(models):\n    lr  = LogisticRegression(random_state = 12345)\n    knn = KNeighborsClassifier()\n    svm = SVC(gamma='auto',random_state = 12345)\n    cart = DecisionTreeClassifier(random_state = 12345)\n    rf = RandomForestClassifier(random_state = 12345)\n    lgbm = LGBMClassifier(random_state = 12345)\n    xgbm = XGBClassifier(random_state = 12345)\n    models.append(('LR', lr))\n    models.append(('KNN', knn))\n    models.append(('SVM', svm))\n    models.append(('CART', cart))\n    models.append(('RF', rf))\n    models.append((\"LGBM\", lgbm))\n    models.append(('XGBM', xgbm))\n    return models, lr, knn, svm, cart, rf, lgbm, xgbm\n\ndef calculate_base_cv_acc(models,X_train,y_train,X_test,y_test,sonuc_ilkel_cv,sonuc_ilkel_acc):\n    for name, model in models:\n        kfold = KFold(n_splits = 10, random_state = 12345)\n        cv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring= \"accuracy\")\n        sonuc_ilkel_cv.append((name,cv_results.mean(),cv_results.std()))\n    sonuc_ilkel_cv_df = pd.DataFrame(sonuc_ilkel_cv, columns = [\"Model Ismi\", \"Ilkel CV Skor\",\"Ilkel CV SSapma\"])\n    sonuc_ilkel_cv_df = sonuc_ilkel_cv_df.set_index(\"Model Ismi\")\n    sonuc_ilkel_cv_df.sort_values('Ilkel CV Skor', ascending=True, inplace = True)\n    \n    for name, model in models:\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        acc = accuracy_score(y_test, y_pred)\n        sonuc_ilkel_acc.append((name,acc))    \n    sonuc_ilkel_acc_df = pd.DataFrame(sonuc_ilkel_acc, columns = [\"Model Ismi\", \"Ilkel ACC Skor\"])\n    sonuc_ilkel_acc_df = sonuc_ilkel_acc_df.set_index(\"Model Ismi\")\n    sonuc_ilkel_acc_df.sort_values('Ilkel ACC Skor', ascending=True, inplace = True)\n        \n    sonuc_ilkel = pd.concat([sonuc_ilkel_cv_df,sonuc_ilkel_acc_df], axis = 1)\n    \n    return sonuc_ilkel\n\ndef feat_imp(fig,axarr,boyut,fi_models,X):\n    for i in boyut:\n        feature_imp = pd.Series(fi_models[i][1].feature_importances_,index=X.columns).sort_values(ascending=False)\n        ax = sns.barplot(x=feature_imp, y=feature_imp.index, ax = axarr[i])\n        ax.set_xlabel('Significance Score Of Variables')\n        ax.set_ylabel('Variables')\n        ax.set_title(fi_models_base[i][0] + \" Variable Severity Levels\")    \n            \ndef draw_feat_imp(fi_models,X):\n    fig, axarr = plt.subplots(4, 1, figsize=(10, 25))\n    boyut = [0,1,2,3]\n    feat_imp(fig,axarr,boyut,fi_models,X)\n    \ndef compML_tuned(params, model, alg, model_ismi, X_train, y_train, X_test, y_test):\n    kfold = KFold(n_splits = 10, random_state = 12345)\n    cv_model = GridSearchCV(model,params, cv = kfold, n_jobs = -1, verbose = 2).fit(X_train,y_train)\n    model_tuned = alg(**cv_model.best_params_).fit(X_train,y_train)\n    cv_tuned = cross_val_score(model_tuned, X_train, y_train, cv = kfold).mean()\n    print(model_ismi + \" CV Tuned: \" + str(cv_tuned))\n    sonuc_tuned_cv.append((model_ismi,cv_model.best_params_,cv_tuned))\n    \n    y_pred = model_tuned.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    sonuc_tuned_acc.append((model_ismi,acc))\n    print(model_ismi + \" ACC: \" + str(acc))\n    return model_tuned, y_pred\n\ndef define_params():\n    lr_params = {'C': [0.1,0.5,1,10,50,100], \n                 'max_iter': [250], \n                 'fit_intercept':[True],\n                 'intercept_scaling':[1],\n                 'penalty':['l2'],\n                 'tol':[0.00001,0.0001,0.000001]}\n\n    knn_params = {'n_neighbors': np.arange(1,50,1)}\n\n    svm_params = {'C': [0.5,100,150], \n                  'gamma': [0.1,0.01,0.001],\n                  'probability':[True],\n                  'kernel': ['rbf']}\n\n    cart_params = {\"max_depth\": [2,3,4,5,10,20, 100, 1000,None],\n                  \"min_samples_split\": [2,10,5,30,50,10]}\n\n    rf_params = {'max_depth': [3, 5, 6, 7, 8], \n                 'max_features': [2,4,6,7,8,9],\n                 'n_estimators':[50,100],\n                 'min_samples_split': [3, 5, 6, 7]}\n\n    lgbm_params = {'max_depth': [5,6,7,8], \n                   'gamma': [0.01,0.001,0.001],\n                   'min_child_weight':[1,5,10], \n                   'learning_rate': [0.05,0.1, 0.2, 0.3], \n                   'n_estimators':[5,10,20,100]}\n\n    xgbm_params = {'max_depth': [5,6,7,8], \n                   'gamma': [0.01,0.001,0.001],\n                   'min_child_weight':[1,5,10], \n                   'learning_rate': [0.05,0.1, 0.2, 0.3], \n                   'n_estimators':[5,10,20,100]}\n\n    return lr_params, knn_params, svm_params, cart_params, rf_params, lgbm_params, xgbm_params\n\ndef calculate_tuned_cv_acc(sonuc_tuned_cv, sonuc_tuned_acc):\n    sonuc_tuned_cv_df = pd.DataFrame(sonuc_tuned_cv, columns = [\"Model Ismi\",\"Best Params\", \"Tune Edilmis CV Skor\"])\n    sonuc_tuned_cv_df = sonuc_tuned_cv_df.set_index(\"Model Ismi\")\n    sonuc_tuned_cv_df.sort_values('Tune Edilmis CV Skor', ascending=True, inplace = True)\n    \n    sonuc_tuned_acc_df = pd.DataFrame(sonuc_tuned_acc, columns = [\"Model Ismi\",\"Tune Edilmis ACC Skor\"])\n    sonuc_tuned_acc_df = sonuc_tuned_acc_df.set_index(\"Model Ismi\")\n    sonuc_tuned_acc_df.sort_values('Tune Edilmis ACC Skor', ascending=True, inplace = True)\n    \n    sonuc_tuned = pd.concat([sonuc_tuned_cv_df,sonuc_tuned_acc_df], axis = 1)\n    \n    return sonuc_tuned\n\ndef calculate_result(sonuc_ilkel,sonuc_tuned):\n    sonuc = pd.concat([sonuc_ilkel,sonuc_tuned], axis = 1)\n    return sonuc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1). Veriyi Okuma"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = read_data()\ndf_copy = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2). Keşifçi Veri Analizi"},{"metadata":{"trusted":true},"cell_type":"code","source":"#veri setinin yapısal bilgileri\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#veri setindeki değişkenlerin bilgisi\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NumOfProducts için değerler neler?\ndf['NumOfProducts'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Betimsel İstatistikler\ndf.describe([0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip Dönüşümleri"},{"metadata":{},"cell_type":"markdown","source":"#### Bool tipine dönüşmesi gereken değişkenler : \n- HasCrCard \n- IsActiveMember\n- Exited"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tip Dönüşümleri\ncols = [\"HasCrCard\",\"IsActiveMember\",\"Exited\"]\ndf = convert_bool(df,cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tip Dönüşümü başarılı olmuş mu? Olmuş.\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bool tipli değişkenlerin gelmemesini bekliyorum.\ndf.describe([0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#veri setinde boyut bilgisi\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#veri setinde hangi değişkenden kaç tane eksik gözlem var?\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Her bir değişken için eşsiz gözlem sayısı\ndf.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Veri Görselleştirme"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Belirleyici kategorik değişkenlere göre churn olma durumunu countplot ile alacağım.\nchurn_countplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sürekli değişkenlere göre churn olma durumunu boxplot ile alacağım.\nchurn_boxplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3). Değişken Mühendisliği (Feature Engineering)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = feature_engineering(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4). Veri Ön İşleme"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Eksik Değer\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Değişken Tipleri\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kategorik Değişkenler\ndf, kat_df, cat_col = get_catvar(df)\n\n#Numerik Değişkenler\ndf, num_df, num_col = get_numvar(cat_col,df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kat_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding\nkat_df = one_hot_encoding(kat_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kat_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tip Dönüşümleri\ncols = [\"Gender_Male\",\"Geography_Germany\",\"Geography_Spain\"]\nkat_df = convert_bool(kat_df,cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kat_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kat_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Aykırı Gözlem"},{"metadata":{},"cell_type":"markdown","source":"#### a). Klasik Yöntemle Aykırı Gözlem Analizi"},{"metadata":{"trusted":true},"cell_type":"code","source":"aykiri_cols = get_outlier_col(num_df)\noutlier_cols = aykiri_cols.copy()\ndraw_outlier_boxplot(num_df,aykiri_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df = handle_outlier(outlier_cols,num_df)\ndraw_outlier_boxplot(num_df,outlier_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### b). LOF ile Aykırı Gözlem Analizi"},{"metadata":{"trusted":true},"cell_type":"code","source":"aykiri_index,num_df = eliminate_outlier_via_lof(num_df)\n\n# Kategorik değişkenlerden, indexi aykırı olanları uçuruyorum\nkat_df = kat_df.drop(aykiri_index)\n\n#df ten, indexi aykırı olanları uçuruyorum\ndf = df.drop(aykiri_index)\n\nprint(num_df.shape)\nprint(kat_df.shape)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Değişken Standardizasyonu"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kat_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df = standardization(num_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kat_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model kurmadan önce numerik ve kategorik değişkenin birleştirilmesi  \ngecici_df = pd.concat([num_df,kat_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gecici_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dengesiz Veri Problemi İnceleme"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dengesiz veri problemine bakmasak ne olurdu? Aşağıda incelemek için kopyasını aldım.\ngecici_df_copy = gecici_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dengesiz veri problemi var mı? Var.\nshow_classification_ratio(gecici_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dengesiz Veri Problemi Çözümü \nX,y = handle_imbalanced_data(gecici_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dengesiz veri problemi çözülmüş mü? Çözülmüş.\ngecici_df = pd.concat([X,y], axis = 1)\nshow_classification_ratio(gecici_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5). Model Kurma"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Base Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nsonuc_ilkel_cv = []\nsonuc_ilkel_acc = []\nmodels_tuned = []\nsonuc_tuned_cv= []\nsonuc_tuned_acc = []\nfi_models_base = []\nfi_models_tuned = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Nesneleri Oluştur, İlkel Hata hesapla\nmodels, lr, knn, svm, cart, rf, lgbm, xgbm = create_model_object(models)\n\n#Dengesiz veri problemine bakmasak ne olurdu? Aşağıda incelemek için kopyasını aldım.\nxgbm_copy = clone(xgbm)\n\n\nsonuc_ilkel = calculate_base_cv_acc(models,X_train,y_train,X_test,y_test,sonuc_ilkel_cv, sonuc_ilkel_acc)\nsonuc_ilkel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Değişken Önem Düzeylerini Göster\nfi_models_base.append(('LGBM',lgbm))\nfi_models_base.append(('CART',cart))\nfi_models_base.append(('RF',rf))\nfi_models_base.append(('XGBM',xgbm))\n\ndraw_feat_imp(fi_models_base,X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Parametrelerini ayarla\nlr_params, knn_params, svm_params, cart_params, rf_params, lgbm_params, xgbm_params = define_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbm_tuned, y_pred_xgbm_tuned = compML_tuned(xgbm_params,xgbm, XGBClassifier,'XGBM', X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_tuned, y_pred_lgbm_tuned = compML_tuned(lgbm_params,lgbm,LGBMClassifier,'LGBM', X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned, y_pred_rf_tuned = compML_tuned(rf_params,rf,RandomForestClassifier,'RF', X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_tuned, y_pred_knn_tuned = compML_tuned(knn_params,knn,KNeighborsClassifier,'KNN', X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CART"},{"metadata":{"trusted":true},"cell_type":"code","source":"cart_tuned, y_pred_cart_tuned = compML_tuned(cart_params,cart,DecisionTreeClassifier,'CART', X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_tuned, y_pred_svm_tuned = compML_tuned(svm_params,svm,SVC,'SVM', X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_tuned, y_pred_lr_tuned = compML_tuned(lr_params,lr,LogisticRegression,'LR', X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Değişken Önem Düzeylerini Göster\nfi_models_tuned.append(('LGBM',lgbm_tuned))\nfi_models_tuned.append(('CART',cart_tuned))\nfi_models_tuned.append(('RF',rf_tuned))\nfi_models_tuned.append(('XGBM',xgbm_tuned))\n\ndraw_feat_imp(fi_models_tuned,X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sonuc_tuned = calculate_tuned_cv_acc(sonuc_tuned_cv, sonuc_tuned_acc)\nsonuc_tuned","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sonuc = calculate_result(sonuc_ilkel,sonuc_tuned)\nsonuc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sonuc[\"Best Params\"][\"XGBM\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dengesiz Veri Problemine Bakmasaydık XGBM için Confusion Matrix Nasıl Değişirdi?"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_copy = gecici_df_copy[\"Exited\"]\nX_copy = gecici_df_copy.drop(\"Exited\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_copy, X_test_copy, y_train_copy, y_test_copy = train_test_split(X_copy, y_copy, test_size=0.20, random_state = 12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Nesnesi Oluştur, İlkel Hata hesapla. \n#XGBM_COPY isimli yeni model geldi. Bu model, veri setine SMOTE uygulanmadan kuruldu. \n#İlkel ACC Skor XGBM de 0.9051 iken, XGBM_COPY de 0.8609 a düştü.\nmodels_copy = []\nsonuc_ilkel_cv_copy = []\nsonuc_ilkel_acc_copy = []\nmodels_copy.append(('XGBM_COPY', xgbm_copy))\nsonuc_ilkel_copy = calculate_base_cv_acc(models_copy,X_train_copy,y_train_copy,X_test_copy,y_test_copy,sonuc_ilkel_cv_copy,sonuc_ilkel_acc_copy)\nsonuc_ilkel_copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Tuning\nxgbm_tuned_copy, y_pred_xgbm_tuned_copy = compML_tuned(xgbm_params,xgbm_copy, XGBClassifier,'XGBM_COPY', X_train_copy, y_train_copy, X_test_copy, y_test_copy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dengesiz veri problemine bakılmazsa confusion matrix\nconf_xgbm_copy = confusion_matrix(y_test_copy, y_pred_xgbm_tuned_copy)\nconf_xgbm_copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dengesiz veri için SMOTE yöntemi kullanıldıktan sonra confusion matrix\nconf_xgbm = confusion_matrix(y_test,y_pred_xgbm_tuned)\nconf_xgbm","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}