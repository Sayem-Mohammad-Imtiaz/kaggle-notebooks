{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"color: blue;border: 1px solid black; text-align: center; font-size: 30px \">\n Social Network Analysis of Disinformation/Influence Operation from Bots  \n</p>","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:48:54.824486Z","iopub.execute_input":"2021-06-19T07:48:54.824798Z","iopub.status.idle":"2021-06-19T07:48:54.832147Z","shell.execute_reply.started":"2021-06-19T07:48:54.824772Z","shell.execute_reply":"2021-06-19T07:48:54.831227Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport seaborn as sns\nimport nltk\nfrom wordcloud import WordCloud,STOPWORDS\nimport plotly.express as px\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:54:11.219996Z","iopub.execute_input":"2021-06-19T07:54:11.220339Z","iopub.status.idle":"2021-06-19T07:54:11.225926Z","shell.execute_reply.started":"2021-06-19T07:54:11.2203Z","shell.execute_reply":"2021-06-19T07:54:11.224782Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntraining_data = pd.read_csv('../input/twitter-hate-speech/train_E6oV3lV.csv')\n\n\ntraining_data['length'] = training_data['tweet'].apply(len)\n\ndef vectorization(table):\n    #CountVectorizer will convert a collection of text documents to a matrix of token counts\n    #Produces a sparse representation of the counts \n    #Initialize\n    vector = CountVectorizer()\n    #We fit and transform the vector created\n    frequency_matrix = vector.fit_transform(table.tweet)\n    #Sum all the frequencies for each word\n    sum_frequencies = np.sum(frequency_matrix, axis=0)\n    #Now we use squeeze to remove single-dimensional entries from the shape of an array that we got from applying np.asarray to\n    #the sum of frequencies.\n    frequency = np.squeeze(np.asarray(sum_frequencies))\n    #Now we get into a dataframe all the frequencies and the words that they correspond to\n    frequency_df = pd.DataFrame([frequency], columns=vector.get_feature_names()).transpose()\n    return frequency_df\n\n\ndef graph(word_frequency, sent):\n    labels = word_frequency[0][1:51].index\n    title = \"Frequency of Negative Words\"\n    #Plot the figures\n    plt.figure(figsize=(15,8))\n    plt.bar(np.arange(50), word_frequency[0][1:51], width = 0.8, color = sns.color_palette(\"bwr\"), alpha=0.5, \n            edgecolor = \"black\", capsize=8, linewidth=1);\n    \n    plt.xticks(np.arange(50), labels, rotation=90, size=14);\n    plt.xlabel(\"50 more frequent words\", size=14);\n    plt.ylabel(\"Frequency\", size=14);\n    #plt.title('Word Frequency for %s', size=18) %sent;\n    plt.title(title, size=18)\n    plt.grid(False);\n    plt.gca().spines[\"top\"].set_visible(False);\n    plt.gca().spines[\"right\"].set_visible(False);\n    plt.show()\n\n    \nword_frequency_neg = vectorization(training_data[training_data['label'] == 1]).sort_values(0, ascending = False)\n\ngraph(word_frequency_neg, 'negative')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:29:48.712519Z","iopub.execute_input":"2021-06-19T07:29:48.713036Z","iopub.status.idle":"2021-06-19T07:29:49.832427Z","shell.execute_reply.started":"2021-06-19T07:29:48.712989Z","shell.execute_reply":"2021-06-19T07:29:49.831579Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"color: blue;border: 1px solid black; text-align: center; font-size: 20px \">\n Bots are usualy tweet with the same words , so if we look at the frequency of the repeated words we may find an interisting patterns \n</p>\n","metadata":{}},{"cell_type":"code","source":"\n\n\ntrain  = pd.read_csv(\"../input/twitter-hate-speech/train_E6oV3lV.csv\")\n\ntrain['cleaned_tweet'] = train.tweet.apply(lambda x: ' '.join([word for word in x.split() if not word.startswith('@')]))\n\n\nnegative_words = ' '.join([word for word in train['cleaned_tweet'][train['label'] == 1]])\nneg_htag = [htag for htag in negative_words.split() if htag.startswith('#')]\nneg_htag = [neg_htag[i][1:] for i in range(len(neg_htag))]\nneg_htag_freqcount = nltk.FreqDist(neg_htag)\nneg_htag_df = pd.DataFrame({'Hashtag' : list(neg_htag_freqcount.keys()),\n                            'Count' : list(neg_htag_freqcount.values())})\n\n\nmost_frequent = neg_htag_df.nlargest(columns=\"Count\", n = 20)\n\nplt.figure(figsize=(16,5))\nax = sns.barplot(data=most_frequent, x= \"Hashtag\", y = \"Count\")\nplt.title (\"Frequency of Negative Hashtags\" , fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:31:20.372877Z","iopub.execute_input":"2021-06-19T07:31:20.373208Z","iopub.status.idle":"2021-06-19T07:31:20.808734Z","shell.execute_reply.started":"2021-06-19T07:31:20.37318Z","shell.execute_reply":"2021-06-19T07:31:20.807698Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"color: blue;border: 1px solid black; text-align: center; font-size: 20px \">\nWhat if we checked the Hashtages with the same concept\n</p>","metadata":{}},{"cell_type":"code","source":"\n\nnegative_words = ' '.join([word for word in train['cleaned_tweet'][train['label'] == 1]])\nwordcloud = WordCloud(width = 1500, height = 800, max_font_size = 110).generate(negative_words)\nplt.figure(figsize= (12,8))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('Visualizing the Negative Words' , fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:32:22.56664Z","iopub.execute_input":"2021-06-19T07:32:22.567128Z","iopub.status.idle":"2021-06-19T07:32:24.991025Z","shell.execute_reply.started":"2021-06-19T07:32:22.567098Z","shell.execute_reply":"2021-06-19T07:32:24.989945Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"color: blue;border: 1px solid black; text-align: center; font-size: 20px \">\nLet's visualize the negative words\n</p>","metadata":{}},{"cell_type":"code","source":"trump = pd.read_csv('/kaggle/input/private/privet.csv')\ntrump = trump.drop('Unnamed: 0', axis=1)\n\n\n\nmonths = []\ndatas = []\ntrump['year'] = [o[:4] for o in trump['date']]\nfor i in trump.groupby('year'):\n    i[1]['month'] = [j[5:7] for j in i[1]['date']]\n    for k in i[1].groupby('month'):\n        months.append(i[0]+'-'+k[0])\n        datas.append(k[1]['tweet'])\n        \nmonth_list = []\nfor i in datas:\n    length = len(list(i))\n    month_count = 0 \n    for j in i:\n        month_count += len(j.split(' '))\n    month_list.append(round(month_count/length, 2))\n\n\n\n\ndf = pd.DataFrame({'Date of tweet':months, 'Average number of words per tweet':month_list})\nfig = px.line(df, 'Date of tweet', 'Average number of words per tweet', title='Number of words in tweets per month')\nfig.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:50:07.971167Z","iopub.execute_input":"2021-06-19T07:50:07.97153Z","iopub.status.idle":"2021-06-19T07:50:09.139195Z","shell.execute_reply.started":"2021-06-19T07:50:07.971498Z","shell.execute_reply":"2021-06-19T07:50:09.138219Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"color: blue;border: 1px solid black; text-align: center; font-size: 20px \">\nCounting the number of words per tweets may show us something interisting \n</p>","metadata":{}},{"cell_type":"code","source":"\n\nmonths = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\ntrump['year'] = 2015\n\nfor year in trump.groupby('year'):\n    count = Counter([int(j[5:7]) for j in year[1]['date']])\n    df = pd.DataFrame({'Month':count.keys(), 'Number of tweets':count.values()})\n\n    month_list = []\n    for i in df['Month']:\n        month_list.append(months[int(i-1)])\n    df['Month'] = month_list\n\n    fig = px.pie(df, 'Month', 'Number of tweets',  title='Percentage of Negative tweets per Months')\n    fig.update_layout(legend_title=dict(text='Months in '+str(year[0]), font=dict(size=18)))\n    fig.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:56:17.447268Z","iopub.execute_input":"2021-06-19T07:56:17.44763Z","iopub.status.idle":"2021-06-19T07:56:17.505678Z","shell.execute_reply.started":"2021-06-19T07:56:17.447599Z","shell.execute_reply":"2021-06-19T07:56:17.504699Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"color: blue;border: 1px solid black; text-align: center; font-size: 20px \">\nThat would be useful if we checked the percentage of Negative tweets per Months\n</p>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}