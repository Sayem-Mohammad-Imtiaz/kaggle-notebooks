{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%config InlineBackend.figure_format = 'svg'\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport pandas as pd\nimport numpy\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2021-06-23T06:52:24.928573Z","iopub.execute_input":"2021-06-23T06:52:24.929056Z","iopub.status.idle":"2021-06-23T06:52:26.170081Z","shell.execute_reply.started":"2021-06-23T06:52:24.928976Z","shell.execute_reply":"2021-06-23T06:52:26.169282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class residual(nn.Module):\n    def __init__(self,input_c,output_c,downsample=False):\n        super().__init__()\n        if downsample:\n            stride = 2\n            self.process = nn.Sequential(nn.Conv2d(input_c, output_c, kernel_size=1, stride=2))\n        else:\n            stride = 1\n            self.process = nn.Sequential()\n        self.bn1 = nn.BatchNorm2d(input_c)\n        self.bn2 =  nn.BatchNorm2d(output_c)\n        self.conv1 = nn.Conv2d(input_c, output_c, kernel_size=3, padding=1, stride=stride)\n        self.conv2 = nn.Conv2d(output_c, output_c, kernel_size=3, padding=1)\n    \n    def forward(self,x):\n        y = self.conv1(torch.relu(self.bn1(x)))\n        y = self.conv2(torch.relu(self.bn2(y)))\n        x = self.process(x)\n        return y + x\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-23T06:52:26.171357Z","iopub.execute_input":"2021-06-23T06:52:26.171683Z","iopub.status.idle":"2021-06-23T06:52:26.180588Z","shell.execute_reply.started":"2021-06-23T06:52:26.171648Z","shell.execute_reply":"2021-06-23T06:52:26.17896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n                   nn.BatchNorm2d(64), nn.ReLU(),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\ndef block(input_c, output_c, num, use_1x1= False):\n    blk = []\n    for i in range(num):\n        if i == 0 and not use_1x1:\n            blk.append(\n                residual(input_c, output_c, downsample=True))\n        else:\n            blk.append(residual(output_c, output_c))\n    return blk\n\nb2 = nn.Sequential(*block(64, 64, 2, True))\nb3 = nn.Sequential(*block(64, 128, 2))\nb4 = nn.Sequential(*block(128, 256, 2))\nb5 = nn.Sequential(*block(256, 512, 2))\n\nnet = nn.Sequential(b1, b2, b3, b4, b5, nn.AdaptiveAvgPool2d((1, 1)),\n                    nn.Flatten(), nn.Linear(512, 10))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T06:52:26.182967Z","iopub.execute_input":"2021-06-23T06:52:26.183326Z","iopub.status.idle":"2021-06-23T06:52:26.322961Z","shell.execute_reply.started":"2021-06-23T06:52:26.183291Z","shell.execute_reply":"2021-06-23T06:52:26.32211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = torch.rand(size=(1, 1, 96, 96))\nfor layer in net:\n    X = layer(X)\n    print(layer.__class__.__name__, 'output shape:\\t', X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T06:52:26.32452Z","iopub.execute_input":"2021-06-23T06:52:26.324841Z","iopub.status.idle":"2021-06-23T06:52:26.457417Z","shell.execute_reply.started":"2021-06-23T06:52:26.324808Z","shell.execute_reply":"2021-06-23T06:52:26.456475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class mnist(Dataset):\n    def __init__(self,path,resize=None):\n        data = pd.read_csv(path)\n        self.y = data.iloc[:,0].to_numpy()\n        self.x = data.iloc[:,1:].to_numpy().reshape(-1,28,28)\n        self.resize = resize\n        if resize:\n            self.transform = transforms.Compose([transforms.Resize(resize),\n                                                transforms.ToTensor()])\n        else:\n            self.transform = transforms.Compose([transforms.ToTensor()])\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        x = Image.fromarray(self.x[idx].astype('uint8'))\n        y = self.y[idx]\n        if self.transform:\n            x = self.transform(x)\n            #x = x.view(self.resize)\n        return x, y\n\ntest = mnist('../input/mnist-in-csv/mnist_test.csv', 96)\ntrain = mnist('../input/mnist-in-csv/mnist_train.csv', 96)\ntest_iter = DataLoader(test, batch_size=256, shuffle=True)\ntrain_iter = DataLoader(train, batch_size=256, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T06:52:26.458847Z","iopub.execute_input":"2021-06-23T06:52:26.459188Z","iopub.status.idle":"2021-06-23T06:52:31.909273Z","shell.execute_reply.started":"2021-06-23T06:52:26.45915Z","shell.execute_reply":"2021-06-23T06:52:31.908247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time as t\ndef try_gpu(i=0):  #@save\n    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()。\"\"\"\n    if torch.cuda.device_count() >= i + 1:\n        return torch.device(f'cuda:{i}')\n    return torch.device('cpu')\n\ndef evaluate_accuracy_gpu(net, data_iter, device=None):  #@save\n    \"\"\"使用GPU计算模型在数据集上的精度。\"\"\"\n    if isinstance(net, torch.nn.Module):\n        net.eval()  # 设置为评估模式\n        if not device:\n            device = next(iter(net.parameters())).device\n    # 正确预测的数量，总预测的数量\n    acc = [0,0]\n    for X, y in data_iter:\n        if isinstance(X, list):\n            # BERT微调所需的（之后将介绍）\n            X = [x.to(device) for x in X]\n        else:\n            X = X.to(device)\n        y = y.to(device)\n        acc[0] += torch.sum(net(X).argmax(dim=1)==y)\n        acc[1] += len(y)\n    return acc[0] / acc[1]\n\ndef train(train_iter, test_iter, net, lr, epochs, device, net_init=True):\n    def init_weights(m):\n        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n            nn.init.xavier_uniform_(m.weight)\n    if net_init:\n        net.apply(init_weights)\n    print('training on', device)\n    net.to(device)\n    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n    loss = nn.CrossEntropyLoss()\n    \n    history = {'train_acc':[],'test_acc':[],'train_loss':[]}\n    \n    for epoch in range(epochs):\n        net.train()\n        time = t.time()\n        for X, y in train_iter:\n            optimizer.zero_grad()\n            X, y = X.to(device), y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n    \n        with torch.no_grad():\n            acc=torch.sum(y_hat.argmax(dim=1)==y)/len(y)             \n\n        history['train_acc'].append(acc)\n        history['train_loss'].append(l)\n        test_acc=evaluate_accuracy_gpu(net, test_iter, device)\n        history['test_acc'].append(test_acc)    \n        print('epoch {} use{:.1f}s: train_acc {:.3f}\\t test_acc: {:.4f}\\t train_loss: {:.4f} '.format(epoch+1,\n                                                                                                t.time()-time,\n                                                                                               acc,\n                                                                                               test_acc,\n                                                                                               l))\n    return history\n\n\nlr = 0.001\nhistory = train(train_iter, test_iter, net, lr, 8, try_gpu(), True)\nlr = 0.0005\nhistory = train(train_iter, test_iter, net, lr, 15, try_gpu(), False)\nlr = 0.0001\nhistory = train(train_iter, test_iter, net, lr, 20, try_gpu(), False)\nlr = 0.00005\nhistory = train(train_iter, test_iter, net, lr, 25, try_gpu(), False)\nhistory = train(train_iter, test_iter, net, 0.00001, 25, try_gpu(), False)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T06:52:31.910724Z","iopub.execute_input":"2021-06-23T06:52:31.911088Z","iopub.status.idle":"2021-06-23T06:55:24.688912Z","shell.execute_reply.started":"2021-06-23T06:52:31.911044Z","shell.execute_reply":"2021-06-23T06:55:24.687998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(net.state_dict(),'net_weight.pt')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T06:55:24.690147Z","iopub.execute_input":"2021-06-23T06:55:24.690639Z","iopub.status.idle":"2021-06-23T06:55:24.841228Z","shell.execute_reply.started":"2021-06-23T06:55:24.6906Z","shell.execute_reply":"2021-06-23T06:55:24.840357Z"},"trusted":true},"execution_count":null,"outputs":[]}]}