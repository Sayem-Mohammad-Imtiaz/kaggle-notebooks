{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Binary classification for dataisbeutiful","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Загрузка и предоработка данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/dataisbeautiful/r_dataisbeautiful_posts.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Обработка недостающих данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# визуально посмотрим на распределение незаполненных значений по признакам\nfig, ax = plt.subplots(figsize=(14,10))\nsns.heatmap(df.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# удалим признаки с наибольшим количеством незаполненных данных, а также не влияющие на итоговую классификацию\ndf.drop(columns=['id', 'author_flair_text', 'removed_by', 'total_awards_received', 'awarders', 'created_utc', 'full_link'], inplace=True)\n# удалим строку с пустым 'title'\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ещё раз визуально проверим распределение незаполненных значений по признака\nfig, ax = plt.subplots(figsize=(14,10))\nsns.heatmap(df.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Обработка категориальных и булевых данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# преобразуем булевый признак 'over_18' в числовые значения (0 и 1)\ndf['over_18'] = df['over_18'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на распределение признака по классам\ndf['over_18'].value_counts()\n# видим, что классы несбалансированные","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на признаки с категориальными данными\ndf.select_dtypes(include= np.object).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# закодируем признак 'author' числовыми значениям\nfrom sklearn.preprocessing import LabelEncoder\n\nclass_le = LabelEncoder()\nencoded_df = df.copy()\nencoded_df['author'] = class_le.fit_transform(encoded_df['author'].values)\nencoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# построим гистограммы различных признаков для оценки корректности данных\nencoded_df.hist(figsize=(18, 8), layout=(2,2), bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# построим на матрице корреляций зависимость между признаками, а также между признаками и целевой переменной\nplt.subplots(figsize=(12, 10))\nsns.heatmap(encoded_df.corr(), square = True, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отобразим размерность матрицы с признаками перед последующей обработкой\nencoded_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# для оперативности дальнейших вычислений обрежем данные, предварительно их перемешав\nencoded_df = encoded_df.sample(frac=1).reset_index(drop=True)\nencoded_df = encoded_df[:50000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверим размерность обрезанной матрицы\nencoded_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Преобразование текста в матрицу tfidf","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим функцию для предобработки текста в оставшемся признаке 'title'\nimport string\n\ndef preprocess(doc):\n    doc = doc.lower()\n    for p in string.punctuation + string.whitespace:\n        doc = doc.replace(p, ' ')\n    doc = doc.strip()\n    doc = ' '.join([w for w in doc.split(' ') if w != ''])\n    return doc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# и обработаем 'title'\nfor colname in encoded_df.select_dtypes(include= np.object).columns:\n    encoded_df[colname] = encoded_df[colname].map(preprocess)\nencoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# преобразуем текст признака 'title'  в матрицу tfidf, ограничив итоговое количество признаков\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(max_features=10000)\nX_np = vectorizer.fit_transform(encoded_df['title'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим размерность получившейся после обработки матрицы\nX_np.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на названия признаков, получившихя после обработки\nprint(vectorizer.get_feature_names()[7880:7890])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Разбиение и масштабирование признаков","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# выделим обучающую выборку и целевую переменную\nX = np.array(encoded_df.drop(columns=['over_18', 'title']), float)\ny = np.array(encoded_df['over_18'])\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# разбиваем данные на обучающие и испытательные наборы\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# приведём признаки к одному и тому же масштабу с помощью стандратизации\nfrom sklearn.preprocessing import StandardScaler\n\nstdsc = StandardScaler()\nX_train = stdsc.fit_transform(X_train)\nX_test = stdsc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на получившуюся размерность признаков после стандратизации\nX_train, X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# добавляем к обучающим данным матрицу признаков tfidf\nX_train = np.append(X_train, X_np.toarray()[:40000], axis=1)\nX_test = np.append(X_test, X_np.toarray()[40000:], axis=1)\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Обучение модели","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### K-nearest neighbor (KNN)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# перебор параметров с помощью GridSearchCV занимает длительное время\n# knn = KNeighborsClassifier()\n# knn_grid = {'n_neighbors': np.array(np.linspace(1, 100, 5), dtype='int')}\n# gs = GridSearchCV(knn, knn_grid, cv=3)\n# gs.fit(X_train, y_train)\n# gs.best_params_, gs.best_score_\n\n# поэтому применим KNeighborsClassifier со стандратными настройками\nknn = KNeighborsClassifier()\nknn_mtx = knn.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания на тестовой выборке и выводим метрики  \ny_knn = knn.predict(X_test)\nprint(metrics.classification_report(y_test, y_knn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отобразим результаты на conf-matrix\nplot_confusion_matrix(knn_mtx, X_test, y_test, display_labels=['0','1'], cmap=\"Blues\", values_format = '')\n# видим, что при высокой точности алгоритм совсем не распознаёт класс 'True'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# переберём модели с различными параметрами с помощью GridSearchCV\nalg = LogisticRegression()\ngrid = {'penalty': ['l1', 'l2'],\n        'C': np.array(np.logspace(-3, 2, num = 5), dtype='float'),\n        }\ngs = GridSearchCV(alg, grid, verbose=2)\ngs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим лучшие параметры, получившиеся в результате GridSearchCV\ngs.best_params_, gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# инициализируем алгоритм с лучшими параметрами без балансировки весов и обучаем модель\nlogreg = LogisticRegression(penalty='l2', C = 0.001)\nlogreg_mtx = logreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания на тестовой выборке и выводим метрики (без балансировки)\ny_logreg = logreg.predict(X_test)\nprint(metrics.classification_report(y_test, y_logreg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отобразим результаты без балансировки весов на conf-matrix \nplot_confusion_matrix(logreg_mtx, X_test, y_test, display_labels=['0','1'], cmap=\"Blues\", values_format = '')\n# видим, что при высокой точности алгоритм совсем не распознаёт класс 'True'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# инициализируем алгоритм с лучшими параметрами и с балансировкой весов\nlogreg_balanced = LogisticRegression(penalty='l2', C = 0.001, class_weight='balanced')\nlogreg_balanced_mtx = logreg_balanced.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания на тестовой выборке и выводим метрики (с балансировкой)\ny_logreg_balanced = logreg_balanced.predict(X_test)\nprint(metrics.classification_report(y_test, y_logreg_balanced))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отобразим результаты с балансировкой весов на conf-matrix \nplot_confusion_matrix(logreg_balanced_mtx, X_test, y_test, display_labels=['0','1'], cmap=\"Blues\", values_format = '')\n# видим, что точность предсказаний упала, но при этом алгоритм смог верно распознать несколько образцов класса 'True' ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Support vector machine (SVM)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n# перебор параметров с помощью GridSearchCV занимает длительное время\n# alg = SVC()\n# grid = {'C': np.array(np.linspace(0, 100, 5), dtype='float'),\n#        'kernel': ['rbf', 'sigmoid'],\n#        }\n# gs = GridSearchCV(alg, grid, verbose=2)\n# gs.fit(X_train, y_train)\n\n# поэтому применим SVM со стандратными настройками и сразу с балансировкой весов\nsvm = SVC(class_weight='balanced')\nsvm_mtx = svm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания на тестовой выборке и выводим метрики\ny_svm = svm.predict(X_test)\nprint(metrics.classification_report(y_test, y_svm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отобразим результаты на conf-matrix \nplot_confusion_matrix(svm_mtx, X_test, y_test, display_labels=['0','1'], cmap=\"Blues\", values_format = '')\n# видим, что аналогично  KNN, при высокой точности алгоритм совсем не распознаёт класс 'True'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# инициализируем алгоритм и обучаем модель\nrfc = RandomForestClassifier(class_weight='balanced')\nrfc_mtx = rfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания на тестовой выборке и выводим метрики\ny_rfc = rfc.predict(X_test)\nprint(metrics.classification_report(y_test, y_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отобразим результаты на conf-matrix \nplot_confusion_matrix(rfc_mtx, X_test, y_test, display_labels=['0','1'], cmap=\"Blues\", values_format = '')\n# видим, что как в KNN, SVM и в логистической регрессии без (балансировки весов), при высокой точности алгоритм совсем не распознаёт класс 'True'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sequential class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## from keras.models import Sequential\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# инициализируем нейросеть с 6 слоями и функцией активации ReLU\nmodel = Sequential()\nmodel.add(Dense(units = 128, activation = 'relu' , input_dim = X_train.shape[1]))\nmodel.add(Dense(units = 64 , activation = 'relu'))\nmodel.add(Dense(units = 32 , activation = 'relu'))\nmodel.add(Dense(units = 32 , activation = 'relu'))\nmodel.add(Dense(units = 16 , activation = 'relu'))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# обучим модель на 5 эпохах с размером партии в 128 элементов\nhistory = model.fit(X_train, y_train, epochs = 5, batch_size = 128, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# делаем предсказания на тестовой выборке и выводим метрики\ny_sqn = model.predict_classes(X_test)\nprint(metrics.classification_report(y_test, y_sqn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отобразим результаты на conf-matrix \ncm = confusion_matrix(y_test, y_sqn)\ncm = pd.DataFrame(cm, index = ['0', '1'], columns = ['0', '1'])\nplt.figure(figsize = (10,10))\nsns.heatmap(cm, cmap= \"Blues\", linecolor = 'black', linewidth = 1, annot = True, fmt='')\n# видим, что хоть нейросеть и старалась что-то распознать (есть ошибки в классе 'False'), но в классе 'True' нет верных результатов","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Simple Transformers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# это пока в процессе...\nfrom simpletransformers.classification import ClassificationModel\n\n# Create a TransformerModel\nmodel = ClassificationModel('roberta', 'roberta-base')\n\n# Train the model\nmodel.train_model(train_df)\n\n# Evaluate the model\nresult, model_outputs, wrong_predictions = model.eval_model(eval_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}