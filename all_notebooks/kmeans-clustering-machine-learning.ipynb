{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Hello Guys..Please have a look at this and Enjoy! \n\n* This is a Dataset for Online Retail Store.\n* I have loaded the dataset and cleaned the columns in the first part of this project\n* then I have created some visuals and some new columns to analyze the data\n* then have performed KMeans Clustering (Unsupervised) Machine Learning Model.\n* I have also used the Elbow Method after KMeans Clustering to see if the clusters I chse could be any better.\n* At the end I have created a plotly mapping of the Countries by Revenue from Customers!\n* UPVOTE IF YOU LIKE THE WORK! THANKS!!!"},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries and Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/online-retail-customer-clustering/OnlineRetail.csv\", delimiter=',', encoding = \"ISO-8859-1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observing Datatypes, Columns and Rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning: Checking for Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We observed that CustomerID is missing.\n* We will first check approximately how many rows are mssing this detail\n* Then we will delete the missing rows. \n* The type of analysis I will be performing requires groupby according to customers so that is why it is necessary to remove null values from this column. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['CustomerID'].isnull()].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"100 - ((541909-135000)/541909 * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Approximately 25% of the data is missing.\n* We will prooceed with dropping the missing rows now."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now we can see above that the matrix is showing all bars are equal\n* meaning that the data is clean and ready to be used in the model\n* meanwhile we will change the data type of InvoiceDate to Datetime.\n* We will also create three new fields:"},{"metadata":{},"cell_type":"markdown","source":"1. Amount\n2. Number of Transactons\n3. Last Transactions(how many days ago was that customer's last transaction)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], format='%d-%m-%Y %H:%M')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Total Amount Spent']= df['Quantity'] * df['UnitPrice']\n\ntotal_amount = df['Total Amount Spent'].groupby(df['CustomerID']).sum()\ntotal_amount = pd.DataFrame(total_amount).reset_index()\ntotal_amount.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of Transactions"},{"metadata":{"trusted":true},"cell_type":"code","source":"transactions = df['InvoiceNo'].groupby(df['CustomerID']).count()\ntransaction = pd.DataFrame(transactions).reset_index()\ntransaction.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Last Transaction (LT)"},{"metadata":{"trusted":true},"cell_type":"code","source":"final = df['InvoiceDate'].max()\ndf['Last_transact'] = final - df['InvoiceDate']\nLT = df.groupby(df['CustomerID']).min()['Last_transact']\nLT = pd.DataFrame(LT).reset_index()\nLT.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging All the newly created columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = pd.merge(total_amount, transaction, how='inner', on='CustomerID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = pd.merge(df_new, LT, how='inner', on='CustomerID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Last Transact column still needs to be simplified for just number of days"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['Last_transact'] = df_new['Last_transact'].dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K Means Clustering Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans= KMeans(n_clusters=2)\nkmeans.fit(df_new[['Total Amount Spent', 'InvoiceNo', 'Last_transact']])\npred = kmeans.predict(df_new[['Total Amount Spent', 'InvoiceNo', 'Last_transact']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame(pred, columns=['pred'])\ndf_new = df_new.join(pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clusters are created!\n\n* we will now visualize them using different analytics tools and plots. \n* KMeans Clustering is unsupervised learning model so this means we do not really have anything to compare it with. \n* However we will try to visualize and make assumptions of how it actually made the segmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(nrows= 1, ncols = 3, figsize= (14,6))\nty=sns.stripplot(x='pred', y='Total Amount Spent', data=df_new, s=8, ax = ax[0], palette='magma_r')\nsns.despine(left=True)\nty.set_title('Clusters based on different Amounts')\nty.set_ylabel('Total Spent')\nty.set_xlabel('Clusters')\n\ntt=sns.boxplot(x='pred', y='InvoiceNo', data=df_new, ax = ax[1], palette='coolwarm_r')\ntt.set_title('Clusters based on Number of Transactions')\ntt.set_ylabel('Total Transactions')\ntt.set_xlabel('Clusters')\n\ntr=sns.boxplot(x='pred', y='Last_transact', data=df_new, ax = ax[2], palette='magma_r')\ntr.set_title('Clusters based on Last Transaction')\ntr.set_ylabel('Last Transactions (Days ago)')\ntr.set_xlabel('Clusters')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(hue='pred', data=df_new, diag_kind='kde', palette='magma')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Elbow Method to decide how many Clusters to chose!\n*  It is difficult to predict the right number of clusters that we should opt for \n*  We can do this Elbow method to get the right number of clusters\n*  After performing this we might add or reduce the number of clusters based on how much error we are reducing by increasing the clusters!\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.inertia_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = []\nfor clusters in range(1,16):\n    kmeans = KMeans(n_clusters = clusters)\n    kmeans.fit(df_new)\n    kmeans.predict(df_new)\n    error_rate.append(kmeans.inertia_)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = pd.DataFrame({'Cluster':range(1,16) , 'Error':error_rate})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\np = sns.barplot(x='Cluster', y= 'Error', data= error_rate, palette='coolwarm_r')\nsns.despine(left=True)\np.set_title('Error Rate and Clusters')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Country wise Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_wise = df.groupby('Country').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_codes = pd.read_csv('../input/iso-country-codes-global/wikipedia-iso-country-codes.csv', names=['Country', 'two', 'three', 'numeric', 'ISO'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset for country codes is taken from wikipedia"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_codes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_wise = pd.merge(country_codes,country_wise, on='Country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_wise.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly import __version__\nimport cufflinks as cf\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\ncf.go_offline()\nimport plotly.graph_objs as go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dict(type='choropleth',colorscale='GnBu', locations = country_wise['three'], locationmode = 'ISO-3', z= country_wise['Total Amount Spent'], text = country_wise['Country'], colorbar={'title':'Revenue'},  marker = dict(line=dict(width=0))) \nlayout = dict(title = 'European Countries According to Revenue!', geo = dict(scope='europe',showlakes=False, projection = {'type': 'winkel tripel'}))\nChoromaps2 = go.Figure(data=[data], layout=layout)\niplot(Choromaps2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dict(type='choropleth',colorscale='rainbow', locations = country_wise['three'], locationmode = 'ISO-3', z= country_wise['Total Amount Spent'], text = country_wise['Country'], colorbar={'title':'Revenue'},  marker = dict(line=dict(width=0))) \nlayout = dict(title = 'All Countries According to Revenue!', geo = dict(scope='world',showlakes=False, projection = {'type': 'winkel tripel'}))\nChoromaps2 = go.Figure(data=[data], layout=layout)\niplot(Choromaps2)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thank you! Please Upvote if you liked it :)"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/j6ZReIODqJXh5sPLVq/giphy.gif\">"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}