{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport random\n!pip install -q efficientnet\nimport efficientnet.keras as effnet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Declaring constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE=tf.data.experimental.AUTOTUNE\nIMG_SIZE=299\nBATCH_SIZE=16\nTFRECS_FORMAT={'image': tf.io.FixedLenFeature([], tf.string),\n                      'image_name': tf.io.FixedLenFeature([], tf.string),\n                      'target': tf.io.FixedLenFeature([], tf.int64)}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading TFRecords and other utility functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef readTFRecs(dir_name):\n    TFRecFiles=tf.constant(tf.io.gfile.listdir(dir_name))\n    TFRecFiles=tf.map_fn(lambda name:dir_name+'/'+name,TFRecFiles)\n    TFRecDataset=tf.data.TFRecordDataset(TFRecFiles)#.batch(self.BATCH_SIZE).prefetch(1)\n    Dataset = TFRecDataset.map(lambda example:tf.io.parse_example(example,TFRECS_FORMAT))\n    return Dataset\n    \n@tf.function\ndef decode_image(entry):\n    return tf.cast(tf.image.decode_jpeg(entry['image'],channels=3),tf.float32),tf.cast(tf.one_hot(entry['target'],5),tf.float32) #[batch_size,h,w,3]    \n    \ndef makeDataset(filename):\n    TFRecDataset=readTFRecs(filename)\n    Dataset = TFRecDataset.map(lambda entry: decode_image(entry))\n    #Dataset = Dataset.shuffle(1000)\n    #Dataset=Dataset.zip(TFRecDataset.map(lambda entry:entry['target']))\n    Dataset = Dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    return Dataset\n\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = makeDataset('../input/cassava-tfrecords-512x512')\nvalDataset = dataset.take(50)\ntrainDataset = dataset.skip(50)\ndel dataset\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Augmentations using @tf.function\n\nWe will use keras layer for including gaussian noise\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#@tf.function\n#@tf.function\ndef get_augs():\n    aug_list = np.random.randint(2, size=6)\n    aug_list = list(map(lambda x:x>0,aug_list))\n    return aug_list\n    \n#@tf.function\ndef resize_batch(images):\n    return tf.image.resize(images,[IMG_SIZE,IMG_SIZE])\n\n    \n    \n#@tf.function\ndef augment_batch_randomly(imgs,labels):\n    '''\n    Augmentaions to be used: (use stateless versions of these)\n    \n    Random hue (0.2)\n    Random brightness (0.3)\n    Random saturation (0.7,1.3)\n    Random contrast  (0.8,1.2)\n    ''' \n    augment_list=get_augs()\n    images = resize_batch(imgs)\n     #(32,512,512,3)\n    \n    if augment_list[0]:\n        images = tf.image.random_saturation(images,0.7,1.3)\n    if augment_list[1]:\n        images = tf.image.random_contrast(images,0.8,1.2)\n    if augment_list[2]:\n        images = tf.image.random_brightness(images,0.3)\n    if augment_list[3]:\n        images = tf.image.random_hue(images,0.2)\n    if augment_list[4]:\n        images = tf.image.random_flip_left_right(images)\n    if augment_list[5]:\n        images = tf.image.random_flip_up_down(images)\n    \n    images = tf.math.divide(images,255)\n        \n    return images,labels\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Map dataset with augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDataset = trainDataset.map(augment_batch_randomly)\nvalDataset = valDataset.map(augment_batch_randomly)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make model"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"effnet4_aug-{epoch:02d}.hdf5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\nefn_model = effnet.EfficientNetB4(weights='noisy-student')\nbase_model = tf.keras.models.Model(inputs=efn_model.input, outputs=efn_model.layers[-3].output)\nbase_model.trainabe = True\nmodel.add(tf.keras.Input((299,299,3)))\nmodel.add(base_model)\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(10,activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(5,activation='softmax'))\n\nmodel.compile(optimizer='adam',\n             loss=tf.keras.losses.CategoricalCrossentropy(),\n             metrics=[tf.keras.metrics.CategoricalAccuracy()])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(trainDataset,epochs=15,validation_data=valDataset,callbacks=[checkpoint],verbose=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}