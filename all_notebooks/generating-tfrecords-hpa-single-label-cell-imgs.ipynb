{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport pprint\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport PIL\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfrecords_dir = 'tfrecords'\nimages_dir = '../input/hpa-single-label-cell-level-dataset/single-label-cell-level/rgb'\ndf = pd.read_csv('../input/hpasinglelabelcellcsv/singlelabelcellonly.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_samples = 4096\nnum_tfrecords = len(df) // num_samples\nif len(df) % num_samples:\n    num_tfrecords += 1\n    \nif not os.path.exists(tfrecords_dir):\n    os.makedirs(tfrecords_dir)\n\nnum_tfrecords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x= cv2.resize((cv2.imread( images_dir + '/' + '0f2aca4a-bbb6-11e8-b2ba-ac1f6b6435d0_12.png')), dsize= (224,224) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value, is_list=False):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    \n    if not is_list:\n        value = [value]\n    \n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n\ndef _float_feature(value, is_list=False):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n        \n    if not is_list:\n        value = [value]\n        \n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\ndef _int64_feature(value, is_list=False):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n        \n    if not is_list:\n        value = [value]\n        \n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef image_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    return tf.train.Feature(\n        bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()])\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef create_example(image, image_name, target):\n    \"\"\"\n    Creates a tf.Example message ready to be written to a file from 4 features.\n\n    Args:\n        image (TBD): TBD\n        image_name (str): TBD\n        target (str): | delimited integers\n    \n    Returns:\n        A tf.Example Message ready to be written to file\n    \"\"\"\n    \n    # Create a dictionary mapping the feature name to the \n    # tf.Example-compatible data type.\n    feature = {\n        'image': image_feature(((image))),\n        'image_name': _bytes_feature(image_name, is_list=False),\n        'target': _bytes_feature(target, is_list=False),\n    }\n\n    # Create a Features message using tf.train.Example.\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n    \n\n    \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_tfrecods = 64\n# num_samples = len(df)\n# N_EX_PER_REC = int(np.ceil(N_EX/64))\n# write_tfrecords(train_ds.as_numpy_iterator(), out_dir=\"/kaggle/working/train_slide_records\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for tfrec_num in tqdm(range(num_tfrecords)):\n    samples = df[(tfrec_num * num_samples) : ((tfrec_num + 1) * num_samples)]\n\n    with tf.io.TFRecordWriter(\n        tfrecords_dir + \"/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))\n    ) as writer:\n        for i in  tqdm(range(len(samples))): \n            image_name = samples.iloc[i].ID\n            image_path = images_dir + '/' + image_name\n            x = str(samples.iloc[i].Label).encode()\n            image = tf.io.decode_jpeg(tf.io.read_file(image_path), channels = 3)  \n            example = create_example(image, image_name.encode(), x)\n            writer.write(example.SerializeToString())\n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom glob import glob\nimport tensorflow as tf\nfrom PIL import ImageFont\nfrom typing import List, Tuple\nfrom collections import Counter\nimport plotly.graph_objects as go\nfrom matplotlib import pyplot as plt\nfrom plotly.subplots import make_subplots\nfrom kaggle_datasets import KaggleDatasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TFRecordLoader:\n\n    def __init__(self, image_size: List[int], n_classes: int, include_yellow_channel: bool):\n        self.image_size = image_size\n        self.n_classes = n_classes\n        self.include_yellow_channel = include_yellow_channel\n\n    def _parse_image(self, image):\n        image = tf.image.decode_png(image, channels=3)\n        image = tf.cast(image, dtype=tf.float32) / 255.0\n        image = tf.image.resize(image, self.image_size)\n        \n        return image\n\n    def _parse_label(self, label):\n        indices = tf.strings.to_number(\n            label       \n        )\n        indices =tf.cast(indices ,dtype = tf.uint8)\n        return tf.one_hot(indices, depth=self.n_classes)\n        \n\n    def _make_example(self, example):\n        feature_format = {\n            'image': tf.io.FixedLenFeature([], dtype=tf.string),\n            'image_name': tf.io.FixedLenFeature([], dtype=tf.string),\n            'target': tf.io.FixedLenFeature([], dtype=tf.string)\n        }\n        features = tf.io.parse_single_example(example, features=feature_format)\n        image = self._parse_image(features['image'])\n        image_name = features['image_name']\n        label = self._parse_label(features['target'])\n        return image, image_name, label\n\n    def _combine_channels(self, red, green, blue, yellow):\n        # Ref: https://www.kaggle.com/dschettler8845/hpa-xai-ig-tfrecords-tpu-training\n        (r_i, r_j, r_k), (g_i, g_j, g_k), (b_i, b_j, b_k), (y_i, y_j, y_k) = red, green, blue, yellow\n        combined_image = tf.stack(\n            [r_i[..., 0], g_i[..., 0], b_i[..., 0], y_i[..., 0]], axis=-1\n        ) if self.include_yellow_channel else tf.stack(\n            [r_i[..., 0], g_i[..., 0], b_i[..., 0]], axis=-1\n        )\n        return combined_image, r_k\n\n    def _preprocess(self, dataset):\n        # Ref: https://www.kaggle.com/dschettler8845/hpa-xai-ig-tfrecords-tpu-training\n        red_dataset = dataset.filter(\n            lambda x, y, z: tf.strings.regex_full_match(y, \".*red.*\"))\n        green_dataset = dataset.filter(\n            lambda x, y, z: tf.strings.regex_full_match(y, \".*green.*\"))\n        blue_dataset = dataset.filter(\n            lambda x, y, z: tf.strings.regex_full_match(y, \".*blue.*\"))\n        yellow_dataset = dataset.filter(\n            lambda x, y, z: tf.strings.regex_full_match(y, \".*yellow.*\"))\n        dataset = tf.data.Dataset.zip(\n            (red_dataset, green_dataset, blue_dataset, yellow_dataset)\n        )\n        dataset = dataset.map(\n            map_func=self._combine_channels,\n            num_parallel_calls=tf.data.AUTOTUNE\n        )\n        return dataset\n\n    def get_dataset(self, train_tfrecord_files: List[str], ignore_order: bool = False):\n        options = tf.data.Options()\n        options.experimental_deterministic = False\n        dataset = tf.data.TFRecordDataset(\n            train_tfrecord_files, num_parallel_reads=tf.data.AUTOTUNE)\n        dataset = dataset.with_options(options) if ignore_order else dataset\n        dataset = dataset.map(\n            map_func=self._make_example, num_parallel_calls=tf.data.AUTOTUNE)\n        #dataset = self._preprocess(dataset)\n        return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loader = TFRecordLoader(\n    image_size=[224,224], n_classes=19, include_yellow_channel=False\n)\ndataset = loader.get_dataset('./tfrecords/file_00-4096.tfrec')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in dataset.take(1\n                     ):\n    plt.imshow(x[0])\n    print(x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}