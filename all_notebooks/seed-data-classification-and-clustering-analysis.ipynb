{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/seed-from-uci/Seed_Data.csv')\ndf=df.sample(frac=0.5,random_state=3)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.sample(frac=1,random_state=3)\ny=df['target']\nx=df.drop('target',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts(normalize=True).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building predictive algorithm using random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=3)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nXs=ss.fit_transform(x)\n\nX_trains=ss.fit_transform(X_train)\nX_tests=ss.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve\nfrom sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=100)\n\nrfc.fit(X_trains,y_train)\ny_train_pred =rfc.predict(X_trains)\ny_train_prob = rfc.predict_proba(X_trains)[:,1]\n\nprint('Confusion Matrix - Train: \\n', confusion_matrix(y_train, y_train_pred))\nprint('\\n')\nprint('Overall Accuracy - Train: ', accuracy_score(y_train, y_train_pred))\n#print('AUC - Train: ', roc_auc_score(y_train, y_train_prob))\n\ny_test_pred = rfc.predict(X_tests)\ny_test_prob = rfc.predict_proba(X_tests)[:,1]\n\nprint('\\n')\nprint('Confusion Matrix - Test: \\n', confusion_matrix(y_test, y_test_pred))\nprint('\\n')\nprint('Overall Accuracy - Test: ', accuracy_score(y_test, y_test_pred))\n'''print('AUC - Test: ', roc_auc_score(y_test, y_test_prob))\n\n\nfpr,tpr,th=roc_curve(y_test, y_test_prob)\nfig,ax=plt.subplots()\nplt.plot(fpr,tpr)\nplt.plot(fpr,fpr)\nax1=ax.twinx()'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb=GaussianNB()\ngnb.fit(X_trains,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = gnb.predict(X_trains)\ny_train_prob = gnb.predict_proba(X_trains)[:,1]\n\nprint('Confusion Matrix - Train: \\n', confusion_matrix(y_train, y_train_pred))\nprint('\\n')\nprint('Overall Accuracy - Train: ', accuracy_score(y_train, y_train_pred))\n\n\ny_test_pred = gnb.predict(X_tests)\ny_test_prob = gnb.predict_proba(X_tests)[:,1]\n\nprint('\\n')\nprint('Confusion Matrix - Test: \\n', confusion_matrix(y_test, y_test_pred))\nprint('\\n')\nprint('Overall Accuracy - Test: ', accuracy_score(y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\nfrom scipy.stats import randint as sp_randint\n\nknn=KNeighborsClassifier()\n\nparams={'n_neighbors':sp_randint(1,20),'p':sp_randint(1,5)}\n\nrsearch_knn=RandomizedSearchCV(knn,param_distributions=params,cv=3,n_iter=50,return_train_score=True,random_state=3,n_jobs=-1)\nrsearch_knn.fit(Xs,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsearch_knn.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,roc_auc_score,roc_curve\n\n\nknn=KNeighborsClassifier(**rsearch_knn.best_params_)\n\n# done above\nknn.fit(X_trains,y_train)\ny_train_pred = knn.predict(X_trains)\ny_train_prob = knn.predict_proba(X_trains)[:,1]\n\nprint('Confusion Matrix - Train: \\n', confusion_matrix(y_train, y_train_pred))\nprint('\\n')\nprint('Overall Accuracy - Train: ', accuracy_score(y_train, y_train_pred))\n#print('AUC - Train: ', roc_auc_score(y_train, y_train_prob))\n\ny_test_pred = knn.predict(X_tests)\ny_test_prob = knn.predict_proba(X_tests)[:,1]\n\nprint('\\n')\nprint('Confusion Matrix - Test: \\n', confusion_matrix(y_test, y_test_pred))\nprint('\\n')\nprint('Overall Accuracy - Test: ', accuracy_score(y_test, y_test_pred))\nprint('Classification Report-Test: \\n', classification_report(y_test,y_test_pred))\n#print('AUC - Test: ', roc_auc_score(y_test, y_test_prob))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KMeans(n_clusters = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import zscore\ndf_scaled=df.apply(zscore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_range = range( 1, 10 )\ncluster_errors = []\nfor num_clusters in cluster_range:\n  clusters = KMeans( num_clusters, n_init = 10 )\n  clusters.fit(df_scaled)\n  cluster_errors.append( clusters.inertia_ )\nclusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )\nclusters_df[0:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans=KMeans(n_clusters=3, n_init=15,random_state=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.fit(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"centroids=kmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(centroids,columns=df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scaled['Class']=kmeans.labels_.astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scaled['Class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_k=df_scaled.copy()\ndf_k.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8, 6))\nax = Axes3D(fig, rect=[0, 0, .95, 1], elev=20, azim=100)\nkmeans.fit(df)\nlabels = kmeans.labels_\nax.scatter(df_scaled.iloc[:, 0], df_scaled.iloc[:, 1], df_scaled.iloc[:, 3],c=labels.astype(np.float), edgecolor='k')\nax.w_xaxis.set_ticklabels([])\nax.w_yaxis.set_ticklabels([])\nax.w_zaxis.set_ticklabels([])\nax.set_xlabel('Length')\nax.set_ylabel('Height')\nax.set_zlabel('Weight')\nax.set_title('3D plot of KMeans Clustering')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import linkage, dendrogram\nplt.figure(figsize=[10,10])\nmerg = linkage(df, method='ward')\ndendrogram(merg, leaf_rotation=90)\nplt.title('Dendrogram')\nplt.xlabel('Data Points')\nplt.ylabel('Euclidean Distances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\n\nhie_clus = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\ncluster2 = hie_clus.fit_predict(df)\n\ndf_h = df.copy(deep=True)\ndf_h['label'] = cluster2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_h","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('K-Means Predicted Data Classes:')\nprint(df_k['Class'].value_counts())\nprint('-' * 30)\nprint('Hierarchical Predicted Data Classes:')\nprint(df_h['label'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df_h,hue='label')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from __future__ import print_function\n%matplotlib inline\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\n\nprint(__doc__)\n\n# Generating the sample data from make_blobs\n# This particular setting has one distinct cluster and 3 clusters placed close\n# together.\nX=np.array(df.drop('target',axis=1))\ny=np.array(df['target'])\n\nrange_n_clusters = [2, 3, 4, 5, 6]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.Spectral(float(i) / n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.Spectral(cluster_labels.astype(float) / n_clusters)\n    ax2.scatter(X[:,0], X[:,1], marker='.', s=30, lw=0, alpha=0.7,c=colors)\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 1],\n                marker='o', c=\"white\", alpha=1, s=200)\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Do Upvote if you like my work!!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}