{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Salary Prediction for Hitters Dataset with Linear and Non-Linear Models\n\nIn this project, we will build several linear and non-linear models on the Hitters dataset. After creating base models, some of them will be tuned to minimize prediction errors in terms of the RMSE metric. To split the dataset for training and test purposes, K-fold Cross-Validation will be used. Linear models used in this project are Linear Regression, Ridge, Lasso, ElasticNet. Non-linear models used in this project are regression implementations of K-Nearest Neighbors (KNN), Classification and Regression Trees (CART), Random Forest (RF), Support Vector Machine (SVM), Gradient Boosting Machine (GBM), eXtreme Gradient Boosting (XGB), and Light-GBM (LGBM).\n\n### Context of Study:\n\n* Understanding Data\n* Exploratory Data Analysis\n* Data Preparation\n* Feature Engineering\n* Constructing Base Models (Linear and Non-linear)\n* Hyperparameter Tuning for Some Models\n* Conclusion","metadata":{}},{"cell_type":"markdown","source":"### Understanding Data\n\nHitters dataset includes Major League Baseball (MLB) data from the seasons 1986 and 1987.\nSource: This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\nA data frame with 322 observations of major league players on the following 20 variables.\n\n#### Variables:\n* AtBat: Number of times at bat in 1986\n* Hits: Number of hits in 1986\n* HmRun: Number of home runs in 1986\n* Runs: Number of runs in 1986\n* RBI: Number of runs batted in in 1986\n* Walks: Number of walks in 1986\n* PutOuts: Number of put outs in 1986\n* Assists: Number of assists in 1986\n* Errors: Number of errors in 1986\n* CAtBat: Number of times at bat during his career\n* CHits: Number of hits during his career\n* CHmRun: Number of home runs during his career\n* CRuns: Number of runs during his career\n* CRBI: Number of runs batted in during his career\n* CWalks: Number of walks during his career\n* Years:Number of years in the major leagues\n* League: A factor with levels A and N indicating player's league at the end of 1986\n* Division: A factor with levels E and W indicating player's division at the end of 1986\n* NewLeague: A factor with levels A and N indicating player's league at the beginning of 1987\n* Salary: 1987 annual salary on opening day in thousands of dollars\n","metadata":{}},{"cell_type":"code","source":"# install required model libraries\n#!pip install xgboost\n#!pip install lightgbm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-14T12:52:54.427445Z","iopub.execute_input":"2021-07-14T12:52:54.427867Z","iopub.status.idle":"2021-07-14T12:52:54.431814Z","shell.execute_reply.started":"2021-07-14T12:52:54.427834Z","shell.execute_reply":"2021-07-14T12:52:54.430783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ignore warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\n\n# linear models\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n# non-linear models\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:52:54.798582Z","iopub.execute_input":"2021-07-14T12:52:54.799172Z","iopub.status.idle":"2021-07-14T12:52:54.807223Z","shell.execute_reply.started":"2021-07-14T12:52:54.799134Z","shell.execute_reply":"2021-07-14T12:52:54.805748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read the Hitters dataset\ndata = pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")\n# copy loaded data into df\ndf = data.copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:52:55.70649Z","iopub.execute_input":"2021-07-14T12:52:55.707121Z","iopub.status.idle":"2021-07-14T12:52:55.724566Z","shell.execute_reply.started":"2021-07-14T12:52:55.707081Z","shell.execute_reply":"2021-07-14T12:52:55.722747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:52:56.900975Z","iopub.execute_input":"2021-07-14T12:52:56.901436Z","iopub.status.idle":"2021-07-14T12:52:56.92731Z","shell.execute_reply.started":"2021-07-14T12:52:56.901399Z","shell.execute_reply":"2021-07-14T12:52:56.925647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of rows and columns in data\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:52:57.262647Z","iopub.execute_input":"2021-07-14T12:52:57.263063Z","iopub.status.idle":"2021-07-14T12:52:57.271018Z","shell.execute_reply.started":"2021-07-14T12:52:57.263027Z","shell.execute_reply":"2021-07-14T12:52:57.269767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# descriptive statistics for data\ndf.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:52:58.434032Z","iopub.execute_input":"2021-07-14T12:52:58.434456Z","iopub.status.idle":"2021-07-14T12:52:58.503905Z","shell.execute_reply.started":"2021-07-14T12:52:58.434421Z","shell.execute_reply":"2021-07-14T12:52:58.502448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preparation","metadata":{}},{"cell_type":"code","source":"# categorical features\ncat_cols = [col for col in df.columns if df[col].dtypes == \"O\"]\n# numerical features except for target (Salary)\nnum_cols = [col for col in df.columns if df[col].dtypes != \"O\" and col not in \"Salary\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:53:00.648948Z","iopub.execute_input":"2021-07-14T12:53:00.649363Z","iopub.status.idle":"2021-07-14T12:53:00.655684Z","shell.execute_reply.started":"2021-07-14T12:53:00.649326Z","shell.execute_reply":"2021-07-14T12:53:00.654872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check outliers in data and replace them with thresholds\nq1 = 0.10\nq3 = 0.90\nfor col in num_cols:\n    quartile1 = df[col].quantile(q1)\n    quartile3 = df[col].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    if df[(df[col] > up_limit) | (df[col] < low_limit)].any(axis=None):\n        df.loc[(df[col] < low_limit),col] = low_limit\n        df.loc[(df[col] > up_limit), col] = up_limit","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:53:01.17282Z","iopub.execute_input":"2021-07-14T12:53:01.173427Z","iopub.status.idle":"2021-07-14T12:53:01.248955Z","shell.execute_reply.started":"2021-07-14T12:53:01.17339Z","shell.execute_reply":"2021-07-14T12:53:01.248274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove outliers for Salary and keep NaN values\nsalary_up = int(df[\"Salary\"].quantile(q3))\ndf = df[(df[\"Salary\"] < salary_up) | (df[\"Salary\"].isnull())]\n# data shape after removing outliers in Salary\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:53:02.247025Z","iopub.execute_input":"2021-07-14T12:53:02.247662Z","iopub.status.idle":"2021-07-14T12:53:02.257541Z","shell.execute_reply.started":"2021-07-14T12:53:02.247624Z","shell.execute_reply":"2021-07-14T12:53:02.256457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of NaN values in each feature\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:53:03.369071Z","iopub.execute_input":"2021-07-14T12:53:03.369467Z","iopub.status.idle":"2021-07-14T12:53:03.381138Z","shell.execute_reply.started":"2021-07-14T12:53:03.369437Z","shell.execute_reply":"2021-07-14T12:53:03.379682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove rows containing NaN values\ndf.dropna(inplace=True)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:53:04.686136Z","iopub.execute_input":"2021-07-14T12:53:04.686737Z","iopub.status.idle":"2021-07-14T12:53:04.698964Z","shell.execute_reply.started":"2021-07-14T12:53:04.686691Z","shell.execute_reply":"2021-07-14T12:53:04.69768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding of categorical features (League, Division, NewLeague) with two class \nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float] and df[col].nunique() == 2]\nfor col in binary_cols:\n    labelencoder = LabelEncoder()\n    df[col] = labelencoder.fit_transform(df[col])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:53:06.133061Z","iopub.execute_input":"2021-07-14T12:53:06.13358Z","iopub.status.idle":"2021-07-14T12:53:06.143655Z","shell.execute_reply.started":"2021-07-14T12:53:06.133548Z","shell.execute_reply":"2021-07-14T12:53:06.142773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:53:07.229121Z","iopub.execute_input":"2021-07-14T12:53:07.229694Z","iopub.status.idle":"2021-07-14T12:53:07.254851Z","shell.execute_reply.started":"2021-07-14T12:53:07.229657Z","shell.execute_reply":"2021-07-14T12:53:07.253692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering\n\nFor creating new features, it is important to have domain knowledge about the data we have. For this purpose, I tried to get insights from the glossary of mlb.com the official site of Major League Baseball. I also created some features myself that I think might be useful.","metadata":{}},{"cell_type":"code","source":"df[\"New_BattingAverage\"] = df[\"CHits\"] / df[\"CAtBat\"]\ndf[\"New_TotalBases\"] =  ((df[\"CHits\"] * 2) + (4 * df[\"CHmRun\"]))\ndf[\"New_SluggingPercentage\"] = df[\"New_TotalBases\"] / df[\"CAtBat\"]\ndf[\"New_IsolatedPower\"] = df[\"New_SluggingPercentage\"] - df[\"New_BattingAverage\"]\ndf[\"New_TripleCrown\"] = (df[\"CHmRun\"] * 0.4) + (df[\"CRBI\"] * 0.25) + (df[\"New_BattingAverage\"] * 0.35)\ndf[\"New_BattingAverageOnBalls\"] = (df[\"CHits\"] - df[\"CHmRun\"]) / (df[\"CAtBat\"] - df[\"CHmRun\"])\ndf[\"New_RunsCreated\"] = df[\"New_TotalBases\"] * (df[\"CHits\"] + df[\"CWalks\"]) / (df[\"CAtBat\"] + df[\"CWalks\"])\ndf[\"New_FieldingPercentage\"] = 1 - ((df[\"PutOuts\"] + df[\"Assists\"]) / (df[\"PutOuts\"] + df[\"Assists\"] + df[\"Errors\"] + 1))\n\ndf[\"New_CRunsYearsRatio\"] = df[\"CRuns\"] / df[\"Years\"]\ndf['New_PutOutsYears'] = df['PutOuts'] * df['Years']\ndf[\"New_RBIWalks\"] = df[\"RBI\"] * df[\"Walks\"]\ndf[\"New_RBIWalksRatio\"] = df[\"RBI\"] / df[\"Walks\"]\ndf[\"New_CHmRunCAtBatRatio\"] = df[\"CHmRun\"] / df[\"CAtBat\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T13:10:48.023623Z","iopub.execute_input":"2021-07-14T13:10:48.026292Z","iopub.status.idle":"2021-07-14T13:10:48.083045Z","shell.execute_reply.started":"2021-07-14T13:10:48.026042Z","shell.execute_reply":"2021-07-14T13:10:48.081716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Constructing Base Models (Linear and Non-linear)","metadata":{}},{"cell_type":"code","source":"# assign X (input features) and y (target feature)\nX = df.drop([\"Salary\"], axis=1)\ny = df[\"Salary\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T13:10:51.191779Z","iopub.execute_input":"2021-07-14T13:10:51.19228Z","iopub.status.idle":"2021-07-14T13:10:51.204608Z","shell.execute_reply.started":"2021-07-14T13:10:51.19222Z","shell.execute_reply":"2021-07-14T13:10:51.203197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list feature importances for a regressor model like LGBM\npre_model = LGBMRegressor(random_state=17).fit(X, y)\nfeature_imp = pd.DataFrame({'Feature': X.columns, 'Value': pre_model.feature_importances_})\nfeature_imp.sort_values(\"Value\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T13:10:52.259867Z","iopub.execute_input":"2021-07-14T13:10:52.260508Z","iopub.status.idle":"2021-07-14T13:10:52.357534Z","shell.execute_reply.started":"2021-07-14T13:10:52.260468Z","shell.execute_reply":"2021-07-14T13:10:52.356567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_models = [('LR', LinearRegression()), \n               (\"Ridge\", Ridge(random_state=17)),\n               (\"Lasso\", Lasso(random_state=17)),\n               (\"ElasticNet\", ElasticNet(random_state=17)),\n               ('KNN', KNeighborsRegressor()),\n               ('CART', DecisionTreeRegressor(random_state=17)),\n               ('RF', RandomForestRegressor(random_state=17)),\n               ('SVR', SVR()),\n               ('GBM', GradientBoostingRegressor(random_state=17)),\n               (\"XGBoost\", XGBRegressor(objective='reg:squarederror', random_state=17)),\n               (\"LightGBM\", LGBMRegressor(random_state=17))]\n\nfor name, model in base_models:\n    rmse = np.mean(np.sqrt(-cross_val_score(model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")","metadata":{"execution":{"iopub.status.busy":"2021-07-14T13:10:54.957261Z","iopub.execute_input":"2021-07-14T13:10:54.957709Z","iopub.status.idle":"2021-07-14T13:11:04.232047Z","shell.execute_reply.started":"2021-07-14T13:10:54.957668Z","shell.execute_reply":"2021-07-14T13:11:04.231128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter Tuning for Some Models","metadata":{}},{"cell_type":"code","source":"# GridSearchCV parameter space for selected models\nknn_params = {\"n_neighbors\": list(range(1, 31)),\n              \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]}\n\ncart_params = {'max_depth': range(1, 20),\n               \"min_samples_split\": range(2, 30)}\n\nrf_params = {\"max_depth\": [5, 8, 15, None],\n             \"max_features\": [5, 7, \"auto\"],\n             \"min_samples_split\": [8, 15, 20],\n             \"n_estimators\": [100, 200, 300]}\n\nlightgbm_params = {\"learning_rate\": [0.01, 0.1, 0.001],\n                   \"n_estimators\": [300, 500, 1500],\n                   \"colsample_bytree\": [0.5, 0.7, 1]}","metadata":{"execution":{"iopub.status.busy":"2021-07-14T13:11:08.790063Z","iopub.execute_input":"2021-07-14T13:11:08.79095Z","iopub.status.idle":"2021-07-14T13:11:08.801077Z","shell.execute_reply.started":"2021-07-14T13:11:08.790892Z","shell.execute_reply":"2021-07-14T13:11:08.799618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fast_models = [(\"KNN\", KNeighborsRegressor(), knn_params),\n              (\"CART\", DecisionTreeRegressor(random_state=17), cart_params),\n              (\"RF\", RandomForestRegressor(random_state=17), rf_params),\n              (\"LightGBM\", LGBMRegressor(random_state=17), lightgbm_params)]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T13:11:14.683167Z","iopub.execute_input":"2021-07-14T13:11:14.683875Z","iopub.status.idle":"2021-07-14T13:11:14.689215Z","shell.execute_reply.started":"2021-07-14T13:11:14.683829Z","shell.execute_reply":"2021-07-14T13:11:14.688401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_models = {}\n\nfor name, model, params in fast_models:\n    rmse = np.mean(np.sqrt(-cross_val_score(model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE (Before): {round(rmse, 4)} ({name}) \")\n    gs_best = GridSearchCV(model, params, cv=3, n_jobs=-1, verbose=False).fit(X, y)\n    final_model = model.set_params(**gs_best.best_params_)\n    rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE (After): {round(rmse, 4)} ({name}) \")\n    print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n    best_models[name] = final_model","metadata":{"execution":{"iopub.status.busy":"2021-07-14T13:11:26.454855Z","iopub.execute_input":"2021-07-14T13:11:26.455437Z","iopub.status.idle":"2021-07-14T13:12:57.843007Z","shell.execute_reply.started":"2021-07-14T13:11:26.455399Z","shell.execute_reply":"2021-07-14T13:12:57.841351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion\n\nIn conclusion, the best model seems like **RF** with a **154.9561** score of root-mean-squared error (RSME). RMSE is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed. \n\nConsidering the feature importances, it is seen that the newly created features are effective in the success of the model, although it varies according to the model used.\n\n* After setting q1=0.05, q3=0.95, and removing outliers in \"Salary\", 249 rows left and achieved 185.6107 RSME score with tuned RF.\n* After setting q1=0.10, q3=0.90, and removing outliers in \"Salary\", 236 rows left and achieved 154.9561 RSME score with tuned RF.\n* After setting q1=0.20, q3=0.80, and removing outliers in \"Salary\", 210 rows left and achieved 126.4241 RSME score with tuned RF.\n* After setting q1=0.25, q3=0.75, and removing outliers in \"Salary\", 193 rows left and achieved 118.4944 RSME score with tuned RF.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}