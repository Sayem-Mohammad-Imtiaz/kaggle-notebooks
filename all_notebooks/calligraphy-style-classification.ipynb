{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\" role=\"alert\">\n  <h1 class=\"alert-heading\">Working with the Chinese Calligraphy Styles dataset*</h1>\n  <p><i>*By Kauvin Lucas, submitted in Kaggle[1] and Jovian[2]. More details in the references section.</i></p>"},{"metadata":{},"cell_type":"markdown","source":"![header](https://i.imgur.com/XzJ2RvS.png)"},{"metadata":{},"cell_type":"markdown","source":"Chinese calligraphy is a very unique visual art and an important manifestation of Chinese ancient culture which is popular with many people in the world [3]. As with any other artwork, Chinese calligraphy can take several years to master and have a high economic value for the holders. \n\nAlthough it's a form of art, there are traditional, strict rules that must be followed to make a legitimate calligraphy. Still, the style of each calligraphy is unique and anyone looking at it can tell its caligrapher.\n\nIn this notebook, we'll build and test a simple Convolutional Neural Network (CNN) model with 9 layers without batch normalization to identify the author's initials of each available font. Compared to other classification models, CNN performs well without feature design [4]."},{"metadata":{},"cell_type":"markdown","source":"### 1 - Install and import the required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install jovian --upgrade -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import random_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data.dataloader import DataLoader\nfrom torchvision.utils import make_grid\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport jovian","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2 - Load and transform the the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/chinese-calligraphy-styles-by-calligraphers/data/data'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = ImageFolder(data_dir+'/train', transform=ToTensor())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3 - Explore the dataset"},{"metadata":{},"cell_type":"markdown","source":"#### 3.1 - How many classes are in the dataset?"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = os.listdir(data_dir + \"/train\")\nprint(os.listdir(data_dir))\nprint(classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a total of 20 classes in the dataset"},{"metadata":{},"cell_type":"markdown","source":"#### 3.2 - How many examples are in each class?"},{"metadata":{"trusted":true},"cell_type":"code","source":"for class_ in classes:\n    print(\"Class \"+ class_ + \": \" + str(len(os.listdir(data_dir + \"/train/\" + class_))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All of the classes contain a total of 82022 images"},{"metadata":{},"cell_type":"markdown","source":"#### 3.3 - Visualize 3 examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_example(img, label):\n    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example from class 1\nimg1, label1 = dataset[0]\nprint(img1.shape, label1)\nprint(img1)\nshow_example(*dataset[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example from class 9\nimg2, label2 = dataset[40000]\nprint(img2.shape, label2)\nprint(img2)\nshow_example(*dataset[40000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example from class 12\nimg2, label2 = dataset[55000]\nprint(img2.shape, label2)\nprint(img2)\nshow_example(*dataset[55000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4 - Split the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = 1234\ntorch.manual_seed(random_seed);\n\nval_size = 8202 # 10% of the total size\ntrain_size = len(dataset) - val_size\n\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5 - Load data in batches"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=128\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_batch(train_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6 - Modelling"},{"metadata":{},"cell_type":"markdown","source":"#### 6.1 - Test a simple model"},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_model = nn.Sequential(\n    nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n    nn.MaxPool2d(2, 2)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = simple_model(images)\n    print('out.shape:', out.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If our simple model has been called without problems, we'll proceed to define our main CNN model"},{"metadata":{},"cell_type":"markdown","source":"#### 6.2 - Define helper functions for training and validation\nWe will use the Cross Entropy loss function for calculating loss in the training and validation steps"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n        \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.3 - Chain layers into a single network architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Cifar10CnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n\n            nn.Flatten(), \n            nn.Linear(16384, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 20))\n        \n    def forward(self, xb):\n        return self.network(xb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Cifar10CnnModel()\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.4 - Build helper functions to move model and data to a CUDA device"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = get_default_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7 - Training"},{"metadata":{},"cell_type":"markdown","source":"#### 7.1 - Define functions to fit and evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7.2 - Move model to device"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = to_device(Cifar10CnnModel(), device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7.3 - Evaluate the model by its initial parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(model, val_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7.4 - Define and log hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define hyperparameters\nnum_epochs = 6 # Number of epochs, enough to prevent overfitting\nopt_func = torch.optim.Adam # Implements Adam algorithm for optimization\nlr = 0.001 # Learning rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log hyperparamenters to Jovian\njovian.reset()\njovian.log_hyperparams({\n    'num_epochs': num_epochs,\n    'opt_func': opt_func.__name__,\n    'batch_size': batch_size,\n    'lr': lr,\n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7.5 - Fit model and log metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# log fitted model metrics to Jovian\njovian.log_metrics(train_loss=history[-1]['train_loss'], \n                   val_loss=history[-1]['val_loss'], \n                   val_acc=history[-1]['val_acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7.6 - Plot accuracy and loss history"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot accuracy history\ndef plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\nplot_accuracies(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot loss history\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_losses(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8 - Testing"},{"metadata":{},"cell_type":"markdown","source":"#### 8.1 - Transform test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8.2 - Predict and compare labels (5 examples)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return dataset.classes[preds[0].item()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dataset[0]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dataset[1002]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dataset[6153]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dataset[12000]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = test_dataset[14560]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8.4 - Look for overall loss and accuracy on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\nresult = evaluate(model, test_loader)\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8.5 - Save the model once it's done"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), 'cifar10-cnn.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = to_device(Cifar10CnnModel(), device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.load_state_dict(torch.load('cifar10-cnn.pth'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9 - Final commit to Jovian"},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=\"calligraphy-style-classification\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 10 - Conclusion and final remarks"},{"metadata":{"trusted":false},"cell_type":"markdown","source":"We've defined our model with 9 layers, and after trying with different hyperparamenters, we arrived at a model that performed quite well and generated an accuracy of **96%** on the test data. No batch normalization was employed since this overfitted the model.\n\nThis notebook was intented to explore simple CNN models to predict the caligraphers initials behind each calligraphy font. Of course, a few things could be done to improve the model like applying augmentation schemes on the training data."},{"metadata":{},"cell_type":"markdown","source":"### 11 - References"},{"metadata":{},"cell_type":"markdown","source":"[1] \"Calligraphy Style Classification\", by Kauvin Lucas in Kaggle: https://www.kaggle.com/kauvinlucas/calligraphy-style-classification.\n\n[2] \"Calligraphy Style Classification\", by Kauvin Lucas in Jovian: https://jovian.ai/kauvinlucas/calligraphy-style-classification.\n\n[3] Auto-Encoder Guided GAN for Chinese Calligraphy Synthesis, by Pengyuan Lyu, Xiang Bai, Cong Yao, Zhen Zhu, Tengteng Huang, Wenyu Liu1 in 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR): https://doi.org/10.1109/ICDAR.2017.181\n\n[4] Recognizing Chinese Calligraphy Styles: A Cage Fight, by Chen Yu-Sheng, Li Haihong, Su Guangjun in Stanford University:http://cs229.stanford.edu/proj2016/poster/ChenSuLi-Machine%20Learning%20for%20Different%20Calligraphy%20Style%20Recognition-poster.pdf"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}