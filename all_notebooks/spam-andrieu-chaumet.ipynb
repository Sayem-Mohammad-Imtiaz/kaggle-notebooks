{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# On importe toutes les librairies utiles \nimport seaborn as sns\nimport pandas as pd\nimport string\nfrom nltk.tokenize import word_tokenize\nimport nltk\nfrom nltk.stem import WordNetLemmatizer   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On charge les données dans sms \nsms = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding='latin-1')\nsms.head() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on supprime les 3 autres colonnes avec drop \nsms=sms.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'] ) \nsms ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on renomme les deux colonnes v1 et V2\nsms=sms.rename(columns={'v1':'label','v2':'message'})\nsms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on affiche le diagramme de label avec countplot \nax=sns.countplot(x=\"label\", data=sms) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On affiche les dimensions de la dataframe \nsms.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Questions 9: nettoyage","metadata":{}},{"cell_type":"code","source":"#mettre en minuscule \nsms['message']=sms['message'].str.lower()\nsms       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On affiche les punctuations pour voir ce qu'on va enelever  \nstring.punctuation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On créé la fonction remove punct \ndef remove_punct(text):\n    text_tok = word_tokenize(text)\n    A=[]\n    for word in text_tok: \n        if not word in string.punctuation:\n            A.append(word)\n            \n    resultat=\" \".join(A)  \n    return resultat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On applique la fonction de retrait des ponctuations \nsms.message=sms.message.apply(remove_punct)\nsms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Télécharger les stopwords\nfrom nltk.corpus import stopwords\n# on affiche les stopwords en les incrémentant dans stop\nstop=set(stopwords.words('english'))\nstop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on créé la fonction de retrait des stopsword\ndef remove_stopword(text):\n    text_tok = word_tokenize(text)\n    A = []\n    for a in text_tok:\n        if not a in stop:\n            A.append(a)\n            \n    resultat =\" \".join(A)\n    return resultat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on applique la fonction de retrait des stopword et on affiche le résultat\nsms.message=sms.message.apply(remove_stopword)\nsms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlemmatizer=WordNetLemmatizer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On créé la fonction de lemmetizing\ndef lemm(text):\n    text_tok = word_tokenize(text) \n    l=[]\n    for word in text_tok:\n        l.append(lemmatizer.lemmatize(word))\n        \n    resultat = \" \".join(l)\n\n    return resultat\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On applique la fonction de lemmetizing et on affiche le résultat\nsms.message=sms.message.apply(lemm)\nsms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# la colonne message est nettoyée","metadata":{}},{"cell_type":"code","source":"#On affecte les messages dans corpus afin de s'en reservir \ncorpus=sms['message'].values\ncorpus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bag of words\n","metadata":{}},{"cell_type":"code","source":"#On vectorise pour bag of words \nfrom sklearn.feature_extraction.text import CountVectorizer\nbw_vect = CountVectorizer()\nbw_fit=bw_vect.fit(corpus)\n# on vectorise les mots \nbw_corpus = bw_fit.transform(corpus)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on affiche sous forme de dataframe \nbw_sms=pd.DataFrame(bw_corpus.toarray(),columns=bw_fit.get_feature_names())\nbw_sms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On créé et sauvegarde dans XX et Y \nfrom sklearn.model_selection import train_test_split\nY=sms.label\nXX=bw_sms\n# On divise les deux variables en deux parties chacunes  \nXX_train, XX_test, Y_train, Y_test = train_test_split(XX, Y, test_size=0.3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On paramètre l'arbre de décision \nfrom sklearn import tree\ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model=tree_model.fit(XX_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On compte les valeurs dans Y_train\nY_train.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On affiche l'arbre de décision en paramerant sa taille et ses titres \nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'ham']\ntree.plot_tree(tree_model,feature_names = XX.columns, \n               class_names=names,\n               filled = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On regarde si XX test contient des spam et on sauvegarde dans Y_Predict \nY_predict=tree_model.predict(XX_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On affiche la matrice de confusion entre Y_Predict et Y_test \nfrom sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predict,Y_test)\nprint(mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On affiche sous forme graphique la matrice de confusion avec une heatmap\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On a énormément de spam, on remarque que on a des erreur de tri entre les predictions et le test (41 confusions entre prédit ham et testé spam, 92 prédit spam et testés ham). ","metadata":{}},{"cell_type":"markdown","source":"# TFI DF","metadata":{}},{"cell_type":"code","source":"#On importe la fonction \nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On initialise les paramètres du vectoriseur \ntf_vect = TfidfVectorizer(max_features=5000)  \ntfidf_fit=tf_vect.fit(corpus)\n#on vectorise le corpus déclaré plus haut \ntfidf_corpus= tfidf_fit.transform(corpus)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on affiche les vecteurs \ntfidf_fit.get_feature_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on met sous forme de dataframe \ntfidf_data=pd.DataFrame(tfidf_corpus.toarray(),columns=tfidf_fit.get_feature_names())\ntfidf_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on enregistre dans X et Y label et le corpus \nfrom sklearn.model_selection import train_test_split\nY=sms.label\nX=tfidf_corpus \n# on utilise la fonction train test split \nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on implémente les méthodes fit et predict\nfrom sklearn import tree\n#on paramètre l'arbre de décision \ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model=tree_model.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on compte les valeurs contenue dans le Y_train \nY_train.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on affiche l'arbre de décision en paramétrant son affichage \nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'ham']\ntree.plot_tree(tree_model,feature_names = Y_train, \n               class_names=names,\n               filled = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on stocke dans Y predict la réponse \nY_predict=tree_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on calcule la matrice de confusion \nfrom sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predict,Y_test)\nprint(mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On  affiche la matrice confusion sous forme de heatmap\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Question 16**\nOn peut voir que l'on a 11 confusions entre des messages prédis comme ham et testé comme spam, on a également 118 confusions entre la prediction de spam et le test qui les a classé comme ham. ","metadata":{}},{"cell_type":"code","source":"#on importe gridsearch \nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On déclare toutes les deths que l'on veut tester \ndepths = np.arange(10, 40,5) # The maximum depth of the tree\nparam_grid = [{'max_depth':depths}]\nparam_grid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on reprend l'arbre avec les différents deths \ngrid_tree= GridSearchCV(estimator=tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='accuracy',cv=10)\ngrid_tree.fit(X_train, Y_train)\nbest_model_tree = grid_tree.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Y_grid=best_model_tree.predict(X_test)\naccuracy_score(Y_test, Y_grid)\n","metadata":{}},{"cell_type":"code","source":"#On affiche le résultat \ngrid_tree.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Question 18","metadata":{}},{"cell_type":"code","source":"# on importe les methodes des foret d'arbres \nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Rf_model = RandomForestClassifier()\nRf_model=Rf_model.fit(X_train, Y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on calcule le accuracy score \nY_predict=Rf_model.predict(X_test)\na_CART = accuracy_score(Y_test,Y_predict)\nprint(\"Accuracy score: \",a_CART)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on affiche la matrice de confusion\nmat = confusion_matrix(Y_predict, Y_test)\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Question 19","metadata":{}},{"cell_type":"code","source":"tfidf_data=pd.DataFrame(tfidf_corpus.toarray(),columns=tfidf_fit.get_feature_names())\ntfidf_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classer(text):\n    text=text.lower()\n    text=remove_punct(text)\n    text=remove_stopword(text)\n    text=lemm(text)\n    tfidf_text=tfidf_fit.transform([text])\n    resultat=Rf_model.predict(tfidf_text)\n    \n    #if text == Y_test spam\n    #print ('spam')\n    #if text == Y_test spam \n    #print('ham')\n    \n    \n   \n    \n    return resultat\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Question 20","metadata":{}},{"cell_type":"code","source":"while True:\n    text = str(input(\"Input: \"))\n    if text== \"exit\":\n        print(\"Response: Exiting.....\")\n        break\n    print(\"Response:\",classer(text))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}