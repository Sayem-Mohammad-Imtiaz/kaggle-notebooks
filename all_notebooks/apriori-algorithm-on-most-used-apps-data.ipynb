{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:purple\">Apriori algo applied on apps used most...</h1>\n\n<p style=\"text-align:center; border:1px solid black\"><img style=\"text-align:center\",src=\"https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.macstories.net%2Fstories%2Fdevelopers-decade-long-rollercoaster-ride-the-business-of-selling-apps-on-the-app-store%2F&psig=AOvVaw10K7zSdrodFo3wCheb56AQ&ust=1608676511286000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCICX87aZ4O0CFQAAAAAdAAAAABAD\"></p>\n"},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"color:orange\" > This is my first NB to kaggle , do SUPPORT it if you like </h3>  \nn feel free to give your suggestions for further improvements"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## all about data:\n#### **the data has been collected through a survey of 30 students aged between 17-21 n asked to select the top apps they watch or stream or install?**\n#### **this data is cleaned and made into the format needed by the user to see the data**\n#### **there were 16 most famous app in choices among the data to choose from.**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as  np\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori,association_rules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/apps-user-used-the-most/apriori_data.csv')\ndata.head()\ndata['AppName'].dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### --as we see that the data is encoded as whole strings format \n### --so we convert and split the data into the lists format"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = list(data[\"AppName\"].apply(lambda x:x.split(',')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<h3> <p style=\"color:lightblue\" > we can clearly see from the table which apps were installed and which ones were not by the 30 individuals </p> </h3>"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:lightblue\" > so lets start !!  </h2>"},{"metadata":{},"cell_type":"markdown","source":"<html>\n\n<h3 style=\"color:orange\">\nwhat is association rule mining???? \n\nAssociation rule mining finds interesting associations and relationships among large sets of data items. This rule shows how frequently a itemset occurs in a transaction. \n</h3>\n\n<p style=\"color:orange\">\nBefore we start implementation of <b> # the apriori rule</b> \n    </p>\n    <h2 style=\"color:purple\">\n    <b>let us first see the basic definitions.⬇⬇⬇</b>\n    </h2>\n    \n</html>\n\n\n* Support Count(sigma) – Frequency of occurrence of a itemset.\n\n\n* Frequent Itemset – An itemset whose support is greater than or equal to minsup threshold.\n\n\n* Association Rule – An implication expression of the form X -> Y, where X and Y are any 2 itemsets.\n\n\n* Support(s) –The number of transactions that include items in the {X} and {Y} parts of the rule as a percentage of the total number of transaction.It is a measure of how frequently the collection of items occur together as a percentage of all transactions.\n\n\n*    **FORMULA** support = sigma(X+Y)/total items – It is interpreted as fraction of transactions that contain both X and Y.\n\n\n* Confidence(c) – It is the ratio of the no of transactions that includes all items in {B} as well as the no of transactions that includes all items in {A} to the no of transactions that includes all items in {A}.  \n\n* **FORMULA** Conf(X=>Y) = **Supp(XUY) / Supp(X)** – It measures how often each item in Y appears in transactions that contains items in X also.\n\n*    Lift(l) – he lift of the rule X=>Y is the confidence of the rule divided by the expected confidence, assuming that the itemsets X and Y are independent of each other.The  expected confidence is the confidence divided by the frequency of {Y}.\n\n\n* Lift(X=>Y) = Conf(X=>Y) / Supp(Y) – Lift value near 1 indicates X and Y almost often appear together as expected, greater than 1 means they appear together more than expected and less than 1  they appear less than expected.Greater lift values indicate stronger association.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"te = TransactionEncoder()\nte_data = te.fit(df).transform(df)\ndata = pd.DataFrame(te_data,columns=te.columns_)\ndata\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so,\n\nto keep it simple we have used a very low support price for the analysis \n\nmin_support == .30  i.e (30%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_items = apriori(data, min_support = 0.30, use_colnames = True, verbose = 1)\nfreq_items.sort_values(\"support\", ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:black'>Interpretation From Above :--</h2>\n\n<p style=\"color:violet\"> maximum support pair of apps was youtube n whatsapp(WA) - being used in tandom\n\n<p style=\"color:violet\"> instagram , youtube and WA had max support as triplet pair\n\n<p style=\"color:violet\"> and WA,insta,youtube,meet being the only 4 pair app with greater value of supporting threshold (30% in this case)\n\n\n<p style='color:orange'> the support values for the head n tail of the data \n\n<p style='color:orange'> youtube and whatsapp being highest in support pairs of 2 tells us that out of 100% there is 87.0968% chance of both being downloaded or Watched \n\n<h2 style='color:lightblue'>starting with some exploration of the table!!</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_items['length'] = freq_items['itemsets'].apply(lambda x: len(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_items","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_items.loc[((freq_items['length']>=2) \n                | (freq_items['support']>50)),:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<html>\nwe now apply the association_rule onto the freq_items dataframe \n\nwhich will return all the possible combinations of apps with\n    \n    Support >= Min_Threshold_Support \nvalues \n    </html>\n    \nto find more on how this works you may check [this github link](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/)\n\nOR\n\n[this youtube video](https://youtu.be/guVvtZ7ZClw) for theory building and analysis interpretation "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ar = association_rules(freq_items, metric = \"confidence\", min_threshold = 0.5)\ndf_ar","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b style=\"color:black\">what are antecedants 'n' Consequents ???</b>\n\n<p style=\"color:orange\">\n➡➡  Antecedent support variable tells us probability of antecedent products alone\n\n<p style=\"color:orange\">\n➡➡  Consequents support variable tells us probability of consequents products alone(may cross check manually)\n\n<p style=\"color:orange\">    \n➡➡  The support value is the support value of the two products combined (Antecedents and Consequents)\n</p>\n</p>\n</p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ar[(df_ar.support > 0.45) | (df_ar.confidence > 0.5)].sort_values(\"confidence\", ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:orange\"> ➡➡ I Am Interested In Knowing What All Combinations Had a High Confidence n Support Values So Why Not Make a Scatter Plot</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.scatterplot(data=df_ar,x=df_ar['support'],y=df_ar['confidence'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style='color:pink'> some failed approaches to make labels appear in NB while hovering over em</p>\n<p style='color:pink'> this didnt worked may be NB's doesnt provide this feature of hovering </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df_ar['support']\ny=df_ar['confidence']\n\nfig,ax = plt.subplots()\ncmap = plt.cm.RdYlGn\nnorm = plt.Normalize(1,4)\n# c = np.random.randint(1,3,size=43)\n\nsc = plt.scatter(X,y, s=100, cmap=cmap, norm=norm)#c=c)\n\nannot = ax.annotate(\"\", xy=(0,0), xytext=(20,20),textcoords=\"offset points\",\n                    bbox=dict(boxstyle=\"round\", fc=\"w\"),\n                    arrowprops=dict(arrowstyle=\"->\"))\nannot.set_visible(True)\n\ndef update_annot(ind):\n\n    pos = sc.get_offsets()[ind[\"ind\"][0]]\n    annot.xy = pos\n    text = \"{}, {}\".format(\" \".join(list(map(str,ind[\"ind\"]))), \n                           \" \".join([names[n] for n in ind[\"ind\"]]))\n    annot.set_text(text)\n    annot.get_bbox_patch().set_facecolor(cmap(norm(c[ind[\"ind\"][0]])))\n    annot.get_bbox_patch().set_alpha(0.4)\n\n\ndef hover(event):\n    vis = annot.get_visible()\n    if event.inaxes == ax:\n        cont, ind = sc.contains(event)\n        if cont:\n            update_annot(ind)\n            annot.set_visible(True)\n            fig.canvas.draw_idle()\n        else:\n            if vis:\n                annot.set_visible(False)\n                fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect(\"motion_notify_event\", hover)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def onpick3(event):\n    ind = event.ind\n    print('onpick3 scatter:', ind, npy.take(X, ind), npy.take(y, ind))\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\ncol = ax1.scatter(X, y, picker=True)\n#fig.savefig('pscoll.eps')\nfig.canvas.mpl_connect('pick_event', onpick3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install mplcursors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import mplcursors\nfig, ax = plt.subplots()\nax.scatter(X,y)\nax.set_title(\"Mouse over a point\")\ncrs = mplcursors.cursor(ax,hover=True)\n\ncrs.connect(\"add\", lambda sel: sel.annotation.set_text(\n    'Point {},{}'.format(sel.target[0], sel.target[1])))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### thanks for reading "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}