{"cells":[{"metadata":{},"cell_type":"markdown","source":"**LOAD DATASET**"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport keras\n\n# load dataset\ndataframe = pd.read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n\n# scale dataset\nfrom sklearn.preprocessing import MinMaxScaler\ndataset = dataframe.values\ndataset = dataset.astype('float32')\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n\n# split into train and test set\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n\n\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)\n\n\nlook_back = 4\nx_train, y_train = create_dataset(train, look_back)\nx_test, y_test = create_dataset(test, look_back)\n\n# reshape input to be [samples, time steps, features]\nx_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CREATE AND TRAIN MODEL**"},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nfrom keras import regularizers\n\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n# train\nmodel.fit(x_train, y_train, epochs=100, batch_size=1, verbose=2)\n\n# model summary\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EVALUATE MODEL**"},{"metadata":{"trusted":false},"cell_type":"code","source":"import math\nfrom sklearn.metrics import mean_squared_error\n\n# make predictions\ntrain_predict = model.predict(x_train)\ntest_predict = model.predict(x_test)\n\n# invert predictions\ntrain_predict = scaler.inverse_transform(train_predict)\ny_train = scaler.inverse_transform([y_train])\ntest_predict = scaler.inverse_transform(test_predict)\ny_test = scaler.inverse_transform([y_test])\n\n# calculate root mean squared error\ntrain_score = math.sqrt(mean_squared_error(y_train[0], train_predict[:,0]))\nprint('Train Score: %.2f RMSE' % (train_score))\ntest_score = math.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\nprint('Test Score: %.2f RMSE' % (test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** PLOT ACTUAL DATA AND TRAIN-TEST PREDICTIONS **"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(dataset)-1, :] = test_predict\n\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset)) # real values\nplt.plot(trainPredictPlot) # train values\nplt.plot(testPredictPlot) # test values\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:tensorflow_env] *","language":"python","name":"conda-env-tensorflow_env-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}