{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3-final"},"orig_nbformat":2,"kernelspec":{"name":"tf_gpu","display_name":"tf_gpu"}},"nbformat":4,"nbformat_minor":2,"cells":[{"cell_type":"markdown","metadata":{},"source":"# VGG Birds Transfer Learning"},{"cell_type":"markdown","metadata":{},"source":"## Definition of Transfer Learning\n\nTransfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer of learning, although formal ties between the two fields are limited. From the practical standpoint, reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a reinforcement learning agent.\n<br><br>\nRessource from : [Wikipedia](https://en.wikipedia.org/wiki/Transfer_learning)"},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"from IPython.display import Image\nImage('../input/birds-transfer-learning/220px-Annas_hummingbird.jpg')"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport glob\nimport matplotlib.pyplot as plt"},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint"},{"cell_type":"markdown","metadata":{},"source":"# Split Data"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":"top_path = '../input/100-bird-species/train'\nbirds = np.array(list(os.listdir(top_path)))"},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":"# pick only 20 type of birds to train on\nnr_birds = 20\n\nnp.random.shuffle(birds)\nbirds = birds[:nr_birds]"},{"cell_type":"code","execution_count":26,"metadata":{"tags":[]},"outputs":[],"source":"idx_to_name = {i:x for (i,x) in enumerate(birds)}\nname_to_idx = {x:i for (i,x) in enumerate(birds)}\nprint(idx_to_name)"},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":"def get_data_labels(path, birds, dim):\n    data = []\n    labels = []\n\n    for bird in birds:\n        imgs = [cv2.resize(cv2.imread(img), dim, interpolation=cv2.INTER_AREA) for img in glob.glob(path + \"/\" + bird + \"/*.jpg\")]\n        for img in imgs:\n            data.append(img)\n            labels.append(name_to_idx[bird])\n    return np.array(data), np.array(labels)"},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":"data_train, labels_train = get_data_labels('../input/100-bird-species/train', idx_to_name.values(), (224,224))\ndata_test, labels_test = get_data_labels('../input/100-bird-species/test', idx_to_name.values(), (224,224))\ndata_valid, labels_valid = get_data_labels('../input/100-bird-species/valid', idx_to_name.values(), (224,224))"},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":"def normalize(data):\n    data = data / 255.0\n    data = data.astype('float32')\n    return data\n\ndef one_hot(labels):\n    labels = np.eye(len(np.unique(labels)))[labels]\n    return labels"},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":"data_train = normalize(data_train)\ndata_test = normalize(data_test)\ndata_valid = normalize(data_valid)\n\nlabels_train = one_hot(labels_train)\nlabels_test = one_hot(labels_test)\nlabels_valid = one_hot(labels_valid)"},{"cell_type":"markdown","metadata":{},"source":"# Architecture"},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":"Image('../input/birds-transfer-learning/05-06_img_0027.png')"},{"cell_type":"markdown","metadata":{},"source":"# Implementation"},{"cell_type":"code","execution_count":55,"metadata":{"tags":[]},"outputs":[],"source":"weights_path = \"../input/birds-transfer-learning/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nbase_model = VGG16(weights=weights_path, include_top=False, input_shape=(224, 224, 3))\nbase_model.summary()"},{"cell_type":"code","execution_count":56,"metadata":{"tags":[]},"outputs":[],"source":"# Freeze the extraction layers\nfor layer in base_model.layers:\n    layer.trainable = False\n \nbase_model.summary()"},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":"Image('../input/birds-transfer-learning/05-06_img_0028.png')"},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Model\n \n# use “get_layer” method to save the last layer of the network\nlast_layer = base_model.get_layer('block5_pool')\n# save the output of the last layer to be the input of the next layer\nlast_output = last_layer.output\n \n# flatten the classifier input which is output of the last layer of VGG16 model\nx = Flatten()(last_output)\n \n# add our new softmax layer with 3 hidden units\nx = Dense(nr_birds, activation='softmax', name='softmax')(x)"},{"cell_type":"code","execution_count":75,"metadata":{"tags":[]},"outputs":[],"source":"# instantiate a new_model using keras’s Model class\nnew_model = Model(inputs=base_model.input, outputs=x)\n \n# print the new_model summary\nnew_model.summary()"},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":"new_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"},{"cell_type":"code","execution_count":77,"metadata":{"tags":[]},"outputs":[],"source":"checkpointer = ModelCheckpoint(filepath='birds.model.hdf5', save_best_only=True)\n \nhistory = new_model.fit(data_train, labels_train, steps_per_epoch=len(data_train),\nvalidation_data=(data_test, labels_test), validation_steps=3, epochs=10, verbose=1, callbacks=[checkpointer])"},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":"# Analyze Training Data"},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":"plt.plot(history.history['val_accuracy'], 'b')\nplt.plot(history.history['val_loss'], 'r')\nplt.show()"},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":"def get_accuracy(model, data_valid, labels_valid):\n    predictions = model(data_valid)\n    wrong = 0\n    for i, pred in enumerate(predictions):\n        if( np.argmax(pred) !=  np.argmax(labels_valid[i])):\n            wrong += 1\n    return (len(data_valid) - wrong) / len(data_valid)"},{"cell_type":"code","execution_count":102,"metadata":{"tags":[]},"outputs":[],"source":"# we use the validation data to verify the accuracy\naccuracy = get_accuracy(new_model, data_valid, labels_valid)\nprint(\"Accuracy:\", accuracy)"},{"cell_type":"markdown","metadata":{},"source":"# Resources"},{"cell_type":"markdown","metadata":{},"source":"Architectures images from [Deep Learning for Vision Systems Book](https://www.manning.com/books/deep-learning-for-vision-systems)"}]}