{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Description\nOn this notebook we are going to use a logistic regression model for a classification problem. We want to predict whether a passenger will survive  or die from the Titanic disaster. The notebook shows all the steps used in a machine learning process. The purpose of this notebook is getting familiar with logistic regression and understand it in the simple possible way. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#import libraries for data visualisation \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the input file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#read train cvs file with pandas \nfile_path ='../input/titanic-machine-learning-from-disaster/train.csv'\ndata =pd.read_csv( file_path)\n#show the first 5 rows of data dataframe \ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Explore data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# identify missing data \nmissing_data=data.isnull()\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The isnull() function return a True value when the data is missining NAN value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize missing data with heatmap of boolean values \nsns.heatmap(missing_data, cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The heatmap tells us that every white dash is a True value for a missing data. So we assume that we have missing a lot of data for **\"Cabin\"** columns and some data are missing too for **\"Age\"**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we want to visualize survived passanger based on their gender. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data[\"Survived\"], hue=\"Sex\", data=data, palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot tells us that we have more female survived than male. Next we are going to explore whether the rich people survived more than poor one ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data[\"Survived\"], hue=\"Pclass\", data=data, palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A lot of people did not survive from the third class. Is it because money matters in life-death situation or just simply because we have more passenger from the third class than the others? We want to get a distribution of passangers based on their classes.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data[\"Pclass\"], data=data, palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rate of people from the third class is the highest. That explains why more people died from this class. Well it's time to stop guessing and do some logistic machine learning to predict death among passengers. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Cleaning data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We are going to replace null age value by the average age per class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(\"Pclass\")[\"Age\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We are going to use a function that fills missing age value by 38 for class 1 and 29 for class 2 and 25 for class 3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#define a function that return missing value per class \ndef fill_missing(cols) : \n    Age = cols[0] #Age column\n    Pclass = cols[1] #Pclass column\n    if pd.isnull(Age): #if the age value is missing \n        if Pclass==1: \n            return 38\n        elif Pclass==2: \n            return 29\n        else :\n            return 25\n    else : \n        return Age \n    \ndata[\"Age\"]= data[[\"Age\",\"Pclass\"]].apply(fill_missing, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking visually that our function filled the missing value \nsns.heatmap(data.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the second missing value; we are just going to drop this column and donâ€™t use it in our model as a feature for simplicity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"Cabin\", axis=1, inplace=True) \n#if you don't use inplace =True the cabin column will still exist on your data ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Create a dummy variable ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use get_dummies to transform a categorical variable to a numerical value. For example for columns sex , we transform male to 1 and female to 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.get_dummies(data[\"Sex\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can mention here that if it's not a male it's female wish makes our columns predictives. We don't want this behaviour calles multicollinearity so we fix this issue by calling he parameter drop_first as True","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dummiee variables for sex and Embarked\nsex=pd.get_dummies(data[\"Sex\"],drop_first=True)\nembarked= pd.get_dummies(data[\"Embarked\"],drop_first=True)\n#Add this two variable to our data : \ndata=pd.concat([data,sex,embarked], axis=1)\n#Check the first row of our data\ndata.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again we drop columns we don't need like Sex, Embarked, Name, Ticket \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"Sex\",\"Embarked\",\"Name\",\"Ticket\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the passanger ID\ndata.drop(\"PassengerId\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Train the model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select the output y and the features X\ny=data[\"Survived\"]\nfeatures = [\"Pclass\",\"Age\", \"SibSp\", \"Parch\",\"Fare\",\"male\",\"Q\",\"S\"]\nX=data[features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Import scikit learn libraries\n1. Create an instance of a logistic regression model \n1. Fit the model to our data \n1. predict ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import scikit learn libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n#split our data into a train and test data\nX_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.30, random_state=0)\n\n#Create an instance of a logistic model \nlgmodel= LogisticRegression()\n\n#train the lgmodel \nlgmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = lgmodel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluating model ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Import libraries for evaluting model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n#show the confusing matrix \nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report \n#show a full classification report\nprint(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nYet we finished all the steps but we want to improve our model. So in the next notebook we are going to do some changes in order to explore whether we can do better.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}