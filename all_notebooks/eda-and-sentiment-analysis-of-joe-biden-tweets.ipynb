{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center; background-color:#C8D741\">Deep Learning Model for Performing Sentiment Analysis of Tweets from Joe Biden</h1>"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, I have tried to perform sentiment analysis on Joe Biden's tweets using a BERT-based model. This model is trained on [\"First GOP Debate Twitter Sentiment\"](https://www.kaggle.com/crowdflower/first-gop-debate-twitter-sentiment). After which, the trained model is used to classify Joe Biden's tweets into three categories : *positive, negative and neutral*. The rest of the notebook is organized as follows :\n\n1. Exploratory Data Analysis\n    * Most common words employed in Joe Biden's tweets\n    * Twitter word cloud of most commons terms\n    * Analyze how the frequency of *likes, retweets, replies and quotes* vary with time.\n\n2. Sentiment Analysis on Tweets\n    * Importing libraries\n    * Loading BERT model and BERT tokenizer\n    * Sample tweets\n    * Creating data loaders\n    * Sentiment classifier model\n    * Mode training\n    * Results and evaluations\n  \n3. Final dataset that contains sentiment classification of Joe Biden's tweets.\n4. Word clouds for positive, negative and neutral tweets from Joe Biden.\n5. Future work\n6. References"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/joe-biden-tweets/JoeBidenTweets.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center; background-color:#D8E46B\">Exploratory Data Analysis</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport re\nimport string\nfrom string import punctuation\nfrom nltk.corpus import stopwords\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n\n    return text\n\n\ndef punctuation_stopwords_removal(git_text):\n    remove_punctuation = [ch for ch in git_text if ch not in punctuation]\n    # convert them back to sentences and split into words\n    remove_punctuation = \"\".join(remove_punctuation).split()\n    filtered_git_text = [word.lower() for word in remove_punctuation if word.lower() not in stopwords.words('english')]\n    return filtered_git_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tweet'] = df['tweet'].apply(lambda x: clean_text(x))\ndf['tweet'] = df['tweet'].apply(punctuation_stopwords_removal)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing optional columns\ndf.drop(['id', 'url'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfrom collections import Counter\n\ndef plot_most_common_terms(df):\n    word_list = []\n    \n    for i, j in df.iterrows():\n        for word in j['tweet']:\n            word_list.append(word)\n        \n    count_dict = Counter(word_list)\n    most_common_words_df = pd.DataFrame(count_dict.most_common(20), columns=['word', 'count'])\n    \n    fig = px.histogram(most_common_words_df,\n                       x='word', \n                       y='count',\n                       title='Most common terms used in Joe Biden\\'s tweets.',\n                       color_discrete_sequence=['#D8E46B'] )\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_most_common_terms(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport urllib\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, ImageColorGenerator\n\ndef load_mask(mask_url):\n    with urllib.request.urlopen(mask_url) as resp:\n        mask = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n        mask = cv2.imdecode(mask, cv2.IMREAD_COLOR)\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n        \n    return mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_mask = load_mask('https://www.creativefreedom.co.uk/wp-content/uploads/2017/06/Twitter-featured.png')\n\nwordcloud = WordCloud(\n    background_color=\"white\",\n    mask=new_mask,\n    random_state=42,\n    max_font_size=50,\n    max_words=1000,\n)\n\ndf_tweet = pd.read_csv('/kaggle/input/joe-biden-tweets/JoeBidenTweets.csv')\ntext = ''.join(df_tweet['tweet'].values)\n\n\nwordcloud.generate(text) \n\nimage_colors = ImageColorGenerator(new_mask)\n\nplt.figure(figsize=(16, 8))\nplt.imshow(wordcloud.recolor(color_func=image_colors))\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\ndf['timestamp'] = df['timestamp'].apply(lambda x : datetime.datetime.strptime(x.split(\" \")[0], \"%Y-%m-%d\"))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_count = pd.DataFrame()\n\ndf_count['replies'] = df.groupby(['timestamp'])['replies'].sum()\ndf_count['retweets'] = df.groupby(['timestamp'])['retweets'].sum()\ndf_count['quotes'] = df.groupby(['timestamp'])['quotes'].sum()\ndf_count['likes'] = df.groupby(['timestamp'])['likes'].sum()\ndf_final = df_count.reset_index()\ndf_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\ndef plot_frequency_of_tweet_properties(df):\n    # Create traces\n    fig = go.Figure()\n    \n    fig.add_trace(go.Scatter(x=df['timestamp'], y=df['replies'],\n                        mode='lines',\n                        name='Replies'))\n    \n    fig.add_trace(go.Scatter(x=df['timestamp'], y=df['retweets'],\n                        mode='lines',\n                        name='Re-tweets'))\n    \n    fig.add_trace(go.Scatter(x=df['timestamp'], y=df['quotes'],\n                        mode='lines',\n                        name='Quotes'))\n    \n    fig.add_trace(go.Scatter(x=df['timestamp'], y=df['likes'],\n                        mode='lines',\n                        name='Likes'))\n\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_frequency_of_tweet_properties(df_final)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center; background-color:#D8E46B\">Sentiment Analysis on Tweets</h1>"},{"metadata":{},"cell_type":"markdown","source":"In order to classify tweets from Joe Biden, I would be leveraging a BERT based model. In order to train the model, I will be using [First GOP Debate Twitter Sentiment](https://www.kaggle.com/crowdflower/first-gop-debate-twitter-sentiment) which contains sentiment value (positive, negative and neutral) as well s the tweet."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_debate_tweets = pd.read_csv('/kaggle/input/first-gop-debate-twitter-sentiment/Sentiment.csv')\ndf_debate = pd.DataFrame()\ndf_debate['tweet'] = df_debate_tweets['text']\ndf_debate['sentiment'] = df_debate_tweets['sentiment']\n\ndf_debate['tweet'] = df_debate['tweet'].apply(lambda x: clean_text(x))\ndf_debate['tweet'] = df_debate['tweet'].apply(lambda x: x.replace(\"rt\", \"\"))\n\ndf_debate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_labels(df):\n    for i, j in df_debate.iterrows():\n        if j['sentiment']=='Negative':\n            j['sentiment']=0\n        elif j['sentiment']=='Positive':\n            j['sentiment']=1\n        elif j['sentiment']=='Neutral':\n            j['sentiment']=2\n            \n    return df_debate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_debate = encode_labels(df_debate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_debate.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Importing Libraries</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom torch.utils.data import Dataset, DataLoader\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Loading BERT model and BERT tokenizer</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading our BERT model\nBERT_UNCASED = '/kaggle/input/bert-base-uncased'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the pre-trained BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(BERT_UNCASED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Sample Tweet</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# some basic operations to understand how BERT converts a sentence into tokens and then into IDs\nsample_body = 'danscavino gopdebate w realdonaldtrump delivered the highest ratings in the history of presidential debates'\ntokens = tokenizer.tokenize(sample_body)\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\n\nprint(f' Sentence: {sample_body}')\nprint(f'   Tokens: {tokens}')\nprint(f'Token IDs: {token_ids}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using encode_plus to add special tokens : [CLS]:101, [SEP]:102, [PAD]:0\nencodings = tokenizer.encode_plus(\n            sample_body,\n            max_length=32,\n            add_special_tokens=True,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n)\n\nencodings.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Input IDs : {}'.format(encodings['input_ids'][0]))\nprint('\\nAttention Mask : {}'.format(encodings['attention_mask'][0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Class for tweets dataset</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting maximum length of tweets\nMAX_LENGTH = 150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Tweets(Dataset):\n    \n    def __init__(self, tweet, label, tokenizer, max_len):\n        self.tweet = tweet\n        self.label = label\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.tweet)\n    \n    def __getitem__(self, item):\n        tweet = str(self.tweet[item])\n        label = self.label[item]\n        \n        encoding = self.tokenizer.encode_plus(\n        tweet,\n        add_special_tokens=True,\n        max_length=self.max_len,\n        return_token_type_ids=False,\n        pad_to_max_length=True,\n        return_attention_mask=True,\n        return_tensors='pt')\n        return {\n        'tweet': tweet,\n         'input_ids': encoding['input_ids'],\n         'attention_mask': encoding['attention_mask'],\n         'label': torch.tensor(label, dtype=torch.long)\n          }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Creating data loaders</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntraining_data, testing_data = train_test_split(\n    df_debate,\n    test_size=0.1,\n    random_state=RANDOM_SEED\n)\n\ntesting_data, validation_data = train_test_split(\n    testing_data,\n    test_size=0.5,\n    random_state=RANDOM_SEED\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data_loader(data, tokenizer, max_len, batch_size):\n    \n    ds = Tweets(tweet=data.tweet.to_numpy(),\n    label=data.sentiment.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len)\n    \n    return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4)\n\n\nBATCH_SIZE = 64\ntrain_data_loader = create_data_loader(training_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\ntesting_data_loader = create_data_loader(testing_data, tokenizer, MAX_LENGTH, BATCH_SIZE)\nval_data_loader = create_data_loader(validation_data, tokenizer, MAX_LENGTH, BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = next(iter(train_data_loader))\ndf.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['input_ids'].squeeze().shape, df['attention_mask'].squeeze().shape, df['label'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('tweet  : ', df['tweet'][0])\nprint('input_ids : ', df['input_ids'].squeeze()[0])\nprint('attention_mask : ', df['attention_mask'].squeeze()[0])\nprint('label : ', df['label'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_model = BertModel.from_pretrained(BERT_UNCASED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_hidden_state, pooled_output = bert_model(\n  input_ids=encodings['input_ids'],\n  attention_mask=encodings['attention_mask']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_hidden_state.shape, pooled_output.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Sentiment Classifier Model</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n    \n    def __init__(self, n_classes):\n        super(SentimentClassifier, self).__init__()\n        self.bert_model = BertModel.from_pretrained(BERT_UNCASED)\n        self.dropout = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert_model.config.hidden_size, n_classes)\n        \n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.bert_model(\n        input_ids=input_ids,\n        attention_mask = attention_mask\n        )\n        output = self.dropout(pooled_output)\n        return self.out(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nlabel 0: Negative\nlabel 1: Positive\nlabel 2: Neutral\n\"\"\"\nclass_names = [0, 1, 2]\nsentiment_classifier = SentimentClassifier(len(class_names))\nsentiment_classifier = sentiment_classifier.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\n\noptimizer = AdamW(sentiment_classifier.parameters(), lr=2e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps = 0,\n    num_training_steps = total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n    model = model.train()\n    \n    losses = []\n    correct_predictions = 0\n    \n    for d in data_loader:\n        input_ids = d['input_ids'].squeeze().to(device)\n        attention_mask = d['attention_mask'].squeeze().to(device)\n        targets = d['label'].to(device)\n\n        outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n        loss = loss_fn(outputs, targets)\n        \n        correct_predictions += torch.sum(preds==targets)\n        losses.append(loss.item())\n        \n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n    \n    return correct_predictions.double()/n_examples, np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n    model = model.eval()\n    \n    losses = []\n    correct_predictions = 0\n    \n    with torch.no_grad():\n        for d in data_loader:\n            input_ids = d['input_ids'].squeeze().to(device)\n            attention_mask = d['attention_mask'].squeeze().to(device)\n            targets = d['label'].to(device)\n\n            outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            loss = loss_fn(outputs, targets)\n\n            correct_predictions += torch.sum(preds==targets)\n            losses.append(loss.item())\n    \n    return correct_predictions.double()/n_examples, np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Model training</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom collections import defaultdict\n\nhistory = defaultdict(list)\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n    print('EPOCH {}/{}'.format(epoch+1,EPOCHS))\n    print('-' * 10)\n    \n    train_acc, train_loss = train_model(sentiment_classifier, train_data_loader, loss_fn, optimizer, device, scheduler, len(training_data))\n    \n    print('Train loss : {} accuracy : {}'.format(train_loss, train_acc))\n    \n    val_acc, val_loss = eval_model(sentiment_classifier, val_data_loader, loss_fn, device, len(validation_data))\n    \n    print('Validation loss : {} accuracy : {}'.format(val_loss, val_acc))\n    \n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n    \n    if val_acc > best_accuracy:\n        print('Saving the best model ...')\n        torch.save(sentiment_classifier.state_dict(), 'best_model.bin')\n        best_accuracy = val_acc\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; background-color:#D8E46B\">Results and Evaluation</h2>"},{"metadata":{},"cell_type":"markdown","source":"So our BERT model has achieved 93.7% accuracy on training dataset and 74.0% accuracy on validation dataset. This was achieved after training our BERT model on \"GOP debate\" dataset. Now, we will use this trained model to classify tweets from Joe Biden into 3 categories : *positive, negative and neutral*."},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_sentiment_category(tweet, model):\n    class_names = ['negative', 'positive', 'neutral']\n    encoded_message = tokenizer.encode_plus(tweet, max_length=MAX_LENGTH, add_special_tokens=True, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n    input_ids = encoded_message['input_ids'].to(device)\n    attention_mask = encoded_message['attention_mask'].to(device)\n    \n    output = model(input_ids=input_ids, attention_mask=attention_mask)\n    _, prediction_idx = torch.max(output, dim=1)\n        \n    return (prediction_idx, class_names[prediction_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet = testing_data['tweet'][3448]\nprint('Sample tweet from Joe Biden : ', tweet)\nprint('Predicted sentiment category : ', predict_sentiment_category(tweet, sentiment_classifier)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/joe-biden-tweets/JoeBidenTweets.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center; background-color:#D8E46B\">Final dataset containing Joe Biden's Tweets and the sentiment classification</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tweet'] = df['tweet'].apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"joe_sentiment = []\nfor i, j in df.iterrows():\n    joe_sentiment.append(predict_sentiment_category(j['tweet'], sentiment_classifier)[0].cpu().numpy().data[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment']= joe_sentiment\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center; background-color:#D8E46B\">Word cloud of positive, negative and neutral Joe Biden's tweets</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_joe_negative = df[df['sentiment']==0]\ndf_joe_positive = df[df['sentiment']==1]\ndf_joe_neutral = df[df['sentiment']==2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_word_cloud(df_tweet, colormap, category):\n    new_mask = load_mask('https://www.creativefreedom.co.uk/wp-content/uploads/2017/06/Twitter-featured.png')\n\n    wordcloud = WordCloud(\n        background_color=\"white\",\n        colormap=colormap,\n        mask=new_mask,\n        random_state=42,\n        max_font_size=50,\n        max_words=1000,\n    )\n\n    text = ''.join(df_tweet['tweet'].values)\n\n\n    wordcloud.generate(text) \n\n    image_colors = ImageColorGenerator(new_mask)\n\n    plt.figure(figsize=(16, 8))\n    plt.title('Word cloud for {} tweets'.format(category))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.colors import LinearSegmentedColormap\ncolors_pos = [\"#88D969\", \"#1D800E\"]\ncmap_pos = LinearSegmentedColormap.from_list(\"mycmapos\", colors_pos)\n\ncolors_neg = [\"#ffbaba\", \"#ff0000\"]\ncmap_neg = LinearSegmentedColormap.from_list(\"mycmapos\", colors_neg)\n\ncolors_neutral = [\"#ffecb3\", \"#ffca28\"]\ncmap_neutral = LinearSegmentedColormap.from_list(\"mycmapos\", colors_neutral)\n\n\n\n\nplot_word_cloud(df_joe_positive, cmap_pos, 'positive')\nplot_word_cloud(df_joe_negative, cmap_neg, 'negative')\nplot_word_cloud(df_joe_neutral, cmap_neutral, 'neutral')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center; background-color:#D8E46B\">Future Work</h1>"},{"metadata":{},"cell_type":"markdown","source":"1. I still need to employ BERT large model to test its accuracy on GitHub message classification use-case.\n2. The dataset provided has rich textual information. This can be leveraged for other NLP tasks such as natural language generation."},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center; background-color:#D8E46B\">References</h1>"},{"metadata":{},"cell_type":"markdown","source":"1. https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n2. https://huggingface.co/transformers/\n3. http://jalammar.github.io\n4. Word cloud reference : https://www.kaggle.com/ihelon/ukrainian-descriptions-word-cloud-tutorial"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}