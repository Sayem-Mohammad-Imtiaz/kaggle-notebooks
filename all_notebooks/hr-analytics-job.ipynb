{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HR Analytics job "},{"metadata":{},"cell_type":"markdown","source":"## Index\n- [1. Import libraries and download data](#section1)\n- [2. EDA](#section2)\n- [3. Data Engineering](#section3)\n- [4. Cleaning Data](#section4)\n- [5. Modelling](#section5)\n"},{"metadata":{},"cell_type":"markdown","source":"## 1. Import libraries and dowonload data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/hr-analytics-job-change-of-data-scientists/'\ntrain = pd.read_csv(path + 'aug_train.csv')\ntest = pd.read_csv(path + 'aug_test.csv')\nsample_submission = pd.read_csv(path + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. EDA\n\nWe are going to analyse the data."},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Structure\n\nLet's see what shape the data has, what type of features there are and whether they contain null values for each data set, train and test.\n\n#### 2.1.1. Train"},{"metadata":{},"cell_type":"markdown","source":"- Shape & dataframe's head"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Train shape:', train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Type of features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Null values"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_null = pd.DataFrame(train.isnull().sum())\ndf_null = df_null.rename(columns={0:'Number of null values'})\ndf_null['Percentage null values'] = round(train.isnull().sum()/train. enrollee_id.count()*100,2)\ndf_null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### 2.1.2. Test"},{"metadata":{},"cell_type":"markdown","source":"- Shape & dataframe's head"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Test shape:', test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Type of features"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Null values"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\ndf_null = pd.DataFrame(test.isnull().sum())\ndf_null = df_null.rename(columns={0:'Number of null values'})\ndf_null['Percentage null values'] = round(test.isnull().sum()/test. enrollee_id.count()*100,2)\ndf_null","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observing the previous results, obviously the test set contains 1 feature less than the train, which is the target. The 13 features that they have in common, they are 3 numerical and 10 categorical. Both sets have missing values in the same features and similar percentages. "},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Features\n\nLet's study the features from both sets, and how the target is represented in them."},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.1. Target"},{"metadata":{},"cell_type":"markdown","source":"Note that the target value indicates wether the person in the sample is looking for a job change (=1) or not (=0). Looking at the plot below, the target is binary and there is not balance between values, there is much less people looking for a job change than people not looking for it."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1,ncols=1, figsize=(16,4))\naux = train['target'].value_counts().to_frame()\nplt.title('Frequency of Target')\naux.plot.bar(ax = axes)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.2. City\n\nThe city feature is grouped and we only show the cities which are represented at least 50 times for train set plot and at least 10 times for test set plot. Both have similar shape and even the majority of cities are the same. In addition, the target is added in train plot and values do not have the same proportion in each city.  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,8))\nplt.subplots_adjust(hspace = 0.45)\n# Train\naxes[0].title.set_text('Frequency of the cities (represented >50)- Train set')\naux = train['city'].value_counts().to_frame()\ninde_50=list(aux[aux.city>50].index)\ndf_city_target = train.groupby('city')['target'].value_counts().to_frame().unstack()\ndf_city_target[df_city_target.index.isin(inde_50)].reindex(inde_50).plot.bar(ax = axes[0], stacked = True)\naxes[0].legend(['Not job change', 'Job change'])\n\n\n# Test\naxes[1].title.set_text('Frequency of the cities (represented >10)- Test set')\naux = test['city'].value_counts().to_frame()\naux[aux.city>10].plot.bar(ax = axes[1])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.3. City development index\n\nThis feature gets values between 0 and 1, it is scaled, for that reason we are going to use a histogram and a density function in order to plot the feature. In the train set, we make distinctions between the total, not looking for a job change and looking for a job change. Comparing these three plots and test plot, they have the similar shape, changing a bit the concentration of data in these two peaks around  0.6 and 0.9. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,8))\nplt.subplots_adjust(hspace = 0.45)\n\ntrain_not_looking = train[train['target']==0].city_development_index\ntrain_looking = train[train['target']==1].city_development_index\ntrain_total = train.city_development_index\n\n# train\nsns.distplot(train_not_looking, ax=axes[0] )\nsns.distplot(train_looking, ax = axes[0])\nsns.distplot(train_total, ax = axes[0] ).set_title('city_development_index histrogram and density function - Train set')\naxes[0].legend(['Not job change', 'Job change','Total'])\n\n\n#test\nsns.distplot(test.city_development_index, ax = axes[1]).set_title('city_development_index histrogram and density function - Test set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.4. Gender\n\nGender's plots have the same shape for train set and test set. Most of the people of both groups are men. Despite of the difference between groups are significantly, the percentage of people who are not looking or looking for a job change are quite homogenous between the gender's type."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_gender_target = train.groupby('gender')['target'].value_counts().to_frame().unstack()\ndf = pd.DataFrame(df_gender_target.sum(axis=1))\ndf = df.rename(columns={0:'Total'})\ndf['Percen 0 gender'] = np.round((df_gender_target.target[[0.0]][0.0].values/df.Total.values) * 100,2)\ndf['Percen 1 gender'] = np.round((df_gender_target.target[[1.0]][1.0].values/df.Total.values) * 100,2)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,10))\nplt.subplots_adjust(hspace = 0.4)\n# Train\ndf_gender_target = train.groupby('gender')['target'].value_counts().to_frame().unstack()\ndf_gender_target.reindex(['Male', 'Female', 'Other']).plot.bar(ax = axes[0], stacked = True)\naxes[0].title.set_text('Frequency of Gender- Train set')\naxes[0].legend(['Not job change', 'Job change'])\n# Test\naxes[1].title.set_text('Frequency of Gender- Test set')\naux = test['gender'].value_counts().to_frame()\naux.plot.bar(ax = axes[1])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.5. Professional Experience"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### 2.2.5.1. Relevent_Expereience\n\n\nFor train and test sets, the relevent experience has the same shape. The majority of people from these sets have a relevant experience. However, comparing the percentage of people who are looking for a job change, it is bigger for people who do not have experience."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_rel_exp_target = train.groupby('relevent_experience')['target'].value_counts().to_frame().unstack()\ndf = pd.DataFrame(df_rel_exp_target.sum(axis=1))\ndf = df.rename(columns={0:'Total'})\ndf['Percen 0 Has expe'] = np.round((df_rel_exp_target.target[[0.0]][0.0].values/df.Total.values) * 100,2)\ndf['Percen 1 No expe'] = np.round((df_rel_exp_target.target[[1.0]][1.0].values/df.Total.values) * 100,2)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,10))\nplt.subplots_adjust(hspace = 0.7)\n# Train\ndf_rel_exp_target = train.groupby('relevent_experience')['target'].value_counts().to_frame().unstack()\ndf_rel_exp_target.plot.bar(ax = axes[0], stacked = True,)\naxes[0].set_xticklabels(list(df_rel_exp_target.index.values),rotation=25, ha='right')\naxes[0].title.set_text('Frequency of relevent_experience- Train set')\naxes[0].legend(['Not job change', 'Job change'])\n# Test\naxes[1].title.set_text('Frequency of relevent_experience- Test set')\naux = test['relevent_experience'].value_counts().to_frame()\naux.plot.bar(ax = axes[1])\naxes[1].set_xticklabels(list(aux.index.values),rotation=25, ha='right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.5.2. Experience\n\nPlotting the experience, it has the same shape for train and test data. Moreover, we can observe that the proportion of people who are or not looking for a job change, is changing through different period of experience."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,8))\nplt.subplots_adjust(hspace = 0.5)\n# Train\ndf_experience_target = train.groupby('experience')['target'].value_counts().to_frame().unstack()\nind = ['<1','1','3', '4', '5', '6', '7', '8', '9','2','10', '11', '12', '13', '14',\n     '15', '16', '17', '18', '19', '20', '>20']\ndf_experience_target = df_experience_target.reindex(index=ind).plot.bar(ax = axes[0], stacked = True)\naxes[0].set_xticklabels(ind,rotation=0, ha='right')\naxes[0].title.set_text('Frequency of experience- Train set')\naxes[0].legend(['Not job change', 'Job change'])\n# Test\naxes[1].title.set_text('Frequency of experience- Test set')\naux = test['experience'].value_counts().to_frame()\naux = aux.reindex(index=ind)\naux.plot.bar(ax = axes[1])\naxes[1].set_xticklabels(ind,rotation=0, ha='right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.5.3. Company_size\n\nBoth plots have similar distribution through compani size, and the proprortion of not looking or looking for a job change seems that it does not differ too much between company_size."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,8))\nplt.subplots_adjust(hspace = 0.5)\n# Train\ndf_size_comp_target = train.groupby('company_size')['target'].value_counts().to_frame().unstack()\nind = ['<10','10/49','50-99', '100-500', '500-999', '1000-4999', '5000-9999', '10000+']\ndf_size_comp_target.reindex(index=ind).plot.bar(ax = axes[0], stacked = True)\naxes[0].set_xticklabels(ind,rotation=25, ha='right')\naxes[0].title.set_text('Frequency of company_size - Train set')\naxes[0].legend(['Not job change', 'Job change'])\n# Test\naxes[1].title.set_text('Frequency of company_size - Test set')\naux = test['company_size'].value_counts().to_frame()\naux = aux.reindex(index=ind)\naux.plot.bar(ax = axes[1])\naxes[1].set_xticklabels(ind,rotation=25, ha='right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.5.4. Company_type \n\nBoth graphs have the same shape. The proportion for people who are or not looking for a job change differs in different through company type."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,8))\nplt.subplots_adjust(hspace = 0.5)\n# Train\ndf_type_comp_target = train.groupby('company_type')['target'].value_counts().to_frame().unstack()\nind =['Pvt Ltd','Public Sector','Funded Startup','Early Stage Startup', 'NGO', 'Other']\ndf_type_comp_target.reindex(ind).plot.bar(ax = axes[0], stacked=True)\naxes[0].set_xticklabels(ind,rotation=25, ha='right')\naxes[0].title.set_text('Frequency of company_type - Train set')\naxes[0].legend(['Not job change', 'Job change'])\n# Test\naxes[1].title.set_text('Frequency of company_type - Test set')\naux = test['company_type'].value_counts().to_frame()\naux.plot.bar(ax = axes[1])\naxes[1].set_xticklabels(ind,rotation=25, ha='right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.5.5. Last_new_job\n\nComparing two plots of last new job, they have similar shape, where the value 1 is the most popular. Looking at the first plot, the proportion of  values from target is different through the last new job feature."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,8))\nplt.subplots_adjust(hspace = 0.5)\n# Train\ndf_last_new_job_target = train.groupby('last_new_job')['target'].value_counts().to_frame().unstack()\nind = ['never','1','2','3', '4', '>4']\ndf_last_new_job_target.reindex(index=ind).plot.bar(ax = axes[0], stacked=True)\naxes[0].legend(['Not job change', 'Job change'])\naxes[0].title.set_text('Frequency of last_new_job - Train set')\n# Test\naxes[1].title.set_text('Frequency of last_new_job - Test set')\naux = test['last_new_job'].value_counts().to_frame()\naux = aux.reindex(index=ind)\naux.plot.bar(ax = axes[1])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.5.6. Training hours \n\nThe training hours feature are grouped by intervals to make it more tidy and see a structure. Then, both plots have nearly the same shape. However, focusing on the proportion of different values of looking or not looking for a job change differs through training hours."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,9))\nplt.subplots_adjust(hspace = 0.6)\n\n# Train\naux = train['training_hours'].value_counts().to_frame()\nn = np.linspace(min(aux.index), max(aux.index), 70, endpoint = True,dtype = int)\ntrain['train_hours_2'] = pd.cut(train.training_hours, n)\ntest['train_hours_2'] = pd.cut(test.training_hours, n)\n\ndf_train_hours_target = train.groupby('train_hours_2')['target'].value_counts().to_frame().unstack()\ndf_train_hours_target.sort_index().plot.bar(ax = axes[0], stacked = True)\naxes[0].title.set_text('Frequency of training_hours - Train set')\naxes[0].legend(['Not job change', 'Job change'])\n\n# Test\n\naux_1 = test['train_hours_2'].value_counts().to_frame()\naux_1.sort_index().plot.bar(ax = axes[1])\naxes[1].title.set_text('Frequency of training_hours - Test set')\naxes[1].legend(['training hours'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.6. Education"},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.6.1. Enrolled_university\n\nBoth barcharts continue to have the same shape. The majoritiy of people are not enrolled in university. However, the proportion between the values which get target differs in the three type of enrolled university. The higher proportion for people who are looking for a job change is in Full time course."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_enro_uni_target = train.groupby('enrolled_university')['target'].value_counts().to_frame().unstack()\ndf = pd.DataFrame(df_enro_uni_target.sum(axis=1))\ndf = df.rename(columns={0:'Total'})\ndf['Percen 0 enrolled_university'] = np.round((df_enro_uni_target.target[[0.0]][0.0].values/df.Total.values) * 100,2)\ndf['Percen 1 enrolled_university'] = np.round((df_enro_uni_target.target[[1.0]][1.0].values/df.Total.values) * 100,2)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,9))\nplt.subplots_adjust(hspace = 0.6)\n\n# Train\ndf_enro_uni_target = train.groupby('enrolled_university')['target'].value_counts().to_frame().unstack()\ndf_enro_uni_target.sort_index().plot.bar(ax = axes[0], stacked = True)\naxes[0].title.set_text('Frequency of enrolled university - Train set')\naxes[0].legend(['Not job change', 'Job change'])\naxes[0].set_xticklabels(df_enro_uni_target.index.values,rotation=25, ha='right')\n\n# Test\n\naux_1 = test['enrolled_university'].value_counts().to_frame()\naux_1.sort_index().plot.bar(ax = axes[1])\naxes[1].title.set_text('Frequency of enrolled university - Test set')\naxes[1].set_xticklabels(aux_1.index.sort_values(),rotation=25, ha='right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.6.2. Education_level\n\nBoth barplots have the same shape, where the majority of people from data are Graduated and inside of  this group is where we can find the higher proportion of people who are looking for a job change."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_edu_level_target = train.groupby('education_level')['target'].value_counts().to_frame().unstack()\ndf = pd.DataFrame(df_edu_level_target.sum(axis=1))\ndf = df.rename(columns={0:'Total'})\ndf['Percen 0 education_level'] = np.round((df_edu_level_target.target[[0.0]][0.0].values/df.Total.values) * 100,2)\ndf['Percen 1 education_level'] = np.round((df_edu_level_target.target[[1.0]][1.0].values/df.Total.values) * 100,2)\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,9))\nplt.subplots_adjust(hspace = 0.6)\n\n# Train\ndf_edu_level_target = train.groupby('education_level')['target'].value_counts().to_frame().unstack()\nind = ['Primary School','High School','Graduate','Masters','Phd'] \ndf_edu_level_target.reindex(ind).plot.bar(ax = axes[0], stacked = True)\naxes[0].title.set_text('Frequency of education level - Train set')\naxes[0].legend(['Not job change', 'Job change'])\naxes[0].set_xticklabels(ind,rotation=25, ha='right')\n\n# Test\n\naux_1 = test['education_level'].value_counts().to_frame()\naux_1.reindex(ind).plot.bar(ax = axes[1])\naxes[1].title.set_text('Frequency of education_level - Test set')\naxes[1].set_xticklabels(ind,rotation=25, ha='right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2.2.6.3. Major_discipline\n\nThis feature also has the same shape for train and test set. The majority of people have the major discipline in STEM. Looking at the behaviour of the values that target can get, the porportion of them seems similar through the different major discipline."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_MajDisci_target = train.groupby('major_discipline')['target'].value_counts().to_frame().unstack()\ndf = pd.DataFrame(df_MajDisci_target.sum(axis=1))\ndf = df.rename(columns={0:'Total'})\ndf['Percen 0 education_level'] = np.round((df_MajDisci_target.target[[0.0]][0.0].values/df.Total.values) * 100,2)\ndf['Percen 1 education_level'] = np.round((df_MajDisci_target.target[[1.0]][1.0].values/df.Total.values) * 100,2)\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(16,9))\nplt.subplots_adjust(hspace = 0.6)\n\n# Train\ndf_MajDisci_target = train.groupby('major_discipline')['target'].value_counts().to_frame().unstack()\nind=['STEM','Business Degree', 'Humanities', 'Arts', 'No Major', 'Other']\ndf_MajDisci_target.reindex(ind).plot.bar(ax = axes[0], stacked = True)\naxes[0].title.set_text('Frequency of major discipline - Train set')\naxes[0].legend(['Not job change', 'Job change'])\naxes[0].set_xticklabels(ind,rotation=25, ha='right')\n\n# Test\n\naux_1 = test['major_discipline'].value_counts().to_frame()\naux_1.reindex(ind).plot.bar(ax = axes[1])\naxes[1].title.set_text('Frequency of major discipline - Test set')\naxes[1].set_xticklabels(ind,rotation=25, ha='right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Data Engineering"},{"metadata":{},"cell_type":"markdown","source":"The data is composed by different type of features, as you can see below:\n    - Numerical: city_development_index and training_hours.\n    - Categorical: \n        - Nominal: city, gender, relevent_experience, enrolled_university, major_discipline and company_type. \n        - Ordinal: education_level, company size, experience and last_new_job. "},{"metadata":{},"cell_type":"markdown","source":"In this section, we are going to convert categorical data to numerical."},{"metadata":{},"cell_type":"markdown","source":"### 3.1. Nominal Features"},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.1. City\n\nWe convert the feature in number, taking only the value which is assigned."},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_number(text):\n    num = re.findall(r'[0-9]+',text)\n    return \" \".join(num)\n\ntrain['city'] = train['city'].apply(lambda x: find_number(x))\ntrain['city']= train['city'].astype(int)\ntest['city'] = test['city']. apply(lambda x: find_number(x))\ntest['city']= test['city'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.2. Gender\n\nTransforming feature, being Other in 0, Male in 1 and Female in 2."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['gender']= train.gender.replace({'Male':1, 'Female':2, 'Other':0})\ntest['gender']= test.gender.replace({'Male':1, 'Female':2, 'Other':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.3. Relevent_experience\nTransforming the feature in binary type: Has relevent experince in 1 and No relevent experience in 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['relevent_experience']=train.relevent_experience.replace({'Has relevent experience':1, 'No relevent experience':0})\ntest['relevent_experience']=test.relevent_experience.replace({'Has relevent experience':1, 'No relevent experience':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.4 Major_discipline and company_type\n\nThese two features, we will apply them One-hot-encode."},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Ordinal Features\n\nWe assign a number depending on level is taking the string value."},{"metadata":{},"cell_type":"markdown","source":"#### 3.2.1. Education_level"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['education_level'] = train.education_level.replace({'Primary School': 1,\n                                'High School': 2,\n                                'Graduate': 3,\n                                'Masters': 4,\n                                'Phd': 5})\ntest['education_level'] = test.education_level.replace({'Primary School': 1,\n                                'High School': 2,\n                                'Graduate': 3,\n                                'Masters': 4,\n                                'Phd': 5})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.2.2. Company_size"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['company_size'] = train.company_size.replace({'<10':0,'10/49':1,'50-99':2, '100-500': 3,\n                            '500-999':4, '1000-4999':5, '5000-9999':6, '5000-9999': 7,'10000+':8})\ntest['company_size'] = test.company_size.replace({'<10':0,'10/49':1,'50-99':2, '100-500': 3,\n                            '500-999':4, '1000-4999':5, '5000-9999':6, '5000-9999': 7,'10000+':8})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.2.3. Experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['experience'] = train.experience.replace({'<1':0,'>20':21})\ntrain['experience'] = train['experience'].astype(str).astype(float)\ntest['experience'] = test.experience.replace({'<1':0,'>20':21})\ntest['experience'] = test['experience'].astype(str).astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.2.4. Last_new_job"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['last_new_job'] = train.last_new_job.replace({'never':0, '>4':5})\ntrain['last_new_job'] = train['last_new_job'].astype(str).astype(float)\ntest['last_new_job'] = test.last_new_job.replace({'never':0, '>4':5})\ntest['last_new_job'] = test['last_new_job'].astype(str).astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Cleaning data\n\nIn this section, we are going to fill the missing values. We will use two process: firstly, for the features that have been converted in numerical, we will use KNN imputer, and secondly, for the features which are still categorical, we will use the mode."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 4.1. KNN imputer"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import KNNImputer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_miss = ['gender', 'education_level','experience','company_size', 'last_new_job']\ntrain_miss_knn = train[['enrollee_id'] + col_miss]\ntrain_no_miss_knn = train.drop(col_miss, axis=1)\n\ntest_miss_knn = test[['enrollee_id'] + col_miss]\ntest_no_miss_knn = test.drop(col_miss, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNNImputer(n_neighbors=5)\nknn.fit(train_miss_knn)\ntrain_miss_knn = pd.DataFrame(np.round(knn.transform(train_miss_knn)),columns = train_miss_knn.columns )\ntest_miss_knn = pd.DataFrame(np.round(knn.transform(test_miss_knn)),columns = train_miss_knn.columns )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.merge(train_miss_knn, train_no_miss_knn, on='enrollee_id')\ndf_test = pd.merge(test_miss_knn, test_no_miss_knn, on='enrollee_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2. Mode\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['enrolled_university'].fillna(df_train['enrolled_university'].mode()[0], inplace=True)\ndf_test['enrolled_university'].fillna(df_test['enrolled_university'].mode()[0], inplace=True)\n\ndf_train['major_discipline'].fillna(df_train['major_discipline'].mode()[0], inplace=True)\ndf_test['major_discipline'].fillna(df_test['major_discipline'].mode()[0], inplace=True)\n\ndf_train['company_type'].fillna(df_train['major_discipline'].mode()[0], inplace=True)\ndf_test['company_type'].fillna(df_test['major_discipline'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Modelling"},{"metadata":{},"cell_type":"markdown","source":"Our problem is based on binary classifcation, and we are going to use a neural network with keras as model and use it to find the predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom keras.models import Sequential\n\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_num = ['gender', 'education_level', 'experience', 'company_size', 'last_new_job', 'city',\n                'city_development_index','relevent_experience', 'training_hours']\nfeatures_cat = ['enrolled_university', 'major_discipline','company_type']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we draw the target, we realise that there is not balance between the values looking or not looking for job change. Then we will use SMOTE in order to create a more homogeneous sample. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\ndf_train_X = df_train[features_num + features_cat]\n\npreprocessor = make_column_transformer(\n                (StandardScaler(), features_num),\n                (OneHotEncoder(), features_cat))\n\nX = preprocessor.fit_transform(df_train_X)\nY = df_train[['target']]\nsmote = SMOTE(random_state = 550)\nX_smote, Y_smote = smote.fit_resample(X,Y)\n\nsmote = SMOTE(random_state = 450)\nX_smote1, Y_smote1 = smote.fit_resample(X,Y)\n\n\ndf_train_X = pd.concat([pd.DataFrame(X_smote), pd.DataFrame(X_smote1)], axis = 0).reset_index(drop = True)\ndf_train_y = pd.concat([Y_smote, Y_smote1], axis = 0).reset_index(drop = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(df_train_X, df_train_y, test_size=0.3, random_state = 540)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input_nodes = [X_valid.shape[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=keras.Sequential([\n        layers.Dense(512, activation = 'relu', input_shape = Input_nodes), \n        layers.Dropout(0.3),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation = 'relu'),\n        layers.Dropout(0.3),\n        layers.BatchNormalization(),\n        layers.Dense(1, activation = 'sigmoid'),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n            loss='binary_crossentropy',\n            optimizer='adam',\n            metrics=[tf.keras.metrics.AUC()],\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n                                    patience = 10,\n                                    min_delta = 0.001,\n                                    restore_best_weights= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n            X_train, y_train,\n            validation_data = (X_valid, y_valid),\n            batch_size = 128,\n            epochs = 70,\n            callbacks = [early_stopping],\n            verbose = 1,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=1, figsize=(10,8))\nhistory_df.loc[:, ['loss', 'val_loss']].plot(ax = axes[0])\nhistory_df.loc[:, ['auc', 'val_auc']].plot(ax = axes[1])\naxes[0].set_xlabel('epochs')\naxes[1].set_xlabel('epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test\ndf_test = df_test[features_num + features_cat]\nX_test = preprocessor.transform(df_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = model.predict(X_test)\nsample_submission['target'] = [ 1 if i>=0.5 else 0 for i in test_preds]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('submission.csv', index=False)\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reference \n\nhttps://www.kaggle.com/nkitgupta/who-will-leave-a-job-test-auc-0-93"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}