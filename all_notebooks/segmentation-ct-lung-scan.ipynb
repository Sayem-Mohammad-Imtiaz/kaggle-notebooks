{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Lung CT Segmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\n\nHTML('''<script>\ncode_show=true; \nfunction code_toggle() {\n if (code_show){\n $('div.input').hide();\n } else {\n $('div.input').show();\n }\n code_show = !code_show\n} \n$( document ).ready(code_toggle);\n</script>\n<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize=(40,8))\n\nimg=mpimg.imread('/kaggle/input/images1/CT UNET3D.png')\nimgplot = plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %pylab inline\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n\n# plt.figure(figsize=(40,8))\n\n# img=mpimg.imread('/kaggle/input/images1/CT UNET3D.png')\n# imgplot = plt.imshow(img)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from nibabel.testing import data_path\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Sample Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"example_filename = os.path.join(data_path, '/kaggle/input/covid19-ct-scans/ct_scans/coronacases_org_001.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_filename ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef multi_slice_viewer(volume):\n    #remove_keymap_conflicts({'j', 'k'})\n    fig, ax = plt.subplots()\n    ax.volume = volume\n    ax.index = volume.shape[0] // 2\n    ax.imshow(volume[ax.index])\n    fig.canvas.mpl_connect('key_press_event', process_key)\n\ndef process_key(event):\n    fig = event.canvas.figure\n    ax = fig.axes[0]\n    if event.key == 'j':\n        previous_slice(ax)\n    elif event.key == 'k':\n        next_slice(ax)\n    fig.canvas.draw()\n\ndef previous_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n    ax.images[0].set_array(volume[ax.index])\n\ndef next_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index + 1) % volume.shape[0]\n    ax.images[0].set_array(volume[ax.index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nibabel as nib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = nib.load(example_filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[:,:,i])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(images):\n\n    n_ = min(images.shape[0], 20) \n    rows = 4\n    cols = (n_ // 4) + (1 if (n_ % 4) != 0 else 0)\n    figure = plt.figure(figsize=(2*rows, 2*cols))\n    plt.subplots_adjust(0, 0, 1, 1, 0.001, 0.001)\n    for i in range(n_):\n        plt.subplot(cols, rows, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        if images.shape[1] == 3:\n           \n            vol = images[i].detach().numpy()\n            img = [[[(1-vol[0,x,y])*vol[1,x,y], (1-vol[0,x,y])*vol[2,x,y], 0] \\\n                            for y in range(vol.shape[2])] \\\n                            for x in range(vol.shape[1])]\n            plt.imshow(img)\n        else: \n            plt.imshow((images[i, 0]*255).int(), cmap= \"gray\")\n\n    return figure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/ct_scans/'\n    label_dir = '/kaggle/input/covid19-ct-scans/lung_and_infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reshape(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cv2.resize(image[:,:,i], ( 64, 64))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out=LoadLungData(64, 64,100)\n# print(out.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     value=out[0]['seg'][i,:,:]>0\n#     print(value)\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(10,35):\n#     plt.subplot(5, 5, i + 1-10)\n\n#     plt.imshow(out[0]['seg'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keys = range(len(out))\n# split = dict()\n# size=len(out)\n# split_1=int(size*0.7)\n# split_2=int(size*0.7)+int(size*0.2)\n# split['train']=range(0,split_1)\n# split['test']=range(split_1,split_2)\n# split['val']=range(split_2,size)\n# print('len val',len(split['val']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs =10\ntime_start = \"\"\ntime_end = \"\"\nepoch = 0\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch\n# from torch.utils.data import Dataset\n\n\n# class SlicesDataset(Dataset):\n\n#     def __init__(self, data):\n#         self.data = data\n\n#         self.slices = []\n\n#         for i, d in enumerate(data):\n#             print(d[\"image\"].shape[0])\n#             for j in range(d[\"image\"].shape[0]):\n#                 self.slices.append((i, j))\n#         print('Len slices ',len(self.slices))\n\n#     def __getitem__(self, idx):\n\n#         slc = self.slices[idx]\n#         sample = dict()\n#         sample[\"id\"] = idx\n\n\n#         i,j=slc\n        \n#         #print('i ',i)\n#         #print('j ',j)\n    \n#         import numpy as np\n\n#         image_=self.data[i]['image']\n#         label_=self.data[i]['seg']\n#         image=image_[j,:,:]\n#         #print('Slice shape ',image.shape)\n#         print('1',image.shape)\n#         image=image.reshape(1,image.shape[0],image.shape[1])\n#         print('2',image.shape)\n#         label=label_[j,:,:]\n#         label=label.reshape(1,label.shape[0],label.shape[1])\n   \n#         sample['image']=torch.tensor(image)#\n#         sample['seg']=torch.tensor(label)#\n\n#         return sample\n\n#     def __len__(self):\n   \n#         return len(self.slices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom nilearn.surface import surface\nfrom nilearn.plotting import show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_loader = DataLoader(SlicesDataset(out[split[\"train\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)\n# val_loader = DataLoader(SlicesDataset(out[split[\"val\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_data = out[split[\"test\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(inp_shape, k_size=3):\n    merge_axis = -1 # Feature maps are concatenated along last axis (for tf backend)\n    data = Input(shape=inp_shape)\n    conv1 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(data)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    conv2 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(conv1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n\n    conv3 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool1)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv4 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n\n    conv5 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool2)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n    conv6 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv5)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv6)\n\n    conv7 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool3)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation('relu')(conv7)\n    conv8 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv7)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Activation('relu')(conv8)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conv8)\n\n    conv9 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool4)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = Activation('relu')(conv9)\n\n    up1 = UpSampling3D(size=(2, 2, 2))(conv9)\n    conv10 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(up1)\n    conv10 = BatchNormalization()(conv10)\n    conv10 = Activation('relu')(conv10)\n    conv11 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv10)\n    conv11 = BatchNormalization()(conv11)\n    conv11 = Activation('relu')(conv11)\n    merged1 = concatenate([conv11, conv8], axis=merge_axis)\n    conv12 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(merged1)\n    conv12 = BatchNormalization()(conv12)\n    conv12 = Activation('relu')(conv12)\n\n    up2 = UpSampling3D(size=(2, 2, 2))(conv12)\n    conv13 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up2)\n    conv13 = BatchNormalization()(conv13)\n    conv13 = Activation('relu')(conv13)\n    conv14 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv13)\n    conv14 = BatchNormalization()(conv14)\n    conv14 = Activation('relu')(conv14)\n    merged2 = concatenate([conv14, conv6], axis=merge_axis)\n    conv15 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged2)\n    conv15 = BatchNormalization()(conv15)\n    conv15 = Activation('relu')(conv15)\n\n    up3 = UpSampling3D(size=(2, 2, 2))(conv15)\n    conv16 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up3)\n    conv16 = BatchNormalization()(conv16)\n    conv16 = Activation('relu')(conv16)\n    conv17 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv16)\n    conv17 = BatchNormalization()(conv17)\n    conv17 = Activation('relu')(conv17)\n    merged3 = concatenate([conv17, conv4], axis=merge_axis)\n    conv18 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged3)\n    conv18 = BatchNormalization()(conv18)\n    conv18 = Activation('relu')(conv18)\n\n    up4 = UpSampling3D(size=(2, 2, 2))(conv18)\n    conv19 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up4)\n    conv19 = BatchNormalization()(conv19)\n    conv19 = Activation('relu')(conv19)\n    conv20 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv19)\n    conv20 = BatchNormalization()(conv20)\n    conv20 = Activation('relu')(conv20)\n    merged4 = concatenate([conv20, conv2], axis=merge_axis)\n    conv21 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged4)\n    conv21 = BatchNormalization()(conv21)\n    conv21 = Activation('relu')(conv21)\n\n    conv22 = Convolution3D(padding='same', filters=2, kernel_size=k_size)(conv21)\n    output = Reshape([-1, 2])(conv22)\n    output = Activation('softmax')(output)\n    output = Reshape(inp_shape[:-1] + (2,))(output)\n\n    model = Model(data, output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out[0]['image'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X=np.array(X)\n# # y=np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv3D, Input, MaxPooling3D, Dropout, concatenate, UpSampling3D\nimport tensorflow as tf\n\ndef Unet3D(inputs,num_classes):\n    x=inputs\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same',data_format=\"channels_last\")(x)\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv1)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(pool1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv2)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(pool2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv3)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(pool3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(drop4)\n\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(pool4)\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv3D(64, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(drop5))\n    merge6 = concatenate([drop4,up6],axis=-1)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(merge6)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv6)\n\n    up7 = Conv3D(32, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv6))\n    merge7 = concatenate([conv3,up7],axis=-1)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(merge7)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv7)\n\n    up8 = Conv3D(16, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv7))\n    merge8 = concatenate([conv2,up8],axis=-1)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(merge8)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv8)\n\n    up9 = Conv3D(8, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv8))\n    merge9 = concatenate([conv1,up9],axis=-1)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(merge9)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv9)\n    conv10 = Conv3D(1,1, activation = 'sigmoid')(conv9)\n    model = Model(inputs=inputs, outputs = conv10)\n    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_loss(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.cast(tf.reshape(y_true,[-1]),tf.float32)\n    y_pred_f =tf.cast(tf.reshape(y_pred,[-1]),tf.float32)\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (1-(2. * intersection + smooth) / (union + smooth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coe(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.reshape(y_true,[-1])\n    y_pred_f = tf.reshape(y_pred,[-1])\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (2. * intersection + smooth) / (union + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_generator(x_train, y_train, batch_size):\n    data_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(x_train, x_train, batch_size)\n    mask_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(y_train, y_train, batch_size)\n    while True:\n        x_batch, _ = data_generator.next()\n        y_batch, _ = mask_generator.next()\n        yield x_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install nilearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nilearn.plotting import view_img, glass_brain, plot_anat, plot_epi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# image_batch, mask_batch = next(my_generator(X, y, 8))\n# fix, ax = plt.subplots(8,2, figsize=(8,20))\n# for i in range(8):\n    \n    \n#     ax[i,0].imshow(image_batch[i,:,:,0])\n#     ax[i,1].imshow(mask_batch[i,:,:,0])\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nweight_saver = ModelCheckpoint('lung.h5', monitor='val_dice_coef', \n                                              save_best_only=True, save_weights_only=True)\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist = Model_3D.fit(X, y,\n#                            steps_per_epoch = 20,\n                           \n#                            epochs=10, verbose=2,\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.array([X[0]]).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# segmented=Model_3D.predict(np.array([X[0]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# segmented_=segmented[0,:,:,:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# segmented_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import SimpleITK as sitk\n# filtered_image = sitk.GetImageFromArray(segmented_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filtered_image ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import nibabel as nib\n# import numpy as np\n\n# data = np.arange(4*4*3).reshape(4,4,3)\n\n# new_image = nib.Nifti1Image(segmented_, affine=np.eye(4))\n\n# new_image_ = nib.Nifti1Image(np.array(X[0]), affine=np.eye(4))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_anat(new_image)\n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view_img(new_image , new_image_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nib.save(new_image , '/kaggle/working/segmented.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nib.save(new_image_ , '/kaggle/working/original.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/ct_scans/'\n    label_dir = '/kaggle/input/covid19-ct-scans/infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out=LoadLungData(64, 64,200)\n# print(out.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(30):\n#     plt.subplot(5, 6, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X=np.array(X)\n# y=np.array(y)\n\n# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = Model_3D.fit(X_train, y_train,\n#                            batch_size=2,\n#                            validation_data=(X_test,y_test),\n#                            epochs=50, verbose=2,\n#                            )\n# auc=max(history.history['dice_coe'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('/kaggle/working/singleinput'+'.csv')\n\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score single input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n# plt.savefig('/kaggle/working/singleinput.png')\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cluster(img):\n            vectorized = img.reshape((-1,4))\n            vectorized = np.float32(vectorized)\n            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n            K = 4\n            attempts=10\n            ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n            center = np.uint8(center)\n            res = center[label.flatten()]\n            result_image = res.reshape((img.shape))\n            return result_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import ndimage\nfrom skimage import filters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef reshape_cluster2(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=filters.median(cv2.resize(image[:,:,i], ( 64, 64)),disk(1))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=filters.median(reshaped_image[:,i,:],disk(1))\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=filters.median(reshaped_image[i,:,:],disk(1))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef reshape_cluster(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cluster(cv2.resize(image[:,:,i], ( 64, 64)))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=cluster(reshaped_image[:,i,:])\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=cluster(reshaped_image[i,:,:])\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef reshape_cluster_spectral(image, new_shape):\n    \n    \n    import skimage.segmentation as seg\n\n\n\n    reshaped_image = np.zeros(new_shape)\n\n    #print(reshaped_image.shape)\n    #print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]= seg.slic(cv2.resize(image[:,:,i], ( 64, 64)),n_segments=30)\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]= seg.slic(reshaped_image[:,i,:],n_segments=30)\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]= seg.slic(reshaped_image[i,:,:],n_segments=30)\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    #print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungMaskData(x_shape, y_shape,limit):\n    \n\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/lung_and_infection_mask'\n    label_dir = '/kaggle/input/covid19-ct-scans/infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungDataClusterData(x_shape, y_shape,limit):\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/lung_and_infection_mask'\n    label_dir = '/kaggle/input/covid19-ct-scans/infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape_cluster(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape_cluster(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=LoadLungData(64, 64,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_=LoadLungDataClusterData(64, 64,100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out__=LoadLungMaskData(64, 64,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[0]['seg'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(40,70,1):\n    plt.subplot(5, 6, i + 1-40)\n\n    plt.imshow(out_[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out__[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[1]['image'][i,:,:]-out_[1]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX=np.array([out[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(y[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-4\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# history = Model_3D.fit(X, y,\n#                            batch_size=2,\n#                            #validation_data=(np.array(X_test),np.array(y_test)),\n#                            epochs=150, verbose=2,\n#                            callbacks=[ tf.keras.callbacks.EarlyStopping(patience=3)]\n#                            )\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('/kaggle/working/withoutsoby.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model_3D.save_weights('/kaggle/working/single.h5')\nModel_3D.load_weights('../input/ctlungseg/single (1).h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%javascript\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# for j in range(20):\n\n#     segmented=Model_3D.predict(np.array([X[j]]))\n#     segmented_=segmented[0,:,:,:,0]\n#     print(len(segmented_[segmented_>0]))\n\n#     import matplotlib.pyplot as plt\n#     im_fdata=img.get_fdata()\n\n\n\n\n#     plt.figure(figsize=(10,8))\n\n#     # Iterate and plot random images\n#     for i in range(0,60):\n#         plt.subplot(10, 6, i + 1)\n\n#         plt.imshow(segmented_[i,:,:])\n#         plt.axis('off')\n\n#     # Adjust subplot parameters to give specified padding\n#     plt.tight_layout()  \n#     plt.show()\n    \n#     import nibabel as nib\n#     import numpy as np\n\n#     data = np.arange(4*4*3).reshape(4,4,3)\n\n#     new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n#     nib.save(new_image , '/kaggle/working/infection'+str(j)+'.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=np.array([out[i]['image'] for i in range(len(out))]+[out_[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-4\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D_filter=Unet3D(inputs,num_classes=3)\n    Model_3D_filter.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    Model_3D_filter.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# history = Model_3D.fit(X, y,\n#                            batch_size=2,\n#                            #validation_data=(np.array(X_test),np.array(y_test)),\n#                            epochs=150, verbose=2,\n#                            callbacks=[ tf.keras.callbacks.EarlyStopping(patience=3)]\n#                            )\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('/kaggle/working/fusion.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model_3D.save_weights('/kaggle/working/multi.h5')\nModel_3D_filter.load_weights('../input/ctlungseg1/multi.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=np.array([out[i]['image'] for i in range(len(out))]+[out_[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef clean(image):\n    \n    \n    import skimage.segmentation as seg\n    \n    count_lines=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            count_lines+=1\n    \n            \n        \n\n\n    reshaped_image = np.zeros((count_lines,512,512))\n    count=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            \n            #print(np.sum(image[i,:,:]))\n            \n        \n            reshaped_image[count,:,:]=cv2.resize(image[i,:,:],(512,512),interpolation=cv2.INTER_CUBIC)\n            count+=1\n\n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef lung(image,lung):\n    \n    \n    import skimage.segmentation as seg\n    \n    count_lines=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            count_lines+=1\n    \n            \n        \n\n\n    reshaped_image = np.zeros((count_lines,512,512))\n    count=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            \n            #print(np.sum(image[i,:,:]))\n            \n        \n            reshaped_image[count,:,:]=cv2.resize(lung[i,:,:],(512,512),interpolation=cv2.INTER_CUBIC)\n            count+=1\n\n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diffv=[]\nfor j in range(20):\n\n    segmented=Model_3D.predict(np.array([X[j]]))\n    segmented_=segmented[0,:,:,:,0]\n    segmented_=clean(segmented_)\n    lung_=lung(segmented_,X[j])\n    print(len(segmented_[segmented_>0.5]))\n    print(len(y[j][y[j]>0.5]))\n    diffv.append(len(segmented_[segmented_>0.5])- len(y[j][y[j]>0.5]))\n    print(diffv)\n   \n    size=len(segmented_[segmented_>0])\n\n    import matplotlib.pyplot as plt\n    im_fdata=img.get_fdata()\n\n\n    if size>200:\n\n        plt.figure(figsize=(10,8))\n\n        # Iterate and plot random images\n        for i in range(0,9):\n            plt.subplot(3, 3, i + 1)\n\n            plt.imshow(segmented_[i,:,:])\n            plt.axis('off')\n\n        # Adjust subplot parameters to give specified padding\n        plt.tight_layout()  \n        plt.show()\n        \n        \n        \n        plt.figure(figsize=(10,8))\n\n        # Iterate and plot random images\n        for i in range(0,9):\n            plt.subplot(3, 3, i + 1)\n\n            plt.imshow(y[j][i,:,:])\n            plt.axis('off')\n\n        # Adjust subplot parameters to give specified padding\n        plt.tight_layout()  \n        plt.show()\n\n    import nibabel as nib\n    import numpy as np\n\n    data = np.arange(4*4*3).reshape(4,4,3)\n    \n    if j==0:\n\n        new_image = nib.Nifti1Image(segmented_, affine=np.eye(4))\n        nib.save(new_image , '/kaggle/working/infection'+str(j)+'.nii')\n        new_image_1 = nib.Nifti1Image(lung_, affine=np.eye(4))\n        nib.save(new_image_1 , '/kaggle/working/lung'+str(j)+'.nii')\nimport csv\n\npd.DataFrame(diffv).to_csv('/kaggle/working/difffusion.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungTestData(x_shape, y_shape,limit):\n\n\n    image_dir = '/kaggle/input/mosmed-covid19-ct-scans/CT-2/'\n\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            covid, _ = load(os.path.join(image_dir, f))\n\n\n            \n\n            #image=image/255\n\n            try:\n\n                covid = reshape(covid, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n               \n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": covid, \"filename\": f})\n        else:\n            break\n   \n    #print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=LoadLungTestData(64, 64,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model_3D.load_weights('../input/ctlungseg/single (1).h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=np.array([out[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor j in range(4):\n\n    segmented=Model_3D.predict(np.array([X[j]]))\n    segmented_=segmented[0,:,:,:,0]\n    segmented_=clean(segmented_)\n    print(len(segmented_[segmented_>0]))\n\n    import matplotlib.pyplot as plt\n    im_fdata=img.get_fdata()\n\n\n\n\n    plt.figure(figsize=(10,8))\n\n    # Iterate and plot random images\n    for i in range(0,4):\n        plt.subplot(3, 2, i + 1)\n\n        plt.imshow(segmented_[i,:,:])\n        plt.axis('off')\n\n    # Adjust subplot parameters to give specified padding\n    plt.tight_layout()  \n    plt.show()\n    \n    import nibabel as nib\n    import numpy as np\n\n    data = np.arange(4*4*3).reshape(4,4,3)\n\n    new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n    nib.save(new_image , '/kaggle/working/infection'+str(j)+'.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model_3D_filter.load_weights('../input/ctlungseg1/multi.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.morphology import disk\n\ndef clean(image):\n    \n    \n    import skimage.segmentation as seg\n    \n    count_lines=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            count_lines+=1\n    \n            \n        \n\n\n    reshaped_image = np.zeros((count_lines,512,512))\n    count=0\n    for i in range(image.shape[0]):\n        if np.sum(image[i,:,:])>0:\n            \n            #print(np.sum(image[i,:,:]))\n            \n        \n            reshaped_image[count,:,:]=cv2.resize(image[i,:,:],(512,512),interpolation=cv2.INTER_CUBIC)\n            count+=1\n\n        \n    return reshaped_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# for j in range(99):\n\n#     segmented=Model_3D.predict(np.array([X[j]]))\n    \n    \n    \n    \n#     segmented_=segmented[0,:,:,:,0]\n#     segmented_=clean(segmented_)\n    \n#     print(len(segmented_[segmented_>0]))\n\n#     import matplotlib.pyplot as plt\n#     im_fdata=img.get_fdata()\n\n\n\n\n#     plt.figure(figsize=(10,8))\n\n#     # Iterate and plot random images\n#     for i in range(0,60):\n#         plt.subplot(10, 6, i + 1)\n\n#         plt.imshow(segmented_[i,:,:])\n#         plt.axis('off')\n\n#     # Adjust subplot parameters to give specified padding\n#     plt.tight_layout()  \n#     plt.show()\n    \n#     import nibabel as nib\n#     import numpy as np\n\n#     data = np.arange(4*4*3).reshape(4,4,3)\n\n#     new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n#     nib.save(new_image , '/kaggle/working/infection'+str(j)+'.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=LoadLungData(64, 64,100)\n#out_=LoadLungDataClusterData(64, 64,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coe_sorense(y_true,y_pred, smooth=1.):\n\n    y_true_f = tf.reshape(y_true,[-1])\n    y_pred_f = tf.reshape(y_pred,[-1])\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    \n    return (2. * intersection + smooth) / (union + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pywt\n# import cv2\n# import numpy as np\n\n# # This function does the coefficient fusing according to the fusion method\n# def fuseCoeff(cooef1, cooef2, method):\n\n#     if (method == 'mean'):\n#         cooef = (cooef1 + cooef2) / 2\n#     elif (method == 'min'):\n#         cooef = np.minimum(cooef1,cooef2)\n#     elif (method == 'max'):\n#         cooef = np.maximum(cooef1,cooef2)\n#     else:\n#         cooef = []\n\n#     return cooef\n\n# def fuse(I1,I2):\n\n\n#     # Params\n#     FUSION_METHOD = 'mean' # Can be 'min' || 'max || anything you choose according theory\n\n#     # We need to have both images the same size\n#     #I2 = cv2.resize(I2,I1.shape) # I do this just because i used two random images\n\n#     ## Fusion algo\n\n#     # First: Do wavelet transform on each image\n#     wavelet = 'db1'\n#     cooef1 = pywt.wavedec2(I1[:,:], wavelet)\n#     cooef2 = pywt.wavedec2(I2[:,:], wavelet)\n\n#     # Second: for each level in both image do the fusion according to the desire option\n#     fusedCooef = []\n#     for i in range(len(cooef1)-1):\n\n#         # The first values in each decomposition is the apprximation values of the top level\n#         if(i == 0):\n\n#             fusedCooef.append(fuseCoeff(cooef1[0],cooef2[0],FUSION_METHOD))\n\n#         else:\n\n#             # For the rest of the levels we have tupels with 3 coeeficents\n#             c1 = fuseCoeff(cooef1[i][0],cooef2[i][0],FUSION_METHOD)\n#             c2 = fuseCoeff(cooef1[i][1], cooef2[i][1], FUSION_METHOD)\n#             c3 = fuseCoeff(cooef1[i][2], cooef2[i][2], FUSION_METHOD)\n\n#             fusedCooef.append((c1,c2,c3))\n\n#     # Third: After we fused the cooefficent we nned to transfor back to get the image\n#     fusedImage = pywt.waverec2(fusedCooef, wavelet)\n\n#     # Forth: normmalize values to be in uint8\n#     fusedImage = np.multiply(np.divide(fusedImage - np.min(fusedImage),(np.max(fusedImage) - np.min(fusedImage))),255)\n#     #fusedImage = fusedImage.astype(np.uint8)\n#     return  cv2.resize(fusedImage,(64,64))\n# # Fith: Show image\n\n# !pip install imutils\n# # import the necessary packages\n# from imutils import paths\n# import argparse\n# import cv2\n\n# def variance_of_laplacian(image):\n# \t# compute the Laplacian of the image and then return the focus\n# \t# measure, which is simply the variance of the Laplacian\n# \treturn cv2.Laplacian(image, cv2.CV_64F).var()\n\n# def fuse_(I1,I2):\n#     IMAGE=[]\n#     #print('teste')\n#     for i in range(I1.shape[0]):\n#         IMAGE.append(fuse(I1[i,:,:], cv2.Laplacian(I2[i,:,:],cv2.CV_64F)))\n#     return np.array(IMAGE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])\nX=np.array([(out[i]['image']-cv2.Laplacian(out[i]['image'],cv2.CV_64F))/2 for i in range(len(out))]+[cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))]+[out[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))]+[out[i]['seg'] for i in range(len(out))])\nX=np.array([(out[i]['image']+cv2.Laplacian(out[i]['image'],cv2.CV_64F))/2 for i in range(len(out))]+[cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionhistoryminus.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# #X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\n# y=np.array([out[i]['seg'] for i in range(len(out))])\n# X=np.array([out[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/nofusionhistoryminus.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# #X=np.array([fuse_(out[i]['image'],out[i]['image']) for i in range(len(out))])\n# y=np.array([out[i]['seg'] for i in range(len(out))])\n# X=np.array([(out[i]['image']+cv2.Laplacian(out[i]['image'],cv2.CV_64F))/2 for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionhistoryplus.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([cv2.Laplacian(out[i]['image'],cv2.CV_64F) for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionlaplacian.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([cv2.Laplacian(out[i]['image'],cv2.CV_64F)+out[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionsoma.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)+out[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n# # \n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionsobelsoma.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)+out[i]['image'])/2 for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionsobelsomadiv2.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)-out[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n# #                            batch_size=1 ,\n#                            validation_data=(X_test,y_test),\n#                            epochs=10, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionsobeldiffdiv2.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndivminus2laplacian=pd.read_csv('../input/papersegmentctresults/fusion-div2laplacian.csv')\ndfnofusion=pd.read_csv('../input/papersegmentctresults/nofusion.csv')\ndivplus2laplacian=pd.read_csv('../input/papersegmentctresults/fusiondiv2laplacian.csv')\naddlaplacian=pd.read_csv('../input/papersegmentctresults/fusionlaplacian.csv')\ndivminus2sobel=pd.read_csv('../input/papersegmentctresults/fusion-div2sobel.csv')\ndivplus2sobel=pd.read_csv('../input/papersegmentctresults/fusiondiv2sobel.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndivminus2laplacian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import altair as alt\ndfaltair=pd.DataFrame(columns=['x','y','class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,r in divminus2laplacian.iterrows():\n    dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Laplacian fusion diff/2'},ignore_index=True)\nfor i,r in dfnofusion.iterrows():\n    dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'No fusion'},ignore_index=True)\n\nfor i,r in  divplus2laplacian.iterrows():\n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Laplacian fusion add/2'},ignore_index=True)\n\nfor i,r in  addlaplacian.iterrows():\n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Laplacian fusion add'},ignore_index=True)\n\n\nfor i,r in  divminus2sobel.iterrows():\n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Sobel fusion diff/2'},ignore_index=True)\nfor i,r in  divplus2sobel.iterrows():\n    \n        dfaltair=dfaltair.append({'x':r['Unnamed: 0'],'y':r['val_dice_coe'],'class':'Sobel fusion add/2'},ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alt.Chart(dfaltair).mark_line().encode(x='x',y=alt.Y('y', scale=alt.Scale(domain=[0.2, 0.88])),color='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#alt.Chart(dfaltair).mark_line().encode(x='x',y=alt.Y('y', scale=alt.Scale(domain=[0.2, 0.3])),color='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#alt.Chart(dfaltair).mark_line().encode(x='x',y=alt.Y('y', scale=alt.Scale(domain=[0.874, 0.88])),color='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out=LoadLungData(64, 64,100)\n# out__=LoadLungMaskData(64, 64,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([out__[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=20, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([out[i]['image'] for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadClusterData(x_shape, y_shape,limit):\n    \n\n\n\n    image_dir = '/kaggle/input/covid19-ct-scans/lung_and_infection_mask'\n    label_dir = '/kaggle/input/covid19-ct-scans/infection_mask/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image/255\n\n            try:\n\n                image = reshape_cluster_spectral(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape_cluster_spectral(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cv2.Sobel(out[i]['image'], ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)+cv2.Laplacian(out[i]['image'],cv2.CV_64F))/2 for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-2\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n#                               patience=1, min_lr=0.001)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\n# hist = Model_3D.fit(X_train, y_train,\n                           \n#                            batch_size=1,\n#                            validation_data=(X_test,y_test),\n#                            epochs=20, verbose=2,\n#                            callbacks=[reduce_lr]\n#                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# df_history=pd.DataFrame.from_dict(hist.history)\n# df_history.to_csv('/kaggle/working/fusionlaplaciansobel.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(hist.history['dice_coe'])\n# #plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cluster(out[i]['image'])+cv2.Laplacian(out[i]['image'],cv2.CV_64F))/2 for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-2\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n                              patience=1, min_lr=0.001)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\nhist = Model_3D.fit(X_train, y_train,\n                           \n                           batch_size=1,\n                           validation_data=(X_test,y_test),\n                           epochs=20, verbose=2,\n                           callbacks=[reduce_lr]\n                           )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf_history=pd.DataFrame.from_dict(hist.history)\ndf_history.to_csv('/kaggle/working/fusionlaplaciankmeans.csv')\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\nplt.plot(hist.history['dice_coe'])\n#plt.plot(history.history['val_dice_coe'])\nplt.title('Dice score multi input')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['dice', 'val_dice'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scikit-fuzzy\nimport skfuzzy as fuzz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import transform,io\nimport cv2\n\ndef fuzzy(image):\n    \n    \n    \n    mfx = fuzz.trapmf(image.flatten(),  [0.4, 0.6,200,200])\n    \n \n    \n    return mfx.reshape(64,64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(out[0]['image'].shape)\n#plt.imshow(out[0]['image'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddepth = cv2.CV_16S\nscale = 1\ndelta = 0\ny=np.array([out[i]['seg'] for i in range(len(out))])\nX=np.array([ (cluster(out[i]['image'])+out[i]['image'])/2 for i in range(len(out))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[2][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-2\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='dice_coe', factor=0.2,\n                              patience=1, min_lr=0.001)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    #Model_3D.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n\nhist = Model_3D.fit(X_train, y_train,\n                           \n                           batch_size=1,\n                           validation_data=(X_test,y_test),\n                           epochs=20, verbose=2,\n                           callbacks=[reduce_lr]\n                           )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}