{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Tweets: Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"**Credits**:\n* Indonesian Stoplist by <a href=\"https://www.kaggle.com/oswinrh\">oswinrh</a>\n* Indonesian Abusive and Hate Speech Twitter Text by <a href=\"https://www.kaggle.com/ilhamfp31\">ilhamfp31</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom textblob import TextBlob as tb\nfrom subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\n\n!pip install PySastrawi\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n\n!pip install googletrans\nfrom googletrans import Translator","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/covid19-indonesian-twitter-sentiment/covid-sentiment.csv')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping Duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop_duplicates(subset='tweet', keep='first').reset_index()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"* Lowercasing\n* Stemming\n* Stopwords Removal\n* Non-Alphanumeric Removal\n* Unnecessary Character Removal"},{"metadata":{},"cell_type":"markdown","source":"### Slang Words Replacement"},{"metadata":{"trusted":true},"cell_type":"code","source":"slang_dict = pd.read_csv('../input/indonesian-abusive-and-hate-speech-twitter-text/new_kamusalay.csv', encoding='latin-1', header=None)\nslang_dict = slang_dict.rename(columns={0: 'original', \n                                      1: 'replacement'})\n\nid_stopword_dict = pd.read_csv('../input/indonesian-stoplist/stopwordbahasa.csv', header=None)\nid_stopword_dict = id_stopword_dict.rename(columns={0: 'stopword'})\nstopwords_new = pd.DataFrame(['sih','nya', 'iya', 'nih', 'biar', 'tau', 'kayak', 'banget'], columns=['stopword'])\nid_stopword_dict = pd.concat([id_stopword_dict,stopwords_new]).reset_index()\nid_stopword_dict = pd.DataFrame(id_stopword_dict['stopword'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Others"},{"metadata":{"trusted":true},"cell_type":"code","source":"factory = StemmerFactory()\nstemmer = factory.create_stemmer()\n\n\ndef lowercase(text):\n    return text.lower()\n\ndef remove_unnecessary_char(text):\n    text = re.sub(r'pic.twitter.com.[\\w]+', '', text) # Remove every pic \n    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n    \n    text = re.sub('gue','saya',text) # Sub gue saya\n    text = re.sub('\\n',' ',text) # Remove every '\\n'\n    \n    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n    text = re.sub(r':', '', text)\n    text = re.sub(r'‚Ä¶', '', text)\n    \n    to_delete = ['hypertext', 'transfer', 'protocol', 'over', 'secure', 'socket', 'layer', 'dtype', 'tweet', 'name', 'object'\n                 ,'twitter','com', 'pic', ' ya ']\n    \n    for word in to_delete:\n        text = re.sub(word,'', text)\n        text = re.sub(word.upper(),' ',text)\n    \n    retweet_user = [' rt ', ' user ']\n    \n    for word in retweet_user:\n        text = re.sub(word,' ',text) # Remove every retweet symbol & username\n        text = re.sub(word.upper(),' ',text)\n        \n    text = re.sub('  +', ' ', text) # Remove extra spaces\n    return text\n    \ndef remove_nonaplhanumeric(text):\n    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n    return text\n\nslang_dict_map = dict(zip(slang_dict['original'], slang_dict['replacement']))\n\ndef normalize_slang(text):\n    return ' '.join([slang_dict_map[word] if word in slang_dict_map else word for word in text.split(' ')])\n\ndef remove_stopword(text):\n    text = ' '.join(['' if word in id_stopword_dict.stopword.values else word for word in text.split(' ')])\n    text = re.sub('  +', ' ', text) # Remove extra spaces\n    text = text.strip()\n    return text\n\ndef stemming(text):\n    return stemmer.stem(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(text):\n    text = lowercase(text)\n    text = remove_unnecessary_char(text)\n    text = remove_nonaplhanumeric(text)\n    text = normalize_slang(text)\n    text = stemming(text) \n    text = remove_stopword(text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tweet'] = df['tweet'].apply(preprocess).apply(preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop_duplicates(subset='tweet', keep='first').reset_index()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('covid-sentiment-preprocessed.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"mpl.rcParams['figure.figsize']=(12.0,12.0) \nmpl.rcParams['font.size']=12              \nmpl.rcParams['savefig.dpi']=100             \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=id_stopword_dict,\n                          max_words=400,\n                          max_font_size=50, \n                          random_state=69\n                         ).generate(str(df['tweet']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\nfig.savefig(\"word1.png\", dpi=900)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Sentiment Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"translator = Translator()\ntranslator.translate('nice', dest='id').text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def en_to_id(sentence):\n    if tb(sentence).detect_language() == 'en':\n        return tb(sentence)\n    \n    translator = Translator()\n    \n    output = translator.translate(sentence, dest='en')\n    return tb(output.text)\n    \ndef get_sentiment(sentence):\n    sentence = en_to_id(sentence)\n    return sentence.sentiment\n\ndef round_polarity(value):\n    if value >= 0.3:\n        return 1\n    elif value == 0:\n        return 0\n    return -1\n\ndef round_subjectivity(value):\n    if value >= 0:\n        return 1\n    elif value == 0:\n        return 0\n    return -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = df['tweet']\npolarity = []\nsubjectivity = []\n\nfor tweet in tweets:\n    sentiment = get_sentiment(tweet)\n    \n    polarity.append(round_polarity(sentiment[0]))\n    subjectivity.append(round_subjectivity(sentiment[1]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}