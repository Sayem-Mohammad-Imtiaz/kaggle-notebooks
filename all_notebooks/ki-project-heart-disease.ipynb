{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Heart Disease Classification\n\nEin weit verbreiteter Anwendungsbereich von Machine Learning ist die medizinische Diganostik, die durch ihre Interaktion mit künstlicher Intelligenz tiefgründigere Zusammenhänge zwischen Krankheiten und ihren Ursachen aufdecken kann. Birgt die maschinell gestützte Diagnose selbst einige Risiken, profitieren Ärzte dennoch durch die Unterstützung eines repräsentativen, trainierten Modells, da Erfahrungswerte aus Millionen von Patientendaten zu einer Diagnose heranzgezogen werden können.\n\nDie folgende Arbeit soll einen Einblick in die medizinische Anwendung von Machine Learning am Beispiel der Erkennung von Herzkrankheiten ermöglichen. Die Diagnose von Herzkrankheiten stützt sich auf eine Reihe körperlicher Anzeichen und klinischer Testergebnisse, wie z.B. EKG Tests, Herz-Scans oder Bluttests. \n\nDer im Folgenden verwendete Datensatz beinhaltet eine Auswahl von Attributen, die Ergebnisse solcher Tests und zusätzliche Patienteninformationen wie Alter und Geschlecht beinhalten. Auf Basis dieser Daten soll ein Modell des Supervised Learning, die binäre Klassifikation, das Vorliegen einer Herzkrankheit beurteilen. "},{"metadata":{},"cell_type":"markdown","source":"## Beschreibung der Attribute\n\nDer Datensatz stammt aus einer klinischen Testreihe der Ärzte Andras Janosi, William Steinbrunn, Matthias Pfisterer und Robert \nDetrano. Die anschließende Beschreibung ist der Quelle entnommen, detaillierte Informationen folgen im Rahmen der Data Exploration.\n\n- **Age**: in years\n- **Sex**: (1 = male; 0 = female)\n- **Cp**: chest pain type\n    - Value 1: typical angina \n    - Value 2: atypical angina \n    - Value 3: non-anginal pain \n    - Value 4: asymptomatic \n- **Testbps**: resting blood pressure (in mm Hg on admission to the hospital)\n- **Chol**: serum cholestoral in mg/dl\n- **Fbs**: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n- **Restec**: gresting electrocardiographic results\n- **Thalach**: maximum heart rate achieved\n- **Exang**: exercise induced angina (1 = yes; 0 = no)\n- **Oldpeak**: ST depression induced by exercise relative to rest\n- **Slope**: the slope of the peak exercise ST segment\n- **Ca**: number of major vessels (0-3) colored by flourosopy\n- **Thal**: thallium heart scan, 3 = normal; 6 = fixed defect; 7 = reversable defect\n- **Target**: 1 or 0\n\nQuelle: https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n\n### Ziel: Vorhersage einer vorhandenen Herzkrankheit auf Basis von Patientendaten"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport pandas_profiling\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nrandom_state = 42\n\nprint(os.listdir(\"../input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Erster Einblick in den Datensatz:"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":false},"cell_type":"code","source":"df = pd.read_csv('../input/heart.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"Nach der folgenden Analyse lässt sich der Datensatz mit diesen Eckpunkten beschreiben:\n\n- Der Datensatz umfasst 303 Reihen und 14 Spalten\n- Der Speicherplatz beträgt 33.2 KB\n- Bis auf das Attribut \"oldpeak\" liegen alle weiteren Spalten im \"int64\" Datenformat vor\n\nAlle kategorischen Attribute wurden bereits in numerische Dummy-Variablen umgewandelt."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Die folgende Tabelle enthält allgemeine Informationen zu den vorhandenen Daten, aus denen sich erste Rückschlüsse ziehen lassen, wie z.B.: Das Durchschnittsalter der Patienten beträgt ca. 54 Jahre, der jüngste Studienteilnehmer ist 29 Jahre alt, der älteste 77."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Attributtypen\n\nDer Datensatz umfasst 9 kategorische und 5 numerische Attribute:\n\n###### Kategorische Variablen:\n\nAlle kategorischen Attribute (Geschlecht, Cp (Schmerzkategorie), hoher Blutzucker, restecg & slope (EKG Resultate), ca (Anzahl der Hauptgefäße) und thal (Einstfung des Thaliumwerts) wurden bereits in Dummy Variablen umgesetzt\n\n- **Sex**: Geschlecht\n- **Cp**: Schmerzkategorie von 1-4 \n- **Fbs**: Abnormalie des Blutzuckers (0 = unter dem Durchschnittswert, 1 = über dem Durchschnittswert)\n- **Exang**: \"Engegefühl\" bei sportlicher Aktivität (0 = Nein, 1 = Ja)\n- **Restecg**: EKG Untersuchung nach Abnormalitäten (0 = ohne Befund, 1 & 2 mittlerer bis schwerwiegender Befund)\n- **Slope**: EKG Untersuchung nach kardiographischen Auffälligkeiten (Einteilung von 0-4)\n- **Ca**: Anzahl erkennbarer Hauptgefäße im Rahmen einer Durchleuchtungsuntersuchung (Einteilung von 0-4, ein Hauptgefäß ist bei Verstopfung nicht sichtbar)\n- **thal**: Test zur Qualität der Blutversorgung, Prüfung nach Durchblutungsstörung \"Thalassämie\", welche vererbt werden kann\n- **target**: Ergebnis der Patientenuntersuchung (0 = keine Herzkrankheit, 1 = Herzkrankheit)\n\n###### Numerische Variablen:\n\n- **Age**: Alter\n- **Trestbps**: Ruhepuls gemessen an Millimeter Quecksilbersäule, Durchschnittswert bei Erwachsenen: 120-129)\n- **Chol**: Cholesterin in mg pro Deziliter, Durchschnittswert ist 240 mg/dl\n- **Thalach**: Maximale Herzfrequenz (bei größtmöglicher Anstrengung) in Herzschläge/ Minute\n- **Oldpeak**: Befund bei EKG (ST Streckensenkung), der eine bestimmte Basislinie nicht unterschreiten sollte"},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Data Visualization"},{"metadata":{},"cell_type":"markdown","source":"Um ein besseres Verständnis von den entahltenen Daten zu erhalten, werden einige Zusammenhänge als Statistiken visualisiert."},{"metadata":{},"cell_type":"markdown","source":"####  1.1.1 Allgemeine Patienteninformationen"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"values = [96, 207]\nlabels = ['Weiblich', 'Männlich']\nplt.pie(values, labels= values,counterclock=False, shadow=True)\nplt.title('Geschlechterverteilung der Patienten')\nplt.legend(labels,loc=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Der Datensatz enthält 96 weibliche und 207 männliche Patienten. Damit ist der Datensatz hinsichtlich der Geschlechteraufteilung hin zu männlichen Geschlechtern verzerrt, da fast doppelt so viele Daten zu Männern, als zu Frauen vorliegen. "},{"metadata":{"trusted":false},"cell_type":"code","source":"df.groupby('sex').age.plot(kind='kde')\nplt.title('Alter der Patienten abhängig von Geschlecht')\nlabels = ['Weiblich', 'Männlich']\nplt.legend(labels,loc=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Sowohl bei weiblichen, als auch bei männlichen Patienten liegen die meisten daten für Personen zwischen 40 und ca. 75 Jahren vor."},{"metadata":{"trusted":false},"cell_type":"code","source":"values = [138, 165]\nlabels = ['Nicht herzkrank', 'Herzkrank']\nplt.pie(values, labels= values,counterclock=False, shadow=True)\nplt.title('Verteilung der Präsenz von Herzkrankheiten')\nplt.legend(labels,loc=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Hinsichtlich der Präsenz von Herzkrankheiten ist der Datensatz \"relativ\" ausbalanciert. Somit hat das ML Modell eine augeglichene Informationsbasis für die Klassifizierung von gesunden und kranken Patienten."},{"metadata":{"trusted":false},"cell_type":"code","source":"ct_tarsex = pd.crosstab(df.target, df.sex)\nct_tarsex.plot.bar(stacked=True)\nlabels = ['Weiblich', 'Männlich']\nplt.legend(labels,loc=3)\nplt.title('Präsenz von Herzkrankheiten nach Geschlechtern')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Der Graphik zufolge sind unter den Patienten ohne Herzkrankheiten deutlich mehr Männer als Frauen. Das Modell könnte demnach bei der Klassifizierung von gesunden Patienten daher möglicherweise \"biased\" bzw. voreingenommen sein und Männer tendenziell öfter als nicht herzkrank einstufen. Jedoch muss bei der Graphik die ungleiche Geschlechterverteilung innerhalb des Datensatzes beachtet werden."},{"metadata":{},"cell_type":"markdown","source":"####  1.1.2 Spezifische medizinische Informationen"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"values = [143, 86, 50, 23]\nlabels = ['Typisches Beklemmungsgefühl / Angina', 'Untpyische Angina', 'Nicht-anginale Schmerzen', 'Ohne erkennbare Symptome']\nplt.pie(values, labels= values,counterclock=False, shadow=True)\nplt.title('Verteilung der Schmerzkategorien')\nplt.legend(labels, loc=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Fast 50% aller Patienten haben ein typisches Beklemmungsgefühl im Herzbereich, auch Angina genannt. Die verbleibenden Testpersonen teilen sich zu ungefähr gleichen Teilen auf untypische Beklemmungserscheinungen und nicht präsente Symptome auf."},{"metadata":{"trusted":false},"cell_type":"code","source":"ct2_anglabel = pd.crosstab(df.target, df.cp)\nct2_anglabel.plot.bar(stacked=True)\n\nplt.title('Schmerzkategorien gemappt zu vorhandenen Herzkrankheiten')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Entgegen der gängigen Vermutung, dass anginale Schmerzen stark mit Herzkrankheiten korrelieren, sind vor allem nicht-angila und untypische Schmerzen Zeichen für eine Herzkrankheit."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"ct2_calabel = pd.crosstab(df.target, df.ca)\nct2_calabel.plot.bar(stacked=True)\n\nplt.title('Anzahl erkannter Gefäße im Verhältnis zu präsenten Herzkrankheiten')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Auf Basis des allgemeinen medizinischen Kontexts kann die Hypothese aufgestellt werden, dass Patienten mit 0 erkannten großen Hergefäßen (durch Verstopfung) häufiger unter einer Herzkrankheiten leiden. D.h. je weniger Gefäße erkannt wurden, desto höher wäre die Wahrscheinlichkeit einer Herzkrankheit. \n\nDie obige Graphik bestätigt diese Vermutung, da ein Großteil aller Patienten mit verstopften Gefäßen tatsächlich unter einer Herzkrankheit leiden. Dies liefert einen ersten Hinweis auf eine vorliegende Korrelation zwischen der Anzahl erkannter Hauptgefäße und dem \"Label\" Herzkrankheit. "},{"metadata":{"trusted":false},"cell_type":"code","source":"norm_bot = 120\nnorm_top = 129\n\nresult = plt.hist(df[['trestbps']].values, bins=24, color='dodgerblue', edgecolor='k', alpha=0.65)\nplt.axvline(norm_bot, color='r', linewidth=2)\nplt.axvline(norm_top, color='r', linewidth=2)\n\n_, max_ = plt.ylim()\n\nplt.text(160 + 160/10, \n         max_ - max_/10, \n         'Optimal      {:}'.format(norm_bot))\n\nplt.text(160 + 160/10, \n         max_ - max_/10 - 5, \n         'Normal <= {:}'.format(norm_top))\n\nplt.title('Werteverteilung des Ruhepuls')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: Der obigen Graphik kann entnommen werden, dass die Mehrheit aller Patienten in ihren Ruhepuls-Werten um Durchschnittswerte zentriert ist. Aus diesem Grund lässt sich vermuten, dass der Ruhepuls als solches nicht direkt mit dem Label korreliert.  "},{"metadata":{"trusted":false},"cell_type":"code","source":"avg = 240\n\nresult = plt.hist(df[['chol']].values, bins=24, color='dodgerblue', edgecolor='k', alpha=0.65)\nplt.axvline(avg, color='r', linewidth=2)\n\n_, max_ = plt.ylim()\n\nplt.text(400 + 400/10, \n         max_ - max_/10, \n         'Durchschnitt: {:}'.format(avg))\n\nplt.title('Werteverteilung der Cholesterin-Konzentration in mg/dl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation**: In Bezug auf die Cholesterin Konzentration der Patienten lässt sich ein ähnliches Phänomen feststellen. Auch hier wird eine geringe Korrelation mit dem Label vermutet, da sich ein Großteil der Cholesterin Werte des Datensatzes um einen normalen bzw. durchschnittlichen Wertebereich ansiedeln.\n\nHinweis: Zunächst wurde der Wert von über 500 mg/dl Cholesterin als Outlier betrachtet, weitere Recherchen ergaben, dass ein derartiger Wert allerdings durchaus bei spezifischen Herzkrankheiten auftreten kann."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#pandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Interpretation der zusätzlichen Report-Ergebnisse:\n\n- Im Datensatz befindet sich ein Duplikat, welches aus Gründen der Repräsentativität entfernt werden sollte\n- Das Attribut \"oldpeak\" ist in der Verteilung seiner Werte linksverzerrt, da 32,7% aller Datensätze den Wert \"0\" enthalten. \n\nHinweis: Die verbleibenden \"zero\" Warnungen bei Attributen beziehen sich auf kategrosiche Variablen und sind in diesem Fall nicht negativ auszuwerten."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Löschen der Duplikate und dauerhafte Speicherung mtihilfe von inplace=True, andernfalls würde eine Kopie erstellt werden\ndf.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"Um erkennen zu können, welche Attribute tatsächlich ausschlaggebend für die Diagnose einer Herzkrankheit sind, können sowohl ihre Korrelationen mit dem Label \"krank\" oder \"nicht krank\", als auch ihre Verbidnung untereinander betrachtet werden. Die Matrix zeigt die jeweiligen Korrelationen auf Basis des Pearson Koeffizients, wobei eine Nähe zu dem Wert 1 eine starke Korrelation bedeutet. "},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"plt.matshow(df.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vermutete Korrelationen:\n\n- Wie bereits vermutet, haben Ruhepuls und Cholesterin-Konzentration aufgrund ihrer starken Orientierung an Durchschnittswerten keine starke Korrelation zu dem Label. (Korrelation nahe 0)\n\nAm stärksten korrelieren die folgenden Features:\n\n- CP (0,43)\n- Thalach (0,41)\n- Exang (-0,43)\n- Oldpeak (-0,42)\n- Ca (-0,40)\n\nDie Vermutung liegt nahe, dass diese Features am besten für das spätere Model Training geeignet sind. "},{"metadata":{},"cell_type":"markdown","source":"Die obige Matrix lässt eine erste Beurteilung der Signifikanz der Attribute zu. Um eine möglichst optimale Anzahl an repräsentativen Attributen bzw. Features zu erhalten, wird eine statistische Selektionsmethode gewählt:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import f_classif, SelectKBest","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def select_kbest_clf(data_frame, target, k=5):\n\n    feat_selector = SelectKBest(f_classif, k=k)\n    _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n    \n    feat_scores = pd.DataFrame()\n    feat_scores[\"F Score\"] = feat_selector.scores_\n    feat_scores[\"P Value\"] = feat_selector.pvalues_\n    feat_scores[\"Support\"] = feat_selector.get_support()\n    feat_scores[\"Attribute\"] = data_frame.drop(target, axis=1).columns\n    \n    return feat_scores ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"select_kbest_clf(df, 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Die mit \"True\" gekennzeichneten Attribute sind laut der Analyse als Features am besten geeignet."},{"metadata":{},"cell_type":"markdown","source":"## 3. Modeling"},{"metadata":{},"cell_type":"markdown","source":"#### Pipeline:\n- Pipeline \n    - Zusammenfassen von Teilen des Preprocessing und des Classifiers zu einer Pipeline. Da die Pipeline Modifikationen aller Paramter der einzelnen Komponenten anbietet, wird die Anwendung einer Grid Search erleichtert/ermöglicht\n    \n\n\n#### Feature Selection: \n- SelectKBest \n    - Ermitteln der am besten korrelierenden Features -> reduzieren der Features\n\n#### Scaling: \n- StandardScaler\n    - Normalizieren der einzelnen Spalten auf einen mean = 0 (Durchschnitt) und eine standard deviation = 1 (Standardabweichung)\n\n#### Parameter Tuning: \n- GridSearchCV \n    - Trainieren mehrerer Modelle mit unterschiedlichen Parameterkombinationen. Hier wird ein Modell pro Kombination trainiert, was diese Methode bei grossen Datensätzen und vielen Parameterkombinationen sehr langsam macht. \n    - Zusätzlich wird Cross Validation angewandt, was den Datensatz in sogenannte Folds einteilt. Die Anzahl kann hier mit Parameter k festgelegt werden. Das Modell wird dann auf verschiedene Kombinationen dieser Folds trainiert und aus den Ergebnissen ein Mittelwert erzeugt. Hierdurch kann Overfitting weitesgehend verhindert werden.\n- RandomizedGridSearchCV\n    - Randomisierte Grid Search um bei grosser Anzahl an Parameterkombinationen die Trainingszeit zu verringern. Hier werden zufällig Parameterkombinationen gewählt und die entsprechenden Modelle trainiert.\n- StratifiedKFold \n    - Methode zur Einteilung des Datensatzes in k Folds\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import f_classif, SelectKBest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Visualizieren der Confusion Matrix\n#Source: https://github.com/rohanjoseph93/Python-for-data-science/blob/master/Grid%20Search%20-%20Breast%20Cancer.ipynb\nfrom sklearn.metrics import confusion_matrix\nnp.set_printoptions(precision=2)\n\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    print('False Negative Rate (should be close to 0): ', cnf_matrix[0][1] / (cnf_matrix[0][1] + cnf_matrix[1][1]))\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Aufteilen des Datensatzes in X (Features) und y (Label).\nSplitten der X Matrix und des y Vektors in Training- und Testset. Hierzur wird train_test_split von Sklearn verwendet und der Datensatz in 80% Trainings- und 20% Testdaten aufgeteilt."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX, y = df.iloc[:,:-1],df.iloc[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n\nprint('Training Shapes:', X_train.shape, y_train.shape)\nprint('Test Shapes:', X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Dummy Classifier"},{"metadata":{},"cell_type":"markdown","source":"Der folgende Classifier ist ein initiales Modell, um die Trefferquote eines ML Modells zu zeigen, das bisher mit keinen Methoden optimiert wurde. Es dient zum Vergleich von später eingesetzten Modellen."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nsgdcd = SGDClassifier(random_state = random_state)\nsgdcd.fit(X_train,y_train)\nac_sgdcd = sgdcd.score(X_test, y_test)\n\nprint('Dummy Classifier Accuracy:', ac_sgdcd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In diesem Fall sind False Negatives (versehentlich als gesund eingestuft) aus medizinischer Perspektive relevanter als False Positives (versehentlich als krank eingestuft), da es wesentlich gravierender ist einen kranken Patienten als gesund einzustufen, als einen gesunden Patienten als krank einzustufen. Wird ein kranker Patient als gesund eingestuft und sucht deshalb keinen Arzt auf, ist dies weitaus schlimmer, als ein gesunder Patient, dessen falsche Diagnose sich spätestens beim nächsten Arztbesuch auflöst. \n\nDie hierzu passende Metrik ist die False Negative-Rate, welche möglichst niedrig sein sollte (nahe 0)."},{"metadata":{"trusted":false},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, sgdcd.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - Dummy Classifier')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Der \\\"Dummy Classifier\\\" hat eine Accuracy von 59%, damit ist er \"nur knapp\" besser als eine zufällige Klassifizierung, da er über 40% der Labels nicht richtig zuordnet. Da jedoch keine False Positives auftreten, wird eine Specificity von 1 erreicht."},{"metadata":{},"cell_type":"markdown","source":"### Vorgehensweise Modeling\n\nAufbau einer Pipeline:\n- Feature Selection ('kbest')\n- Scaling ('scaler')\n- Classifier\n\nSetzen der Parameter:\n- Anzahl der (besten) Features, die verwendet werden sollen\n- Classifier spezifische Parameter (n_jobs=-1 erlaubt maximal mögliche Anzahl an parallelen Prozessen)\n\nFitting / Training der Pipeline:\n- Aufrufen der fit() Methode mit den Trainingsdaten\n\nScore der Pipeline mit dem ausgewählten Classifier:\n- Aufrufen der score() Methode mit den Testdaten\n\nHyperparameter Tuning:\n- In CLASSIFIERNAME_params werden mögliche Parameter definiert, welche später von der Grid Search kombiniert werden\n- Aufrufen der fit() Methode der GridSearchCV mit den Trainingsdaten (trotz integrierter Cross Validation)\n\nAuswerten der Grid Search\n- Anzeigen der besten Parameterkombinationen\n- Anzeigen der besten erzielten Accuracy durch Abfragen des best_score_ Attributs der Grid Search, welches die Accuracy des besten Models enthält\n    - Trainingsdaten, GRIDSEARCH.best_score_\n- Verifikation des Ergebnisses durch Aufrufen der score() Methode des besten ermittelten Models \n    - Testdaten, GRIDSEARCH.best_estimator_.score(X_test,y_test)\n- Aufrufen der score() Methode des besten Classifiers, welcher durch die Grid Search bestimmt wurde. Hierzu werden die Testdaten verwendet, welche hier jedoch eher als Validation Set verwendet werden\n\nDa die Grid Search eine integrierte Cross Validation durchführt, können die bei Seite gelegten Testdaten als Validationset verwendet werden. Durch die unterschiedlichen Folds wird Overfitting weitesgehend verhindert. Da manche Folds jedoch schlechter performen als andere, ist eine geringere Accuracy als bei der vorherigen Prediction (fit(Trainingsdaten), score(Testdaten), keine Cross Validation) zu erwarten. Die Aussagekraft ist jedoch höher, da es das Generalisieren neuer Daten besser wiederspiegelt."},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Linear Classifier"},{"metadata":{},"cell_type":"markdown","source":"Initialisieren der Pipeline und erster Test des Linear Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nsgdc_pipe  = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('sgdc', SGDClassifier())\n])\n\nsgdc_pipe.set_params(\n    kbest__k=5,\n    sgdc__eta0=0.1, sgdc__random_state=random_state, sgdc__n_jobs=-1\n)\n\nsgdc_pipe.fit(X_train,y_train)\n\nac_sgdc = sgdc_pipe.score(X_test, y_test)\nprint('SGD Classifier Accuracy:', ac_sgdc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameter Tuning um eine höhere Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Regularization/Penalty\n    - Learning Rate\n- Datenspezifisch\n    - Anzahl der (besten) Features"},{"metadata":{"trusted":false},"cell_type":"code","source":"sgdc_params = {\n        'sgdc__penalty': ['l1', 'l2', 'none', 'elasticnet'],\n        'sgdc__learning_rate': ['constant', 'optimal', 'invscaling'],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_sgdc = GridSearchCV(sgdc_pipe, param_grid=sgdc_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_sgdc.fit(X_train, y_train)\n\ngrid_search_sgdc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_sgdc.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ac_sgdc_cv = grid_search_sgdc.best_estimator_.score(X_test,y_test)\nprint('SGD Classifier Accuracy CV:', ac_sgdc_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, grid_search_sgdc.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - SGDClassifier + Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4 DecisonTreeClassifier"},{"metadata":{},"cell_type":"markdown","source":"Initialisieren der Pipeline und erster Test des DecisionTree Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndtc_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('dtc', DecisionTreeClassifier(random_state=random_state))\n])\n\ndtc_pipe.set_params(\n    kbest__k=5\n)\n\ndtc_pipe.fit(X_train, y_train)\n\nac_dtc = dtc_pipe.score(X_test, y_test)\nprint('DecisionTree Classifier Accuracy:', ac_dtc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameter Tuning um eine höhere Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Maximale Tiefe des Baumes\n    - Maximale Anzahl an Blättern (des Baumes)\n- Datenspezifisch\n    - Anzahl der (besten) Features"},{"metadata":{"trusted":false},"cell_type":"code","source":"dtc_params = {\n        'dtc__max_depth': [2, 3, 5, 10, None],\n        'dtc__max_leaf_nodes': [3, 5, 8, 10, 15, 20, None],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_dtc = GridSearchCV(dtc_pipe, param_grid=dtc_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_dtc.fit(X_train, y_train)\n\ngrid_search_dtc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_dtc.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ac_dtc_cv = grid_search_dtc.best_estimator_.score(X_test, y_test)\nprint('DecisionTree Classifier Accuracy CV:', ac_dtc_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, grid_search_dtc.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - DecisionTreeClassifier + Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.5 KNN"},{"metadata":{},"cell_type":"markdown","source":"Initialisieren der Pipeline und erster Test des K-Nearest-Neighbor Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('knn', KNeighborsClassifier())\n])\n\nknn_pipe.set_params(\n    kbest__k=5,\n    knn__n_jobs=-1\n)\n\nknn_pipe.fit(X_train,y_train)\n\nac_knn = knn_pipe.score(X_test, y_test)\nprint('KNN Classifier Accuracy:', ac_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameter Tuning um eine höhere Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Anzahl der einbezogenen Nachbarn\n    - Verwendeter Algorithmus\n    - Blattgrösse\n- Datenspezifisch\n    - Anzahl der (besten) Features"},{"metadata":{"trusted":false},"cell_type":"code","source":"knn_params = {\n        'knn__n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n        'knn__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n        'knn__leaf_size': [20, 30, 40],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_knn = GridSearchCV(knn_pipe, param_grid=knn_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_knn.fit(X_train, y_train)\n\ngrid_search_knn.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_knn.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ac_knn_cv = grid_search_knn.best_estimator_.score(X_test,y_test)\nprint('KNN Classifier Accuracy CV:', ac_knn_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, grid_search_knn.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - KNN + Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6 RandomForestClassifier"},{"metadata":{},"cell_type":"markdown","source":"Initialisieren der Pipeline und erster Test des RandomForest Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('rfc', RandomForestClassifier())\n])\n\nrfc_pipe.set_params(\n    rfc__random_state=random_state,\n    kbest__k=5\n)\n\nrfc_pipe.fit(X_train, y_train)\n\nac_rfc = rfc_pipe.score(X_test, y_test)\nprint('RandomForest Classifier Accuracy:', ac_rfc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameter Tuning um eine höhere Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Minimale Anzahl an Sampels, bevor ein Ast aufgespaltet werden darf\n    - Maximale Tiefe des Baumes\n    - Anzahl der zu trainierenden Estimators\n    - Einsatz von Bootstrap-Samples\n    - Minimale Samples pro Blatt\n- Datenspezifisch\n    - Anzahl der (besten) Features"},{"metadata":{"trusted":false},"cell_type":"code","source":"rfc_params = {\n        'rfc__min_samples_split': [2, 5, 10, 15, 20],\n        'rfc__max_depth': [5, 10, 15, 20, 25, None],\n        'rfc__n_estimators': [100, 250, 500, 750, 1000],\n        'rfc__bootstrap': [True, False],\n        'rfc__min_samples_leaf': [1, 2, 5, 6, 10],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }\n\nparams_comb_all = int(5 * 6 * 5 * 2 * 5  * 6)\nparam_comb = int(params_comb_all / 100)\n\nprint('GridSearchCV parameter combinations: ' + str(params_comb_all) + '\\n' + 'RandomizedSearchCV parameter combinations: ' + str(param_comb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rnd_search_rfc = RandomizedSearchCV(rfc_pipe, param_distributions=rfc_params, n_iter=param_comb, scoring='roc_auc', n_jobs=-1, random_state=random_state )\nrnd_search_rfc.fit(X_train, y_train)\n\nrnd_search_rfc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rnd_search_rfc.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ac_rfc_cv = rnd_search_rfc.best_estimator_.score(X_test,y_test)\nprint('RandomForest Classifier Accuracy CV:', ac_rfc_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, rnd_search_rfc.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - RandomForestClassifier + Randomized Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fazit\n\nIm Zuge der Analyse von Patientendaten für die Vorhersage von Herzkrankheiten wurden verschiedene gängige ML Praktiken durchgeführt, wie beispielweise Data Preprocessing, Feature Engineering und Modeling. Um bestmögliche Vorhersagen zu erreichen, wurden verschiedene Classifier Modelle mit den Daten trainiert. Im Folgenden werden die Modelle in ihrer Performance gegenübergestellt und die Grösse des Datensatyes kritisch evaluiert. "},{"metadata":{},"cell_type":"markdown","source":"### Vergleich der Modelle\n\nDurch das Trainieren verschiedener Modelle und Optimierung der zugehörigen Stellschrauben (Hyperparameter), konnten mehrere Lösungsansätze evaluiert werden."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"ac_df = pd.DataFrame()\nac_df['Dummy'] = [ac_sgdcd, '-']\nac_df['Linear'] = [ac_sgdc, ac_sgdc_cv]\nac_df['Decision Tree'] = [ac_dtc, ac_dtc_cv]\nac_df['KNN'] = [ac_knn, ac_knn_cv]\nac_df['Random Forest'] = [ac_rfc, ac_rfc_cv]\nac_df\n\n#0 ist ohne CV, 1 ist mit CV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Der obige Vergleich anhand der Accuracy zeigt, dass das KNN Modell in Verbidnung mit Cross Validation die besten Ergebnisse erzielt. Unter Verwendung dieses Modells kann eine vorhandene Herzkrankheit mit einer Accuracy von 0.9 vorhergesagt werden. Dies bedeutet, dass auf Basis der eingegebenen Daten eine Herzkrankheit zu 90% korrekt diagnostiziert werden kann."},{"metadata":{},"cell_type":"markdown","source":"### Kritische Betrachtung\n\nSowohl die Auswahl der Parameter, als auch die obige Evaluation der Modelle wurde hauptsächlich anhand der Performance Metrik \"Accuracy\" durchgeführt. Die Akkuratheit stellt eine repräsentative Kennzahl dar, wenn eine möglichst gleihe Verteilung der Labels vorliegt. Auch wenn diese Bedingung durch den Datensatz gut erfüllt ist, sollten bei einer tiefergrehenden Beurteilung auch andere Metriken, wie beispielsweise die erwähnte \"True Negative Rate\" in Betracht gezogen werden.\n\n#### Kleiner Datensatz\n\nIm Vergleich zu gängigen Machine Learning Projekten handelt sich bei dem verwendeten Datensatz mit ca. 300 Einträgen um einen sehr kleinen Datensatz, dessen Nutzung einige Risiken birgt. Die Accuracy von über 90% sollte daher unter den Risiken einer geringeren Repräsentativität und der Beeinträchtigung der Fähigkeit der Generalisierung des Modells betrachtet werden. Der Datensatz repräsentiert nur einen kleinen Teil der realen Welt und spiegelt damit nur wenige Krankheitsmuster wider. Es besteht damit die Gefahr des Overifittings, das bedeutet, dass das Modell möglicherweise zu stark an die gegebenen Daten angepasst ist und bei neuen, ungesehenen Daten schlechtere Vorhersagen trifft."},{"metadata":{},"cell_type":"markdown","source":"## Zusatz Modeling"},{"metadata":{},"cell_type":"markdown","source":"Im Folgenden wird versucht mit Hilfe des XGBoost Algorithmus und eines Deep Neural Networks eine möglichst hohe Accuracy zu erziehlen. Es bleibt jedoch zu erwähnen, dass dies aufgrund des sehr kleinen Datensatzes (~ 300 Tupeln) mit Vorsicht zu behandeln ist und am besten als \"Mit Kanonen auf Spatzen schiessen\" beschrieben werden kann."},{"metadata":{},"cell_type":"markdown","source":"### Modeling - xgboost"},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgc_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('xgc', XGBClassifier())\n])\n\nxgc_pipe.set_params(\n    kbest__k=5\n)\n\nxgc_pipe.fit(X_train, y_train)\n\nxgc_pipe.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Da hier 480 Parameterkombinationen existieren, wird vorerst eine RandomizedSearchCV durchgefürht, welche die Kombinationen auf 96 reduziert und somit auch auf einem Mittelklasserechner in annehmbarer Zeit durchgeführt werden kann."},{"metadata":{},"cell_type":"markdown","source":"Parameter Tuning um eine höhere Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Learning Rate\n    - Maximale Tiefe der einzelnen Baume\n    - Anzahl der Estimator die trainiert bzw. für die Prediciton zu Rate gezogen werden\n- Datenspezifisch\n    - Anzahl der (besten) Features"},{"metadata":{"trusted":false},"cell_type":"code","source":"xgc_params = {\n        'xgc__learning_rate': [.0001, .001, .01, .1],\n        'xgc__max_depth': [5, 10, 15, 20, 25],\n        'xgc__n_estimators': [250, 500, 750, 1000],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }\n\nparams_comb_all = int(4 * 5 * 4 * 6)\nparam_comb = int(params_comb_all / 5)\n\nprint('GridSearchCV parameter combinations: ' + str(params_comb_all) + '\\n' + 'RandomizedSearchCV parameter combinations: ' + str(param_comb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rnd_search_xgc = RandomizedSearchCV(xgc_pipe, param_distributions=xgc_params, n_iter=param_comb, scoring='roc_auc', n_jobs=-1, random_state=random_state )\nrnd_search_xgc.fit(X_train, y_train)\n\nrnd_search_xgc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rnd_search_xgc.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rnd_search_xgc.best_estimator_.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = rnd_search_xgc.best_estimator_.predict(X_test)\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Um das Model noch weiter zu verbessern wird die in diesem Falle etwas aufwendigere GridSearchCV durchgeführt, welche alle 480 Parameterkombinationen abdeckt."},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_xgc = GridSearchCV(xgc_pipe, param_grid=xgc_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_xgc.fit(X_train, y_train)\n\ngrid_search_xgc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_xgc.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_xgc.best_estimator_.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling - Neural Network with Keras\n\nBase Setup:\n\nhttps://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n\nNumber of Neurons in Hidden Layer:\n\nhttps://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw"},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n#### Model Aufbau:\n- Input Layer mit 13 Inputs \n    - alle verfügbaren Features werden verwendet\n- Hidden Layer mit 10 Neuronen\n    - relu als Activation Function\n- Output Layer mit 1 Ouput\n    - Binary Classification, sigmoid als Activation Function -> Value entweder 0 oder 1\n    \n#### Model Parameter:\n- Loss Function\n    - Binary Crossentropy\n- Optimizer\n    - Adam\n- Zu optimierende Metrik\n    - Accuracy\n- Dense Layer\n    - Neuron eines Layers erhält Input von allen Neuronen des vorangeheneden Layers\n- Sequential\n    - Feed Forward\n    \n#### Zusatz:\nAuch hier wird wieder eine Pipeline verwendet um das Scaling direkt in den Prozess zu integrieren. Durch den Keras Wrapper, welcher von Sklearn bereitgestellt wird, lässt sich der KerasClassifier wie ein Sklearn nativer Classifier verwenden (Stellt z.B. Methoden wie fit() und score() bereit.\n\nZudem wird Cross Validation eingesetzt, wobei der Datensatz in k = 10 Folds aufgeteilt und anschliessend kombiniert wird. Auf ein Test- bzw. Validationset wird hier verzichtet, da ein DNN einen grösseren Datensatz benötigt und durch die Cross Validation hier aussreichend Schutz gegen Overfitting existiert. Tradeoff hier zwischen Overfitting und Datensatzgrösse!"},{"metadata":{"trusted":false},"cell_type":"code","source":"def keras_model():\n    model = Sequential()\n    model.add(Dense(22, input_dim=5, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"kfold = KFold(n_splits=10, shuffle=True, random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"estimators = []\nestimators.append(('scaler', StandardScaler()))\nestimators.append(('keras_clf', KerasClassifier(build_fn=keras_model, epochs=200, batch_size=5, verbose=0)))\n\npipeline = Pipeline(estimators)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy mit Cross Validation (gemittelt):"},{"metadata":{"trusted":false},"cell_type":"code","source":"results = cross_val_score(pipeline, X[['cp', 'thalach', 'exang', 'oldpeak', 'ca']], y, cv=kfold)\nprint(\"Accuracy der verschiedenen Folds: \", results)\nprint(\"Accuracy: mean %.2f%% (std %.2f%%)\" % (results.mean()*100, results.std()*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Im Verlgeich die Accuracy ohne Cross Validation (ein einzelner Split):"},{"metadata":{"trusted":false},"cell_type":"code","source":"pipeline.fit(X_train[['cp', 'thalach', 'exang', 'oldpeak', 'ca']], y_train)\n\ny_pred = pipeline.predict(X_test[['cp', 'thalach', 'exang', 'oldpeak', 'ca']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"13 features = all\n5 features = cp thalach exang oldpeak ca\n\n#### Neural Network Configurations\nI played around with the number of neurons in the hidden layer, but finally sticked to a formula that worked quite well.\n\nInput, Hidden, Output, Accuracy\n13 - 10 - 1 \t80.75\n\n5 - 10 - 1 \t\t83.06\n\n5 - 4 - 1 \t\t81.43\n\n5 - 15 - 1\t\t83.42\n\n5 - 22 - 1 \t\t83.75\n\n5 - 30 - 1      81.75 \n\n\n5 - 22 - 5 - 1\t\t82.40\n\n5 - 15 - 5 -  1\t\t81.09\n\n\t"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}