{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bushe Customer behaviour analysis - Classifiers"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"\n<h4>Цель этого исследования - понять поведение клиентов, которые останутся верными  Bushe.\nРешение задачи будет осуществляться путем построения классификатора.\nВ этом Kernel мы будем использовать различные модели классификации,<br> чтобы увидеть, насколько они точны при определении того, <br>будет ли посетитель с определенным набором параметров посещать Bushe снова.</center>\n<br><h3>Алгоритм выполнения процедур построения классификатора <br>(*кликнув на выделенный элемент, можно перейти сразу к нужному блоку  в структуре кернел)</h3>\n\n* [Обзор датафрейма](#aaa)<br>\n* [Преобразование категориальных признаков в числовые значения](#qqq)\n<br>В начале будет проведено преобразование категориальных признаков в числовые значения.Что приведет к увеличению числа независимых предикторов - их станет 63. Далее будет произведена стандаритизация и нормирование.\n\nЧтобы выбрать предикторы, которые сильнее объясняли бы поведение зависсимой переменной Y (в нашем случае это вреятность возврата гостя в BUshe -'Comeback') мы предлагаем три варианта:\n\n1. [Выполнение процедуры Оценки Коэффициента Корреляции Пирсона и нахождение уровня значимости P-value.](#eee)\n\n2. [GridSearchCV –  инструмент для автоматического подбирания параметров для моделей машинного обучениялучшие оценки с оптимальной комбинацией гиперпараметров.](#yyy)Определяет какие параметры лучше всего работают со случайным поиском, и формируем на их основе сетку, чтобы увидеть, сможем ли мы найти лучшую комбинацию.\n\n3. PCA - это метод преобразования исходного набора данных, представленного векторными выборками, в новый набор векторных образцов (или главных компонент) с производными размерами.Позволяет легко уменьшить размерность структуры данных в нескольких главных компонентах без эффекта на данные.(* PCA в этом исследовании пока не рассмотрено)\n\n\n\n**[Выявление наиболее значимых Предикторов, проявляющих  сильное влияние на показатель \"Comeback\" - возвращения гостя в Bushe](#prj)** \n    \n    \n[+**Классификация**](#rrr)\n\nВ этом разделе мы обучим четыре типа классификаторов и решим, какой классификатор будет более эффективным при обнаружении поведения посетителей. Прежде всего нам нужно разделить наши данные на наборы для обучения и тестирования\n\n* K Nearest Neighbor(KNN)\n* Decision Tree\n* Support Vector Machine\n* Logistic Regression\n<br><br>\n**[Кривые обучения -learning Curves](#iii) Позволяют определить наличие переобучения модели, и наглядно демонстрируют точность. [Было выявлено, Классификатор Логистической регрессии, а также SVM показывают лучший результат как в обучающих наборах, так и в Cross-validation проверке](#ooo)\n\n*[ROC Кривая ошибок](#hhh)\n\n*[Построение Классификатора на основе Логистической Регресии](#kkk)\n\n*[Confusion Matrix](#cmm)\n* [Проверка работоспособности классификатора](#nnn)\n\n* [Оценка Точности и Меры сходства**](#msx)\n\n\n     \n     "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imported Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections\n\n# Other Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw = pd.read_csv('../input/busheclassique/Busheclassic.csv')\ndf_raw\ndff = pd.read_csv('../input/starbucks-customer-retention-malaysia-survey/Starbucks satisfactory survey.csv')\ndf_raw['membership']=dff['9. Do you have Starbucks membership card?']\ndf_raw['Comeback']=dff['20. Will you continue buying at Starbucks?']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = df_raw.rename(columns={\"1. Your Gender\": 'Gender',\n                                \"2. Your Age\": \"ageGroup\",\n                                \"3. Are you currently....?\":\"status\",\n                                \"4. What is your annual income?\":\"annualIncome\",\n                                \"5. How often do you visit Bushe?\":\"visitFrequency\",\n                                \"6. How do you usually enjoy Bushe?\":\"Method\",\n                                \"7. How much time do you normally  spend during your visit?\":\"timeCost\",\n                                \"8. The nearest Bushe's outlet to you is...?\":\"location\",\n                                \"10. What do you most frequently purchase at Bushe?\":\"mostPurchase\",\n                                \"11. On average, how much would you spend at Bushe per visit?\":\"moneySpend\",\n                                \"12. How would you rate the quality of Bushe compared to other brands (Coffee Bean, Old Town White Coffee..) to be:\":\"ComparingRate\",\n                                \"13. How would you rate the price range at Bushe?\":\"PriceRate\",\n                                \"14. How important are sales and promotions in your purchase decision?\":\"s&pCareness\",\n                                \"15. How would you rate the ambiance at Bushe? (lighting, music, etc...)\":\"AmbientRate\",\n                                \"16. You rate the WiFi quality at Bushe as..\":\"WifiRate\",\n                                \"17. How would you rate the service at Bushe? (Promptness, friendliness, etc..)\":\"ServiceRate\",\n                                '19. How do you come to hear of promotions at Bushe? Check all that apply.':'Promo Source',\n                                \"18. How likely you will choose Bushe for doing business meetings or hangout with friends?\":\"MhRating\",\n                                \"20. bakery\":\"bakery\",\n                                'membership':'membership',\n                                'Comeback': 'Comeback'\n                        \n                                 }, inplace=False)\ndf_new.drop('21. Will you continue buying at Bushe?',\naxis='columns', inplace=True)\ndf_new.drop('9. Do you have Bushe membership card?',\naxis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"aaa\"></a>\n# Так выглядит наш анализируемый датасет\n122 позиций по 22 столбцам. Зависсимой переменной будет приходиться последний столбец ['Comeback']"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df_new\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"qqq\"></a>\n# Преобразование категориальных признаков в числовые значения\nВ нашем датасете полно колонок с категорийными признаками где присутствует и текст и числовые комбинации.\nПреобразование категориальных признаков в числовые значения. Нам необходимо все признаки перевести в числовые значения.\n<br><br>Взглянем на распределение Лояльных признаков по половому признаку"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"#0101DF\", \"#DF0101\"]\n\nsns.countplot('Comeback', data=df, palette=colors)\nplt.title('Class Distributions \\n (0:Loyal|| 1: Lost)', fontsize=14)\n\ndf.groupby(['Gender'])['Comeback'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"76% опрошенных мужчин пожелали бы вернуться, против 77% женщин. Что практически одинаково <br>\nПреобразуем мужской пол в 0, а женский в 1:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Gender'].replace(to_replace=['Male','Female'], value=[0,1],inplace=True)\ndf['membership'].replace(to_replace=['Yes','No'], value=[1,0],inplace=True)\ndf['Comeback'].replace(to_replace=['Yes','No'], value=[1,0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf['Method'].replace(to_replace=['never  ','Never buy'], value=['Never','Never'],inplace=True)\ndf['Method'].replace(to_replace=['I dont like coffee','Never buy'], value=['Never','Never'],inplace=True)\ndf['Method'].replace(to_replace=['I dont like coffee','never'], value=['Never','Never'],inplace=True)\ndf['Method'].replace(to_replace=['Never ','never'], value=['Never','Never'],inplace=True)\ndf['Method'].replace(to_replace=['Never '], value=['Never'],inplace=True)\ndf['Method'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling and Distributing\nСтандартизация данных дает нулевое среднее значение и единичную дисперсию\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Feature = df[['membership','PriceRate','s&pCareness','AmbientRate','WifiRate','ServiceRate','MhRating']]\nFeature = pd.concat([Feature,pd.get_dummies(df['mostPurchase'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['ageGroup'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['status'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['annualIncome'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['visitFrequency'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['timeCost'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['location'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['Method'])], axis=1)\nFeature = pd.concat([Feature,pd.get_dummies(df['bakery'])], axis=1)\nFeature.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fh=Feature\n#Fh['Comeback']=df['Comeback']\n#Fh.to_csv('train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nFtt=Feature\n#Ftt=Ftt.loc[:, Ftt.columns != 'Comeback']\nscaler = StandardScaler()\ndf_sc= pd.DataFrame(scaler.fit_transform(Ftt.values), columns=Ftt.columns)\ndf_sc['Comeback']=df['Comeback']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FAQ\nСтолбец **Comeback** представляет  собой ответы респондентов на вопрос :'20. Will you continue buying at Bushe?', который имеет бинарный параметр Yes или NO. **Comeback** В нашем классификаторе будет играть роль зависсимой переменной Y, поведение которой и будет моделироваться "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sc = df_sc.sample(frac=1)\n\n# amount of fraud classes 492 rows.\ncomeback_df = df_sc.loc[df_sc['Comeback'] == 1]\nnon_comeback_df = df_sc.loc[df_sc['Comeback'] == 0][:122]\n\nnormal_distributed_df = pd.concat([comeback_df, non_comeback_df])\n\n# Shuffle dataframe rows\nnew_df = normal_distributed_df.sample(frac=1, random_state=22)\n\nnew_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"eee\"></a>\n# **Строим Матрицу корреляций**\n****"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr=new_df.corr()\ndf1 = pd.DataFrame(df_corr.Comeback)\ndf1.sort_values(by=['Comeback'], inplace=True)\nprint(df1.to_markdown())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n# Entire DataFrame\ncorr = df.corr()\nsns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\nax1.set_title('Imbalanced Correlation Matrix', fontsize=14)\n\n\nsub_sample_corr = new_df.corr()\nsns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\nax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"prj\"></a>\n<h2>Предикторы, которые показали положительную значимость с оценивающим\n    показателем \"Comeback\" по Пирсону и P-value</h2> \n                                                 \n         \n\nИмеют статистическую значимость по показателю теста  P-value <0,005\n* | Параметр                                      |  Pearson    |   P-value\n* | Monthly                                       |  0.236433   |  0.00874456029197296\n* | AmbientRate                                   |  0.318145   |  0.0003554891498241922\n* | membership                                    |  0.341955   |  0.00011572126682106971\n* | MhRating                                      |  0.369625   |  2.789627898236357e^-5\n* | PriceRate                                     |  0.452593   |  1.6600899812402898e^-7\n\nгде\n\n\n* MhRating - это  Насколько вероятно, что вы выберете Буше для деловых встреч или встреч с друзьями?\n* AmbientRate -Как бы вы оценили атмосферу в Буше? (освещение, музыка и т. д.)\n* PriceRate  - Как бы вы оценили диапазон цен в Буше?\n* membership - наличие накопительных карт\n* Monthly  - посещает раз в месяц"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"rrr\"></a>\n# Classification\nВ этом разделе мы обучим четыре типа классификаторов и решим, какой классификатор будет более эффективным при обнаружении поведения посетителей. Прежде всего нам нужно разделить наши данные на наборы для обучения и тестирования \n\n* K Nearest Neighbor(KNN)\n* Decision Tree\n* Support Vector Machine\n* Logistic Regression\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = new_df.drop('Comeback', axis=1)\ny = new_df['Comeback']\n\nfrom sklearn.model_selection import train_test_split\n\n\n#Установка фиксированного значения random_state используется для инициализации внутреннего генератора \n#случайных чисел гарантирует, \n#что при каждом запуске кода будет генерироваться одна и та же последовательность случайных чисел\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn the values into an array for feeding the classification algorithms.\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Объявим  классификаторы - Алгортимы которые будем использовать"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"KNearest\": KNeighborsClassifier(),\n    \"Support Vector Classifier\": SVC(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n\nfor key, classifier in classifiers.items():\n    classifier.fit(X_train, y_train)\n    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Педварительная оценка подогнанных моделей, распределилась таким образом, что  KNeighborsClassifier Has a training score около 80 % accuracy score. Не будем на этом останавливаться. Подберем лучшие параметры для обучения и оценим модели на наличие переобучения"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"yyy\"></a>\n# GridSearchCV \nэто очень мощный инструмент для автоматического подбирания параметров для моделей машинного обучения. GridSearchCV находит наилучшие параметры, путем обычного перебора: он создает модель для каждой возможной комбинации параметров.\n**используется для определения параметров, которые дают лучший прогноз для классификаторов**.\nПолученные параметры являются лучшими для нашей модели.\n**grid.best_params_ подберем по всем классификаторам, что в итоге, должно увеличить качество и точность классификатора.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n\n# Logistic Regression \nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\n\ngrid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\ngrid_log_reg.fit(X_train, y_train)\n# We automatically get the logistic regression with the best parameters.\nlog_reg = grid_log_reg.best_estimator_\n\nknears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\ngrid_knears.fit(X_train, y_train)\n# KNears best estimator\nknears_neighbors = grid_knears.best_estimator_\n\n# Support Vector Classifier\nsvc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\ngrid_svc = GridSearchCV(SVC(), svc_params)\ngrid_svc.fit(X_train, y_train)\n\n# SVC best estimator\nsvc = grid_svc.best_estimator_\n\n# DecisionTree Classifier\ntree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))}\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\ngrid_tree.fit(X_train, y_train)\n\n# tree best estimator\ntree_clf = grid_tree.best_estimator_\n# Overfitting Case\n\nlog_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\nprint('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n\n\nknears_score = cross_val_score(knears_neighbors, X_train, y_train, cv=5)\nprint('Knears Neighbors Cross Validation Score', round(knears_score.mean() * 100, 2).astype(str) + '%')\n\nsvc_score = cross_val_score(svc, X_train, y_train, cv=5)\nprint('Support Vector Classifier Cross Validation Score', round(svc_score.mean() * 100, 2).astype(str) + '%')\n\ntree_score = cross_val_score(tree_clf, X_train, y_train, cv=5)\nprint('DecisionTree Classifier Cross Validation Score', round(tree_score.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>**Покзатели точности для Логистической регресси и SVM улучшились**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"iii\"></a>\n# Кривые обучения:\n\nПостроение кривых обучения, нужно для наглядного обхяснения, того, а какой алгоритм справился с классификацией точнее, и без переобучений\nЧем шире разрыв между оценкой обученной моедли и оценкой  проверки cross validation, тем больше вероятность того, что ваша модель переобучена (высокая дисперсия).\n\nЕсли результат низкий как в обучающем наборе, так и в наборе cross validation, это свидетельствует о том, что наша модель не соответствует требованиям (высокая систематическая ошибка)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's Plot LogisticRegression Learning Curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import learning_curve\n\ndef plot_learning_curve(estimator1, estimator2, estimator3, estimator4, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(20,14), sharey=True)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    # First Estimator\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"#ff9124\")\n    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n             label=\"Training score\")\n    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n             label=\"Cross-validation score\")\n    ax1.set_title(\"Logistic Regression Learning Curve\", fontsize=14)\n    ax1.set_xlabel('Training size (m)')\n    ax1.set_ylabel('Score')\n    ax1.grid(True)\n    ax1.legend(loc=\"best\")\n    \n    # Second Estimator \n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator2, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax2.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"#ff9124\")\n    ax2.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    ax2.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n             label=\"Training score\")\n    ax2.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n             label=\"Cross-validation score\")\n    ax2.set_title(\"Knears Neighbors Learning Curve\", fontsize=14)\n    ax2.set_xlabel('Training size (m)')\n    ax2.set_ylabel('Score')\n    ax2.grid(True)\n    ax2.legend(loc=\"best\")\n    \n    # Third Estimator\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator3, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax3.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"#ff9124\")\n    ax3.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    ax3.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n             label=\"Training score\")\n    ax3.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n             label=\"Cross-validation score\")\n    ax3.set_title(\"Support Vector Classifier \\n Learning Curve\", fontsize=14)\n    ax3.set_xlabel('Training size (m)')\n    ax3.set_ylabel('Score')\n    ax3.grid(True)\n    ax3.legend(loc=\"best\")\n    \n    # Fourth Estimator\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator4, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax4.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"#ff9124\")\n    ax4.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    ax4.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n             label=\"Training score\")\n    ax4.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n             label=\"Cross-validation score\")\n    ax4.set_title(\"Decision Tree Classifier \\n Learning Curve\", fontsize=14)\n    ax4.set_xlabel('Training size (m)')\n    ax4.set_ylabel('Score')\n    ax4.grid(True)\n    ax4.legend(loc=\"best\")\n    return plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ooo\"></a>\n# Классификатор Логистической регрессии, а также SVM показывают лучший результат как в обучающих наборах, так и в Cross-validation проверке."},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\nplot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, X_train, y_train, (0.67, 1.01), cv=cv, n_jobs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.model_selection import cross_val_predict\n# Create a DataFrame with all the scores and the classifiers names.\n\nlog_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5,\n                             method=\"decision_function\")\n\nknears_pred = cross_val_predict(knears_neighbors, X_train, y_train, cv=5)\n\nsvc_pred = cross_val_predict(svc, X_train, y_train, cv=5,\n                             method=\"decision_function\")\n\ntree_pred = cross_val_predict(tree_clf, X_train, y_train, cv=5)\n\nfrom sklearn.metrics import roc_auc_score\n\nprint('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))\nprint('KNears Neighbors: ', roc_auc_score(y_train, knears_pred))\nprint('Support Vector Classifier: ', roc_auc_score(y_train, svc_pred))\nprint('Decision Tree Classifier: ', roc_auc_score(y_train, tree_pred))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"hhh\"></a>\n#  ROC Кривая ошибок \nграфичекая характеристика качества бинарного классификатора. наглядно представляет, каким будет качество классификации при различных варьированиях порога"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)\nknear_fpr, knear_tpr, knear_threshold = roc_curve(y_train, knears_pred)\nsvc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)\ntree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, tree_pred)\n\n\ndef graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr):\n    plt.figure(figsize=(16,8))\n    plt.title('ROC Curve \\n Top 4 Classifiers', fontsize=18)\n    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))\n    plt.plot(knear_fpr, knear_tpr, label='KNears Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_train, knears_pred)))\n    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_train, svc_pred)))\n    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_train, tree_pred)))\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.01, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n                )\n    plt.legend()\n    \ngraph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Площадь под ROC-кривой AUC (Area Under Curve) является агрегированной характеристикой качества классификации, не зависящей от соотношения цен ошибок. Чем больше значение AUC, тем «лучше» модель классификации.</h3>\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"kkk\"></a>\n# Logistic Regression¶\n\n<h2>В ходе проверки моделей, было выявлено о превосходстве линейного байесовского классификатора (логистической регрессии)</h2>\nДальнейшую процедуру классификации, и последующие верификации модели будут проводиться исключительно на этом классификаторе  LR"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\n%matplotlib inline \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Выбираем лучшие параметры из GridSearchCV grid_log_reg.best_estimator_ который мы получили ранее\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngrid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\ngrid_log_reg.fit(X_train, y_train)\n# We automatically get the logistic regression with the best parameters.\nlog_reg = grid_log_reg.best_estimator_\nLR=log_reg\nLR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = LR.predict(X_test)\nyhat\nyhat_prob = LR.predict_proba(X_test)\nyhat_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import jaccard_score\njaccard_score(y_test, yhat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n#print(confusion_matrix(y_test, yhat))\nprint(confusion_matrix(y_test, yhat, labels=[1,0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"cmm\"></a>\n# Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Я приду в Буше еще','Это вряд ли'],normalize= False,  title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (classification_report(y_test, yhat))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"nnn\"></a>\n# ПРОВЕРКА РАБОТОСПОСОБНОСТИ КЛАССИФИКАТОРА"},{"metadata":{},"cell_type":"markdown","source":"Загрузим новую таблицу из 9 строк и попробуем оценить, как склассифицирует респондентов обученная модель "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_checker = pd.read_csv('../input/lr-check/cheker_LR.csv')\n\ndf_checkerLR=df_checker.loc[:, df_checker.columns != 'Comeback']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_checkerLR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#для проверки\nt_y = df_checker['Comeback'].values\nt_y[0:9]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**МОДЕЛИРОВАНИЕ**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nt_yhatLR = LR.predict(df_checkerLR)\nt_yhatLR_prob = LR.predict_proba(df_checkerLR)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Результат классифицирования**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(t_yhatLR) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Результат в виде оценки Вероятностей.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_prob=pd.DataFrame(t_yhatLR_prob)\nLR_prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"msx\"></a>\n# **Оценка Точности и Меры сходства**\n* Коэффициент Жаккара - отношение количества элементов пересечения множеств количеству элементов их объединения\n* Метрика F1 раскрывает одновременно и точность и полноту "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ОЦЕНКА КАЧЕСТВА ПОСТРОЕННОГО КЛАССИФИКАТОРА\" )\nLGR_Jaccard = jaccard_score(t_y, t_yhatLR)\nprint(\"Logistic Regression - Jaccard accuracy = \" , LGR_Jaccard)\n\n# f1_score\nLGR_f1_score = f1_score(t_y, t_yhatLR , average='weighted') \nprint(\"Logistic Regression - F1 score accuracy = \" , LGR_f1_score)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"finito\"></a>\n# Спасибо за внимание !"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}