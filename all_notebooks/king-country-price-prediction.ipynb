{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nfrom tqdm import tqdm_notebook as tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nplt.style.use('fivethirtyeight')\nnp.random.seed(3325)\nsns.set_style('ticks', {'axes.edgecolor':'0.2', 'axes.spines.right': False, 'axes.spines.top': False})\nsns.set_context('notebook', rc={'axes.linewidth': 1.4, \"lines.linewidth\": 2.5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.ticker import FuncFormatter\ndef kformat(x, p):\n  if x < 1_000:\n    return f'{x:.0f}'\n  elif x < 1_000_000:\n    return f'{x / 1e3:.0f}k'\n#   elif x < 10_000_000:\n#     return f'{x / 1e6:.1f}M'\n  else:\n    return f'{x / 1e6:.0f}M'\nkticker = FuncFormatter(kformat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\ndata['date'] = pd.to_datetime(data.date, format='%Y%m%dT000000')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop('date', axis=1).hist(figsize=(21, 16), bins=20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15']\nfor col in cols:\n    data[col + '_log'] = np.log1p(data[col])\n\ndata[[c + '_log' for c in cols]].hist(figsize=(21, 10), bins=20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Impute yr_renovated zero's with the year that it was built in\ndata.loc[data.yr_renovated == 0, 'yr_renovated'] = data.loc[data.yr_renovated == 0, 'yr_built']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a basement flag variable and impute missing sqft_basement zero's with the average\ndata['has_basement'] = data.sqft_basement_log > 0\n\ndata.loc[data.sqft_basement_log == 0, 'sqft_basement_log'] = data[data.sqft_basement_log > 0].sqft_basement_log.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create time features\ndata['month'] = data.date.dt.month\ndata['year'] = data.date.dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Track which variables we want to continue observing\nX = [c for c in data.columns if c not in cols and c not in ['price', 'date', 'price_log', 'id']]\ny = 'price_log'\nprint(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize Relationships with Price"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 5, figsize=(21, 16))\naxes_iter = iter(np.ravel(axes))\n\nfor i, (col, ax) in enumerate(zip(X, axes_iter)):\n    sns.scatterplot(x=col, y='price_log', data=data, ax=ax)\n    ax.yaxis.grid(True, alpha=0.3)\n    ax.yaxis.set_major_formatter(kticker)\n    if i % 5 != 0:\n        ax.set_ylabel('')\nfor ax in axes_iter:\n    ax.remove()\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\nfrom folium.plugins import HeatMap\n\nm = folium.Map(location=[data.lat.mean(), data.long.mean()], zoom_start=10)\n\nheatmap_data = data.groupby(['lat', 'long']).price.mean().reset_index().values\nHeatMap(\n    heatmap_data, \n    name='Price', radius=25, max_zoom=18, min_opacity=0.3\n).add_to(folium.FeatureGroup(name='Heat Map').add_to(m))\n\nm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef haversine_distance(lat1, lon1, lat2, lon2):\n    \"\"\"Haversine formula for calculating distance between two points\"\"\"\n    R = 6371.0088  #Radius of the earth\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1,lon1,lat2,lon2])\n    \n    a = np.sin((lat2 - lat1) / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin((lon2 - lon1) / 2) ** 2\n    c = 2 * np.arctan2(a**0.5, (1-a)**0.5)\n    d = R * c\n    return round(d, 4)\n\nlandmarks = pd.read_csv('/kaggle/input/seattle-landmarks-map/Seattle_Landmarks_Map.csv')\n#Convert \"(47.60870201200004, -122.30853251899998)\" into lat and long features\nlandmarks = landmarks.join(landmarks.Shape.str.extract('\\((?P<lat>.+), (?P<long>.+)\\)').astype(float))\n#Convert \"101 Pike Place Street\" to \"landmark_101_Pike_Place_Street\"\nlandmarks['FNAME'] = 'landmark_' + landmarks.NAME.str.replace('[^0-9a-zA-Z]+', '_')\n\n#For each landmark, add distance between house and landmark\nlandmark_df = pd.DataFrame()\nfor i, row in landmarks.groupby('FNAME')[['lat', 'long']].mean().iterrows():\n    landmark_df[row.name] = haversine_distance(data.lat, data.long, row.lat, row.long)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n#400 landmarks is a little too much, so let's convert them into components\npca_dim = 3\n\nlandmark_cols = ['Landmark_' + str(i + 1) for i in range(pca_dim)]\nX.extend(landmark_cols)\ndata = data.join(pd.DataFrame(PCA(pca_dim).fit_transform(landmark_df.values), columns=landmark_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = folium.Map(location=[data.lat.mean(), data.long.mean()], zoom_start=10)\n\nfor i, row in landmarks.groupby('NAME')[['lat', 'long']].mean().iterrows():\n    folium.Marker(\n        [row.lat, row.long], popup=row.index\n    ).add_to(m)\n\nm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering #2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Leaving zipcode as an integer will make the model think that zipcode order matters\n# data['zipcode'] = data.zipcode.astype(str)\n# data = pd.get_dummies(data)\n# X.extend([c for c in data.columns if c.startswith('zipcode_')])\n# X.remove('zipcode')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection & Linear Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_bound = '2015-03-01'\ntrain, test = data[data.date < train_bound], data[data.date >= train_bound]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\nknn = KNeighborsRegressor(n_neighbors=10, n_jobs=-1)\nknn.fit(train[X].values, train[y].values)\n\nneighbor_cols = ['knn_' + str(c + 1) for c in range(10)]\ndata = data.join(pd.DataFrame(knn.kneighbors(data[X].values)[0], columns=neighbor_cols))\nX.extend(neighbor_cols)\ntrain, test = data[data.date < train_bound], data[data.date >= train_bound]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom boruta import BorutaPy\n\nrf_model = RandomForestRegressor(n_estimators=300, criterion='mse', max_depth=5, n_jobs=-1)\n\nselection = BorutaPy(rf_model, n_estimators='auto', verbose=2, random_state=1, max_iter=len(X))\nselection.fit(train[X].values, train[y].values);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 12))\nax.barh(X, selection.ranking_)\nax.set_title(\"Feature Ranking (lower is better)\")\nax.set_xlabel(\"Rank\")\nax.axvspan(2.5, max(selection.ranking_), alpha=0.3, color='red')\nax.axvspan(1.5, 2.5, alpha=0.3, color='yellow')\nax.axvspan(0, 1.5, alpha=0.3, color='green')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop features which ranked poorly in feature selection\nX = np.array(X)[selection.ranking_ <= 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.linear_model import RidgeCV, LassoCV\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\n\nmodels = {\n    'RandomForest': rf_model,\n    'Ridge': RidgeCV(alphas=(0.01, 0.05, 0.1, 0.3, 1.0, 5.0, 10.0), normalize=True, cv=5),\n    'Lasso': LassoCV(eps=0.001, n_alphas=1000, tol=1e-2, alphas=None, normalize=True, cv=5, n_jobs=-1, positive=True),\n    'ExtraTrees': ExtraTreesRegressor(n_estimators=600, criterion='mse', max_depth=10, n_jobs=-1),\n    'LightGBM': lgb.LGBMRegressor(n_estimators=1000, num_leaves=31, silent=False, max_depth=-1, learning_rate=0.1, n_jobs=-1, importance_type='gain'),\n    'XGBoost': xgb.XGBRegressor(n_estimators=2000, verbosity=1, eta=0.1, max_depth=8, n_jobs=-1)\n}\n\npreds = {}\nfor name, model in models.items():\n    #Scale features, and include polynomial and interaction terms for regression\n    if name in ['Ridge', 'Lasso']:\n        pf = PolynomialFeatures()\n        X_train = pf.fit_transform(train[X].values)\n        X_test = pf.transform(test[X].values)\n    else:\n        X_train = train[X].values\n        X_test = test[X].values\n        \n    #Scale features for regression\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    #Fit and store predictions\n    model.fit(X_train, train[y].values)\n    preds[name] = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\ndef mape(y_true, y_pred):\n    return np.mean(np.abs(y_true - y_pred) / max(1e-6, np.mean(y_true)))\n\nscores_df = pd.DataFrame()\nfor name, pred in preds.items():\n    scores = {\n        'MSE': metrics.mean_squared_error(test.price.values, np.expm1(pred)),\n        'MAE': metrics.mean_absolute_error(test.price.values, np.expm1(pred)),\n        'MSE (log)': metrics.mean_squared_error(test.price_log.values, pred),\n        'MAPE': mape(test.price.values, np.expm1(pred)),\n        'R^2': metrics.r2_score(test.price.values, np.expm1(pred)),\n    }\n    scores_df = scores_df.append(pd.DataFrame(scores, index=[name]))\nscores_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16, 6))\norder = np.argsort(models['LightGBM'].feature_importances_)\nsns.barplot(x=models['LightGBM'].feature_importances_[order][::-1], y=X[order][::-1])\nax.set_title('Feature Importance')\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}