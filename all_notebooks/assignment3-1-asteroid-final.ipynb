{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.decomposition import PCA,  FastICA\nfrom sklearn.random_projection import GaussianRandomProjection,SparseRandomProjection\nfrom sklearn.feature_selection import RFE\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import accuracy_score\n\nfrom collections import Counter, defaultdict\n\nfrom datetime import datetime\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', 'Solver terminated early.*')\nwarnings.filterwarnings(\"ignore\")\n\nprint('imports completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(10)\nprint('random seed set to 10 completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute accuracy of cluster\ndef my_accuracy_cluster(labelIn,labelOut):\n    \n    # create an empty array with shape to match the incoming label\n    myprediction = np.empty_like(labelIn)\n    \n    # Get the key of the dictionary returned most common label \n    for l in set(labelOut):\n        mask = labelOut == l\n        target = Counter(labelIn[mask]).most_common(1)[0][0]\n        myprediction[mask] = target  \n    return accuracy_score(labelIn,myprediction)\n\n# Plot the curve # clusters vs score\ndef plot_score_curve(datadictionary,mytitle) :\n    fig=plt.figure()\n    \n    num_clusters = list(datadictionary.keys())\n    score_clusters = list(datadictionary.values())\n    \n    ax = fig.add_subplot(111,xlabel='# Clusters',ylabel='Score',title=mytitle)\n    ax.plot(num_clusters, score_clusters, 'o-', color=\"b\",\n             label=\"Num of Clusters\")\n    ax.set_xticks(num_clusters)\n    ax.legend(loc=\"best\")\n    fig.savefig(mytitle+\".png\")\n    plt.close(fig)\n    return plt\n\n# Plot the curve # clusters vs time\ndef plot_time_curve(datadictionary,mytitle) :\n    fig=plt.figure()\n    \n    num_clusters = list(datadictionary.keys())\n    time_clusters = list(datadictionary.values())\n    \n    ax = fig.add_subplot(111,xlabel='# Clusters',ylabel='Time',title=mytitle)\n    ax.plot(num_clusters, time_clusters, 'o-', color=\"b\",\n             label=\"Num of Clusters\")\n    ax.set_xticks(num_clusters)\n    ax.legend(loc=\"best\")\n    fig.savefig(mytitle+\".png\")\n    plt.close(fig)\n    return plt\n\ndef plot_score_feature_transform(datadictionary,mytitle) :\n    fig=plt.figure()\n    \n    PCA_components = list(datadictionary.keys())\n    ax = fig.add_subplot(111,xlabel='# Clusters',ylabel='Score',title=mytitle)\n    \n    colors = ['b','g','r','c','m','y','k','w']\n       \n    for PCA_comp in range(len(PCA_components)):\n        num_clusters = list(datadictionary[PCA_components[PCA_comp]].keys())\n        score_clusters = list(datadictionary[PCA_components[PCA_comp]].values())\n        ax.plot(num_clusters, score_clusters, 'o-', color=colors[PCA_comp],\n                 label=str(PCA_components[PCA_comp]))\n        \n    ax.set_xticks(num_clusters)\n    ax.legend(loc=\"best\")\n    fig.savefig(mytitle+\".png\") \n    plt.close(fig)\n    return plt\n    \ndef plot_time_feature_transform(datadictionary,mytitle) :\n    fig=plt.figure()\n    \n    PCA_components = list(datadictionary.keys())\n    ax = fig.add_subplot(111,xlabel='# Clusters',ylabel='Time',title=mytitle)\n    \n    colors = ['b','g','r','c','m','y','k','w']\n       \n    for PCA_comp in range(len(PCA_components)):\n        num_clusters = list(datadictionary[PCA_components[PCA_comp]].keys())\n        time_clusters = list(datadictionary[PCA_components[PCA_comp]].values())\n        ax.plot(num_clusters, time_clusters, 'o-', color=colors[PCA_comp],\n                 label=str(PCA_components[PCA_comp]))\n        \n    ax.set_xticks(num_clusters)\n    ax.legend(loc=\"best\")\n    fig.savefig(mytitle+\".png\")\n    plt.close(fig)\n    return plt\n\ndef plot_dataIn2(myTitle,df_orig_labels,df_data,figName,component):\n    fig = plt.figure(figsize = (8,8))\n    ax = fig.add_subplot(1,1,1) \n    ax.set_xlabel(component +' 1', fontsize = 15)\n    ax.set_ylabel(component +' 2', fontsize = 15)\n    ax.set_title(myTitle, fontsize = 20)\n    targets = list(set(df_orig_labels))\n    colors = ['r', 'g', 'b','c','m','y','k']\n    for target, color in zip(targets,colors):\n        indicesToKeep = df_orig_labels == target\n        ax.scatter(df_data.loc[indicesToKeep,0]\n                   , df_data.loc[indicesToKeep,1]\n                   , c = color\n                   , s = 50)\n    ax.legend(targets)\n    ax.grid()\n    fig.savefig(figName +\".png\") \n\nprint('definitions completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load asteroid data\ndf_orig = pd.read_csv(\"../input/asteroid-dataset/dataset.csv\")\n\ndf_count = df_orig['class'].value_counts().sort_index()\n\ndf_count.index\nprint('dataset load completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the data\ndf_count = df_orig[['class','diameter']].groupby(['class'],as_index=False)\ndf_count = df_count.count()\ndf_count.rename(columns={'diameter':'count'},inplace=True)\n\nfig = plt.figure(figsize =(15,10))\nax = fig.add_subplot(111,xlabel='class',ylabel='count',title='Asteroid Data')\nax.bar(df_count['class'],df_count['count'])\nax.set_xticks(df_count['class'])\nfor item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n             ax.get_xticklabels() + ax.get_yticklabels()):\n    item.set_fontsize(20)\nfig.savefig('asteroid_grouped_data.png')\nplt.close(fig) \n\nprint(\"There are \" + str(df_orig.shape[0]) + \" rows of data\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = None\ndf_x = None\ndf_y = None\nto_encode = []\n\ndf_data = pd.read_csv('../input/asteroid-dataset/dataset.csv')\n    \ninputs = df_data\n\ninputs.pha.replace(('Y', 'N'), (1, 0), inplace = True)\ninputs['pha'] = inputs['pha'].fillna(0)\ninputs['pha'] = inputs.pha.astype(int)\n\ninputs.neo.replace(('Y', 'N'), (1, 0), inplace = True)\ninputs['neo'] = inputs['neo'].fillna(0)\ninputs['neo'] = inputs.neo.astype(int)\n\ninputs = inputs.drop(['id', 'spkid', 'full_name', 'name', 'prefix', 'orbit_id', 'pdes', 'equinox', 'diameter', \n                      'albedo', 'diameter_sigma'], axis='columns')\ninputs.dropna(inplace=True)\ntarget = inputs['class']\n\ndf = inputs\ninputs1 = inputs.drop(['class'], axis='columns')\ndf_x = inputs1.columns\ndf_y = 'class'\nto_encode = inputs.columns\n        \nle = LabelEncoder\nencoderDict = defaultdict(le)\nfor column in to_encode:\n    df[column] = df[column].dropna()\n    df = df[df[column].notnull()]\n    df[column] = encoderDict[column].fit_transform(df[column])\n\ndf = df.head(5000)\n\ndf = df.dropna()  \n\ndf = df.sample(frac=1).reset_index(drop=True)\nprint('Dataset size: ' + str(df.size))\nprint('Features: ' + str(df_x))\nprint('Target Decision: ' + df_y)\n\n# Split the data into attributes and labels\n\ndf_orig_attributes = df.loc[:, df_x]\ndf_orig_labels = df.loc[:, df_y]\nprint(df_orig_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize the attributes\nscaler=StandardScaler().fit(df_orig_attributes)\n\ndf_orig_attributes[df_orig_attributes.columns.difference(['class'])] = scaler.fit_transform(df_orig_attributes[df_orig_attributes.columns.difference(['class'])])\n\n# Clusters\nmycluster_df = [2,3,4,5,6,7,10,15,20,25,30,40,50]\nprint ('standardize and clusters completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################################################################\n# k - means cluster and EM (using gaussian mixture) with no feature selection #\n###############################################################################\n\nmy_accuracy_kmeans = dict()\nmy_time_kmeans = dict()\n\nmy_accuracy_em = dict()\nmy_time_em = dict()\n\nfor myk in mycluster_df:\n    \n    # kMeans Clustering\n    startTime = datetime.now()        \n    myk_mean_prediction = KMeans(n_clusters=myk,random_state=0).fit_predict(df_orig_attributes)        \n    myk_mean_accuracy_res = my_accuracy_cluster(df_orig_labels,myk_mean_prediction)        \n    endTime = datetime.now()\n    \n    # append accuracy\n    my_accuracy_kmeans[myk] = myk_mean_accuracy_res        \n    # append my_time array\n    my_time_kmeans[myk] = (endTime-startTime).total_seconds()\n    \n    # EM with GaussianMixture Clustering\n    startTime = datetime.now()        \n    my_em_prediction = GaussianMixture(n_components=myk,random_state=0).fit(df_orig_attributes).predict(df_orig_attributes)        \n    my_accuracy_em_res = my_accuracy_cluster(df_orig_labels,my_em_prediction)        \n    endTime = datetime.now()\n    \n    # append accuracy\n    my_accuracy_em[myk] = my_accuracy_em_res        \n    # append my_time array\n    my_time_em[myk] = (endTime-startTime).total_seconds()\n    \nplot_score_curve(my_accuracy_kmeans,\"k-means Clusters vs Score\")\nplot_time_curve(my_time_kmeans,\"k-means Clusters vs Time\")\n\nplot_score_curve(my_accuracy_em,\"EM Clusters vs Score\")\nplot_time_curve(my_time_em,\"EM Clusters vs Time\")    \nprint('k - means Cluster and EM (using gaussian mixture) with no feature selection completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################################################\n# k - means cluster and EM (using gaussian mixture) after PCA #\n###############################################################\n\n# for the dataset PCA, we can only have 33 Principal components \n# since the number of features for the dataset is 33\nPCA_component_df = [1,10,20,25,30,33]\n\nmy_accuracy_kmeans_PCA = defaultdict(dict)\nmy_time_kmeans_PCA = defaultdict(dict)\nmy_accuracy_em_PCA = defaultdict(dict)\nmy_time_em_PCA = defaultdict(dict)\n\ndf_data_PCA = PCA(random_state=0)\ndf_data_eigen  = df_data_PCA.fit(df_orig_attributes)\ndf_data_eigenvalues = df_data_eigen.explained_variance_\n\nfor PCA_comp in PCA_component_df :\n    \n    df_data_PCA = PCA(n_components=PCA_comp,random_state=0) \n    df_data_PCA_data = df_data_PCA.fit_transform(df_orig_attributes)\n    df_data_PCA_df = pd.DataFrame(data = df_data_PCA_data)\n    \n    df_data_PCA_df_nn = pd.concat([df_data_PCA_df,df_orig_labels],axis=1)\n            \n    for cluster in mycluster_df:\n        \n        # kMeans clustering\n        startTime = datetime.now()\n        myk_mean_PCA_prediction = KMeans(n_clusters=cluster,random_state=0).fit_predict(df_data_PCA_df)        \n        myk_mean_accuracy_res = my_accuracy_cluster(df_orig_labels,myk_mean_PCA_prediction)    \n        endTime = datetime.now()\n        # append accuracy\n        my_accuracy_kmeans_PCA[PCA_comp][cluster] = myk_mean_accuracy_res        \n        # append my_time array\n        my_time_kmeans_PCA[PCA_comp][cluster] = (endTime-startTime).total_seconds()\n        \n        # EM using GaussianMixture clustering    \n        startTime = datetime.now()        \n        my_em_prediction = GaussianMixture(n_components=cluster).fit(df_data_PCA_df).predict(df_data_PCA_df)        \n        my_accuracy_em_res = my_accuracy_cluster(df_orig_labels,my_em_prediction)        \n        endTime = datetime.now()\n        \n        # append accuracy\n        my_accuracy_em_PCA[PCA_comp][cluster] = my_accuracy_em_res        \n        # append my_time array\n        my_time_em_PCA[PCA_comp][cluster] = (endTime-startTime).total_seconds()\n\nplot_time_feature_transform(my_time_kmeans_PCA,\"k-means PCA Clusters vs Time\")\nplot_score_feature_transform(my_accuracy_kmeans_PCA,\"k-means PCA Clusters vs Score\")\nplot_time_feature_transform(my_time_em_PCA,\"EM PCA Clusters vs Time\")\nplot_score_feature_transform(my_accuracy_em_PCA,\"EM PCA Clusters vs Score\")\n\n# Data in 2 component PCA\ndf_data_PCA = PCA(n_components=2,random_state=0) \ndf_data_PCA_data = df_data_PCA.fit_transform(df_orig_attributes)\ndf_data_PCA_df = pd.DataFrame(data = df_data_PCA_data)\n\nplot_dataIn2(\"2 component PCA\", df_orig_labels, df_data_PCA_df, \"data_in_2_PCA\", \"Principal Component\")\n\nprint('k - means cluster and EM (using gaussian mixture) after PCA completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data_eigenvalues","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################################################\n# k - means cluster and EM (using gaussian mixture) after ICA #\n###############################################################\n\n# for the dataset ICA, we can only have 33 Principal components \n# since the number of features for the dataset is 33\nICA_component_df = [1,10,20,25,30,33]\n\nmy_accuracy_kmeans_ICA = defaultdict(dict)\nmy_time_kmeans_ICA = defaultdict(dict)\nmy_accuracy_em_ICA = defaultdict(dict)\nmy_time_em_ICA = defaultdict(dict)\n\ndf_data_ICA = FastICA(random_state=0) \ndf_data_ICA_data = df_data_ICA.fit_transform(df_orig_attributes)\ndf_data_ICA_df = pd.DataFrame(data = df_data_ICA_data)\ndf_data_ICA_kurtosis = df_data_ICA_df.kurt()\n\nfor ICA_comp in ICA_component_df :\n    \n    df_data_ICA = FastICA(n_components=ICA_comp,random_state=0) \n    df_data_ICA_data = df_data_ICA.fit_transform(df_orig_attributes)\n    df_data_ICA_df = pd.DataFrame(data = df_data_ICA_data)\n    \n    for cluster in mycluster_df:\n        \n        # kMeans Clustering\n        startTime = datetime.now()\n        myk_mean_ICA_prediction = KMeans(n_clusters=cluster,random_state=0).fit_predict(df_data_ICA_df)        \n        myk_mean_accuracy_res = my_accuracy_cluster(df_orig_labels,myk_mean_ICA_prediction)    \n        endTime = datetime.now()\n        # append accuracy\n        my_accuracy_kmeans_ICA[ICA_comp][cluster] = myk_mean_accuracy_res        \n        # append my_time array\n        my_time_kmeans_ICA[ICA_comp][cluster] = (endTime-startTime).total_seconds()\n        \n        # EM using GaussianMixture Clustering     \n        startTime = datetime.now()        \n        my_em_prediction = GaussianMixture(n_components=cluster).fit(df_data_ICA_df).predict(df_data_ICA_df)        \n        my_accuracy_em_res = my_accuracy_cluster(df_orig_labels,my_em_prediction)        \n        endTime = datetime.now()\n        \n        # append accuracy\n        my_accuracy_em_ICA[ICA_comp][cluster] = my_accuracy_em_res        \n        # append my_time array\n        my_time_em_ICA[ICA_comp][cluster] = (endTime-startTime).total_seconds()\n\nplot_time_feature_transform(my_time_kmeans_ICA,\"k-means ICA Clusters vs Time\")\nplot_score_feature_transform(my_accuracy_kmeans_ICA,\"k-means ICA Clusters vs Score\")\nplot_time_feature_transform(my_time_em_ICA,\"EM ICA Clusters vs Time\")\nplot_score_feature_transform(my_accuracy_em_ICA,\"EM ICA Clusters vs Score\")\n\n# to illustrate the data in 2 component ICA\ndf_data_ICA = FastICA(n_components=2) \ndf_data_ICA_data = df_data_ICA.fit_transform(df_orig_attributes)\ndf_data_ICA_df = pd.DataFrame(data = df_data_ICA_data)\n\nplot_dataIn2('2 component ICA',df_orig_labels, df_data_ICA_df,\"data_in_2_ICA\", \"Component\")\n  \nprint('k - means cluster and EM (using gaussian mixture) after ICA completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data_ICA_kurtosis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##############################################################\n# k - means cluster and EM (using gaussian mixture) after RP #\n##############################################################\n# for the dataset RP, we can only have 33 Principal components \n# since the number of features for the dataset is 33\nRP_component_df = [1,10,20,25,30,33]\n\nmy_accuracy_kmeans_RP = defaultdict(dict)\nmy_time_kmeans_RP = defaultdict(dict)\nmy_accuracy_em_RP = defaultdict(dict)\nmy_time_em_RP = defaultdict(dict)\n\ndf_data_RP = GaussianRandomProjection(random_state=0,n_components=33) \ndf_data_RP_data = df_data_RP.fit_transform(df_orig_attributes)\ndf_data_RP_df = pd.DataFrame(data = df_data_RP_data)\ndf_data_RP_kurtosis = df_data_RP_df.kurt()\n\nfor RP_comp in RP_component_df :\n    \n    df_data_RP = GaussianRandomProjection(n_components=RP_comp,random_state=0) \n    df_data_RP_data = df_data_RP.fit_transform(df_orig_attributes)\n    df_data_RP_df = pd.DataFrame(data = df_data_RP_data)\n    \n    for cluster in mycluster_df:\n        \n        # kMeans clustering\n        startTime = datetime.now()\n        myk_mean_RP_prediction = KMeans(n_clusters=cluster,random_state=0).fit_predict(df_data_RP_df)        \n        myk_mean_accuracy_res = my_accuracy_cluster(df_orig_labels,myk_mean_RP_prediction)    \n        endTime = datetime.now()\n        # append accuracy\n        my_accuracy_kmeans_RP[RP_comp][cluster] = myk_mean_accuracy_res        \n        # append my_time array\n        my_time_kmeans_RP[RP_comp][cluster] = (endTime-startTime).total_seconds()\n        \n        # EM using GaussianMixture clustering\n        startTime = datetime.now()        \n        my_em_prediction = GaussianMixture(n_components=cluster).fit(df_data_RP_df).predict(df_data_RP_df)        \n        my_accuracy_em_res = my_accuracy_cluster(df_orig_labels,my_em_prediction)        \n        endTime = datetime.now()\n        \n        # append accuracy\n        my_accuracy_em_RP[RP_comp][cluster] = my_accuracy_em_res        \n        # append my_time array\n        my_time_em_RP[RP_comp][cluster] = (endTime-startTime).total_seconds()\n\nplot_time_feature_transform(my_time_kmeans_RP,\"k-means RP Clusters vs Time\")\nplot_score_feature_transform(my_accuracy_kmeans_RP,\"k-means RP Clusters vs Score\")\nplot_time_feature_transform(my_time_em_RP,\"EM RP Clusters vs Time\")\nplot_score_feature_transform(my_accuracy_em_RP,\"EM RP Clusters vs Score\")\n\n# to illustrate the data in 2 component RP\ndf_data_RP = GaussianRandomProjection(n_components=2) \ndf_data_RP_data = df_data_RP.fit_transform(df_orig_attributes)\ndf_data_RP_df = pd.DataFrame(data = df_data_RP_data)\n\nplot_dataIn2('2 component RP',df_orig_labels, df_data_RP_df,\"data_in_2_RP\", \"Component\")\n\nprint('k - means cluster and EM (using gaussian mixture) after RP completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################################################\n# k - means cluster and EM (using gaussian mixture) after RFE #\n###############################################################\n# for the dataset RFE, we can only have 33 Principal components \n# since the number of features for the dataset is 33\nRFE_component_df = [1,10,20,25,30,33]\n\nestimator = SVR(kernel=\"linear\")\n\nmy_accuracy_kmeans_RFE = defaultdict(dict)\nmy_time_kmeans_RFE = defaultdict(dict)\nmy_accuracy_em_RFE = defaultdict(dict)\nmy_time_em_RFE = defaultdict(dict)\n\nfor RFE_comp in RFE_component_df :\n    \n    df_data_RFE = RFE(estimator,n_features_to_select=RFE_comp) \n    df_data_RFE_data = df_data_RFE.fit_transform(df_orig_attributes,df_orig_labels)\n    df_data_RFE_df = pd.DataFrame(data = df_data_RFE_data)\n                    \n    for cluster in mycluster_df:\n        \n        # kMeans clustering\n        startTime = datetime.now()\n        myk_mean_RFE_prediction = KMeans(n_clusters=cluster,random_state=0).fit_predict(df_data_RFE_df)        \n        myk_mean_accuracy_res = my_accuracy_cluster(df_orig_labels,myk_mean_RFE_prediction)    \n        endTime = datetime.now()\n        # append accuracy\n        my_accuracy_kmeans_RFE[RFE_comp][cluster] = myk_mean_accuracy_res        \n        # append my_time array\n        my_time_kmeans_RFE[RFE_comp][cluster] = (endTime-startTime).total_seconds()\n        \n        # EM using GaussianMixture clustering    \n        startTime = datetime.now()        \n        my_em_prediction = GaussianMixture(n_components=cluster).fit(df_data_RFE_df).predict(df_data_RFE_df)        \n        my_accuracy_em_res = my_accuracy_cluster(df_orig_labels,my_em_prediction)        \n        endTime = datetime.now()\n        \n        # append accuracy\n        my_accuracy_em_RFE[RFE_comp][cluster] = my_accuracy_em_res        \n        # append my_time array\n        my_time_em_RFE[RFE_comp][cluster] = (endTime-startTime).total_seconds()\n\nplot_time_feature_transform(my_time_kmeans_RFE,\"k-means RFE Clusters vs Time\")\nplot_score_feature_transform(my_accuracy_kmeans_RFE,\"k-means RFE Clusters vs Score\")\nplot_time_feature_transform(my_time_em_RFE,\"EM RFE Clusters vs Iime\")\nplot_score_feature_transform(my_accuracy_em_RFE,\"EM RFE Clusters vs Score\")\n\n# Data in 2 component RFE\ndf_data_RFE = RFE(estimator,n_features_to_select=2) \ndf_data_RFE_data = df_data_RFE.fit_transform(df_orig_attributes,df_orig_labels)\ndf_data_RFE_df = pd.DataFrame(data = df_data_RFE_data)\n\nplot_dataIn2('2 component RFE',df_orig_labels, df_data_RFE_df,\"data_in_2_RFE\", \"Component\")\n  \nprint('k - means cluster and EM (using gaussian mixture) after RFE completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport glob\n\nfor image_path in glob.glob(\"/kaggle/working/*.png\"):\n    img = mpimg.imread(image_path)\n    plt.ion()\n    plt.figure()\n    plt.axis('off') \n    plt.imshow(img)\n    plt.show()\n    plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}