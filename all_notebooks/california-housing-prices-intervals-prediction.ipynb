{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div>\n    <img src=\"https://storage.googleapis.com/kaggle-datasets-images/5227/7876/3d18388d350d2791f4121a232acce097/dataset-cover.jpg\" />\n</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nfrom numpy import asarray\nimport pandas as pd\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"dataset\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/california-housing-prices/housing.csv'\ndf = pd.read_csv(path)\ndf = shuffle(df)\nvalues = df.values\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace ocean proximity with values\nocean_proximity = {v:k for k,v in enumerate(df['ocean_proximity'].unique())}\ndf.replace(ocean_proximity, inplace=True)\n\n# replace NaN with mean\ndf = df.apply(lambda x: x.fillna(x.mean()))\n\nfeatures = df.drop(columns=['median_house_value'])\nlabels = df['median_house_value']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_mean = labels.mean()\nhouses_std = labels.std()\n\n# normalize prices\nlabels = (labels - houses_mean) / houses_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the features\nscaler = MinMaxScaler()\nscaler.fit(features)\nfeatures = scaler.transform(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.67)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"model\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Model\n        <a class=\"anchor-link\" href=\"#model\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(X_train, y_train):\n    # define neural network model\n    features = X_train.shape[1]\n    model = Sequential()\n    model.add(Dense(20, kernel_initializer='he_normal', activation='relu', input_dim=features))\n    model.add(Dense(5, kernel_initializer='he_normal', activation='relu'))\n    model.add(Dense(1))\n    # compile the model and specify loss and optimizer\n    opt = Adam(learning_rate=0.01, beta_1=0.85, beta_2=0.999)\n    model.compile(optimizer=opt, loss='mse')\n    # fit the model on the training dataset\n    model.fit(X_train, y_train, verbose=0, epochs=300, batch_size=16)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"ensemble\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Ensemble\n        <a class=\"anchor-link\" href=\"#ensemble\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n    ensemble = list()\n    for i in range(n_members):\n        # define and fit the model on the training set\n        model = fit_model(X_train, y_train)\n        # evaluate model on the test set\n        yhat = model.predict(X_test, verbose=0)\n        mae = mean_absolute_error(y_test, yhat)\n        print('>%d, MAE: %.3f' % (i+1, mae))\n        # store the model\n        ensemble.append(model)\n    return ensemble","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"predict\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Interval Predictions\n        <a class=\"anchor-link\" href=\"#predict\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_with_pi(ensemble, X):\n    # make predictions\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\n    yhat = asarray(yhat)\n    # calculate 95% gaussian prediction interval\n    interval = 1.96 * yhat.std()\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n    return lower, yhat.mean(), upper","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"training\" style=\"color:#2a200b; background:#fcc688;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit ensemble\nn_members = 10\nensemble = fit_ensemble(n_members, X_train, X_test, y_train, y_test)\n# make predictions with prediction interval\nnewX = asarray([X_test[0, :]])\nlower, mean, upper = predict_with_pi(ensemble, newX)\nprint('Point prediction: %.3f' % mean)\nprint('95%% prediction interval: [%.3f, %.3f]' % (lower, upper))\nprint('Actual result:', y_test.iloc[0])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}