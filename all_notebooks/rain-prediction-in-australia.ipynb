{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Predicting rain in Australia</h1>"},{"metadata":{},"cell_type":"markdown","source":"<h2>List of contents</h2>\n1. EDA\n2. Data cleaning & feature extraction\n3. Comparison of preprocessed data against original data\n4. Model training\n5. Model validation \n"},{"metadata":{},"cell_type":"markdown","source":"<h2>1. EDA - Exploratory Data Analysis </h2>\n<h3> Preliminary data insight </h3>\nImport libraries and load dataset:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndf = pd.read_csv('../input/weatheraus/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the head of dataset\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check shape of dataset:\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the datatypes\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that we have 24 variables including one target variable (RainTomorrow) and one variable that we should skip according to data description on kaggle (RAIN_MM).\nBesides this we have 5 categorical variables: Location, WindGustDir, WindDir9am, WindDir3pm and RainToday (can also be considered as binary)\nWe also have Date - how to treat this variable we decide after analysis. Surely we cannot just use it as it is because it will cause overfit to the rain history.\n"},{"metadata":{},"cell_type":"markdown","source":"<h3> Target value insigths </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First - we check the distribution of the target value\ncounts = df['RainTomorrow'].value_counts()\nprint(counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We check the exact ratio of 'Yes' samples\nprint(np.sum(counts))\nprint(counts[1]/np.sum(counts))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have ~22% samples with the 'Yes' output. So we have imbalanced dataset. Now let's check the distribution of the other values against the target value.\nFirst numeric data."},{"metadata":{},"cell_type":"markdown","source":"<h3> Exploration of numeric variables </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ntmp = df.select_dtypes(include=numerics)\ntmp[\"RainTomorrow\"]= df[\"RainTomorrow\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distributions of first 4 numerical values against target:\nsns.pairplot(tmp, vars = tmp.columns[:4],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Min and Max temperature  have slight differences in distributions among our target class. This two variables are also correlated.\nRainfall and Evaporation are skewed and probably have some outliers (long 'tail' of the distribution plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distributions of first numerical values against target (cols 4-8):\nsns.pairplot(tmp, vars = tmp.columns[4:8],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the figure above we see that 'Sunshine' may be good feature (peaks of 'No' and 'Yes' distributions are clearly separable)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distributions of first numerical values against target (cols 8-12):\nsns.pairplot(tmp, vars = tmp.columns[8:12],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both hummudities show differences in distributions for our target value, also pressures have their distribution peaks slightly different. This probably makes them good feature to distinguish our target value. Pressures are also correlated with each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distributions of first numerical values against target (cols 4-8):\nsns.pairplot(tmp, vars = tmp.columns[12:16],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that cloud features have good separation of distributions. Temperatures are correlated."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Just for curiosity we check the RISK_MM - but according to the data description we should drop this data to not oto overfit\n# Below note from dataset description:\n# \"Note: You should exclude the variable Risk-MM when training a binary classification model. \n# Not excluding it will leak the answers to your model and reduce its predictability.\"\"\nsns.pairplot(tmp, vars = tmp.columns[16:17],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Exploration of non-numerical variables </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We should not use strict date in our model - instead we will engineer a feature by extracting the month.\n# We assume that it makes sense that in some months rain is more likely to happen\ndf['Month'] = pd.to_datetime(df['Date']).dt.month\n\n# We check the target distribution across our new feature\nsns.countplot(x = 'Month', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see thaht in monts 6 and 7 it rained more oftern than in other months."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now check  the location\n# Set the plot size to make it more readable\nplt.figure(figsize=(20, 10))\nsns.countplot(y = 'Location', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that certain location (like Portland) have higher chance for the rain than the others. Seems like we can leave location as a feature.\nWe just check its cardinality and values counts:"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['Location'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Location'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 49 unique values and the distribution is quite even. We can take this column as categorical.\nWe could also engineer additional features - like geographic coordinates for that locations - but we will be basing on the original dataset content"},{"metadata":{},"cell_type":"markdown","source":"We check the rest of categorical variables: WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y = 'WindGustDir', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some directions like NW seem to be correlated stronger with the 'Yes' outpiut of our target value"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y = 'WindDir9am', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similar here - for example 'N'"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y = 'WindDir3pm', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we laso have to differences"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y = 'RainToday', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we see that for most days if it was raining today - we also had rain tomorrow."},{"metadata":{},"cell_type":"markdown","source":"<h3> Data cleaning </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We drop the Date to not overfit the model to particular date and place:\ndf.drop(['Date'], axis=1, inplace = True)\n\n# And Risk-MM according to the data descripton:\n# \"Note: You should exclude the variable Risk-MM when training a binary classification model. \n# Not excluding it will leak the answers to your model and reduce its predictability.\"\"\ndf.drop(['RISK_MM'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check % of missing data in columns\ndf.isnull().sum()/df.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaporation, Sunshine Cloud 9 am and Cloud 3pm have a lot of missing data (above 30%)- we remove them:\ndf.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1, inplace = True)\ndf.isnull().sum()/df.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace Na in numerical columns with mean for columns with Na ratio higher than 3%:\ndf['WindGustSpeed'].fillna(np.mean(df['WindGustSpeed'].dropna().values), inplace = True)\ndf['Pressure9am'].fillna(np.mean(df['Pressure9am'].dropna().values), inplace = True)\ndf['Pressure3pm'].fillna(np.mean(df['Pressure3pm'].dropna().values), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace categorical values with the 'Unknown' value for columns with Na ratio higher than 3%:\ndf['WindGustDir']= df['WindGustDir'].fillna('Unknown')\ndf['WindDir9am']= df['WindDir9am'].fillna('Unknown')\ndf.isnull().sum()/df.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop rest of the Na values from dataset (we assume that we can delete data in columns where the Na ratio is < 3%):"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace = True)\ndf.isnull().sum()/df.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Check distributions of 'cleaned' data </h3>\n\nFirst target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First - we check the distribution of the target value\ncounts = df['RainTomorrow'].value_counts()\nprint(counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We check the exact ratio of 'Yes' samples\nprint(np.sum(counts))\nprint(counts[1]/np.sum(counts))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall ratio of target value after data cleaning is close the ratio before that process."},{"metadata":{},"cell_type":"markdown","source":"Now check numeric variables after data cleaning:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# build temporary dataset:\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ntmp2 = df.select_dtypes(include=numerics)\ntmp2[\"RainTomorrow\"]= df[\"RainTomorrow\"]\n# check columns:\ntmp2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distributions of first 3 numerical values against target (to comapre with the previous plots on original data - we take 3 colums\n# because we removed evaporation because a lot of Na:\nsns.pairplot(tmp2, vars = tmp2.columns[:4],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distributions are similar to the ones before data cleaning. We have to remember to transoform Rainfall due to outliers and skewed distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(tmp2, vars = tmp2.columns[4:8],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distributions are similar to the ones before data cleaning. We have to remember to transoform Humidities due to skewed distribution.\nWind speeds have outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(tmp2, vars = tmp2.columns[8:12],hue=\"RainTomorrow\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that distributions for Pressures have 'spikes' caused by our inputation of mean value.\nTo overcome this we should use more sofisticated metod of inputation. We leave it as it is and check how our model will perform.\n\nWe don't need to check the Month variable - it  was derived from date and we didn't remove Nan's from this column\n"},{"metadata":{},"cell_type":"markdown","source":"Now we check again categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checkt the types after data removal:\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.countplot(y = 'Location', hue =  'RainTomorrow', orient = 'v', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'WindGustDir', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'WindDir9am', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'WindDir3pm', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'RainToday', hue =  'RainTomorrow', orient = 'h', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In general distributions of variables is similar to the distribution before data cleaning\nNow we can do the encoding and transformations"},{"metadata":{},"cell_type":"markdown","source":"<h3> Encoding the categorical data </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace the string labels with 0 and 1 numbers:\ndf['RainToday'].replace({'No':0,'Yes':1},inplace = True)\ndf['RainTomorrow'].replace({'No':0,'Yes':1},inplace = True)\n\n# encode categorical values\ncategorical = ['WindGustDir','WindDir9am','WindDir3pm','Location']\ndf = pd.get_dummies(df,columns = categorical,drop_first=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have to deal with the skew distributions in datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes(include=numerics).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\nskew_var = ['Humidity3pm', 'Humidity9am', 'Rainfall', 'WindSpeed3pm', 'WindSpeed9am']\ntmp3 = df[skew_var]\n\nfor c in tmp3.columns:\n    r = stats.boxcox(df[c] + 1)\n    tmp3[c] = r[0]\n\nsns.pairplot(tmp3)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[skew_var] = tmp3\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Build the model </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.drop(labels = ['RainTomorrow'],axis = 1)\nx.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['RainTomorrow']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sc.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.4,random_state = 40)\nx_test,x_validation,y_test,y_validation = train_test_split(x_test,y_test,test_size = 0.5,random_state = 40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ANN - Artificial Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.add(Dense(units = 30,kernel_initializer='uniform',activation = 'relu',input_dim = 109))\nclassifier.add(Dense(units = 30,kernel_initializer='uniform',activation = 'relu'))\nclassifier.add(Dense(units = 30,kernel_initializer='uniform',activation = 'relu'))\nclassifier.add(Dense(units = 1,activation='sigmoid',kernel_initializer='uniform'))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(classifier, show_shapes=True, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train,y_train,epochs = 100,batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict_classes(x_test)\ny_train_pred = classifier.predict_classes(x_train)\ny_validation_pred = classifier.predict_classes(x_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint('Training Accuracy ---->',accuracy_score(y_train,y_train_pred))\nprint('Testing Accuracy  ---->',accuracy_score(y_test,y_pred))\nprint('Validation Accuracy  ---->',accuracy_score(y_validation,y_validation_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_train,y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_train,y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_validation,y_validation_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_validation,y_validation_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}