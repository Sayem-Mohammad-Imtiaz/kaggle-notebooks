{"cells":[{"metadata":{"_uuid":"48687ed97124814c0206bae31b9d975b9fbfdcdd"},"cell_type":"markdown","source":"# DCGAN with CelebA\n- Generative Adversarial Nets : https://arxiv.org/pdf/1406.2661.pdf"},{"metadata":{"_uuid":"6d166cbcdba9c22c4fefcca35ac97974e4475143"},"cell_type":"markdown","source":"## 1. Data"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-03T09:29:58.235472Z","start_time":"2018-04-03T09:22:25.522388Z"},"_uuid":"6c8ebb69f739967bef74a54fa950f9d56df48e1e"},"cell_type":"markdown","source":"```script\nchmod +x download.sh\n./download.sh\nunzip -q CelebA_128crop_FD.zip?dl=0 -d ./data/\n```"},{"metadata":{"_uuid":"2cfb27e74699e539b237df2f4018986223ed9259"},"cell_type":"markdown","source":"## 2. Import Libs"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:48.295105Z","start_time":"2018-04-04T06:02:47.939168Z"},"trusted":true,"_uuid":"168f7a50c59881d213fc8944aba4daf5a80e5709"},"cell_type":"code","source":"import torch, os\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.datasets as dset\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d97055aa17f160648e6840a20590fd2256249083"},"cell_type":"markdown","source":"## 3. Hyperparameters"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:48.953705Z","start_time":"2018-04-04T06:02:48.930677Z"},"trusted":true,"_uuid":"20e09172b51911239d77a70c43618033d1b52224"},"cell_type":"code","source":"lr = 0.0002\nmax_epoch = 8\nbatch_size = 32\nz_dim = 100\nimage_size = 64\ng_conv_dim = 64\nd_conv_dim = 64\nlog_step = 100\nsample_step = 500\nsample_num = 32\nIMAGE_PATH = '../input/celeba-dataset/img_align_celeba/'\nSAMPLE_PATH = '../'\n\nif not os.path.exists(SAMPLE_PATH):\n    os.makedirs(SAMPLE_PATH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e804f880d4ebb38d3738fed26aebce69eda657fd"},"cell_type":"markdown","source":"## 4. Load Data"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:50.200318Z","start_time":"2018-04-04T06:02:49.706612Z"},"trusted":true,"_uuid":"a37abdb26b2dee12502e9aaf0209cf82be09f6ba"},"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Scale(image_size),\n    # transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ndataset = ImageFolder(IMAGE_PATH, transform)\ndata_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c00320fab9d2b12cf53f5af3a9bdec0cb518175"},"cell_type":"markdown","source":"## 5. Model Define"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:52.496616Z","start_time":"2018-04-04T06:02:50.926448Z"},"trusted":true,"_uuid":"6da5809574999fcc35d78f455947c82dcc62a09c"},"cell_type":"code","source":"def conv(ch_in, ch_out, k_size, stride=2, pad=1, bn=True):\n    layers = []\n    layers.append(nn.Conv2d(ch_in, ch_out, k_size, stride, pad))\n    if bn:\n        layers.append(nn.BatchNorm2d(ch_out))\n    return nn.Sequential(*layers)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, image_size=128, conv_dim=64):\n        super(Discriminator, self).__init__()\n        self.conv1 = conv(3, conv_dim, 4, bn=False)\n        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n        self.conv4 = conv(conv_dim*4, conv_dim*8, 4)\n        self.fc = conv(conv_dim*8, 1, int(image_size/16), 1, 0, False)\n        \n    def forward(self, x):                                 # if image_size is 64, output shape is below\n        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 32, 32)     \n        out = F.leaky_relu(self.conv2(out), 0.05) # (?, 128, 16, 16)\n        out = F.leaky_relu(self.conv3(out), 0.05) # (?, 256, 8, 8)\n        out = F.leaky_relu(self.conv4(out), 0.05) # (?, 512, 4, 4)\n        out = F.sigmoid(self.fc(out)).squeeze()\n        return out\n    \nD = Discriminator(image_size)\nD.cuda()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:52.612709Z","start_time":"2018-04-04T06:02:52.544843Z"},"trusted":true,"_uuid":"00873b3bc2e0f3f4a0298a85240c9a8d9b01a9b1"},"cell_type":"code","source":"def deconv(ch_in, ch_out, k_size, stride=2, pad=1, bn=True):\n    layers = []\n    layers.append(nn.ConvTranspose2d(ch_in, ch_out, k_size, stride, pad))\n    if bn:\n        layers.append(nn.BatchNorm2d(ch_out))\n    return nn.Sequential(*layers)\n\nclass Generator(nn.Module):\n    def __init__(self, z_dim=256, image_size=128, conv_dim=64):\n        super(Generator, self).__init__()\n        self.fc = deconv(z_dim, conv_dim*8, int(image_size/16), 1, 0, bn=False)\n        self.deconv1 = deconv(conv_dim*8, conv_dim*4, 4)\n        self.deconv2 = deconv(conv_dim*4, conv_dim*2, 4)\n        self.deconv3 = deconv(conv_dim*2, conv_dim, 4)\n        self.deconv4 = deconv(conv_dim, 3, 4, bn=False)\n        \n    def forward(self, z):\n        z = z.view(z.size(0), z.size(1), 1, 1)\n        out = self.fc(z)\n        out = F.leaky_relu(self.deconv1(out), 0.05)\n        out = F.leaky_relu(self.deconv2(out), 0.05)\n        out = F.leaky_relu(self.deconv3(out), 0.05)\n        out = F.tanh(self.deconv4(out))\n        return out\n    \nG = Generator(z_dim, image_size, g_conv_dim)\nG.cuda()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db913af3d9882377d3cfe6193ca1f359b2385d90"},"cell_type":"markdown","source":"## 6. Loss func & Optimizer"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:53.887966Z","start_time":"2018-04-04T06:02:53.884538Z"},"trusted":true,"_uuid":"37bb5f8979e543a39b49c94b0448d82fa78067f5"},"cell_type":"code","source":"criterion = nn.BCELoss().cuda()\nd_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\ng_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a13f525bdf10695e4b3f2dbd112b7758b1aa35c"},"cell_type":"markdown","source":"## 7. etc"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:55.129681Z","start_time":"2018-04-04T06:02:54.621331Z"},"trusted":true,"_uuid":"75305e0d2ff6c78520b0ba2dbb6b79b8c7b630a1"},"cell_type":"code","source":"# denormalization : [-1,1] -> [0,1]\n# normalization : [0,1] -> [-1,1]\ndef denorm(x):\n    out = (x + 1) / 2\n    return out.clamp(0, 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f97e3111b7722388c46f412842b7e45e47a9ca9f"},"cell_type":"markdown","source":"## 8. Train"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:55.89152Z","start_time":"2018-04-04T06:02:55.876549Z"},"trusted":true,"_uuid":"8d534bc2d5f1aa883d79aa79cdd43d35a4a87012"},"cell_type":"code","source":"try:\n    G.load_state_dict(torch.load('generator.pkl'))\n    D.load_state_dict(torch.load('discriminator.pkl'))\n    print(\"\\n-------------model restored-------------\\n\")\nexcept:\n    print(\"\\n-------------model not restored-------------\\n\")\n    pass","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T08:06:08.655704Z","start_time":"2018-04-04T06:02:56.573771Z"},"trusted":true,"_uuid":"b02a071c606980687f9084586bd81c37904ed4be","scrolled":false},"cell_type":"code","source":"total_batch = len(data_loader.dataset)//batch_size\nfixed_z = Variable(torch.randn(sample_num, z_dim)).cuda()\nfor epoch in range(max_epoch):\n    for i, (images, labels) in enumerate(data_loader):\n        # Build mini-batch dataset\n        image = Variable(images).cuda()\n        # Create the labels which are later used as input for the BCE loss\n        real_labels = Variable(torch.ones(batch_size)).cuda()\n        fake_labels = Variable(torch.zeros(batch_size)).cuda()\n        \n        #============ train the discriminator ============\n        # Compute BCE_loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n        # Second term of the loss is always zero since real_labels = 1\n        outputs = D(image)\n        d_loss_real = criterion(outputs, real_labels) # BCE\n        real_score = outputs\n        \n        # compute BCE_loss using fake images\n        z = Variable(torch.randn(batch_size, z_dim)).cuda()\n        fake_images = G(z)\n        outputs = D(fake_images)\n        d_loss_fake = criterion(outputs, fake_labels) #BCE\n        fake_score = outputs\n        \n        # Backprob + Optimize\n        d_loss = d_loss_real + d_loss_fake\n        D.zero_grad()\n        d_loss.backward()\n        d_optimizer.step()\n        \n        #============ train the generator ============\n        # Compute loss with fake images\n        z = Variable(torch.randn(batch_size, z_dim)).cuda()\n        fake_images = G(z)\n        outputs = D(fake_images)\n        \n        # We train G to maximize log(D(G(z))) instead of minimizing log(1-D(G(z)))\n        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n        g_loss = criterion(outputs, real_labels) # BCE\n        \n        # Backprob + Optimize\n        D.zero_grad()\n        G.zero_grad()\n        g_loss.backward()\n        g_optimizer.step()\n        \n        if(i+1)%log_step == 0:\n            print(\"Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, D(x): %.2f, D(G(z)): %.2f\"%(\n            epoch, max_epoch, i+1, total_batch, d_loss.data[0], g_loss.data[0], real_score.data.mean(), fake_score.data.mean()))\n        \n        if(i+1)%sample_step == 0:\n            fake_images = G(fixed_z)\n            torchvision.utils.save_image(denorm(fake_images.data), os.path.join(SAMPLE_PATH, 'fake_samples-%d-%d.png')%(\n            epoch+1, i+1), nrow=8)\n            \ntorch.save(G.state_dict(), 'generator.pkl')\ntorch.save(D.state_dict(), 'discriminator.pkl')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3dfca500ed75902e90eaaaa679ea3df56d2c4e3e"},"cell_type":"markdown","source":"## 9. test"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T08:10:16.998066Z","start_time":"2018-04-04T08:10:15.959265Z"},"trusted":true,"_uuid":"84b305145253a35e9c0c93ceed14ddb6f5d49ea5"},"cell_type":"code","source":"fixed_z = Variable(torch.randn(sample_num, z_dim)).cuda()\nfake_images = G(fixed_z)\nplt.imshow(denorm(fake_images[0].cpu().permute(1, 2, 0).data).numpy())\nplt.show()\n\nplt.imshow(make_grid(denorm(fake_images).data.cpu()).permute(1, 2, 0).numpy())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"977c909a8cbe1c4e3ce5b4abb612237b008a27ec"},"cell_type":"markdown","source":"## 10. img2gif"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T08:35:59.216095Z","start_time":"2018-04-04T08:35:31.383768Z"},"trusted":true,"_uuid":"153c08e10fdb2b6fd10282fe9b9c26112766617f","scrolled":false},"cell_type":"code","source":"import imageio\n\nimages = []\nfor epoch in range(max_epoch):\n    for i in range(total_batch):\n        if(i+1)%sample_step == 0:\n            img_name = '../fake_samples-' + str(epoch + 1) + '-' + str(i + 1) + '.png'\n            images.append(imageio.imread(img_name))\n            print(\"epoch : {}, step : {}\".format(epoch+1, i+1))\nimageio.mimsave('dcgan_celebA_generation_animation.gif', images, fps=5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}