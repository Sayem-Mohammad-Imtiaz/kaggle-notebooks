{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"4oCr7ZnmmSCT","outputId":"98a52f28-03eb-4845-d483-885bffb9b51e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install imagecodecs","metadata":{"id":"qvZj0UlzUW2V","outputId":"4a1a4495-11ac-4775-d4b5-14abc3aea59c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"id":"wqVa4nxhAD6M","outputId":"e5526df7-7d62-447a-dee9-16e208e28a44","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport skimage.io\nimport matplotlib.pylab as plt\nimport tensorflow as tf\n\nimport torch\nimport random\n\nRANDOM_STATE = 42\n\nimport ast\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nprint(tf.__version__)","metadata":{"id":"UtCriAZV4hj4","outputId":"0f3e7fc6-bef8-4913-86f1-2d40c76d67d2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['PYTHONSEED'] = str(seed)\n\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"id":"WJMgq_izhzK3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now start loading the data. The data consists of satellite images of agricultural fields along with meta-data files.\n\n**Update:** The data files are now updated to include only unique (Location, PlotSize) pairs and the files are named accordingly *-unique.csv\n\nThe main meta-data files are *train-unique.csv* for the training images and *test-unique.csv* for the test images.\n\nLet's start with the training data.","metadata":{"id":"zWumOaU1-4fQ"}},{"cell_type":"code","source":"train = pd.read_csv('../input/lacuna2021/train-unique.csv')","metadata":{"id":"UbtizXaqMrHN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 2 types of satellite images provided in this competition:\n\n\n*   RGB color images taken at June'17, December'17, June'18, and December'18\n*   Spectral band images from the Sentinel-2 satellite taken monthly over the entire year of the data point acquisition i.e. the *Year* column in the meta-data.\n\nMore details of these images can be found in the data description page. \n\n","metadata":{"id":"TrvwlOzoAVA_"}},{"cell_type":"markdown","source":"**DATA EXPLORATION**\n\nWe now try to do understand our data.\n\nLet's start with the meta-data.","metadata":{"id":"cnCOi8VTCjoJ"}},{"cell_type":"code","source":"\nbands = '../input/lacuna2021/ImageBands.docx'\n\nimage_size = 80","metadata":{"id":"xDa5gQKfb-M5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train meta-data shape:\", train.shape)\ntrain.head(5)","metadata":{"id":"URA4LOvtCZ_6","outputId":"eaf2bd38-1298-4146-9eb3-6e88356ac841","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Year.value_counts()","metadata":{"id":"-_oUjrCGD6yB","outputId":"2e145be2-88e6-46db-ef47-d555e75a5217","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Quality.value_counts()","metadata":{"id":"Pw4Y1SJpECVj","outputId":"18ea3c81-4967-4d43-9c6f-e90f4ca1b607","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that we have data points from 2015 to 2018. We have the most data points from 2018 and the least from 2016.\n\nThe Quality column describes the confidence of the annotator in the label, with *1* being least confident and *3* being most confident.\n\nLet's statistically summarize the remaining columns grouped by each year.","metadata":{"id":"sZAriXVFEVy-"}},{"cell_type":"code","source":"train.drop('Quality', 1).groupby(\"Year\").describe(percentiles=[])","metadata":{"id":"WceU9svJAK0I","outputId":"d2b3779d-2d6c-4b96-dca5-2527b8425347","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(len(train.Year.unique()), 3, figsize=(12,14))\nfor i, year in enumerate(train.Year.unique()):\n    ax[i][0].hist(train[train.Year == year].PlotSize_acres)\n    ax[i][0].set_title('PlotSize_acres')\n    ax[i][1].hist(train[train.Year == year].x)\n    ax[i][1].set_title('x')\n\n    ax[i][2].hist(train[train.Year == year].y)\n    ax[i][2].set_title('y')\nplt.show()","metadata":{"id":"Y8SxApVOGpHs","outputId":"505a7dbf-b972-443c-94ff-0b90b5e943b5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's visualize the images.\n\nWe need two constant value to map the (x,y) values into the pixel-space of the image.","metadata":{"id":"2fQkor55GaLT"}},{"cell_type":"code","source":"CONST_X = 10.986328125 / 2\nCONST_Y = 10.985731758 / 2","metadata":{"id":"2n60YnsKVVhf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can sample a random row from the data.","metadata":{"id":"RlIdyd3SRRu5"}},{"cell_type":"markdown","source":"We now read the RGB images for each of the 4 image dates June'17, December'17, June'18, and December'18.","metadata":{"id":"37r5mIjMRYQv"}},{"cell_type":"code","source":"def read_image(path):\n    image = cv2.imread(path)[:, :, ::-1]\n    return image","metadata":{"id":"YwLYQdBJ6Mst","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_gray_images(ID, load_extra=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    name = ID.split('_')[1]\n\n    img_jun17 = read_image(f'../input/lacuna2021/{extra}planet-jun17/{extra}planet-jun17/{name}.png')\n    img_dec17 = read_image(f'../input/lacuna2021/{extra}planet-dec17/{extra}planet-dec17/{name}.png')\n    img_jun18 = read_image(f'../input/lacuna2021/{extra}planet-jun18/{extra}planet-jun18/{name}.png')\n    img_dec18 = read_image(f'../input/lacuna2021/{extra}planet-dec18/{extra}planet-dec18/{name}.png')\n\n    img_jun17 = cv2.resize(img_jun17, (image_size, image_size))\n    img_jun18 = cv2.resize(img_jun18, (image_size, image_size))\n    img_dec17 = cv2.resize(img_dec17, (image_size, image_size))\n    img_dec18 = cv2.resize(img_dec18, (image_size, image_size))\n\n    img_jun17 = cv2.cvtColor(img_jun17, cv2.COLOR_BGR2GRAY)\n    img_jun18 = cv2.cvtColor(img_jun18, cv2.COLOR_BGR2GRAY)\n    img_dec17 = cv2.cvtColor(img_dec17, cv2.COLOR_BGR2GRAY)\n    img_dec18 = cv2.cvtColor(img_dec18, cv2.COLOR_BGR2GRAY)\n\n    return [img_jun17 , img_dec17, img_jun18,  img_dec18]","metadata":{"id":"q9MXC8YIJ9NP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_RGB_images(ID, load_extra=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    name = ID.split('_')[1]\n\n    img_jun17 = read_image(f'../input/lacuna2021/{extra}planet-jun17/{extra}planet-jun17/{name}.png')\n    img_dec17 = read_image(f'../input/lacuna2021/{extra}planet-dec17/{extra}planet-dec17/{name}.png')\n    img_jun18 = read_image(f'../input/lacuna2021/{extra}planet-jun18/{extra}planet-jun18/{name}.png')\n    img_dec18 = read_image(f'../input/lacuna2021/{extra}planet-dec18/{extra}planet-dec18/{name}.png')\n\n    img_jun17 = cv2.resize(img_jun17, (image_size, image_size))\n    img_jun18 = cv2.resize(img_jun18, (image_size, image_size))\n    img_dec17 = cv2.resize(img_dec17, (image_size, image_size))\n    img_dec18 = cv2.resize(img_dec18, (image_size, image_size))\n\n    return [img_jun17 , img_dec17, img_jun18,  img_dec18]","metadata":{"id":"Uc3ag1nhb13S","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.transform import resize\n\ndef load_Spectral_image(ID, load_extra=False, year_2015=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    \n    name = ID.split('_')[1]\n    if year_2015:\n        root_dir = 'sentinel_for_points_collected_in_2015/sentinel_for_points_collected_in_2015'\n    elif not load_extra:\n        if os.path.isfile(f'../input/lacuna2021/sentinel-2-part1/sentinel/{name}.tif'):\n            root_dir = 'sentinel-2-part1/sentinel'\n        elif os.path.isfile(f'../input/lacuna2021/sentinel-2-part2/sentinel/{name}.tif'):\n            root_dir = 'sentinel-2-part2/sentinel'\n    else:\n        root_dir = extra + 'sentinel' + '/extra_train-sentinel'\n            \n    img_sentinel = skimage.io.imread(f'../input/lacuna2021/{root_dir}/{name}.tif')\n    \n    img_sentinel = resize(img_sentinel, (40, 40))\n\n    return img_sentinel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test_Spectral_image(ID, load_extra=False, year_2015=False):\n    # e.g id_0b242e06 -> 0b242e06\n    if load_extra:\n        extra = 'extra_train-'\n    else:\n        extra = ''\n    \n    name = ID.split('_')[1]\n    if year_2015:\n        if os.path.isfile(f'../input/lacuna2021/sentinel_for_points_collected_in_2015/sentinel_for_points_collected_in_2015/sentinel_for_points_collected_in_2015/sentinel_for_points_collected_in_2015/{name}.tif'):\n            root_dir = 'sentinel_for_points_collected_in_2015/sentinel_for_points_collected_in_2015'\n        elif os.path.isfile(f'../input/lacuna2021/sentinel-2-part1/sentinel/{name}.tif'):\n            root_dir = 'sentinel-2-part1/sentinel'\n        elif os.path.isfile(f'../input/lacuna2021/sentinel-2-part2/sentinel/{name}.tif'):\n            root_dir = 'sentinel-2-part2/sentinel'            \n    else:\n        if not load_extra:\n            if os.path.isfile(f'../input/lacuna2021/sentinel-2-part1/sentinel/{name}.tif'):\n                root_dir = 'sentinel-2-part1/sentinel'\n            else:\n                root_dir = 'sentinel-2-part2/sentinel'\n                \n        else:\n            root_dir = extra + 'sentinel' + '/extra_train-sentinel'\n\n    img_sentinel = skimage.io.imread(f'../input/lacuna2021/{root_dir}/{name}.tif')\n    \n    img_sentinel = resize(img_sentinel, (40, 40))\n\n    return img_sentinel\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the image size can slightly vary e.g. 84x84 or 83x83.\n\nIt is important to account for this difference in your preprocessing code when training a model e.g. padding with zeros.","metadata":{"id":"HpSL655jB6fw"}},{"cell_type":"code","source":"train.shape","metadata":{"id":"4yKMa54sRtcg","outputId":"ffc03867-8abf-42cb-8238-fa6bacda5038","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's inspect one of these images.\n\nWe can visualize it.","metadata":{"id":"2-Yrr5tmRoDl"}},{"cell_type":"markdown","source":"**AUXLIARY DATA**\n\nIn addition to the main training data, we also have additional data points in *auxilary_data-unique.csv*.\n\nThese points can be used to improve the training of the model.\n\n**Update:** The number of auxilary data points has decreased after removing duplicate data points. The extra training data compensates this shortage.","metadata":{"id":"8-RPsdXITNpd"}},{"cell_type":"code","source":"aux = pd.read_csv('../input/lacuna2021/auxilary_data-unique.csv')\naux.head(5)","metadata":{"id":"jiodCAo8ZKnK","outputId":"bf77cc86-caed-4754-a336-f7b9d9ba6c3a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(get_features_fromBands(ex, bands=band_names, Band_Names = names))","metadata":{"id":"8x40L7ntyH7o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_Features = pd.DataFrame([get_features_fromBands(train['Field_ID'].values[fid_idx],bands=bands,Band_Names=names) for fid_idx in tqdm(range(len(train['Field_ID'].values))) ])\n# train_Features['Field_ID'] = train['Field_ID'].values","metadata":{"id":"zijKHR3Ix_Cr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aux.shape)\naux.isna().sum()","metadata":{"id":"WzNfOZCgh7nW","outputId":"fc1a12de-1919-4956-cccd-40e323b70644","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aux.Year.value_counts()","metadata":{"id":"h-Ok0BBPZNzf","outputId":"fc6be051-d851-4158-b728-eadeec0eab6d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aux.Quality.value_counts()","metadata":{"id":"ajLTRGJDMxc8","outputId":"fa8e0fd6-9761-4759-8f89-fb20b24fce1c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aux.drop('Quality', 1).groupby(\"Year\").describe(percentiles=[])","metadata":{"id":"2_fYYNrQXMwd","outputId":"be413bbb-76af-42f9-f74e-b6fedfd940ce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's also visualize a sample from the auxilary data.","metadata":{"id":"rI8yqzNLWEWx"}},{"cell_type":"code","source":"def compute_distance(x0, y0, x1, y1):\n\n    a = np.array([x0, y0])\n    b = np.array([x1, y1])\n\n    dist = np.linalg.norm(b - a)\n\n    return dist\n  ","metadata":{"id":"XuK2CmXHb8FH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EXTRA DATA**\n\nIn addition to the main training data and auxilary data, we have annotated an extra 1000 unique data points to be used also for training in *extra_train.csv*.\n","metadata":{"id":"D6Msqw67bcau"}},{"cell_type":"code","source":"extra = pd.read_csv('../input/lacuna2021/extra_train.csv')\nextra.head(5)","metadata":{"id":"av3gtVDYbbwY","outputId":"62c3dad7-d23e-4bff-cd29-44d898ad85c4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extra.loc[:, 'is_extra'] = True\naux.loc[:,   'is_extra'] = False\ntrain.loc[:, 'is_extra'] = False","metadata":{"id":"fr0CvOuTEt4e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/lacuna2021/test.csv')\ntest.head(5)","metadata":{"id":"5PR2gzANDr6z","outputId":"e527fc9a-95b4-4453-d6bd-c998fa63a589","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.shape)\ntest.isna().sum()","metadata":{"id":"_fNOuUwZE_cY","outputId":"c675c561-c2cc-4276-d8e5-bdc554503fdc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = test[test['ID'].isin(sample_submission.ID.values)]","metadata":{"id":"-arhEt17nKtF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.shape)","metadata":{"id":"LBIAEBXgnbJW","outputId":"c49744b5-3108-4b7c-f2f6-b156221faacc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Quality'] = 3","metadata":{"id":"0JHPE7bBF4IH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"id":"NaAlJI35GF6c","outputId":"abc0a90b-ae75-4cc7-c977-29043b343df8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_extra = pd.concat([train, aux, extra], axis=0).reset_index(drop=True)","metadata":{"id":"a-ORcTlrHQPJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_extra.shape","metadata":{"id":"9HOpSKwHZz3E","outputId":"2db4494f-f60b-4434-e92b-95fc31c56fac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train_extra,test], axis=0).reset_index(drop=True)","metadata":{"id":"5kUCO799nAuM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape, train.shape","metadata":{"id":"1ZWBcYfzcL3X","outputId":"37de2f85-235d-437b-9d10-7e108a1c50ab","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"id":"7wGeFUMp-B_J","outputId":"8c313930-c1b5-427f-b7fa-b774a0e71f55","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"Q4FuEOM8GORw","outputId":"b31bbb1c-cb5f-4f6e-d0f4-bf5f3d92d59f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Year.value_counts()","metadata":{"id":"sygfJLee-KBI","outputId":"540c91b3-0b84-4f34-fcc5-2e962c95faf7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Yield.fillna(value = df.groupby(['PlotSize_acres','Quality'])['Yield'].transform('mean'), inplace=True)\ndf.Yield.fillna(value = df.groupby(['Year'])['Yield'].transform('mean'), inplace=True)","metadata":{"id":"3iprtY_GnKaS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"DZEXIBfG9ibs","outputId":"a2130b5c-aaba-4921-ab95-275eae3c2028","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Quality.value_counts()","metadata":{"id":"82nUN584cNLh","outputId":"15ef3faf-84b9-4351-dce8-fa7bb7a20281","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('Quality', 1).groupby(\"Year\").describe(percentiles=[])","metadata":{"id":"ZUR7bEKucPGd","outputId":"6ee7c357-960e-435c-fa26-99787783c63c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"id":"BzhjgzYUmvBJ","outputId":"321de69b-f7ce-451b-b871-51743df54f37","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(len(extra.Year.unique()), 3, figsize=(12,12))\nfor i, year in enumerate(extra.Year.unique()):\n    ax[i][0].hist(extra[extra.Year == year].PlotSize_acres)\n    ax[i][0].set_title('PlotSize_acres')\n    ax[i][1].hist(extra[extra.Year == year].x)\n    ax[i][1].set_title('x')\n    ax[i][2].hist(extra[extra.Year == year].y)\n    ax[i][2].set_title('y')\nplt.show()","metadata":{"id":"n06auOukcRAX","outputId":"1cd5f809-b7d5-492e-ea9e-111a97cfda08","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df['ID'].isin(train_extra['ID'].values)]\ntest_df =  df[~df['ID'].isin(train_extra['ID'].values)]","metadata":{"id":"JM6z9BqAGpQu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TEST SET**\n\nNow let's inspect the test data in *test.csv*. We will also visualize a sample but with out the markers.\n\nThe target columns (x, y) are not provided in *test.csv*. Note that the *Quality* column is also not provided.","metadata":{"id":"lf7gJeM2XR1X"}},{"cell_type":"code","source":"test_df.Year.value_counts()","metadata":{"id":"2UvbYuRzZ30T","outputId":"9d3186de-c314-4ab9-9c11-8032f44c24dc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"id":"H0t9SWTDXMSl","outputId":"27bec8af-9fd5-4a2c-b44e-487edcc1b3d4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"id":"TUfeIzdpGG35","outputId":"8063ac3e-9c82-4504-b3d5-c03e384f4a3f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_idx = train_df[train_df['Quality'] != 3].index\n# valid_idx = train_df[train_df['Quality'] == 3].index\n\n# train = train_df.loc[train_idx].reset_index(drop=True)\n# valid = train_df.loc[valid_idx].reset_index(drop=True)\n\n# train.shape, valid.shape","metadata":{"id":"W8OFEDSXIDqz","outputId":"b9f6fc50-9263-4c7b-ac3f-1289e30e9c1f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictors =  ['Yield','PlotSize_acres','Year']","metadata":{"id":"XNPht6xhIDlU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentinel_feature_cols =['BANDS_FEATURES_Median_FEATURES_B7_B5_0',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_1',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_10',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_11',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_2',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_3',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_4',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_5',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_6',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_7',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_8',\n 'BANDS_FEATURES_Median_FEATURES_B7_B5_9',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_0',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_1',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_10',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_11',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_2',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_3',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_4',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_5',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_6',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_7',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_8',\n 'BANDS_FEATURES_Median_FEATURES_B7_B6_9',\n 'EVI_Max_10',\n 'EVI_Max_11',\n 'EVI_Max_2',\n 'EVI_Max_3',\n 'EVI_Max_4',\n 'EVI_Max_5',\n 'EVI_Max_6',\n 'EVI_Max_7',\n 'EVI_Max_8',\n 'EVI_Max_9',\n 'EVI_Median_0',\n 'EVI_Median_1',\n 'EVI_Median_10',\n 'EVI_Median_11',\n 'EVI_Median_2',\n 'EVI_Median_3',\n 'EVI_Median_4',\n 'EVI_Median_5',\n 'EVI_Median_6',\n 'EVI_Median_7',\n 'EVI_Median_8',\n 'EVI_Median_9',\n 'NDVI_Max_0',\n 'NDVI_Max_10',\n 'NDVI_Max_3',\n 'NDVI_Max_4',\n 'NDVI_Max_5',\n 'NDVI_Max_6',\n 'NDVI_Max_7',\n 'NDVI_Max_8',\n 'NDVI_Max_9',\n 'NDVI_Median_0',\n 'NDVI_Median_1',\n 'NDVI_Median_10',\n 'NDVI_Median_11',\n 'NDVI_Median_2',\n 'NDVI_Median_3',\n 'NDVI_Median_4',\n 'NDVI_Median_5',\n 'NDVI_Median_6',\n 'NDVI_Median_7',\n 'NDVI_Median_8',\n 'NDVI_Median_9',\n 'NDVI_Min_0',\n 'NDVI_Min_10',\n 'NDVI_Min_3',\n 'NDVI_Min_4',\n 'NDVI_Min_5',\n 'NDVI_Min_6',\n 'NDVI_Min_7',\n 'NDVI_Min_8',\n 'NDVI_Min_9']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentinel_train_df= pd.read_csv('../input/sentinel-features/train_features.csv')\nsentinel_test_df = pd.read_csv('../input/sentinel-features/test_features.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nall_images = []\ntrain_dists = []\nsentinel_features = []\n\n# loop over the input house paths\nfor i,row in enumerate(train_df['ID']):\n    \n    row_df = train_df.loc[i]\n    \n    sent_row = sentinel_train_df[sentinel_train_df['ID'] == str(row)][sentinel_feature_cols].values[0]\n    sentinel_features.append(sent_row)\n\n    if row_df['is_extra']:\n        images = load_RGB_images(row, load_extra=True)\n\n        if row_df['Year'] == 2017:\n            idx = random.randint(0,1)\n            img = images[:2][idx]\n\n            x0, y0 = img.shape[1]//2, img.shape[0]//2\n            x1 = x0 - np.round(row_df['x'] / CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n            \n        elif row_df['Year']  == 2018:\n\n            idx = random.randint(0,1)\n\n            img = images[2:][idx]\n\n            x0, y0 = img.shape[1]//2, img.shape[0]//2\n            x1 = x0 - np.round(row_df['x'] / CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n            \n\n        else:\n            idx = random.randint(0,3)\n\n            img = images[idx]\n\n            x0, y0 = img.shape[1]//2, img.shape[0]//2\n            x1 = x0 - np.round(row_df['x'] / CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n        train_dists.append(d)\n        all_images.append(img)\n\n\n    else:\n        images = load_RGB_images(row, load_extra=False)\n\n        if row_df['Year'] == 2017:\n\n            idx = random.randint(0,1)\n\n            img = images[:2][idx]\n            x0, y0 = img.shape[1]//2, img.shape[0]//2\n            x1 = x0 - np.round(row_df['x'] / CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n                    \n        elif row_df['Year'] == 2018:\n            idx = random.randint(0,1)\n\n            img = images[2:][idx]\n            x0, y0 = img.shape[1]//2, img.shape[0]//2\n            x1 = x0 - np.round(row_df['x'] / CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n        else:\n            idx = random.randint(0,3)\n\n            img = images[idx]\n\n            x0, y0 = img.shape[1]//2, img.shape[0]//2\n            x1 = x0 - np.round(row_df['x'] / CONST_X * img.shape[1])\n            y1 = y0 + np.round(row_df['y']/ CONST_Y * img.shape[0])\n\n            d = compute_distance(x0 = x0, y0 = y0, x1 = x1, y1 = y1)\n\n\n        train_dists.append(d)\n        all_images.append(img)\n\n        del img\n        _ = gc.collect()","metadata":{"id":"z9p6fekcPO9J","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nX_train = np.array(all_images)\ntrain_sentinel_features = np.array(sentinel_features)\ntrain_ds = np.array(train_dists)\n\nX_train.shape, train_ds.shape,train_sentinel_features.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tile all images into a single image\nimport gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nall_images = []\ntest_sentinel_features = []\n\n# loop over the input house paths\nfor i,row in enumerate(test_df['ID']):\n\n    row_df = test_df.iloc[i]\n\n    sent_row = sentinel_test_df[sentinel_test_df['ID'] == str(row)][sentinel_feature_cols].values[0]\n    test_sentinel_features.append(sent_row)\n    \n    images = load_RGB_images(row, load_extra=False)\n\n    if row_df['Year'] == 2017:\n\n        idx = random.randint(0,1)\n\n        img = images[:2][idx]\n\n\n    elif row_df['Year'] == 2018:\n        idx = random.randint(0,1)\n\n        img = images[2:][idx]\n\n\n    else:\n        idx = random.randint(0,3)\n        img = images[idx]\n            \n    all_images.append(img)\n\n    del img\n    _ = gc.collect()","metadata":{"id":"Ty3RmA0iJv8Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nX_test = np.array(all_images)\ntest_sentinel_features = np.array(test_sentinel_features)\n\nX_test.shape, test_sentinel_features.shape","metadata":{"id":"I5fyoPHSQCMF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nX_test_aux =  np.concatenate([test_df[predictors].values,test_sentinel_features], axis=1)\nX_train_aux = np.concatenate([train_df[predictors].values,train_sentinel_features], axis=1)","metadata":{"id":"Xm-uFc2Te4_1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_aux.shape, X_train_aux.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nytrain = train_df[['x', 'y']].values\n\nytrain = np.array(ytrain.tolist()).reshape((ytrain.shape[0], 2))\n\nytrain.shape","metadata":{"id":"M28Zz635fbGx","outputId":"b092659d-a01c-4b2b-98dd-6427cb99745f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.layers import *\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.initializers import glorot_normal\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.applications import ResNet50,ResNet152\n\nfrom keras.regularizers import l2\nimport tensorflow as tf\nimport random\n","metadata":{"id":"9bk_VhYnfU7V","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = MultilabelStratifiedKFold(n_splits=20, shuffle=True, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n\n    img_inp = keras.Input(shape=(image_size, image_size,3), name=\"img_inputs\")    \n    aux_inp = keras.Input(shape=(79), name=\"auxillary_inputs\")\n    \n    inp_proj = ResNet50(include_top=False, weights='imagenet')(img_inp)\n\n    x_avg = tf.keras.layers.GlobalAveragePooling2D()(inp_proj)\n\n    out1 = Dropout(0.5)(x_avg)\n\n    out2 = Dense(64, activation='relu')(aux_inp)\n\n    concat = keras.layers.Concatenate(name=\"concat_layer\")([out1, out2])\n\n    prediction = keras.layers.Dense(2, name=\"prediction\")(concat)\n    predict_dist =  keras.layers.Dense(1, name=\"predict_dist\")(concat)\n    \n    # Model\n    model = keras.Model(inputs=[img_inp, aux_inp], outputs=[prediction, predict_dist])\n    \n    opt = keras.optimizers.Adam(learning_rate=0.001)\n    \n    model.compile(\n        loss= {\"prediction\":\"huber\",\"predict_dist\": \"huber\"},\n        loss_weights = { \"prediction\": 0.8,\"predict_dist\": 0.2 },\n        optimizer=opt,\n        metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae')]\n\n    )\n    \n    return model","metadata":{"id":"UrtDme31bYRN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nmodel_predictions = []\n\nfor i,(tr_index,test_index) in enumerate(kf.split(X_train, ytrain)):\n  \n    X_train_,y_train, Xtrain_aux = X_train[tr_index],ytrain[tr_index], X_train_aux[tr_index]\n\n    X_valid_,y_valid ,Xvalid_aux = X_train[test_index],ytrain[test_index], X_train_aux[test_index]\n\n    y_train_2 , y_valid_2 = train_ds[tr_index], train_ds[test_index]\n\n    model = build_model()\n    \n    checkpoint_filepath = '/tmp/efnetb5_checkpoint'\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                                filepath= checkpoint_filepath,\n                                save_weights_only=True,\n                                monitor='val_prediction_mae',\n                                mode='min',\n                                save_best_only=True)\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50,\n                                 mode='min',restore_best_weights=False)\n    sch_cb = ReduceLROnPlateau(\n        monitor='val_prediction_mae',\n        factor= 0.7,\n        patience= 2,\n        min_lr=1e-5,\n        verbose=1,\n        mode='min')\n        \n    print()\n    print(f'######### FOLD {i+1} / {kf.n_splits} ')\n\n    model.fit([X_train_, Xtrain_aux], \n        [y_train, y_train_2],\n        epochs = 300, \n        batch_size = 128,\n        validation_data = ([X_valid_ , Xvalid_aux], [y_valid, y_valid_2]),\n        callbacks = [es, model_checkpoint_callback, sch_cb]\n        )\n    model.load_weights(checkpoint_filepath)\n\n    preds,_ = model.predict([X_test, X_test_aux])\n\n    del model, X_train_, X_valid_, Xvalid_aux, Xtrain_aux\n\n    model_predictions.append(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\npreds = np.mean(model_predictions, axis=0)\n\ntest_df[['x', 'y']] = preds\n\nsub_df = test_df[['ID','x', 'y']]\n\nsub_df.to_csv('sub_resnet50_final.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_resnetmodel():\n\n    img_inp = keras.Input(shape=(image_size, image_size,3), name=\"img_inputs\")    \n    aux_inp = keras.Input(shape=(79), name=\"auxillary_inputs\")\n    \n    inp_proj = ResNet152(include_top=False, weights='imagenet')(img_inp)\n\n    x_avg = tf.keras.layers.GlobalAveragePooling2D()(inp_proj)\n\n    out1 = Dropout(0.5)(x_avg)\n\n    out2 = Dense(64, activation='relu')(aux_inp)\n    \n    concat = keras.layers.Concatenate(name=\"concat_layer\")([out1, out2])\n\n    prediction = keras.layers.Dense(2, name=\"prediction\")(concat)\n    predict_dist =  keras.layers.Dense(1, name=\"predict_dist\")(concat)\n    \n    # Model\n    model = keras.Model(inputs=[img_inp, aux_inp], outputs=[prediction, predict_dist])\n    \n    opt = keras.optimizers.Adam(learning_rate=0.001)\n    \n    model.compile(\n        loss= {\"prediction\":\"huber\",\"predict_dist\": \"huber\"},\n        loss_weights = { \"prediction\": 0.8,\"predict_dist\": 0.2 },\n        optimizer=opt,\n        metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae')]\n\n    )\n    \n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nresnetmodel_predictions = []\n\nfor i,(tr_index,test_index) in enumerate(kf.split(X_train, ytrain)):\n  \n    X_train_,y_train, Xtrain_aux = X_train[tr_index],ytrain[tr_index], X_train_aux[tr_index]\n\n    X_valid_,y_valid ,Xvalid_aux = X_train[test_index],ytrain[test_index], X_train_aux[test_index]\n\n    y_train_2 , y_valid_2 = train_ds[tr_index], train_ds[test_index]\n\n    model = build_resnetmodel()\n    \n    checkpoint_filepath = '/tmp/resnet152_checkpoint'\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                                filepath= checkpoint_filepath,\n                                save_weights_only=True,\n                                monitor='val_prediction_mae',\n                                mode='min',\n                                save_best_only=True)\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50,\n                                  mode='min',restore_best_weights=False)\n    sch_cb = ReduceLROnPlateau(\n        monitor='val_prediction_mae',\n        factor= 0.7,\n        patience= 2,\n        min_lr=1e-5,\n        verbose=1,\n        mode='min')\n    \n    print()\n    print(f'######### FOLD {i+1} / {kf.n_splits} ')\n\n    model.fit([X_train_, Xtrain_aux], \n        [y_train, y_train_2],\n        epochs = 300, \n        batch_size = 128,\n        validation_data = ([X_valid_ , Xvalid_aux], [y_valid, y_valid_2]),\n        callbacks = [model_checkpoint_callback, es,sch_cb]\n        )\n    \n    model.load_weights(checkpoint_filepath)\n    \n    preds,_ = model.predict([X_test, X_test_aux])\n\n    del model, X_train_, X_valid_, Xvalid_aux, Xtrain_aux\n\n    resnetmodel_predictions.append(preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nrespreds = np.mean(resnetmodel_predictions, axis=0)\n\ntest_df[['x', 'y']] = respreds\n\nsub_df = test_df[['ID','x', 'y']]\n\nsub_df.to_csv('sub_resnet152_final_20cv_folds.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model_2():\n\n    inp = keras.Input(shape=(76), name=\"inputs\")\n    \n    x = Dense(64,  activation='relu')(inp)\n    x = Dense(128, activation='relu')(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n    \n    out = Dropout(0.5)(x)\n\n    prediction = keras.layers.Dense(2, name=\"predictions\")(out)\n    \n    # Model\n    model = keras.Model(inputs=[inp], outputs=[prediction])\n    \n    opt = keras.optimizers.Adam(learning_rate=0.001)\n    \n    model.compile(\n        loss= \"mae\",\n        optimizer=opt,\n        metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae')]\n\n    )\n    \n    return model","metadata":{"id":"Z24-aPRSVhKy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n                              \nX_test =   test_sentinel_features\nX_train =  train_sentinel_features\n\nprint(X_test.shape,X_train.shape)","metadata":{"id":"4u2nVCiRhbRv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"id":"j0zsPBX1lfSP","outputId":"a742b300-2d41-4e4b-b101-9a77abce1e28","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nnn_preds = []\n\nfor i,(tr_index,test_index) in enumerate(kf.split(X_train, ytrain)):\n    \n    X_train_,y_train = X_train[tr_index],ytrain[tr_index]\n    X_valid_,y_valid = X_train[test_index],ytrain[test_index]\n\n    model = build_model_2()\n    \n    checkpoint_filepath = '/tmp/mlp_ckpt'\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n                                filepath= checkpoint_filepath,\n                                save_weights_only=True,\n                                monitor='val_mae',\n                                mode='min',\n                                save_best_only=True)\n    \n    es = EarlyStopping(monitor='val_loss', patience=20,\n                                      mode='min',restore_best_weights=False)\n    sch_cb = ReduceLROnPlateau(\n        monitor='val_prediction_mae',\n        factor= 0.7,\n        patience= 2,\n        min_lr=1e-5,\n        verbose=1,\n        mode='min')\n    print()\n    print(f'######### FOLD {i+1} / {kf.n_splits} ')\n\n    model.fit(X_train_, \n            y_train,\n            epochs = 300, \n            batch_size = 64,\n            validation_data = (X_valid_, y_valid),\n            callbacks = [es, model_checkpoint_callback, sch_cb]\n            )\n    model.load_weights(checkpoint_filepath)\n\n    preds = model.predict(X_test)\n\n    del model, X_train_, X_valid_\n\n    nn_preds.append(preds)","metadata":{"id":"j1SluaaNWnRv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nseed_everything(RANDOM_STATE)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nmlp_preds = np.mean(nn_preds, axis=0)\n\ntest_df[['x', 'y']] = mlp_preds\n\nsub_df = test_df[['ID','x', 'y']]\n\nsub_df.to_csv('sub_mlp_final_20cv_folds.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}