{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SAMPLE_DATASET = \"../input/facial-expression-recognition-challenge/icml_face_data.csv/icml_face_data.csv\"\n#print(SAMPLE_DATASET)\nNUM_CLASSES = 7\nTRAIN_HDF5 = \"./train.hdf5\"\nVAL_HDF5 = \"./val.hdf5\"\nTEST_HDF5 = \"./test.hdf5\"\nMODEL_FILE = \"./model.h5\"\nOUTPUT_PATH                                                                                                                                                                                             = \"./\"\nBATCH_SIZE = 128\n\nprint(TEST_HDF5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nimport os\n\n\nclass EpochCheckpoint(Callback):\n    def __init__(self, outpath, every=5, start_at=0):\n        super(Callback, self).__init__()\n        self.out_path = outpath\n        self.every = every\n        self.start_epoch = start_at\n\n    def on_epoch_end(self, epoch, logs={}):\n        if (self.start_epoch + 1) % self.every == 0:\n            p = os.path.sep.join([self.out_path, \"epoch_{}.hdf5\".format(self.start_epoch + 1)])\n            self.model.save(p, overwrite=True)  # 如果文件已经存在就覆盖\n        self.start_epoch += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import img_to_array\n\n\nclass ImageToArrayPreprocessor:\n    \n    def __init__(self,data_format=None):\n        self.data_format = data_format\n    def processes(self,image):\n        return img_to_array(image,data_format = self.data_format)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport h5py\n\n\nclass HDF5DatasetWriter:\n    def __init__(self, dims, output_path, data_key=\"images\", buf_size=1000):\n        if os.path.exists(output_path):\n            raise ValueError(\"您提供的输出文件{}已经存在，请手动删除\".format(output_path))\n        self.db = h5py.File(output_path, \"w\")\n        self.data = self.db.create_dataset(data_key, dims, dtype=\"float\")\n        self.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n\n        self.buf_size = buf_size\n        self.buffer = {\"data\": [], \"labels\": []}\n        self.idx = 0\n\n    def add(self, raw, label):\n        self.buffer[\"data\"].extend(raw)\n        self.buffer[\"labels\"].extend(label)\n        if len(self.buffer[\"data\"]) >= self.buf_size:\n            self.flush()\n\n    def flush(self):\n        i = self.idx + len(self.buffer[\"data\"])\n        self.data[self.idx:i] = self.buffer[\"data\"]\n        self.labels[self.idx:i] = self.buffer[\"labels\"]\n        self.idx = i\n        self.buffer = {\"data\": [], \"labels\": []}\n\n    def store_class_labels(self, class_labels):\n        dt = h5py.special_dtype(vlen=str)\n        label_dim = (len(class_labels),)\n        label_set = self.db.create_dataset(\"label_names\", label_dim, dtype=dt)\n        label_set[:] = class_labels\n\n    def close(self):\n        if len(self.buffer[\"data\"]) > 0:\n            self.flush()\n        self.db.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nimport numpy as np\nimport h5py\n\n\nclass HDF5DatasetGenerator:\n    def __init__(self, db_file, batch_size, preprocessors=None, aug=None, binarize=True, classes=2):\n        self.batch_size = batch_size\n        # 数据预处理器列表\n        self.preprocessor = preprocessors\n        # 数据增强处理器列表\n        self.aug = aug\n        self.binarize = binarize\n        self.classes = classes\n        self.db = h5py.File(db_file,'r')\n        self.numImages = self.db[\"labels\"].shape[0]\n\n    def generator(self, passes=np.inf):\n        epochs = 0\n\n        while epochs < passes:\n            for i in np.arange(0, self.numImages, self.batch_size):\n                images = self.db[\"images\"][i:i + self.batch_size]\n                labels = self.db[\"labels\"][i:i + self.batch_size]\n\n                if self.binarize:\n                    labels = to_categorical(labels, self.classes)\n                if self.preprocessor is not None:\n                    processed_image = []\n                    for image in images:\n                        for p in self.preprocessor:\n                            image = p.processes(image)\n                        processed_image.append(image)\n                    images = np.array(processed_image)\n                if self.aug is not None:\n                    (images, labels) = next(self.aug.flow(images, labels, batch_size=self.batch_size))\n\n                    yield images, labels\n                epochs += 1\n\n    def close(self):\n        self.db.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import BaseLogger\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport json\nimport os\n\n\nclass TrainingMonitor(BaseLogger):\n    def __init__(self,fig_path,json_path=None, start_at =0):\n        super(TrainingMonitor, self).__init__()\n        self.history = {}\n        self.fig_path = fig_path\n        self.json_path = json_path\n        self.start_at = start_at\n\n    def on_train_begin(self, logs={}):\n        if self.json_path is not None:\n            if os.path.exists(self.json_path):\n                self.history = json.loads(open(self.json_path).read())\n\n                if self.start_at > 0:\n                    for k in self.history.keys():\n                        self.history[k] = self.history[k][:self.start_at]\n\n\n    def on_epoch_end(self, epoch, logs={}):\n        for (k,v) in logs.items():\n            log = self.history.get(k, [])\n            log.append(v)\n            self.history[k] =  log\n\n        if self.json_path is not None:\n            f = open(self.json_path, \"w\")\n            f.write(json.dumps(self.history))\n            f.close()\n\n\n        if len(self.history[\"loss\"]) >1:\n            N = np.arange(0, len(self.history[\"loss\"]))\n            plt.style.use(\"ggplot\")\n            plt.figure()\n            plt.plot(N, self.history[\"loss\"], label=\"train_loss\")\n            plt.plot(N, self.history[\"val_loss\"], label=\"val_loss\")\n            plt.plot(N, self.history[\"accuracy\"], label=\"train_acc\")\n            plt.plot(N, self.history[\"val_accuracy\"], label=\"val_acc\")\n            epochs = len(self.history[\"loss\"])\n            plt.title(\"Training Loss & Accuracy [Epoch {}]\".format(epochs))\n            plt.xlabel(\"Epoch #\")\n            plt.ylabel(\"Loss/Accuracy\")\n            plt.legend()\n            plt.savefig(self.fig_path)\n            plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n#import HDF5DatasetWriter\n\n\nprint(\"[信息] 加载csv格式数据集文件\")\n\nfile = open(SAMPLE_DATASET)\nfile.__next__()#跳过第一行\n(train_images, train_label) = ([], [])\n(val_images, val_label) = ([], [])\n(test_images, test_label) = ([], [])\ncount_by_label_train = {}\ncount_by_label_val = {}\ncount_by_label_test = {}\nfor row in file:\n    (label, usage, image) = row.strip().split(\",\")\n    label = int(label)\n    image = np.array(image.split(\" \"), dtype=\"uint8\")\n    image = image.reshape((48, 48))\n\n    if usage == \"Training\":\n        train_images.append(image)\n        train_label.append(label)\n        count = count_by_label_train.get(label, 0)\n        count_by_label_train[label] = count + 1\n\n    elif usage == \"PublicTest\":\n        val_images.append(image)\n        val_label.append(label)\n        count = count_by_label_val.get(label, 0)\n        count_by_label_val[label] = count + 1\n\n    elif usage == \"PrivateTest\":\n        test_images.append(image)\n        test_label.append(label)\n        count = count_by_label_test.get(label, 0)\n        count_by_label_test[label] = count + 1\n\nfile.close()\nprint(\"[信息] 训练集样本数量：{}\".format(len(train_images)))\nprint(\"[信息] 校验集样本数量：{}\".format(len(val_images)))\nprint(\"[信息] 测试集样本数量：{}\".format(len(test_images)))\n#训练集样本分布\nprint(count_by_label_train)\n#校正集样本分布\nprint(count_by_label_val)\n#测试集样本分布\nprint(count_by_label_test)\n\ndatasets = [(train_images,train_label,TRAIN_HDF5),\n            (val_images,val_label,VAL_HDF5),\n            (test_images,test_label,TEST_HDF5)]\n\nfor (images,labels,outputPath) in datasets:\n    print(\"[信息]构建{}...\".format(outputPath))\n    writer = HDF5DatasetWriter((len(images),48,48),outputPath)\n\n    for (image,label) in zip(images,labels):\n        writer.add([image],[label])\n\n    writer.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import backend\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Activation, BatchNormalization\n\n\nclass MiniVGG13Net():\n    @staticmethod\n    def build(width, height, channel, classes, reg=0.0002):\n        model = Sequential(name=\"MiniVGG13Net\")\n        shape = (width, height, channel)\n        channel_dimension = -1\n        if backend.image_data_format == \"channel first\":\n            shape = (channel, width, height)\n            channel_dimension = 1\n        # 第一卷积块\n        model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        # 第二卷积块\n        model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        # 第三卷积块\n        model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        # 第四卷积块\n        model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        #第5个卷积层\n        model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1),padding=\"same\"))\n        model.add(Dropout(0.5))\n        # 第一全连接层\n        model.add(Flatten())\n        model.add(Dense(256, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        # 第二全连接层\n        model.add(Dense(128, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        # 第三全连接层\n        model.add(Dense(classes, kernel_regularizer=l2(reg)))\n        model.add(Activation(\"softmax\"))\n\n        return model\n\n\nif __name__ == \"__main__\":\n    model = MiniVGG13Net.build(48, 48, 1, 7, reg=0.0002)\n    print(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib\n# from config import setting\n# from utils.ImageToArrayPreprocessor import ImageToArrayPreprocessor\n# from utils.TrainingMonitor import TrainingMonitor\n# from utils.HDF5DatasetGenerator import HDF5DatasetGenerator\n# from MiniVGG13 import MiniVGG13Net\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nimport os\nmatplotlib.use(\"Agg\")\n\ntrain_aug = ImageDataGenerator(rotation_range=10,\n                   zoom_range = 0.1,\n                   rescale=1 / 255.0,\n                   fill_mode=\"nearest\")\nval_aug = ImageDataGenerator(rescale=1/255.0)\n\niap = ImageToArrayPreprocessor()\n\ntrain_gen = HDF5DatasetGenerator(TRAIN_HDF5,\n                                 BATCH_SIZE,\n                                 aug=train_aug,\n                                 preprocessors=[iap],\n                                 classes=NUM_CLASSES)\nval_gen = HDF5DatasetGenerator(VAL_HDF5,\n                                 BATCH_SIZE,\n                                 aug=val_aug,\n                                 preprocessors = [iap],\n                                 classes=NUM_CLASSES)\n\nopt = Adam(lr = 1e-3)\nmodel = MiniVGG13Net.build(width=48,height=48,channel=1,classes=NUM_CLASSES)\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\nfig_path = os.path.sep.join([OUTPUT_PATH, \"{}.png\".format(os.getpid())])\ncallbacks = [TrainingMonitor(fig_path=fig_path)]\nmodel.fit_generator(train_gen.generator(),\n                    steps_per_epoch=train_gen.numImages//BATCH_SIZE,\n                    validation_data=val_gen.generator(),\n                    validation_steps=val_gen.numImages // BATCH_SIZE,\n                    epochs=50,\n                    max_queue_size=BATCH_SIZE*2,\n                    callbacks=callbacks,\n                    verbose=1)\nprint(\"[信息] 保存模型...\")\nmodel.save(MODEL_FILE,overwrite=True)\ntrain_gen.close()\nval_gen.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from config import setting\n# from utils.ImageToArrayPreprocessor import ImageToArrayPreprocessor\n# from utils.HDF5DatasetGenerator import HDF5DatasetGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\n\ntestAug = ImageDataGenerator(rescale=1/255.0)\niap = ImageToArrayPreprocessor()\ntestGen = HDF5DatasetGenerator(TEST_HDF5,batch_size=BATCH_SIZE,preprocessors=[iap],\n                               aug=testAug,classes=NUM_CLASSES)\nprint(\"[信息] 加载网络模型\")\nmodel = load_model(MODEL_FILE)\n(loss,acc) = model.evaluate_generator(testGen.generator(),\n                                      steps=testGen.numImages//BATCH_SIZE,\n                                      max_queue_size=BATCH_SIZE*2)\nprint(\"[信息] 测试机准确率：{:.2f}%\".format(acc*100))\ntestGen.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}