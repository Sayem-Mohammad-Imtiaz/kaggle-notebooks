{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"9c7eef32-85dd-5792-f043-cc67084f402f"},"source":"## Initial exploration"},{"cell_type":"markdown","metadata":{"_cell_guid":"2f8d04bc-e8f4-816b-5af9-40f6466a3049"},"source":"Let's load some needed libraries and the dataset, and get a first glance and the contents. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1586bb6-d223-f648-6f32-d4ac3776cbb0"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n\n#read the file\ndf = pd.read_csv('../input/voice.csv',sep=',')\n\n#explore content\ndf.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cd6786aa-eaa0-feb3-d505-a9e8e3967401"},"source":"Here you can configure some settings we gonna play with afterwards"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0e38facb-9e7b-de2e-da01-8e0084569bc1"},"outputs":[],"source":"#------------- CONFIG -----------------\n#wanna do all plotting stuff??\ndoGraphs=True\n\n#Debug mode \nglobal debug\ndebug=False\n\n#Reduce test mode  (only first 4 features are removed in the IPA)\nreduced_scan=False\n#------------- CONFIG -----------------"},{"cell_type":"markdown","metadata":{"_cell_guid":"1f35664a-9d83-7d3b-6251-fb7e6eba85aa"},"source":"Next, we can take a look at the different features, for both male and female. From here we can already have a feeling of the most powerful acoustic attributes to distinguish one from the other."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a1ec9ef-39ad-8ffa-e4e8-40f3683f4424"},"outputs":[],"source":"#---plot some variables\ndef draw_comparison(df, vars):\n    cols=4\n    rows=int(len(vars)/cols)\n\n    f, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\n\n    for vv,axid in zip(vars,range(len(vars))):\n        #plot variable for male\n        sns.distplot(df[df['label']=='male'][vv], hist=False, color=\"g\", kde_kws={\"shade\": True}, ax=axes[int(axid/cols),(axid%cols)], label='Male')\n        #plot variable for female\n        sns.distplot(df[df['label']=='female'][vv], hist=False, color=\"m\", kde_kws={\"shade\": True}, ax=axes[int(axid/cols),(axid%cols)], label='Female')\n\n        #legend\n        ax = axes[int(axid/cols),(axid%cols)]\n        ax.legend(loc='best')\n        ax.set_xlabel(vv,fontsize=18)\n        ax.tick_params(top='on',right='on',direction='in')\n        \n        \n    \n    plt.tight_layout()\n    plt.show()\n    #plt.savefig('distcomp.png')\n\nif doGraphs:\n    draw_comparison(df, vars = list(df)[:-1]) #['Q25','IQR','meanfun','meanfreq','maxfun','kurt'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"c6fc2712-1a91-f10d-b5ba-049e26974c17"},"source":"It is evident that some attributes like `meanfun` and `IQR` will yield a good separation power, while others like `modindx` and `kurt` have little to offer to the classification task."},{"cell_type":"markdown","metadata":{"_cell_guid":"963f902c-5341-5466-9181-80093742be20"},"source":"### Correlations and dimensionality\n\nBut now, how are they correlated? They all really help / add something new?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5da9ca00-fb54-29b2-88b8-12400c52c242"},"outputs":[],"source":"#heatmap version\ndef draw_corr_matrix(df):\n    #compute correlation matrix\n    corr = df.corr()\n\n    sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, annot=False, fmt=\".1f\")\n    plt.title('Acoustic properties correlations',fontweight='bold',fontsize=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.show()\n    #plt.savefig('corr_matrix_hmap.png')\n    \nif doGraphs:\n    draw_corr_matrix(df)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6fb6b5b1-b0e1-2dce-1cf8-0d1551746aac"},"source":"We can observe that some variables are ~ fully correlated, so we can reduce the dimensionality of our problem and remove a few features from our dataset.\n\n\nAlthough is already clear from the correlation matrix, let's check some cases explicitly (extend at will!):"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac19e74e-48eb-716a-9851-e936dfbb48e4"},"outputs":[],"source":"#correlation plots\ndef plot_corr(df,var1,var2):\n    sns.jointplot(df[var1],df[var2], kind=\"hex\", color=\"#4CB391\")\n    plt.tick_params(top='on',right='on',direction='in')\n    plt.xlabel(var1)\n    plt.ylabel(var2)\n    plt.show()\n    #plt.savefig('corr_%s_%s.png' % (var1.replace(' ','_'),var2.replace(' ','_')))\n\nif doGraphs:\n    plot_corr(df,'dfrange','maxdom')\n    plot_corr(df,'meanfreq','centroid')\n    plot_corr(df,'meanfreq','median')\n    plot_corr(df,'skew','kurt')\n\nif debug:\n    print(list(df))"},{"cell_type":"markdown","metadata":{"_cell_guid":"a409be6b-2724-4f8e-070e-12840a6e69bf"},"source":"The four pairs of variables are strongly correlated, so we will remove one for each and reduce our exploratory space."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"758bb9aa-f0be-a827-4899-521049fad63b"},"outputs":[],"source":"#remove redundant info here \ndf.drop(['dfrange','kurt','median','centroid'], axis=1, inplace=True)\n\nif debug: \n    print(list(df))"},{"cell_type":"markdown","metadata":{"_cell_guid":"80e38340-7050-252d-bffa-142fdac2df87"},"source":"## Classification models\n\nLet's get ready to train and test some algorithms for the classificationt task. We extract and scale the features and encode the target labels first."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2aced7e-bffb-1cde-d976-f210e9896415"},"outputs":[],"source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) #ignore some DeprecationWarnings for now. Need to move to model_selection module.\n\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.cross_validation import KFold\nfrom sklearn.preprocessing import scale\n\n#Features (scaled)\nX=scale(df.iloc[:,:-1])\n\n#Labels (encode to binary)\ny=df.iloc[:,-1]\n\nfrom sklearn.preprocessing import LabelEncoder\nbincoder = LabelEncoder()\ny = bincoder.fit_transform(y)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8b2a64d6-6ecf-08a5-19a4-64ed2ea7e54d"},"source":"Then declare some models, in this case three SVC variants. We defined a generic function for model training-testing, using cross validation (5 K-fold). (the last argument will make sense in a moment...)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da448d44-e23b-7df4-9bd8-5e38fe211665"},"outputs":[],"source":"## Define models here\nmodels = {'SVC_Linear' : SVC(kernel='linear'), 'SVC_RBF' : SVC(kernel='rbf'), 'SVC_poly' : SVC(kernel='poly')}\n\n\n# Eval models for shrinking dataframes  .  (The excl_vars argument is a list of the features to be ignored in the dataset)\ndef eval_models(models,df,y,excl_vars=[]):\n    global debug\n    \n    #new features excluding some     \n    X = df.drop(excl_vars, axis=1).iloc[:,:-1]\n\n    mscores=[]\n    for ml in models:\n        #K-fold train-test\n        scores = cross_val_score(models[ml], X, y, cv=5)\n        if debug:\n            print('The K-fold %s model <score> is %.4f   :  ' % (ml, scores.mean()), scores)\n        mscores.append(scores.mean())\n\n    return mscores\n "},{"cell_type":"markdown","metadata":{"_cell_guid":"5f99bb32-149a-98f6-f399-aa34e8e26ac0"},"source":"Then we evaluate the models and booked the scores for later use."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"610605a9-8189-8519-1218-1d80eac809d8"},"outputs":[],"source":"##Create dictionary for scores \nscore_dict = {}\n\n## EVAL model (on full features space)\nscore_dict['IP0'] = eval_models(models, df,y,[])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8979a3f-cfe8-8224-9c9b-8d435fb0545d"},"outputs":[],"source":"for nmod in range(len(models)):\n    print('%-10s : %.2f' %  (list(models)[nmod], score_dict['IP0'][nmod]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"d122d1d5-161e-dfd7-503b-5cadb975345d"},"source":"\n## Increasingly Pessimistic Analysis (IPA)\n\n----------"},{"cell_type":"markdown","metadata":{"_cell_guid":"d77f06cc-6774-356a-a44a-838dec33992d"},"source":"As noted already, the mean frequency seems to be the most powerful attribute to distinguish between male and female voices. A sensible selection of this variable alone can reach almost perfect score. So how do we make things a bit more interesting?\n\nWell, imagine for a moment we don't have access to this acoustic attribute, i.e. some people might not be sensitive to the actual pitch, something like daltonism for visual recognition. So let's repeat the classification exercise removing that feature from our database. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f109bddf-2cb8-34a9-c65b-bd7fa97bb736"},"outputs":[],"source":"## EVAL regression model (on reduced features space)\nscore_dict['IP1'] = eval_models(models,df,y,['meanfun'])\n\nfor nmod in range(len(models)):\n    print('%-10s : %.2f' %  (list(models)[nmod], score_dict['IP1'][nmod]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"d941983a-5c47-198d-92e8-02c0fd32483c"},"source":"Although the performance has expectedly degraded a bit, the model still resolves reasonably well as there are other variables similarly powerful. \n\nLet's then continue the game a bit further, in what I called here a Increasingly Pessimistic Analysis (IPA). (Could have been Gradual Truncation Analysis for game lovers, but I like beer :P).\n\nThe idea is removing the most powerful variables one at a time, to force the model to more challenging scenarios. \nSo the sequence go:\n\n 1. IP1 remove the top variable from the features space (i.e. what we just did above)\n 2. IP2 remove the top two variables from the features space\n 3. ...\n\n...\n\nYou get the idea. How far can we go without losing too much predicting power? \n\nFirst we need to identify the discriminating power or importance ranking for each individual variable:\n "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e97174fd-fa59-ce10-bd21-6d1ab06cad52"},"outputs":[],"source":"##Get ranking list \n\n# Make ranking of individual discrimination power (by Recursive Feature Elimination, using the SVCLinear estimator here)\nfrom sklearn.feature_selection import RFE\nrfe = RFE(estimator=models['SVC_Linear'], n_features_to_select=1, step=1)\nrfe.fit(X,y)\nranking = rfe.ranking_\n\n#print ranking\nranked_vars = [a for (b,a) in sorted(zip(ranking,list(df)))]\nprint('Ranked Features')\nprint('-'*40)\nfor pos,var in enumerate(ranked_vars):\n    print('%-12i%s' % (pos,var))\nprint('-'*40)"},{"cell_type":"markdown","metadata":{"_cell_guid":"dad99932-cd80-46db-3ea9-2cd20998cf90"},"source":"Then we train and test the model for each sub-dataset, as defined above. \n\n*Note*: It might take a few minutes to run the full scan over all the features list. You can enable `reduced_scan` in the Config block at the beginning, or modify the `maxScan` variable by hand here below."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"148ce47f-c09f-89d5-b606-abaaeaa1b946"},"outputs":[],"source":"### train and test the model on the shrinking dataset \n#maxScan = 6\nmaxScan = len(ranked_vars)  #release the kraken!\n\nif reduced_scan: #as configured at the top\n    maxScan=4\nfor att in range(2,maxScan):\n    score_dict['IP%s'%str(att)] = eval_models(models,df,y,ranked_vars[:att])\n\nif debug:  #print scores for each IPA-step\n    print(score_dict)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2562161d-0c7b-1a9b-7c13-4620913e1580"},"source":"Shall we put it all together?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55735efc-a3ac-9a1a-034e-d177c5bec2f4"},"outputs":[],"source":"### make plot of score (mean of K-fold validation) vs IPX (X=0,1...N-1) . And we can add X=N=random guessing! We better do slighly better than that in all cases :)\ndef plot_scores(sdict, models):\n    colors=['r','b','m','g']\n    xp = range(maxScan)\n    for mid,ml in enumerate(models.keys()):\n        yp=[]\n        for sc in range(maxScan):\n            yp.append(sdict['IP%d'%sc][mid])\n        plt.plot(xp,yp,colors[mid],label=ml)\n    plt.xlabel('IP step',fontsize=14)\n    plt.ylabel('score',fontsize=14)\n    plt.tick_params(top='on',right='on',direction='in')\n    plt.legend(loc='upper right')\n    plt.show()\n    #plt.savefig('IPA_scores.png')\n\n\nplot_scores(score_dict, models)"},{"cell_type":"markdown","metadata":{"_cell_guid":"10c1e955-a748-e26e-9eda-68c67afa94ae"},"source":"The performance of the three models follows roughly the loss of information at each step, until we are left with only the last feature (maxfun). As seen in the plot above the distributions for male and female are very similar for this variable, so we get close to a poor random estimator. "},{"cell_type":"markdown","metadata":{"_cell_guid":"211f722b-db09-dd89-3153-d22f6fef9702"},"source":"\n\nSome things in the pipeline:\n\n* I may want to do the normal RFE (with x-val) analysis \n* Try with other models \n* Compare ranking to ExtraTreesClassifier()\n* ...\n\n**Comments are welcome!  :)**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c59284f-2570-f8ee-9c4e-b2e61bf30a0a"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}