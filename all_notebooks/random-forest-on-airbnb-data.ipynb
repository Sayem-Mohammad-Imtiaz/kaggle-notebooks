{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Random Forest Regression\n\n+ Tuning Hyperparametes using Grid Search"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/amsterdam-airbnb/train.csv\")\ndf = pd.DataFrame(data)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = df.columns  #getting list of column names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing column wise %ge of NaN values they contains \n\nfor i in col:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since no column has signficant missing values, there is no need to drop column here."},{"metadata":{},"cell_type":"markdown","source":"> Now start analysis with numerical data. Main objective is to determine the columns fit for predictions by checking their skewness.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = pd.read_csv(\"../input/amsterdam-airbnb/y_train.csv\", header=None)\ny_train = pd.DataFrame(y_train)\ny_train.columns = [\"price\"]\ny_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cormap = pd.concat([ df, y_train], axis = 1, sort=False).corr()\nfig, ax = plt.subplots(figsize=(16,16))\nsns.heatmap(cormap, cmap=\"YlGnBu\", annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simple Function to get the name of top most corelated attributes\n\ndef get_corelated_col(cor_dat, threshold): \n  # Cor_data to be column along which corelation to be measured \n  #Threshold be the value above wich of corelation to considered\n  feature=[]\n  value=[]\n\n  for i ,index in enumerate(cor_dat.index):\n    if abs(cor_dat[index]) > threshold:\n      feature.append(index)\n      value.append(cor_dat[index])\n\n  df = pd.DataFrame(data = value, index = feature, columns=['corr value'])\n  return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_corelated_values = get_corelated_col(cormap[\"price\"], 0.30)\ntop_corelated_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = df[top_corelated_values.index[:-1]]\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(final_df)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets split data in test train pairs\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(final_df, y_train, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can create a random forest and examine the default hyperparameter.\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(ccp_alpha=3,) # Here no paramemter is provided as we are just checking the default hyperparameters\nrfr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's make grid for tunning the hyper parametes\n\nfrom sklearn.model_selection import GridSearchCV\n\nn_estimators = [100, 150, 200, 250, 300]\nmax_features = ['auto', 'sqrt']\nmax_depth = [30, 35, 40, 45, 50]\nmin_samples_leaf = [12, 14, 16, 18, 20]\nbootstrap = [True, False]\n\n\ngrid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"new_rfr = RandomForestRegressor()\n\nrfr_grid = GridSearchCV(estimator = new_rfr, param_grid = grid, cv = 5, verbose=2)\n\nrfr_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> To determine if Grid Search yielded a better model, we compare the base model with the best grid search model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction of Base Model\n\ny_pred_1 = rfr.predict(X_test)\n\ny_pred_1[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluating the Model\n\nfrom sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_1))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_1))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_1)))\nprint('R2 Value:', metrics.r2_score(y_test, y_pred_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictin of Grid Search Model\n\ny_pred_2 = rfr_grid.best_estimator_.predict(X_test)\n\ny_pred_2[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluating the Model\n\nfrom sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_2))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_2))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_2)))\nprint('R2 Value:', metrics.r2_score(y_test, y_pred_2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since there is a rise in R2 score, it shows that Grid Search helped in tunning the hyper parametes of Random Forest and making it more accurate (though its very small here)"},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"> Now lets predict prices for test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/amsterdam-airbnb/test.csv\")\ntest_df = pd.DataFrame(data)\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing column wise %ge of NaN values they contains \n\nfor i in col:\n  print(i,\"\\t-\\t\", test_df[i].isna().mean()*100)\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = pd.read_csv(\"../input/amsterdam-airbnb/y_test.csv\", header=None)\ny_test = pd.DataFrame(y_train)\ny_test.columns = [\"price\"]\ny_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test_df = test_df[top_corelated_values.index[:-1]]\nfinal_test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictin of Grid Search Model\n\ny_pred = rfr_grid.best_estimator_.predict(final_test_df)\n\ny_pred[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}