{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# Import library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf335332fd308489469383918b74c22fad2bb206"},"cell_type":"markdown","source":"# Content\n* Ä°mport data\n* Cleanin data\n* Data Classification and Normalization\n* Data train and test splite\n* Logistic reggresion fit, predict and score\n* KNN fit, score and print accuracy\n* Find the best k value and virtualization\n* SVM fit, score and print accuracy\n* Naive Bayes fit, score and print accuracy\n* Decision Classification fit, score and print accuracy\n* Random Forest Classification fit, score and print accuracy\n* Confusion Matrix fit, score and print accuracy\n* Confusion Matrix Virtualize\n* CONCLUSION"},{"metadata":{"trusted":true,"_uuid":"d7f3ce509340ea6a9200e5edb31c4d4991a32a34"},"cell_type":"code","source":"# import data\ndata = pd.read_csv('../input/column_2C_weka.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4aac5489100ddff3a2e742117ccb47f10b2eaec"},"cell_type":"code","source":"# data info\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"442d320a5deda9e63169b3406adf162309e81012"},"cell_type":"code","source":"# data head\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17b6b23f363f8c25392fcdb19fc5e81801cc8773"},"cell_type":"code","source":"# before cleanin data and virtualize\nabnormal = data[data['class'] == 'Abnormal']\nnormal = data[data['class'] == 'Normal']\nplt.scatter(abnormal.pelvic_incidence,abnormal.pelvic_radius,color='red',label='Abnormal',alpha=0.4)\nplt.scatter(normal.pelvic_incidence,normal.pelvic_radius,color='green',label='Normal',alpha=0.4)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('pelvic_radius')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82db62e1ed89ca1a3442383ed64fba62ad30bb7b"},"cell_type":"code","source":"# classification and normalization\ndata['class'] = [0 if x == 'Abnormal' else 1 for x in data['class']] # clasifications\ny = data['class']\nx_data = data.drop(['class'],axis=1)\nx = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)) # normalizations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81c882692a9e2a595868da264dd821a16e9cdc95"},"cell_type":"code","source":"# data train and test splite\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 1)\n#print(x_train, x_test, y_train, y_test )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1700940983501b3e345eecc7ac24163c2227f560"},"cell_type":"code","source":"# logistic regression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nprint(\"test accuracy {}\".format(lr.score(x_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# knn\nknn = KNeighborsClassifier(n_neighbors=4)\nknn.fit(x_train,y_train)\nprint ('k: {} values score: {}'.format(4,knn.score(x_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67238a10ad5e56aba33bbb994270abc66044c7cd"},"cell_type":"code","source":"# Find the best k value and virtualization\nscore_list = []\n\nfor x in range(1,15):\n    knn_n = KNeighborsClassifier(n_neighbors=x)\n    knn_n.fit(x_train,y_train)\n    score_list.append(knn_n.score(x_test, y_test))\n    print ('k: {} values score: {}'.format(x,knn_n.score(x_test, y_test)))\n\nplt.plot(range(1,15), score_list)\nplt.xlabel('k values')\nplt.ylabel('accurasi')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24a57da017f2012bb2694e7db7d4e3273da47b6f"},"cell_type":"code","source":"# SVM\nsvm = SVC(random_state=1)\nsvm.fit(x_train, y_train)\nprint ('accuracy of svmalgo: ',svm.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1dd33c8e2d6de6be38e03b63a36d59ee2dce306"},"cell_type":"code","source":"# Naive Bayes\ngnb = GaussianNB()\ngnb.fit(x_train, y_train)\nprint ('accuracy of naive bayes: ',gnb.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25a14fd31305e39106079e77790a8bf46df8c250"},"cell_type":"code","source":"# Decision Classification\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\nprint ('accuracy of naive decision tree: ',dtc.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc25910ac8faa4994e34f598986683b999340cf9"},"cell_type":"code","source":"# Random Forest Classification\nrf = RandomForestClassifier(n_estimators=100,random_state=1)\nrf.fit(x_train,y_train)\nprint ('Random forest algo result: ',rf.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24df482ad8994e0b7964e4cf164ecf0f570eda1d"},"cell_type":"code","source":"# Confusion matrix\ny_predict = rf.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_predict)\nprint ('confusion matrix: ',cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a9f7fce861e3a7526493468dfe6ccc25f11c6854"},"cell_type":"code","source":"# Confusion matrix Virtualize\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor='red',fmt='.0f',ax=ax)\nplt.xlabel('y_pred')\nplt.ylabel('y_true')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f23493d5e0a3d2cee22e2289612a70c95ccfde6a"},"cell_type":"markdown","source":"# CONCLUSION\nI have examined this data with a few machine learning algorithms and got the highest score with random forest classification(0.838%) algorithm. test_sise increased from 02 to 0.4 random forest 87%\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}