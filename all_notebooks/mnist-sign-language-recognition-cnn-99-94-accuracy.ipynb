{"cells":[{"metadata":{},"cell_type":"markdown","source":"# In this notebook, we will train the CNN to recognize Americal Sign Language, on dataset released by MNIST and improve the accuracy of the model by using:\n1. Data Augmentation\n2. Learning Rate Scheduler\n3. Batch Normalisation and Regularisation"},{"metadata":{},"cell_type":"markdown","source":"![Image](https://www.kaggleusercontent.com/kf/23902291/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..b4PwWh0-JaEztBfEfxEvxg.R-XjDU5wnsx1xXkhlRqHs5HJNUhIFT33qWmyrKVIggB9AXKOMkL2FkyjBKxlwZOGmXXSgdUSPWyARbtEogVVIPiHkrpR2nYWnlo-lIrhSgRKeepXELPAjTRP9kyiFsGzGUMkHsElPncT_rZ9pqxjBkCGtNYIVqPhpKhBrASPPt7X2Ye69XEBEqMkFO2DrUSwceeRTruc-Y3tRKL6mWxuxFMrJQCETl8pzQe-dQb9ivOEHg_IQlyB0SsGHljdd8MXmv4Y5X-MA1EnFTz6ZkjlLjzfTjX_vuMAe7b1fdnuO7lJxMvR6wUH5qvu5oVkWHgw8MBhpOH1K9MDUJAYnM1-6417kkZtuIHY9KcJpdX3nv41vWxz-AmWKexJiN-HIRk4gVMSnzf9dwWaaznKKdAWYwPZdXkAS-NcKws2ylUS0EUFh-jXS9T4EUrTr9J6-9TCv707WOJola-Lfjk_CJEoeMdKkYVFSiraRVlEstwxLuavwkMUwRwBBuXaZm6STFvoEABiGgB_CiZkan41iO-Tiyg-lBpsICaj_-SKH6Vd0ijs8WSOzKDDWusI3NwtqqZOdamczkGVFUHHmubbS5KnqUdKIO4q-UctePM7lFqZUhKhsBuKdC_bHbWargINs-xyHZRXtOJwiDY7OVdpBkevbpNF7fmk0_lfNpTmGP7OdLC7UNB-gwd1M_vbjgPu5qxu.9kdSjumTYY33e-DaRJUX4Q/__results___files/__results___1_0.png)"},{"metadata":{},"cell_type":"raw","source":"Importing the requried libraries for our task"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras.callbacks import *\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**About Dataset:** Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions)."},{"metadata":{},"cell_type":"markdown","source":"Loading the training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = pd.read_csv('./../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First Column of data corresponds to given label, while columns 1 to 785 represents its 784 pixel values. There are total 27455 images of size 28,28 and are in grayscale mode."},{"metadata":{},"cell_type":"markdown","source":"Lets look at some of the images from training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(20,6))\nax = f.add_subplot(161)\nax2 = f.add_subplot(162)\nax3 = f.add_subplot(163)\nax4 = f.add_subplot(164)\nax5 = f.add_subplot(165)\nax6 = f.add_subplot(166)\nax.imshow(traindata.iloc[0].values[1:].reshape(28,28))\nax2.imshow(traindata.iloc[5].values[1:].reshape(28,28))\nax3.imshow(traindata.iloc[20].values[1:].reshape(28,28))\nax4.imshow(traindata.iloc[456].values[1:].reshape(28,28))\nax5.imshow(traindata.iloc[999].values[1:].reshape(28,28))\nax6.imshow(traindata.iloc[1500].values[1:].reshape(28,28))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separating the labels into trainlabel and image pixels into trainimages"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainlabel=traindata['label'].values\ntraindata.drop('label',inplace=True,axis=1)\ntrainimages = traindata.values\n#reshape it to (28,28,1)-> (height,width,channels)\ntrainimages=trainimages.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata = pd.read_csv('./../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similiar to train data, First column represent labels while others represents its pixel values"},{"metadata":{"trusted":true},"cell_type":"code","source":"testlabel=testdata['label'].values\ntestdata.drop('label',inplace=True,axis=1)\ntestimages = testdata.values\ntestimages=testimages.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing Image Data generator for data augmentation in run time.ImageDataGenerator allows us to augment images on runtime without affecting the local copies. It provides us an advantage of trying different augmentation techniques and can experiment it with its values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Augmenting the training data\n2. Normalising pixel values from (0,255) to (0,1)\n3. Splitting the data into 80% training and 20% validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"traingen=ImageDataGenerator(rotation_range=20,\n                            zoom_range=0.1,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            shear_range=0.1,\n                            horizontal_flip=True,\n                            rescale=1/255.0,#normalising the data\n                            validation_split=0.2 #train_val split\n                            )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generating training and validation data from Image generator we created above"},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata_generator = traingen.flow(trainimages,trainlabel,subset='training')\nvalidationdata_generator = traingen.flow(trainimages,trainlabel,subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the test data Generator, we will only normalise it to (0,1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"testgen=ImageDataGenerator(rescale=1/255.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata_generator = testgen.flow(testimages,testlabel)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the Neural Network using Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential([])\n\nmodel.add(Conv2D(64,(3,3),activation=\"relu\",input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),activation=\"relu\",input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(26,activation=\"softmax\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Structure of the Model and jouney of an image through Neural Network:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling the model, \n1. loss function: sparse_categorical_crossentropy since it is a multiclass classification model\n2. optimizer: adam\n3. metrics: accuracy-> no of images classified correctly"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It might occur that, we will overshoot the optima. Therefore, we should cancel training using callback, once the validation accuracy reaches 99.5 %"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a Callback class that stops training once accuracy reaches 99.5%\nclass myCallback(Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('val_accuracy')>0.995):\n      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n      self.model.stop_training = True\ncallback=myCallback()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To stop fluctuating between the accuracy, we will decrease the learning rate on each epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"dynamicrate = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # # Training the Model for 50 epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(traindata_generator,epochs=50,validation_data=validationdata_generator,callbacks=[callback,dynamicrate])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training Accuracy at the end of 15th epoch: 99.63\n\nValidation Accuracy at the end of 15th epoch: 99.76\n\nSince, validation accuracy has reached  above 99.5, callback function stopped further training of the model"},{"metadata":{},"cell_type":"markdown","source":"# 1. Plotting training vs validation accuracy\n#  2. Plotting training vs validation loss\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test the model on test data using model.evulate_generator and pass the test data generator which we have already created above.\n\nIt returns two arguments \n1. Loss\n2. Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss,accuracy = model.evaluate_generator(testdata_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"test accuracy: \"+ str(accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}