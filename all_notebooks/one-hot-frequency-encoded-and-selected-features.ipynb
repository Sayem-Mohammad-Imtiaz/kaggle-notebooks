{"cells":[{"metadata":{"id":"uZY64JwzVYR6"},"cell_type":"markdown","source":"Dataset contains target variable `Churn` (whether the customer churned or not (Yes or No)) and some customer's attributes described below:\n\n`customerID` – Customer ID<br>\n`gender` – Whether the customer is a male or a female<br>\n`SeniorCitizen` – Whether the customer is a senior citizen or not (1, 0)<br>\n`Partner` – Whether the customer has a partner or not (Yes, No)<br>\n`Dependents` – Whether the customer has dependents or not (Yes, No)<br>\n`tenure` – Number of months the customer has stayed with the company<br>\n`PhoneService` – Whether the customer has a phone service or not (Yes, No)<br>\n`MultipleLines` – Whether the customer has multiple lines or not (Yes, No, No phone service)<br>\n`InternetService` – Customer’s internet service provider (DSL, Fiber optic, No)<br>\n`OnlineSecurity` – Whether the customer has online security or not (Yes, No, No internet service)<br>\n`OnlineBackup` – Whether the customer has online backup or not (Yes, No, No internet service)<br>\n`DeviceProtection` – Whether the customer has device protection or not (Yes, No, No internet service)<br>\n`TechSupport` – Whether the customer has tech support or not (Yes, No, No internet service)<br>\n`StreamingTV` – Whether the customer has streaming TV or not (Yes, No, No internet service)<br>\n`StreamingMovies` – Whether the customer has streaming movies or not (Yes, No, No internet service)<br>\n`Contract` – The contract term of the customer (Month-to-month, One year, Two year)<br>\n`PaperlessBilling` – Whether the customer has paperless billing or not (Yes, No)<br>\n`PaymentMethod` – The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))<br>\n`MonthlyCharges` – The amount charged to the customer monthly<br>\n`TotalCharges` – The total amount charged to the customer<br>\n"},{"metadata":{"id":"sIRCLuWGVYR9"},"cell_type":"markdown","source":"# 1. Data description and preprocessing"},{"metadata":{"id":"s0fDRVkgVYSA","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', None)\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can delete 'customerID' because it doesn't affect the churn.\n\ndata.drop(columns=['customerID'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see there is no missing values. But 'TotalCharges' is object type although it looks like float.\n\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see the categorical features have 2-4 values\n\ndata.describe(include=np.object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check why 'TotalCharges' has object type - what else does it have except numbers\n\ndata[~data['TotalCharges'].str.match('^\\d*\\.?\\d*$')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[488, 'TotalCharges']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'TotalCharges' values belong to accounts which is less than a month. They give us no information so we can get rid of them.\n\ndata.drop(data[data['TotalCharges'] == ' '].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert 'TotalChurges' to float\n\ndata['TotalCharges'] = data['TotalCharges'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert target value 'Churn' to 1 and 0\n\ndata['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We'll work with a copy of the dataset\n\ndf = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"TDUhZEKyVYSN"},"cell_type":"markdown","source":"# 2. Correlation searching"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distinguish features groups: social, subscriptions to services and account features.\n\nsocial_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents']\nservice_features = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n                     'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\naccount_features = ['Contract', 'PaperlessBilling', 'PaymentMethod']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def countplot_stat(data, features, hue=None, n_cols=5):\n    \"\"\"\n    Plot countplots for given columns in dataset by given number of columns\n    \"\"\"\n    n_cols = min(n_cols, len(features))\n    n_rows = int(np.ceil(len(features) / n_cols))\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*5))\n    for ax, feat in zip(axes.flatten(), features):\n        sns.countplot(x=feat, hue=hue, data=data, ax=ax)\n        ax.set_xticklabels(ax.get_xticklabels(),rotation=15)\n        plt.tight_layout()\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar graphs for 'Churn' in social features.\n\ncountplot_stat(df, social_features, hue='Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that 'Gender' is not very useful for predicting 'Churn'.<br>\nAlthough total amonut of churned within Senior Citizens is lower churned ratio in this category is higher.<br>\nMore churned accounts among those who have NO 'Partner' and 'Dependents'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert binary features to 1 and 0\n\ndf[['Partner', 'Dependents']] = df[['Partner', 'Dependents']]\\\n    .stack().map({'Yes': 1, 'No': 0}).unstack()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Bar graphs for 'Churn' in services features\n\ncountplot_stat(df, service_features, hue='Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The higher rate of churned among acounts which have Fiber optic connection and doesn't have OnlineSecurity, OnlineBackup, DeviceProtection and TechSupport options."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binary feature PhoneService convert to 1 and 0\n\ndf[['PhoneService']] = df[['PhoneService']]\\\n    .stack().map({'Yes': 1, 'No': 0}).unstack()\n\n# Create some features based on connected services\n\ndf['is_fiber_optic'] = df['InternetService'].apply(lambda x: 1 if x == 'Fiber optic' else 0)\ndf['no_internet_service'] = df['InternetService'].apply(lambda x: 1 if x == 'No' else 0)\ndf['no_online_security'] = df['OnlineSecurity'].apply(lambda x: 1 if x == 'No' else 0)\ndf['no_online_backup'] = df['OnlineBackup'].apply(lambda x: 1 if x == 'No' else 0)\ndf['no_device_protection'] = df['DeviceProtection'].apply(lambda x: 1 if x == 'No' else 0)\ndf['no_tech_support'] = df['TechSupport'].apply(lambda x: 1 if x == 'No' else 0)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Bar graphs for 'Churn' in account features\n\ncountplot_stat(df, account_features, hue='Churn', n_cols=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those who have monthly subscription are more likely to churn.<br>\nHigher churn rate within those who use PaperlessBilling and Electronic check."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create features on account properties\n\ndf['monthly_payments'] = df['Contract'].apply(lambda x: 1 if x == 'Month-to-month' else 0)\ndf['electronic_check'] = df['PaymentMethod'].apply(lambda x: 1 if x == 'Electronic check' else 0)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(14, 7))\nfor ax, feat in zip(axes.flatten(), ['tenure', 'MonthlyCharges']):\n    sns.distplot(df[df['Churn'] == 0][feat], hist=False, bins=10, color='b', ax=ax, label='No Churn')\n    sns.distplot(df[df['Churn'] == 1][feat], hist=False, bins=10, color='r', ax=ax, label='Churn')\n#     plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distributions of tenure and MonthlyCharges shows that accounts less than 20 months and charges between 70 and 110 per month have higher churn risk."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create binary features based on critical values \n\ndf['short_tenure'] = df['tenure'].apply(lambda x: 1 if x < 20  else 0)\ndf['high_charges'] = df['MonthlyCharges'].apply(lambda x: 1 if x > 70 and x < 110 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose important features and create dataset with them\n\nfeatures = ['SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'is_fiber_optic', 'no_internet_service', 'no_online_security', 'no_online_backup', \n            'no_device_protection', 'no_tech_support', 'monthly_payments', 'electronic_check', 'short_tenure', 'high_charges']\nX_selected = df[features + ['Churn']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the second dataset using one-hot label encoding.\n\nX_dummies = pd.get_dummies(data)\n            \nX_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the third dataset whith categorical feature replaced by their frequencies.\n\nX_freq = data.copy()\n\ncateg_features = X_freq.select_dtypes(include=np.object).columns\nfor column in categ_features:\n    encoding = X_freq.groupby(column).size()\n    encoding /= len(X_freq)\n    X_freq[column] = X_freq[column].map(encoding)\nX_freq.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot correlations between features and target\n\nfig, ax = plt.subplots(1, 3, figsize=(25,15), )\nfig.subplots_adjust(left=0.4)\n\nsns.heatmap(X_dummies.corr()[['Churn']].sort_values(by='Churn', ascending=False), vmin=-1, vmax=1, cmap='YlGnBu', annot=True, ax=ax[0])\nax[0].set_title(\"Dummies data\")\n\nsns.heatmap(X_freq.corr()[['Churn']].sort_values(by='Churn', ascending=False), vmin=-1, vmax=1, cmap='YlGnBu', annot=True, ax=ax[1])\nax[1].set_title(\"Frequencies data\")\n\nsns.heatmap(X_selected.corr()[['Churn']].sort_values(by='Churn', ascending=False), vmin=-1, vmax=1, cmap='YlGnBu', annot=True, ax=ax[2])\nax[2].set_title(\"Selected features\")\n\n# ax[0].tick_params(labelsize=16)\nplt.tight_layout()\nplt.rc('font', size='14')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that features selection is right but some of features have lost part of information while constructing and have slightly smaller correlation with target**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exclude target from datasets\n\nX_dummies = X_dummies.drop(columns=['Churn'])\nX_freq = X_freq.drop(columns=['Churn'])\nX_selected = X_selected.drop(columns=['Churn'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So we have three datasets for model fitting:**\n1. Using one-hot label encoding with numpy.get_dummies function\n2. With categorical features replaced with their frequencies\n3. With features selected after dataset analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"variants = [X_dummies, X_freq, X_selected]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target dataseet\n\ntarget = data['Churn']","execution_count":null,"outputs":[]},{"metadata":{"id":"YnZrI40dVYSZ"},"cell_type":"markdown","source":"# 3. Models construction"},{"metadata":{"id":"wwrrkx8pVYSa","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import (GridSearchCV,\n                                     train_test_split,\n                                     StratifiedKFold)\n\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn.preprocessing import Normalizer\n\nrnd_state = 17\ntest_size_ = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dictionaries with models\n\nmodels = {'gbc': GradientBoostingClassifier(), \n          'rfc': RandomForestClassifier(), \n          'svc': SVC(), \n          'lr': LogisticRegression(),\n          'xgb': XGBClassifier()\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Determine models parameters for using with GridSearchCV\n\ngbc_params = {'learning_rate': np.arange(0.1, 0.6, 0.1), \n              'random_state': [rnd_state]} # GradientBoostingClassifier\n\nrfc_params = {'n_estimators': range(10, 100, 10), # RandomForestClassifier\n              'min_samples_leaf': range(1, 5), \n              'random_state': [rnd_state]}\n\nsvc_params = {'kernel': ['rbf', 'sigmoid'], # SVC\n              'C' : [0.1, 1, 5, 10], \n              'gamma' : [0.01, 0.1, 0.9, 1], \n              'random_state': [rnd_state]}\n\nlr_params = {'C': np.arange(0.5, 1, 0.1), # LogisticRegression\n             'max_iter': [1000],\n             'random_state': [rnd_state]}\n\nxgb_params = {'learning_rate' : [0.01, 0.03, 0.05], # GradientBoostingClassifier\n              'max_depth' : [1, 4, 6], \n              'n_estimators' : [100, 300, 400, 600, 1000], \n              'random_state': [rnd_state]}\n\nparams = [gbc_params, rfc_params, svc_params, \n          lr_params, xgb_params]\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def grid_search_selector(features_df, target_df, models, params, test_size=0.2, random_state=None):\n    \"\"\"\n    Function takes features and target datasets, algorithms and parameters.\n    Devides data into train and validation parts and searches best parameters with GridSearchCV.\n    Prints best scores and returns best parameters and best scores.\n    \"\"\"\n    best_params = {}\n    best_scores = {}\n\n    X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size=test_size, random_state=random_state)\n    \n    for n, (name, model) in enumerate(models.items()):\n        clf = GridSearchCV(estimator=model, param_grid=params[n], cv=skf).fit(X_train, y_train)\n        best_params[name] = clf.best_params_\n        best_scores[name] = clf.score(X_test, y_test)\n        print(f\"{str(name)} -- {best_scores[name]}\")\n    \n    return best_params, best_scores","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Find best parameters for models for three datasets\n\nbest_dummies, dummies_scores = grid_search_selector(X_dummies, target, models, params, test_size=test_size_, random_state=rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_dummies","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"best_freq, freq_scores = grid_search_selector(X_freq, target, models, params, test_size=test_size_, random_state=rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_freq","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"best_selected, selected_scores = grid_search_selector(X_selected, target, models, params, test_size=test_size_, random_state=rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_selected","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine scores to dataframe to choose the best\n\nall_scores = pd.DataFrame([dummies_scores.values(), freq_scores.values(), selected_scores.values()], columns=dummies_scores.keys(), index=['dummies', 'frequencies', 'selected'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7, 5))\nsns.heatmap(all_scores, annot=True, fmt='.3g')\nplt.yticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"uyDpeHkTVYSf"},"cell_type":"markdown","source":"# 4. Models evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation(model, params: 'dict', features_df, target_df, test_size_=None, random_state=None):\n    \"\"\"\n    Fits model with given parameters and print classification report for train and test data\n    and also plots ROC-curve and confusion matrix\n    \"\"\"\n    X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size=test_size_, random_state=random_state)\n    \n    model = model.set_params(**params)\n    model.fit(X_train, y_train)\n    \n    y_pred_train = model.predict(X_train)\n    y_pred = model.predict(X_test)\n    \n    acc_score_train = metrics.accuracy_score(y_train, y_pred_train)\n    acc_score = metrics.accuracy_score(y_test, y_pred)\n    \n    print(metrics.classification_report(y_test, y_pred, target_names=['Non-churned', 'Churned']))\n\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n    metrics.plot_roc_curve(model, X_test, y_test, ax=axes[0])\n    sns.lineplot([0,1], [0,1], ax=axes[0])\n    metrics.plot_confusion_matrix(model, X_test, y_test, display_labels= ['Non-churned', 'Churned'], cmap='GnBu', ax=axes[1])\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# XGBClassifier on frequencies data\n\nmodel_evaluation(models['xgb'], best_freq['xgb'], X_freq, target, test_size_, rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# SVC on selected features\n\nmodel_evaluation(models['svc'], best_selected['svc'], X_selected, target, test_size_, rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# RandomForestClassifier on frequencies data\n\nmodel_evaluation(models['rfc'], best_freq['rfc'], X_freq, target, test_size_, rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# LogisticRegression on one-hot encoded data\n\nmodel_evaluation(models['lr'], best_dummies['lr'], X_dummies, target, test_size_, rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# LogisticRegression on frequencies data\n\nmodel_evaluation(models['lr'], best_freq['lr'], X_freq, target, test_size_, rnd_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"**As we can see all models have almost the same quality.<br><br>\nSVC model on selected features has the highest precision, but for prediction accounts that more likely to churn LogisticRegression model is slightly better as it has higher recall.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}