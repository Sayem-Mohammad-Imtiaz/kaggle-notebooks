{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 0. Setup"},{"metadata":{},"cell_type":"markdown","source":"### 0.1 Install and load libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom numpy import inf\n\n# time operations\nfrom datetime import timedelta\n\n# for numerical analyiss\nimport numpy as np\n\n# to store and process data in dataframe\nimport pandas as pd\n\n# basic visualization package\nimport matplotlib.pyplot as plt\n\n# interactive visualization\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n# import plotly.figure_factory as ff\n#from plotly.subplots import make_subplots\n\n# for offline ploting\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to interface with operating system\nimport os\n\n# for advanced visualization\nimport seaborn as sns; sns.set()\n\n# for trendlines\nimport statsmodels\n\n# data manipulation\nfrom datetime import datetime as dt\nfrom scipy.stats.mstats import winsorize","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 0.1 Define Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# color pallette\ncnf, dth, rec, act = '#393e46', '#ff2e63', '#21bf73', '#fe9801' ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 0.2 Import Data"},{"metadata":{},"cell_type":"markdown","source":"Please add Covid 19 data from https://www.kaggle.com/imdevskp/corona-virus-report\n\nand Worldometer snapshot data from https://www.kaggle.com/selfishgene/covid19-worldometer-snapshots-since-april-18"},{"metadata":{"trusted":true},"cell_type":"code","source":"# list files\n# ==========\n\n!ls ../input/corona-virus-report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = []\n\nfor dirname, _, filenames in os.walk('../input/korea-econfin-data'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n        \nfiles = sorted(files)\nfiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = [pd.read_csv(f, na_values=['.']) for f in files]\nseries_name = ['btc', 'cpi', 'gold', 'korea', 'high_yield_bond', 'inv_grade_bond', 'moderna', 'employment', 'tesla_robinhood', \n               'trea_20y_bond', 'trea_10y_yield', 'tesla_stock', 'korea_m1', 'wti']\nseries_dict = dict(zip(series_name, series))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 0.3 Wrangle Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# =========\n\nfull_table = pd.read_csv('../input/corona-virus-report/covid_19_clean_complete.csv')\n\n# Deep dive into the DataFrame\n# Examine DataFrame (object type, shape, columns, dtypes)\nfull_table.info()\n\n# type(full_table)\n# full_table.shape\n# full_table.columns\n# full_table.dtypes\n# full_table.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Country wise\n# ============\n\ncountry_wise = pd.read_csv('../input/corona-virus-report/country_wise_latest.csv')\n\n# Replace missing values '' with NAN and then 0\ncountry_wise = country_wise.replace('', np.nan).fillna(0)\n\n# Deep dive into the DataFrame\ncountry_wise.info()\ncountry_wise.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouped by day, country\n# =======================\n\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\nfull_grouped.info()\nfull_grouped.head(10)\n\n# Convert Date from Dtype \"Object\" (or String) to Dtype \"Datetime\"\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\nfull_grouped.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouped by day, country\n# =======================\n\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\nfull_grouped.info()\nfull_grouped.head(10)\n\n# Convert Date from Dtype \"Object\" (or String) to Dtype \"Datetime\"\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\nus_covid = full_grouped[full_grouped['Country/Region']==\"South Korea\"]\nus_covid.info()\nus_covid.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Worldometer data\n# ================\n\nworldometer_data = pd.read_csv('../input/corona-virus-report/worldometer_data.csv')\n\n# Replace missing values '' with NAN and then 0\n# What are the alternatives? Drop or impute. Do they make sense in this context?\nworldometer_data = worldometer_data.replace('', np.nan).fillna(0)\nworldometer_data['Case Positivity'] = round(worldometer_data['TotalCases']/worldometer_data['TotalTests'],2)\nworldometer_data['Case Fatality'] = round(worldometer_data['TotalDeaths']/worldometer_data['TotalCases'],2)\n\n# Case Positivity is infinity when there is zero TotalTests due to division by zero\nworldometer_data[worldometer_data[\"Case Positivity\"] == inf] = 0\n\n# Qcut is quantile cut. Here we specify three equally sized bins and label them low, medium, and high, respectively.\nworldometer_data ['Case Positivity Bin']= pd.qcut(worldometer_data['Case Positivity'], q=3, labels=[\"low\", \"medium\", \"high\"])\n\n# Population Structure\nworldometer_pop_struc = pd.read_csv('../input/covid19-worldometer-snapshots-since-april-18/population_structure_by_age_per_contry.csv')\n\n# Replace missing values with zeros\nworldometer_pop_struc = worldometer_pop_struc.fillna(0)\n#worldometer_pop_struc.info()\n\n# Merge worldometer_data with worldometer_pop_struc\n# Inner means keep only common key values in both datasets\nworldometer_data = worldometer_data.merge(worldometer_pop_struc,how='inner',left_on='Country/Region', right_on='Country')\n\n# Keep observations where column \"Country/Region\" is not 0\nworldometer_data = worldometer_data[worldometer_data[\"Country/Region\"] != 0]\n\n# Inspect worldometer_data's metadata\nworldometer_data.info()\n\n# Inspect Data\n# worldometer_data.info()\n# worldometer_data.tail(20)\n# worldometer_data[\"Case Positivity\"].describe()\nworldometer_data.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"same data from problem set 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Korean KS11 \nkorea = series_dict['korea']\nkorea['Date'] = pd.to_datetime(korea['Date'])\nkorea.rename(columns={'Adj Close':'korea'}, inplace=True)\nkorea['korea_return'] = korea['korea'].pct_change()\nkorea['korea_volatility_1m'] = (korea['korea_return'].rolling(20).std())*(20)**(1/2) \nkorea['korea_volatility_1y'] = (korea['korea_return'].rolling(252).std())*(252)**(1/2) \nkorea = korea[['Date','korea','korea_return','korea_volatility_1m','korea_volatility_1y']]\n# Calculate 1-month forward cumulative returns\nkorea['one_month_forward_korea_return'] = korea['korea_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 2. Bitcoin\nbtc = series_dict['btc']\nbtc['Date'] = pd.to_datetime(btc['Date'])\nbtc.rename(columns={'Adj Close':'btc'}, inplace=True)\nbtc['btc_return'] = btc['btc'].pct_change()\nbtc['btc_volatility_1m'] = (btc['btc_return'].rolling(20).std())*(20)**(1/2) \nbtc['btc_volatility_1y'] = (btc['btc_return'].rolling(252).std())*(252)**(1/2) \nbtc = btc[['Date','btc','btc_return','btc_volatility_1m','btc_volatility_1y']]\nbtc['one_month_forward_btc_return'] = btc['btc_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 3. Gold\ngold = series_dict['gold']\ngold['Date'] = pd.to_datetime(gold['DATE'])\ngold.rename(columns={'GOLDPMGBD228NLBM':'gold'}, inplace=True)\ngold['gold_lag1'] = gold['gold'].shift(1)\ngold['gold_lag2'] = gold['gold'].shift(2)\ngold['gold'] = gold['gold'].fillna(gold['gold_lag1'])\ngold['gold'] = gold['gold'].fillna(gold['gold_lag2'])\ngold[\"gold\"] = gold[\"gold\"].astype('float64')\ngold['gold_return'] = gold['gold'].pct_change()\ngold['gold_volatility_1m'] = (gold['gold_return'].rolling(20).std())*(20)**(1/2) \ngold['gold_volatility_1y'] = (gold['gold_return'].rolling(252).std())*(252)**(1/2) \ngold = gold[['Date','gold','gold_return','gold_volatility_1m','gold_volatility_1y']]\ngold['one_month_forward_gold_return'] = gold['gold_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 4. High Yield Bond\nhigh_yield_bond = series_dict['high_yield_bond']\nhigh_yield_bond['Date'] = pd.to_datetime(high_yield_bond['Date'])\nhigh_yield_bond.rename(columns={'Adj Close':'high_yield_bond'}, inplace=True)\nhigh_yield_bond['high_yield_bond_return'] = high_yield_bond['high_yield_bond'].pct_change()\nhigh_yield_bond['high_yield_bond_volatility_1m'] = (high_yield_bond['high_yield_bond_return'].rolling(20).std())*(20)**(1/2)\nhigh_yield_bond['high_yield_bond_volatility_1y'] = (high_yield_bond['high_yield_bond_return'].rolling(252).std())*(252)**(1/2)\nhigh_yield_bond = high_yield_bond[['Date','high_yield_bond','high_yield_bond_return','high_yield_bond_volatility_1m',\n                                   'high_yield_bond_volatility_1y']]\nhigh_yield_bond['one_month_forward_high_yield_bond_return'] = high_yield_bond['high_yield_bond_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 5. Investment Grade Bond\ninv_grade_bond = series_dict['inv_grade_bond']\ninv_grade_bond['Date'] = pd.to_datetime(inv_grade_bond['Date'])\ninv_grade_bond.rename(columns={'Adj Close':'inv_grade_bond'}, inplace=True)\ninv_grade_bond['inv_grade_bond_return'] = inv_grade_bond['inv_grade_bond'].pct_change()\ninv_grade_bond['inv_grade_bond_volatility_1m'] = (inv_grade_bond['inv_grade_bond_return'].rolling(20).std())*(20)**(1/2)\ninv_grade_bond['inv_grade_bond_volatility_1y'] = (inv_grade_bond['inv_grade_bond_return'].rolling(252).std())*(252)**(1/2)\ninv_grade_bond = inv_grade_bond[['Date','inv_grade_bond','inv_grade_bond_return','inv_grade_bond_volatility_1m',\n                                 'inv_grade_bond_volatility_1y']]\ninv_grade_bond['one_month_forward_inv_grade_bond_return'] = inv_grade_bond['inv_grade_bond_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 6. Crude Oil WTI\nwti = series_dict['wti']\nwti['Date'] = pd.to_datetime(wti['DATE'])\nwti.rename(columns={'WTISPLC':'wti'}, inplace=True)\nwti['wti_return'] = wti['wti'].pct_change()\nwti['wti_volatility_1m'] = wti['wti_return'].rolling(20).std()*(20)**(1/2)\nwti['wti_volatility_1y'] = wti['wti_return'].rolling(252).std()*(252)**(1/2)\nwti = wti[['Date','wti','wti_return','wti_volatility_1m','wti_volatility_1y']]\nwti['one_month_forward_wti_return'] = wti['wti_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"new things to add here"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7. Inflation\ncpi = series_dict['cpi']\ncpi['Date'] = pd.to_datetime(cpi['DATE'])\ncpi.rename(columns={'CUUR0000SEHE':'cpi'}, inplace=True)\ncpi = cpi[['Date','cpi']]\n\n# 8. Korean Employment\nemployment = series_dict['employment']\nemployment['Date'] = pd.to_datetime(employment['DATE'])\nemployment.rename(columns={'PAYEMS_CHG':'employment'}, inplace=True)\nemployment = employment[['Date','employment']]\n\n# 9. Korean\nfed_bs = series_dict['korea_m1']\nfed_bs['Date'] = pd.to_datetime(fed_bs['DATE'])\nfed_bs.rename(columns={'WALCL':'korea_m1'}, inplace=True)\nfed_bs = fed_bs[['Date','korea_m1']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nber_recession_indicator_month = pd.read_csv('../input/nber-based-recession-indicators-united-states/USRECM.csv')\nnber_recession_indicator_day = pd.read_csv('../input/nber-based-recession-indicators-united-states/USRECD.csv')\n\nnber_recession_indicator_day[\"Date\"] = pd.to_datetime(nber_recession_indicator_day[\"date\"])\nnber_recession_indicator_day[\"value\"] = nber_recession_indicator_day[\"value\"].astype('bool')\nnber_recession_indicator_day.rename(columns={'value':'recession'}, inplace=True)\nnber_recession_indicator_day = nber_recession_indicator_day[[\"Date\",\"recession\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline = pd.merge(korea, nber_recession_indicator_day, how='left', on='Date')\nbaseline = pd.merge(baseline, btc, how='left', on='Date')\nbaseline = pd.merge(baseline, cpi, how='left', on='Date')\nbaseline = pd.merge(baseline, gold, how='left', on='Date')\nbaseline = pd.merge(baseline, high_yield_bond, how='left', on='Date')\nbaseline = pd.merge(baseline, inv_grade_bond, how='left', on='Date')\nbaseline = pd.merge(baseline, wti, how='left', on='Date')\nbaseline = pd.merge(baseline, employment, how='left', on='Date')\nbaseline = pd.merge(baseline, fed_bs, how='left', on='Date')\n\nbaseline.loc[baseline.Date >= '2020-03-01', \"recession\"] = 1\nbaseline[\"recession\"] = baseline[\"recession\"].fillna(0)\n#baseline[\"recession\"] = baseline[\"recession\"].astype(int)\n\nbaseline.info()\n\n#2020 covid19 period\nbaseline2020 = baseline[baseline['Date'] >= '2020-01-01']\nbaseline2020 = pd.merge(baseline2020,us_covid, how='left', on='Date')\nbaseline2020['New cases'] = baseline2020['New cases'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. How does Korea's pandemic curve look? "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Boolean indexing to generate a mask which is just a series of boolean values representing whether the column contains the specific element or not\nselected = full_grouped['Country/Region'].str.contains('South Korea')\n\n# Apply this mask to our original DataFrame to filter the required values.\nkorea = full_grouped[selected]\nkorea[\"New active\"] = korea[\"Active\"].diff()\n\nkorea.info()\nkorea.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = korea.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Recovered', 'Deaths', 'Active'],\n                 var_name='Case', value_name='Count')\ntemp.head()\n\n# Plot a stack area graph with the three types of cases (i.e., recovered, deaths, and active)\nfig = px.area(temp, x=\"Date\", y=\"Count\", color='Case', height=600, width=700,\n             title='Cases over time - S. Korea', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1 How does it compare to a country similar to Korea?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Boolean indexing to generate a mask which is just a series of boolean values representing whether the column contains the specific element or not\nselected2 = full_grouped['Country/Region'].str.contains('Denmark')\n\n# Apply this mask to our original DataFrame to filter the required values.\ndenmark = full_grouped[selected2]\ndenmark[\"New active\"] = denmark[\"Active\"].diff()\n\ndenmark.info()\ndenmark.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = denmark.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Recovered', 'Deaths', 'Active'],\n                 var_name='Case', value_name='Count')\ntemp.head()\n\n# Plot a stack area graph with the three types of cases (i.e., recovered, deaths, and active)\nfig = px.area(temp, x=\"Date\", y=\"Count\", color='Case', height=600, width=700,\n             title='Cases over time - Denmark', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 What may explain the similarity or difference?"},{"metadata":{},"cell_type":"markdown","source":"### Similarity:\n\n\n### Difference:\n\n"},{"metadata":{},"cell_type":"markdown","source":"# 2. Are the reported confirmed cases and deaths reliable? Why? "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hbar_wm(col, n, min_pop=50000000, max_pop=100000000):\n    df = worldometer_data[(worldometer_data['Population']>min_pop)&(worldometer_data['Population']<max_pop)]\n    df = df.sort_values(col, ascending=True).tail(n)\n    df.info()\n    fig = px.bar(df,\n                 x=col, y=\"Country/Region\", color='WHO Region',  \n                 text=col, orientation='h', width=700, \n                 color_discrete_sequence = px.colors.qualitative.Dark2)\n    fig.update_layout(title=col+' (Only countries with Population > ' + str(min_pop)+' and < '+str(max_pop), \n                      xaxis_title=\"\", yaxis_title=\"\", \n                      yaxis_categoryorder = 'total ascending',\n                      uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.show()\n    \n# Draw histogram with two arguments\n# 1. variable of interest\n# 2. the number of bins\ndef plot_histogram_wm(col, bins):\n    fig = px.histogram(worldometer_data[col], x=col, nbins=bins)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw bar chart for case fatality of the top 10 countries with the highest case fatality rate (with the close population of Korea)\nplot_hbar_wm('Case Fatality', 10, 40000000,60000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hbar_w(col, n, min_pop=1000000):\n    df = worldometer_data[worldometer_data['Population']>min_pop]\n    df = df.sort_values(col, ascending=True).tail(n)\n    df.info()\n    fig = px.bar(df,\n                 x=col, y=\"Country/Region\", color='WHO Region',  \n                 text=col, orientation='h', width=700, \n                 color_discrete_sequence = px.colors.qualitative.Dark2)\n    fig.update_layout(title=col+' (Only countries with Population > ' + str(min_pop), \n                      xaxis_title=\"\", yaxis_title=\"\", \n                      yaxis_categoryorder = 'total ascending',\n                      uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hbar_w('Tests/1M pop', 15, 1000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hbar_w('Case Positivity', 15, 1000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw the histogram for case fatality rate (50 bins)\nplot_histogram_wm(\"Case Fatality\",50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_histogram_wma(col, bins,n):\n    mi = worldometer_data[worldometer_data['Case Positivity']<n]\n    fig = px.histogram(mi[col], x=col, nbins=bins)\n    fig.show()\nplot_histogram_wma(\"Case Positivity\",50,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_histogram_wmn(col, bins,n):\n    mi = worldometer_data[worldometer_data['Population']>n]\n    fig = px.histogram(mi[col], x=col, nbins=bins)\n    fig.show()\n\nplot_histogram_wmn(\"Tests/1M pop\",50,1000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k1=worldometer_data['Country/Region'].str.contains('S. Korea')\nk2=worldometer_data['Country/Region'].str.contains('Denmark')\nworldometer_data[k1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"worldometer_data[k2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.1 What are the economic and financial impacts of Covid19 on your country?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces to create subplots\nfig.add_trace(\n    go.Scatter(x=baseline2020['Date'], y=baseline2020['korea'], name = 'KS11'),  \n    secondary_y=False,\n)\n\nfig.add_trace(\n    go.Scatter(x=baseline2020['Date'], y=baseline2020['New cases'], name = 'New COVID19 Cases'), \n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"KS11 and New COVID19 Cases\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>KS11</b>\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>New COVID19 Cases</b>\", secondary_y=True)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline['korea_return'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The worst single-day return in 2020 is \", str(round(abs(baseline2020['korea_return'].min()/baseline['korea_return'].std()),2)), \n      \" X standard deviations of KS11 historical returns!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"KS11 historical daily returns from \" + str(baseline[baseline['korea_return'].notnull()]['Date'].min().date()) + ' to '\n       + str(baseline[baseline['korea_return'].notnull()]['Date'].max().date()))\n\nfig = px.histogram(baseline, x=\"korea_return\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_chart(series):\n    fig = px.scatter(baseline[baseline[series].notnull()], x=\"Date\", y=series, color='recession', width=1000)\n    fig.update_traces(mode='markers', marker_size=4)\n    fig.update_layout(title=series, xaxis_title=\"\", yaxis_title=\"\")\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_chart(\"employment\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_chart('korea_m1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.2 What are the plausible reasons for the observed impacts? "},{"metadata":{},"cell_type":"markdown","source":"# 4. What do you want to find out more? What do you find?"},{"metadata":{},"cell_type":"markdown","source":"How to find a country whose COVID-19 condition is close to Korea?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def gt_n(n,m):\n    # Identify countries with confirmed cases greater than m and recovered cases less than n - close condition to Korea\n    # Then among these countries choose the unique set of countries\n    countries = full_grouped[(full_grouped['Recovered']>n) & (full_grouped['Confirmed']<m)]['Country/Region'].unique()\n    \n    # Filter countries that are in the unique set of countries with confirmed cases greater than N\n    temp = full_table[full_table['Country/Region'].isin(countries)]\n    \n    # Aggregate (i.e., sum up) confirmed cases by Country/Region and Date\n    # Reset the index (it is no longer in running order)\n    temp = temp.groupby(['Country/Region', 'Date'])['Confirmed','Recovered'].sum().reset_index()\n    \n    # Filter observations with confirmed cases more than N\n    temp = temp[(temp['Recovered']>n) & (temp['Confirmed']<m)]\n    # print(temp.head())\n\n    # Identify the start date when confirmed cases exceed N for each country\n    min_date = temp.groupby('Country/Region')['Date'].min().reset_index()\n    \n    # Name the columns in the dataframe min_date\n    min_date.columns = ['Country/Region', 'Min Date']\n    # print(min_date.head())\n\n    # Merge dataframe temp with dataframe min_date by 'Country/Region'\n    from_nth_case = pd.merge(temp, min_date, on='Country/Region')\n    \n    # Convert data type to datetime object\n    from_nth_case['Date'] = pd.to_datetime(from_nth_case['Date'])\n    from_nth_case['Min Date'] = pd.to_datetime(from_nth_case['Min Date'])\n    \n    # Create a variable that counts the number of days relative to the day when confirmed cases exceed N\n    from_nth_case['N days'] = (from_nth_case['Date'] - from_nth_case['Min Date']).dt.days\n    # print(from_nth_case.head())\n\n    # Plot a line graph from dataframe from_nth_case with column 'N days' and 'Confirmed' mapped to x-axis and y-axis, respectively.\n    # Distinguish each country by color (system-determined color)\n    # str converts n integer into string and \"'N days from '+ str(n) +' case'\" is the title \n    fig = px.line(from_nth_case, x='N days', y='Confirmed', color='Country/Region', \n                  title='N days from '+ str(n) +' case', height=600)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Call function gt_n with argument 10000,30000 to get information from countries have close condition with Korea\ngt_n(10000,15000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We set the constrain to find out countries with less than 15,000 of confirmed cases and more than 10,000 of recovered cases, and then plot them in the same plot. From the plot above, we found the lines of Denmark and Korea are pretty close."},{"metadata":{},"cell_type":"markdown","source":"# Relation between GDP and Case Positivity & Case Fatality"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}