{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n"},{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\nfrom itertools import combinations\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport scipy.stats as sst\nfrom collections import Counter\nimport re\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfilenames_list = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        filenames_list.append(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nimport os\nprint(os.listdir(\"/kaggle/working\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_pop_filename = '/kaggle/input/world-cities/worldcities.csv'\ncities_pop_filename","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Завернем модель в функцию для того, чтобы было удобнее вызывать\n\ndef model_func(df_preproc):\n    # выделим тестовую часть\n    train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n    test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\n    y = train_data.Rating.values            # наш таргет\n    X = train_data.drop(['Rating'], axis=1)\n    \n    RANDOM_SEED = 42\n    \n    # Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n    # выделим 20% данных на валидацию (параметр test_size)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n\n    # Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n    model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n    \n    # Обучаем модель на тестовом наборе данных\n    model.fit(X_train, y_train)\n\n    # Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n    # Предсказанные значения записываем в переменную y_pred\n    y_pred = model.predict(X_test)\n    \n    result = metrics.mean_absolute_error(y_test, y_pred)\n    \n    # в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n    plt.rcParams['figure.figsize'] = (10,10)\n    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n    feat_importances.nlargest(15).plot(kind='barh')\n    \n    plt.show\n    \n    return result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')\n\n# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана"},{"metadata":{},"cell_type":"markdown","source":"# Предобработка и анализ данных, создание новых признаков"},{"metadata":{},"cell_type":"markdown","source":"## 1. Обработка NAN "},{"metadata":{"trusted":true},"cell_type":"code","source":"# обработаем столбец Number of Reviews\nnumber_rew_nan = pd.isna(data['Number of Reviews']).astype('uint8')\n\nnumber_rew_nan.name = 'number_rew_nan'\nnumber_rew_nan.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Далее заполняем пропуски нулем\n\n#mean = data['Number of Reviews'].mean()\nnumber_rew = data['Number of Reviews'].fillna(0)\n\nnumber_rew.name = 'number_rew'\nnumber_rew.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверим модель на имеющихся числовых признаках без обработки\n\ndf_preproc = pd.concat([data.loc[:,['Rating', 'sample','Ranking']], number_rew, number_rew_nan], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Отклонение предсказания - большое. Попробуем путем предобработки и создания новых признаков улучшить предсказание модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим, что другие числовые столбцы не содержат пропусков, поэтому перейдем к следующему шагу."},{"metadata":{},"cell_type":"markdown","source":"## 2. Создадим новые числовые признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Number of Reviews'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на топ 10 городов\nfor x in (data['City'].value_counts())[0:10].index:\n    data['Ranking'][data['City'] == x].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение. \nПопробуем использовать этот факт для нормализации Ranking."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.City == 'London'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data.City == 'London') & (data.Rating == 5)].loc[:,['Number of Reviews', 'Ranking']].\\\nsort_values('Ranking', ascending = False).iloc[:10,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (5,5))\nsns.jointplot(data = data[(data.City == 'London') & (data.Rating > 0)], x = 'Ranking', y = 'Rating', kind = 'kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получается, что самые популярные рестораны (минимальный Ranking) имеют Rating равный примерно 4 баллам.\nНо есть рестораны с высоким рейтингом 5, но по ранку расположенные примерно посередине. Это будет верно, например, для локальной забегаловки для местных, в которой не много посетителей, но которые все ставят ей стабильно 5.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим признак, который на основании Ranking вычисляет значение Rating. Зависимость линейная\n# f(1) = 5 и f(n) = 1 при f(x) = k*x + b\n\nmax_rank_by_city = data.groupby(['City']).max().Ranking\n\ndef true_rating(row):\n    return round(5 - 4*(1 - row['Ranking'])/(1 - max_rank_by_city[row['City']]),1)\n\ndata['rating_by_rank'] = data.apply(true_rating, axis = 1)\ndata['rating_by_rank'].sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (10,5))\nax = sns.heatmap(data.loc[data.City == 'London',['Rating', 'rating_by_rank']].corr(),annot = True, cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['rating_by_rank'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Новый признак, построенный из Ranking путем лин. преобразования, тем не менее = равномерен и нормален."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data.City == 'London') & (data.Rating == 5)].loc[:,['Number of Reviews', 'Ranking', 'rating_by_rank']].\\\nsort_values('Ranking', ascending = False).iloc[:20,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Number of Reviews','rating_by_rank']], data.loc[:,['Rating', 'sample']]], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"После обработки Ranking предсказание модели значительно улучшилось."},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_by_rank = data['rating_by_rank']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.City == 'London'].loc[:,['Number of Reviews', 'Ranking', 'rating_by_rank','Rating']].\\\nsort_values('rating_by_rank', ascending = True).iloc[:20,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим еще один признак на основе Ranking, проверим, какой работает лучше\n# просто поделим Ranking на макс. значение в городе\n\ndef norm_rank_funk(row):\n    return round(row['Ranking']*100/max_rank_by_city[row['City']],5)\n\nnorm_rank = data.apply(norm_rank_funk, axis = 1)\nnorm_rank.name = 'norm_rank'\nnorm_rank.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_rank.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (5,5))\nplt.boxplot(norm_rank, vert = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Новый признак также не имеет смещений и выбросов.\nПосмотрим на поведение модели на новом признаке"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample']], number_rew, number_rew_nan, norm_rank], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Новый признак не особо повлиял на модель. Оставим для модели признак norm_rank."},{"metadata":{"trusted":true},"cell_type":"code","source":"# среднее количество отзывов в городе\nmean_rews_by_city = round((data.groupby(['City']).sum()['Number of Reviews']\n                           /data.groupby(['City']).max()['Ranking']),2)\n\nmean_rews = data.City.apply(lambda x: mean_rews_by_city[x])\nmean_rews.name = 'mean_rews'\nmean_rews.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# два признака для количества ресторанов в городе, один на основе макс Ranking, другой просто по количеству записей в городе\n\nmax_rank = data.City.apply(lambda x: max_rank_by_city[x])\nmax_rank.name = 'max_rank'\n\nplaces_counts_by_sity = data.groupby(['City']).count().Ranking\nplaces_counts = data.City.apply(lambda x: places_counts_by_sity[x])\nplaces_counts.name = 'places_counts'\n\npd.concat([max_rank, places_counts], axis = 1).sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample']], number_rew, number_rew_nan, norm_rank, mean_rews, places_counts], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Модель улучшилась."},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на Restaurant_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.Restaurant_id.value_counts()[:50])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В датасете встречаются рестораны с одинаковыми Restaurant_id. Судя по всему, эти рестораны пренадлежат одной сети. Сделаем новый признак."},{"metadata":{"trusted":true},"cell_type":"code","source":"nets = data.Restaurant_id.value_counts()\nrests_by_id = data.Restaurant_id.apply(lambda x: nets[x])\nrests_by_id.name = 'rests_by_id'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([data.Restaurant_id,rests_by_id],axis = 1).sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample']], number_rew, number_rew_nan, norm_rank, mean_rews, places_counts,\\\n                        max_rank, rests_by_id], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на ID_TA"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[data.ID_TA == 'd3161682'].iloc[0].URL_TA)\nprint(data[data.ID_TA == 'd3161682'].iloc[1].URL_TA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.ID_TA.duplicated().value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В датасете есть рестораны с одинаковыми ID_TA, посмотрим на них"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.ID_TA.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Все эти рестораны их Мадрида и Варшавы, что странно."},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = data[data.ID_TA.duplicated()].ID_TA.values\ndef is_dubl(item):\n    if item in ids:\n        return True\n    else:\n        return False\n\n# посмотирм на пары этих дублей    \nfor id_ta in ids:\n    display(data[data.ID_TA == id_ta])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Анализ пар показал, что это все-таки дубли. Прометим их и посмотрим, как ведет себя при этом модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"# определим функцию для прометки дублей\ndef mark_dubl(row):\n    id_ta = row.ID_TA\n    ind = row.name\n    if id_ta in ids:\n        ind0 = data[data['ID_TA'] == id_ta].index.tolist()[0]\n        ind1 = data[data['ID_TA'] == id_ta].index.tolist()[1]\n        row0 = data[data['ID_TA'] == id_ta].iloc[0]\n        row1 = data[data['ID_TA'] == id_ta].iloc[1]\n        if (row0['sample'] == 0) and (row1['sample'] == 0):\n            if row0.Ranking >= row1.Ranking:\n                if ind0 == ind:\n                    return 0\n                else:\n                    return 1\n            else:\n                if ind0 == ind:\n                    return 1\n                else:\n                    return 0\n\n        elif (row0['sample'] == 1) and (row1['sample'] == 0):\n            if ind0 == ind:\n                return 1\n            else:\n                return 0\n            return 1\n        elif (row0['sample'] == 0) and (row1['sample'] == 1):\n            if ind0 == ind:\n                return 0\n            else:\n                return 1\n        elif (row0['sample'] == 1) and (row1['sample'] == 1):\n            if row0.Ranking >= row1.Ranking:\n                if ind0 == ind:\n                    return 0\n                else:\n                    return 1\n            else:\n                if ind0 == ind:\n                    return 1\n                else:\n                    return 0\n    else:\n        return 0\ndata['dubl'] = data.apply(mark_dubl, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверим, как прометились дубли\nfor id_ta in ids:\n    display(data[data.ID_TA == id_ta])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['dubl'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'dubl']], number_rew, number_rew_nan, norm_rank, mean_rews, places_counts,\\\n                        rests_by_id], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Предсказание немного улучшилось"},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на  URL_TA"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.URL_TA.duplicated().value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Дубли мы уже прометили, посмотрим поближе на значения"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[4:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проанализируем значение ***gNNNNNN*** из url"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['url_g'] = data.URL_TA.str.extract(r'(g\\d+)')\ndata['url_g'] = data.url_g.apply(lambda x: int(x[1:]))\ndata['url_g'].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['url_g'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['City'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['url_g'] == 6919449]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['url_g'].duplicated()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Судя по всему, реквизит url_g содержит код населенного пункта на tadvisor"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.url_g.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.City.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = data.groupby(['City'])\ncities['url_g'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_gcnt = cities['url_g'].value_counts()\ncities_gcnt['Brussels'][188644]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def g_cnt(row):\n    return cities_gcnt[row['City']][row['url_g']]\n\ndata['district_cnt'] = data.apply(g_cnt, axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['district_cnt'].sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt']], number_rew, number_rew_nan, norm_rank, mean_rews, places_counts,\\\n                        rests_by_id], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"С новым реквизитом предсказание немного улучшилось"},{"metadata":{},"cell_type":"markdown","source":"### Склеим все новые признаки и посмотирм на матрицу корреляции"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (10,5))\nax = sns.heatmap(df_preproc.corr(),annot = True, cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Очевидно, что признаки norm_rank и rating_by_rank имеют корреляцию = -1, так как получены один из другого путем линейного преобразования."},{"metadata":{},"cell_type":"markdown","source":"## 3. Обработка категориальных признаков\nДля начала посмотрим какие признаки у нас могут быть категориальными."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на признак City. Является ли он значимым для модели?"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_cities = data.City.value_counts().index\n\nfig, ax = plt.subplots(figsize = (15, 5))\n\nsns.boxplot(x='City', y='Rating',data=data[data.Rating > 0],ax=ax)\n\nplt.xticks(rotation=45)\nax.set_title('Boxplot for City')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак, очевидно, значим для определения Rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"# выделим список с городами, боксплоты которых отличаются от остальных\nphen_cities = [ i for i in all_cities if data[data.City == i].quantile(q = 0.75).Rating - data[data.City == i].quantile(q = 0.25).Rating != 1.5]\nphen_cities  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1. Сконструируем dummy-признаки из City"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.City.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим отдельный признак с городами, у которых боксплоты отличаются от остальных\n\ndata['phen_cities'] = data.City.apply(lambda x: x if x in phen_cities else 'other')\ndata['phen_cities'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# воспользуемся get_dummies\n\ncities = pd.get_dummies(data.City, columns=[ 'City'])\ncities.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phen_cities_dummy = pd.get_dummies(data.phen_cities, columns=[ 'phen_cities'])\nphen_cities_dummy.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверим дамми признаки на модели\n\ndf_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt']], number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, \\\n                        rests_by_id, cities], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Модель дает более точное предсказание на всех городах. Оставим для модели cities"},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Обработаем признак \"Price Range\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Пропусков в цене много. Выделим пропуски в цене в отдельный признак\n\nprice_isnan = pd.isna(data['Price Range']).astype('uint8')\nprice_isnan.name = 'price_isnan'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим функцию для заполнения Price Range\n\ndef price_ordinal(price):\n    if price == '$':\n        result = 1\n    elif price == '$$ - $$$':\n        result = 2\n    elif price == '$$$$':\n        result = 3\n    else:\n        result = 0\n    return result\n\nprices = data['Price Range'].apply(price_ordinal)\nprices.name = 'prices'\n\nprices.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверим модель с обработанной ценой\n\ndf_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt']], number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, \\\n                        rests_by_id, cities,\\\n                        prices, price_isnan], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3. Обработаем Cuisine Style"},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим, сколько всего стилей кухни встречается датасете\n\ncuisine_styles = Counter()\n\nfor i in data['Cuisine Style'].dropna():\n    l = re.sub('\\s\\'|\\'','', i)[1:-1].split(',')\n    cuisine_styles.update(l)\n\ncuisines = [x[0] for x in cuisine_styles.most_common()]\n\nlen(cuisines)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_styles.most_common()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisines_groups = {\n    'healty': ['Vegetarian Friendly', 'Gluten Free Options', 'Healthy', 'Vegan Options'],\n    'taboo' : ['Halal', 'Kosher'],\n    'seafood' : ['Seafood'],\n    'alco' : ['Bar', 'Pub', 'Wine Bar', 'Gastropub', 'Brew Pub'],\n    'fast' : ['Cafe', 'Fast Food', 'Diner', 'Street Food'],\n    'other' : ['International', 'Fusion', 'Contemporary', 'Delicatessen'],\n    'italian' : ['Italian', 'Pizza'],\n    'eurapian' : ['European', 'Mediterranean', 'Italian', 'French', 'Spanish', 'British', 'Central European', 'Portuguese',\\\n           'German', 'Greek', 'Czech', 'Eastern European', 'Austrian', 'Polish', 'Scandinavian', 'Hungarian',\\\n           'Dutch', 'Irish', 'Belgian', 'Danish', 'Swiss', 'Swedish', 'Scottish', 'Norwegian',\\\n           'Slovenian', 'Russian', 'Croatian', 'Ukrainian', 'Romanian', 'Albanian', 'Welsh', 'Latvian'],\n    'asian' : ['Asian', 'Japanese', 'Sushi', 'Chinese', 'Indian',  'Thai', 'Vietnamese', 'Korean', 'Pakistani', 'Nepali'\\\n         , 'Balti', 'Bangladeshi', 'Indonesian', 'Malaysian', 'Sri Lankan', 'Taiwanese', 'Tibetan',\\\n         'Cambodian', 'Singaporean', 'Mongolian', 'Filipino', 'Minority Chinese', 'Central Asian', 'Yunnan', \\\n         'Xinjiang'],\n    'steak' : ['Steakhouse', 'Barbecue', 'Grill'],\n    'eastern' : ['Middle Eastern', 'Turkish', 'Lebanese', 'Israeli', 'Persian', 'Arabic', 'Afghani', 'Uzbek'],\n    'african' : ['African', 'Moroccan', 'Ethiopian', 'Egyptian', 'Tunisian'],\n    'australian' : ['Australian', 'New Zealand'],\n    'american' : ['American', 'Canadian'],\n    'latamerican' : ['Mexican', 'South American', 'Latin', 'Argentinean', 'Central American', 'Brazilian', 'Peruvian',\\\n               'Venezuelan', 'Jamaican', 'Cuban', 'Colombian', 'Cajun & Creole', 'Southwestern',\\\n               'Chilean', 'Ecuadorean', 'Native American', 'Salvadoran'],\n    'exotic' : ['Hawaiian', 'Polynesian', 'Jamaican', 'Cuban', 'Fujian', 'Burmese', 'Caribbean'],\n    'сaucas' : ['Georgian', 'Armenian', 'Caucasian', 'Azerbaijani']\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisines_groups['asian']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_most_common = [x[0] for x in cuisine_styles.most_common()[:10]]\ncuisine_most_common","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# превратим Cuisine Style в список\n\ncuisine_style = data['Cuisine Style'].apply(lambda x: ['other_style'] if pd.isnull(x) else x[1:-1].split(',') )\ncuisine_style.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,k in enumerate(cuisine_style):\n    new_list = []\n    for j in k:\n        j = re.sub('\\s\\'|\\'','', j)\n        new_list.append(j)\n    cuisine_style.at[i] = new_list\ncuisine_style.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# добавим новый признак \"Количество кухонь в ресторане\"\n\ncuisine_counts = cuisine_style.apply(lambda x: len(x))\ncuisine_counts.name = 'cuisine_counts'\n\ncuisine_counts.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cuisines_groups.keys():\n    s1 = set(cuisines_groups[col])\n    data[col] = cuisine_style.apply(lambda x: len(s1.intersection(set(x))))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisines_cols = data.loc[:,cuisines_groups.keys()]\ncuisines_cols.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Изменим столбец Cuisine Style так: если стиль кухни ресторана попадает в самые частые значения, то оставляем его, если нет, меняем на other_style"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,k in enumerate(cuisine_style):\n    new_list = []\n    for j in k:\n        if j in cuisine_most_common:\n            new_list.append(j)\n        else:\n            new_list.append('other_style')\n    cuisine_style.at[i] = new_list\ncuisine_style.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь добавим новые признаки, соответсвующие самым частым значениям стилей кухонь"},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_style_df = pd.DataFrame(cuisine_style)\nfor i in cuisine_most_common + ['other_style']:\n    cuisine_style_df[i] = cuisine_style.apply(lambda x: 1 if i in x else 0).astype('uint8')\n\ncuisine_style_df.drop('Cuisine Style', axis = 1, inplace=True)\n\ncuisine_style_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_style_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisines_cols.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt']], number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, rests_by_id, \\\n                        cities,\n                        prices, price_isnan, \\\n                        cuisines_cols\n                       ], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Cuisine Style'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Cuisine Style'].fillna('other_style', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 3.4. Теперь обработаем Reviews\nВыделим даты обзоров и посчитаем, сколько времени прошло между двумя обзорами"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['rew_dates'] = data.Reviews.apply(lambda x : [0] if pd.isna(x) else x[2:-2].split('], [')[1][1:-1].split(\"', '\"))\ndata['max_rew_date'] = pd.to_datetime(data['rew_dates'].apply(lambda x: max(x)))\n\ndata['first_rew'] = pd.to_datetime(data['rew_dates'].apply(lambda x : x[0]))\ndata['second_rew'] = pd.to_datetime(data['rew_dates'].apply(lambda x: x[1] if len(x) == 2 else ''))\n\nrew_delta = np.abs(data['first_rew'] - data['second_rew'])\nrew_delta = rew_delta.apply(lambda x: x.days)\n\nrew_delta.name = 'rew_delta'\n\nrew_delta.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rew_delta.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пропусокв очень много, выделим отдельный признак для них"},{"metadata":{"trusted":true},"cell_type":"code","source":"# пустых значений много, сделаем новый признак для NAN\nrew_delta_isnan = pd.isna(rew_delta).astype('uint8')\n\nrew_delta_isnan.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заполним пропуски средним\n\nmean = round(rew_delta.mean(), 2)\nrew_delta = rew_delta.fillna(mean)\nrew_delta.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Создадим еще один признак для даты: количество дней, прошедшее между текущей датой и последним отзывом"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\nrew_delta_cur = (datetime.now() - data['max_rew_date'])\nrew_delta_cur = rew_delta_cur.fillna(rew_delta_cur.median())\n\nrew_delta_cur = rew_delta_cur.apply(lambda x : x.days)\n\nrew_delta_cur.name = 'rew_delta_cur'\n\nrew_delta_cur.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt']], number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, rests_by_id, \\\n                        cities,\n                        prices, price_isnan, \\\n                        cuisine_counts, cuisines_cols, \\\n                        rew_delta, rew_delta_cur,rew_delta_isnan\n                       ], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.5. Сконструируем новый признак \"Население города\" на основе внешних данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_add = pd.read_csv(cities_pop_filename)\ndata_add.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info = pd.DataFrame(data.City.value_counts().index)\ncities_info.columns = ['city']\ncities_info.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_europe = data_add[data_add.iso2.apply(lambda x: x not in ('US','CA','VE'))]\ndata_europe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_country = cities_info.merge(data_europe, how = 'left', on = 'city').loc[:, ['city', 'iso2']]\ncities_country.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_country[cities_country.iso2.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_country.at[23,'iso2'] = 'PT'\ncities_country.at[25,'iso2'] = 'PL'\ncities_country.at[22,'iso2'] = 'CH'\ncities_country.at[19,'iso2'] = 'DK'\ncities_country.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info = cities_info.merge(data_europe.loc[:,['city','capital', 'population']], how = 'left', on = 'city')\ncities_info.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info['capital'] = cities_info.capital.fillna('not_cap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info[cities_info.population.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# заполним пропуски в населении и странах\ncities_info.at[23,'population'] = 237591\ncities_info.at[25,'population'] = 769498\ncities_info.at[22,'population'] = 428737\ncities_info.at[19,'population'] = 615993","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info.columns =  ['City', 'capital', 'population']\ncities_country.columns = ['City', 'country']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# объединим с исходным датасетом\n\ncities_pop = data.loc[:,['City']].merge(cities_info, how = 'left', on = 'City')\n\ncities_pop.drop(['City'], axis = 1, inplace = True)\n\ncities_pop.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_capital = pd.get_dummies(cities_pop.capital)\ncities_pop.drop(['capital'], axis = 1, inplace = True)\n\ncities_capital.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# добавим дамми признаки для стран\ncountries = data.loc[:,['City']].merge(cities_country, how = 'left', on = 'City')\n\ncountries.drop(['City'], axis = 1, inplace = True)\ncountries.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = pd.get_dummies(countries)\ncountries.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt']], number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, rests_by_id, \\\n                        cities,\n                        prices, price_isnan, \\\n                        cuisine_counts, cuisines_cols, \\\n                        rew_delta, rew_delta_cur,rew_delta_isnan,\n                        cities_pop, cities_capital, countries\n                       ], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6. Количество туристов"},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_info['City']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# заведем словарь для гоордов с новыми данными [кол-во млн. туристов, место в рейтенге благосостояния] по данным из wiki\nth = {\n    'London' : [19233, 14],\n    'Paris' : [17560, 18],\n    'Madrid' : [5440, 19],\n    'Barcelona' : [6714, 19],\n    'Berlin' : [5959, 15],\n    'Milan' : [6481, 24],\n    'Rome' : [10065, 24],\n    'Prague' : [8949, 22],\n    'Lisbon' : [3539, 29],\n    'Vienna' : [6410, 2],\n    'Amsterdam' : [8354, 7],\n    'Brussels' : [3942, 13],\n    'Hamburg' : [1450, 15],\n    'Munich' : [4067, 15],\n    'Lyon' : [6000, 18],\n    'Stockholm' : [2605, 8],\n    'Budapest' : [3823, 31],\n    'Warsaw' : [2850, 27],\n    'Dublin' : [5213, 16],\n    'Copenhagen' : [3070, 5],\n    'Athens' : [5728, 36],\n    'Edinburgh' : [1660, 14],\n    'Zurich' : [2240, 6],\n    'Oporto' : [2341, 29],\n    'Geneva' : [1150, 6],\n    'Krakow' : [2732, 27],\n    'Oslo' : [1400, 1],\n    'Helsinki' : [1240, 9],\n    'Bratislava' : [126, 26],\n    'Luxembourg' : [1139, 11],\n    'Ljubljana' : [5900, 20]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tourists = data.City.apply(lambda x : th[x][0])\ntourists.name = 'tourists'\n\nhapiness = data.City.apply(lambda x : th[x][1])\nhapiness.name = 'hapiness'\n\ntourists\nhapiness","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt']], number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, rests_by_id, \\\n                        cities,\n                        prices, price_isnan, \\\n                        cuisine_counts, cuisines_cols, \\\n                        rew_delta, rew_delta_cur,rew_delta_isnan,\n                        cities_pop, cities_capital, countries,\n                        tourists, hapiness\n                       ], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.7. Построим на основе текстов обзоров новые признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# выделим текст обзоров для последующего анализа.\ndata['rew_texts'] = data.Reviews.apply(lambda x : '' if pd.isna(x) else x[2:-2].split('], [')[0])\n\nrew_texts_list = data['rew_texts'].apply(lambda x : [''] if x == '' else x.split(\"', '\"))\n\ndata['first_text'] = rew_texts_list.apply(lambda x : x[0][1:-1] if len(x) == 1 else x[0][1:] if len(x) == 2 else '')\ndata['second_text'] = rew_texts_list.apply(lambda x: x[1][:-1] if len(x) == 2 else '')\n\ndata.loc[:,['Reviews', 'rew_texts', 'first_text', 'second_text']].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rew_counts_func(row):\n    result = 0 if row['rew_texts'] == ''  else 1 if row['second_text'] == '' else 2\n    return result\n    \nrew_counts = data.apply(rew_counts_func, axis = 1)\nrew_counts.name = 'rew_counts'\n\npd.concat([rew_counts, data['rew_texts']], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rew_counts.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# количество слов в отзывах\n\nwords_count = data['rew_texts'].apply(lambda x : len(x.split()))\n\nwords_count.name = 'words_count'\npd.concat([rew_counts, data['rew_texts'], words_count], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_words = Counter()\n\nfor i in (data['first_text'].str.split() + data['second_text'].str.split()):\n    all_words.update(i)\n\nwords = [x[0] for x in all_words.most_common()]\n\nall_words.most_common()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive = ['fine', 'better', 'great', 'good', 'nice', 'excellent', 'best', 'lovely', 'delicious',\\\n            'amazing', 'friendly', 'atmosphere', 'tasty',  'perfect', 'wonderful', 'super', 'top','cosy',\\\n            'beautiful', 'pleasant', 'brilliant', 'fantastic', 'cool', 'outstanding','favorite',\\\n            'enjoyable', 'welcome', 'incredible', 'awesome', 'charming', 'original'\n           ]\nnegative = ['worth','bad', 'poor', 'terrible', 'slow', 'worst','disappointing', 'overpriced', 'awful',\\\n            'rude','horrible', 'too'\n           ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_rew(rew):\n    sent = rew.split()\n    new_sent = []\n    for word in sent:\n        if re.search('\\w+', word.lower()) is None:\n            continue\n        else:\n            new_word = re.search('\\w+', word.lower()).group(0)\n            new_sent.append(new_word)\n    return new_sent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['rew_texts1'] = data.rew_texts.apply(format_rew)\ndata.loc[:,['rew_texts','rew_texts1']].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tone_pos(item):\n    cnt = 0\n    for word in positive:\n        if word in item:\n            cnt +=1\n    return cnt\n\ndef tone_neg(item):\n    cnt = 0\n    for word in negative:\n        if word in item:\n            cnt +=1\n    return cnt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['rew_pos'] = data.rew_texts1.apply(tone_pos)\ndata['rew_neg'] = data.rew_texts1.apply(tone_neg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[:,['rew_texts1', 'rew_pos', 'rew_neg']].sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt','rew_pos', 'rew_neg']], \\\n                        number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, rests_by_id, \\\n                        cities,\n                        prices, price_isnan, \\\n                        cuisine_counts, , \\\n                        rew_delta, rew_delta_cur,rew_cuisines_colsdelta_isnan,\n                        cities_pop, cities_capital, countries,\n                        tourists, hapiness,\n                        rew_counts\n                       ], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Количество слов модель ухудшило. А количество отзывов - наоборот. Оставим признак rew_counts"},{"metadata":{},"cell_type":"markdown","source":"### 3.8. На основе признаков population, tourists и Number of Reviews построим новые признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на корреляцию признаков\n\nX = pd.concat([number_rew, cities_pop, tourists, data['Rating']], axis = 1)\n\nfig, ax = plt.subplots(1,1, figsize = (10,5))\nax = sns.heatmap(X.corr(),annot = True, cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Количество туристов и население города очень сильно положительно скоррелированы.\nПопробуем использовать главную компоненту вместо этого признака.\nСначала нормируем признаки."},{"metadata":{},"cell_type":"markdown","source":"# Final model test"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = pd.concat([data.loc[:,['Rating', 'sample', 'district_cnt','rew_pos', 'rew_neg']], \\\n                        number_rew, number_rew_nan,\\\n                        norm_rank, mean_rews, rests_by_id, \\\n                        cities,\n                        prices, price_isnan, \\\n                        cuisine_counts, cuisines_cols, \\\n                        rew_delta, rew_delta_cur,rew_delta_isnan,\n                        cities_pop, cities_capital, countries,\n                        tourists, hapiness,\n                        rew_counts\n                       ], axis = 1)\nmodel_func(df_preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nготовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"# выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values           # наш таргет\nX = train_data.drop(['Rating'], axis=1)\n    \nRANDOM_SEED = 42\n    \n# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n\n# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators= 200, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n    \n# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)\n\ny_pred = np.round(y_pred * 2) / 2\nprint('MAE: ',metrics.mean_absolute_error(y_test, y_pred))\n    \n# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)\nsample_submission.Rating","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обратила внимание, что Rating в датасете - заполняет значения от 1 до 5 с шагом 0.5. Поэтому, если округлить предсказание до ближайшеего x.5 числа, то предсказание улучшится."},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = np.round(predict_submission * 2)/2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}