{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#/kaggle/input/the-great-indian-hiring-hackathon/Participants_Data_TGIH/Test.csv\n#/kaggle/input/the-great-indian-hiring-hackathon/Participants_Data_TGIH/Sample Submission.csv\n#/kaggle/input/the-great-indian-hiring-hackathon/Participants_Data_TGIH/Train.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/the-great-indian-hiring-hackathon/Participants_Data_TGIH/Train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=pd.read_csv(\"/kaggle/input/the-great-indian-hiring-hackathon/Participants_Data_TGIH/Test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['first_2_CID']=df['CustomerID'].apply(lambda x: int(str(x)[:2]))   \n# extract the first two number of the customerid\ndf1['first_2_CID']=df1['CustomerID'].apply(lambda x: int(str(x)[:2])) \n#feature extrzction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #there are no null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"InvoiceDate\"]=pd.to_datetime(df[\"InvoiceDate\"])\ndf1[\"InvoiceDate\"]=pd.to_datetime(df1[\"InvoiceDate\"]) #change to date type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"InvoiceDateO\"]=df[\"InvoiceDate\"].apply(lambda x: x.toordinal())\ndf1[\"InvoiceDateO\"]=df1[\"InvoiceDate\"].apply(lambda x: x.toordinal()) #change date to ordinal data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.InvoiceNo.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df=df.sort_values(\"StockCode\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df[df[\"InvoiceDate\"].dt.month==12]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() #all data type is now correct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df1[df1['Country']==35]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df[['InvoiceNo', 'StockCode', 'Description', 'Quantity',\n       'UnitPrice', 'CustomerID', 'Country','InvoiceDateO']].columns:\n    sns.boxplot(df[i])\n    plt.show() #check for outliers \n#looks like quantity and unitprice has some outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"UnitPrice\"]>5000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df[df['InvoiceDateO']==734298]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.drop(labels=[239556],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using this value because the data is randomly selected in for training and testing so outliers can be used for trees based algorithm you will know more which algorithm is suitable at the bottom"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df[df[\"UnitPrice\"]>10000].index,inplace=True) \n#df.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df[df[\"UnitPrice\"]==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df1[df1['Quantity']<0] \n#quantity cannot be negative it could be a grabage or the quantity is by mistake negative","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Quantity']=df['Quantity'].abs()\ndf1['Quantity']=df1['Quantity'].abs()\n#quantity has negative which is invalid and also they are not garbage value \n#converting them to positive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.drop(df[df[\"Quantity\"]>10000].index,inplace=True) #10k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"linear correlation is very less w.r.t unitprice with every variable so there could be a \nnon linear correlation "},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr, pearsonr\nspearmanr(df['UnitPrice'], df['Quantity']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"unit price and quantity has high non linear correlation after checking with all the other variables ([Spearman-RankCorrelation](http://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient))"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(17,7))\nsns.scatterplot(x=\"Country\",y=\"UnitPrice\",data=df)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****In country 35 ,14 and 30 there are comparatively high unit price****"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(17,7))\nsns.scatterplot(x=\"CustomerID\",y=\"UnitPrice\",data=df) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Low customer id has also high unit price with low prices****"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(17,7))\nsns.scatterplot(x=\"StockCode\",y=\"UnitPrice\",data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****3700 or 3800 has also high unit price with low unitprice****"},{"metadata":{},"cell_type":"markdown","source":"# Data Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df[['InvoiceDateO','Quantity','StockCode', 'Description','Country','first_2_CID']]\ny_train=df1[['InvoiceDateO','Quantity','StockCode', 'Description',  'Country', 'first_2_CID']]\nX_test=df['UnitPrice'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nX_train = sc.fit_transform(X_train)\ny_train = sc.fit_transform(y_train)\n#X_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ML Algorithms"},{"metadata":{},"cell_type":"markdown","source":" ### Compared all algorithm and got extra trees regressor with high accuracy as they use all their data in making trees                   "},{"metadata":{},"cell_type":"markdown","source":"### You can see the other algorithm used in the appendix section"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import cross_val_score\nextra1=ExtraTreesRegressor(max_depth=200,\n  n_estimators=200)\nextra1.fit(X_train,X_test)\nnp.mean(cross_val_score(extra1,X_train,X_test,scoring = 'neg_mean_squared_error', cv= 3))#36.9 #7.5569158 #.3212 #7.55609","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = extra1.predict(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['UnitPrice']=results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['UnitPrice'].to_csv(\"Submission_Final.csv\",header=True,index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Used genetic algorithm for optimization for extra tree"},{"metadata":{"trusted":false},"cell_type":"code","source":"#from tpot import TPOTRegressor\n\n\n#tpot_classifier = TPOTRegressor(generations= 5, population_size= 24, offspring_size= 12,\n#                                 verbosity= 2, early_stop= 12,\n#                                 config_dict={'sklearn.ensemble.ExtraTreesRegressor': param}, \n#                                 cv = 2)\n#tpot_classifier.fit(X_train,X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#results=tpot_classifier.predict(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#tpot_classifier.fitted_pipeline_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#tpot.score(X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#tpot.export(path_to_pipeline)\n#pickle.dump(tpot.fitted_pipeline_, open(file_name, ‘wb’))\n#import pickle\n#tpot.score(X_train, X_test)\n#pickle.dump(tpot.fitted_pipeline_, open(\"tpot.pkl\", \"wb\"))\n#tpot.export(\"tpot.py\")\n#tpot.export()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Appendix"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nclassifier = KNeighborsRegressor(n_neighbors = 1, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, X_test)\ny_pred=classifier.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred))#36.9","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom sklearn.model_selection import cross_val_score\nmodel = CatBoostRegressor(\nmax_depth=10,\n        n_estimators=100,\n        learning_rate=1)\nmodel.fit( X_train,X_test, use_best_model=True, silent=True )\ny_pred=model.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred))#36.9","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nRegressor = DecisionTreeRegressor(criterion='mse')\nRegressor.fit(X_train, X_test)\nnp.mean(cross_val_score(Regressor,X_train,X_test, scoring = 'neg_mean_squared_error', cv= 3)) #145.88","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred=Regressor.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(X_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf =  RandomForestRegressor(300)\nrf.fit(X_train, X_test)\n#np.mean(cross_val_score(rf,X_train,X_test,scoring = 'neg_mean_squared_error', cv= 3)) #124\ny_pred=rf.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred))#36.9","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression().fit(X_train, X_test)\ny_pred=rf.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred))#36.9","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Lasso, Ridge\nalpha = []\nerror = []\n\nfor i in range(1,1000):\n    alpha.append(i/1)\n    lml = Lasso(alpha=(i/1))\n    error.append(np.mean(cross_val_score(lml,X_train,X_test, scoring = 'neg_mean_absolute_error', cv= 3)))\n    \nplt.plot(alpha,error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"err = tuple(zip(alpha,error))\ndf_err = pd.DataFrame(err, columns = ['alpha','error'])\ndf_err[df_err.error == max(df_err.error)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lm_l = Lasso(alpha=581.0)\nlm_l.fit(X_train,X_test)\ny_pred=lm_l.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\nmodel = XGBRegressor(  \n        max_depth=100,\n        n_estimators=200,\n        learning_rate=1.5,bootstrap=False\n        )\nmodel.fit(X_train, X_test)\n#np.mean(cross_val_score(model,X_train,X_test,scoring = 'neg_mean_squared_error', cv= 3)) #103\n#max_depth=6, min_child_weight=3, nthread=1,objective='reg:squarederror', subsample=0.8\ny_pred=model.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred)) #6.4 #5.769 #33.5295 #57.106 #7.556915879158611","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\nclassifier = AdaBoostRegressor( \n        n_estimators=100,\n        learning_rate=1)\nclassifier.fit(X_train, X_test)\n#np.mean(cross_val_score(classifier,X_train,X_test,scoring = 'neg_mean_squared_error', cv= 3))\ny_pred=classifier.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngb_clf = GradientBoostingRegressor(\n        max_depth=20,\n        n_estimators=100,\n        learning_rate=1)\ngb_clf.fit(X_train, X_test)\n#np.mean(cross_val_score(gb_clf,X_train,X_test,scoring = 'neg_mean_squared_error', cv= 3))\ny_pred=gb_clf.predict(X_train)\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(X_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n#d_train = lgb.Dataset(X_train, label=X_test)\n#X_train, X_test, y_train, y_test = train_test_split( X_train, X_test, test_size=0.2, random_state=42)\nhyper_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': ['l2', 'auc'],\n    'learning_rate': 0.5,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 10,\n    'verbose': 0,\n    \"max_depth\": 8,\n    \"num_leaves\": 128,  \n    \"max_bin\": 512,\n    \"num_iterations\": 100,\n    \"n_estimators\": 100\n}\ngbm = lgb.LGBMRegressor(**hyper_params)\ngbm.fit(X_train, X_test,\n        eval_set=[(X_train, X_test)],\n        eval_metric='l1',\n        early_stopping_rounds=100)\nnp.mean(cross_val_score(gbm,X_train,X_test,scoring = 'neg_mean_squared_error', cv= 3)) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}