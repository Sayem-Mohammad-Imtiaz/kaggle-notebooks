{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conda install -c plotly plotly-orca==1.2.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import rcParams\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nfrom collections import Counter\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom wordcloud import WordCloud\nfrom datetime import datetime\nimport plotly","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"restarant_names = pd.read_csv(\"/kaggle/input/zomato-restaurants-hyderabad/Restaurant reviews.csv\")\nreviews = pd.read_csv(\"/kaggle/input/zomato-restaurants-hyderabad/Restaurant names and Metadata.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names[\"Restaurant\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams[\"figure.figsize\"] = 50,10\nsns.countplot(x=\"Restaurant\",hue=\"Rating\",data=restarant_names[:300])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names[\"Rating\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_review_rating(Rating):\n    if Rating==\"1.5\":\n        Rating =1\n    elif Rating == \"1\":\n        Rating =1\n    elif Rating ==\"2.5\":\n        Rating = 2\n    elif Rating ==\"2\":\n        Rating = 2\n    elif Rating ==\"3.5\":\n        Rating = 3\n    elif Rating ==\"3\":\n        Rating = 3\n    elif Rating == \"4.5\":\n        Rating = 4\n    elif Rating ==\"4\":\n        Rating = 4\n    elif Rating ==\"5\":\n        Rating = 5\n    elif Rating ==\"Like\":\n        Rating = 5\n    return Rating","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names[\"Rating\"] = restarant_names[\"Rating\"].apply(convert_review_rating)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(restarant_names[\"Rating\"])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rcParams[\"figure.figsize\"]  =15,10\n# restarant_names[\"Rating\"].value_counts().plot(kind=\"pie\")\nfig = px.pie(values=restarant_names[\"Rating\"].value_counts(),hover_name=[5.0,4.0,3.0,2.0,1.0],title=\"Hotel Rating Distribution\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.sort_values(by=['Rating'], inplace=True,ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dowinng_10 = restarant_names[restarant_names[\"Restaurant\"]==\"10 Downing Street\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams[\"figure.figsize\"] = 20,10\nsns.countplot(x=Dowinng_10[\"Restaurant\"],hue=Dowinng_10[\"Rating\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(restarant_names.Reviewer))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## There are totally 1000 data points and has almost 7447 unique reviewers and only remaining people are regular reviewers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Five star Hotels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"five_start_hotels = restarant_names[restarant_names[\"Rating\"]==5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"five_start_hotels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams[\"figure.figsize\"] = 50,10\nfive_start_hotels.Restaurant.value_counts().plot(kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert(text):\n    return int(text.replace(',',''))\nreviews[\"Cost\"] = reviews[\"Cost\"].apply(convert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_5  = reviews.sort_values(by=\"Cost\",ascending=False).head(5)\ntail_5 = reviews.sort_values(by=\"Cost\",ascending=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_cost = pd.concat([top_5,tail_5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(final_cost ,values=\"Cost\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top and  Bottom price distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(restarant_names.Rating)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names = restarant_names.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names[\"Rating\"].fillna(round(restarant_names[\"Rating\"].mean()))\n# eplace(\"NaN\",)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## There is no NaN values in the dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names[\"final_text\"] = restarant_names[\"Restaurant\"]+\" \"+restarant_names[\"Review\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewers = restarant_names['Reviewer'].value_counts().reset_index()\nreviewers.columns = ['Reviewer', 'Reviews']\n\nfig = px.histogram(reviewers, 'Reviews')\nfig.update_layout(title = \"Distribution in no of reviews:\",\n                 xaxis_title = \"No of Reviews\",\n                 yaxis_title = \"Given By users\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = reviewers.head()['Reviewer'].tolist()\nprint(\"People who have posted most reviews are :\", temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names['final_text'] = restarant_names['final_text'].apply(lambda x:clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names['temp_list'] = restarant_names['final_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in restarant_names['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(x):\n    return [w for w in x if not w in stop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names['temp_list'] = restarant_names['temp_list'].apply(lambda x:remove_stopword(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in restarant_names['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_word_cloud(text,img_name):\n    wordcloud = WordCloud(\n        width = 3000,\n        height = 2000,\n        background_color = 'black').generate(str(text))\n    fig = plt.figure(\n        figsize = (40, 30),\n        facecolor = 'k',\n        edgecolor = 'k')\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.axis('off')\n    plt.tight_layout(pad=0)\n    plt.show()\n    plt.savefig(img_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_values = restarant_names.final_text.values[:100]\ngenerate_word_cloud(text_values,'image1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisines = reviews['Cuisines']\ncuisines = cuisines.apply(lambda x : x.lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_cuisines = ', '.join(i for i in cuisines.tolist())\nall_cuisines = Counter(all_cuisines.split(', '))\nall_cuisines = pd.DataFrame.from_records(list(dict(all_cuisines).items()), columns=['Name','No Of Restaurents'])\nall_cuisines.sort_values(by='No Of Restaurents', ascending=False, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(x=\"Name\",y=\"No Of Restaurents\",data_frame=all_cuisines,title=\"Total cuisine Available\",color=\"No Of Restaurents\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(x=\"Name\",y=\"No Of Restaurents\",data_frame=all_cuisines[:10],title=\"Top cuisine loved by people\")\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cusine_sort = reviews.sort_values(by=\"Cost\",ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cusine_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cusine_sort_price = cusine_sort[cusine_sort[\"Cost\"]>=1000]\ncusine_sort_price_1000 = cusine_sort[cusine_sort[\"Cost\"]<1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cusine_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(cusine_sort_price, x='Cost', y='Cuisines', color='Cost',title=\"Cost distribution based on Cusines cost greater than 1000\",)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(cusine_sort_price_1000, x='Cost', y='Cuisines', color='Cost',title=\"Cost distribution based on Cusines cost less than 1000\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cusine_text = reviews.Cuisines.values\ngenerate_word_cloud(cusine_text,\"cusines.jpeg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cusine_sort_price_viz = cusine_sort_price_1000[cusine_sort_price_1000[\"Cost\"]<300]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(cusine_sort_price_viz, x='Cost', y='Name', color='Cost',title=\"Cost distribution based on Cusines cost less than 1000\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names_very_low = restarant_names[restarant_names[\"Rating\"]<3.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names_very_low.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names['Time'] = restarant_names['Time'].apply(lambda x : datetime.strptime(x, '%m/%d/%Y %H:%M'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names_very_low_values = restarant_names_very_low.Review.values\ngenerate_word_cloud(restarant_names_very_low_values,\"low_restarant.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(restarant_names_very_low, y='Restaurant')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restarant_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_to_three_class(Rating):\n    if Rating <3.0:\n        Rating = 0\n    elif Rating>3.0:\n        Rating = 2\n    elif Rating ==3.0:\n        Rating = 1\n    return Rating","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Labels\n>Label 0 says the restaraunt which are less than 3 rating\n\n>Label 1 says the restaraunt which are equal to 3  rating\n\n>Label 2 says the restaraunt which are greater than 3 rating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_restarant = restarant_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_restarant[\"Rating\"] = restarant_names[\"Rating\"].apply(convert_to_three_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(new_restarant[\"Rating\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_review = new_restarant[new_restarant[\"Rating\"]==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import LatentDirichletAllocation as LDA\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport gensim, spacy, logging, warnings\nimport gensim.corpora as corpora\nfrom gensim.utils import lemmatize, simple_preprocess\nfrom gensim.models import CoherenceModel\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_text = list(zero_review.Review.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sent_to_words(sentences):\n    for sent in sentences:\n        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n        yield(sent)  \n\n# Convert to list\n# data = df.content.values.tolist()\ndata_words = list(sent_to_words(negative_text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nstop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the bigram and trigram models\nbigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\ntrigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \nbigram_mod = gensim.models.phrases.Phraser(bigram)\ntrigram_mod = gensim.models.phrases.Phraser(trigram)\n\n# !python3 -m spacy download en  # run in terminal once\ndef process_words(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n    texts = [bigram_mod[doc] for doc in texts]\n    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n    texts_out = []\n    nlp = spacy.load('en', disable=['parser', 'ner'])\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n    # remove stopwords once more after lemmatization\n    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n    return texts_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ready = process_words(data_words)  # processed Text Data!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dictionary\nid2word = corpora.Dictionary(data_ready)\n\n# Create Corpus: Term Document Frequency\ncorpus = [id2word.doc2bow(text) for text in data_ready]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=4, \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=10,\n                                           passes=10,\n                                           alpha='symmetric',\n                                           iterations=100,\n                                           per_word_topics=True)\n\nprint(lda_model.print_topics())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_topics_sentences(ldamodel, corpus, texts):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n\n    # Get main topic in each document\n    for i, row_list in enumerate(ldamodel[corpus]):\n        row = row_list[0] if ldamodel.per_word_topics else row_list            \n        # print(row)\n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n\n    # Add original text to the end of the output\n    contents = pd.Series(texts)\n    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n    return(sent_topics_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n\n# Format\ndf_dominant_topic = df_topic_sents_keywords.reset_index()\ndf_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\ndf_dominant_topic.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ntopics = lda_model.show_topics(formatted=False)\ndata_flat = [w for w_list in data_ready for w in w_list]\ncounter = Counter(data_flat)\n\nout = []\nfor i, topic in topics:\n    for word, weight in topic:\n        out.append([word, i , weight, counter[word]])\n\ndf = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \nimport matplotlib.colors as mcolors\n# Plot Word Count and Weights of Topic Keywords\nfig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\ncols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\nfor i, ax in enumerate(axes.flatten()):\n    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n    ax_twin = ax.twinx()\n    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n    ax.set_ylabel('Word Count', color=cols[i])\n    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n    ax.tick_params(axis='y', left=False)\n    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n\nfig.tight_layout(w_pad=2)    \nfig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \nplt.show()\nplt.savefig(\"final.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cusine_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}