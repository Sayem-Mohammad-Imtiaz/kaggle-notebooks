{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfilepath = '/kaggle/input/brent-oil-prices/BrentOilPrices.csv'\ndata_RAW = pd.read_csv(filepath)\n#data_RAW.head()\ndata_RAW.tail()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-23T03:49:16.102034Z","iopub.execute_input":"2021-05-23T03:49:16.102434Z","iopub.status.idle":"2021-05-23T03:49:16.135283Z","shell.execute_reply.started":"2021-05-23T03:49:16.102403Z","shell.execute_reply":"2021-05-23T03:49:16.133983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Starting visualization\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(16,9))\nplt.plot(data_RAW[['Price']])\nplt.axhline(linestyle='dotted', color='r')\nplt.xticks(range(0,data_RAW.shape[0],1000),data_RAW['Date'].loc[::1000],rotation=90)\nplt.xlabel('Date', fontsize=20)\nplt.ylabel('Oil Price (USD)', fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T03:49:34.666242Z","iopub.execute_input":"2021-05-23T03:49:34.666641Z","iopub.status.idle":"2021-05-23T03:49:34.955561Z","shell.execute_reply.started":"2021-05-23T03:49:34.666611Z","shell.execute_reply":"2021-05-23T03:49:34.954507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the dataset\n\nprice = data_RAW[['Price']]\n\n# Splitting for training and testing:\n\n\nsequence_length = 22 # 8 => (1234567 -> 8)\ntest_percentail = 0.05 # 5% de test\n\ndata_raw = price.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T03:52:54.737455Z","iopub.execute_input":"2021-05-23T03:52:54.737817Z","iopub.status.idle":"2021-05-23T03:52:54.744192Z","shell.execute_reply.started":"2021-05-23T03:52:54.737787Z","shell.execute_reply":"2021-05-23T03:52:54.743265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalizer:\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler= MinMaxScaler()\nscaler.fit(data_raw)\nnorm = scaler.transform(data_raw)\n#print(norm)\n# reconstruct = scaler.inverse_transform(norm)\n# print(reconstruct)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T03:52:59.118041Z","iopub.execute_input":"2021-05-23T03:52:59.118596Z","iopub.status.idle":"2021-05-23T03:52:59.127626Z","shell.execute_reply.started":"2021-05-23T03:52:59.118562Z","shell.execute_reply":"2021-05-23T03:52:59.126405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nfor i in range(len(norm) - sequence_length):\n  data.append(norm[i:i+sequence_length])\n\ndata = np.array(data);\ntest_set_size = int(np.round(test_percentail*data.shape[0]));\ntrain_set_size = data.shape[0] - (test_set_size);\n#print(f'test size: {test_set_size}, train size: {train_set_size}')\n#>> test size: 427, train size: 8122\n\ni_train = data[:train_set_size,:-1,:]\n\no_train = data[:train_set_size,-1,:]\n\ni_test = data[train_set_size:,:-1]\n\no_test = data[train_set_size:,-1,:]\n\n\n#print(f'{i_train.shape} \\n{o_train.shape} \\n{i_test.shape} \\n{o_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T03:55:03.689512Z","iopub.execute_input":"2021-05-23T03:55:03.689924Z","iopub.status.idle":"2021-05-23T03:55:03.713856Z","shell.execute_reply.started":"2021-05-23T03:55:03.689892Z","shell.execute_reply":"2021-05-23T03:55:03.712736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model building\n# Models Parameters\nimport torch\nimport torch.nn as nn\nimport time\n\ni_train_tensor = torch.from_numpy(i_train).type(torch.Tensor)\ni_test_tensor = torch.from_numpy(i_test).type(torch.Tensor)\no_train_tensor = torch.from_numpy(o_train).type(torch.Tensor)\no_test_tensor = torch.from_numpy(o_test).type(torch.Tensor)\n\ninput_dim = 1   # Lista de {sequence_length-1}\nhidden_dim = 22 # Memoria interna das RNN/RNR\nnum_layers = 2  # \noutput_dim = 1  # 1 Lista de 1 elemento\nnum_epochs = 100\n\nlearn_rate = 0.01","metadata":{"execution":{"iopub.status.busy":"2021-05-23T03:56:36.281203Z","iopub.execute_input":"2021-05-23T03:56:36.281669Z","iopub.status.idle":"2021-05-23T03:56:36.28986Z","shell.execute_reply.started":"2021-05-23T03:56:36.281624Z","shell.execute_reply":"2021-05-23T03:56:36.288887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM:\n\nclass LSTM(nn.Module):\n  def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n    super(LSTM, self).__init__()\n    self.hidden_dim = hidden_dim\n    self.num_layers = num_layers        \n    self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n    self.fc = nn.Linear(hidden_dim, output_dim)\n    \n  def forward(self, x):\n    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n    out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n    out = self.fc(out[:, -1, :]) \n    return out\n\nmodel_LSTM = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\ncriterion = torch.nn.MSELoss(reduction='mean')\n#criterion = torch.nn.MSELoss(reduction='sum')\n#criterion = torch.nn.L1Loss()\noptimiser = torch.optim.Adam(model_LSTM.parameters(), lr=learn_rate)\n#optimiser = torch.optim.Adagrad(model_LSTM.parameters(), lr=learn_rate)\n#optimiser = torch.optim.AdamW(model_LSTM.parameters(), lr=learn_rate)\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\nlstm = []\n\nfor t in range(num_epochs):\n  o_train_pred = model_LSTM(i_train_tensor)\n  loss = criterion(o_train_pred, o_train_tensor)\n  #print(\"Epoch \", t+1, \"Loss: \", loss.item())\n  hist[t] = loss.item()\n  optimiser.zero_grad()\n  loss.backward()\n  optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(f'Training time: {training_time}')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T03:56:43.901728Z","iopub.execute_input":"2021-05-23T03:56:43.902345Z","iopub.status.idle":"2021-05-23T03:57:50.699825Z","shell.execute_reply.started":"2021-05-23T03:56:43.902291Z","shell.execute_reply":"2021-05-23T03:57:50.698913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,9))\nplt.plot(hist)\nplt.axhline(linestyle='dotted', color='r')\nplt.xlabel('Epoch', fontsize=20)\nplt.ylabel('Loss', fontsize=20)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T03:58:06.783264Z","iopub.execute_input":"2021-05-23T03:58:06.783611Z","iopub.status.idle":"2021-05-23T03:58:07.012707Z","shell.execute_reply.started":"2021-05-23T03:58:06.783583Z","shell.execute_reply":"2021-05-23T03:58:07.011797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Results:\n\ntrain_score1 = criterion(model_LSTM(i_train_tensor).detach(), o_train_tensor)\ntest_score1 = criterion(model_LSTM(i_test_tensor).detach(), o_test_tensor)\n\nprint('Parametros: ',\n          f'\\n  Arquiteture {model_LSTM}',\n          f'\\n  Input lookback length: {sequence_length-1}',\n          f'\\n  Learning Rate: {learn_rate}',\n          f'\\n  Training/Testing Relation: {(1-test_percentail)*100}%/{100*test_percentail}%',\n          f'\\n  Loss function: {criterion}')\n\n\nprint('\\nResultados',\n      f'\\n  Training time: {training_time:.2f} seconds',\n      f'\\n  Training Loss: {train_score1.item()}',\n      f'\\n  Test Loss: {test_score1.item()}')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T04:00:16.230125Z","iopub.execute_input":"2021-05-23T04:00:16.230457Z","iopub.status.idle":"2021-05-23T04:00:16.57531Z","shell.execute_reply.started":"2021-05-23T04:00:16.230428Z","shell.execute_reply":"2021-05-23T04:00:16.573822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,9))\nplt.plot(scaler.inverse_transform(model_LSTM(i_test_tensor).detach().numpy()))\nplt.plot(scaler.inverse_transform(o_test))\nplt.axhline(linestyle='dotted', color='r')\nplt.xlabel('Date', fontsize=20)\nplt.ylabel('Oil Price (USD)', fontsize=20)\nplt.legend(['LSTM', 'Real'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T04:00:35.130679Z","iopub.execute_input":"2021-05-23T04:00:35.131076Z","iopub.status.idle":"2021-05-23T04:00:35.410933Z","shell.execute_reply.started":"2021-05-23T04:00:35.131035Z","shell.execute_reply":"2021-05-23T04:00:35.409604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GRU:\n\nclass GRU(nn.Module):\n  def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n    super(GRU, self).__init__()\n    self.hidden_dim = hidden_dim\n    self.num_layers = num_layers       \n    self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n    self.fc = nn.Linear(hidden_dim, output_dim)\n\n  def forward(self, x):\n    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n    out, (hn) = self.gru(x, (h0.detach()))\n    out = self.fc(out[:, -1, :]) \n    return out\n\nmodel_GRU = GRU(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\ncriterion = torch.nn.MSELoss(reduction='mean')\n#criterion = torch.nn.MSELoss(reduction='sum')\n#criterion = torch.nn.L1Loss()\noptimiser = torch.optim.Adam(model_GRU.parameters(), lr=learn_rate)\n#optimiser = torch.optim.Adagrad(model_GRU.parameters(), lr=learn_rate)\n#optimiser = torch.optim.AdamW(model_GRU.parameters(), lr=learn_rate)\n\nhist2 = np.zeros(num_epochs)\nstart_time = time.time()\ngru = []\n\nfor t in range(num_epochs):\n  o_train_out = model_GRU(i_train_tensor)\n  loss = criterion(o_train_out, o_train_tensor)\n  #print(\"Epoch \", t+1, \"Loss: \", loss.item())\n  hist2[t] = loss.item()\n  optimiser.zero_grad()\n  loss.backward()\n  optimiser.step()\n\ntraining_time_GRU = time.time()-start_time    \nprint(f'Training time: {training_time_GRU}')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T04:00:56.538378Z","iopub.execute_input":"2021-05-23T04:00:56.538742Z","iopub.status.idle":"2021-05-23T04:01:47.535224Z","shell.execute_reply.started":"2021-05-23T04:00:56.538687Z","shell.execute_reply":"2021-05-23T04:01:47.533887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,9))\nplt.plot(hist2)\nplt.axhline(linestyle='dotted', color='r')\nplt.xlabel('Epoch', fontsize=20)\nplt.ylabel('Loss', fontsize=20)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_score2 = criterion(model_GRU(i_train_tensor).detach(), o_train_tensor)\ntest_score2 = criterion(model_GRU(i_test_tensor).detach(), o_test_tensor)\n\n\nprint('Parametros: ',\n          f'\\n  Arquiteture {model_GRU}',\n          f'\\n  Input lookback length: {sequence_length-1}',\n          f'\\n  Learning Rate: {learn_rate}',\n          f'\\n  Training/Testing Relation: {(1-test_percentail)*100}%/{100*test_percentail}%',\n          f'\\n  Loss function: {criterion}')\n\n\nprint('\\nResultados',\n      f'\\n  Training time: {training_time_GRU:.2f}  seconds',\n      f'\\n  Training Loss: {train_score2.item()}',\n      f'\\n  Test Loss: {test_score2.item()}')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T04:02:49.014533Z","iopub.execute_input":"2021-05-23T04:02:49.014889Z","iopub.status.idle":"2021-05-23T04:02:49.236912Z","shell.execute_reply.started":"2021-05-23T04:02:49.01486Z","shell.execute_reply":"2021-05-23T04:02:49.23605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,9))\nplt.plot(scaler.inverse_transform(model_GRU(i_test_tensor).detach().numpy()))\nplt.plot(scaler.inverse_transform(o_test))\nplt.axhline(linestyle='dotted', color='r')\nplt.xlabel('Date', fontsize=20)\nplt.ylabel('Oil Price (USD)', fontsize=20)\nplt.legend(['GRU', 'Real'])\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T04:03:06.059328Z","iopub.execute_input":"2021-05-23T04:03:06.059673Z","iopub.status.idle":"2021-05-23T04:03:06.360429Z","shell.execute_reply.started":"2021-05-23T04:03:06.059642Z","shell.execute_reply":"2021-05-23T04:03:06.359127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comparing LSTM e GRU:\n\nplt.figure(figsize=(16,9))\nplt.plot(scaler.inverse_transform(o_test))\nplt.plot(scaler.inverse_transform(model_GRU(i_test_tensor).detach().numpy()))\nplt.plot(scaler.inverse_transform(model_LSTM(i_test_tensor).detach().numpy()))\nplt.axhline(linestyle='dotted', color='r')\n#plt.xticks(range(428),pred_y,rotation=90)\nplt.xlabel('Date', fontsize=20)\nplt.ylabel('Oil Price (USD)', fontsize=20)\n\nplt.legend(['Real', 'GRU', 'LSTM'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T04:03:29.868824Z","iopub.execute_input":"2021-05-23T04:03:29.869178Z","iopub.status.idle":"2021-05-23T04:03:30.285402Z","shell.execute_reply.started":"2021-05-23T04:03:29.869149Z","shell.execute_reply":"2021-05-23T04:03:30.284126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss function in training (LSTM and GRU):\n\nplt.figure(figsize=(16,9))\nplt.plot(hist)\nplt.plot(hist2)\nplt.axhline(linestyle='dotted', color='r')\nplt.xlabel('Epoch', fontsize=20)\nplt.ylabel('Loss', fontsize=20)\n\nplt.legend(['LSTM', 'GRU'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T04:04:20.804959Z","iopub.execute_input":"2021-05-23T04:04:20.805347Z","iopub.status.idle":"2021-05-23T04:04:21.059041Z","shell.execute_reply.started":"2021-05-23T04:04:20.805317Z","shell.execute_reply":"2021-05-23T04:04:21.057831Z"},"trusted":true},"execution_count":null,"outputs":[]}]}