{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Chinese Digit Recognizer with a Keras CNN","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\npath = '../input/chinese-mnist-digit-recognizer/chineseMNIST.csv'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-13T07:29:14.011443Z","iopub.execute_input":"2021-07-13T07:29:14.012051Z","iopub.status.idle":"2021-07-13T07:29:21.431336Z","shell.execute_reply.started":"2021-07-13T07:29:14.011902Z","shell.execute_reply":"2021-07-13T07:29:21.430324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the dataset\nds = pd.read_csv(path)\nds.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:29:21.432877Z","iopub.execute_input":"2021-07-13T07:29:21.433242Z","iopub.status.idle":"2021-07-13T07:29:31.63378Z","shell.execute_reply.started":"2021-07-13T07:29:21.4332Z","shell.execute_reply":"2021-07-13T07:29:31.632719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:29:31.635401Z","iopub.execute_input":"2021-07-13T07:29:31.635698Z","iopub.status.idle":"2021-07-13T07:29:31.642607Z","shell.execute_reply.started":"2021-07-13T07:29:31.63567Z","shell.execute_reply":"2021-07-13T07:29:31.641488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the labels and the character cols\nlabels_cols = ['label', 'character']\n# select only the images\ndata = ds.drop(labels_cols, axis=1).values\n# select the labels and the characters\nlabels = ds[labels_cols[0]].values\ncharacters = ds[labels_cols[1]].values\n\ndata.shape, labels.shape, characters.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:29:31.644159Z","iopub.execute_input":"2021-07-13T07:29:31.644433Z","iopub.status.idle":"2021-07-13T07:29:31.858572Z","shell.execute_reply.started":"2021-07-13T07:29:31.644405Z","shell.execute_reply":"2021-07-13T07:29:31.85753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Processing and Useful functions","metadata":{}},{"cell_type":"code","source":"# to process the data and convert to 64x64 images\n# receives data\ndef process_data(x):\n    images = [] # all the images\n    # is each row in x, each image\n    for img in x:\n        # reshape the flatten data\n        image = img.reshape(64,64,1)\n        images.append(image)\n    # return the images in an apropiate format\n    return np.array(images).astype('float32')/255\n\n# recieves labels\ndef process_target(chars, num_classes):\n    target = [] # is the result\n    class_names = {} # other result\n    count = count_values(chars) # count the characters\n    ###### add the labels for the dict\n    for key, i in zip(count.keys(), range(num_classes)):\n        class_names[key] = i\n    ###### create the labels data, the numbers\n    labs = class_names.keys()\n    for char in chars:\n        pos = class_names[char] # position of the 1\n        row = []\n        for i in range(num_classes):# create the target [0,0,0...,1,...]\n            if pos != i:\n                row.append(0)\n            else:\n                row.append(1)\n        target.append(row)\n    return np.array(target).astype('float32'), class_names\n\n\ndef count_values(arr):\n    dic = {}\n    for val in arr:\n        if val not in dic.keys():\n            dic[val] = 1\n        else:\n            dic[val] += 1\n    return dic\n\n# plot multiple images, preds is for the titles\n# preds must be like [[real, pred]]\ndef plot_images(imgs, dims, figsize, title_size, preds=[]):\n    plt.figure(figsize=figsize)\n    for img, i, in zip(imgs, np.arange(imgs.shape[0])):\n        plt.subplot(dims[0], dims[1], i+1)\n        plt.imshow(np.squeeze(img), cmap='gray')\n        plt.axis('off')\n        title = f'Image {i+1}'\n        if preds != []:\n            title = f'Real: {preds[i][0]}, Pred: {preds[i][1]}'\n        plt.title(title, fontsize=title_size)\n    plt.show()\n    \n# these numbers are just to prove*\nsample_data = process_data(data[:8008:1001])\nplot_images(sample_data, dims=(2,4), figsize=(16,8), title_size=22)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:29:39.940608Z","iopub.execute_input":"2021-07-13T07:29:39.940986Z","iopub.status.idle":"2021-07-13T07:29:40.527621Z","shell.execute_reply.started":"2021-07-13T07:29:39.94095Z","shell.execute_reply":"2021-07-13T07:29:40.526851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying the Processing Functions","metadata":{}},{"cell_type":"code","source":"# get the images from the df as arrays\nX = process_data(data)\n\n# and obtain the target data from the characters\nY, class_names = process_target(characters, num_classes=15)\n\nX.shape, X.dtype, Y.shape, Y.dtype","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:30:08.29954Z","iopub.execute_input":"2021-07-13T07:30:08.299904Z","iopub.status.idle":"2021-07-13T07:30:08.775792Z","shell.execute_reply.started":"2021-07-13T07:30:08.29987Z","shell.execute_reply":"2021-07-13T07:30:08.774812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the Data on *train* and *test*","metadata":{}},{"cell_type":"code","source":"# split the dataset in train and test. validation set will be included in the training, later\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=314, shuffle=True)\nx_train.shape, x_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:30:08.777345Z","iopub.execute_input":"2021-07-13T07:30:08.777667Z","iopub.status.idle":"2021-07-13T07:30:08.859847Z","shell.execute_reply.started":"2021-07-13T07:30:08.777637Z","shell.execute_reply":"2021-07-13T07:30:08.85885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[0] # sample of the result of the predictions","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:30:08.861527Z","iopub.execute_input":"2021-07-13T07:30:08.861839Z","iopub.status.idle":"2021-07-13T07:30:08.86771Z","shell.execute_reply.started":"2021-07-13T07:30:08.86181Z","shell.execute_reply":"2021-07-13T07:30:08.866691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Model, a Convolutional Neural Network","metadata":{}},{"cell_type":"code","source":"# to reset the keras session\n#keras.backend.clear_session()\n\ninput_shape = (64,64,1) # the dimension of the data\nnum_classes = 15 # the number of classes\n\nmodel = Sequential([\n    # define the input shape with a layer\n    layers.InputLayer(input_shape=input_shape),\n\n    # convolutional part with relu and later pooling\n    layers.Conv2D(filters=32, kernel_size=5, activation='relu'),\n    layers.MaxPooling2D(pool_size=2),\n\n    # flatten the data, as it comes with (64,64,1) shape\n    layers.Flatten(),\n    \n    # dense part, with neurons\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(rate=.3), # turn off random neurons in each step\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(rate=.3), # it helps to prevent overfitting\n    layers.Dense(num_classes, activation='softmax')\n])\n\n# the last layer has multiple (15) neurons since the result we\n# want looks like the one in the cell above, each neuron provides\n# one of these numbers\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics = ['accuracy'],\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:30:08.869173Z","iopub.execute_input":"2021-07-13T07:30:08.869517Z","iopub.status.idle":"2021-07-13T07:30:09.055413Z","shell.execute_reply.started":"2021-07-13T07:30:08.869485Z","shell.execute_reply":"2021-07-13T07:30:09.054317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# as the model performance increases faster\n# it might be good to use an early stopping\n\nearly_stopping = EarlyStopping(\n    min_delta=.005, # minimum performance increase\n    patience=10, # epochs until the stop\n    restore_best_weights=True\n)\n\nhist = model.fit(\n    x_train,\n    y_train,\n    batch_size=64,\n    epochs=20,\n    validation_split=.1,# as there's no val data\n    callbacks=[early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:30:09.056737Z","iopub.execute_input":"2021-07-13T07:30:09.056998Z","iopub.status.idle":"2021-07-13T07:35:51.197401Z","shell.execute_reply.started":"2021-07-13T07:30:09.056972Z","shell.execute_reply":"2021-07-13T07:35:51.196605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\n# plot the loss function\nplt.subplot(1,2,1)\nplt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='validation')\nplt.title('Loss Function')\nplt.grid(True)\nplt.legend()\n\n# and the accuracy\nplt.subplot(1,2,2)\nplt.plot(hist.history['accuracy'], label='train')\nplt.plot(hist.history['val_accuracy'], label='validation')\nplt.grid(True)\nplt.title('Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:35:51.198752Z","iopub.execute_input":"2021-07-13T07:35:51.199356Z","iopub.status.idle":"2021-07-13T07:35:51.522961Z","shell.execute_reply.started":"2021-07-13T07:35:51.199308Z","shell.execute_reply":"2021-07-13T07:35:51.521978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the Model with *test* set","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(x_test, y_test, batch_size=64)\nprint(\"test loss, test acc:\", results)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:35:51.524148Z","iopub.execute_input":"2021-07-13T07:35:51.524413Z","iopub.status.idle":"2021-07-13T07:35:53.22498Z","shell.execute_reply.started":"2021-07-13T07:35:51.524386Z","shell.execute_reply":"2021-07-13T07:35:53.223819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"def max_index(arr):\n    mx = 0\n    idx = 0\n    for a, i in zip(arr, range(len(list(arr)))):\n        if a > mx:\n            mx = a\n            idx = i\n    return idx\n\n# prepare the data for the matrix\npreds = model.predict(x_test) # make predictions\ny_pred = []\n# iterate the preds as we want the class number\nfor p in preds:\n    c_num = max_index(p) # find the index of the max\n    y_pred.append(c_num)\n\n# obtain the y_real, the same process but with y_test\ny_real = []\nfor p in y_test:\n    c_num = max_index(p) # find the index of the max\n    y_real.append(c_num)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:36:37.078393Z","iopub.execute_input":"2021-07-13T07:36:37.079826Z","iopub.status.idle":"2021-07-13T07:36:38.885305Z","shell.execute_reply.started":"2021-07-13T07:36:37.079765Z","shell.execute_reply":"2021-07-13T07:36:38.884316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the matrix with the real classes and the predicted\nm = confusion_matrix(y_real, y_pred)\n# the labels for the plot\nlabels = list(class_names.values()) # the characters throw warnings\nplt.figure(figsize=(20, 8))\n# create the plot\nheatmap = sns.heatmap(m, xticklabels=labels, yticklabels=labels, annot=True, fmt='d', color='blue')\n# labels for the axes\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:36:38.886532Z","iopub.execute_input":"2021-07-13T07:36:38.886804Z","iopub.status.idle":"2021-07-13T07:36:39.812873Z","shell.execute_reply.started":"2021-07-13T07:36:38.886778Z","shell.execute_reply":"2021-07-13T07:36:39.811573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Samples of Predictions from *test* set","metadata":{}},{"cell_type":"code","source":"x_test[:10].shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:36:45.145581Z","iopub.execute_input":"2021-07-13T07:36:45.145951Z","iopub.status.idle":"2021-07-13T07:36:45.151504Z","shell.execute_reply.started":"2021-07-13T07:36:45.145918Z","shell.execute_reply":"2021-07-13T07:36:45.150755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data = x_test[:15] # the first 15 numbers\n# a process similar as the one above\npreds = model.predict(sample_data) # make predictions\ny_pred = []\n\n# iterate the preds as we want the class number\nfor pred,real in zip(preds, y_test):\n    pred_num = max_index(pred) # find the index of the max\n    real_num = max_index(real) # in each arrays\n    y_pred.append((real_num, pred_num)) # first real\n\n\nimages = np.squeeze(sample_data) # delete the extra dim\n# as the shape of sample data is (15, 64, 64, 1)\n\n# it will be 15 preds\nplot_images(images, (3,5), figsize=(25,15), title_size=22, preds=y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:36:51.969221Z","iopub.execute_input":"2021-07-13T07:36:51.969781Z","iopub.status.idle":"2021-07-13T07:36:52.839334Z","shell.execute_reply.started":"2021-07-13T07:36:51.969743Z","shell.execute_reply":"2021-07-13T07:36:52.838412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the Model","metadata":{}},{"cell_type":"code","source":"model.save('Chinese_Digit_Recognizer.h5')\n# also I will save the processed data\nnp.save('training_data.npy', X)\nnp.save('testing_data.npy', Y)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T07:36:55.335659Z","iopub.execute_input":"2021-07-13T07:36:55.336006Z","iopub.status.idle":"2021-07-13T07:36:55.76821Z","shell.execute_reply.started":"2021-07-13T07:36:55.335973Z","shell.execute_reply":"2021-07-13T07:36:55.766979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nThis is my fist practise where the objective is to recognize hand-written digits. I liked it. `The model reach a performance of almost 0.96 in validation and testing and .99 in training`, I guess that was because of there was a good quantity of data, `1K samples of each class`, and the borders and `lines are such a thing that cnn's are good at` and I think this dataset proves that and helps us to experiment with cnn's. It was a really good dataset. **Thank you :D**","metadata":{}}]}