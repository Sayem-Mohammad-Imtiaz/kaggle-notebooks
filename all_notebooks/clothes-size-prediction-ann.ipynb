{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T20:54:13.774987Z","iopub.execute_input":"2021-06-17T20:54:13.775678Z","iopub.status.idle":"2021-06-17T20:54:13.792448Z","shell.execute_reply.started":"2021-06-17T20:54:13.775568Z","shell.execute_reply":"2021-06-17T20:54:13.791693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clothes = pd.read_csv('/kaggle/input/clothessizeprediction/final_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:20.063762Z","iopub.execute_input":"2021-06-17T20:54:20.064414Z","iopub.status.idle":"2021-06-17T20:54:20.154082Z","shell.execute_reply.started":"2021-06-17T20:54:20.064361Z","shell.execute_reply":"2021-06-17T20:54:20.153154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clothes.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:21.289795Z","iopub.execute_input":"2021-06-17T20:54:21.290199Z","iopub.status.idle":"2021-06-17T20:54:21.320003Z","shell.execute_reply.started":"2021-06-17T20:54:21.290141Z","shell.execute_reply":"2021-06-17T20:54:21.319054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let check the basic info about the dataset\nclothes.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:22.281504Z","iopub.execute_input":"2021-06-17T20:54:22.28187Z","iopub.status.idle":"2021-06-17T20:54:22.332269Z","shell.execute_reply.started":"2021-06-17T20:54:22.28184Z","shell.execute_reply":"2021-06-17T20:54:22.330992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clothes.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:23.152674Z","iopub.execute_input":"2021-06-17T20:54:23.153038Z","iopub.status.idle":"2021-06-17T20:54:23.183201Z","shell.execute_reply.started":"2021-06-17T20:54:23.153009Z","shell.execute_reply":"2021-06-17T20:54:23.182206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the number of null values present in the data\nclothes.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:24.015148Z","iopub.execute_input":"2021-06-17T20:54:24.015867Z","iopub.status.idle":"2021-06-17T20:54:24.038666Z","shell.execute_reply.started":"2021-06-17T20:54:24.015816Z","shell.execute_reply":"2021-06-17T20:54:24.03745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# since it is a fairly large dataset with 119734 rows,dropping these null values will have\n# very minimum effect on the model \nclothes.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:24.857606Z","iopub.execute_input":"2021-06-17T20:54:24.857954Z","iopub.status.idle":"2021-06-17T20:54:24.902919Z","shell.execute_reply.started":"2021-06-17T20:54:24.857924Z","shell.execute_reply":"2021-06-17T20:54:24.901792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check if the value of age,weight or height is 0\nprint(f\"There are {len(clothes[clothes['age']==0])} rows with value of age as 0\")\nprint(f\"There are {len(clothes[clothes['weight']==0])} rows with values of weight as 0\")\nprint(f\"There are {len(clothes[clothes['height']==0])} rows with values of height as 0\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:25.94766Z","iopub.execute_input":"2021-06-17T20:54:25.947996Z","iopub.status.idle":"2021-06-17T20:54:25.95965Z","shell.execute_reply.started":"2021-06-17T20:54:25.947968Z","shell.execute_reply":"2021-06-17T20:54:25.958129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's remove the 18 rows as a customer can not have age as 0\nage_is_0 = clothes[clothes['age']==0]\nclothes.drop(age_is_0.index,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:26.807264Z","iopub.execute_input":"2021-06-17T20:54:26.807752Z","iopub.status.idle":"2021-06-17T20:54:26.828901Z","shell.execute_reply.started":"2021-06-17T20:54:26.807721Z","shell.execute_reply":"2021-06-17T20:54:26.827693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing the libraries for visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:27.786378Z","iopub.execute_input":"2021-06-17T20:54:27.786722Z","iopub.status.idle":"2021-06-17T20:54:28.617103Z","shell.execute_reply.started":"2021-06-17T20:54:27.786692Z","shell.execute_reply":"2021-06-17T20:54:28.615878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check what are the different size of clothes present and how many cutomers are wearing them\nclothes['size'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:29.199309Z","iopub.execute_input":"2021-06-17T20:54:29.199651Z","iopub.status.idle":"2021-06-17T20:54:29.216409Z","shell.execute_reply.started":"2021-06-17T20:54:29.199621Z","shell.execute_reply":"2021-06-17T20:54:29.21491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order = ['XXS','S','M','L','XL','XXL','XXXL']\nsns.set_style('darkgrid')\nsns.countplot(x='size',data=clothes,palette='Spectral',order=order)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:30.427388Z","iopub.execute_input":"2021-06-17T20:54:30.427843Z","iopub.status.idle":"2021-06-17T20:54:30.762319Z","shell.execute_reply.started":"2021-06-17T20:54:30.4278Z","shell.execute_reply":"2021-06-17T20:54:30.760964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are very few cutomers who wear XXL size clothes","metadata":{}},{"cell_type":"code","source":"# Let's see the relation between age,weight and height of customers and size of their clothes\n# Size vs Age\nsns.boxplot(x='size',y='age',data=clothes,order=order)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:37.468074Z","iopub.execute_input":"2021-06-17T20:54:37.468713Z","iopub.status.idle":"2021-06-17T20:54:37.803555Z","shell.execute_reply.started":"2021-06-17T20:54:37.468669Z","shell.execute_reply":"2021-06-17T20:54:37.80256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Size vs Weight\nsns.boxplot(x='size',y='weight',data = clothes,order=order)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:38.735942Z","iopub.execute_input":"2021-06-17T20:54:38.73654Z","iopub.status.idle":"2021-06-17T20:54:39.080313Z","shell.execute_reply.started":"2021-06-17T20:54:38.7365Z","shell.execute_reply":"2021-06-17T20:54:39.079179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Size vs Height\nsns.boxplot(x='size',y='height',data= clothes,order=order)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:40.031784Z","iopub.execute_input":"2021-06-17T20:54:40.032214Z","iopub.status.idle":"2021-06-17T20:54:40.331145Z","shell.execute_reply.started":"2021-06-17T20:54:40.032176Z","shell.execute_reply":"2021-06-17T20:54:40.330243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Weight has the most impact on the size of clothes. With increase in weight, size of the clothes increased.","metadata":{}},{"cell_type":"code","source":"# Let's check the correlation between the columns: weight,age,height\nclothes_corr = clothes.corr()\nsns.heatmap(clothes_corr,annot=True,cmap='YlOrBr')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:50.793047Z","iopub.execute_input":"2021-06-17T20:54:50.793473Z","iopub.status.idle":"2021-06-17T20:54:51.21873Z","shell.execute_reply.started":"2021-06-17T20:54:50.79344Z","shell.execute_reply":"2021-06-17T20:54:51.2177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next step would be to divide the data into X which will be used as input values\n# and y which will be used as output value\nX = clothes.drop('size',axis=1).values\ny = clothes['size'].values","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:52.157236Z","iopub.execute_input":"2021-06-17T20:54:52.15763Z","iopub.status.idle":"2021-06-17T20:54:52.169776Z","shell.execute_reply.started":"2021-06-17T20:54:52.157596Z","shell.execute_reply":"2021-06-17T20:54:52.168567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check what type of values are present in y\ny","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:54:53.436094Z","iopub.execute_input":"2021-06-17T20:54:53.436484Z","iopub.status.idle":"2021-06-17T20:54:53.444372Z","shell.execute_reply.started":"2021-06-17T20:54:53.436451Z","shell.execute_reply":"2021-06-17T20:54:53.442742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datatype of y is object which ML model will not be able to understand and process.\n# We will use LabelEncoder and to_categorical methods of sklearn and keras respectively to\n# do one hot encoding\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:11:52.347274Z","iopub.execute_input":"2021-06-17T21:11:52.347715Z","iopub.status.idle":"2021-06-17T21:11:52.353735Z","shell.execute_reply.started":"2021-06-17T21:11:52.347674Z","shell.execute_reply":"2021-06-17T21:11:52.352225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)\ny_encoded = to_categorical(y_encoded)\ny_encoded","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:55:02.266539Z","iopub.execute_input":"2021-06-17T20:55:02.266983Z","iopub.status.idle":"2021-06-17T20:55:02.320031Z","shell.execute_reply.started":"2021-06-17T20:55:02.26694Z","shell.execute_reply":"2021-06-17T20:55:02.318974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's split the data into train set and test set with 25% of data as test_set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y_encoded,test_size=0.25,random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:55:10.855757Z","iopub.execute_input":"2021-06-17T20:55:10.85624Z","iopub.status.idle":"2021-06-17T20:55:10.936569Z","shell.execute_reply.started":"2021-06-17T20:55:10.856192Z","shell.execute_reply":"2021-06-17T20:55:10.935761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next task would be to do feature scaling on X_train and X_test data\n# will use MinMaxScaler method of sklearn module for feature scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\n# will only perform fit method to X_train and not to X_test to avoid data leakage\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:55:12.090973Z","iopub.execute_input":"2021-06-17T20:55:12.091515Z","iopub.status.idle":"2021-06-17T20:55:12.108002Z","shell.execute_reply.started":"2021-06-17T20:55:12.091478Z","shell.execute_reply":"2021-06-17T20:55:12.107132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ANN model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2021-06-17T20:57:09.034516Z","iopub.execute_input":"2021-06-17T20:57:09.035151Z","iopub.status.idle":"2021-06-17T20:57:09.04008Z","shell.execute_reply.started":"2021-06-17T20:57:09.035096Z","shell.execute_reply":"2021-06-17T20:57:09.039399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating the model with 2 hidden layer and 7 nodes in each layers\nmodel = Sequential()\n\n# 1st hidden layer\nmodel.add(Dense(7,activation='relu',input_shape=[3]))\n\n# 2nd hidden layer\nmodel.add(Dense(7,activation='relu'))\n\n# output layer will have 7 nodes as there are 7 different sizes present\nmodel.add(Dense(7,activation='softmax'))\n\n# compiling the model\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')\n\n# model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:01:23.963279Z","iopub.execute_input":"2021-06-17T21:01:23.963737Z","iopub.status.idle":"2021-06-17T21:01:24.117999Z","shell.execute_reply.started":"2021-06-17T21:01:23.963697Z","shell.execute_reply":"2021-06-17T21:01:24.117074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# earlystop is used to avoid overfitting of the model on training data.It is used to monitor\n# the performence of the model during training.It allows us to choose the large number of epochs \n# and stop training once the model performence stop improving on the validation data\nearly_stop = EarlyStopping(monitor='val_loss',mode='min',verbose = 1, patience=20)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:16:38.6871Z","iopub.execute_input":"2021-06-17T21:16:38.687691Z","iopub.status.idle":"2021-06-17T21:16:38.6929Z","shell.execute_reply.started":"2021-06-17T21:16:38.687651Z","shell.execute_reply":"2021-06-17T21:16:38.691314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fitting the model to training data\nmodel.fit(X_train_scaled,y_train,validation_data=(X_test_scaled,y_test),epochs=300,callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:18:17.119038Z","iopub.execute_input":"2021-06-17T21:18:17.11948Z","iopub.status.idle":"2021-06-17T21:23:30.625764Z","shell.execute_reply.started":"2021-06-17T21:18:17.119444Z","shell.execute_reply":"2021-06-17T21:23:30.624795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Evaluation**","metadata":{}},{"cell_type":"code","source":"metrics = pd.DataFrame(model.history.history)\nmetrics.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:28:11.885075Z","iopub.execute_input":"2021-06-17T21:28:11.88554Z","iopub.status.idle":"2021-06-17T21:28:11.906094Z","shell.execute_reply.started":"2021-06-17T21:28:11.885499Z","shell.execute_reply":"2021-06-17T21:28:11.904802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss vs val_loss\nmetrics[['loss','val_loss']].plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:28:51.085662Z","iopub.execute_input":"2021-06-17T21:28:51.086207Z","iopub.status.idle":"2021-06-17T21:28:51.317354Z","shell.execute_reply.started":"2021-06-17T21:28:51.086146Z","shell.execute_reply":"2021-06-17T21:28:51.316246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracy vs val_accuracy\nmetrics[['accuracy','val_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:29:23.488581Z","iopub.execute_input":"2021-06-17T21:29:23.488928Z","iopub.status.idle":"2021-06-17T21:29:23.732384Z","shell.execute_reply.started":"2021-06-17T21:29:23.488892Z","shell.execute_reply":"2021-06-17T21:29:23.731133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy for X_test\nmodel.evaluate(X_test_scaled,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:30:41.980512Z","iopub.execute_input":"2021-06-17T21:30:41.980884Z","iopub.status.idle":"2021-06-17T21:30:42.819858Z","shell.execute_reply.started":"2021-06-17T21:30:41.980851Z","shell.execute_reply":"2021-06-17T21:30:42.818557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Accuracy of the model is 52.22%**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}