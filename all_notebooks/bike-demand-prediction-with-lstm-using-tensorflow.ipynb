{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Bike Demand Prediction with LSTMs using TensorFlow and Keras","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### My goal is to predict the number of future bike shares given the season and weather information.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom pandas.plotting import register_matplotlib_converters\nfrom pylab import rcParams\nimport tensorflow as tf\nfrom tensorflow import keras\nsns.set_style(\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/london-bike-sharing-dataset/london_merged.csv', parse_dates=['timestamp'], index_col='timestamp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- \"timestamp\" - timestamp field for grouping the data\n- \"cnt\" - the count of a new bike shares\n- \"t1\" - real temperature in C\n- \"t2\" - temperature in C \"feels like\"\n- \"hum\" - humidity in percentage\n- \"windspeed\" - wind speed in km/h\n- \"weathercode\" - category of the weather\n- \"isholiday\" - boolean field - 1 holiday / 0 non holiday\n- \"isweekend\" - boolean field - 1 if the day is weekend\n- \"season\" - category field meteorological seasons: 0-spring ; 1-summer; 2-fall; 3-winter.\n\n\"weathe_code\" category description:\n1 = Clear ; mostly clear but have some values with haze/fog/patches of fog/ fog in vicinity 2 = scattered clouds / few clouds 3 = Broken clouds 4 = Cloudy 7 = Rain/ light Rain shower/ Light rain 10 = rain with thunderstorm 26 = snowfall 94 = Freezing Fog","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hour'] = df.index.hour\ndf['day_of_week'] = df.index.dayofweek\ndf['day_of_month'] = df.index.day\ndf['month'] = df.index.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 8))\nsns.lineplot(x=df.index, y='cnt',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_by_month = df.resample('M').sum()\nplt.figure(figsize=(14, 8))\nsns.lineplot(x=df_by_month.index, y='cnt',data=df_by_month)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 8))\nsns.pointplot(x='hour', y='cnt',hue='is_holiday',data=df)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 8))\nsns.pointplot(x='day_of_week', y='cnt',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n# Get/Compute the number of rows to train the model on\ntraining_data_len = math.ceil(len(df) *.9) # taking 90% of data to train and 10% of data to test\ntesting_data_len = len(df) - training_data_len\n\ntime_steps = 24\ntrain, test = df.iloc[0:training_data_len], df.iloc[(training_data_len-time_steps):len(df)]\nprint(df.shape, train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Scale the all of the data from columns ['t1', 't2', 'hum', 'wind_speed']\ntrain_trans = train[['t1', 't2', 'hum', 'wind_speed']].to_numpy()\ntest_trans = test[['t1', 't2', 'hum', 'wind_speed']].to_numpy()\nRobust_scale = RobustScaler() # Many outliners exist, so using robustscaler\ntrain.loc[:, ['t1', 't2', 'hum', 'wind_speed']]=Robust_scale.fit_transform(train_trans)\ntest.loc[:, ['t1', 't2', 'hum', 'wind_speed']]=Robust_scale.fit_transform(test_trans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale the all of the data from columns ['cnt']\ntrain['cnt'] = Robust_scale.fit_transform(train[['cnt']])\ntest['cnt'] = Robust_scale.fit_transform(test[['cnt']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_numpy()\ntest.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data into x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(len(train) - time_steps):\n    x_train.append(train.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n    y_train.append(train.loc[:,'cnt'].iloc[i + time_steps])\n\n#Convert x_train and y_train to numpy arrays\nx_train = np.array(x_train)\ny_train = np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the x_test and y_test data sets\nx_test = []\ny_test = df.loc[:,'cnt'].iloc[training_data_len:len(df)]\n\nfor i in range(len(test) - time_steps):\n    x_test.append(test.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n    #y_test.append(test.loc[:,'cnt'].iloc[i + time_steps])\n\n#Convert x_test and y_test to numpy arrays\nx_test = np.array(x_test)\ny_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# [samples, time_steps, n_features]\n# Using all 12 columns of data (take out the bike sharing amount column) to make prediction\nprint('Train data size:')\nprint(x_train.shape, y_train.shape)\nprint('Test data size:')\nprint(x_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build the LSTM network model\nmodel = keras.Sequential()\nmodel.add(keras.layers.Bidirectional(\n    keras.layers.LSTM(units=50,input_shape=(x_train.shape[1], x_train.shape[2]))))\nmodel.add(keras.layers.Dropout(rate=0.2))\nmodel.add(keras.layers.Dense(units=1))\n#Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs=200, batch_size=20, validation_split=0.15, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred = Robust_scale.inverse_transform(y_pred)#Undo scaling\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\nrmse_lstm = np.sqrt(mean_squared_error(y_test, y_pred))\nrmse_lstm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test, y_pred)\nr2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pcik some values to zoom in\nplt.figure(figsize=(16, 8))\nplt.plot(y_test[1200:1600], label='true')\nplt.plot(y_pred[1200:1600], label='predicted')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}