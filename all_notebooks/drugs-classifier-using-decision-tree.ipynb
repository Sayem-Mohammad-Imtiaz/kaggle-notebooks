{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Drugs Classifier using Decision Tree\n\nHere [Drug Classification](https://www.kaggle.com/prathamtripathi/drug-classification) dataset by [Pratham Tripathi](https://www.kaggle.com/prathamtripathi) is used to create a classifier that classifies `drugs` on the basis of it `properites` using `Decision Tree`.\n\n![](https://media.giphy.com/media/xT8qB2zDVGj7ly4moU/giphy.gif)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import f1_score, precision_score, recall_score, classification_report\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n\n# Models\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\n\nfrom joblib import dump","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/drug-classification/drug200.csv')\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## üèãÔ∏è‚Äç‚ôÄÔ∏è Data preparation"},{"metadata":{},"cell_type":"markdown","source":"Looing if the dataset is `balanced` or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.Drug.value_counts())\nsns.countplot(x='Drug', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Label encoding vs OneHot encoding` üëâ [Source_1](https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b) and [Source_2](https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_encoding(df):\n    df.Sex = LabelEncoder().fit_transform(df.Sex)\n    df.BP = LabelEncoder().fit_transform(df.BP)\n    df.Cholesterol = LabelEncoder().fit_transform(df.Cholesterol)\n\n\n# data_encoding(df)\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This will be done after `EDA` so that we can get insight into data & don't need to worry about mapping fig plot's x & y labels to original values"},{"metadata":{},"cell_type":"markdown","source":"- Sex\n    - Female - 0\n    - Male - 1\n- BP\n    - HIGH - 0\n    - LOW - 1\n    - Normal - 2\n- Cholesterol\n    - HIGH - 0\n    - LOW - 1\n    \nSince we are using `DecisionTreeClassifier` algorithm for classification, `LabelEncoding` is ok, otherwise if we are using something else where numbers matter, there we should use `OneHotEncoding`."},{"metadata":{},"cell_type":"markdown","source":"## üç© Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"''' Helper functions for plotting '''\n\n\ndef plot_histplot(column, ax=None):\n    sns.histplot(x=column, color='#65b87b', alpha=.7, ax=ax)\n    \n    \ndef plot_countplot(column, ax=None):\n    with sns.axes_style('ticks'):\n        sns.countplot(x=column, palette=sns.color_palette('rocket'), ax=ax)\n        sns.despine(offset=6)\n        \n        \ndef plot_barplot(x, y, ax=None):\n    sns.barplot(x=x, y=y, palette=sns.color_palette('rocket'))\n    \n    \ndef plot_boxplot(x, y, ax=None):\n    sns.boxplot(x=x, y=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_histplot(df.Age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_histplot(df.Na_to_K)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(16, 4))\n\nplot_countplot(df[df.Sex == 'M'].BP, ax=ax[0])\nplot_countplot(df[df.Sex == 'F'].BP, ax=ax[1])\n\nax[0].set_title('Male - BP')\nax[1].set_title('Female - BP')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Less number of `males` have `normal BP` compared to `females`. Large proportion of both the genders have a `high BP`"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(16, 4))\n\nplot_countplot(df[df.Sex == 'M'].Cholesterol, ax=ax[0])\nplot_countplot(df[df.Sex == 'F'].Cholesterol, ax=ax[1])\n\nax[0].set_title('Male - Cholesterol')\nax[1].set_title('Female - Cholesterol')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both `male` & `female` have `high cholesterol`"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=df.Age, y=df.Na_to_K)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Age` is not correlated to `Na_to_K`"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_boxplot(df.Cholesterol, df.Na_to_K)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_boxplot(df.BP, y=df.Na_to_K)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_countplot(df.Drug)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_boxplot(df.Drug, df.Age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> `drugB` is majorly consumed by people whose age is greater than 60 while other durgs are majorly consumed by people whose age is lesser than 60.\n>\n> `DrugY` is consumed more than other drugs while `drugB` and `drugA` are consumed by less number of people"},{"metadata":{},"cell_type":"markdown","source":"### Data preparation: Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_encoding(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Sex\n    - Female - 0\n    - Male - 1\n- BP\n    - HIGH - 0\n    - LOW - 1\n    - NORMAL - 2\n- Cholesterol\n    - HIGH - 0\n    - NORMAL - 1\n    \nSince we are using `DecisionTreeClassifier` algorithm for classification, `LabelEncoding` is ok, otherwise if we are using something else where numbers matter, there we should use `OneHotEncoding`."},{"metadata":{},"cell_type":"markdown","source":"## üçÄ Modelling\n\nLet's create our `AI`.\n\n![](https://media.giphy.com/media/xT0xepagSrUXfM1eNi/giphy.gif)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\ny = df.Drug.values\n\n# Scaling x\nx = StandardScaler().fit_transform(x)\n\nprint(f'Dataset size: {len(x)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=3\n)\n\nprint(f'Training set size: {len(x_train)}')\nprint(f'Test set size: {len(x_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For cross validation\nskf = StratifiedKFold(n_splits=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\n    LogisticRegression(), \n    SGDClassifier(), \n    KNeighborsClassifier(), \n    GaussianNB(), \n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    SVC(),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    scores = cross_val_score(model, x_train, y_train, cv=skf)\n    print(f'== {model} ==')\n    print(f'Cross-Validation mean-score: {scores.mean()}')\n    \n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameter tuning\n\ndef dt_param_selection(x, y, nfolds):\n    criterion = ['gini', 'entropy']\n    splitter = ['best', 'random']\n    max_depth = [1, 2, 3, 4, 5]\n\n    param_grid = {\n        'criterion': criterion, \n        'splitter': splitter, \n        'max_depth': max_depth\n    }\n\n    grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=nfolds)\n    grid_search.fit(x, y)\n    return grid_search.best_params_\n\n\nbest_params_ = dt_param_selection(x_train, y_train, skf)\nbest_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation\n\nmodel = DecisionTreeClassifier(criterion='gini', max_depth=4, splitter='best')\nscores = cross_val_score(model, x_train, y_train, cv=skf)\nprint(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier(criterion='gini', max_depth=4, splitter='best')\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ü¶ã Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = model.predict(x_test)\n\nprint(f\"Prediction: \\n{pd.DataFrame(y_test_pred)[0].value_counts()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Actual: \\n{pd.DataFrame(y_test).value_counts()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Model Score: {model.score(x_test, y_test)}')\nprint(f'f1-score: {f1_score(y_test, y_test_pred, average=\"weighted\")}')\nprint(f'precision score: {precision_score(y_test, y_test_pred, average=\"weighted\")}')\nprint(f'recall score: {recall_score(y_test, y_test_pred, average=\"weighted\")}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the model\ndump(model, 'model.joblib')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### üêö Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from io import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = StringIO()\n\nfilename = \"drugtree.png\"\nfeatureNames = df.columns[0:5]\ntargetNames = df[\"Drug\"].unique().tolist()\n\nout=tree.export_graphviz(model,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_train), filled=True,  special_characters=True,rotate=False)  \n\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\nI'll wrap things up there. If you want to find some other answers then go ahead `edit` this kernel. If you have any `questions` then do let me know.\n\nIf this kernel helped you then don't forget to üîº `upvote` and share your üéô `feedback` on improvements of the kernel.\n\n![](https://media.giphy.com/media/Md9UQRsv94yCAjeA1w/giphy.gif)\n\n---"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}