{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loading dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/brasilian-houses-to-rent/houses_to_rent_v2.csv')\n\nnew_column_names = {'hoa (R$)':'hoa',\n                    'rent amount (R$)': 'rent_amount',\n                    'property tax (R$)':'property_tax',\n                    'fire insurance (R$)':'fire_insurance',\n                    'total (R$)':'total',\n                    'parking spaces': 'parking_spaces'}\n\ndf = df.rename(new_column_names, axis='columns')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = df.copy()\ndf_copy['floor'].replace('-',0, inplace=True)\ndf_copy['floor'] = df_copy['floor'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### What is the most popular city among brazilians"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['city'])['city'].aggregate(lambda x: x.count()/ 10692).plot(kind='pie',autopct='%.2f',fontsize=11);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### What is the average area of a house in each city"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['city'])['area'].aggregate(lambda x: x.mean()).plot(kind='bar',color=['r','g','b','y','c']\\\n    , ylabel='Average area', title='Average area in a city', fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Maximum number of rooms of a house in each city"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['city'])['rooms'].aggregate(lambda x: x.max()).plot(kind='barh',color=['r','g','b','y','c']\\\n    ,xlabel='City', title='Maximum number of rooms of a house in each city', fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Average number of rooms of a house in each city"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['city'])['rooms'].aggregate(lambda x: x.mean()).plot(kind='barh',color=['r','g','b','y','c']\\\n    ,xlabel='City', title='Average number of rooms of a house in each city', fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Maximum number of bathrooms of a house in each city"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['city'])['bathroom'].aggregate(lambda x: x.max()).plot(kind='barh',color=['r','g','b','y','c']\\\n    ,xlabel='City', title='Maximum number of bathrooms of a house in each city', fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Average number of bathrooms of a house in each city"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['city'])['bathroom'].aggregate(lambda x: x.mean()).plot(kind='barh',color=['r','g','b','y','c']\\\n    ,xlabel='City', title='Average number of bathrooms of a house in each city', fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Average number of floors of a house in each city"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy.groupby(['city'])['floor'].aggregate(lambda x: x.mean()).plot(kind='barh',color=['r','g','b','y','c']\\\n    ,xlabel='City', title='Average number of floors of a house in each city', fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### It is evident that most of the houses accept animals and most of the houses are not furnished"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(14,5))\n\nsns.countplot(x='city', hue='animal', data=df, palette=sns.color_palette(), ax=axes[0]);\nsns.countplot(x='city', hue='furniture', data=df, palette='Set1', ax=axes[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### It is also evident that 60 percent of all houses are not furnished and do accept animals"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.groupby(['animal','furniture']).size().unstack(), annot=True, fmt=\"d\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### fire insurance relationship with rent amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(14,5))\nsns.scatterplot(data=df, y='fire_insurance', x='rent_amount', hue=\"furniture\", ax=axes[0]);\nsns.scatterplot(data=df, y='fire_insurance', x='rent_amount', hue=\"animal\", ax=axes[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### rent amount relationship with area -> log-transformed dependency\n- It can be seen from the plots that there are several outliers in our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(16,5))\nsns.scatterplot(data=df, y=np.log(df['area']), x=np.log(df['rent_amount']), hue=\"furniture\", ax=axes[0]);\nsns.scatterplot(data=df, y=np.log(df['area']), x=np.log(df['rent_amount']), hue=\"animal\", ax=axes[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 46335 square meters !!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy['area'].sort_values().values[-10:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Does rental housing differ from city to city\n#### Hoa, Fire Insurance, and Property Tax impact on Rent Amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2,2, figsize=(18,8), sharex=True)\nlist_of_metrics = [['rent_amount','hoa'],['property_tax','fire_insurance']]\n\ndef bar_plot_func(ax, metric):\n    df.groupby(['city'])[f'{metric}'].aggregate(lambda x: x.mean()).plot(kind='bar',color=['r','g','b','y','c']\\\n    , ylabel='Average ' + f'{metric}', title='Average ' + f'{metric}' + ' in a city', fontsize=10, ax=ax);\n    \nbar_plot_func(axes[0,0],list_of_metrics[0][0])\nbar_plot_func(axes[0,1],list_of_metrics[0][1])\nbar_plot_func(axes[1,0],list_of_metrics[1][0])\nbar_plot_func(axes[1,1],list_of_metrics[1][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Boxplot of Rent amount by (Parking spaces, Bathroom, Room, City)\n- Does housing rent increases when the # of bathrooms increases?\n- Does housing rent increases when the # of rooms increases?\n- Does housing rent increases when the # of parking spaces increases?"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_metrics = [['parking_spaces','rooms'], ['bathroom', 'city']]\n\ndef box_plot_func(ax, metric):\n    df.boxplot(column='rent_amount', by=f'{metric}', fontsize=12, ax=ax);\n    ax.set_title(\"Boxplot of Rent amount by \" + f\"{metric}\")\n    ax.set_xlabel(f\"{metric}\")\n    ax.set_ylabel('Rent amount')\n    plt.suptitle(\"\")\n\n    \nfig, axes = plt.subplots(2,2, figsize=(16,13))\n\nbox_plot_func(axes[0,0], list_of_metrics[0][0])\nbox_plot_func(axes[0,1], list_of_metrics[0][1])\nbox_plot_func(axes[1,0], list_of_metrics[1][0])\nbox_plot_func(axes[1,1], list_of_metrics[1][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data types"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check for Nan values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train/Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndel df_copy['total']\nx, y = df_copy.drop('rent_amount',axis=1), df_copy['rent_amount']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\nprint(f'X_train shape: {x_train.shape}, X_test shape: {x_test.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nx_train.loc[:,'city'] = le.fit_transform(x_train['city'])\nx_test.loc[:,'city'] = le.transform(x_test['city'])\n\nx_train.loc[:,'animal'] = le.fit_transform(x_train['animal'])\nx_test.loc[:,'animal'] = le.transform(x_test['animal'])\n\nx_train.loc[:,'furniture'] = le.fit_transform(x_train['furniture'])\nx_test.loc[:,'furniture'] = le.transform(x_test['furniture'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(x_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"formula_str = x_train.columns[-1]+ ' ~ '+ ' + '.join(x_train.columns[:-1])\nformula_str","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as sm\n\nlm = sm.ols(formula=formula_str,data=x_train)\n\nfitted = lm.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(fitted.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Durbin Watson (DW) statistic is a test for autocorrelation in the residuals from a statistical regression analysis. A value of <b> 2.0 means that there is no autocorrelation detected in the sample</b>."},{"metadata":{},"cell_type":"markdown","source":"Not all p-values are significant, so we should remove the non-significant features from the model and test it again. The nong-significant values indicate that there is insufficient evidence in your sample to conclude that a non-zero correlation exists."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\np=plt.scatter(x=fitted.fittedvalues,y=fitted.resid,edgecolor='k')\nxmin=min(fitted.fittedvalues)\nxmax = max(fitted.fittedvalues)\nplt.hlines(y=0,xmin=xmin*0.9,xmax=xmax*1.1,color='red',linestyle='--',lw=3)\nplt.xlabel(\"Fitted values\",fontsize=15)\nplt.ylabel(\"Residuals\",fontsize=15)\nplt.title(\"Fitted vs. residuals plot\",fontsize=18)\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>violation of the constant variance assumption - Heteroscedasticity </b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nplt.hist(fitted.resid_pearson,bins=20,edgecolor='k')\nplt.ylabel('Count',fontsize=15)\nplt.xlabel('Normalized residuals',fontsize=15)\nplt.title(\"Histogram of normalized residuals\",fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### It can be inferred from the above results, we need to change our baseline model"},{"metadata":{},"cell_type":"markdown","source":"### Regression models are sensitive to feature scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean, absolute\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import HuberRegressor, LinearRegression\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler, MinMaxScaler\nfrom sklearn.compose import TransformedTargetRegressor\n\n# prepare the model with input scaling\npipeline = Pipeline(steps=[('power', PowerTransformer()), ('model', HuberRegressor())])\n# prepare the model with target scaling\nmodel = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n# evaluate model\ncv = KFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(model, x_train, y_train, scoring=['neg_root_mean_squared_error', 'r2'], cv=cv, n_jobs=-1)\nmean_mae = mean(absolute(scores['test_neg_root_mean_squared_error']))\nmean_r2 = mean(absolute(scores['test_r2']))\n\nprint(f'Mean MAE: {mean_mae:.3f}, R2: {mean_r2:.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Automatic Outlier Detection\nOur baseline model: decision tree regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\ndef dart(*args):\n    x_train, x_test, y_train, y_test = args\n    model = DecisionTreeRegressor()\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    print(f'RMAE: {mean_absolute_error(y_test, y_pred)**.5:.3f}, R-squared: {r2_score(y_test, y_pred):.3f}')\n\ndart(x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Isolation Forest -> resulted in better performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\niso = IsolationForest(contamination=0.0001)\nyhat = iso.fit_predict(x_train)\n# select all rows that are not outliers\nmask = yhat != -1\nX_train, Y_train = x_train[mask], y_train[mask]\ndart(X_train, x_test, Y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Minimum Covariance Determinant -> resulted in even better performance:)\n- Due to central limit theorem, we can say that our input has Gaussian distribution so we can use MCD"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.covariance import EllipticEnvelope\n\nee = IsolationForest(contamination=0.001)\nyhat = ee.fit_predict(x_train)\n# select all rows that are not outliers\nmask = yhat != -1\nX_train, Y_train = x_train[mask], y_train[mask]\ndart(X_train, x_test, Y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Local Outlier Factor: resulted in a better performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor\n\nlof = LocalOutlierFactor(contamination=0.001)\nyhat = lof.fit_predict(x_train)\n# select all rows that are not outliers\nmask = yhat != -1\nX_train, Y_train = x_train[mask], y_train[mask]\ndart(X_train, x_test, Y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I stick with Local Outlier Factor because it has a better performance overall."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}