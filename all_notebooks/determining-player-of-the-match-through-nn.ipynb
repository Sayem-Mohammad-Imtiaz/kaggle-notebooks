{"cells":[{"metadata":{"_uuid":"7b67d32b070dcda59068a7de2b0d21e3b9bf98b3"},"cell_type":"markdown","source":"I have attempted to built a neural network to automatically determine the 'Player of the Match' in a One Day International (ODI) cricket match. This title is given to the player who played the most significant role in the given match, and the winner is decided by the commentators.\n\nPrevious work on this topic has been done by Jhawar et al. in their paper \"[Honest Mirror: Quantitative Assessment ofPlayer Performances in an ODI Cricket Match](https://pdfs.semanticscholar.org/4dff/589c61101b590d8633725ac72016aeca2af1.pdf)\". They reported a 59.14% accuracy rate. A major difference between their approach and mine is that they used ball-by-ball data, which allows to judge a player's contribution according to the match scenario.\n\nThe dataset consists of more than 3500 cricket matches' data, scraped from ESPNcricinfo. There are 9 match attributes such as the result, the runs scored in both innings, etc. and there are 12 attributes for each player, such as runs scored, wickets taken, etc."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/data.csv')\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"241bd79985ee306958548f6215a0671e8e246b03"},"cell_type":"code","source":"data.info()\ndata=data.dropna()\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"783e38249bf06d4e6b1e63a70f6e2698eb07d105"},"cell_type":"code","source":"d = data.values\nX = []\nY = []\nfor r in d:\n    Y.append(r[3])\n    t = [np.concatenate((r[[0, 1, 2, 4, 5, 6, 7, 8, 9]], [0, 0, 0]))]\n    for i in range(1, 23):\n        t.append(r[list(range(10 + 12 * (i - 1), 10 + 12 * i))])\n    X.append(t)\nY = np.asarray(Y)\nX = np.asarray(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b419ac56778087bd9e10d9ef7fec9dcc5f3e25f1"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 1)\ny_train = label_binarize(y_train, classes=range(22))\ny_test = label_binarize(y_test, classes=range(22))\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2275d2f04cbdbcb95d9510ec9a08881250ff5115"},"cell_type":"code","source":"def create_placeholders():\n    X = tf.placeholder(tf.float32, shape=(None, 23, 12))\n    Y = tf.placeholder(tf.float32, shape=(None, 22))\n    return X,Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43b5e8520c3373b392f7a647a2c65839edaba15c"},"cell_type":"code","source":"def initialize_parameters(layers_dims):\n    L1 = len(layers_dims)\n    parameters = {}\n    for l in range(1, L1):\n        parameters['W' + str(l)] = tf.get_variable(shape=[layers_dims[l - 1], layers_dims[l]], initializer=tf.contrib.layers.variance_scaling_initializer(seed=l), name='W' + str(l))\n        parameters['b' + str(l)] = tf.get_variable(shape=[1, layers_dims[l]], initializer=tf.zeros_initializer(), name='b' + str(l))\n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a92620062ef5a5c8f27b67a94e179d8185c92b9"},"cell_type":"markdown","source":"The idea is to generate a score for each player by passing the match attributes (7) and the player attributes (12) through a fully-connected neural network with three hidden layers of size 12, 6, and 3. The scores are then passed to a softmax layer to determine the 'Player of the Match'."},{"metadata":{"trusted":true,"_uuid":"a8e1b9b9d3f1dd34ede8d0562a72ce7a9507313e"},"cell_type":"code","source":"def forward_propagation(X, parameters):\n    L1 = len(parameters) // 2\n    values = {}\n    mat = X[:, 0, 1:9]\n    values['Z'] = [0 for _ in range(22)]\n    for p in range(22):\n        values['A' + str(p) + '0'] = tf.concat((mat, X[:, p + 1]), axis=1)\n        for l in range(1, L1):\n            values['Z' + str(p) + str(l)] = tf.add(tf.matmul(values['A' + str(p) + str(l - 1)], parameters['W' + str(l)]), parameters['b' + str(l)])\n            values['A' + str(p) + str(l)] = tf.nn.leaky_relu(values['Z' + str(p) + str(l)])\n        values['Z'][p] = tf.add(tf.matmul(values['A' + str(p) + str(L1 - 1)], parameters['W' + str(L1)]), parameters['b' + str(L1)])\n    values['Z'] = tf.reshape(tf.stack(values['Z'], axis=1), [-1, 22])\n    return values['Z']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7c7f81d694235d8a3467c0af4e0565811774090"},"cell_type":"code","source":"def compute_cost(Y, Z):\n    vars = tf.trainable_variables() \n    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=Z, labels=tf.argmax(Y, axis=1)))\n    return cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba4ce3a5070bf702367b4ccb1654f6aa36845bbb"},"cell_type":"code","source":"def model(X_train, Y_train, layers_dims, learning_rate, epochs, print_costs=False):    \n    tf.reset_default_graph()\n    m = X_train.shape[0]\n    X, Y = create_placeholders()\n    layers_dims = [20] + layers_dims + [1]\n    parameters = initialize_parameters(layers_dims)\n    Z = forward_propagation(X, parameters)\n    cost = compute_cost(Y, Z)\n    \n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n    costs = []\n    \n    init = tf.global_variables_initializer()\n    \n    with tf.Session() as sess:\n        sess.run(init)\n        num = 1\n        while num <= epochs:\n            _, epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n            if print_costs and num % 1000 == 0:\n                print('Cost after epoch', num, '=', epoch_cost)\n            if num % 5000 == 0:\n              learning_rate -= 0.001\n            if print_costs and num > 15:\n                costs.append(epoch_cost)\n            num += 1\n        \n        if print_costs:\n            plt.plot(np.squeeze(costs))\n            plt.xlabel('Epoch number')\n            plt.ylabel('Cost')\n            plt.show()\n        \n        parameters = sess.run(parameters)\n        correct_predictions = tf.equal(tf.argmax(Y, axis=1), tf.argmax(Z, axis=1))\n        accuracy = tf.reduce_mean(tf.cast(correct_predictions, 'float'))\n        print('Training Accuracy:', accuracy.eval({X: X_train, Y: Y_train}))\n        \n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f77c0450efad414057d43a04dcc8dae6117865c"},"cell_type":"code","source":"parameters = model(X_train, y_train, layers_dims=[12, 6, 3], epochs=10000, learning_rate=0.001, print_costs=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ac27a81b835241b95d39fd4b17cc6721605b0a82"},"cell_type":"code","source":"def test(X_test, Y_test, parameters):\n    X = tf.placeholder(tf.float32, shape=X_test.shape)\n    Z = forward_propagation(X, parameters)\n    correct_predictions = tf.equal(tf.argmax(Y_test, axis=1), tf.argmax(Z, axis=1))\n    accuracy = tf.reduce_mean(tf.cast(correct_predictions, 'float'))\n    top2 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(predictions=Z, targets=tf.argmax(Y_test, axis=1), k=2), tf.float32))\n    top3 = tf.reduce_mean(tf.cast(tf.nn.in_top_k(predictions=Z, targets=tf.argmax(Y_test, axis=1), k=3), tf.float32))\n    with tf.Session() as sess:\n        print('Test Accuracy:', accuracy.eval({X: X_test}))\n        print('Top-2 Accuracy:', top2.eval({X: X_test}))\n        print('Top-3 Accuracy:', top3.eval({X: X_test}))\n        return Z.eval({X: X_test})\n\ny_pred = test(X_test, y_test, parameters)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ff9dde965076ef15a2c23ad6eb88a49ced3dd61"},"cell_type":"markdown","source":"The model has a better top-1, top-2, and top-3 accuracy rates than the one reported by Jhawar et al. However the apparently low training accuracy suggests that the model suffers from underfitting."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}