{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport plotly.express as px\n\n# Load libraries\n\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import  linear_model\nfrom sklearn.model_selection import KFold\n\nfrom plotly.offline import init_notebook_mode, plot, iplot\nimport plotly as py\ninit_notebook_mode(connected=True) \nimport plotly.graph_objs as go # plotly graphical object\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the data\nusa_data = pd.read_csv(\"../input/covid19-in-usa/us_counties_covid19_daily.csv\")\n\n# Data Glimpse\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data[(usa_data['deaths']>50) & (usa_data['date'])]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data['deaths'].mode()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data['deaths'].std()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data.cov()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Korelasyon Gösterim\nimport seaborn as sns\ncorr = usa_data.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data.plot(x='date', y='deaths', style='-')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data.isnull().sum().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Özniteliklerin değer almadığı kaç satır var?\nusa_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Eksik değer tablosu\ndef eksik_deger_tablosu(usa_data): \n    eksik_deger = usa_data.isnull().sum()\n    eksik_deger_yuzde = 100 * usa_data.isnull().sum()/len(usa_data)\n    eksik_deger_tablo = pd.concat([eksik_deger, eksik_deger_yuzde], axis=1)\n    eksik_deger_tablo_son = eksik_deger_tablo.rename(\n    columns = {0 : 'Eksik Değerler', 1 : '% Değeri'})\n    return eksik_deger_tablo_son\n  \neksik_deger_tablosu(usa_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%70 üzerinde null değer içeren kolonları sil\ntr = len(usa_data) * .3\nusa_data.dropna(thresh = tr, axis = 1, inplace = True)\n\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply fonksiyonu \ndef olum_durumu(deaths):\n    return (deaths >= 100)\n\nusa_data['yuksek_olum'] = usa_data['deaths'].apply(olum_durumu)\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#veri bilgisini 0 ve 1lere çevirdik.\n\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder() \nusa_data['yuksek_olum_Encoded']= label_encoder.fit_transform(usa_data['yuksek_olum'])\n\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#deaths özniteliğini ölçeklendirmek istiyoruz\nx = usa_data[['deaths']].values.astype(float)\n\n#Ölçeklendirme için MinMaxScaler fonksiyonunu kullanıyoruz.\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nusa_data['deaths2'] = pd.DataFrame(x_scaled)\n\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quartile (Kartiller) ve IQR ile Aykırı Değer Tespiti\n\nimport seaborn as sns\nsns.boxplot(x=usa_data['deaths'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = usa_data.deaths.quantile(0.25)\nQ2 = usa_data.deaths.quantile(0.5)\nQ3 = usa_data.deaths.quantile(0.75)\nQ4 = usa_data.deaths.quantile(1)\nIQR = Q3 - Q1\n\nprint(\"Q1-->\", Q1)\nprint(\"Q3-->\", Q3)\nprint(\"Q2-->\", Q2)\nprint(\"Q4-->\", Q4)\nprint(\"IQR-->\", IQR)\nprint(\"Alt sınır: Q1 - 1.5 * IQR--->\", Q1 - 1.5 * IQR)\nprint(\"Üst sınır: Q3 + 1.5 * IQR--->\", Q3 + 1.5 * IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import HTML\nHTML('''<div class=\"flourish-embed\" data-src=\"story/258632\" data-url=\"https://flo.uri.sh/story/258632/embed\"><script src=\"https://public.flourish.studio/resources/embed.js\"></script></div>''')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_details = pd.pivot_table(usa_data, values=['cases','deaths'], index='state', aggfunc='max')\nstate_details['Death Rate'] = round(state_details['deaths'] /state_details['cases'], 2)\nstate_details = state_details.sort_values(by='cases', ascending= False)\nstate_details.style.background_gradient(cmap='YlOrRd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(usa_data, x=\"date\", y=\"total\")\n\nlayout = go.Layout(\n    title=go.layout.Title(\n        text=\"ABD'de zaman içinde kümülatif Toplam COVID-19 testi sayısı\",\n        x=0.5\n    ),\n    font=dict(size=14),\n    width=800,\n    height=500,\n    xaxis_title = \"Gözlem tarihi\",\n    yaxis_title = \"Covid-19 testlerinin sayısı\"\n)\n\nfig.update_layout(layout)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest_data = usa_data[usa_data[\"date\"] == max(usa_data[\"date\"])].reset_index()\ncountry_latest_data = latest_data.groupby('state').sum().reset_index().sort_values(by = 'cases',ascending = False).head(5)\nfig = go.Figure(data=[\n    #go.Bar(name='Confirmed', x=country_latest_data[\"state\"], y=country_latest_data['cases'],marker_color = 'rgb(55, 83, 109)'),\n    go.Bar(name='vaka', x=country_latest_data[\"state\"], y=country_latest_data['cases'],marker_color = 'lightsalmon'),\n    go.Bar(name = 'ölüm',x=country_latest_data[\"state\"],y=country_latest_data['deaths'],marker_color = 'crimson' ),\n    \n])\nfig.update_layout(barmode='group',title_text ='İlk 5 eyalet ')\nfig.layout.template ='plotly_dark'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data.loc[usa_data['deaths'] <10, 'Sınıf'] = 'İyi'\nusa_data.loc[ (usa_data['deaths'] >= 100) & (usa_data['deaths'] < 300), 'Sınıf'] = 'Önemli'\nusa_data.loc[ (usa_data['deaths'] >= 50) & (usa_data['deaths'] < 100), 'Sınıf'] = 'Güçlü'\nusa_data.loc[ (usa_data['deaths'] >= 25) & (usa_data['deaths'] < 50), 'Sınıf'] = 'Ilımlı'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data.dropna(how=\"any\",inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Magnitude Class distribution\n\nsns.countplot(x=\"Sınıf\", data=usa_data)\nplt.ylabel('Sıklık')\nplt.title('Önem derecesi VS Sıklık')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder() \nusa_data['county_Encoded']= label_encoder.fit_transform(usa_data['county'])\nusa_data['state_Encoded']= label_encoder.fit_transform(usa_data['state'])\nusa_data['fips_Encoded']= label_encoder.fit_transform(usa_data['fips'])\nusa_data['deaths_Encoded']= label_encoder.fit_transform(usa_data['deaths'])\nusa_data['cases_Encoded']= label_encoder.fit_transform(usa_data['cases'])\n\n\n\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data =usa_data.drop(columns ='county')\nusa_data =usa_data.drop(columns ='state')\nusa_data =usa_data.drop(columns ='fips')\nusa_data =usa_data.drop(columns ='cases')\nusa_data =usa_data.drop(columns ='deaths')\nusa_data =usa_data.drop(columns ='yuksek_olum_Encoded')\nusa_data =usa_data.drop(columns ='yuksek_olum')\nusa_data =usa_data.drop(columns ='deaths2')\nusa_data =usa_data.drop(columns ='date')\n\n\n\n\n\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = usa_data.values\nX = array[:,1:6]\ny = array[:,0:1]\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\n\nprint(\"Dataframe boyutu: \",usa_data.shape)\nprint(\"Eğitim verisi boyutu: \",X_train.shape, Y_train.shape)\nprint(\"Test verisi boyutu: \",X_validation.shape, Y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn import utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n#Decision Trees\ncellTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nprint(cellTree) # it shows the default parameters\n  #I fit the data with the training\ncellTree.fit(X_train,Y_train)\n  #now predictions\nyhat_dt = cellTree.predict(X_validation)\n\n  #Accuracy evaluation\nacc = metrics.accuracy_score(Y_validation, yhat_dt)\nprint('karar agaci icin accuracy: ',acc)\n\n#karar agaci icin confusion matrix ve metrik degerler\ncellTree_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_dt = cross_val_score(cellTree_dt, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_dt)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_dt)))\nfrom sklearn.metrics import classification_report\nprec_dt = classification_report(yhat_dt,Y_validation)\nprint(prec_dt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#call the models\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(n_neighbors = 3)\n# fit the models\nneigh = knn_model.fit(X_train,Y_train)\n#predict the mode;\nyhatknn=neigh.predict(X_validation)\n\n  #Accuracy evaluation\naccknn = metrics.accuracy_score(Y_validation, yhatknn)\nprint('en yakin komsular icin accuracy',accknn)\n\n#knn=3 icin confusion matrix ve metrik degerler\nknn_knn = KNeighborsClassifier(n_neighbors = 3)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_knn = cross_val_score(knn_knn, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_knn)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_knn)))\n\n#knn scores\nfrom sklearn.metrics import classification_report\nprec_knn = classification_report(yhatknn,Y_validation)\nprint(prec_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lojistik regresyon\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,Y_train)\nLR\n#predict\nyhatlr = LR.predict(X_validation)\n#print('yhat', yhat)\n  #Accuracy evaluation\nacclr = metrics.accuracy_score(Y_validation, yhatlr)\nprint('lojistik regresyon icin accuracy',acclr)\n\n\n#lojistik regresyon icin confusion matrix ve metrik degerler\nlr_lr = LogisticRegression(C=0.01, solver='liblinear')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_lr = cross_val_score(lr_lr, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_lr)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_lr)))\n\n\nfrom sklearn.metrics import classification_report\nprec_lr = classification_report(yhatlr,Y_validation)\nprint(prec_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVM \nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, Y_train) \n#predict\nyhatsvm = clf.predict(X_validation)\n#yhat [0:5]\naccsvm = metrics.accuracy_score(Y_validation, yhatsvm)\nprint('svm icin accuracy',accsvm)\n\n\n\n#svm icin confusion matrix ve metrik degerler\nclf_svm = svm.SVC(kernel='rbf')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_svm = cross_val_score(clf_svm, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_svm)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_svm)))\n\n\nfrom sklearn.metrics import classification_report\nprec_svm = classification_report(yhatsvm,Y_validation)\nprint(prec_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gaussian NB \n# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n#call the models\ngnb = GaussianNB()\n  #fit the model\ngnb.fit(X_train, Y_train) \n  #predict\nyhatgnb = gnb.predict(X_validation)\naccgnb = metrics.accuracy_score(Y_validation, yhatgnb)\nprint('gaussian naive bayes icin accuracy',accgnb)\n\n\n#gaussian naive bayes icin confusion matrix ve metrik degerler\nclf_gnb = GaussianNB()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_gnb = cross_val_score(clf_gnb, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_gnb)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_gnb)))\n\n#klasifikasyon tablosu\nfrom sklearn.metrics import classification_report\nprec_gnb = classification_report(yhatgnb,Y_validation)\nprint(prec_gnb)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear discriminant analysis \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\n#fit the model\nlda.fit(X_train, Y_train) \n#predict\nyhatlda = lda.predict(X_validation)\nacclda = metrics.accuracy_score(Y_validation, yhatlda)\nprint('linear discriminant analiz icin accuracy',acclda)\n\n\n\n\n#linear discrimant icin confusion matrix ve metrik degerler\nclf_ld = LinearDiscriminantAnalysis()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_ld = cross_val_score(clf_ld, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_ld)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_ld)))\n\n#klasifikasyon linear diskrimannt\nfrom sklearn.metrics import classification_report\nprec_lda = classification_report(yhatlda,Y_validation)\nprint(prec_lda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nrfc = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\nrfc.fit(X_train, Y_train) \n#predict\nyhat1 = rfc.predict(X_validation)\n#yhat [0:5]\n#evaluate\n\n#create a new SVM model\nrfc_cv = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\n#train model with cv of 10\ncv_scores = cross_val_score(rfc_cv, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores)))\n\n\n\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nfrom sklearn.metrics import f1_score\nprint('f1_score for Random Forest Classifier:',f1_score(Y_validation, yhat1, average='weighted'))\n#print(\"Train set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, rfc.predict(X_train)))\n#print(\"Test set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, yhat1))\nfrom sklearn.metrics import classification_report\nprec_rec = classification_report(yhat1,Y_validation)\nprint(prec_rec)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}