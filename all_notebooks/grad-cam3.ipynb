{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import backend as K\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\nimport shutil\nimport cv2\nimport os\n\nprint(tf.version.VERSION)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imutils import paths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = './dataset'\nlog_path = './logs'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\nrm -rf dataset\nmkdir -p dataset/covid\nmkdir -p dataset/normal\nmkdir -p dataset/pneumonia\nmkdir -p logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_dataset_path='../input/covid-chest-xray'\ncsvPath = os.path.sep.join([covid_dataset_path, \"metadata.csv\"])\ndf = pd.read_csv(csvPath)\n\nfor (i, row) in df.iterrows():\n    # if (1) the current case is not COVID-19 or (2) this is not\n    # a 'PA' view, then ignore the row\n    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n        continue\n\n    imagePath = os.path.sep.join([covid_dataset_path, \"images\", row[\"filename\"]])\n\n    if not os.path.exists(imagePath):\n        continue\n\n    filename = row[\"filename\"].split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/covid\", filename])\n\n    shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir('../working/dataset/covid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = 141","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pneumonia_dataset_path ='../input/chest-xray-pneumonia/chest_xray'\n\n\nbasePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"NORMAL\"])\nimagePaths = list(paths.list_images(basePath))\n\n# randomly sample the image paths\nrandom.seed(42)\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:samples]\n\nfor (i, imagePath) in enumerate(imagePaths):\n    filename = imagePath.split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n\n    shutil.copy2(imagePath, outputPath)\n\n\n    \nbasePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"PNEUMONIA\"])\nimagePaths = list(paths.list_images(basePath))\n\n# randomly sample the image paths\nrandom.seed(42)\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:samples]\n\nfor (i, imagePath) in enumerate(imagePaths):\n    filename = imagePath.split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/pneumonia\", filename])\n\n    shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir('../working/dataset/pneumonia'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !ls ../input/covid-chest-xray/images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recreate the exact same model, including its weights and the optimizer\nbase_model = tf.keras.models.load_model('/kaggle/input/covid-19-pretrained1/final_cnn_model.h5')\n\n# Show the model architecture\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_names = ['Normal', 'COVID-19', 'Pneumonia']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import data, color, io, img_as_float\n\ndef get_heatmap(vgg_conv, processed_image, class_idx):\n    # we want the activations for the predicted label\n    class_output = vgg_conv.output[:, class_idx]\n    \n    # choose the last conv layer in your model\n    last_conv_layer = vgg_conv.get_layer('block5_conv3')\n    \n    # get the gradients wrt to the last conv layer\n    grads = K.gradients(class_output, last_conv_layer.output)[0]\n    \n    # we pool the gradients over all the axes leaving out the channel dimension\n    pooled_grads = K.mean(grads, axis=(0,1,2))\n    \n    # Define a function that generates the values for the output and gradients\n    iterate = K.function([vgg_conv.input], [pooled_grads, last_conv_layer.output[0]])\n    \n    # get the values\n    grads_values, conv_ouput_values = iterate([processed_image])\n    \n    # iterate over each feature map in your conv output and multiply\n    # the gradient values with the conv output values. This gives an \n    # indication of \"how important a feature is\"\n    for i in range(512): # we have 512 features in our last conv layer\n        conv_ouput_values[:,:,i] *= grads_values[i]\n    \n    # create a heatmap\n    heatmap = np.mean(conv_ouput_values, axis=-1)\n    \n    # remove negative values\n    heatmap = np.maximum(heatmap, 0)\n    \n    # normalize\n    heatmap /= heatmap.max()\n    \n    return heatmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_GradCAM(base_model, path_image):\n    # select the sample and read the corresponding image and label\n    sample_image = cv2.imread(path_image)\n    # pre-process the image\n    sample_image = cv2.resize(sample_image, (224,224))\n    if sample_image.shape[2] ==1:\n                sample_image = np.dstack([sample_image, sample_image, sample_image])\n    sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n    sample_image = sample_image.astype(np.float32)/255.\n#     sample_label = 1\n\n    #since we pass only one image,we expand dim to include batch size 1\n    sample_image_processed = np.expand_dims(sample_image, axis=0)\n\n    # get the label predicted by our original model\n    pred_label = np.argmax(base_model.predict(sample_image_processed), axis=-1)[0]\n    print(base_model.predict(sample_image_processed))\n\n    # get the heatmap for class activation map(CAM)\n    heatmap = get_heatmap(base_model, sample_image_processed, pred_label)\n    heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n    heatmap = heatmap *255\n    heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n    heatmap = 255 - heatmap\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n    # f,ax = plt.subplots(1,2, figsize=(16,6))\n    plt.figure()\n    f, ax = plt.subplots(ncols=3, figsize=(16, 6))\n\n    ax[1].imshow(heatmap)\n    ax[1].set_title(\"heatmap\")\n    ax[1].axis('off')\n\n    #superimpose the heatmap on the image    \n    sample_image_hsv = color.rgb2hsv(sample_image)\n    heatmap = color.rgb2hsv(heatmap)\n\n    alpha=0.7\n    sample_image_hsv[..., 0] = heatmap[..., 0]\n    sample_image_hsv[..., 1] = heatmap[..., 1] * alpha\n\n    img_masked = color.hsv2rgb(sample_image_hsv)\n\n    # f,ax = plt.subplots(1,2, figsize=(16,6))\n    ax[0].imshow(sample_image)\n    ax[0].set_title(f\"original image (predicted label: {target_names[pred_label]})\")\n    ax[0].axis('off')\n\n    ax[2].imshow(img_masked)\n    ax[2].set_title(\"superimposed image\")\n    ax[2].axis('off')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filename = random.choice(os.listdir('../working/dataset/pneumonia'))\n# outputPath = os.path.sep.join([f\"../working/dataset/pneumonia\", filename])\n# outputPath","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normal\noutputPath = '../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0037-0001.jpeg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normal\noutputPath = '../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0011-0001-0002.jpeg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pnu\noutputPath = '../input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person108_bacteria_507.jpeg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pnu\noutputPath = '../input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person120_bacteria_570.jpeg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid\noutputPath = '../input/covid-chest-xray/images/1-s2.0-S0929664620300449-gr2_lrg-a.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid\noutputPath = '../input/covid-chest-xray/images/16654_2_1.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid\noutputPath = '../input/covid-chest-xray/images/16660_1_1.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid\noutputPath = '../input/covid-chest-xray/images/16660_5_1.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid\noutputPath = '../input/covid-chest-xray/images/16664_1_1.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid -f\noutputPath = '../input/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/covid/03BF7561-A9BA-4C3C-B8A0-D3E585F73F3C-1068x1083.jpeg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid\noutputPath = '../input/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/covid/COVID-19 (124).jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normal\noutputPath = '../input/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/normal/00000005_005.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normal\noutputPath = './covid.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_GradCAM(base_model, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pneumonia_dataset_path ='../input/chest-xray-pneumonia/chest_xray'\n\n\nbasePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"NORMAL\"])\nimagePaths = list(paths.list_images(basePath))\n\n# randomly sample the image paths\nrandom.seed(42)\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:samples]\n\nfor (i, imagePath) in enumerate(imagePaths):\n    filename = imagePath.split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n\n#     shutil.copy2(imagePath, outputPath)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"PNEUMONIA\"])\nimagePaths = list(paths.list_images(basePath))\n\n# randomly sample the image paths\nrandom.seed(42)\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:samples]\n\nfor (i, imagePath) in enumerate(imagePaths):\n    filename = imagePath.split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/pneumonia\", filename])\n    \n    print_GradCAM(base_model, imagePath)\n\n#     shutil.copy2(imagePath, outputPath)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_dataset_path='../input/covid-chest-xray'\ncsvPath = os.path.sep.join([covid_dataset_path, \"metadata.csv\"])\ndf = pd.read_csv(csvPath)\n\nfor (i, row) in df.iterrows():\n    # if (1) the current case is not COVID-19 or (2) this is not\n    # a 'PA' view, then ignore the row\n    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n        continue\n\n    imagePath = os.path.sep.join([covid_dataset_path, \"images\", row[\"filename\"]])\n\n    if not os.path.exists(imagePath):\n        continue\n\n    print(imagePath)\n    print_GradCAM(base_model, imagePath)\n    \n#     filename = row[\"filename\"].split(os.path.sep)[-1]\n#     outputPath = os.path.sep.join([f\"{dataset_path}/covid\", filename])\n\n#     shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install wget","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wget\nurl = \"https://drive.google.com/uc?export=download&id=1dt6yTMEV0kNG7ZUa7rmIZDWH-JGjlzzf\"\nfilename = wget.download(url, out=\"covid.png\")\nfilename","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class_to_label_map = {'pneumonia' : 2, 'covid' : 1, 'normal' : 0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset_path ='../input/covid-chest-xray/images'\n# imagePaths = list(paths.list_images(dataset_path))\n# data = []\n# labels = []\n# for imagePath in imagePaths:\n#     label = imagePath.split(os.path.sep)[-2]\n#     image = cv2.imread(imagePath)\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#     image = cv2.resize(image, (224, 224), interpolation = cv2.INTER_AREA)\n#     data.append(image)\n# #     labels.append(class_to_label_map[label])\n    \n# data = np.array(data) / 255.0\n# # labels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # select the sample and read the corresponding image and label\n# sample_image = cv2.imread('../input/covid-chest-xray/images/1312A392-67A3-4EBF-9319-810CF6DA5EF6.jpeg')\n# # pre-process the image\n# sample_image = cv2.resize(sample_image, (224,224))\n# if sample_image.shape[2] ==1:\n#             sample_image = np.dstack([sample_image, sample_image, sample_image])\n# sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n# sample_image = sample_image.astype(np.float32)/255.\n# sample_label = 1\n\n# #since we pass only one image,we expand dim to include batch size 1\n# sample_image_processed = np.expand_dims(data[100], axis=0)\n    \n# # get the label predicted by our original model\n# pred_label = np.argmax(base_model.predict(sample_image_processed), axis=-1)[0]\n# print(base_model.predict(sample_image_processed))\n    \n# # get the heatmap for class activation map(CAM)\n# heatmap = get_heatmap(base_model, sample_image_processed, pred_label)\n# heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n# heatmap = heatmap *255\n# heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n# heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n# # f,ax = plt.subplots(1,2, figsize=(16,6))\n# f, ax = plt.subplots(ncols=3, figsize=(16, 6))\n\n# ax[1].imshow(heatmap)\n# ax[1].set_title(\"heatmap\")\n# ax[1].axis('off')\n\n# #superimpose the heatmap on the image    \n# sample_image_hsv = color.rgb2hsv(sample_image)\n# heatmap = color.rgb2hsv(heatmap)\n\n# alpha=0.5\n# sample_image_hsv[..., 0] = heatmap[..., 0]\n# sample_image_hsv[..., 1] = heatmap[..., 1] * alpha\n\n# img_masked = color.hsv2rgb(sample_image_hsv)\n\n# # f,ax = plt.subplots(1,2, figsize=(16,6))\n# ax[0].imshow(sample_image)\n# ax[0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label} \\n original image\")\n# ax[0].axis('off')\n\n# ax[2].imshow(img_masked)\n# ax[2].set_title(\"superimposed image\")\n# ax[2].axis('off')\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(1,50):\n#     #since we pass only one image,we expand dim to include batch size 1\n#     sample_image_processed = np.expand_dims(data[i], axis=0)\n\n#     # get the label predicted by our original model\n#     pred_label = np.argmax(base_model.predict(sample_image_processed), axis=-1)[0]\n#     print(base_model.predict(sample_image_processed))\n\n#     # get the heatmap for class activation map(CAM)\n#     heatmap = get_heatmap(base_model, sample_image_processed, pred_label)\n#     heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n#     heatmap = heatmap *255\n#     heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n#     heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n#     # f,ax = plt.subplots(1,2, figsize=(16,6))\n#     f, ax = plt.subplots(ncols=3, figsize=(16, 6))\n\n#     ax[1].imshow(heatmap)\n#     ax[1].set_title(\"heatmap\")\n#     ax[1].axis('off')\n\n#     #superimpose the heatmap on the image    \n#     sample_image_hsv = color.rgb2hsv(sample_image)\n#     heatmap = color.rgb2hsv(heatmap)\n\n#     alpha=0.5\n#     sample_image_hsv[..., 0] = heatmap[..., 0]\n#     sample_image_hsv[..., 1] = heatmap[..., 1] * alpha\n\n#     img_masked = color.hsv2rgb(sample_image_hsv)\n\n#     # f,ax = plt.subplots(1,2, figsize=(16,6))\n#     ax[0].imshow(sample_image)\n#     ax[0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label} \\n original image\")\n#     ax[0].axis('off')\n\n#     ax[2].imshow(img_masked)\n#     ax[2].set_title(\"superimposed image\")\n#     ax[2].axis('off')\n\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def superimpose(img, cam):\n#     \"\"\"superimpose original image and cam heatmap\"\"\"\n    \n#     heatmap = cv2.resize(cam, (img.shape[1], img.shape[0]))\n#     heatmap = np.uint8(255 * heatmap)\n#     heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n#     superimposed_img = heatmap * .5 + img * .5\n#     superimposed_img = np.minimum(superimposed_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n#     superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n    \n#     return img, heatmap, superimposed_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def _plot(model, cam_func, img, cls_true):\n#     \"\"\"plot original image, heatmap from cam and superimpose image\"\"\"\n    \n#     # for cam\n#     x = np.expand_dims(img, axis=0)\n# #     x = preprocess_input(copy.deepcopy(x))\n\n#     # for superimpose\n#     img = np.uint8(img)\n\n#     # cam / superimpose\n#     cls_pred, cam = cam_func(model=model, x=x, layer_name=model.layers[-2].name)\n#     img, heatmap, superimposed_img = superimpose(img, cam)\n\n#     fig, axs = plt.subplots(ncols=3, figsize=(9, 4))\n\n#     axs[0].imshow(img)\n#     axs[0].set_title('original image')\n#     axs[0].axis('off')\n\n#     axs[1].imshow(heatmap)\n#     axs[1].set_title('heatmap')\n#     axs[1].axis('off')\n\n#     axs[2].imshow(superimposed_img)\n#     axs[2].set_title('superimposed image')\n#     axs[2].axis('off')\n\n#     plt.suptitle('True label: ' + class_to_label[cls_true] + ' / Predicted label : ' + class_to_label[cls_pred])\n#     plt.tight_layout()\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## Grad-CAM function\n\n# def grad_cam(model, x, layer_name):\n#     \"\"\"Grad-CAM function\"\"\"\n    \n#     cls = np.argmax(model.predict(x))\n    \n#     y_c = model.output[0, cls]\n#     conv_output = model.get_layer(layer_name).output\n#     grads = K.gradients(y_c, conv_output)[0]\n\n#     # Get outputs and grads\n#     gradient_function = K.function([model.input], [conv_output, grads])\n#     output, grads_val = gradient_function([x])\n#     output, grads_val = output[0, :], grads_val[0, :, :, :]\n    \n#     weights = np.mean(grads_val, axis=(0, 1)) # Passing through GlobalAveragePooling\n\n#     cam = np.dot(output, weights) # multiply\n#     cam = np.maximum(cam, 0)      # Passing through ReLU\n#     cam /= np.max(cam)            # scale 0 to 1.0\n\n#     return cls, cam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# _plot(model=base_model, cam_func=grad_cam, img=data[0], cls_true=\"Classes[0]\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # select the sample and read the corresponding image and label\n# sample_image = cv2.imread('../input/covid-chest-xray/images/1.CXRCTThoraximagesofCOVID-19fromSingapore.pdf-001-fig2b.png')\n# # pre-process the image\n# sample_image = cv2.resize(sample_image, (224,224))\n# if sample_image.shape[2] ==1:\n#             sample_image = np.dstack([sample_image, sample_image, sample_image])\n# sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n# sample_image = sample_image.astype(np.float32)/255.\n# sample_label = 1\n\n# #since we pass only one image,we expand dim to include batch size 1\n# sample_image_processed = np.expand_dims(sample_image, axis=0)\n    \n# # get the label predicted by our original model\n# pred_label = np.argmax(base_model.predict(sample_image_processed), axis=-1)[0]\n# print(base_model.predict(sample_image_processed))\n    \n# # get the heatmap for class activation map(CAM)\n# heatmap = grad_cam(base_model, sample_image_processed, pred_label)\n# heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n# heatmap = heatmap *255\n# heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n# heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n# # f,ax = plt.subplots(1,2, figsize=(16,6))\n# f, ax = plt.subplots(ncols=3, figsize=(16, 6))\n\n# ax[1].imshow(heatmap)\n# ax[1].set_title(\"heatmap\")\n# ax[1].axis('off')\n\n# #superimpose the heatmap on the image    \n# sample_image_hsv = color.rgb2hsv(sample_image)\n# heatmap = color.rgb2hsv(heatmap)\n\n# alpha=0.5\n# sample_image_hsv[..., 0] = heatmap[..., 0]\n# sample_image_hsv[..., 1] = heatmap[..., 1] * alpha\n\n# img_masked = color.hsv2rgb(sample_image_hsv)\n\n# # f,ax = plt.subplots(1,2, figsize=(16,6))\n# ax[0].imshow(sample_image)\n# ax[0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label} \\n original image\")\n# ax[0].axis('off')\n\n# ax[2].imshow(img_masked)\n# ax[2].set_title(\"superimposed image\")\n# ax[2].axis('off')\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nimport tensorflow as tf\nimport numpy as np\nimport cv2\n\nclass GradCAM:\n    def __init__(self, model, classIdx, layerName=None):\n        # store the model, the class index used to measure the class\n        # activation map, and the layer to be used when visualizing\n        # the class activation map\n        self.model = model\n        self.classIdx = classIdx\n        self.layerName = layerName\n\n        # if the layer name is None, attempt to automatically find\n        # the target output layer\n        if self.layerName is None:\n            self.layerName = self.find_target_layer()\n\n    def find_target_layer(self):\n        # attempt to find the final convolutional layer in the network\n        # by looping over the layers of the network in reverse order\n        for layer in reversed(self.model.layers):\n            # check to see if the layer has a 4D output\n            if len(layer.output_shape) == 4:\n                return layer.name\n\n        # otherwise, we could not find a 4D layer so the GradCAM\n        # algorithm cannot be applied\n        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n\n    def compute_heatmap(self, image, eps=1e-8):\n        # construct our gradient model by supplying (1) the inputs\n        # to our pre-trained model, (2) the output of the (presumably)\n        # final 4D layer in the network, and (3) the output of the\n        # softmax activations from the model\n        gradModel = Model(\n            inputs=[self.model.inputs],\n            outputs=[self.model.get_layer(self.layerName).output, \n                self.model.output])\n\n        # record operations for automatic differentiation\n        with tf.GradientTape() as tape:\n            # cast the image tensor to a float-32 data type, pass the\n            # image through the gradient model, and grab the loss\n            # associated with the specific class index\n            inputs = tf.cast(image, tf.float32)\n            (convOutputs, predictions) = gradModel(inputs)\n            loss = predictions[:, self.classIdx]\n\n        # use automatic differentiation to compute the gradients\n        grads = tape.gradient(loss, convOutputs)\n\n        # compute the guided gradients\n        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n        castGrads = tf.cast(grads > 0, \"float32\")\n        guidedGrads = castConvOutputs * castGrads * grads\n\n        # the convolution and guided gradients have a batch dimension\n        # (which we don't need) so let's grab the volume itself and\n        # discard the batch\n        convOutputs = convOutputs[0]\n        guidedGrads = guidedGrads[0]\n\n        # compute the average of the gradient values, and using them\n        # as weights, compute the ponderation of the filters with\n        # respect to the weights\n        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n\n        # grab the spatial dimensions of the input image and resize\n        # the output class activation map to match the input image\n        # dimensions\n        (w, h) = (image.shape[2], image.shape[1])\n        heatmap = cv2.resize(cam.numpy(), (w, h))\n\n        # normalize the heatmap such that all values lie in the range\n        # [0, 1], scale the resulting values to the range [0, 255],\n        # and then convert to an unsigned 8-bit integer\n        numer = heatmap - np.min(heatmap)\n        denom = (heatmap.max() - heatmap.min()) + eps\n        heatmap = numer / denom\n        heatmap = (heatmap * 255).astype(\"uint8\")\n\n        # return the resulting heatmap to the calling function\n        return heatmap\n\n    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n        colormap=cv2.COLORMAP_VIRIDIS):\n        # apply the supplied color map to the heatmap and then\n        # overlay the heatmap on the input image\n        heatmap = cv2.applyColorMap(heatmap, colormap)\n        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n\n        # return a 2-tuple of the color mapped heatmap and the output,\n        # overlaid image\n        return (heatmap, output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from pyimagesearch.gradcam import GradCAM\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.applications import imagenet_utils\nimport numpy as np\nimport argparse\nimport imutils\nimport cv2\n\n# # construct the argument parser and parse the arguments\n# ap = argparse.ArgumentParser()\n# ap.add_argument(\"-i\", \"--image\", required=True,\n# \thelp=\"path to the input image\")\n# ap.add_argument(\"-m\", \"--model\", type=str, default=\"vgg\",\n# \tchoices=(\"vgg\", \"resnet\"),\n# \thelp=\"model to be used\")\n# args = vars(ap.parse_args())\n\n# # initialize the model to be VGG16\n# Model = VGG16\n\n# # check to see if we are using ResNet\n# if args[\"model\"] == \"resnet\":\n# \tModel = ResNet50\n\n# # load the pre-trained CNN from disk\n# print(\"[INFO] loading model...\")\n# model = Model(weights=\"imagenet\")\n\n# load the original image from disk (in OpenCV format) and then\n# resize the image to its target dimensions\nimgpath = '../input/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/covid/01E392EE-69F9-4E33-BFCE-E5C968654078-768x572.jpeg'\norig = cv2.imread(imgpath)\nresized = cv2.resize(orig, (224, 224))\n\n# load the input image from disk (in Keras/TensorFlow format) and\n# preprocess it\nimage = load_img(imgpath, target_size=(224, 224))\nimage = img_to_array(image)\nimage = np.expand_dims(image, axis=0)\nimage = imagenet_utils.preprocess_input(image)\n\n# use the network to make predictions on the input imag and find\n# the class label index with the largest corresponding probability\npreds = base_model.predict(image)\ni = np.argmax(preds[0])\n\n# decode the ImageNet predictions to obtain the human-readable label\ndecoded = imagenet_utils.decode_predictions(preds)\n(imagenetID, label, prob) = decoded[0][0]\nlabel = \"{}: {:.2f}%\".format(label, prob * 100)\nprint(\"[INFO] {}\".format(label))\n\n# initialize our gradient class activation map and build the heatmap\ncam = GradCAM(base_model, i, 'block5_conv3')\nheatmap = cam.compute_heatmap(image)\n\n# resize the resulting heatmap to the original input image dimensions\n# and then overlay heatmap on top of the image\nheatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n\n# draw the predicted label on the output image\ncv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\ncv2.putText(output, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n\n# display the original image and resulting heatmap and output image\n# to our screen\noutput = np.vstack([orig, heatmap, output])\noutput = imutils.resize(output, height=700)\n# cv2.imshow(\"Output\", output)\n# cv2.waitKey(0)\nplt.imshow(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# from tensorflow.keras.preprocessing.image import img_to_array\n# from tensorflow.keras.preprocessing.image import load_img\n# from tensorflow.keras.applications import imagenet_utils\n# import numpy as np\n# import argparse\n# import imutils\n# import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"orig = cv2.imread('../input/covid-chest-xray/images/1-s2.0-S0140673620303706-fx1_lrg.jpg')\nresized = cv2.resize(orig, (224, 224))\n\n# load the input image from disk (in Keras/TensorFlow format) and\n# preprocess it\nimage = load_img('../input/covid-chest-xray/images/1-s2.0-S0140673620303706-fx1_lrg.jpg', target_size=(224, 224))\nimage = img_to_array(image)\nimage = np.expand_dims(image, axis=0)\nimage = imagenet_utils.preprocess_input(image)\n\n# use the network to make predictions on the input imag and find\n# the class label index with the largest corresponding probability\npreds = base_model.predict(image)\nprint(preds)\ni = np.argmax(preds[0])\nprint(i)\n\n# # decode the ImageNet predictions to obtain the human-readable label\n# decoded = imagenet_utils.decode_predictions(preds)\n# (imagenetID, label, prob) = decoded[0][0]\n# label = \"{}: {:.2f}%\".format(label, prob * 100)\n# print(\"[INFO] {}\".format(label))\n\nlabel =\"hello\"\n\n# initialize our gradient class activation map and build the heatmap\ncam = GradCAM(base_model, i)\nheatmap = cam.compute_heatmap(image)\n\n# resize the resulting heatmap to the original input image dimensions\n# and then overlay heatmap on top of the image\nheatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n\n# draw the predicted label on the output image\ncv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\ncv2.putText(output, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX,\n\t0.8, (255, 255, 255), 2)\n\n# display the original image and resulting heatmap and output image\n# to our screen\noutput = np.vstack([orig, heatmap, output])\noutput = imutils.resize(output, height=700)\n# cv2.imwrite(\"Output.png\", output)\nplt.imshow(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}