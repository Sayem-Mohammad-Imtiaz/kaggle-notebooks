{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**1. Implementação**\n\n**1.1. Importações e Definições de Parâmetros**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# Importando a biblioteca para leitura dos dados\nimport pandas as pd\nimport numpy as np\n\n# Importando função para separar o dataset em TREINO e TESTE\nfrom sklearn.model_selection import train_test_split \n\n# Importando as classes do sklearn para padronização dos dados\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n# Importando os construtores dos modelos \nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Importando as métricas a serem utilizadas\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# Importando bibliotecas para visualização de dados\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.415193Z","iopub.execute_input":"2021-07-30T21:24:43.415566Z","iopub.status.idle":"2021-07-30T21:24:43.427322Z","shell.execute_reply.started":"2021-07-30T21:24:43.415531Z","shell.execute_reply":"2021-07-30T21:24:43.426265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**Importando a base de dados**\n\nDepois de importar a base de dados, fazemos uma breve analise observando se existem valores nulos, quais são os tipos das variáveis (método df.info) e entendendo quais são as escalas de cada uma das variáveis (método df.mean()).","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/mobile-price-classification/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.428804Z","iopub.execute_input":"2021-07-30T21:24:43.429196Z","iopub.status.idle":"2021-07-30T21:24:43.45037Z","shell.execute_reply.started":"2021-07-30T21:24:43.429151Z","shell.execute_reply":"2021-07-30T21:24:43.449528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.452214Z","iopub.execute_input":"2021-07-30T21:24:43.45293Z","iopub.status.idle":"2021-07-30T21:24:43.498122Z","shell.execute_reply.started":"2021-07-30T21:24:43.452884Z","shell.execute_reply":"2021-07-30T21:24:43.497016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info() ## não temos dados faltantes, todos os dados são do tipo numérico","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.500038Z","iopub.execute_input":"2021-07-30T21:24:43.50035Z","iopub.status.idle":"2021-07-30T21:24:43.52394Z","shell.execute_reply.started":"2021-07-30T21:24:43.500319Z","shell.execute_reply":"2021-07-30T21:24:43.52254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.mean()  ## com as medias podemos ver que os números possuem escalas diferentes de valor","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.525333Z","iopub.execute_input":"2021-07-30T21:24:43.52567Z","iopub.status.idle":"2021-07-30T21:24:43.544665Z","shell.execute_reply.started":"2021-07-30T21:24:43.525635Z","shell.execute_reply":"2021-07-30T21:24:43.543439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe() ## avaliando os valores do dataset","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.546311Z","iopub.execute_input":"2021-07-30T21:24:43.546786Z","iopub.status.idle":"2021-07-30T21:24:43.626163Z","shell.execute_reply.started":"2021-07-30T21:24:43.546742Z","shell.execute_reply":"2021-07-30T21:24:43.625044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sem_label = df.drop(['price_range'], axis=1) ## separando o price_range do restante do dataset\n\ndf_sem_label","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.627509Z","iopub.execute_input":"2021-07-30T21:24:43.627798Z","iopub.status.idle":"2021-07-30T21:24:43.658318Z","shell.execute_reply.started":"2021-07-30T21:24:43.627771Z","shell.execute_reply":"2021-07-30T21:24:43.657523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler() ## chamando a função StanderdScaler para fazer a padronização dos dados numéricos","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.660747Z","iopub.execute_input":"2021-07-30T21:24:43.661054Z","iopub.status.idle":"2021-07-30T21:24:43.665557Z","shell.execute_reply.started":"2021-07-30T21:24:43.661026Z","shell.execute_reply":"2021-07-30T21:24:43.664184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc.fit(df_sem_label) ## treinando o modelo a partir dos dados sem o label de price_range","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.668198Z","iopub.execute_input":"2021-07-30T21:24:43.668669Z","iopub.status.idle":"2021-07-30T21:24:43.687196Z","shell.execute_reply.started":"2021-07-30T21:24:43.668618Z","shell.execute_reply":"2021-07-30T21:24:43.685975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc.mean_  ## observando o que foi aprendido a partir do treino","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.688386Z","iopub.execute_input":"2021-07-30T21:24:43.688711Z","iopub.status.idle":"2021-07-30T21:24:43.695747Z","shell.execute_reply.started":"2021-07-30T21:24:43.688679Z","shell.execute_reply":"2021-07-30T21:24:43.694934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc.var_  ## observando o que foi aprendido a partir do treino","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.696746Z","iopub.execute_input":"2021-07-30T21:24:43.697036Z","iopub.status.idle":"2021-07-30T21:24:43.71056Z","shell.execute_reply.started":"2021-07-30T21:24:43.697008Z","shell.execute_reply":"2021-07-30T21:24:43.709287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_norm = sc.transform(df_sem_label) ## normalizando os valores das variveis do dataset a partir do uso do metodo StanderdScaler","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.712424Z","iopub.execute_input":"2021-07-30T21:24:43.712731Z","iopub.status.idle":"2021-07-30T21:24:43.722846Z","shell.execute_reply.started":"2021-07-30T21:24:43.712702Z","shell.execute_reply":"2021-07-30T21:24:43.72199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_norm ## analisando os valores normalizados","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.72393Z","iopub.execute_input":"2021-07-30T21:24:43.724212Z","iopub.status.idle":"2021-07-30T21:24:43.736438Z","shell.execute_reply.started":"2021-07-30T21:24:43.724184Z","shell.execute_reply":"2021-07-30T21:24:43.735437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**Analisando a melhor quantidade de clusters usando a técnica WSCC**\n\n\nFalando de maneira matemática, quando usamos o **WSCC (do inglês within-clusters sum-of-squares)** estamos em busca de uma quantidade de agrupamentos no qual a **soma dos quadrados intra-clusters** seja a menor.\n\nTratando-se do **KMeans** da biblioteca **scikit_learn** o cálculo do WSCC é processado e após isso ele retorna o nome de inertia.","metadata":{}},{"cell_type":"code","source":"wcss = []\n\nfor i in range(1,10):\n    kmeans = KMeans(n_clusters=i, max_iter=300) ## chamando a função do kmeans e atribuindo o numero de clusters com o numero maximo de 300 iterações\n    kmeans.fit(df_norm) ## aplicando o K-means na base de dados\n    wcss.append(kmeans.inertia_)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:24:43.73781Z","iopub.execute_input":"2021-07-30T21:24:43.73819Z","iopub.status.idle":"2021-07-30T21:25:05.332168Z","shell.execute_reply.started":"2021-07-30T21:24:43.738147Z","shell.execute_reply":"2021-07-30T21:25:05.330837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Soluções - Parte 01:**\n\n\n**2.1. K-Means: Cluesterização com Análise não Supervisionada\nda pergunta 1-A:**\n\nTemos o melhor número de clusters quando o número de wcss e o de clusters cai drasticamente.\n\nNo caso do gráfico abaixo o **nosso número ideal de clusters seria 3.**\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**a. Sua análise levou a mais ou menos clusteres que o esperado?**\n\nNa minha analise o número ideal de clusters seria 3, contudo, analisando o df original o numero correto de clusters seria 4, conforme a analise abaixo.","metadata":{}},{"cell_type":"code","source":"plt.plot(range(1,10), wcss)\nplt.title(\"Analisando o numero de clusters\")\nplt.xlabel(\"Numero de clusters\")\nplt.ylabel(\"WCSS\")\nplt.show()\n\n\n## o numero de clusters em que temos o melhor wcss e 3","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:05.33401Z","iopub.execute_input":"2021-07-30T21:25:05.334659Z","iopub.status.idle":"2021-07-30T21:25:05.627635Z","shell.execute_reply.started":"2021-07-30T21:25:05.334606Z","shell.execute_reply":"2021-07-30T21:25:05.62665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Comparando com a quantidade ideal de clusters no df original que seriam 4**","metadata":{}},{"cell_type":"code","source":"df['price_range'].drop_duplicates() ## quantidade original de modelos foram 4","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:05.631169Z","iopub.execute_input":"2021-07-30T21:25:05.631525Z","iopub.status.idle":"2021-07-30T21:25:05.644366Z","shell.execute_reply.started":"2021-07-30T21:25:05.631475Z","shell.execute_reply":"2021-07-30T21:25:05.643605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Agregando o numero de clusters criados ao DF original**","metadata":{}},{"cell_type":"code","source":"clusterizacao = KMeans(n_clusters = 3,  max_iter=300) ## criando o modelo\nclusterizacao.fit(df_norm) # fazendo a aplicação do modelo na base de dados","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:05.648226Z","iopub.execute_input":"2021-07-30T21:25:05.650007Z","iopub.status.idle":"2021-07-30T21:25:07.698799Z","shell.execute_reply.started":"2021-07-30T21:25:05.649965Z","shell.execute_reply":"2021-07-30T21:25:07.697887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['KMeans_Clusters'] = clusterizacao.labels_ ## atribuindo os clusters ao objeto original\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:07.706358Z","iopub.execute_input":"2021-07-30T21:25:07.706745Z","iopub.status.idle":"2021-07-30T21:25:07.739483Z","shell.execute_reply.started":"2021-07-30T21:25:07.706712Z","shell.execute_reply":"2021-07-30T21:25:07.738513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**da pergunta 1-B:**\n\n**b. Baseado nos valores das amostras pertencentes a cada um dos clusteres formados, o que eles significam?**\n\nComo usamos a **técnica de PCA**, todas as variáveis foram resumidas em dois componentes, sendo que cada um desses dois componentes possuem os valores principais de cada cluster **(1,2,3).**\n\nNestes dois componentes nós temos os valores que serão usados para plotar cada ponto no cluster ao qual ele pertence.\n\n**Visualizando todos os clusters de maneira grafica**\n\nPara isso vamos usar a **análise de componentes principais (PCA).**\n\nA análise de componentes principais consiste em técnica que transforma um determinado grupo de variáveis originais em outro grupo com a mesma dimensão que chamamos de componentes principais.","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2) ## como usaremos um grafico com duas dimensões (x, y) usamos então um modelo que tenha dois componentes principais\npca_df = pca.fit_transform(df_norm) ## para conseguir os dois componentes principais usamos a função fit_transform com o dataset normalizado\npca_df_principal = pd.DataFrame(data = pca_df, columns = ['Primeiro_componente', 'Segundo_componente']) ## com o recurso do Pandas chamado DataFrame, faço o uso para transformar os componentes principais em um dataframe e renomeio as colunas\npca_labels_celulares = pd.concat([pca_df_principal, df[['KMeans_Clusters']]], axis=1) ## depois com a função Concat, concateno as colunas com os clusters criados chamada de \"KMeans_Clusters\"\n\npca_labels_celulares","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:07.743204Z","iopub.execute_input":"2021-07-30T21:25:07.743532Z","iopub.status.idle":"2021-07-30T21:25:07.852788Z","shell.execute_reply.started":"2021-07-30T21:25:07.743486Z","shell.execute_reply":"2021-07-30T21:25:07.851914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (12,12))\n\nax = fig.add_subplot(1,1,1)\nax.set_xlabel('Primeiro_Componente', fontsize=15)\nax.set_ylabel('Segundo_Componente', fontsize=15)\nax.set_title('Componentes Principais', fontsize=20)\n\ncolor_theme = np.array([\"green\", \"yellow\", \"orange\"])\nax.scatter(x = pca_labels_celulares.Primeiro_componente, y=pca_labels_celulares.Segundo_componente, \n           c=color_theme[pca_labels_celulares.KMeans_Clusters], s=50)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:07.860287Z","iopub.execute_input":"2021-07-30T21:25:07.860644Z","iopub.status.idle":"2021-07-30T21:25:08.201439Z","shell.execute_reply.started":"2021-07-30T21:25:07.860611Z","shell.execute_reply":"2021-07-30T21:25:08.200521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Soluções - Parte 02:**","metadata":{}},{"cell_type":"markdown","source":"**3.1. KNN: Classificação - Análise Supervisionada**","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:08.203141Z","iopub.execute_input":"2021-07-30T21:25:08.203747Z","iopub.status.idle":"2021-07-30T21:25:08.245361Z","shell.execute_reply.started":"2021-07-30T21:25:08.203703Z","shell.execute_reply":"2021-07-30T21:25:08.244614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:08.248709Z","iopub.execute_input":"2021-07-30T21:25:08.249227Z","iopub.status.idle":"2021-07-30T21:25:08.267461Z","shell.execute_reply.started":"2021-07-30T21:25:08.249184Z","shell.execute_reply":"2021-07-30T21:25:08.266529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.2. Questão 2.a. Quais serão as métricas utilizadas?**\n\nA métrica a ser adotada será a acurácia de classificação.\n\nTemos também já predefinido como Label a variável **Intervelo de Preço (price_range)** e como demais variáveis a compor esta classificação optamos pela escolha de atributos físicos (Hardware) e Tecnológicos que compõem os aparelhos mais modernos, sendo elas: **Capacidade de Bateria (battery_power), bluetooth (blue), Sensibilidade ao toque (touch_screen), Conexão de rede (wifi), Memória Interna (int_memory), Dupla entrada de Chip (dual_sim), Largura de Pixels (px_width), Altura de Pixels (px_height).**\n","metadata":{}},{"cell_type":"code","source":"df1 = df[[\"price_range\", \"battery_power\", \"blue\", \"touch_screen\", \"wifi\", \"int_memory\", \"dual_sim\", \"px_width\", \"px_height\"]] #Cria outro DF apenas com as variáveis escolhidas\ndf1","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:08.271064Z","iopub.execute_input":"2021-07-30T21:25:08.271607Z","iopub.status.idle":"2021-07-30T21:25:08.292566Z","shell.execute_reply.started":"2021-07-30T21:25:08.271564Z","shell.execute_reply":"2021-07-30T21:25:08.291631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Para fazerem divisão de TREINO, TESTE usando 70/30 e semente aleatória = 42\nX = df.drop(columns=[\"battery_power\", \"blue\", \"touch_screen\", \"wifi\", \"int_memory\", \"dual_sim\", \"px_width\", \"px_height\"])\ny = df[\"price_range\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, \n                                                    random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:08.294198Z","iopub.execute_input":"2021-07-30T21:25:08.294834Z","iopub.status.idle":"2021-07-30T21:25:08.307757Z","shell.execute_reply.started":"2021-07-30T21:25:08.294791Z","shell.execute_reply":"2021-07-30T21:25:08.306752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como a dataframe é composto apenas por valores numéricos não será necessário o uso do OneHotEncoder","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled  = scaler.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:08.309706Z","iopub.execute_input":"2021-07-30T21:25:08.310769Z","iopub.status.idle":"2021-07-30T21:25:08.328208Z","shell.execute_reply.started":"2021-07-30T21:25:08.310725Z","shell.execute_reply":"2021-07-30T21:25:08.327385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.3. Análise da Acurácia da Classificação**\n\nA princípio realizei um teste afim de encontrar o melhor número de vizinhos, através do experimento abaixo, que irá demostrar um gráfico de linha:","metadata":{}},{"cell_type":"code","source":"mean_scores = [] #Lista que recebe a acurácia média de obtida para cada K\nfor k in range(1,42): #Intervalo de variação de K vizinhos\n    scores = []\n    for i in range(60):\n        X_train, X_test, y_train, y_test = train_test_split(X,y)\n        model = KNeighborsClassifier(n_neighbors=k)\n        model.fit(X_train,y_train)\n        accuracy = model.score(X_test,y_test)\n        scores.append(accuracy)\n    mean_scores.append(np.mean(scores))\n\n#Gráfico de linha\nplt.plot(np.arange(1,42),mean_scores)\nplt.yticks([])\nplt.title(\"Acurácias do k-NN por número de vizinhos\")\nplt.xlabel(\"Número de vizinhos\")\nplt.ylabel(\"Acurácia\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T21:25:08.329723Z","iopub.execute_input":"2021-07-30T21:25:08.330389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Neste código estabeleci uma **lista []** onde serão salvas as acurácias. Determinei o número de **k vizinhos de 1 à 42** e determinei que isto seja **repetido 60 vezes,** rodando o treinamento e a validação.\n\nObservei que a partir de **15 vizinhos** o nível de acurácia não apresenta grandes alterações, apesar de sim aumentar. O KNN pode demonstrar modelos diferentes a cada execução e sendo a acurácia uma variável aleatória de acordo com uma probabilidade, decidi **manter o valor de 15 vizinhos.** Porém considerando esta situação para ser estudada futuramente e entender o porque isto ocorre.","metadata":{}}]}