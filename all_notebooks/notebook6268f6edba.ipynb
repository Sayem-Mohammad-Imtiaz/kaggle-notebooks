{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Project: prediction of the mechanical properties using the alloy composition and temperature.\n\n","metadata":{}},{"cell_type":"markdown","source":"Conclusion: random forest regression has showed best performance for this task. Data scaling, outliers removal and skewness amendmend have sensibly improved the performance.\n\nMethods: machine learning and deep learning\n\nDataset: \"Mechanical properties of low alloy steels\" from Kaggle, Contains alloy composition, temperature and mechanical properties\n\nContext: currently there are no precise theoretical methods to predict mechanical properties of steels. All the methods available are by backed by statistics and extensive physical testing of the materials. Since testing each material with different composition is a highly tedious task (imagine the number of possibilities!), let's apply our knowledge of machine learning and statistics to solve this problem.\n\nContent: this dataset contains compositions by weight percentages of low-alloy steels along with the temperatures at which the steels were tested and the values mechanical properties observed during the tests. The alloy code is a string unique to each alloy. Weight percentages of alloying metals and impurities like Aluminum, copper, manganese, nitrogen, nickel, cobalt, carbon, etc are given in columns. The temperature in celsius for each test is mentioned in a column. Lastly mechanical properties including tensile strength, yield strength, elongation and reduction in area are given in separate columns. The dataset contains 915 rows.","metadata":{}},{"cell_type":"markdown","source":"Link to the dataset:\n\nhttps://www.kaggle.com/rohannemade/mechanical-properties-of-low-alloy-steels","metadata":{}},{"cell_type":"markdown","source":"STEP 1: Learning the dataset and feature engineering","metadata":{}},{"cell_type":"code","source":"# importing libraries\nimport numpy as np\nimport pandas as pd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing the dataset\ndf = pd.read_csv(\"../input/mechanical-properties-of-low-alloy-steels/MatNavi Mechanical properties of low-alloy steels.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learning the dataset and making feature engineering","metadata":{}},{"cell_type":"code","source":"# showing first five rows of the dateset\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing the column names\nlist(df.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# editing the column names\nnew_list = {' C': 'C',\n            ' Si': 'Si',\n            ' Mn': 'Mn',\n            ' P': 'P',\n            ' S': 'S',\n            ' Ni': 'Ni',\n            ' Cr': 'Cr',\n            ' Mo': 'Mo',\n            ' Cu': 'Cu', \n            ' Al': 'Al',\n            ' N': 'N', \n            ' Temperature (°C)': 'Temperature (°C)',\n            ' 0.2% Proof Stress (MPa)': '0.2% Proof Stress (MPa)',\n            ' Tensile Strength (MPa)': 'Tensile Strength (MPa)',\n            ' Elongation (%)': 'Elongation (%)', \n            ' Reduction in Area (%)': 'Reduction in Area (%)'}\ndf.rename(columns=new_list, inplace=True)\nlist(df.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing the column names\nlist(df.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing statistical information about the dataset\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing statistical data of the dataset\ndf.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removeing Alloy code column because it is for information only\ndf.drop('Alloy code', axis='columns', inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize data columns\n\nExplore distribution, skewness, outliers and other statistical properties","metadata":{}},{"cell_type":"code","source":"# plotting C variable\nboxplot = df.boxplot(column=[\"C\"]);","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Si variable\nboxplot = df.boxplot(column=[\"Si\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Mn variable\nboxplot = df.boxplot(column=[\"Mn\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting S variable in descending order\nboxplot = df.boxplot(column=[\"S\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting P variable in descending order\nboxplot = df.boxplot(column=[\"P\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Ni variable\nboxplot = df.boxplot(column=[\"Ni\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting non-zero Ni variable\ndf_Ni = df[\"index\" and \"Ni\"]\ndf_Ni_nonzero = df_Ni[df_Ni != 0]\ndf_Ni_nonzero.to_frame().boxplot(column=[\"Ni\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Cr variable\nboxplot = df.boxplot(column=[\"Cr\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Mo variable\nboxplot = df.boxplot(column=[\"Mo\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Cu variable\nboxplot = df.boxplot(column=[\"Cu\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating skewness of Al variable\ncu_skewness = df[\"Cu\"].skew()\ncu_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trying log transformation to improve the skewness\nlog_cu_skewness = np.log(df[\"Cu\"]).skew()\nlog_cu_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trying root square transformation to improve the skewness\nsqrt_cu_skewness = np.sqrt(df[\"Cu\"]).skew()\nsqrt_cu_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Square root transformation gave low skewness","metadata":{}},{"cell_type":"code","source":"# creating sqrt(Cu) column\ndf[\"sqrt(Cu)\"] = np.sqrt(df['Cu'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting sqrt(Cu) variable\nboxplot = df.boxplot(column=[\"sqrt(Cu)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing Cu column\ndf.drop([\"Cu\"], axis=1, inplace=True)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting V variable\nboxplot = df.boxplot(column=[\"V\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting non-zero V variable\ndf_V = df[\"index\" and \"V\"]\ndf_V_nonzero = df_V[df_V != 0]\ndf_V_nonzero.to_frame().boxplot(column=[\"V\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Al variable\nboxplot = df.boxplot(column=[\"Al\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Al variable\ndf[\"Al\"].plot(); # There is no zewroes in Al variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating skewness of Al variable\nal_skewness = df[\"Al\"].skew()\nal_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Al variable is highly skewed","metadata":{}},{"cell_type":"code","source":"# trying log transformation to improve the skewness\nlog_al_skewness = np.log(df[\"Al\"]).skew()\nlog_al_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trying root square transformation to improve the skewness\nsqrt_al_skewness = np.sqrt(df[\"Al\"]).skew()\nsqrt_al_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Log transformation gave better results then square root transformation","metadata":{}},{"cell_type":"code","source":"# creating log(Al) column\ndf[\"log(Al)\"] = np.log(df['Al'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting log(Al) variable\nboxplot = df.boxplot(column=[\"log(Al)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing Al column\ndf.drop([\"Al\"], axis=1, inplace=True)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting N variable\nboxplot = df.boxplot(column=[\"N\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Ceq variable\nboxplot = df.boxplot(column=[\"Ceq\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Ceq non-zero variable\ndf_Ceq = df[\"index\" and \"Ceq\"]\ndf_Ceq_nonzero = df_Ceq[df_Ceq != 0]\ndf_Ceq_nonzero.to_frame().boxplot(column=[\"Ceq\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Nb + Ta variable\nax = df[\"Nb + Ta\"].value_counts().sort_index().plot.bar(xlabel=\"Nb + Ta\", ylabel=\"Frequency\", figsize=(2,6), rot=45);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Temperature (°C) variable\nboxplot = df.boxplot(column=[\"Temperature (°C)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting 0.2% Proof Stress (MPa) variable\nboxplot = df.boxplot(column=[\"0.2% Proof Stress (MPa)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Tensile Strength (MPa) variable\nboxplot = df.boxplot(column=[\"Tensile Strength (MPa)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tensile Strength (MPa) column has an outlier. Let's detect and remove it.","metadata":{}},{"cell_type":"code","source":"# detecting the outlier\ndf.loc[df[\"Tensile Strength (MPa)\"] > 1000]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# deleting the outlier\ndf.drop(626, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Tensile Strength (MPa) variable\nboxplot = df.boxplot(column=[\"Tensile Strength (MPa)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Elongation (%) variable\nboxplot = df.boxplot(column=[\"Elongation (%)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating skewness of Elongation (%) variable\nelongation_skewness = df[\"Elongation (%)\"].skew()\nelongation_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Elongation (%) variable is highly skewed","metadata":{}},{"cell_type":"code","source":"# trying log transformation to improve the skewness\nlog_el_skewness = np.log(df[\"Elongation (%)\"]).skew()\nlog_el_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's replace Elongation (%) variable with log(Elongation (%)) to fix the skewness","metadata":{}},{"cell_type":"code","source":"# creating log(Elongation (%)) column\ndf[\"log(Elongation (%))\"] = np.log(df['Elongation (%)'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting log(Elongation (%)) variable\nboxplot = df.boxplot(column=[\"log(Elongation (%))\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing Elongation column\ndf.drop([\"Elongation (%)\"], axis=1, inplace=True)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting Reduction in Area (%) variable\nboxplot = df.boxplot(column=[\"Reduction in Area (%)\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating skewness of Reduction in Area (%) variable\nReduction_skewness = df[\"Reduction in Area (%)\"].skew()\nReduction_skewness","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reduction in Area (%) variable is reasonably skewed","metadata":{}},{"cell_type":"code","source":"# reordering the dataframe columns in original order\ndf = df[['C',\n 'Si',\n 'Mn',\n 'P',\n 'S',\n 'Ni',\n 'Cr',\n 'Mo',\n 'sqrt(Cu)',\n 'V',\n 'log(Al)',\n 'N',\n 'Ceq',\n 'Nb + Ta',\n 'Temperature (°C)',\n '0.2% Proof Stress (MPa)',\n 'Tensile Strength (MPa)',\n 'log(Elongation (%))',\n 'Reduction in Area (%)']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing libraries for heatmap building \nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating a correlation matrix\ncorr_matrix = df.corr()\nprint(corr_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drawing a heatmap\nplt.figure(figsize = (20,20))\nax = sns.heatmap(corr_matrix, annot=True, square=True, cmap='Blues')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"STEP2: Choosing best performing machine learning model","metadata":{}},{"cell_type":"markdown","source":"Multiple linear regression for 0.2% Proof Stress (MPa)","metadata":{}},{"cell_type":"code","source":"# defining variables\nX = df.iloc[:, :-4].values\ny = df.iloc[:, -4].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the multiple Linear regression model on the training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting the test set results\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test scoring\nfrom sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decision tree regression for 0.2% Proof Stress (MPa)","metadata":{}},{"cell_type":"code","source":"# training the decision tree regression model on the training set\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor()\nregressor.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting the test set results\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test scoring\nfrom sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random forest regression for 0.2% Proof Stress (MPa)","metadata":{}},{"cell_type":"code","source":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting the test set results\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_1 = r2_score(y_test, y_pred)\nscore_1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Discussion: Random forest seems suitable model for this type of data.","metadata":{}},{"cell_type":"markdown","source":"Random forest regression for Tensile Strength (MPa)","metadata":{}},{"cell_type":"code","source":"# defining variables\nX = df.iloc[:, :-4].values\nz = df.iloc[:, -3].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.20, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, z_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting the test set results\nz_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((z_pred.reshape(len(z_pred),1), z_test.reshape(len(z_test),1)),1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_2 = r2_score(z_test, z_pred)\nscore_2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random forest regression for Elongation (%)","metadata":{}},{"cell_type":"code","source":"# defining variables\nX = df.iloc[:, :-4].values\nv = df.iloc[:, -2].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, v_train, v_test = train_test_split(X, v, test_size = 0.20, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, v_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting the test set results\nv_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=1)\nprint(np.concatenate((v_pred.reshape(len(v_pred),1), v_test.reshape(len(v_test),1)),1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_3 = r2_score(v_test, v_pred)\nscore_3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random forest regression for Reduction in Area (%)","metadata":{}},{"cell_type":"code","source":"# defining variables\nX = df.iloc[:, :-4].values\nw = df.iloc[:, -1].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, w_train, w_test = train_test_split(X, w, test_size = 0.20, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, w_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting the test set results\nw_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=1)\nprint(np.concatenate((w_pred.reshape(len(w_pred),1), w_test.reshape(len(w_test),1)),1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_4 = r2_score(w_test, w_pred)\nscore_4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R squared score for random forest with default parametrs:","metadata":{}},{"cell_type":"code","source":"print({\"0.2% Proof Stress (MPa) score is\": \"{:.3f}\".format(score_1)})\nprint({\"Tensile Strength (MPa) score is\": \"{:.3f}\".format(score_2)})\nprint({\"log(Elongation (%)) score is\": \"{:.3f}\".format(score_3)})\nprint({\"Reduction in Area (%) score is\": \"{:.3f}\".format(score_4)})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Results discussion: Random forest regression has showed high level of predectibility for the both strengths and reasonably high for geometrical deformations.","metadata":{}},{"cell_type":"markdown","source":"STEP3: Building and optimising deep learning model","metadata":{}},{"cell_type":"markdown","source":"Building the ANN #1 for prediction of 0.2% Proof Stress (MPa)","metadata":{}},{"cell_type":"code","source":"# importing tensorflow\nimport tensorflow as tf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initializing the ANN\nann_1 = tf.keras.models.Sequential()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing a shape of X_train array\nX_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the input layer and the first hidden layer\nann_1.add(tf.keras.layers.Dense(units=15, activation='relu'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the second hidden layer\nann_1.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the third hidden layer\nann_1.add(tf.keras.layers.Dense(units=60, activation='relu'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the output layer\nann_1.add(tf.keras.layers.Dense(units=1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the ANN#1","metadata":{}},{"cell_type":"code","source":"# compiling the ANN\nann_1.compile(optimizer = 'adam', loss = 'mean_squared_error')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the ANN model on the Training set\nann_1.fit(X_train, y_train, batch_size = 64, epochs = 600)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann_1.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predicting the results of the Test set","metadata":{}},{"cell_type":"code","source":"y_pred = ann_1.predict(X_test)\nnp.set_printoptions(precision=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scoring the ANN#1 prediction","metadata":{}},{"cell_type":"code","source":"# y_test scoring\nfrom sklearn.metrics import r2_score\nann_1_score = r2_score(y_test, y_pred)\nann_1_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building the ANN #2 for prediction of Tensile Strength (MPa)","metadata":{}},{"cell_type":"code","source":"# initializing the ANN\nann_2 = tf.keras.models.Sequential()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the input layer and the first hidden layer\nann_2.add(tf.keras.layers.Dense(units=15, activation='relu'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the second hidden layer\nann_2.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the third hidden layer\nann_2.add(tf.keras.layers.Dense(units=60, activation='relu'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the output layer\nann_2.add(tf.keras.layers.Dense(units=1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the ANN#2","metadata":{}},{"cell_type":"code","source":"# compiling the ANN\nann_2.compile(optimizer = 'adam', loss = 'mean_squared_error')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the ANN model on the Training set\nann_2.fit(X_train, z_train, batch_size = 64, epochs = 750)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predicting the results of the Test set","metadata":{}},{"cell_type":"code","source":"z_pred = ann_2.predict(X_test)\nnp.set_printoptions(precision=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scoring the ANN#2 prediction","metadata":{}},{"cell_type":"code","source":"# z_test scoring\nfrom sklearn.metrics import r2_score\nann_2_score = r2_score(z_test, z_pred)\nann_2_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building the ANN #3 for prediction of log(Elongation (%))","metadata":{}},{"cell_type":"code","source":"# initializing the ANN\nann_3 = tf.keras.models.Sequential()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the input layer and the first hidden layer\nann_3.add(tf.keras.layers.Dense(units=15, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the second hidden layer\nann_3.add(tf.keras.layers.Dense(units=60, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the third hidden layer\nann_3.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the output layer\nann_3.add(tf.keras.layers.Dense(units=1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the ANN#3","metadata":{}},{"cell_type":"code","source":"# compiling the ANN\nann_3.compile(optimizer = 'adam', loss = 'mean_squared_error')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the ANN model on the Training set\nann_3.fit(X_train, v_train, batch_size = 64, epochs = 5000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predicting the results of the Test set","metadata":{}},{"cell_type":"code","source":"v_pred = ann_3.predict(X_test)\nnp.set_printoptions(precision=3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scoring the ANN#3 prediction","metadata":{}},{"cell_type":"code","source":"# v_test scoring\nfrom sklearn.metrics import r2_score\nann_3_score = r2_score(v_test, v_pred)\nann_3_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building the ANN #4 for prediction of Reduction in Area (%)","metadata":{}},{"cell_type":"code","source":"# initializing the ANN\nann_4 = tf.keras.models.Sequential()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the input layer and the first hidden layer\nann_4.add(tf.keras.layers.Dense(units=15, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the second\nann_4.add(tf.keras.layers.Dense(units=15, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the third hidden layer\nann_4.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the output layer\nann_4.add(tf.keras.layers.Dense(units=1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the ANN#4","metadata":{}},{"cell_type":"code","source":"# compiling the ANN\nann_4.compile(optimizer = 'adam', loss = 'mean_squared_error')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training the ANN model on the Training set\nann_4.fit(X_train, w_train, batch_size = 64, epochs = 1000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predicting the results of the Test set","metadata":{}},{"cell_type":"code","source":"w_pred = ann_4.predict(X_test)\nnp.set_printoptions(precision=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scoring the ANN#4 prediction","metadata":{}},{"cell_type":"code","source":"# w_test scoring\nfrom sklearn.metrics import r2_score\nann_4_score = r2_score(w_test, w_pred)\nann_4_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R squared score for the ANNs:","metadata":{}},{"cell_type":"code","source":"print({\"0.2% Proof Stress (MPa) score is\": \"{:.3f}\".format(ann_1_score)})\nprint({\"Tensile Strength (MPa) score is\": \"{:.3f}\".format(ann_2_score)})\nprint({\"log(Elongation (%)) score is\": \"{:.3f}\".format(ann_3_score)})\nprint({\"Reduction in Area (%) score is\": \"{:.3f}\".format(ann_4_score)})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Discussion: ANN performs similarly to Random Forest regression for all the four dependent variables. R square score is about 2% less for the ANN.","metadata":{}},{"cell_type":"markdown","source":"Conclusion: random forest regression has showed best performance for this task. Data scaling, outliers removal and skewness amendmend have sensibly improved the performance.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}