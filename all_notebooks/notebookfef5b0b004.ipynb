{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport glob\nimport os\nimport cv2\nimport time\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.layers.normalization import BatchNormalization\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T19:51:45.45041Z","iopub.execute_input":"2021-06-28T19:51:45.450765Z","iopub.status.idle":"2021-06-28T19:51:57.569607Z","shell.execute_reply.started":"2021-06-28T19:51:45.450688Z","shell.execute_reply":"2021-06-28T19:51:57.56875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = pd.read_csv('../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/names.csv')\nnames = names.values\nnp.random.shuffle(names)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:51:57.571221Z","iopub.execute_input":"2021-06-28T19:51:57.571568Z","iopub.status.idle":"2021-06-28T19:51:57.585083Z","shell.execute_reply.started":"2021-06-28T19:51:57.571532Z","shell.execute_reply":"2021-06-28T19:51:57.584232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nr_cars = 15\nidx_to_name = {x : names[x][0] for x in np.arange(nr_cars)}\nname_to_idx = {x:i for i,x in enumerate(idx_to_name.values())}\nidx_to_name","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:51:57.58825Z","iopub.execute_input":"2021-06-28T19:51:57.588507Z","iopub.status.idle":"2021-06-28T19:51:57.596201Z","shell.execute_reply.started":"2021-06-28T19:51:57.588482Z","shell.execute_reply":"2021-06-28T19:51:57.595425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/train/'\ntest_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/test/'","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:51:57.597686Z","iopub.execute_input":"2021-06-28T19:51:57.598239Z","iopub.status.idle":"2021-06-28T19:51:57.607464Z","shell.execute_reply.started":"2021-06-28T19:51:57.598203Z","shell.execute_reply":"2021-06-28T19:51:57.606612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(path):\n    train = []\n    for i, name in enumerate(name_to_idx.keys()):\n        new_path = path + name + \"/\"\n        [train.append([i, cv2.resize(cv2.imread(img), (244,244), interpolation = cv2.INTER_AREA)]) for img in glob.glob(new_path + \"*.jpg\")]\n    return np.array(train)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:51:57.60869Z","iopub.execute_input":"2021-06-28T19:51:57.609041Z","iopub.status.idle":"2021-06-28T19:51:57.620161Z","shell.execute_reply.started":"2021-06-28T19:51:57.609006Z","shell.execute_reply":"2021-06-28T19:51:57.619206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = get_data(train_path)\ntest = get_data(test_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:51:57.623111Z","iopub.execute_input":"2021-06-28T19:51:57.62338Z","iopub.status.idle":"2021-06-28T19:52:12.947533Z","shell.execute_reply.started":"2021-06-28T19:51:57.623354Z","shell.execute_reply":"2021-06-28T19:52:12.946652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr = np.concatenate(train[:,1], axis=0).reshape(len(train), 244, 244, 3)\nX_tr = X_tr / 255.0\nX_tr = X_tr.astype('float32')\ny_tr = train[:,0]\ny_tr = np.eye(len(idx_to_name))[list(y_tr)]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:52:12.948932Z","iopub.execute_input":"2021-06-28T19:52:12.949254Z","iopub.status.idle":"2021-06-28T19:52:13.425774Z","shell.execute_reply.started":"2021-06-28T19:52:12.949219Z","shell.execute_reply":"2021-06-28T19:52:13.424883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size = 0.15, random_state = 42)\nprint(\"x_train shape = \",x_train.shape)\nprint(\"y_train shape = \",y_train.shape)\nprint(\"x_val shape = \",x_val.shape)\nprint(\"y_val shape = \",y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:52:13.428268Z","iopub.execute_input":"2021-06-28T19:52:13.428631Z","iopub.status.idle":"2021-06-28T19:52:13.56728Z","shell.execute_reply.started":"2021-06-28T19:52:13.428588Z","shell.execute_reply":"2021-06-28T19:52:13.566443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential(name=\"Alexnet\")\n#1 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=(227,227,3)))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\n#2 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\n#3 layer (conv + batchnorm)\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(BatchNormalization())\n#4 layer (conv + batchnorm)\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(BatchNormalization())\n#5 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\n#1 dense layer\nmodel.add(Dense(4096,input_shape=(227,227,3),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#2 dense layer\nmodel.add(Dense(4096,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#3 dense layer\nmodel.add(Dense(1000,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#output layer\nmodel.add(Dense(15,activation=\"softmax\"))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:52:13.56999Z","iopub.execute_input":"2021-06-28T19:52:13.570274Z","iopub.status.idle":"2021-06-28T19:52:15.986365Z","shell.execute_reply.started":"2021-06-28T19:52:13.57023Z","shell.execute_reply":"2021-06-28T19:52:15.985495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce learning rate by 0.1 when the validation error plateaus\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n \n# set the SGD optimizer with lr of 0.01 and momentum of 0.9\noptimizer = SGD(lr = 0.01, momentum = 0.9)\n \n# compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:52:15.989221Z","iopub.execute_input":"2021-06-28T19:52:15.9896Z","iopub.status.idle":"2021-06-28T19:52:16.006074Z","shell.execute_reply.started":"2021-06-28T19:52:15.989573Z","shell.execute_reply":"2021-06-28T19:52:16.005178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\n# call the reduce_lr value using callbacks in the training method\nhistory = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:52:16.007366Z","iopub.execute_input":"2021-06-28T19:52:16.007759Z","iopub.status.idle":"2021-06-28T19:53:30.921672Z","shell.execute_reply.started":"2021-06-28T19:52:16.007723Z","shell.execute_reply":"2021-06-28T19:53:30.920848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 100) # set the vertical range to [0-1]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:53:30.925105Z","iopub.execute_input":"2021-06-28T19:53:30.925373Z","iopub.status.idle":"2021-06-28T19:53:31.129461Z","shell.execute_reply.started":"2021-06-28T19:53:30.925344Z","shell.execute_reply":"2021-06-28T19:53:31.128721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nDefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n padding=\"SAME\", use_bias=False)\nclass ResidualUnit(keras.layers.Layer):\n def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n     super().__init__(**kwargs)\n     self.activation = keras.activations.get(activation)\n     self.main_layers = [\n         DefaultConv2D(filters, strides=strides),\n         keras.layers.BatchNormalization(),\n         self.activation,\n         DefaultConv2D(filters),\n         keras.layers.BatchNormalization()]\n     self.skip_layers = []\n     if strides > 1:\n         self.skip_layers = [\n             DefaultConv2D(filters, kernel_size=1, strides=strides),\n             keras.layers.BatchNormalization()]\n def call(self, inputs):\n     Z = inputs\n     for layer in self.main_layers:\n         Z = layer(Z)\n     skip_Z = inputs\n     for layer in self.skip_layers:\n        skip_Z = layer(skip_Z)\n     return self.activation(Z + skip_Z)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:53:31.130666Z","iopub.execute_input":"2021-06-28T19:53:31.131037Z","iopub.status.idle":"2021-06-28T19:53:31.139699Z","shell.execute_reply.started":"2021-06-28T19:53:31.131Z","shell.execute_reply":"2021-06-28T19:53:31.138724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = keras.models.Sequential(name=\"Resnet34\")\nmodel2.add(DefaultConv2D(64, kernel_size=7, strides=2,\n input_shape=[224, 224, 3]))\nmodel2.add(keras.layers.BatchNormalization())\nmodel2.add(keras.layers.Activation(\"relu\"))\nmodel2.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\nprev_filters = 64\nfor filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n strides = 1 if filters == prev_filters else 2\n model2.add(ResidualUnit(filters, strides=strides))\n prev_filters = filters\nmodel2.add(keras.layers.GlobalAvgPool2D())\nmodel2.add(keras.layers.Flatten())\nmodel2.add(keras.layers.Dense(15, activation=\"softmax\"))\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:53:31.141341Z","iopub.execute_input":"2021-06-28T19:53:31.141764Z","iopub.status.idle":"2021-06-28T19:53:31.728418Z","shell.execute_reply.started":"2021-06-28T19:53:31.141731Z","shell.execute_reply":"2021-06-28T19:53:31.72752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce learning rate by 0.1 when the validation error plateaus\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n \n# set the SGD optimizer with lr of 0.01 and momentum of 0.9\noptimizer = SGD(lr = 0.001, momentum = 0.9)\n # compile the model\nmodel2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nhistory = model2.fit(x_train, y_train,\n validation_data=(x_val, y_val),\n epochs=20)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:53:31.730395Z","iopub.execute_input":"2021-06-28T19:53:31.730732Z","iopub.status.idle":"2021-06-28T19:54:14.68688Z","shell.execute_reply.started":"2021-06-28T19:53:31.730696Z","shell.execute_reply":"2021-06-28T19:54:14.686035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 10) # set the vertical range to [0-1]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T19:54:14.688652Z","iopub.execute_input":"2021-06-28T19:54:14.689008Z","iopub.status.idle":"2021-06-28T19:54:14.865049Z","shell.execute_reply.started":"2021-06-28T19:54:14.688971Z","shell.execute_reply":"2021-06-28T19:54:14.864128Z"},"trusted":true},"execution_count":null,"outputs":[]}]}