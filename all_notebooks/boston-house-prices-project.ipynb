{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1. Prepare Problem\n# 1.a) Load libraries\nimport numpy as np\nfrom numpy import arange\nfrom matplotlib import pyplot as plt\nfrom pandas import read_csv\nfrom pandas import set_option\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# 1.b) Load dataset\nfilename = '/kaggle/input/boston-house-prices/housing.csv'\nnames = ['CRIM', 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV' ]\ndataset = read_csv(filename, delim_whitespace=True, names=names)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# 2. Summarize Data\n# shape, type & head\nset_option('display.width', 160)\nset_option('precision', 6)\nprint('dimension :', dataset.shape,'\\nType :\\n', dataset.dtypes,'\\nHead :\\n', dataset.head(20))\n# 2.a) Descriptive statistics\n# summarizing the distribution of each attribute\nset_option('precision', 3)\nprint('Statistics :\\n', dataset.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation between attributes\nprint('Correlations :\\n', dataset.corr(method='pearson'))\n# many attributes have a strong correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.b) Data visualizations\n# histogram of individual attributes\ndataset.hist(sharex = False, sharey = False,xlabelsize=1,ylabelsize=1,figsize=(18,12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# density\ndataset.plot(kind='density', subplots=True,  layout=(4,4),figsize=(18,12), sharex=False, legend=True,fontsize=1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# box and whisker plots\ndataset.plot(kind= 'box', subplots=True, layout=(4,4), sharex=False, sharey=False,fontsize=8,figsize=(18,12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizations of the interactions between variables : scatter matrix\nscatter_matrix(dataset,figsize=(18,12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation matrix\nfig = plt.figure()\nax = fig.add_axes([0,0,2.5,2.5])\ncax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation= 'none',cmap ='coolwarm')\nfig.colorbar(cax)\nticks = np.arange(0,14,1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3. Evaluate Algorithms\n# Split-out validation dataset\narray = dataset.values\nX = array[:,0:13]\nY = array[:,13]\ntest_size = 0.20\nseed = 7\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=test_size, random_state=seed)\n# Standarize the data & spot-Check Algorithms\n# using pipelines to avoid data leakage when we transform the data\npipelines = []\npipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LinearRegression())])))\npipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\npipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\npipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\npipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\npipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())])))\n# Test options and evaluation metric\nnum_folds = 10\nseed = 7\nscoring = 'neg_mean_squared_error'\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in pipelines:\n    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n    \n# Compare Algorithms\nfig2 = plt.figure()\nax2 = fig2.add_axes([0,0,2,2])\nax2.boxplot(results, labels=names, showmeans=True, meanline=True, meanprops = dict(linestyle='--', linewidth=2.5, color='green'))\nax2.yaxis.grid(True)\nax2.set_title('Algorithm Comparison')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that KNN has both a tight distribution of error and has the lowest score, can it perform better more by parameter tunning? \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Improve Accuracy\n# a) Algorithm Tuning : iterate on the nbr of neighbors \n# KNN Algorithm tuning\nk_values = np.array([1,3,5,7,9,11,13,15,17,19,21])\nparam_grid = dict(KNN__n_neighbors = k_values) # tunning parameter : n_neighbors\nmodel = Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X_train, Y_train)\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best for k (n_neighbors) is 1 providing a mean squared error of -19.493."},{"metadata":{"trusted":true},"cell_type":"code","source":"# b) Ensembles\nseed2 = 8\nensembles = []\nensembles.append(('ScaledAB',Pipeline([('Scaler', StandardScaler()),('AB',AdaBoostRegressor(random_state=seed2))])))\nensembles.append(('ScaledGBM',Pipeline([('Scaler', StandardScaler()),('GBM',GradientBoostingRegressor(random_state=seed2))])))\nensembles.append(('ScaledRF',Pipeline([('Scaler', StandardScaler()),('RF',RandomForestRegressor(random_state=seed2))])))\nensembles.append(('ScaledET',Pipeline([('Scaler', StandardScaler()),('ET',ExtraTreesRegressor(random_state=seed2))])))\nresults = []\nnames = []\nfor name, model in ensembles:\n    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n    \n# Compare Ensemble Algorithms\nfig3 = plt.figure()\nax3 = fig3.add_axes([0,0,2,2])\nax3.boxplot(results, labels=names, showmeans=True, meanline=True, meanprops = dict(linestyle='--', linewidth=2.5, color='green'))\nax3.yaxis.grid(True)\nax3.set_title('Scaled Ensemble Algorithm Comparison')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like ExtraTrees has a better mean score, it also looks like GradientBoostingRegressor has a similar distribution and perhaps a better median score.\nTuning the ExtraTrees to further lift the performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ET Algorithm tuning\nparam_grid = dict(ET__n_estimators = np.array([50,60,80,100,150,200,250,300])) # tunning parameter : n_estimators\nmodel = Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesRegressor(random_state=seed2))])\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X_train, Y_train)\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the best conÔ¨Åguration was n estimators=250 resulting in a mean squared error of -8.995152."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\n# 5. Finalize Model\n# a) Predictions on validation dataset\n# prepare the model : training the model on the entire training dataset\nsc = StandardScaler()\nrescaledX = sc.fit_transform(X_train)\nmodel = ExtraTreesRegressor(random_state=seed2, n_estimators=250)\nmodel.fit(rescaledX, Y_train)\n# transform the validation dataset\nrescaledTestX = sc.transform(X_test)\npredictions = model.predict(rescaledTestX)\nprint('- mean squared error: {}, r-squared: {}' .format(-mean_squared_error(Y_test, predictions), r2_score(Y_test, predictions)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}