{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"cd '../input/pccnet3/PCC-Net'","metadata":{"execution":{"iopub.status.busy":"2021-05-22T22:14:09.539428Z","iopub.execute_input":"2021-05-22T22:14:09.539815Z","iopub.status.idle":"2021-05-22T22:14:09.553308Z","shell.execute_reply.started":"2021-05-22T22:14:09.539735Z","shell.execute_reply":"2021-05-22T22:14:09.552102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2021-05-22T22:14:12.927707Z","iopub.execute_input":"2021-05-22T22:14:12.928016Z","iopub.status.idle":"2021-05-22T22:14:12.934734Z","shell.execute_reply.started":"2021-05-22T22:14:12.927987Z","shell.execute_reply":"2021-05-22T22:14:12.933794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install easydict\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-22T22:14:19.943802Z","iopub.execute_input":"2021-05-22T22:14:19.944137Z","iopub.status.idle":"2021-05-22T22:14:29.14192Z","shell.execute_reply.started":"2021-05-22T22:14:19.944106Z","shell.execute_reply":"2021-05-22T22:14:29.140924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorboardX import SummaryWriter\nimport os\nimport random\nimport cv2\nimport torch\nfrom torch import optim\nfrom torch.autograd import Variable\nfrom torch.nn import NLLLoss2d\nfrom torch.optim.lr_scheduler import StepLR\nimport torchvision.transforms as standard_transforms\nimport torchvision.utils as vutils\nfrom models.CC import CrowdCounter\nfrom config import cfg\nfrom loading_data import loading_data\nfrom misc.utils import *\nfrom misc.timer import Timer\nimport pdb\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\nimport seaborn as sn\n\n\ndef miou(im1, im2):\n    im1 = np.asarray(im1).astype(np.bool)\n    im2 = np.asarray(im2).astype(np.bool)\n\n    if im1.shape != im2.shape:\n        raise ValueError(\"Shape mismatch\")\n\n    intersection = np.logical_and(im1, im2)\n    union = np.logical_or(im1, im2)\n\n    return intersection.sum() / union.sum()\n\ndef dice(im1, im2):\n    im1 = np.asarray(im1).astype(np.bool)\n    im2 = np.asarray(im2).astype(np.bool)\n\n    if im1.shape != im2.shape:\n        raise ValueError(\"Shape mismatch\")\n\n    intersection = np.logical_and(im1, im2)\n\n    return 2. * intersection.sum() / (im1.sum() + im2.sum())\n\n    \ntrain_set, train_loader, val_set, val_loader, restore_transform = loading_data()\n\n_t = {'iter time' : Timer(),'train time' : Timer(),'val time' : Timer()} \n\nrand_seed = cfg.TRAIN.SEED    \nif rand_seed is not None:\n    np.random.seed(rand_seed)\n    torch.manual_seed(rand_seed)\n    torch.cuda.manual_seed(rand_seed)\n\ndef main():\n\n    cfg_file = open('./config.py',\"r\")  \n    cfg_lines = cfg_file.readlines()\n    \n    torch.cuda.set_device(cfg.TRAIN.GPU_ID[0])\n    torch.backends.cudnn.benchmark = True\n\n    net = CrowdCounter(ce_weights=train_set.wts,modelname='vgg_backbone')\n\n    net.train()\n    \n    i_tb = 0\n    epoch = 20\n    model_path = './exp/all_ep_331.pth'\n    _t['val time'].tic()\n    validate(val_loader, model_path, epoch, restore_transform)\n    _t['val time'].toc(average=False)\n    print( 'val time of one epoch: {:.2f}s'.format(_t['val time'].diff))\n\n\ndef validate(val_loader, model_path, epoch, restore):\n    net = CrowdCounter(ce_weights=train_set.wts)\n    net.load_state_dict(torch.load(model_path))\n    net.cuda()\n    net.eval()\n    print( '='*50 )\n    val_loss_mse = []\n    val_loss_cls = []\n    val_loss_seg = []\n    val_loss = []\n    mae = 0.0\n    mse = 0.0\n    count = 0\n    accuracy_total = 0\n    precision_total = 0\n    recall_total = 0\n    f1_total = 0\n    total_dice = 0\n    total_miou = 0\n    confusion_matrix_total = None\n    for vi, data in enumerate(val_loader, 0):\n        img, gt_map, gt_cnt, roi, gt_roi, gt_seg = data\n        with torch.no_grad():\n            count+=1\n            img = Variable(img).cuda()\n            gt_map = Variable(gt_map).cuda()\n            gt_seg = Variable(gt_seg).cuda()\n\n            roi = Variable(roi[0]).cuda().float()\n            gt_roi = Variable(gt_roi[0]).cuda()\n\n            pred_map,pred_cls,pred_seg = net(img, gt_map, roi, gt_roi, gt_seg)\n            cloned_pred = pred_seg.clone().detach().cpu().numpy()\n            cloned_gt = gt_seg.clone().detach().cpu().numpy()\n            \n            loss1,loss2,loss3 = net.f_loss()\n            val_loss_mse.append(loss1.item())\n            val_loss_cls.append(loss2.item())\n            val_loss_seg.append(loss3.item())\n            val_loss.append(net.loss.item())\n            # class_id = np.argmax(pred_cls)\n            pred_map = pred_map.data.cpu().numpy()/cfg.DATA.DEN_ENLARGE\n            gt_map = gt_map.data.cpu().numpy()/cfg.DATA.DEN_ENLARGE\n            #print(pred_seg.shape)\n            pred_seg = pred_seg.cpu().max(1)[1].squeeze_(1).data.numpy()\n            gt_seg = gt_seg.data.cpu().numpy()\n            gt_count = np.sum(gt_map)\n            pred_cnt = np.sum(pred_map)\n            total_dice = dice(gt_seg.flatten(), pred_seg.flatten())+total_dice\n            total_miou = miou(gt_seg.flatten(), pred_seg.flatten())+total_miou\n            # print(gt_seg.flatten().shape, pred_seg.flatten().shape)\n            if count==1:\n                confusion_matrix_total = confusion_matrix(gt_seg.flatten().tolist(), pred_seg.flatten().tolist())\n            else:\n                confusion_matrix_total += confusion_matrix(gt_seg.flatten().tolist(), pred_seg.flatten().tolist())\n            # print(confusion_matrix_total)\n            color = (255, 0, 0)\n  \n            # Line thickness of 2 px\n            thickness = 2\n            image = img.cpu()[0,:,:,:].permute(1, 2, 0).numpy()\n            maxi = np.max(image)\n            mini = np.min(image)\n            image = (image-mini)*255/(maxi-mini)\n            image = np.array(image, np.uint8)\n            predicted_class=pred_cls\n            pred_cls = pred_cls.cpu().numpy().tolist()\n            roi = roi.cpu().numpy().tolist()\n            for i in range(len(roi)):\n              # start_point = (int(r[2]), int(r[1]))\n              # end_point = (int(r[4]), int(r[3]))\n              xmin = int(roi[i][1])\n              ymin = int(roi[i][2])\n              xmax = int(roi[i][3])\n              ymax = int(roi[i][4])\n              start_point = (xmin, ymin)\n              end_point = (xmax, ymax)\n              # print(start_point, end_point) \n              \n              image=image.copy()\n              image = cv2.rectangle(image,start_point, end_point, color, thickness)\n              cls = np.argmax(pred_cls[i])\n              cv2.putText(image,str(cls),(xmin,ymin),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,255,0),1)\n            # print(type(image))\n            plt.imshow((image))\n            plt.show()\n            # cv2.imshow(image)\n            # cv2.imwrite('image.png', image)\n            # plt.imshow(img[0,:,:,:].cpu().permute(1,2,0))\n            # plt.show()\n            # plt.imshow(gt_seg[0,:,:])\n            # plt.show()\n            # plt.imshow(gt_seg[0,:,:])\n            # plt.show()\n            #change the gt_seg --> gt_roi and pred_seg --> pred_cls\n\n\n            #print(calculate_lane_metrics(pred_cls,gt_roi.cpu().numpy().tolist(), 10))\n            #print(type(gt_seg))\n            #print(type(pred_seg))\n            #print(type(pred_cls))\n            \n            gt_roi=gt_roi.cpu().numpy()\n           \n            \n            \n            predicted_class = predicted_class.cpu().numpy()\n            ####\n            predicted_class_score = np.zeros_like(predicted_class)\n            predicted_class_score[np.arange(len(predicted_class)), predicted_class.argmax(1)] = 1\n            \n            \n            #######\n            \n            accuracy = accuracy_score(gt_roi.flatten(), predicted_class_score.flatten())\n            precision = precision_score(gt_roi.flatten(), predicted_class_score.flatten()) \n            f1 = f1_score(gt_roi.flatten(), predicted_class_score.flatten())\n            recall = recall_score(gt_roi.flatten(), predicted_class_score.flatten())\n            pred_dummy = np.array(pred_seg>0.5, np.float32)\n            accuracy_total = accuracy+accuracy_total\n            recall_total=recall+recall_total\n            precision_total=precision+precision_total\n            f1_total=f1+f1_total\n            mae += abs(gt_count-pred_cnt)\n            mse += ((gt_count-pred_cnt)*(gt_count-pred_cnt))\n\n    confusion = confusion_matrix_total\n    sn.heatmap(confusion, annot=True, annot_kws={\"size\": 16})\n    plt.imshow(image)\n    plt.show()\n    mean_iou = total_miou/count*100\n    mean_dice = total_dice/count*100\n    mean_accuracy = accuracy_total/count*100\n    mean_f1 = f1_total/count*100\n    mean_recall = recall_total/count*100\n    mean_precision = precision_total/count*100\n    mae = mae/val_set.get_num_samples()\n    mse = np.sqrt(mse/val_set.get_num_samples())\n    loss1 = np.mean(val_loss_mse)\n    loss2 = np.mean(val_loss_cls)\n    loss3 = np.mean(val_loss_seg)\n    loss = np.mean(val_loss)\n\n    print( '='*50 )\n    print( '    '+ '-'*20 )\n    print( '    [mae %.1f mse %.1f], [val loss %.8f %.8f %.4f %.4f]' % (mae, mse, loss, loss1, loss2, loss3) )        \n    print( '    '+ '-'*20 )\n    print(f\"accuracy:{mean_accuracy}\\nprecision:{mean_precision}\\nrecall:{mean_recall}\\nf1_score:{mean_f1}\")\n    print(f'MIOU:{mean_iou}\\nDice Score:{mean_dice}')\n    print( '='*50 )\n\n\nif __name__ == '__main__':\n    main()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-22T23:48:14.687528Z","iopub.execute_input":"2021-05-22T23:48:14.687864Z","iopub.status.idle":"2021-05-22T23:54:57.277934Z","shell.execute_reply.started":"2021-05-22T23:48:14.687832Z","shell.execute_reply":"2021-05-22T23:54:57.277028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}