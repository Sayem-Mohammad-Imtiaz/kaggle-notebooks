{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Check, clean data for better usability\n1. Parsed columns \n* \"period\" into \"period_name\" ,\"period start\", \"period end\"  \n*  \"named_by\" into \"named by\" ,\"year of naming\"\n2. Moved some values from wrong columns\n* from \"type\" to \"length\" (1 value)\n* from \"named_by\" to \"species\" (5 values)\n3. replace column \"length\" (type str) with column \"length_meters\" (type float)","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# functions to parse columns\n\ndef parse_length(s):\n    # parse field \"length\" into \"length\" ,\"unit of measure\"\n    if pd.isnull(s):\n        return (np.nan, np.nan)\n    return (float(str(s)[:-1]), str(s)[-1:])\n\ndef parse_period(s):\n    # parse field \"period\" into \"period_name\" ,\"period start\", \"period end\"\n    try:\n        parsed_groups = re.match(r'([\\D]+)([\\d]+)(-?)([\\d]*)([\\D]+)', s).groups()\n    except: \n        return [s, np.nan, np.nan]\n    period = parsed_groups[0].strip()\n    period_start = parsed_groups[1]\n    period_end = parsed_groups[3] if parsed_groups[3] != '' else parsed_groups[1] \n    return [period, str(period_start), str(period_end)]\n\ndef parse_named(s):\n    # parse field \"named_by\" into \"named by\" ,\"year of naming\"\n    try:\n        parsed_groups = re.match(r'([^\\d\\(]+)(\\(?)(\\d+)', s).groups()\n    except: \n        return [s, np.nan]\n    named = parsed_groups[0].strip()\n    year = parsed_groups[2]\n    return [named, str(year)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/jurassic-park-the-exhaustive-dinosaur-dataset/data.csv')\nprint(df.shape)\ndf.set_index('name', inplace=True)\ndf.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{df.type.nunique()}')\nprint(f'{df.type.isna().sum()}')\ndf.type.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# manually moved value from \"type\" to \"length\"\nprint(df.type.nunique())\ndf.type.value_counts()[:10]\ndf.loc[df.type=='1.0m', 'length'] = '1.0m'\ndf.loc[df.type=='1.0m','type'] = np.nan\ndf.loc[df.type.isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parse column \"period\"\ndf['period_name'], df['period_start'], df['period_end']  = zip(*df['period'].apply(parse_period))\ndf[['period', 'period_name', 'period_start', 'period_end']].sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['named'], df['named_year'] = zip(*df['named_by'].apply(parse_named))\ndf[['named_by','named', 'named_year']].sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# founded, that 5 field filled by species name\ndf.loc[df['named_year'].isnull()][['named_by','named', 'named_year','species']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# and there is no more nan values for species\ndf.loc[df['species'].isnull()].named.count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# moved values from named_by to species\ndf['species'] = np.where(df['species'].isnull(), df['named'], df['species'])\ndf.loc[df['named_year'].isnull(), 'named_by'] = np.nan\ndf.loc[df['named_year'].isnull(), 'named'] = np.nan\ndf.loc[df['named_year'].isnull()][['named_by','named', 'named_year','species']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['length_parsed'],df['measure'] = zip(*df['length'].apply(parse_length))\ndf[['length','length_parsed', 'measure']].sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check that there only one measure - meters\n# rename column and drop column 'measure'\nprint(df.measure.nunique())\ndf.rename(columns={'length_parsed':'length_meters'}, inplace=True)\ndf.drop(columns=['measure'], inplace=True)\ndf.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop useless columns\ndf_clean = df[['diet', 'lived_in', 'type', 'taxonomy',\n       'species', 'period_name', 'period_start',\n       'period_end', 'named', 'named_year',\n       'length_meters']].copy()\nprint(df_clean.shape)\ndf_clean.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean.to_csv('jurassic_park.csv', sep='|')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}