{"cells":[{"metadata":{"id":"ASTVU0BaRSkA","trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torch import nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport pandas as pd\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"RNZuBiNeRSkL","trusted":true},"cell_type":"code","source":"# torch.Tensor.ndim = property(lambda x: len(x.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"id":"WXA1P0o2AouE","outputId":"83d14313-e3a0-4e88-f072-f574f2bd4620","trusted":false},"cell_type":"code","source":"!unzip digit-recognizer.zip","execution_count":null,"outputs":[]},{"metadata":{"id":"IzY-yWz6RSkd","trusted":true},"cell_type":"code","source":"# path = \"/content/Mnist\"\ntrain_path = \"../input/digit-recognizer/train.csv\"\ntest_path = \"../input/digit-recognizer/test.csv\"","execution_count":null,"outputs":[]},{"metadata":{"id":"SVmOxxm2A6ie","trusted":true},"cell_type":"code","source":"train = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_size = 8000\n# train_size = len(train) - val_size\n# train_data, val_data = random_split(train, [train_size, val_size])","execution_count":null,"outputs":[]},{"metadata":{"id":"7HHHqAX6A6rx","trusted":true},"cell_type":"code","source":"Y = train[\"label\"]\nX = train.drop(labels = [\"label\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting\nX_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2)\nX_train.shape, Y_train.shape, X_val.shape, Y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"kMIA5dfVD2ba","outputId":"a0b50dbc-3326-46d8-fe94-a7a8bc45df0e","trusted":true},"cell_type":"code","source":"train_size = X_train.shape[0]\nval_size = X_val.shape[0]\nprint(\"Training size {}, Validation size {} \".format(train_size, val_size))","execution_count":null,"outputs":[]},{"metadata":{"id":"sTeNr9HpC_dq","trusted":true},"cell_type":"code","source":"#Normalization \nX_train = X_train / 255.0\nX_val = X_val / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"id":"f-rdW9MtB8A3","outputId":"182e278d-c2ff-440a-e6ce-eecfa1752f56","trusted":true},"cell_type":"code","source":"X_train = np.array(X_train, np.float32)\ntest = np.array(test, np.float32)\nY_train = np.array(Y_train, np.long)\nX_val = np.array(X_val, np.float32)\nY_val = np.array(Y_val, np.long)\nprint(X_train.shape)\nprint(test.shape)\nprint(X_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[10].reshape(28, 28), cmap='gray')\nprint(Y_train[10])","execution_count":null,"outputs":[]},{"metadata":{"id":"W6gQWgImCCPJ","outputId":"ae485f01-b0d8-4e13-ea42-3856a015b6c6","trusted":true},"cell_type":"code","source":"type(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"-BkY2SPQDGTP","trusted":true},"cell_type":"code","source":"X_train = torch.from_numpy(X_train)\nY_train = torch.from_numpy(Y_train)\nX_val = torch.from_numpy(X_val)\nY_val = torch.from_numpy(Y_val)\ntest = torch.from_numpy(test)","execution_count":null,"outputs":[]},{"metadata":{"id":"hyNZvdmkRSkl","trusted":false},"cell_type":"code","source":"# transform_img = torchvision.transforms.Compose([\n# #                                           torchvision.transforms.Resize((224, 224)),\n#                                           torchvision.transforms.ToTensor(),\n#                                           torchvision.transforms.Normalize(mean=[0.485], std=[0.229])\n#                                           ])","execution_count":null,"outputs":[]},{"metadata":{"id":"-Ai7oHR0RSkv","trusted":false},"cell_type":"code","source":"# print(transform_img)","execution_count":null,"outputs":[]},{"metadata":{"id":"RGEz3da-RSk3","trusted":false},"cell_type":"code","source":"# data = torchvision.datasets.MNIST(path, train=True, transform=transform_img, target_transform=None, download=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"orhNXSB_Ck3H","trusted":true},"cell_type":"code","source":"train_data = torch.utils.data.TensorDataset(X_train, Y_train)\nval_data = torch.utils.data.TensorDataset(X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"id":"E1yXuZgkRSlA","trusted":true},"cell_type":"code","source":"# inputs = data.data\n# labels = data.targets\n# print(inputs.shape)\n\n\n# print(labels[2])\n# plt.imshow(inputs[2].numpy())","execution_count":null,"outputs":[]},{"metadata":{"id":"HCkF2sa32Zb9","trusted":false},"cell_type":"code","source":"# dir(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 32","execution_count":null,"outputs":[]},{"metadata":{"id":"12P4rGEsRSlH","trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch, shuffle=True, num_workers=4)\nval_loader = torch.utils.data.DataLoader(val_data, batch_size=2*batch, shuffle=True, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":null,"outputs":[]},{"metadata":{"id":"7GfM58IpRSla","trusted":true},"cell_type":"code","source":"class MLP(torch.nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        self.fc1 = torch.nn.Linear(784, 32)\n        # nn.ReLU(),\n        self.fc2 = torch.nn.Linear(32, 16)\n        # nn.ReLU(),\n        self.fc3 = torch.nn.Linear(16, 10)\n        # nn.Softmax()\n#         self.fc1 = torch.nn.Linear(784, 10)\n          \n    def forward(self, x):\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.fc3(x)\n#         x = self.fc1(x)\n        return x\n\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        preds = self(images)\n        loss = F.cross_entropy(preds, labels)\n        acc = accuracy(preds, labels)\n        return {'val_loss': loss, 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))","execution_count":null,"outputs":[]},{"metadata":{"id":"EjYn2BVsRSlk","trusted":true},"cell_type":"code","source":"model = MLP()","execution_count":null,"outputs":[]},{"metadata":{"id":"K8K8e2b7RSls","outputId":"73858ebe-47b6-4b33-ac4a-a9a200e7e62c","trusted":true},"cell_type":"code","source":"print(model)","execution_count":null,"outputs":[]},{"metadata":{"id":"C4Hnduy3CbaZ","outputId":"53f7f577-3652-41ce-9f9b-c9563f0250e8","trusted":true},"cell_type":"code","source":"for para in model.parameters():\n  print(para.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"0dasZJZYRSly","trusted":true},"cell_type":"code","source":"# loss_fn = F.cross_entropy\n# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"id":"6hPTw8DlUWLM","outputId":"42244c01-feb7-40e9-8d05-7afc30ddce68","trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n  device = torch.device('cuda')\nelse:\n  device = torch.device('cpu')\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)","execution_count":null,"outputs":[]},{"metadata":{"id":"bzOcO9a5U-NB","outputId":"c7215ddc-d020-413b-e105-4b4ccbd57b43","trusted":true},"cell_type":"code","source":"# model.to(device=device)","execution_count":null,"outputs":[]},{"metadata":{"id":"YbySJADSETB8","trusted":true},"cell_type":"code","source":"# images, labels = next(iter(train_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model","execution_count":null},{"metadata":{"id":"kPv0FK24RSl6","outputId":"fdcc9fb9-f7b0-4b1f-8b6b-86e7a0658c23","trusted":true},"cell_type":"code","source":"def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    \n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_device(model, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [evaluate(model, val_loader)]\nhistory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history += fit(5, 0.5, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history += fit(5, 0.1, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = [x['val_loss'] for x in history]\nplt.plot(losses, '-x')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('Loss vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracies = [x['val_acc'] for x in history]\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction on Samples","execution_count":null},{"metadata":{"id":"qfEeElwlRSmA","trusted":false},"cell_type":"code","source":"# test_data = torchvision.datasets.MNIST(path, train=False, transform=transform_img, target_transform=None, download=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"zoXitpFURSmG","trusted":false},"cell_type":"code","source":"# inputs = test_data.test_data\n# labels = test_data.test_labels\n# print(inputs.shape)\n\n\n# print(labels[1])\n# plt.imshow(inputs[1].numpy())","execution_count":null,"outputs":[]},{"metadata":{"id":"fwwyrbm3Fv2Z","trusted":true},"cell_type":"code","source":"test_data = torch.utils.data.TensorDataset(test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Z8uQHRBzRSmM","trusted":true},"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DeviceDataLoader(train_loader, device)","execution_count":null,"outputs":[]},{"metadata":{"id":"e5JKwVklRSmT","outputId":"0a1d9ca5-4964-4f69-f5aa-c423a3ff7e48","trusted":true},"cell_type":"code","source":"model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = test_data[1]\nplt.imshow(img[0].reshape(28, 28), cmap='gray')\nprint('Predicted: ', predict_image(img[0], model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = test_data[1]\nprint(type(img))\nprint(type(img[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate(model, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"id":"8BnekZYMRSmb","trusted":false},"cell_type":"code","source":"# correct_ans = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"pjBkeB7hRSmn","trusted":false},"cell_type":"code","source":"# def correct_pred_count(pred, answer):\n#     pred = torch.argmax(pred, dim=1)\n#     correct_count_vector = (pred.data == answer.data)\n#     correct_count = correct_count_vector.sum()\n#     return correct_count","execution_count":null,"outputs":[]},{"metadata":{"id":"-gxbV3WxRSmi","trusted":false},"cell_type":"code","source":"# for images, labels in test_loader:\n    \n#     images = images.view(images.size(0), -1)\n\n#     images = images.to(device=device)\n#     labels = labels.to(device=device)\n\n#     preds = model(images)\n    \n#     correct_ans += correct_pred_count(preds, labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"GrvLYC91RSmt","trusted":false},"cell_type":"code","source":"# accuracy = (correct_ans /  10000.0)","execution_count":null,"outputs":[]},{"metadata":{"id":"TsrtU_MgaF56","trusted":false},"cell_type":"code","source":"# accuracy","execution_count":null,"outputs":[]},{"metadata":{"id":"r1odYnI-T3OB","trusted":true},"cell_type":"code","source":"# import csv","execution_count":null,"outputs":[]},{"metadata":{"id":"vU5IEj4BTTVH","outputId":"c59303a7-f4ea-4678-d89f-f11ff89997cc","trusted":true},"cell_type":"code","source":"# csv_path = \"mnist.csv\"\n# file = open(csv_path, 'w')\n# writer = csv.writer(file)\n# writer.writerow([\"ImageId\", \"Label\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"hFV3SQqUP7tA","outputId":"709a88df-8e94-4547-82cc-80833ebc40c0","trusted":true},"cell_type":"code","source":"prediction = []\nfor i, images in enumerate(test_loader, 1):\n  images = images[0]\n#   images = images.to(device=device)\n\n  preds = model(images)\n#   print(i)\n  preds = torch.argmax(preds, dim=1)\n  prediction.append(preds.item())\n#   writer.writerow([i, preds.item()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(prediction)","execution_count":null,"outputs":[]},{"metadata":{"id":"QeOHgUYMVhjv","trusted":true},"cell_type":"code","source":"path = \"CNN_submission2.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv('../input/digit-recognizer/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.DataFrame({\"ImageId\": list(range(1,len(prediction)+1)),\n                         \"Label\": prediction})\nsample_sub.to_csv('CNN_submission2.csv', index=False)\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"9OkJDlK1VhbT","trusted":true},"cell_type":"code","source":"file = [row.strip().split() for row in open(path)]","execution_count":null,"outputs":[]},{"metadata":{"id":"s9_38M_pQ0WQ","outputId":"a7e5019c-a438-4a81-bbdd-d4514555b9d2","trusted":true},"cell_type":"code","source":"len(file)","execution_count":null,"outputs":[]},{"metadata":{"id":"LqFZ9iEUX0Nh","outputId":"ac58d284-2b14-4f8c-c338-415339deaf6f","trusted":true},"cell_type":"code","source":"file[len(file) - 1]","execution_count":null,"outputs":[]},{"metadata":{"id":"FBPcuVIUX7g8","outputId":"b6fd39f3-6e01-43fb-d32a-dce8e874d1c0","trusted":true},"cell_type":"code","source":"len(test_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save and upload","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"saved_weights_fname='MNIST-feedforward.pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), saved_weights_fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install jovian --upgrade --quiet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import jovian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"project_name = \"MNISt Feed forward\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None, outputs=[saved_weights_fname])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}