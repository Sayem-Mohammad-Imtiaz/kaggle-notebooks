{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-22T06:49:41.352028Z","iopub.execute_input":"2021-06-22T06:49:41.352365Z","iopub.status.idle":"2021-06-22T06:49:41.525954Z","shell.execute_reply.started":"2021-06-22T06:49:41.352328Z","shell.execute_reply":"2021-06-22T06:49:41.525142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport glob\nimport PIL\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage.util import montage \nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nfrom PIL import Image, ImageOps  \n\n# neural imaging\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\n!pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif \nimport gif_your_nifti.core as gif2nif\n\n# ml libs\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# Make numpy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:49:59.212044Z","iopub.execute_input":"2021-06-22T06:49:59.212483Z","iopub.status.idle":"2021-06-22T06:50:11.753972Z","shell.execute_reply.started":"2021-06-22T06:49:59.212445Z","shell.execute_reply":"2021-06-22T06:50:11.753061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pynrrd","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:50:11.766253Z","iopub.execute_input":"2021-06-22T06:50:11.766585Z","iopub.status.idle":"2021-06-22T06:50:17.946089Z","shell.execute_reply.started":"2021-06-22T06:50:11.766554Z","shell.execute_reply":"2021-06-22T06:50:17.945154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Data Visualization***","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nfrom random import randint\n\nimport numpy as np\nimport pandas as pd\n\nimport nibabel as nib\nimport pydicom as pdm\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nimport nrrd\nimport h5py\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport matplotlib.animation as anim\n\nimport imageio\nfrom skimage.transform import resize\nfrom skimage.util import montage\n\nfrom IPython.display import Image as show_gif\n\nimport warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:50:53.860842Z","iopub.execute_input":"2021-06-22T06:50:53.861201Z","iopub.status.idle":"2021-06-22T06:50:53.867301Z","shell.execute_reply.started":"2021-06-22T06:50:53.861173Z","shell.execute_reply":"2021-06-22T06:50:53.866158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image data descriptions Sample:\n\nAll multimodal scans (Images) are available as NIfTI files (.nii.gz) -> commonly used medical imaging format to store brain imagin data obtained using MRI and describe different MRI settings\n\nT1: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1–6 mm slice thickness.\nT1c: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients.\nT2: T2-weighted image, axial 2D acquisition, with 2–6 mm slice thickness.\nFLAIR: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2–6 mm slice thickness.\nData were acquired with different clinical protocols and various scanners from multiple (n=19) institutions.\n\nAll the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise the GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2), and the necrotic and non-enhancing tumor core (NCR/NET — label 1). The provided data are distributed after their pre-processing, i.e., co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped.","metadata":{}},{"cell_type":"code","source":"class ImageToGIF:\n    \"\"\"Create GIF without saving image files.\"\"\"\n    def __init__(self,\n                 size=(600, 400), \n                 xy_text=(80, 10),\n                 dpi=100, \n                 cmap='CMRmap'):\n\n        self.fig = plt.figure()\n        self.fig.set_size_inches(size[0] / dpi, size[1] / dpi)\n        self.xy_text = xy_text\n        self.cmap = cmap\n        \n        self.ax = self.fig.add_axes([0, 0, 1, 1])\n        self.ax.set_xticks([])\n        self.ax.set_yticks([])\n        self.images = []\n \n    def add(self, *args, label, with_mask=True):\n        \n        image = args[0]\n        mask = args[-1]\n        plt.set_cmap(self.cmap)\n        plt_img = self.ax.imshow(image, animated=True)\n        if with_mask:\n            plt_mask = self.ax.imshow(np.ma.masked_where(mask == False, mask),\n                                      alpha=0.7, animated=True)\n\n        plt_text = self.ax.text(*self.xy_text, label, color='red')\n        to_plot = [plt_img, plt_mask, plt_text] if with_mask else [plt_img, plt_text]\n        self.images.append(to_plot)\n        plt.close()\n \n    def save(self, filename, fps):\n        animation = anim.ArtistAnimation(self.fig, self.images)\n        animation.save(filename, writer='imagemagick', fps=fps)\n        \n        \nclass Image3dToGIF3d:\n    \"\"\"\n    Displaying 3D images in 3d axes.\n    Parameters:\n        img_dim: shape of cube for resizing.\n        figsize: figure size for plotting in inches.\n    \"\"\"\n    def __init__(self, \n                 img_dim: tuple = (55, 55, 55),\n                 figsize: tuple = (15, 10),\n                ):\n        \"\"\"Initialization.\"\"\"\n        self.img_dim = img_dim\n        print(img_dim)\n        self.figsize = figsize\n    \n    def _explode(self, data: np.ndarray):\n        \"\"\"\n        Takes: array and return an array twice as large in each dimension,\n        with an extra space between each voxel.\n        \"\"\"\n        shape_arr = np.array(data.shape)\n        size = shape_arr[:3] * 2 - 1\n        exploded = np.zeros(np.concatenate([size, shape_arr[3:]]),\n                            dtype=data.dtype)\n        exploded[::2, ::2, ::2] = data\n        return exploded\n\n    def _expand_coordinates(self, indices: np.ndarray):\n        x, y, z = indices\n        x[1::2, :, :] += 1\n        y[:, 1::2, :] += 1\n        z[:, :, 1::2] += 1\n        return x, y, z\n    \n    def _normalize(self, arr: np.ndarray):\n        \"\"\"Normilize image value between 0 and 1.\"\"\"\n        return arr / arr.max()\n    \n    def _scale_by(self, arr: np.ndarray, factor: int):\n        \"\"\"\n        Scale 3d Image to factor.\n        Parameters:\n            arr: 3d image for scalling.\n            factor: factor for scalling.\n        \"\"\"\n        mean = np.mean(arr)\n        return (arr - mean) * factor + mean\n    \n    def get_transformed_data(self, data: np.ndarray):\n        \"\"\"Data transformation: normalization, scaling, resizing.\"\"\"\n        norm_data = np.clip(self._normalize(data)-0.1, 0, 1) ** 0.4\n        scaled_data = np.clip(self._scale_by(norm_data, 2) - 0.1, 0, 1)\n        resized_data = resize(scaled_data, self.img_dim, mode='constant')\n        return resized_data\n    \n    def plot_cube(self,\n                  cube,\n                  title: str = '', \n                  init_angle: int = 0,\n                  make_gif: bool = False,\n                  path_to_save: str = 'filename.gif'\n                 ):\n        \"\"\"\n        Plot 3d data.\n        Parameters:\n            cube: 3d data\n            title: title for figure.\n            init_angle: angle for image plot (from 0-360).\n            make_gif: if True create gif from every 5th frames from 3d image plot.\n            path_to_save: path to save GIF file.\n            \"\"\"\n        cube = self._normalize(cube)\n\n        facecolors = cm.gist_stern(cube)\n        facecolors[:,:,:,-1] = cube\n        facecolors = self._explode(facecolors)\n\n        filled = facecolors[:,:,:,-1] != 0\n        x, y, z = self._expand_coordinates(np.indices(np.array(filled.shape) + 1))\n\n        with plt.style.context(\"dark_background\"):\n\n            fig = plt.figure(figsize=self.figsize)\n            ax = fig.gca(projection='3d')\n\n            ax.view_init(30, init_angle)\n            ax.set_xlim(right = self.img_dim[0] * 2)\n            ax.set_ylim(top = self.img_dim[1] * 2)\n            ax.set_zlim(top = self.img_dim[2] * 2)\n            ax.set_title(title, fontsize=18, y=1.05)\n\n            ax.voxels(x, y, z, filled, facecolors=facecolors, shade=False)\n\n            if make_gif:\n                images = []\n                for angle in tqdm(range(0, 360, 5)):\n                    ax.view_init(30, angle)\n                    fname = str(angle) + '.png'\n\n                    plt.savefig(fname, dpi=120, format='png', bbox_inches='tight')\n                    images.append(imageio.imread(fname))\n                    #os.remove(fname)\n                imageio.mimsave(path_to_save, images)\n                plt.close()\n\n            else:\n                plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:51:10.034628Z","iopub.execute_input":"2021-06-22T06:51:10.03495Z","iopub.status.idle":"2021-06-22T06:51:10.058147Z","shell.execute_reply.started":"2021-06-22T06:51:10.03492Z","shell.execute_reply":"2021-06-22T06:51:10.057341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Nifti File Input \"\"\"\nsample_filename = '/kaggle/input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_flair.nii'\nsample_filename_mask = '/kaggle/input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii'\n\nsample_img = nib.load(sample_filename)\nsample_img = np.asanyarray(sample_img.dataobj)\nsample_mask = nib.load(sample_filename_mask)\nsample_mask = np.asanyarray(sample_mask.dataobj)\nprint(\"img shape ->\", sample_img.shape)\nprint(\"mask shape ->\", sample_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:51:15.676284Z","iopub.execute_input":"2021-06-22T06:51:15.676652Z","iopub.status.idle":"2021-06-22T06:51:15.731166Z","shell.execute_reply.started":"2021-06-22T06:51:15.676623Z","shell.execute_reply":"2021-06-22T06:51:15.730394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_img, sample_mask","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:51:19.044184Z","iopub.execute_input":"2021-06-22T06:51:19.044545Z","iopub.status.idle":"2021-06-22T06:51:19.084793Z","shell.execute_reply.started":"2021-06-22T06:51:19.044514Z","shell.execute_reply":"2021-06-22T06:51:19.08383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \"\"\" Visualization of 3d data in 2d slices \"\"\" \n\nslice_n = 100\nfig, ax = plt.subplots(2, 3, figsize=(25, 15))\n\nax[0, 0].imshow(sample_img[slice_n, :, :])\nax[0, 0].set_title(f\"image slice number {slice_n} along the x-axis\", fontsize=18, color=\"red\")\nax[1, 0].imshow(sample_mask[slice_n, :, :])\nax[1, 0].set_title(f\"mask slice {slice_n} along the x-axis\", fontsize=18, color=\"red\")\n\nax[0, 1].imshow(sample_img[:, slice_n, :])\nax[0, 1].set_title(f\"image slice number {slice_n} along the y-axis\", fontsize=18, color=\"red\")\nax[1, 1].imshow(sample_mask[:, slice_n, :])\nax[1, 1].set_title(f\"mask slice number {slice_n} along the y-axis\", fontsize=18, color=\"red\")\n\nax[0, 2].imshow(sample_img[:, :, slice_n])\nax[0, 2].set_title(f\"image slice number {slice_n} along the z-axis\", fontsize=18, color=\"red\")\nax[1, 2].imshow(sample_mask[:, :, slice_n])\nax[1, 2].set_title(f\"mask slice number {slice_n}along the z-axis\", fontsize=18, color=\"red\")\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:51:24.319285Z","iopub.execute_input":"2021-06-22T06:51:24.319627Z","iopub.status.idle":"2021-06-22T06:51:28.167966Z","shell.execute_reply.started":"2021-06-22T06:51:24.319594Z","shell.execute_reply":"2021-06-22T06:51:28.167121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"slice_n = 100\nfig, ax = plt.subplots(2, 3, figsize=(25, 15))\nax[1, 2].imshow(sample_mask[:, :, slice_n])\nax[1, 2].set_title(f\"mask slice number {slice_n}along the z-axis\", fontsize=18, color=\"green\")\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:51:35.448144Z","iopub.execute_input":"2021-06-22T06:51:35.448491Z","iopub.status.idle":"2021-06-22T06:51:36.150995Z","shell.execute_reply.started":"2021-06-22T06:51:35.448459Z","shell.execute_reply":"2021-06-22T06:51:36.150042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## matching colormaps\n#Greys_r RdGy_r  CMRmap afmhot binary_r bone copper cubehelix gist_heat gist_stern gnuplot hot inferno magma nipy_spectral\n\nsample_data_gif = ImageToGIF()\nlabel = sample_filename.replace('/', '.').split('.')[-2]\nfilename = f'{label}_3d_2d.gif'\n\nfor i in range(sample_img.shape[0]):\n    image = np.rot90(sample_img[i])\n    mask = np.clip(np.rot90(sample_mask[i]), 0, 1)\n    sample_data_gif.add(image, mask, label=f'{label}_{str(i)}')\n \nsample_data_gif.save(filename, fps=15)\nshow_gif(filename, format='png')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:52:13.171744Z","iopub.execute_input":"2021-06-22T06:52:13.17206Z","iopub.status.idle":"2021-06-22T06:52:48.091292Z","shell.execute_reply.started":"2021-06-22T06:52:13.17203Z","shell.execute_reply":"2021-06-22T06:52:48.086353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = np.rot90(montage(sample_img))\nmask = np.rot90(montage(sample_mask)) \nmask = np.clip(mask, 0, 1)\n\nfig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.imshow(np.ma.masked_where(mask == False, mask),\n           cmap='cool', alpha=0.6, animated=True)\nax1.imshow(image, cmap ='bone')\nfig.savefig(f'{label}_3d_to_2d.png', format='png', bbox_inches='tight', pad_iches=0.0)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:53:11.281949Z","iopub.execute_input":"2021-06-22T06:53:11.28227Z","iopub.status.idle":"2021-06-22T06:53:33.579686Z","shell.execute_reply.started":"2021-06-22T06:53:11.282239Z","shell.execute_reply":"2021-06-22T06:53:33.578631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Visualization of 3d data in 3d slices %%time  \"\"\"  \n\ntitle = sample_filename.replace(\".\", \"/\").split(\"/\")[-2]\nfilename = title+\"_3d.gif\"\n\ndata_to_3dgif = Image3dToGIF3d()#img_dim = (120, 120, 78)\ntransformed_data = data_to_3dgif.get_transformed_data(sample_img)\ndata_to_3dgif.plot_cube(\n    transformed_data[:38, :47, :35],#[:77, :105, :55]\n    title=title,\n    make_gif=True,\n    path_to_save=filename\n)\nshow_gif(filename, format='png')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T03:32:34.435254Z","iopub.execute_input":"2021-06-07T03:32:34.435572Z","iopub.status.idle":"2021-06-07T03:32:34.440662Z","shell.execute_reply.started":"2021-06-07T03:32:34.435541Z","shell.execute_reply":"2021-06-07T03:32:34.4396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DEFINE seg-areas  \nSEGMENT_CLASSES = {\n    0 : 'NORMAL SAMPLE',\n    1 : 'FRANK SIGN', # or NON-ENHANCING tumor CORE\n    2 : 'FRANK SIGN_VIEW_1',\n    3 : 'FRANK SIGN_VIEW_2' # original 4 -> converted into 3 later\n}\n# there are 155 slices per volume\n# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 # first slice of volume that we will include","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:53:43.962913Z","iopub.execute_input":"2021-06-22T06:53:43.963246Z","iopub.status.idle":"2021-06-22T06:53:43.967776Z","shell.execute_reply.started":"2021-06-22T06:53:43.963215Z","shell.execute_reply":"2021-06-22T06:53:43.966602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH = '../input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\nVALIDATION_DATASET_PATH = '../input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n\ntest_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\ntest_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\ntest_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\ntest_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\ntest_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n\nfig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\nslice_w = 25\nax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\nax1.set_title('Image flair')\nax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\nax2.set_title('Image t1')\nax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\nax3.set_title('Image t1ce')\nax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\nax4.set_title('Image t2')\nax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\nax5.set_title('Mask')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:55:13.148053Z","iopub.execute_input":"2021-06-22T06:55:13.148381Z","iopub.status.idle":"2021-06-22T06:55:14.109582Z","shell.execute_reply.started":"2021-06-22T06:55:13.148351Z","shell.execute_reply":"2021-06-22T06:55:14.108774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Present whole nifti data -> print each slice from 3d data********","metadata":{}},{"cell_type":"markdown","source":"ax[1, 2].imshow(sample_mask[:, :, slice_n])\nax[1, 2].set_title(f\"mask slice number {slice_n}along the z-axis\", fontsize=18, color=\"red\")","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\nslice_w = 25\nax1.imshow(test_image_flair[:,:,test_image_flair.shape[2]//12-slice_w], cmap = 'gray')\nax1.set_title('Image flair')\nax2.imshow(test_image_t1[:,:,test_image_t1.shape[2]//12-slice_w], cmap = 'gray')\nax2.set_title('Image t1')\nax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[2]//12-slice_w], cmap = 'gray')\nax3.set_title('Image t1ce')\nax4.imshow(test_image_t2[:,:,test_image_t2.shape[2]//12-slice_w], cmap = 'gray')\nax4.set_title('Image t2')\nax5.imshow(test_mask[:,:,test_mask.shape[2]//12-slice_w])\nax5.set_title('Mask')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:55:20.584847Z","iopub.execute_input":"2021-06-22T06:55:20.585162Z","iopub.status.idle":"2021-06-22T06:55:21.0562Z","shell.execute_reply.started":"2021-06-22T06:55:20.585133Z","shell.execute_reply":"2021-06-22T06:55:21.055276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:55:27.606157Z","iopub.execute_input":"2021-06-22T06:55:27.606508Z","iopub.status.idle":"2021-06-22T06:55:30.823189Z","shell.execute_reply.started":"2021-06-22T06:55:27.606478Z","shell.execute_reply":"2021-06-22T06:55:30.822236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_flair[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:55:35.692796Z","iopub.execute_input":"2021-06-22T06:55:35.693124Z","iopub.status.idle":"2021-06-22T06:55:38.720178Z","shell.execute_reply.started":"2021-06-22T06:55:35.693094Z","shell.execute_reply":"2021-06-22T06:55:38.719217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Show segment of tumor for each above slice****","metadata":{}},{"cell_type":"markdown","source":"slice_n = 100\nfig, ax = plt.subplots(2, 3, figsize=(25, 15))\nax[1, 2].imshow(sample_mask[:, :, slice_n])\nax[1, 2].set_title(f\"mask slice number {slice_n}along the z-axis\", fontsize=18, color=\"green\")\nfig.tight_layout()\nplt.show()","metadata":{}},{"cell_type":"markdown","source":"slice_n = 100\nfig, ax = plt.subplots(2, 3, figsize=(25, 15))\nax[1, 2].imshow(sample_mask[:, :, slice_n])\nax[1, 2].set_title(f\"mask slice number {slice_n}along the z-axis\", fontsize=18, color=\"green\")\nfig.tight_layout()\nplt.show()","metadata":{}},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_mask[60:-60,:,:]), 90, resize=True), cmap ='gray')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T03:38:56.419232Z","iopub.execute_input":"2021-06-07T03:38:56.419584Z","iopub.status.idle":"2021-06-07T03:38:59.13414Z","shell.execute_reply.started":"2021-06-07T03:38:56.41955Z","shell.execute_reply":"2021-06-07T03:38:59.133375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Gif representation of slices in 3D volume****","metadata":{}},{"cell_type":"code","source":"shutil.copy2(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii', './test_gif_BraTS20_Training_001_flair.nii')\ngif2nif.write_gif_normal('./test_gif_BraTS20_Training_001_flair.nii')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:55:46.378585Z","iopub.execute_input":"2021-06-22T06:55:46.378898Z","iopub.status.idle":"2021-06-22T06:56:14.42183Z","shell.execute_reply.started":"2021-06-22T06:55:46.378868Z","shell.execute_reply":"2021-06-22T06:56:14.420908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*****Show segments of tumor using different effects*****","metadata":{}},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii')\n\nfig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n\nnlplt.plot_anat(niimg,\n                title='BraTS20_Training_001_flair.nii plot_anat',\n                axes=axes[0])\n\nnlplt.plot_epi(niimg,\n               title='BraTS20_Training_001_flair.nii plot_epi',\n               axes=axes[1])\n\nnlplt.plot_img(niimg,\n               title='BraTS20_Training_001_flair.nii plot_img',\n               axes=axes[2])\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:56:22.063532Z","iopub.execute_input":"2021-06-22T06:56:22.063843Z","iopub.status.idle":"2021-06-22T06:58:14.882827Z","shell.execute_reply.started":"2021-06-22T06:56:22.063815Z","shell.execute_reply":"2021-06-22T06:58:14.877455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, figsize=(20, 20))\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[0], cmap='Paired')\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[1], cmap='Paired')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:58:30.059729Z","iopub.execute_input":"2021-06-22T06:58:30.060059Z","iopub.status.idle":"2021-06-22T06:59:44.691137Z","shell.execute_reply.started":"2021-06-22T06:58:30.060028Z","shell.execute_reply":"2021-06-22T06:59:44.690222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = np.rot90(montage(sample_img))\nmask = np.rot90(montage(sample_mask)) \nmask = np.clip(mask, 0, 1)\n\nfig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.imshow(np.ma.masked_where(mask == False, mask),\n           cmap='cool', alpha=0.6, animated=True)\nax1.imshow(image, cmap ='bone')\nfig.savefig(f'{label}_3d_to_2d.png', format='png', bbox_inches='tight', pad_iches=0.0)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:59:55.347976Z","iopub.execute_input":"2021-06-22T06:59:55.348293Z","iopub.status.idle":"2021-06-22T07:00:17.300872Z","shell.execute_reply.started":"2021-06-22T06:59:55.348266Z","shell.execute_reply":"2021-06-22T07:00:17.295432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create model || U-Net: Convolutional Networks for frank sign Image Segmentation\nThe u-net is convolutional network architecture for fast and precise segmentation of images. Up to now it has outperformed the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. It has won the Grand Challenge for Computer-Automated Detection of Caries in Bitewing Radiography at ISBI 2015, and it has won the Cell Tracking Challenge at ISBI 2015 on the two most challenging transmitted light microscopy categories (Phase contrast and DIC microscopy) by a large margin more onofficial definiton.\n\n![](https://www.programmersought.com/images/339/d2f1bf1b83bc1642c5858eab3012d3f3.JPEG)","metadata":{}},{"cell_type":"markdown","source":"Loss function \n\nDice coefficient , which is essentially a measure of overlap between two samples. This measure ranges from 0 to 1 where a Dice coefficient of 1 denotes perfect and complete overlap. The Dice coefficient was originally developed for binary data, and can be calculated as:\n\n![image.png](attachment:cdb9d1c5-d136-4dfb-9556-7350f1271d30.png)\n\n\ndice loss\n\nAs matricesdice loss\n\n![image.png](attachment:eae68955-7cd6-4be3-a3d7-6ab0a19ae169.png)","metadata":{},"attachments":{"cdb9d1c5-d136-4dfb-9556-7350f1271d30.png":{"image/png":"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"},"eae68955-7cd6-4be3-a3d7-6ab0a19ae169.png":{"image/png":"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"}}},{"cell_type":"code","source":"data.shape, data.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n#    K.print_tensor(total_loss, message=' total dice coef: ')\n    return total_loss\n\n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_franksign(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_franksign_view1(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_franksign_view2(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:01:10.622224Z","iopub.execute_input":"2021-06-22T07:01:10.622571Z","iopub.status.idle":"2021-06-22T07:01:10.639619Z","shell.execute_reply.started":"2021-06-22T07:01:10.622543Z","shell.execute_reply":"2021-06-22T07:01:10.637562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DEFINE seg-areas  \nSEGMENT_CLASSES = {\n    0 : 'NORMAL SAMPLE',\n    1 : 'FRANK SIGN', # or NON-ENHANCING tumor CORE\n    2 : 'FRANK SIGN_View_1',\n    3 : 'FRANK SIGN_View_2' # original 4 -> converted into 3 later\n}\n# there are 155 slices per volume\n# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 # first slice of volume that we will include","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:01:17.17624Z","iopub.execute_input":"2021-06-22T07:01:17.176605Z","iopub.status.idle":"2021-06-22T07:01:17.180797Z","shell.execute_reply.started":"2021-06-22T07:01:17.176572Z","shell.execute_reply":"2021-06-22T07:01:17.179922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=128","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:01:22.612648Z","iopub.execute_input":"2021-06-22T07:01:22.612963Z","iopub.status.idle":"2021-06-22T07:01:22.619105Z","shell.execute_reply.started":"2021-06-22T07:01:22.612933Z","shell.execute_reply":"2021-06-22T07:01:22.618277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n\ndef build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    return Model(inputs = inputs, outputs = conv10)\n\ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(input_layer, 'he_normal', 0.2)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_franksign, dice_coef_franksign_view1, dice_coef_franksign_view2] )","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:01:38.759686Z","iopub.execute_input":"2021-06-22T07:01:38.760051Z","iopub.status.idle":"2021-06-22T07:01:38.984314Z","shell.execute_reply.started":"2021-06-22T07:01:38.760018Z","shell.execute_reply":"2021-06-22T07:01:38.983527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Model Architecture****\nIf you are about to use U-NET, check out this awesome library, after manual implementation of U-NET keras-unet-collection, which also contains implementation of dice loss, tversky loss and many more!","metadata":{}},{"cell_type":"code","source":"plot_model(model, \n           show_shapes = True,\n           show_dtype=False,\n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 70)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:01:45.130336Z","iopub.execute_input":"2021-06-22T07:01:45.130658Z","iopub.status.idle":"2021-06-22T07:01:45.623989Z","shell.execute_reply.started":"2021-06-22T07:01:45.130631Z","shell.execute_reply":"2021-06-22T07:01:45.623099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"******Load data******\nLoading all data into memory is not a good idea since the data are too big to fit in. So we will create dataGenerators - load data on the fly. ","metadata":{}},{"cell_type":"code","source":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); \n\ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:01:52.998794Z","iopub.execute_input":"2021-06-22T07:01:52.999121Z","iopub.status.idle":"2021-06-22T07:01:53.014131Z","shell.execute_reply.started":"2021-06-22T07:01:52.99909Z","shell.execute_reply":"2021-06-22T07:01:53.013329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Override Keras sequence DataGenerator class****","metadata":{}},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n        \n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(VOLUME_SLICES):\n                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:02:07.090968Z","iopub.execute_input":"2021-06-22T07:02:07.09128Z","iopub.status.idle":"2021-06-22T07:02:07.10594Z","shell.execute_reply.started":"2021-06-22T07:02:07.091251Z","shell.execute_reply":"2021-06-22T07:02:07.105138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"****Number of data used for training / testing / validation****","metadata":{}},{"cell_type":"code","source":"# show number of data for each dir \ndef showDataLayout():\n    plt.bar([\"Train\",\"Valid\",\"Test\"],\n    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n    plt.legend()\n    plt.ylabel('Number of images')\n    plt.title('Data distribution')\n\n    plt.show()\n    \nshowDataLayout()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:02:16.893661Z","iopub.execute_input":"2021-06-22T07:02:16.893982Z","iopub.status.idle":"2021-06-22T07:02:17.007924Z","shell.execute_reply.started":"2021-06-22T07:02:16.893952Z","shell.execute_reply":"2021-06-22T07:02:17.006953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Add callback for training process**","metadata":{}},{"cell_type":"code","source":"csv_logger = CSVLogger('training.log', separator=',', append=False)\n\ncallbacks = [\n#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n#                               patience=2, verbose=1, mode='auto'),\n      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.000001, verbose=1),\n#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n#                             verbose=1, save_best_only=True, save_weights_only = True)\n        csv_logger\n    ]","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:02:23.08684Z","iopub.execute_input":"2021-06-22T07:02:23.087168Z","iopub.status.idle":"2021-06-22T07:02:23.091625Z","shell.execute_reply.started":"2021-06-22T07:02:23.087137Z","shell.execute_reply":"2021-06-22T07:02:23.090745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\n\n# history =  model.fit(training_generator,\n#                     epochs=35,\n#                     steps_per_epoch=len(train_ids),\n#                     callbacks= callbacks,\n#                     validation_data = valid_generator\n#                     )  \n# model.save(\"model_x1_1.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:02:29.611617Z","iopub.execute_input":"2021-06-22T07:02:29.611934Z","iopub.status.idle":"2021-06-22T07:02:29.619371Z","shell.execute_reply.started":"2021-06-22T07:02:29.611905Z","shell.execute_reply":"2021-06-22T07:02:29.618503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coef_franksign(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_franksign_view1(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_franksign_view2(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:02:41.51103Z","iopub.execute_input":"2021-06-22T07:02:41.511366Z","iopub.status.idle":"2021-06-22T07:02:41.520484Z","shell.execute_reply.started":"2021-06-22T07:02:41.511334Z","shell.execute_reply":"2021-06-22T07:02:41.519561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ load trained model ################\nmodel = keras.models.load_model('../input/datasources/Data Sources/model-per-class-eval/model_per_class.h5',  \n                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n                                                   \"dice_coef\": dice_coef,\n                                                   \"precision\": precision,\n                                                   \"sensitivity\":sensitivity,\n                                                   \"specificity\":specificity,\n                                                   \"dice_coef_franksign\": dice_coef_franksign,\n                                                   \"dice_coef_franksign_view1\": dice_coef_franksign_view1,\n                                                   \"dice_coef_franksign_view2\": dice_coef_franksign_view2\n                                                  }, compile=False)\n\nhistory = pd.read_csv('../input/datasources/Data Sources/model-per-class-eval/training_per_class.log', sep=',', engine='python')\n\nhist=history\n\n############### ########## ####### #######\n\n# hist=history.history\n\nacc=hist['accuracy']\nval_acc=hist['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=hist['loss']\nval_loss=hist['val_loss']\n\ntrain_dice=hist['dice_coef']\nval_dice=hist['val_dice_coef']\n\nf,ax=plt.subplots(1,4,figsize=(16,8))\n\nax[0].plot(epoch,acc,'b',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'b',label='Training Loss')\nax[1].plot(epoch,val_loss,'r',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'b',label='Training dice coef')\nax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\nax[2].legend()\n\nax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\nax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\nax[3].legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:02:49.11298Z","iopub.execute_input":"2021-06-22T07:02:49.113423Z","iopub.status.idle":"2021-06-22T07:02:51.545482Z","shell.execute_reply.started":"2021-06-22T07:02:49.11338Z","shell.execute_reply":"2021-06-22T07:02:51.544652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n# returns volume of specified study at `path`\ndef imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n    for j in range(VOLUME_SLICES):\n        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n    return np.array(image)\n# Hint note down \n# load nifti file at `path`\n# and load each slice with mask from volume\n# choose the mri type & resize to `IMG_SIZE`\ndef loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')   \n#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:03:07.445213Z","iopub.execute_input":"2021-06-22T07:03:07.445565Z","iopub.status.idle":"2021-06-22T07:03:07.456231Z","shell.execute_reply.started":"2021-06-22T07:03:07.445534Z","shell.execute_reply":"2021-06-22T07:03:07.455415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install imutils","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:31:25.237435Z","iopub.execute_input":"2021-06-07T05:31:25.237841Z","iopub.status.idle":"2021-06-07T05:31:32.757188Z","shell.execute_reply.started":"2021-06-07T05:31:25.237801Z","shell.execute_reply":"2021-06-07T05:31:32.756193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import ndimage, misc\nimport matplotlib.pyplot as plt\nimport cv2  \n\n\ndef predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\ndef showPredictsById(case, start_slice = 60):\n    path = f\"../input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    franksign_view1 = p[:,:,:,1]\n    franksign = p[:,:,:,2]\n    franksign_view2 = p[:,:,:,3]\n\n    plt.figure(figsize=(50, 50))\n    f, axarr = plt.subplots(1,8, figsize = (30, 80)) \n    slice_n = 100\n    for i in range(8): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n        \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    \n    axarr[1].imshow(origImage[:,:,start_slice+VOLUME_START_AT])\n    axarr[1].title.set_text('Rotated image')\n    \n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[2].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[2].title.set_text('Ground truth')\n    \n    axarr[3].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text('all classes') \n    \n    full_img_45 = ndimage.rotate(franksign[start_slice,:,:], 90, mode = 'mirror')\n    axarr[4].imshow(full_img_45, cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n        \n    axarr[5].imshow(franksign_view1[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    \n    axarr[6].imshow(franksign_view1[:, :, slice_n])\n    axarr[6].title.set_text('Predicted Frank Sign')\n    \n    axarr[7].imshow(franksign_view2[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[7].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    \n    fig.tight_layout()\n    plt.show()\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\n\n# mask = np.zeros((10,10))\n# mask[3:-3, 3:-3] = 1 # white square in black background\n# im = mask + np.random.randn(10,10) * 0.01 # random image\n# masked = np.ma.masked_where(mask == 0, mask)\n\n# plt.figure()\n# plt.subplot(1,2,1)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.subplot(1,2,2)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:03:46.899184Z","iopub.execute_input":"2021-06-22T07:03:46.899544Z","iopub.status.idle":"2021-06-22T07:04:29.357236Z","shell.execute_reply.started":"2021-06-22T07:03:46.899513Z","shell.execute_reply":"2021-06-22T07:04:29.356368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  axarr[3].imshow(gt[:, :, slice_n])\n    axarr[3].title.set_text('Ground Frank Sign')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\ndef showPredictsById(case, start_slice = 60):\n    path = f\"../input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    franksign_view1 = p[:,:,:,1]\n    franksign = p[:,:,:,2]\n    franksign_view2 = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n\n    for i in range(6): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n        \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes')\n    axarr[3].imshow(franksign[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(franksign_view1[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(franksign_view2[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.show()\n    \n    \n    \n    \n     \nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[0][-3:])\n\n# mask = np.zeros((10,10))\n# mask[3:-3, 3:-3] = 1 # white square in black background\n# im = mask + np.random.randn(10,10) * 0.01 # random image\n# masked = np.ma.masked_where(mask == 0, mask)\n\n# plt.figure()\n# plt.subplot(1,2,1)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.subplot(1,2,2)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:04:49.924624Z","iopub.execute_input":"2021-06-22T07:04:49.924967Z","iopub.status.idle":"2021-06-22T07:05:16.443998Z","shell.execute_reply.started":"2021-06-22T07:04:49.924934Z","shell.execute_reply":"2021-06-22T07:05:16.443211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n #      y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\ndef showPredictsById(case, start_slice = 100):\n    path = f\"../input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n    \n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n    fig, axes = plt.subplots(nrows=2, figsize=(10, 10))\n    niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\n    for i in range(6): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n        \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    Print(''+p)\n    nlplt.plot_roi(curr_gt, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[0], cmap='Paired')\n    nlplt.plot_roi(p[start_slice,:,:,1:4],\n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[1], cmap='Paired')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes')\n    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.show()\n    \n    \nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[1][-3:])\nshowPredictsById(case=test_ids[2][-3:])\nshowPredictsById(case=test_ids[3][-3:])\nshowPredictsById(case=test_ids[4][-3:])\nshowPredictsById(case=test_ids[5][-3:])\nshowPredictsById(case=test_ids[6][-3:])\n\n\n# mask = np.zeros((10,10))\n# mask[3:-3, 3:-3] = 1 # white square in black background\n# im = mask + np.random.randn(10,10) * 0.01 # random image\n# masked = np.ma.masked_where(mask == 0, mask)\n\n# plt.figure()\n# plt.subplot(1,2,1)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.subplot(1,2,2)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:08:15.798033Z","iopub.execute_input":"2021-06-22T07:08:15.798371Z","iopub.status.idle":"2021-06-22T07:08:19.90821Z","shell.execute_reply.started":"2021-06-22T07:08:15.79834Z","shell.execute_reply":"2021-06-22T07:08:19.906333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, figsize=(10, 10))\nniimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\n\n\nnlplt.plot_roi(p, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[0], cmap='Paired')\nnlplt.plot_roi(p, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[1], cmap='Paired')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:08:32.293842Z","iopub.execute_input":"2021-06-22T07:08:32.294156Z","iopub.status.idle":"2021-06-22T07:08:32.513685Z","shell.execute_reply.started":"2021-06-22T07:08:32.294126Z","shell.execute_reply":"2021-06-22T07:08:32.512471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Evalaution****","metadata":{}},{"cell_type":"code","source":"case = case=test_ids[1][-3:]\npath = f\"../input/datasources/Data Sources/BraTS2020 Dataset (Training + Validation)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\ngt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\np = predictByPath(path,case)\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\n\ni=40 # slice at\neval_class = 2 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n\n\n\ngt[gt != eval_class] = 1 # use only one class for per class evaluation \n\nresized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\nfig, axes = plt.subplots(nrows=2, figsize=(10, 10))\nniimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\n\nnlplt.plot_roi(p[i,:,:,eval_class], \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[0], cmap='Paired')\n    nlplt.plot_roi(p[i,:,:,eval_class],\n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[1], cmap='Paired')\n    \nplt.figure()\nf, axarr = plt.subplots(1,2) \naxarr[0].imshow(resized_gt, cmap=\"gray\")\naxarr[0].title.set_text('ground truth')\naxarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\naxarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:08:58.040471Z","iopub.execute_input":"2021-06-22T07:08:58.040786Z","iopub.status.idle":"2021-06-22T07:08:58.052276Z","shell.execute_reply.started":"2021-06-22T07:08:58.040757Z","shell.execute_reply":"2021-06-22T07:08:58.05094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\nprint(\"test loss, test acc:\", results)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T06:57:38.64455Z","iopub.execute_input":"2021-06-03T06:57:38.64489Z","iopub.status.idle":"2021-06-03T06:57:38.664222Z","shell.execute_reply.started":"2021-06-03T06:57:38.644857Z","shell.execute_reply":"2021-06-03T06:57:38.663405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \"\"\" Visualization of 3d data in 2d slices \"\"\" \n\nslice_n = 100\nfig, ax = plt.subplots(2, 3, figsize=(25, 15))\n\nax[0, 0].imshow(sample_img[slice_n, :, :])\nax[0, 0].set_title(f\"image slice number {slice_n} along the x-axis\", fontsize=18, color=\"red\")\nax[1, 0].imshow(sample_mask[slice_n, :, :])\nax[1, 0].set_title(f\"mask slice {slice_n} along the x-axis\", fontsize=18, color=\"red\")\n\nax[0, 1].imshow(sample_img[:, slice_n, :])\nax[0, 1].set_title(f\"image slice number {slice_n} along the y-axis\", fontsize=18, color=\"red\")\nax[1, 1].imshow(sample_mask[:, slice_n, :])\nax[1, 1].set_title(f\"mask slice number {slice_n} along the y-axis\", fontsize=18, color=\"red\")\n\nax[0, 2].imshow(sample_img[:, :, slice_n])\nax[0, 2].set_title(f\"image slice number {slice_n} along the z-axis\", fontsize=18, color=\"red\")\nax[1, 2].imshow(sample_mask[:, :, slice_n])\nax[1, 2].set_title(f\"mask slice number {slice_n}along the z-axis\", fontsize=18, color=\"red\")\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:09:07.41403Z","iopub.execute_input":"2021-06-22T07:09:07.414366Z","iopub.status.idle":"2021-06-22T07:09:08.439189Z","shell.execute_reply.started":"2021-06-22T07:09:07.414332Z","shell.execute_reply":"2021-06-22T07:09:08.43823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_009/BraTS20_Training_009_flair.nii')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_009/BraTS20_Training_009_seg.nii')\n\nnlplt.plot_anat(niimg,\n                title='BraTS20_Training_009_flair.nii plot_anat',\n                axes=axes[0])\n\nnlplt.plot_epi(niimg,\n               title='BraTS20_Training_009_flair.nii plot_epi',\n               axes=axes[1])\n\nnlplt.plot_img(niimg,\n               title='BraTS20_Training_009_flair.nii plot_img',\n               axes=axes[2])\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_009_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:42:49.87964Z","iopub.execute_input":"2021-06-07T09:42:49.879979Z","iopub.status.idle":"2021-06-07T09:43:37.907607Z","shell.execute_reply.started":"2021-06-07T09:42:49.879949Z","shell.execute_reply":"2021-06-07T09:43:37.906127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_005/BraTS20_Training_005_flair.nii')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_005/BraTS20_Training_005_seg.nii')\n\nfig, axes = plt.subplots(nrows=2, figsize=(30, 40))\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_005_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[0], cmap='Paired')\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_005_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[0], cmap='Paired')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T07:09:16.765807Z","iopub.execute_input":"2021-06-22T07:09:16.766126Z","iopub.status.idle":"2021-06-22T07:10:36.519202Z","shell.execute_reply.started":"2021-06-22T07:09:16.766096Z","shell.execute_reply":"2021-06-22T07:10:36.518259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}