{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hypothesis test \n#university towns data cleaning\nuni = pd.read_table('../input/zillow-all-homes-data/university_towns.txt',header = None, names = ['name'])\nuni.name = uni.name.str.split('(',expand = True)[0]\nmask = uni.name.str.contains('edit')\nindex = mask[mask == True].index\nstate = []\nfor i in uni.index:\n    if i in index:\n        state.append(uni.loc[i]['name'])\n    if i not in index:\n        state.append(state[i-1])\nuni['state'] = state\nuni.drop(index, inplace = True)\nuni.state = uni.state.str.split('[', expand = True)[0]\nuni = uni.rename(columns = {'name':'RegionName', 'state':'State'})\nuni['RegionName'] = uni.RegionName.apply(lambda x: x.strip())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drive recession period after 2000\ngdp = pd.read_excel('../input/zillow-all-homes-data/gdplev.xls', skiprows = [0,1,2,3,4,5,6,7],header = None, \n                    usecols = [4,5], names = ['date','gdp'])\ngdp = gdp.iloc[gdp[gdp['date'] == '2000q1'].index[0]:]\n#find recession start\nfor i in range(len(gdp)-3):\n    if gdp.iloc[i][1]<gdp.iloc[i+1][1] and gdp.iloc[i+1][1]>gdp.iloc[i+2][1] and gdp.iloc[i+2][1]>gdp.iloc[i+3][1]:\n        recession_start = gdp.iloc[i+1][0]\ngdp = gdp.reset_index().set_index('date').drop('index', axis = 1)\n#find recession bottom and recession end \nloca = recession_start[0]\nfor i in range(len(gdp)-4):\n    if gdp.iloc[i][0]>gdp.iloc[i+1][0] and gdp.iloc[i+1][0]>gdp.iloc[i+2][0] and gdp.iloc[i+2][0]<gdp.iloc[i+3][0] and gdp.iloc[i+3][0]<gdp.iloc[i+4][0]:\n        recession_bottom  = gdp.iloc[i+2].name\n        recession_end = gdp.iloc[i+4].name\nprint(recession_start, recession_bottom, recession_end)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#housing data\nhousing = pd.read_csv('../input/zillow-all-homes-data/City_Zhvi_AllHomes.csv')\nhousing = housing.set_index(['State','RegionName']).drop(['RegionID','CountyName','Metro','SizeRank'], axis = 1)\nhousing = housing.T\nhousing.index = pd.to_datetime(housing.index, format = '%Y/%m')\nhousing = housing['2000':]\n#change the date into quarter format\nhousing = housing.resample('q',label = 'right',closed = 'left').mean()\nhousing.index = housing.index.strftime('%Y')\nquarter = []\nfor i in range(len(housing)):\n    if i%4 == 0:\n        quarter.append('q1')\n    if i%4 == 1:\n        quarter.append('q2')\n    if i%4 == 2:\n        quarter.append('q3')\n    if i%4 == 3:\n        quarter.append('q4')\nhousing.index = housing.index+quarter\nhousing = housing.T\n#map state into full name\nhousing = housing.reset_index()\nstates = {\n        'AK': 'Alaska',\n        'AL': 'Alabama',\n        'AR': 'Arkansas',\n        'AS': 'American Samoa',\n        'AZ': 'Arizona',\n        'CA': 'California',\n        'CO': 'Colorado',\n        'CT': 'Connecticut',\n        'DC': 'District of Columbia',\n        'DE': 'Delaware',\n        'FL': 'Florida',\n        'GA': 'Georgia',\n        'GU': 'Guam',\n        'HI': 'Hawaii',\n        'IA': 'Iowa',\n        'ID': 'Idaho',\n        'IL': 'Illinois',\n        'IN': 'Indiana',\n        'KS': 'Kansas',\n        'KY': 'Kentucky',\n        'LA': 'Louisiana',\n        'MA': 'Massachusetts',\n        'MD': 'Maryland',\n        'ME': 'Maine',\n        'MI': 'Michigan',\n        'MN': 'Minnesota',\n        'MO': 'Missouri',\n        'MP': 'Northern Mariana Islands',\n        'MS': 'Mississippi',\n        'MT': 'Montana',\n        'NA': 'National',\n        'NC': 'North Carolina',\n        'ND': 'North Dakota',\n        'NE': 'Nebraska',\n        'NH': 'New Hampshire',\n        'NJ': 'New Jersey',\n        'NM': 'New Mexico',\n        'NV': 'Nevada',\n        'NY': 'New York',\n        'OH': 'Ohio',\n        'OK': 'Oklahoma',\n        'OR': 'Oregon',\n        'PA': 'Pennsylvania',\n        'PR': 'Puerto Rico',\n        'RI': 'Rhode Island',\n        'SC': 'South Carolina',\n        'SD': 'South Dakota',\n        'TN': 'Tennessee',\n        'TX': 'Texas',\n        'UT': 'Utah',\n        'VA': 'Virginia',\n        'VI': 'Virgin Islands',\n        'VT': 'Vermont',\n        'WA': 'Washington',\n        'WI': 'Wisconsin',\n        'WV': 'West Virginia',\n        'WY': 'Wyoming'\n}\ndef mapping(state):\n    for i in states.keys():\n        if state == i:\n            state = states[i]\n            return state\nhousing['State'] = housing.State.apply(mapping)\nhousing.head()\n#split housing data into university town and non-university_town\nuni_housing = pd.merge(uni, housing, right_on = ['State', 'RegionName'], left_on=['State','RegionName'], how = 'inner')\nto_be_dropped = uni_housing.set_index(['State','RegionName']).index\nuni_housing = uni_housing.set_index(['State','RegionName'])\nnon_uni_housing = housing.set_index(['State','RegionName']).drop(to_be_dropped)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get data in recession period\ncols_to_keep = [recession_start, recession_bottom]\nuni_housing_re = uni_housing[cols_to_keep]\nnon_uni_housing_re = non_uni_housing[cols_to_keep]\nuni_housing_re['diff'] = uni_housing_re[recession_start] - uni_housing_re[recession_bottom]\nuni_housing_re = uni_housing_re.dropna()\nnon_uni_housing_re = non_uni_housing_re.dropna()\nnon_uni_housing_re['diff'] = non_uni_housing_re[recession_start] - non_uni_housing_re[recession_bottom]\nuni_housing_re.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#T test between university town housing data and non-university housing data during recession period, \n#if p value is larger than 0.05, then means of both have no difference\nimport scipy.stats as stats\np = stats.ttest_ind(uni_housing_re['diff'], non_uni_housing_re['diff']).pvalue\nt = stats.ttest_ind(uni_housing_re['diff'], non_uni_housing_re['diff']).statistic\nprint(t,p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}