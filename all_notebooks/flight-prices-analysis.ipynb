{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain_data = pd.read_csv('../input/flight-prices/Data_Train.csv')\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.544021Z","iopub.execute_input":"2021-06-06T09:32:49.5444Z","iopub.status.idle":"2021-06-06T09:32:49.59805Z","shell.execute_reply.started":"2021-06-06T09:32:49.544366Z","shell.execute_reply":"2021-06-06T09:32:49.596734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to find all missing values in a column\ntrain_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.600384Z","iopub.execute_input":"2021-06-06T09:32:49.600722Z","iopub.status.idle":"2021-06-06T09:32:49.621125Z","shell.execute_reply.started":"2021-06-06T09:32:49.600676Z","shell.execute_reply":"2021-06-06T09:32:49.619659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.622778Z","iopub.execute_input":"2021-06-06T09:32:49.623515Z","iopub.status.idle":"2021-06-06T09:32:49.631177Z","shell.execute_reply.started":"2021-06-06T09:32:49.623475Z","shell.execute_reply":"2021-06-06T09:32:49.629837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop missing values\ntrain_data.dropna(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.632526Z","iopub.execute_input":"2021-06-06T09:32:49.632916Z","iopub.status.idle":"2021-06-06T09:32:49.673722Z","shell.execute_reply.started":"2021-06-06T09:32:49.632886Z","shell.execute_reply":"2021-06-06T09:32:49.672799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.67641Z","iopub.execute_input":"2021-06-06T09:32:49.676961Z","iopub.status.idle":"2021-06-06T09:32:49.694914Z","shell.execute_reply.started":"2021-06-06T09:32:49.676924Z","shell.execute_reply":"2021-06-06T09:32:49.694109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data type of each column\ntrain_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.697585Z","iopub.execute_input":"2021-06-06T09:32:49.698123Z","iopub.status.idle":"2021-06-06T09:32:49.710876Z","shell.execute_reply.started":"2021-06-06T09:32:49.69808Z","shell.execute_reply":"2021-06-06T09:32:49.709938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to change datatype to datetime format\ndef change_into_datetime(col):\n    train_data[col] = pd.to_datetime(train_data[col])\n\n# these three columns have dates so need to be changed\nfor i in ['Date_of_Journey','Dep_Time','Arrival_Time']:\n    change_into_datetime(i)\n    \ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.712213Z","iopub.execute_input":"2021-06-06T09:32:49.712799Z","iopub.status.idle":"2021-06-06T09:32:49.864466Z","shell.execute_reply.started":"2021-06-06T09:32:49.712744Z","shell.execute_reply":"2021-06-06T09:32:49.862951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to access day of journey and add a column for that\ntrain_data['Journey_day'] = train_data['Date_of_Journey'].dt.day\n\n#to access month of journey and add a column for that\ntrain_data['Journey_month'] = train_data['Date_of_Journey'].dt.month\n\ntrain_data.drop('Date_of_Journey',axis=1, inplace=True)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.866002Z","iopub.execute_input":"2021-06-06T09:32:49.866313Z","iopub.status.idle":"2021-06-06T09:32:49.894132Z","shell.execute_reply.started":"2021-06-06T09:32:49.866285Z","shell.execute_reply":"2021-06-06T09:32:49.893052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the hour part of the timestamp and make column\ndef extract_hour(df, col):\n    df[col+'_hour'] = df[col].dt.hour\n\n# Get the minute part of the timestamp and make column    \ndef extract_minute(df, col):\n    df[col+'_minute'] = df[col].dt.minute\n\n# drop column    \ndef drop_column(df, col):\n    df.drop(col, axis=1, inplace = True)\n    \n# apply above functions to departure and arrival time columns\nfor i in ['Dep_Time','Arrival_Time']:\n    extract_hour(train_data,i)\n    extract_minute(train_data,i)\n    drop_column(train_data, i)\n    \ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.895901Z","iopub.execute_input":"2021-06-06T09:32:49.89622Z","iopub.status.idle":"2021-06-06T09:32:49.933678Z","shell.execute_reply.started":"2021-06-06T09:32:49.896191Z","shell.execute_reply":"2021-06-06T09:32:49.931361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making list of the column entries\nduration = list(train_data['Duration'])\n\n# to split duration into hour and min, and make each entry as 'x'h 'y'm (0h 'y'm or 'x'h 0m if any one of the two isnt written)\nx = '2h 50m'\nx.split()\nprint(len(x.split()))\n\nfor i in range(len(duration)):\n    if len(duration[i].split(' ')) == 2:\n        pass\n    else:\n        if 'h' in duration[i]:\n            duration[i] = duration[i] + ' 0m'\n        else:\n            duration[i] = '0h '+ duration[i]\n            \ntrain_data['Duration'] = duration # updatng duration column with updated list\ntrain_data.tail()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.935166Z","iopub.execute_input":"2021-06-06T09:32:49.935503Z","iopub.status.idle":"2021-06-06T09:32:49.971289Z","shell.execute_reply.started":"2021-06-06T09:32:49.93547Z","shell.execute_reply":"2021-06-06T09:32:49.969912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('2h 50m'.split(' ')[1][0:-1]) #extract hour and minute part \n\ndef hour(x):\n    return x.split(' ')[0][0:-1]\n\ndef minute(x):\n    return x.split(' ')[1][0:-1]\n\ntrain_data['Duration_hours'] = train_data['Duration'].apply(hour) # make columns\ntrain_data['Duration_minutes'] = train_data['Duration'].apply(minute)\n\ndrop_column(train_data, 'Duration') # drop duration column\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:49.97289Z","iopub.execute_input":"2021-06-06T09:32:49.973213Z","iopub.status.idle":"2021-06-06T09:32:50.020759Z","shell.execute_reply.started":"2021-06-06T09:32:49.973185Z","shell.execute_reply":"2021-06-06T09:32:50.019925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['Duration_hours'] = train_data['Duration_hours'].astype(int) # converting duration hour and minute column types \ntrain_data['Duration_minutes'] = train_data['Duration_minutes'].astype(int) # to int\n\nobject_cols = [] # finding categorical and numerical data columns\nnumeric_cols = []\nfor col in train_data.columns:\n    if train_data[col].dtype == 'object':\n        object_cols.append(col)\n    elif train_data[col].dtype != 'object':\n        numeric_cols.append(col)\n        \nprint(train_data.dtypes)\nprint(object_cols)\nprint(numeric_cols)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:50.022003Z","iopub.execute_input":"2021-06-06T09:32:50.022305Z","iopub.status.idle":"2021-06-06T09:32:50.037974Z","shell.execute_reply.started":"2021-06-06T09:32:50.022265Z","shell.execute_reply":"2021-06-06T09:32:50.037036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical = train_data[object_cols] #dataframe for all categoorical columns\ncategorical.head()\nprint(train_data['Airline'].value_counts()) # to find number of rows for each airline\n\nplt.figure(figsize = (15,15)) #boxplot with seaborn (sns) for prices for different airlines, descending order\nsns.boxplot(x = 'Airline', y = 'Price', data = train_data.sort_values('Price',ascending = False))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:50.039514Z","iopub.execute_input":"2021-06-06T09:32:50.039887Z","iopub.status.idle":"2021-06-06T09:32:50.497856Z","shell.execute_reply.started":"2021-06-06T09:32:50.039856Z","shell.execute_reply":"2021-06-06T09:32:50.496518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,15)) # boxplot for total stops varying with price in dec. order\nsns.boxplot(x = 'Total_Stops', y = 'Price', data = train_data.sort_values('Price',ascending = False))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:50.499593Z","iopub.execute_input":"2021-06-06T09:32:50.500016Z","iopub.status.idle":"2021-06-06T09:32:50.765595Z","shell.execute_reply.started":"2021-06-06T09:32:50.499974Z","shell.execute_reply":"2021-06-06T09:32:50.764784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Airline = pd.get_dummies(categorical['Airline'],drop_first = True) # one hot enccoding for airline\nAirline.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:50.766825Z","iopub.execute_input":"2021-06-06T09:32:50.767211Z","iopub.status.idle":"2021-06-06T09:32:50.7858Z","shell.execute_reply.started":"2021-06-06T09:32:50.76718Z","shell.execute_reply":"2021-06-06T09:32:50.784781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(categorical['Source'].value_counts())\n\nplt.figure(figsize = (15,15)) # boxplot for source locations varying with price in dec. order\nsns.boxplot(x = 'Source', y = 'Price', data = train_data.sort_values('Price',ascending = False))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:50.787064Z","iopub.execute_input":"2021-06-06T09:32:50.78738Z","iopub.status.idle":"2021-06-06T09:32:51.056768Z","shell.execute_reply.started":"2021-06-06T09:32:50.78735Z","shell.execute_reply":"2021-06-06T09:32:51.055587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Source = pd.get_dummies(categorical['Source'],drop_first = True) # one hot encoding for source\nSource.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:51.05967Z","iopub.execute_input":"2021-06-06T09:32:51.06017Z","iopub.status.idle":"2021-06-06T09:32:51.07479Z","shell.execute_reply.started":"2021-06-06T09:32:51.060127Z","shell.execute_reply":"2021-06-06T09:32:51.073618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(categorical['Destination'].value_counts())\n\nplt.figure(figsize = (15,15)) # boxplot for destination locations varying with price in dec. order\nsns.boxplot(x = 'Destination', y = 'Price', data = train_data.sort_values('Price',ascending = False))\n\nDestination = pd.get_dummies(categorical['Destination'],drop_first = True) # one hot enccoding for destination\nDestination.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:51.077793Z","iopub.execute_input":"2021-06-06T09:32:51.078307Z","iopub.status.idle":"2021-06-06T09:32:51.39592Z","shell.execute_reply.started":"2021-06-06T09:32:51.078274Z","shell.execute_reply":"2021-06-06T09:32:51.394394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to split the route into locations through '→' and make each stop into a column\ncategorical['Route_1'] = categorical['Route'].str.split('→').str[0]\ncategorical['Route_2'] = categorical['Route'].str.split('→').str[1]\ncategorical['Route_3'] = categorical['Route'].str.split('→').str[2]\ncategorical['Route_4'] = categorical['Route'].str.split('→').str[3]\ncategorical['Route_5'] = categorical['Route'].str.split('→').str[4]\ndrop_column(categorical,'Route') # dropping route column\ncategorical.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:51.397623Z","iopub.execute_input":"2021-06-06T09:32:51.397984Z","iopub.status.idle":"2021-06-06T09:32:51.729035Z","shell.execute_reply.started":"2021-06-06T09:32:51.39795Z","shell.execute_reply":"2021-06-06T09:32:51.727861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(categorical.isnull().sum()) # to find all missing values per column for categorical\nprint('\\n')\n\nfor i in ['Route_3', 'Route_4', 'Route_5']:\n    categorical[i].fillna('None',inplace = True) # replacing those missing values with 'None'\n    \nprint(categorical.columns)\nprint('\\n')\n\nfor i in categorical.columns:\n    print('{} has total {} categories'.format(i,len(categorical[i].value_counts()))) # showing number of categories for each \n                                                                                        #categorical column","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:51.73085Z","iopub.execute_input":"2021-06-06T09:32:51.731292Z","iopub.status.idle":"2021-06-06T09:32:51.798805Z","shell.execute_reply.started":"2021-06-06T09:32:51.731246Z","shell.execute_reply":"2021-06-06T09:32:51.797657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder # to label encode the route columns\nencoder = LabelEncoder()\nfor i in ['Route_1', 'Route_2', 'Route_3', 'Route_4', 'Route_5']:\n    categorical[i] = encoder.fit_transform(categorical[i])\n    \n\nprint(categorical['Additional_Info'].value_counts())\ndrop_column(categorical,'Additional_Info')\ncategorical.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:51.800775Z","iopub.execute_input":"2021-06-06T09:32:51.80109Z","iopub.status.idle":"2021-06-06T09:32:52.01572Z","shell.execute_reply.started":"2021-06-06T09:32:51.80106Z","shell.execute_reply":"2021-06-06T09:32:52.014829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical['Total_Stops'].unique()\ndict = {'non-stop':0, '2 stops':2, '1 stop':1, '3 stops':3, '4 stops':4} # to assign integer for each category of total stops \n                                                                            #column as per number of stops through dictionary\ncategorical['Total_Stops'] = categorical['Total_Stops'].map(dict) #mapping the dict to the column\ncategorical.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:52.016932Z","iopub.execute_input":"2021-06-06T09:32:52.017381Z","iopub.status.idle":"2021-06-06T09:32:52.041258Z","shell.execute_reply.started":"2021-06-06T09:32:52.017346Z","shell.execute_reply":"2021-06-06T09:32:52.040289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.concat([categorical,Airline,Source,Destination,train_data[numeric_cols]],axis=1)\n# to concatenate the categorical columns with numerical columns and the onehot encoded columns, and then dropping original\n\ndrop_column(data_train,'Airline')\ndrop_column(data_train,'Source')\ndrop_column(data_train,'Destination')\npd.set_option('display.max_columns',35) #setting limit of columns displayed\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:52.042472Z","iopub.execute_input":"2021-06-06T09:32:52.042801Z","iopub.status.idle":"2021-06-06T09:32:52.08294Z","shell.execute_reply.started":"2021-06-06T09:32:52.042768Z","shell.execute_reply":"2021-06-06T09:32:52.081543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(df, col): # to make distribution and boxplots for price column to find outliers\n    fig,(ax1,ax2) = plt.subplots(2,1)\n    sns.distplot(df[col],ax = ax1)\n    sns.boxplot(df[col],ax = ax2)\n    \nplot(data_train,'Price')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:52.084606Z","iopub.execute_input":"2021-06-06T09:32:52.084965Z","iopub.status.idle":"2021-06-06T09:32:52.548253Z","shell.execute_reply.started":"2021-06-06T09:32:52.084933Z","shell.execute_reply":"2021-06-06T09:32:52.546879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['Price'] = np.where(data_train['Price']>=40000,data_train['Price'].median(),data_train['Price'])\n# replacing outliers with the median (2nd argument), here outliers are where price goes beyond 40000 (1st argument)\n# if price is under 40000, then no change (3rd argument) \nplot(data_train,'Price')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:52.549787Z","iopub.execute_input":"2021-06-06T09:32:52.550184Z","iopub.status.idle":"2021-06-06T09:32:53.026521Z","shell.execute_reply.started":"2021-06-06T09:32:52.550143Z","shell.execute_reply":"2021-06-06T09:32:53.02527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Selecting independent and dependent features\nX = data_train.drop('Price',axis=1)\nY = data_train['Price']\n\nY.head()\nfrom sklearn.feature_selection import mutual_info_classif # to find dependency between feature matrix (X) and dependent var (y)\nmutual_info_classif(X, Y)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:32:53.027837Z","iopub.execute_input":"2021-06-06T09:32:53.028107Z","iopub.status.idle":"2021-06-06T09:33:19.589523Z","shell.execute_reply.started":"2021-06-06T09:32:53.02808Z","shell.execute_reply":"2021-06-06T09:33:19.588536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp = pd.DataFrame(mutual_info_classif(X, Y),index = X.columns) # to make dataframe for dependency pertaining to each feature\nimp.columns = ['Importance']\nimp.sort_values(by = 'Importance',ascending = False)\n# in output, top 3-4 features have highest dependency with price, so they shall only be used for machine learning model","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:33:19.591117Z","iopub.execute_input":"2021-06-06T09:33:19.591435Z","iopub.status.idle":"2021-06-06T09:33:46.206731Z","shell.execute_reply.started":"2021-06-06T09:33:19.591404Z","shell.execute_reply":"2021-06-06T09:33:46.205735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2) # split into training and test sets\n\ndef predict (ml_model, dump): # method to use for any machine learning model to fit the data, make predictions, and give scores\n    model = ml_model.fit(X_train, Y_train)\n    print('Training score: {}'.format(model.score(X_train, Y_train)))\n    predictions = model.predict(X_test)\n    print('Predictions are {}'.format(predictions))\n    print('\\n')\n    r2score = metrics.r2_score(Y_test, predictions)\n    print('R2 score is {}'.format(r2score))\n    \n    print('MAE: ',metrics.mean_absolute_error(Y_test, predictions))\n    print('MSE: ',metrics.mean_squared_error(Y_test, predictions))\n    print('RMSE: ',np.sqrt(metrics.mean_absolute_error(Y_test, predictions)))\n    sns.distplot(Y_test - predictions)\n    \n    if dump == 1: # this function helps save the model to be reused for later\n        file = open('C:/Users/abhin/OneDrive - BITS Pilani K K Birla Goa Campus/BITS Goa academic material/Coursera and Udemy documents/Udemy/All ML material/1..Flight_Price--_ Machine Learning/model.pkl','wb')\n        pickle.dump(model, file)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:33:46.207996Z","iopub.execute_input":"2021-06-06T09:33:46.208298Z","iopub.status.idle":"2021-06-06T09:33:46.2213Z","shell.execute_reply.started":"2021-06-06T09:33:46.208269Z","shell.execute_reply":"2021-06-06T09:33:46.220267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\npredict(RandomForestRegressor(),1)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T09:33:46.222756Z","iopub.execute_input":"2021-06-06T09:33:46.223066Z","iopub.status.idle":"2021-06-06T09:33:50.005292Z","shell.execute_reply.started":"2021-06-06T09:33:46.223036Z","shell.execute_reply":"2021-06-06T09:33:50.003396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:11:25.514904Z","iopub.execute_input":"2021-06-06T10:11:25.515571Z","iopub.status.idle":"2021-06-06T10:11:25.521832Z","shell.execute_reply.started":"2021-06-06T10:11:25.515521Z","shell.execute_reply":"2021-06-06T10:11:25.520371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(LinearRegression(),0)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:11:29.796691Z","iopub.execute_input":"2021-06-06T10:11:29.797313Z","iopub.status.idle":"2021-06-06T10:11:30.432895Z","shell.execute_reply.started":"2021-06-06T10:11:29.797273Z","shell.execute_reply":"2021-06-06T10:11:30.431765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(KNeighborsRegressor(),0)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:11:41.617601Z","iopub.execute_input":"2021-06-06T10:11:41.617966Z","iopub.status.idle":"2021-06-06T10:11:44.111652Z","shell.execute_reply.started":"2021-06-06T10:11:41.617935Z","shell.execute_reply":"2021-06-06T10:11:44.11054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(DecisionTreeRegressor(),0)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:11:48.969017Z","iopub.execute_input":"2021-06-06T10:11:48.969431Z","iopub.status.idle":"2021-06-06T10:11:49.353834Z","shell.execute_reply.started":"2021-06-06T10:11:48.969395Z","shell.execute_reply":"2021-06-06T10:11:49.352453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV #Hypertuning approach\n\nreg_rf = RandomForestRegressor()\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 6)] #list comprehension code\nmax_depth = [int(x) for x in np.linspace(start = 5, stop = 30, num = 4)] #list comprehension code\n\nrandom_grid = {'n_estimators': n_estimators,\n                'max_features': ['auto','sqrt'], # number of features to consider at every split of decision tree\n                 'max_depth': max_depth,         # max number of layers in decision tree\n                'min_samples_split': [5,10,15,100]} # min number of samples required to split node\n                                         \nrf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid, cv = 3, verbose = 2, n_jobs = -1)\nrf_random.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:11:53.146162Z","iopub.execute_input":"2021-06-06T10:11:53.146572Z","iopub.status.idle":"2021-06-06T10:14:06.694419Z","shell.execute_reply.started":"2021-06-06T10:11:53.14654Z","shell.execute_reply":"2021-06-06T10:14:06.693521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rf_random.best_params_)\npreds = rf_random.predict(X_test)\nplt.figure()\nsns.distplot(Y_test - preds)\nprint(metrics.r2_score(Y_test, preds))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:14:25.114586Z","iopub.execute_input":"2021-06-06T10:14:25.115159Z","iopub.status.idle":"2021-06-06T10:14:25.814886Z","shell.execute_reply.started":"2021-06-06T10:14:25.115113Z","shell.execute_reply":"2021-06-06T10:14:25.814043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}