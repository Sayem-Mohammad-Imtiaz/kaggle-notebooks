{"cells":[{"metadata":{"_cell_guid":"7f08e976-bc33-427d-afb1-00f1d543e7df","_uuid":"0edf7f17f7638e1ec142f09f5aa71b568bc115be"},"cell_type":"markdown","source":"# Import packages"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"6a554aef-fbd6-49fd-8959-bcbd64e4cd1b","_uuid":"89a02a46f41226538aa3d504d3c52ded3ff6e084"},"cell_type":"markdown","source":"# Import data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"data  = pd.read_csv('../input/Sales_Transactions_Dataset_Weekly.csv')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"55de32b6-9877-4640-8dfe-77263fd547c0","_uuid":"5555a50b667ee88263ad99145947ab3e2b3ecef6"},"cell_type":"markdown","source":"# Have a look"},{"metadata":{"_cell_guid":"5c231ad1-8802-4131-8a3a-ac8f6b7c8695","_uuid":"d9cb1165d4d2c9567e13a4f797923b450a18381b","trusted":true},"cell_type":"code","source":"data.head()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"bc754e76-26cc-49fb-8436-fcd11ebc3c31","_uuid":"584ee41caf48f487d0c7d5721aafde921ac3ebc1","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"34dcfcd0-9452-4823-9599-51ba1d15cf5a","_uuid":"3436148a0f40c297be0935138e20d1780a11d68d","trusted":true},"cell_type":"code","source":"data","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"94bd0cad-9cbe-4e6a-b35a-9634c0257896","_uuid":"d7eaa6508ec2c108af1881b319926f301dfc6ed1"},"cell_type":"markdown","source":"No obvious indications of bad or missing values here. We could just have a look at the whole frame, since it's just 811 rows, but that's not really a scaleable approach.\n"},{"metadata":{"_cell_guid":"e8736b41-956f-4c88-8f70-653a4f208dd4","_uuid":"9cd3b6774c8d8a45af6ae91d85d78fffe24f43cc","trusted":true},"cell_type":"code","source":"data.isnull().values.any()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"402689da-4d03-443c-9e66-275738693a75","_uuid":"c01a41a0037c9bd214aaf15a3396a53979ef6926"},"cell_type":"markdown","source":"It seems like this particular data set doesn't have any missing values. That's not to say there isn't any noise in the data, just that none of the elements are undefined."},{"metadata":{"_cell_guid":"795971b9-6ee9-4fa4-ba66-adbde547c28b","_uuid":"5ce128456cb7852993d85229695afdb235fd5ecf"},"cell_type":"markdown","source":"# General approach\n\nFirst we'll put together a rough method for finding groups of products that are more related to one another. That is, related in terms of their sales patterns, even if they're from completely different categories. \nAs for the time scale: to start with, we'll just look at the overall pattern over the year for which we have data. A potential challenge is that with such a limited data set, we only have one example per calendar day. It may be hard to separate seasonal, monthly, weekly patterns from noise."},{"metadata":{"_cell_guid":"c6c87021-301c-4cc1-bf7e-d02df78df7eb","_uuid":"20b2cb8777b15aaa1e02a10ddb224c845f316d56"},"cell_type":"markdown","source":"# Feature selection\nHaving had a look at the columns above, we see that there's product counts per week as well normalized sales. Without making any assumptions on the types of products in the list, we don't know that the per-item sales counts are a valid way to compare products. Some products tend to be purchased several at a time, while others only one at a time. We'll consider that their relative variations are more important, and keep only the normalized columns for now."},{"metadata":{"_cell_guid":"6bc60fef-8d16-4496-9fbe-1a9a0ea16098","_uuid":"1e596e359e83aa50519bc657fce0c9edae25920c","trusted":true},"cell_type":"code","source":"data_norm = data.copy()\n\ndata_norm[['Normalized {}'.format(i) for i in range(0,52)]].head()","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"5b4cd4bd-d76b-42f0-9e3d-1c10671d5b0f","_uuid":"e9ff2ab98ba5c6c5658db4d21db1fa26457e950f","collapsed":true,"trusted":true},"cell_type":"code","source":"data_norm = data_norm[['Normalized {}'.format(i) for i in range(0,52)]]","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"e9f9cfb8-5f0e-4a65-a13d-df5048c4c772","_uuid":"4032ae55439f76c8318bf8368828f58fefe10a24","trusted":true},"cell_type":"code","source":"data_norm.head()","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"7c278e21-b779-4dcc-8622-8bb9f0ce9796","_uuid":"b79f99634040f9ddf9459c875845670526ea7194"},"cell_type":"markdown","source":"# Weekly sales differences (\"velocities\")\nTo understand of products are related, we probably want to know if their sales vary together week to week. To approach this question, it might be helpful to calculate the \"sales velocites\", or the difference matrix showing how much the sales went up or down in each week. The assumption is that products with similar sales fluctuations are similar, and should be restocked around the same time. *In reality, this should be subject to constraints on the restock-order volume, and frequency!!!!*"},{"metadata":{"_cell_guid":"e9583ed7-174a-403a-b607-8af9b70c337f","_uuid":"48be196563dc84ce7d2dab0568fae6a677bd5334","trusted":true},"cell_type":"code","source":"data_norm.diff(axis=1).head()","execution_count":101,"outputs":[]},{"metadata":{"_cell_guid":"0e5a6623-3a2e-4d25-8b9a-19ad4351f862","_uuid":"107769c94f2b3715a209aa70682cdde7d89f5f73","collapsed":true,"trusted":true},"cell_type":"code","source":"# Drop the now nonsense first column\ndata_norm_diff = data_norm.diff(axis=1).drop('Normalized 0', axis=1).copy()","execution_count":102,"outputs":[]},{"metadata":{"_cell_guid":"c3f97549-1a04-47cb-a27f-983d4c6f272b","_uuid":"e50d7d70854dbd5d91fd7ff8f44621819b79c56e","trusted":true},"cell_type":"code","source":"data_norm_diff.head()","execution_count":103,"outputs":[]},{"metadata":{"_cell_guid":"cfd79410-ebdb-4624-9903-398963e49a55","_uuid":"458eca9213b6c54ef8c3950c87f89902306adf3f","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(range(0,51), data_norm_diff.values[0])\nplt.scatter(range(0,51), data_norm_diff.values[10])\n","execution_count":104,"outputs":[]},{"metadata":{"_cell_guid":"4d9b354c-7bc3-461a-a299-db9ce6cf77ec","_uuid":"6eff03a25a9d160e949ce113eb28913ef97100c8","trusted":true},"cell_type":"code","source":"data_norm_diff.head()","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"16c2c461ae199add111bf402ec52e51ed5f3cc8d"},"cell_type":"markdown","source":"## Example relatedness test for Product 1\nHaving gotten the differences for all of the products, accross the whole year, now we can see how each product varied which the others on a weekly basis."},{"metadata":{"_cell_guid":"629693ba-3870-48e6-9c07-8bf4d34f5eac","_uuid":"817c493a0e7eb8e0490789665ebfa739e970e1b8","collapsed":true,"trusted":true},"cell_type":"code","source":"data_norm_diff_prod1 =  data_norm_diff.values - data_norm_diff.values[0,:]","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"a13bcf95-c006-4847-a0bb-2ee21248730e","_uuid":"40660a4bf9705f4f89ab7b1dee834c4aaf287373","trusted":true},"cell_type":"code","source":"data_norm_diff_prod1","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"8f28ba94-4848-45e8-8b8b-b7f1b76b20e0","_uuid":"af4fdb73d6ca05032fe4936b527828325a617105","collapsed":true,"trusted":true},"cell_type":"code","source":"data_norm_diff_prod1_sum = data_norm_diff_prod1.sum(axis=1)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"d91f83a36ff1e2943cba00f1dd77e21f62132a87"},"cell_type":"markdown","source":"Let's plot the \"errors\" for Product 1, relative to all of the other products."},{"metadata":{"trusted":true,"_uuid":"52f5e8465f5905b42ebb412bd660fb11d35f5369"},"cell_type":"code","source":"plt.scatter(range(0,811),data_norm_diff_prod1_sum)","execution_count":105,"outputs":[]},{"metadata":{"_cell_guid":"a265b1c0-693b-479e-8010-62b86b09207c","_uuid":"695dfcf9de828420f1c3e265d597b55ea88cb261","trusted":true},"cell_type":"code","source":"print(data_norm_diff_prod1_sum.shape)\ndata_norm_diff_prod1_sum","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"b1c14bd8-a80c-433c-94da-81253cdc898e","_uuid":"580589c2867cdc460e8365234099c4699b076cac","collapsed":true,"trusted":true},"cell_type":"code","source":"prod1_velocities = pd.DataFrame(data_norm_diff_prod1_sum**2, columns=[\"Vel_total_diff\"])","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"97f8238b-e7b5-4598-8787-6f91ae63d2b5","_uuid":"0b8964441247e82b9a5e4da1cc1c313efd601b1d","trusted":true},"cell_type":"code","source":"prod1_velocities.sort_values(by=\"Vel_total_diff\")","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"0fe92afb-bd2c-4bb9-ac5c-4ad60f708030","_uuid":"3a68f6be9f18a9a7d44f0f8273a362bb93666e60","collapsed":true,"trusted":true},"cell_type":"code","source":"def getWeeklyDiffs(products_sales_table):\n    \n    return products_sales_table.diff(axis=1).drop(products_sales_table.columns[0], axis=1).copy()\n\ndef getProductErrors(product_index, products_diffs):\n    \n    return products_diffs - products_diffs.iloc[product_index]\n    \ndef getTotalSquaredError(per_product_error):\n    \n    return pd.DataFrame(per_product_error.sum(axis=1)**2, columns=[\"Total Error\"])\n    \ndef makeProductVelErrorMatrix(products_diffs, nproducts):\n    \n    product_error_matrix = pd.DataFrame()\n    \n    for i in range(0,nproducts):\n    \n        product_errors_table = getProductErrors(i, product_diffs)\n        \n        product_errors_sumsq = getTotalSquaredError(product_errors_table)\n        \n        product_error_matrix[i] = product_errors_sumsq\n        \n    return product_error_matrix\n        \n        \n    ","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"ce63e7c9-ab4b-46a3-a28a-9fb7c55851f8","_uuid":"62f79fb7c4e5a12296858ade85e6b01af3e94051","collapsed":true,"trusted":true},"cell_type":"code","source":"product_diffs  = getWeeklyDiffs(data_norm)","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"788733a0-8a1e-4fb1-913f-cc92c16b432f","_uuid":"1906ea785c7e10fa3183b2a078dd97be0001e57c","collapsed":true,"trusted":true},"cell_type":"code","source":"error_matrix = makeProductVelErrorMatrix(product_diffs, 811)\n","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"8b0443ad-1ebb-4fda-ba17-e465b7468a4c","_uuid":"41c661415383707ac56e3739126a3e95d8dea6e0","scrolled":true,"trusted":true},"cell_type":"code","source":"import seaborn as sb\nplt.figure(figsize=(15,15))\n\nsb.heatmap(error_matrix, \n           square=True)\n","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"ed2dedf0-82fe-4c67-a227-ea1976e861ec","_uuid":"7be8001eebb290c7a4ecebac7db1a019f4741b7e"},"cell_type":"markdown","source":"The error matrix shows us how each product's normalized monthly sales changed relative to the other products. In other words, darker colors indicate products that, over the course of a year, tended to vary together, in terms of sales increases or decreases. Brighter colors indicate products that didn't tend to vary together.\n\nKeep in mind, the sales trends are compared on a per month basis, and then the total-suqared discrepancy for the whole year is taken. So the matrix is giving us just a general view of the whole year\n\nAll that I'm comfortable to say so far, is that there seems to be a cluster of products (#1-200) that make up a \"dark bloc\" in the upper left of the matrix--- these products appear to be more closely related with each other. There is another, larger block, product #s 200-811, that also appear related, but the trend seems less uniform than with the smaller 。\n \nThis probably just indicates that the products, in the order they are given, are already somehow pre-catgorized. We would probably want to have more information about these categories before acting. Are they food vs. non-food items? Generic vs. brand-name?\n\nIn general, we can use a fine-tuned form of the method above, to determine perhaps smaller groupings of similar products.\n\nApply"},{"metadata":{"_cell_guid":"f5284bb5-ffba-4ef0-a59e-37eb8ba580de","_uuid":"fb0641e5f0b7b5008984505efc82c9cb3b61883e","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"f006dd15-b53b-49e9-81d3-86b01efcc5a7","_uuid":"4768a75b4d3356fb123ddfb7e7aa86ca22a0b9c7","collapsed":true,"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=3, whiten=True)","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"abe6e8b8-7665-4111-ba6e-e2ac098cc464","_uuid":"ff40b5f7bf9c30adc97e9d7e18fc9b7662507822","trusted":true},"cell_type":"code","source":"pca.fit_transform(error_matrix)","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"3f0f6d2a-ef04-46f6-9c8a-103a1b0524aa","_uuid":"8ebb5586a2ae1158d6cd4d15a198e112988846a0","trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"b36870cb-79f6-4c9d-9567-983467507b5f","_uuid":"36661696deaa12a92a40dea2c74c6524bdb28cb0","collapsed":true,"trusted":true},"cell_type":"code","source":"components = pca.components_","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"e8a99d7f-5e08-4f28-aa40-4d71fdf791aa","_uuid":"113b164a9bc7ef75a856b7055363cfbd0bf921b6","trusted":true},"cell_type":"code","source":"plt.scatter(y = components[1,:], \n            x = components[0,:])","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"f462e2d8-c2c4-404a-b67d-3e967dab7751","_uuid":"8cad2f59175c344a14c88c18e733d082667dda7a"},"cell_type":"markdown","source":"    "},{"metadata":{"_cell_guid":"12995f35-a5ca-415f-b6a9-ad5786bd52f3","_uuid":"073aecb49ce95dfc49acac0ea26ca719de8cbb61","collapsed":true,"trusted":true},"cell_type":"code","source":"pca_data_norm = PCA(n_components=2)","execution_count":83,"outputs":[]},{"metadata":{"_cell_guid":"4c7ae492-51d6-48f7-a48b-b32787ed81aa","_uuid":"9dfce724bd1347f6e2ee1c93ab0e9c96aded8aaf","trusted":true},"cell_type":"code","source":"pca_data_norm.fit_transform(data_norm.T)","execution_count":84,"outputs":[]},{"metadata":{"_cell_guid":"c506e511-4299-45d1-8fd2-e6978ec4c8e8","_uuid":"ec12104ea10a2ee1118e0be04b2f65ac19018886","trusted":true},"cell_type":"code","source":"pca_data_norm.explained_variance_ratio_\nprint(pca_data_norm.explained_variance_ratio_.sum())","execution_count":85,"outputs":[]},{"metadata":{"_uuid":"a3aa5f4c28e8954da79b96825e801ca973abe384"},"cell_type":"markdown","source":"The difficulty so far is that PCA is not able to squeeze much variance into only 2 components, or even 3.\nThat's a problem because 3 is the most that we mere mortals can plot.\n\nIf we take a look at the variance ratio for the 1st component, 8.65%--- that implies that even though we don't get a nice clean dimension reduction, we can still do better than 811 dimensions.\nLet's to a quick test, to see how many components we need to explain an arbitraty 99% of the variance:"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"16a26d62ed4ea7d6ee9327f192786724c64ab51b"},"cell_type":"code","source":"def determineNComponents(data):\n    \n    n_components = 0\n    sum_explained_variance = 0\n    \n    while sum_explained_variance < 0.99:\n        n_components += 1\n        pca_data_norm = PCA(n_components=n_components)\n        pca_data_norm.fit_transform(data)\n        sum_explained_variance = pca_data_norm.explained_variance_ratio_.sum()\n        \n    return n_components\n\ndetermineNComponents(data_norm.T)","execution_count":100,"outputs":[]},{"metadata":{"_uuid":"8b36d596520b064170451883c96c96ef4af73786"},"cell_type":"markdown","source":"We can compress our data to 50 dimensions, and still explain 99% of the variance. Maybe we can take these as product groups?\nT"},{"metadata":{"trusted":true,"_uuid":"ec02927f22ddcabbfe6ed4829bdc2c35efe0b799"},"cell_type":"code","source":"pca_data_norm = PCA(n_components=50)\npca_data_norm.fit_transform(data_norm.T)\n","execution_count":93,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ca86d4985e0384d1a6d5a2259aa0fe9b2309f18"},"cell_type":"code","source":"plt.scatter(range(0,811), pca_data_norm.components_[1,:])","execution_count":98,"outputs":[]},{"metadata":{"_cell_guid":"74bc2974-e619-49ac-ac23-343020c977ac","_uuid":"5488a845d3f74c7f2a062c9ba1ff93416b211ce7","collapsed":true,"trusted":true},"cell_type":"code","source":"components_data_norm = pca_data_norm.components_","execution_count":64,"outputs":[]},{"metadata":{"_cell_guid":"925763dd-7503-4f62-8cd6-163f900cafe5","_uuid":"95ea3012923719c5c111f1b2f8539667bfd19d10","trusted":true},"cell_type":"code","source":"import seaborn as sb\nsb.jointplot(y = components_data_norm[1,:], \n            x = components_data_norm[0,:],\n            kind = 'hex')","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"57475c17-255b-4067-9999-2678e4ac52d9","_uuid":"990874162953cd3c900e48feb8ea201f4b8ce993","collapsed":true,"trusted":true},"cell_type":"code","source":"pca_data_diffs = PCA(n_components=2, whiten=True)","execution_count":65,"outputs":[]},{"metadata":{"_cell_guid":"d9f828b0-b507-4b2c-85ac-417f136f2023","_uuid":"3d2f07f7fabc41f8702f30f16a5ec261e195cb44","trusted":true},"cell_type":"code","source":"pca_data_diffs.fit_transform(data_norm_diff.T)","execution_count":66,"outputs":[]},{"metadata":{"_cell_guid":"a96f0ac3-76fe-4d9e-be28-bba4b3adcadb","_uuid":"b84069ccfcd802ba2f4f227b15910a9163617e9a","trusted":true},"cell_type":"code","source":"pca_data_diffs.explained_variance_ratio_","execution_count":67,"outputs":[]},{"metadata":{"_cell_guid":"151f14f6-868c-4f0f-b7fa-d6e8b1ffef2a","_uuid":"f8ecd0e1ed740c0ac9b03ca59a37744be14dbe92","collapsed":true,"trusted":true},"cell_type":"code","source":"components_data_diffs = pca_data_diffs.components_","execution_count":68,"outputs":[]},{"metadata":{"_cell_guid":"5bc84155-454a-4708-8441-309ce5b41f94","_uuid":"434a916b983ccfa76b80400f66d89e740f7c7d9d","trusted":true},"cell_type":"code","source":"plt.scatter(y = components_data_diffs[1,:], \n            x = components_data_diffs[0,:],\n             alpha = 0.5)","execution_count":69,"outputs":[]},{"metadata":{"_cell_guid":"4ad9e15c-dc90-415b-8629-756540231746","_uuid":"8eeec01caf3b5476edd48d2e807827e3c90aa535","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans  ","execution_count":75,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4216911c2368f2cfce246011f214a9fc5f96ab3c"},"cell_type":"code","source":"kmeans = KMeans(n_clusters=20)  \nkmeans.fit(data_norm)  ","execution_count":76,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9324813b4beeb6cf298eb6ad47b1b1d9c1ceee7"},"cell_type":"code","source":"print(kmeans.cluster_centers_)  ","execution_count":77,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a19cd811d8c8fa38b40633eed46c9909e12a0181"},"cell_type":"code","source":"plt.scatter(x= components_data_norm[0,:],\n            y= components_data_norm[1,:],\n            c=kmeans.labels_, \n            cmap='rainbow') ","execution_count":78,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"efd6471c8aee6a8cf9e9828b2bd1b7ce6ec278c9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}