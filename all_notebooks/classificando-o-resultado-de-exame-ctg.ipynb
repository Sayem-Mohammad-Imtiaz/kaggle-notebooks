{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Science Aplicada à Área de Saúde"},{"metadata":{},"cell_type":"markdown","source":"## Prevendo resultado de exame CTG\n\n### por Antonildo Santos"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/ctgimage/aparelho-ctg.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O objetivo deste trabalho é analisar um conjunto de dados contendo medições extraídas de cardiotocogramas fetais (CTGs) e criar um modelo para classificar o resultado do exame de Cardiotocograma (CTG) (que representa o bem-estar do feto).\n\n## Introdução\n\nA ausência de acompanhamento médico é considerada uma das principais causas de mortalidade infantil, conforme dados do Fundo de População das Nações Unidas (Fnuap), a taxa de mortalidade infantil mundial é de 45 óbitos a cada mil crianças nascidas vivas. Apesar de comprovadamente este número está em constante declínio é importante destacar que essa redução não ocorre na mesma proporção em todos os países. A ONU espera que, até 2030, os países acabem com as mortes evitáveis ​​de recém-nascidos e crianças menores de 5 anos de idade, e espera que todos os países reduzam a mortalidade de menores de 5 anos para pelo menos 25 por 1.000 nascidos vivos.\n\nA morbimortalidade materna e perinatal continuam ainda muito elevadas no Brasil, incompatíveis com o atual nível de desenvolvimento econômico e social do País. Sabe-se que a maioria das mortes e complicações que surgem durante a gravidez,\nparto e puerpério são preveníveis, mas para isso é necessária a participação ativa do sistema de saúde. \n\nDiante do exposto, os Cardiotocogramas (CTGs) são uma opção simples e de baixo custo para avaliação da saúde fetal, permitindo aos profissionais de saúde atuarem na prevenção da mortalidade infantil e materna. O próprio equipamento funciona enviando pulsos de ultrassom e lendo sua resposta, lançando luz sobre a frequência cardíaca fetal (FCF), movimentos fetais, contrações uterinas e muito mais. \nHospitais, maternidades e clínicas obstétricas que buscam oferecer um atendimento integral à gestante devem estar preparados para a realização da cardiotocografia (CTG). O exame avalia a vitalidade do bebê e indica o sofrimento fetal, trazendo alertas como a necessidade da antecipação do parto, por exemplo.\n\n### Sobre o conjunto de dados\n\nEste conjunto de dados possui 2126 medições extraídas de cardiotocogramas fetais (CTGs) que foram processados ​​automaticamente e os respectivos recursos diagnósticos medidos. Os CTGs também foram classificados por três obstetras especialistas e uma etiqueta de classificação de consenso atribuída a cada um deles, conforme descrito em:\n\nAyres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5: 311-318"},{"metadata":{},"cell_type":"markdown","source":"Fonte dos dados: https://archive.ics.uci.edu/ml/datasets/cardiotocography"},{"metadata":{},"cell_type":"markdown","source":"### Informações sobre os atributos:\n\n    baseline value                                         - linha de base FHR (batimentos por minuto)\n    accelerations                                          - número de acelerações por segundo\n    fetal_movement                                         - número de contrações uterinas por segundo\n    light_decelerations                                    - número de desacelerações leves por segundo\n    severe_decelerations                                   - número de desacelerações graves por segundo\n    prolongued_decelerations                               - número de desacelerações prolongadas por segundo\n    abnormal_short_term_variability                        - porcentagem de tempo com variabilidade anormal de curto prazo\n    mean_value_of_short_term_variability                   - valor médio de variabilidade de curto prazo\n    percentage_of_time_with_abnormal_long_term_variability - porcentagem de tempo com variabilidade anormal de longo prazo\n    mean_value_of_long_term_variability                    - valor médio de variabilidade de longo prazo\n    histogram_width                                        - largura do histograma FHR\n    histogram_min                                          - mínimo do histograma FHR\n    histogram_max                                          - Máximo do histograma FHR\n    histogram_number_of_peaks                              - Nº de picos do histograma\n    histogram_number_of_zeroes                             - Nº de zeros do histograma\n    histogram_mode                                         - modo histograma\n    histogram_mean                                         - média do histograma\n    histogram_median                                       - mediana do histograma\n    histogram_variance                                     - variância do histograma\n    histogram_tendency                                     - tendência do histograma\n    fetal_health                                           - código de classe do estado fetal \n                                                            (1 = normal; 2 = suspeito; 3 = patológico)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Carregando os pacotes\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc, precision_score, recall_score, roc_auc_score \nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Carregando os Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health = pd.read_csv('../input/fetal-health-classification/fetal_health.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise Exploratória"},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando valores nulos\nfetal_health.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health['fetal_health'] = fetal_health['fetal_health'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Em nosso conjunto de dados não existem dados faltantes, isto é muito bom, pois não precisaremos utilizar nenhum tipo de método de inputação de dados."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formato dos dados\nfetal_health.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando valores únicos\nfor col in list(fetal_health.columns):\n    \n    # Obtém uma lista de valores únicos\n    list_of_unique_values = fetal_health[col].unique()\n    \n    # Se o número de valores exclusivos for menor que 15, imprima os valores. \n    # Caso contrário, imprima o número de valores exclusivos\n    if len(list_of_unique_values) < 15:\n        print(\"\\n\")\n        print(col + ': ' + str(len(list_of_unique_values)) + ' valores únicos')\n        print(list_of_unique_values)\n    else:\n        print(\"\\n\")\n        print(col + ': ' + str(len(list_of_unique_values)) + ' valores únicos')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checando as colunas que tem valor = '?'\nfetal_health.isin(['?']).any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"A variável alvo desse conjunto de dados nos indicam três classes que representam a etiqueta de classificação de consenso atribuída por três obstetras especialistas."},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health['fetal_health'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\")\n\n#Usando um gráfico de barras para mostrar a distribuição das classes: Morrer e Sobreviver\nbp = sns.countplot(x=fetal_health['fetal_health'])\nplt.title(\"Distribuição de classe do conjunto de dados\")\nbp.set_xticklabels([\"Normal\",\"Suspeito\",\"Patológico\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verifica a proporção de cada classe\nround(fetal_health['fetal_health'].value_counts() / len(fetal_health.index) * 100, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos visualizar de forma gráfica\n\n# Percentual de cada valor da variável alvo\npercentual = round(fetal_health['fetal_health'].value_counts() / len(fetal_health.index) * 100, 0)\n\n# Labels\nlabels = [\"Normal\",\"Suspeito\",\"Patológico\"]\n\n# Plot\nplt.axis(\"equal\")\nplt.pie(percentual , \n        labels = labels,\n        radius = 1.6,\n        autopct = '%1.2f%%',\n        explode = [0.05,0.05,0.05],\n        startangle = 90,\n        shadow = True,\n        counterclock = False,\n        pctdistance = 0.6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Coletando estatísticas das colunas\nfetal_health.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função para visualizar a distribuição de cada variável\ndef cria_histograma(df, features, rows, cols):\n    fig = plt.figure(figsize = (20,20))\n    \n    for i, feature in enumerate(features):\n        ax = fig.add_subplot(rows, cols, i+1)\n        df[feature].hist(bins = 20, ax = ax, facecolor = 'midnightblue')\n        ax.set_title(feature + \" Distribuição\", color = 'DarkRed')\n        \n    fig.tight_layout()  \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Executa a função\ncria_histograma(fetal_health, fetal_health.columns, 8, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Avaliando a correlação das variáveis independentes com a variável alvo\ncorr = fetal_health.corr()\ncorr[['fetal_health']].sort_values(by = 'fetal_health',ascending = False).style.background_gradient()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health_clean = fetal_health.drop('fetal_health', axis = 1)\ny = fetal_health['fetal_health']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Avaliando a Correlação das variáveis\ncorr = fetal_health_clean.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cria o mapa de calor com a matriz de correlação\nf, ax = plt.subplots(figsize = (15, 9))\nsns.heatmap(corr, cbar = True, annot = True, fmt = '.2f', annot_kws = {'size': 10}, vmax = 1, square = True, cmap = 'rainbow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Através do gráfico de correlação podemos perceber que existe colinearidade entre algumas variáveis, como por exemplo histogram_median, histogram_mean, histogram_mode. Vamos constatar isso através do metodo VIF (Variance Inflation Factor)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import library for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calc_vif(fetal_health_clean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VIF superior a 5 ou 10 indica alta multicolinearidade entre esta variável independente e as outras, neste caso podemos perceber uma alta colinearidade entre as variáveis histogram_mode, histogram_mean, histogram_median, baseline value, também entre as variáveis histogram_width, histogram_mean e histogram_median.\n\nResolverei o problema de multicolinearidade empregando a análise fatorial para agrupar em fatores as variávies com alta colinearidade, depois eliminarei as variáveis colineares, mantendo as demais variáveis juntamente com os fatores."},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health_clean.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aplicando transformação nos dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renomeando a variável baseline value para baseline_value\nfetal_health_clean['baseline_value'] = fetal_health_clean['baseline value']\ndel fetal_health_clean['baseline value']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install factor_analyzer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import FactorAnalysis\nfrom factor_analyzer import FactorAnalyzer\nfrom factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nfrom factor_analyzer.factor_analyzer import calculate_kmo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \nscaler = StandardScaler()\n\nscaled_fetal_health_clean=fetal_health_clean.copy()\nscaled_fetal_health_clean=pd.DataFrame(scaler.fit_transform(scaled_fetal_health_clean), columns=scaled_fetal_health_clean.columns)\nscaled_fetal_health_clean.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Teste de Adequação para Análise Fatorial\nAntes de realizar a análise fatorial, precisamos avaliar a “fatorabilidade” de nosso conjunto de dados. Fatorabilidade significa \"podemos encontrar os fatores no conjunto de dados?\". Existem dois métodos para verificar a fatorabilidade ou adequação da amostragem:\n\n* Teste de Bartlett\n* Teste Kaiser-Meyer-Olkin\n\nO teste de esfericidade de Bartlett verifica se as variáveis ​​observadas estão correlacionadas entre si ou não, usando a matriz de correlação observada contra a matriz de identidade. Se o teste não for estatisticamente significante, não devemos empregar uma análise fatorial.\n\nO teste Kaiser-Meyer-Olkin (KMO) mede a adequação dos dados para a análise fatorial. Ele determina a adequação para cada variável observada e para o modelo completo. KMO estima a proporção da variância entre todas as variáveis ​​observadas. Menor proporção é mais adequado para análise fatorial. Os valores de KMO variam entre 0 e 1. O valor de KMO menor que 0,6 é considerado inadequado."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Teste de adequação\n\n#Bartlett\n#p-value should be 0 (statistically sig.)\nchi_square_value,p_value=calculate_bartlett_sphericity(scaled_fetal_health_clean)\nprint(chi_square_value, p_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KMO\n#Value should be 0.6<\nkmo_all,kmo_model=calculate_kmo(scaled_fetal_health_clean)\nprint(kmo_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O teste de Bartlett retornou o valor p igual zero, isso quer dizer que o teste foi estatisticamente significativo, indicando que a matriz de correlação observada não é uma matriz identidade.\n\nO KMO geral para nossos dados é de 0.74, o que é excelente. Este valor indica que posso prosseguir com a análise fatorial planejada."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_fetal_health_clean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Escolhendo o número de fatores\n\nPara escolher o número de fatores, você pode usar o critério de Kaiser e o gráfico de scree. Ambos são baseados em valores próprios."},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXPLORATORY FACTOR ANALYSIS\nfa = FactorAnalyzer(rotation=None)\nfa.fit(scaled_fetal_health_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GET EIGENVALUES\nev, v = fa.get_eigenvalues()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SCREEPLOT (need pyplot)\nplt.scatter(range(1,scaled_fetal_health_clean.shape[1]+1),ev)\nplt.plot(range(1,scaled_fetal_health_clean.shape[1]+1),ev)\nplt.title('Scree Plot')\nplt.xlabel('Factors')\nplt.ylabel('Eigenvalue')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O método do scree plot desenha uma linha reta para cada fator e seus autovalores. Numere os valores próprios maiores que um considerado como o número de fatores.\n\nAqui, você pode ver apenas que os valores próprios de 5 fatores são maiores que um. Isso significa que precisamos escolher apenas 5 fatores (ou variáveis ​​não observadas). Porém após avaliar as possibilidades cheguei ao número de 3 fatores."},{"metadata":{"trusted":true},"cell_type":"code","source":"fa = FactorAnalysis(n_components=3, random_state=0, svd_method='lapack')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fa.fit(scaled_fetal_health_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create factor analysis object and perform factor analysis\nfa = FactorAnalyzer(3, rotation=\"varimax\", method='minres', use_smc=True)\nfa.fit(scaled_fetal_health_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fa.loadings_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fa.get_communalities()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get variance of each factors\nfa.get_factor_variance()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"loadings = pd.DataFrame(fa.loadings_, columns=['Factor 1', 'Factor 2', 'Factor 3'], index=scaled_fetal_health_clean.columns)\nfator1 = loadings['Factor 1'].copy()\nfator2 = loadings['Factor 2'].copy()\nfator3 = loadings['Factor 3'].copy()\nprint('Factor 1 \\n%s' %fator1.sort_values(ascending=False))\nprint('')\nprint('Factor 2 \\n%s' %fator2.sort_values(ascending=False))\nprint('')\nprint('Factor 3 \\n%s' %fator3.sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O fator 1 tem altas cargas fatoriais para:\n* histogram_width\n* histogram_variance\n* histogram_number_of_peaks\n* mean_value_of_short_term_variability\n* histogram_max\n* light_decelerations\n\nO fator 2 tem altas cargas fatoriais para:\n* histogram_mode\n* histogram_mean\n* histogram_median\n* baseline_value\n\nO fator 3 tem altas cargas fatoriais para:\n* abnormal_short_term_variability\n* percentage_of_time_with_abnormal_long_term_variability\n"},{"metadata":{},"cell_type":"markdown","source":"O Cronbach Alfa pode ser usado para medir se as variáveis de um fator formam ou não um fator “coerente” e confiável. Um valor acima de 0.6 para o alfa é, na prática, considerado aceitável."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pingouin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pingouin as pg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the factors\nfactor1 = scaled_fetal_health_clean[['histogram_width', 'histogram_variance', 'histogram_number_of_peaks', 'mean_value_of_short_term_variability', 'histogram_max', 'light_decelerations']]\nfactor2 = scaled_fetal_health_clean[['histogram_mode', 'histogram_mean', 'histogram_median', 'baseline_value']]\nfactor3 = scaled_fetal_health_clean[['abnormal_short_term_variability', 'percentage_of_time_with_abnormal_long_term_variability']]\n#Get cronbach alpha\nfactor1_alpha = pg.cronbach_alpha(factor1)\nfactor2_alpha = pg.cronbach_alpha(factor2)\nfactor3_alpha = pg.cronbach_alpha(factor3)\nprint(factor1_alpha, factor2_alpha, factor3_alpha)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os alfas são avaliados em 0.87, 0.95 e 0.69, o que indica que eles são úteis e coerentes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um Dataframe com apenas com as colunas que possuem maior relevência para os fatores \nscaled_fetal_health_fact = pd.concat([factor1, factor2, factor3], axis=1, join='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_fetal_health_fact","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplicando os fatores ao Dataframe\nscaled_fetal_health_new = fa.fit_transform(scaled_fetal_health_fact)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coluns_fact = ['factor1', 'factor2', 'factor3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_fetal_health_new_fact=pd.DataFrame(scaled_fetal_health_new, columns=coluns_fact)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health_clean_new = fetal_health_clean.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eliminando a colunas com colinearidade que foram substituidas por fatores\nfor col in factor1:\n    del fetal_health_clean_new[col]\nfor col in factor2:\n    del fetal_health_clean_new[col]\nfor col in factor3:\n    del fetal_health_clean_new[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando a versão final do Dataframe \nfetal_health_clean_finish = pd.concat([fetal_health_clean_new, scaled_fetal_health_new_fact], axis=1, join='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health_clean_finish","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health_clean_finish.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health_clean_finish.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = fetal_health_clean_finish","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplica a divisão com proporção 70/30\nX_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.30, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treina o padronizador com o método fit() e aplica com o método transform() nos dados de treino e teste.\n\nX_scaled_treino = X_treino.copy()\nX_scaled_teste = X_teste.copy()\n\n# features\nnum_cols = fetal_health_clean_finish.columns\n\n# Padronizando as variáveis de entrada\nfor i in num_cols:\n    \n    # fit on training data column\n    scale = StandardScaler().fit(X_scaled_treino[[i]])\n    \n    # transform the training data column\n    X_scaled_treino[i] = scale.transform(X_scaled_treino[[i]])\n    X_scaled_teste[i] = scale.transform(X_scaled_teste[[i]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seleção de Atributos (Feature Selection)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cria o seletor de variáveis\n\n# Cria o estimador\nestimador_rfc = RandomForestClassifier(random_state = 101)\n\n# Cria o seletor\nseletor_f1 = RFECV(estimator = estimador_rfc, step = 1, cv = StratifiedKFold(10), scoring='f1_macro')\n\n# Treinamos o seletor\nseletor_f1 = seletor_f1.fit(X_scaled_treino, y_treino)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Número Ideal de Atributos: {}'.format(seletor_f1.n_features_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos avaliar a acurácia do modelo com F1 Score\nprevisoes_seletor_f1 = seletor_f1.predict(X_scaled_teste)\nfrom sklearn.metrics import accuracy_score\nacc_seletor_f1 = accuracy_score(y_teste, previsoes_seletor_f1)\nacc_seletor_f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualiza os scores das variáveis mais importantes\nseletor_f1.estimator_.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaled_treino.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seletor_f1.support_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaled_treino# Cria um dataframe com os resultados\nresultado_seletor_f1 = pd.DataFrame()\nresultado_seletor_f1['Atributo'] = X_scaled_treino.columns[np.where(seletor_f1.support_ == True)]\nresultado_seletor_f1['Score'] = seletor_f1.estimator_.feature_importances_\nresultado_seletor_f1.sort_values('Score', inplace = True, ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot \n#plt.figure(figsize = (10, 10))\nplt.barh(y = resultado_seletor_f1['Atributo'], width = resultado_seletor_f1['Score'], color = 'Blue')\nplt.title('Importância de Variáveis - RFECV', fontsize = 18, fontweight = 'bold', pad = 10)\nplt.xlabel('Importância', fontsize = 14, labelpad = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extrai as variáveis e quais são importante ou não para o modelo\nvariaveis_rfecv = pd.Series(seletor_f1.support_, index = X_scaled_treino.columns)\nvariaveis_rfecv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_scaled_treino['severe_decelerations']\ndel X_scaled_treino['histogram_number_of_zeroes']\ndel X_scaled_treino['histogram_tendency']\n#del X_scaled_treino['fetal_movement']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_scaled_teste['severe_decelerations']\ndel X_scaled_teste['histogram_number_of_zeroes']\ndel X_scaled_teste['histogram_tendency']\n#del X_scaled_teste['fetal_movement']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model using each importance as a threshold\nthresholds = np.sort(seletor_f1.estimator_.feature_importances_)\nfor thresh in thresholds:\n    # select features using threshold\n    selection = SelectFromModel(seletor_f1.estimator_, threshold=thresh, prefit=True)\n    select_X_treino = selection.transform(X_scaled_treino)\n    # train model\n    selection_model = ExtraTreesClassifier()\n    selection_model.fit(select_X_treino, y_treino)\n    # eval model\n    select_X_teste = selection.transform(X_scaled_teste)\n    y_pred = selection_model.predict(select_X_teste)\n    predictions = [round(value) for value in y_pred]\n    accuracy = accuracy_score(y_teste, predictions)\n    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_treino.shape[1], accuracy*100.0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Criando o Classificador"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Regressão Logística\n\n# Cria o modelo\nmodelo_lr = LogisticRegression(tol = 1e-7, penalty = 'l2', C = 0.1, solver = 'liblinear', multi_class='ovr')\n\n# Treina o modelo\nmodelo_lr.fit(X_scaled_treino, y_treino)\n\n# Faz as previsões\ny_pred = modelo_lr.predict(X_scaled_teste)\npredict_proba = modelo_lr.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# Métricas Globais\ncohen_kappa_lr = cohen_kappa_score(y_teste, y_pred)\nacc_lr = modelo_lr.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_lr))\nprint(\"Acurácia = {}\".format(acc_lr))\nprint(\"\")\n\n# Relatório de Classificação\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patológico']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\n\nimport xgboost as xgb\n\n# Cria o modelo\nxgb_model = xgb.XGBClassifier (eta=0.1,\n                               max_depth=3,\n                               min_child_weight=8,\n                               learning_rate=0.1, \n                               colsample_bytree = 0.8,\n                               subsample = 0.80,\n                               objective='multi: softprob',\n                               n_estimators=65,\n                               reg_alpha = 0.01,\n                               num_class=3,\n                               gamma=0.01,\n                               random_state=42)\n# Treina o modelo\nxgb_model.fit(X_scaled_treino, y_treino)\n\n# Faz as previsões\ny_pred = xgb_model.predict(X_scaled_teste)\npredict_proba = xgb_model.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# Métricas Globais\ncohen_kappa_xgb = cohen_kappa_score(y_teste, y_pred)\nacc_xgb = xgb_model.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_xgb))\nprint(\"Acurácia = {}\".format(acc_xgb))\nprint(\"\")\n\n# Relatório de Classificação\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patológico']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier\n\n# Cria o modelo\nRFclf=RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Treina o modelo\nRFclf.fit(X_scaled_treino, y_treino)\n\n# Faz as previsões\ny_pred=RFclf.predict(X_scaled_teste)\npredict_proba = RFclf.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# Métricas Globais\ncohen_kappa_RF = cohen_kappa_score(y_teste, y_pred)\nacc_RF = RFclf.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_RF))\nprint(\"Acurácia = {}\".format(acc_RF))\nprint(\"\")\n\n# Relatório de Classificação\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patológico']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o classificador ExtraTreesClassifier\nETclf=ExtraTreesClassifier(n_estimators=100,random_state=42)\n\n#Train the model \nETclf.fit(X_scaled_treino, y_treino)\n\n# prediction on test set\ny_pred=ETclf.predict(X_scaled_teste)\npredict_proba = ETclf.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# Métricas Globais\ncohen_kappa_ET = cohen_kappa_score(y_teste, y_pred)\nacc_ET = ETclf.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_ET))\nprint(\"Acurácia = {}\".format(acc_ET))\nprint(\"\")\n\n# Relatório de Classificação\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patológico']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Após comparar o desempenho entre os modelos, o que obteve a melhor performance foi o RandomForestClassifier, agora vamos avaliar a sua performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred=RFclf.predict(X_scaled_teste)\npredict_proba = RFclf.predict_proba(X_scaled_teste)\nconf_matriz = confusion_matrix(y_teste, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Avaliando a performance do modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"TP = conf_matriz[0,0] + conf_matriz[1,1] + conf_matriz[2,2]\nTN = conf_matriz[0,1] + conf_matriz[0,2] + conf_matriz[1,0] + conf_matriz[1,2] + conf_matriz[2,0] + conf_matriz[2,2]\nFP = conf_matriz[0,1] + conf_matriz[0,2] + conf_matriz[1,0] + conf_matriz[1,2] + conf_matriz[2,0] + conf_matriz[2,2]\nFN = conf_matriz[1,0] + conf_matriz[2,0] + conf_matriz[0,1] + conf_matriz[2,1] + conf_matriz[0,2] + conf_matriz[1,2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classe Normal\nTP = conf_matriz[0,0]\nTN = conf_matriz[1,1] + conf_matriz[1,2] + conf_matriz[2,1] + conf_matriz[2,2] \nFN = conf_matriz[0,1] + conf_matriz[0,2]\nFP = conf_matriz[1,0] + conf_matriz[2,0]\nAcc = (TP + TN) / (TP + TN + FP + FN) \nprecisao = TP / (TP + FP) \nsensibilidade = TP / (TP + FN)\nespecificidade = TN / (TN + FP)\nPontuação_F = 2 * TP / (2 * TP + FP + FN)\n#\n# Print\nprint('\\nClasse Normal')\nprint('Precisão :', precisao)\nprint('sensibilidade :', sensibilidade)\nprint('Especificidade :', especificidade)\nprint('Pontuação_F :', Pontuação_F)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classe Suspeito\nTP = conf_matriz[1,1]\nTN = conf_matriz[0,0] + conf_matriz[1,2] + conf_matriz[2,1] + conf_matriz[2,2] \nFN = conf_matriz[1,0] + conf_matriz[1,2]\nFP = conf_matriz[0,1] + conf_matriz[2,1]\nAcc = (TP + TN) / (TP + TN + FP + FN) \nprecisao = TP / (TP + FP) \nsensibilidade = TP / (TP + FN)\nespecificidade = TN / (TN + FP)\nPontuação_F = 2 * TP / (2 * TP + FP + FN)\n#\n# Print\nprint('\\nClasse Suspeito')\nprint('Precisão :', precisao)\nprint('sensibilidade :', sensibilidade)\nprint('Especificidade :', especificidade)\nprint('Pontuação_F :', Pontuação_F)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classe Patológico\nTP = conf_matriz[2,2]\nTN = conf_matriz[0,0] + conf_matriz[0,1] + conf_matriz[1,0] + conf_matriz[1,1] \nFP = conf_matriz[2,0] + conf_matriz[2,1]\nFN = conf_matriz[0,2] + conf_matriz[1,2]\nprecisao = TP / (TP + FP) \nsensibilidade = TP / (TP + FN)\nespecificidade = TN / (TN + FP)\nPontuação_F = 2 * TP / (2 * TP + FP + FN)\n#\n# Print\nprint('\\nClasse Patológico')\nprint('Precisão :', precisao)\nprint('sensibilidade :', sensibilidade)\nprint('Especificidade :', especificidade)\nprint('Pontuação_F :', Pontuação_F)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relatório de Classificação\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patológico']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt\nskplt.metrics.plot_roc(y_teste, predict_proba, figsize=(10, 8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interpretando o resultado do Modelo\nPara realizar este trabalho utilizei o pacote LIME, que serve para gerar explicações locais para o modelo. A ideia central por trás da técnica é bastante intuitiva. Suponha que temos um classificador complexo, com um limite de decisão altamente não linear, seu objetivo é entender por que o modelo de aprendizado de máquina fez uma determinada previsão. O LIME testa o que acontece com as previsões quando você dá variações de seus dados ao modelo de aprendizado de máquina."},{"metadata":{"trusted":true},"cell_type":"code","source":"import lime\nimport lime.lime_tabular","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LIME tem um explainer para todos os tipos de modelos\nexplainer_v1 = lime.lime_tabular.LimeTabularExplainer(X_scaled_treino.values,  \n                              feature_names = X_scaled_treino.columns.values.tolist(), \n                              class_names = ['Normal', 'Suspeito','Patológico'],  \n                              verbose = True, \n                              mode = 'classification')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Submodular Pick And Global Explanations\nServe para encontrar um grupo de interpretações que tentam explicar a maioria dos casos. Utilizei uma amostra de 190 registros, o que representa 30% dos dados de teste."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from lime import submodular_pick\nsp_obj = submodular_pick.SubmodularPick(explainer_v1, X_scaled_treino.values, RFclf.predict_proba, sample_size=190, num_features=9, num_exps_desired=5)\n#Plot the 5 explanations\n[exp.as_pyplot_figure(label=exp.available_labels()[0]) for exp in sp_obj.sp_explanations];\n# Make it into a dataframe\nW_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n \nW_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n \n#Making a dataframe of all the explanations of sampled points\nW=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\nW['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\nW['prediction']  = W.apply(lambda row: 'Normal' if (row['prediction'] == 0) else row['prediction'], axis=1)\nW['prediction']  = W.apply(lambda row: 'Suspeito' if (row['prediction'] == 1) else row['prediction'], axis=1)\nW['prediction']  = W.apply(lambda row: 'Patológico' if (row['prediction'] == 2) else row['prediction'], axis=1)\n#Plotting the aggregate importances\nnp.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True).iplot(kind=\"barh\")\n \n#Aggregate importances split by classes\ngrped_coeff = W.groupby(\"prediction\").mean()\n \ngrped_coeff = grped_coeff.T\ngrped_coeff[\"abs\"] = np.abs(grped_coeff.iloc[:, 0])\ngrped_coeff.sort_values(\"abs\", inplace=True, ascending=False)\ngrped_coeff.head(25).sort_values(\"abs\", ascending=True).drop(\"abs\", axis=1).iplot(kind=\"barh\", bargap=0.05) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O primeiro gráfico dá uma ideia de quais recursos são importantes para o modelo num sentido mais amplo. Bem no topo do gráfico, podemos encontrar o número de desacelerações prolongadas por segundo como um indicador muito forte para diagnosticar o estado fetal, seguido do \"fator 3\" que representa o valor médio de variabilidade de curto prazo e porcentagem de tempo com variabilidade anormal de longo prazo.\n\nO segundo gráfico divide a inferência entre os três rótulos e os examina separadamente. Este gráfico nos permite entender qual recurso foi mais importante na previsão de uma classe específica. Numa visão geral podemos perceber que basicamente os mesmos recursos são importantes para todas as classes, porém para classe \"Normal\" o número de desacelerações prolongadas por segundo como o indicador mais forte, já para as classes \"Suspeito\" e \"Patológico\" destaca-se o \"fator 3\" que representa o valor médio de variabilidade de curto prazo e porcentagem de tempo com variabilidade anormal de longo prazo."},{"metadata":{},"cell_type":"markdown","source":"### Referências\n\nFormação Inteligência Artificial Aplicada à Medicina\nhttps://www.datascienceacademy.com.br/\n\nMinistério da Saúde http://bvsms.saude.gov.br/bvs/publicacoes/manual_tecnico_gestacao_alto_risco.pdf\n\nIntroduction to Factor Analysis in Python https://www.datacamp.com/community/tutorials/introduction-factor-analysis\n\nRFECV https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html\n\nInterpretability part 3: opening the black box with LIME and SHAP https://www.kdnuggets.com/2019/12/interpretability-part-3-lime-shap.html\n"},{"metadata":{},"cell_type":"markdown","source":"# Fim"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}