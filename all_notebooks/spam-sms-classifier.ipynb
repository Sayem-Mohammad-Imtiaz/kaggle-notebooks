{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Classification of spam messages and non-spam messages\n\nAs we know that the spam messages are very frustrating things and to get out of this problem, our data scientists made the spam classifiers which separates spam messages from non-spam messsages.\n\n*And one real time example of such classifier is used in Gmail which efficiently handles spam mails.*\n\n* I have used random forest classifier to do the classify spam and non-spam messages."},{"metadata":{},"cell_type":"markdown","source":"### Import the libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport wordcloud\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sms_data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv',encoding = 'latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the head of our dataframe\nsms_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here the last three columns are null and are not usefull to us. We have to drop it first.\n* And for the first two columns we have to just change the names for our simplicity.\n\n---> We will be doing these in EDA step."},{"metadata":{},"cell_type":"markdown","source":"### EDA (Exploratory Data Analysis)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data.drop(sms_data.iloc[:,2:], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check our data again\nsms_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data.rename(columns = {'v1': 'label', 'v2' : 'sms'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check whether ther are null values present in the data or not\nsms_data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No null values are present."},{"metadata":{},"cell_type":"markdown","source":"#### Let's see the Distribution of the target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data.label.value_counts().plot.bar(rot = 0)\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.title('SMS class distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Clearly we have imbalanced data because ham class has a lot of examples than the spam class.**\n\n**We should handle this issue otherwise our model will overfit to predict only ham/not spam.**\n\n**But first let's add a numerical label for spam or ham.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data['spam'] = pd.get_dummies(sms_data['label'], drop_first = True)\n\nsms_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Wordcloud for spam and ham sms"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ham = sms_data[sms_data['spam'] == 0]\ndata_spam = sms_data[sms_data['spam'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_wordcloud(data_spam_or_ham, title):\n    text = ' '.join(data_spam_or_ham['sms'].astype(str).tolist())\n    stopwords = set(wordcloud.STOPWORDS)\n    \n    fig_wordcloud = wordcloud.WordCloud(stopwords = stopwords,background_color = 'lightgrey',\n                    colormap='Accent', width = 800, height = 600).generate(text)\n    \n    plt.figure(figsize = (10,7), frameon = True)\n    plt.imshow(fig_wordcloud)  \n    plt.axis('off')\n    plt.title(title, fontsize = 20 )\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Word Cloud for Spam sms***"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(data_spam, 'Spam SMS')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Wordcloud for Ham sms***"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(data_ham, 'Ham SMS')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create dependent and independent variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = sms_data['sms']\ny = sms_data['spam']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"#### Let's\n* Remove unwanted Characters from the data.\n* Remove stopwords.\n* Perform stemming."},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data(message):\n    ps = PorterStemmer()   # Porter Stemmer Object\n\n    corpus = []\n\n    for i in range(0, len(message)):\n        review = re.sub('[^A-Za-z]', ' ', message[i])\n        review = review.lower()\n        review = review.split()\n    \n        review = [ps.stem(word) for word in review if word not in(stopwords.words('english'))]\n        review = ' '.join(review)\n        corpus.append(review)\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = process_data(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check our corpus"},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bag of Words model (BOW)\nLet's create our Bag of Words model using TF-IDF vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features = 4000)\nX = tfidf.fit_transform(corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, since we have the data, all numerical to feed into our machine learning model.\n\nBut, first let's handle the problem of imbalanced class"},{"metadata":{},"cell_type":"markdown","source":"### Splitting the data into Train and Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, \n                                                    random_state = 101, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train and Test the model"},{"metadata":{},"cell_type":"markdown","source":"#### Using Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state = 101)\n\nrf_model.fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\nprint(metrics.classification_report(y_test, y_pred))\n\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\ndisplay(pd.DataFrame(data = confusion_matrix, columns = ['Predicted 0', 'Predicted 1'],\n            index = ['Actual 0', 'Actual 1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**And if you liked the notebook please give an upvote. It will boost my confidence and motivation.**\n\n**And any further suggestions for improving this notebook are most welcome as I will be looking to improve this notebook further.**\n\n**Thank you ðŸ˜€**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}