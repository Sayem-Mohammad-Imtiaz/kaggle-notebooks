{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from math import sqrt\n#from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n#from sklearn.metrics import mean_squared_error\nfrom pandas import read_csv\n#from keras.layers import LSTM\nimport matplotlib.pyplot as plt\n#from keras.models import Sequential\n#from keras.layers import Dense\nimport numpy as np\n#import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e106796577752897bf3b23d7ffa205e3a6c36e17"},"cell_type":"code","source":"solarpower = read_csv(\"../input/solarpanelspower/PV_Elec_Gas3.csv\", sep=',',usecols = [0,1])\nprint(solarpower.head(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1267d97d30ec1f55df39422037d2d6d904b0f612"},"cell_type":"code","source":"# make a column with the daily power (stationary)\nsolarpower['day_power']=0.0\nfor index in range(solarpower.index[solarpower.shape[0]-1], 0, -1):\n    power = solarpower.Cumulative_solar_power[index] - solarpower.Cumulative_solar_power[index-1]\n    solarpower.at[index, 'day_power']= power\n#replace the day power of day 0 with the same power as day1\nsolarpower.at[0,'day_power'] = solarpower.at[1,'day_power']\nprint(solarpower.head(2))\nprint(solarpower.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b33a76c435271e1e8624cb04a1ea4b7f3cb7d44c"},"cell_type":"code","source":"plt.plot(solarpower.day_power)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca6b7579ed11e025fbcf69ddd2c5d4063a1fc752"},"cell_type":"code","source":"'''simple exponential smoothing go back to last N values\n y_t = a * y_t + a * (1-a)^1 * y_t-1 + a * (1-a)^2 * y_t-2 + ... + a*(1-a)^n * y_t-n  : c2018:Yogesh Chandra'''\n\ndef exponential_smoothing(panda_series, alpha_value):\n    ouput=sum([alpha_value * (1 - alpha_value) ** i * x for i, x in enumerate(reversed(panda_series))])\n    return ouput\nsolarpower['smooth_power'] = 0.0\nfor index in range(0, solarpower.index[solarpower.shape[0]-1], 1): \n    powers = solarpower.day_power.head(index).values\n    new_power = exponential_smoothing(powers,0.025)   # set alpha-value!!!!!!!!!\n    solarpower.at[index, 'smooth_power'] = new_power","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d2c38517d136c42723b76f005b27193e6b9e913"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.plot(solarpower.day_power[:730])\nplt.plot(solarpower.smooth_power[:730])\nplt.xticks(color='aqua')\nplt.yticks(color='aqua')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9e4ab2ef64a3f596e9ad5f4a47c7fab7d1df395"},"cell_type":"code","source":"solarpower= solarpower.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36e687387bc0d4e1119e95e27799855f3b2f6b44"},"cell_type":"code","source":"x = np.array(solarpower.day_power[:].values)\nacf = []\nfor i in range(1, len(x)-180):\n    acf.append(np.corrcoef(x[:-i], x[i:])[0,1])\nplt.plot(acf)\nplt.xticks(color='aqua')\nplt.yticks(color='aqua')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68e7c2d63ce741956bb76c2433aeb918cb26aa88"},"cell_type":"code","source":"#calc autocorrellation\ny = np.array(solarpower.day_power[:].values)\n\nyunbiased = y-np.mean(y)\nynorm = np.sum(yunbiased**2)\nacor = np.correlate(yunbiased, yunbiased, \"same\")/ynorm\n# use only second half\nacor = acor[len(acor)//2:]\n\nplt.plot(acor)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62d48aa0e3a70acd56ea435730b4724d5f8f1a7e"},"cell_type":"code","source":"'''autocorrellation from https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation\nsee Jason code'''\n\ndef autocorr1(x,lags):\n    '''np.corrcoef, partial'''\n\n    corr=[1. if l==0 else np.corrcoef(x[l:],x[:-l])[0][1] for l in lags]\n    return np.array(corr)\n\ndef autocorr2(x,lags):\n    '''manualy compute, non partial'''\n\n    mean=np.mean(x)\n    var=np.var(x)\n    xp=x-mean\n    corr=[1. if l==0 else np.sum(xp[l:]*xp[:-l])/len(x)/var for l in lags]\n\n    return np.array(corr)\n\ndef autocorr3(x,lags):\n    '''fft, pad 0s, non partial'''\n\n    n=len(x)\n    # pad 0s to 2n-1\n    ext_size=2*n-1\n    # nearest power of 2\n    fsize=2**np.ceil(np.log2(ext_size)).astype('int')\n\n    xp=x-np.mean(x)\n    var=np.var(x)\n\n    # do fft and ifft\n    cf=np.fft.fft(xp,fsize)\n    sf=cf.conjugate()*cf\n    corr=np.fft.ifft(sf).real\n    corr=corr/var/n\n\n    return corr[:len(lags)]\n\ndef autocorr4(x,lags):\n    '''fft, don't pad 0s, non partial'''\n    mean=x.mean()\n    var=np.var(x)\n    xp=x-mean\n\n    cf=np.fft.fft(xp)\n    sf=cf.conjugate()*cf\n    corr=np.fft.ifft(sf).real/var/len(x)\n\n    return corr[:len(lags)]\n\ndef autocorr5(x,lags):\n    '''numpy.correlate, non partial'''\n    mean=x.mean()\n    var=np.var(x)\n    xp=x-mean\n    corr=np.correlate(xp,xp,'full')[len(x)-1:]/var/len(x)\n\n    return corr[:len(lags)]\n\n\nif __name__=='__main__':\n\n    y=np.array(solarpower.day_power[:].values)\n    \n    lags=range(7*365)\n    fig,ax=plt.subplots(figsize=(15,15))\n\n    for funcii, labelii in zip([autocorr1, autocorr2, autocorr3, autocorr4,\n        autocorr5], ['np.corrcoef, partial', 'manual, non-partial',\n            'fft, pad 0s, non-partial', 'fft, no padding, non-partial',\n            'np.correlate, non-partial']):\n\n        cii=funcii(y,lags)\n        #print(labelii)\n        #print(cii)\n        ax.plot(lags,cii,label=labelii)\n\n    ax.set_xlabel('lag')\n    ax.set_ylabel('correlation coefficient')\n    ax.legend()\n    plt.savefig('autocorrellation1.pdf')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6d9879991d02e612cda507f09034b83a247eff8"},"cell_type":"markdown","source":"Besides the obvious seven year cycle there is a lot of noise. If we want to do predictions it is better to smooth the day_power. The  previous 'simple exponential smoothing' program is a usefull sollution but we can try other algorithms."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}