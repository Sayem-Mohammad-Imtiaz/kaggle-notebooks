{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SF-DST Car Price Prediction. Предсказание стоимости авто","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"Изначально данные представлены в виде тестового датасета, предлагающего шаблон для сбора основного датасета, и файла для представления данных на соревнование.\n\nПо условиям задачи основной датасет необходимо собрать, спарсив данные с сайта auto.ru. Допустимо использовать и другие сайты, однако именно на auto.ru имеется информация, подходящая к тестовому шаблону. Использование других сайтов означает очень большую работу по очистке данных.\n\nПарсинг данных сайта в результате выдал более 50 тысяч объявлений. Сбор и подготовка датасета занимает значительное время, данные пришлось несколько раз скачивать заново, внося определенные иправления. В данном ноутбуке используется уже собранный датасет. Файл с кодом парсинга можно посмотреть на гитхабе по ссылке:\nhttps://github.com/Aleorate/skillfactory_rds/blob/master/module_7_Car_price_prediction_parse/project_6_parse.ipynb\n\nТакже в указанном в файле коде я не перепроверяю наглядно сделанные мной изменения для краткости кода, т.е. по факту проверяю, что все как нужно и удаляю лишние строки.","metadata":{}},{"cell_type":"code","source":"# Импортируем необходимые библиотеки\nimport pandas as pd\nimport numpy as np\nimport re\nimport sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom tqdm import tqdm\nfrom collections import Counter\nfrom sklearn.base import clone\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nwarnings.simplefilter('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.219772,"end_time":"2020-10-26T12:46:42.581597","exception":false,"start_time":"2020-10-26T12:46:41.361825","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Зафиксируем версию пакетов, чтобы эксперименты были воспроизводим\n!pip freeze > requirements.txt","metadata":{"_kg_hide-input":true,"papermill":{"duration":5.172536,"end_time":"2020-10-26T12:46:47.852593","exception":false,"start_time":"2020-10-26T12:46:42.680057","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Зафиксируем random_seed для воспроизводимости экспериментов\nRANDOM_SEED = 42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Определим функции для работы с датасетом","metadata":{"papermill":{"duration":0.028837,"end_time":"2020-10-26T12:46:47.981435","exception":false,"start_time":"2020-10-26T12:46:47.952598","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Расчёт результата модели\ndef mape(y_test, y_pred):\n    m = round(np.mean(np.abs((y_test - y_pred) / y_test) * 100), 2)\n    return m\n\n# Визуализация числовых данных\ndef graph_num(col, df, size=6):\n    fig, (g1, g2) = plt.subplots(1, 2, figsize=(2*size, size))\n    fig.suptitle('Histogram and boxplot for {0}'.format(col), fontsize=20)\n    g1.hist(df[col], bins=20, histtype='bar', align='mid',\n            rwidth=0.8, color='blue')  # гистограмма\n    g2.boxplot(df[col], vert=False)  # выбросы\n    plt.figtext(0.5, 0, col, fontsize=16)\n    plt.show\n\n# Визуализация корреляции числовых признаков между собой\ndef jointplot_f(col_num, df):\n    pairs = list(itertools.combinations(col_num, 2))\n    for pair in pairs:\n        sns.jointplot(x=pair[0], y=pair[1], data=df)\n    return\n\n# Статистические данные по выбросам\ndef statistic(col, df):\n    median = df[col].median()\n    IQR = df[col].quantile(0.75) - df[col].quantile(0.25)\n    perc25 = df[col].quantile(0.25)\n    perc75 = df[col].quantile(0.75)\n    l = perc25 - 1.5*IQR\n    r = perc75 + 1.5*IQR\n    print(\"Для {0} IQR: {1}, \".format(col, IQR),\n          \"Границы выбросов: [{0}, {1}].\".format(l, r))\n    print('Всего {} выбросов'.format(\n        df[df[col] > r][col].count()+df[df[col] < l][col].count()))\n\n# Таблица сравнения результатов каждой модели\ndef cumulated_res(data, model, mape):\n    l = len(data)\n    data.loc[l] = [mape, model]\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Зададим переменные пути для скачивания исходных файлов и загрузки итогового\ndir_in_train = '../input/car-price/'\ndir_in   = '../input/sf-dst-car-price-prediction/'\ndir_out = '/kaggle/output/'","metadata":{"papermill":{"duration":0.039969,"end_time":"2020-10-26T12:46:48.052728","exception":false,"start_time":"2020-10-26T12:46:48.012759","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Импорт, обзор и очистка данных\n","metadata":{"papermill":{"duration":0.030254,"end_time":"2020-10-26T12:46:48.112586","exception":false,"start_time":"2020-10-26T12:46:48.082332","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_train = pd.read_csv(dir_in_train+'car_auto_ru_train.csv') # датасет для обучения модели\ndf_test = pd.read_csv(dir_in+'test.csv')\nsub = pd.read_csv(dir_in+'sample_submission.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":13.16556,"end_time":"2020-10-26T12:47:02.12133","exception":false,"start_time":"2020-10-26T12:46:48.95577","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(1).T","metadata":{"papermill":{"duration":0.09378,"end_time":"2020-10-26T12:47:02.246755","exception":false,"start_time":"2020-10-26T12:47:02.152975","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Опишем признаки датасетов:\n- bodyType: Тип корпуса\n- brand: Марка автомобилья\n- car_url: Ссылка на страницу с продажей авто\n- color: Цвет\n- complectation_dict: Словарь, содержащий id, название комплектации, а также ее составляющие\n- description: Дополнительное описание в свободной форме\n- engineDisplacement: Объем двигателя\n- enginePower: Мощность двигателя(значение + N12)\n- equipment_dict: Комплетация автомобиля, отчасти пересекается с available_options в complectation_dict\n- fuelType: Тип топлива\n- image: Ссылка на изображения авто\n- mileage: Пробег\n- modelDate: Дата выпуска данной модели\n- model_info: Информация о модели, марке автомобиля\n- model_name: Модель авто\n- name: Полное название в тренировочном, а в тестовом - информация о коробке передач, приводе, объеме двигателя, мощности итд\n- numberOfDoors: Количество дверей(+ багажник)\n- parsing_unixtime: Дата и время, когда были спарсены данные; в формате unixtime\n- price: искомый признак, цена продажи авто\n- priceCurrency: Валюта, в которой продают автомоибль, везде рубли\n- productionDate: Дата производства авто\n- sell_id: id продажи автомобиля\n- super_gen: В тестовом датасете по факту находятся данные не из super_gen, а из tech_param. Так что парсить для тренировочного датасета будем именно их. Часть данных здесь повторяется: объем двигателя, тип топлива, привод, коробка передач, мощность двигателя в л.с., мощность в киловаттах; а также новые полезные данные о: ускорение до 100 км/ч, клиренс, а также, по-видимому, расход топлива на 100 км\n- vehicleConfiguration: Содержит информацию о типе корпуса, коробке передач и объеме двигателя\n- vehicleTransmission: Коробка передач\n- vendor: Регион производства\n- Владельцы: Количество владельцев \n- ПТС: Оригинал ПТС или нет\n- Привод: Тип привода: передний, задний, полный\n- Руль: Нахождение руля\n- Состояние: Требует или не требует ремонта\n- Таможня: Растоможена ли машина\n- Владение: Срок владения автомобилем","metadata":{}},{"cell_type":"markdown","source":"sell_id - уникальные идентификаторы объявления о продаже автомобиля. Убедимся, что в этом столбце действительно уникальные значения.","metadata":{}},{"cell_type":"code","source":"df_train.drop_duplicates(subset=['sell_id'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.reset_index(inplace=True)\ndf_train.drop(['index'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В датасетах есть признаки с названием на русском языке, с учетом остальных признаков это \"режет глаз\", переименует их на английский.","metadata":{}},{"cell_type":"code","source":"df_train.rename(columns={'Владельцы': 'owners',\n                         'ПТС': 'vehiclePassport',\n                         'Привод': 'gear_type', 'Руль': 'wheel'}, inplace=True)\ndf_test.rename(columns={'Владельцы': 'owners',\n                        'ПТС': 'vehiclePassport',\n                        'Привод': 'gear_type', 'Руль': 'wheel'}, inplace=True)\n# \"Состояниe\" и \"Таможня\" не будем менять, т.к. вскоре избавимся от них","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info(), df_test.info()","metadata":{"papermill":{"duration":0.22352,"end_time":"2020-10-26T12:47:02.502166","exception":false,"start_time":"2020-10-26T12:47:02.278646","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = []\nfor col in df_train.columns:\n    cols.append(col) \ncols.remove('car_url')\ncols.remove('image')\ncols.remove('parsing_unixtime')\ncols.remove('price')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сравним датасеты на предмет уникальных категориальных значений\nfor col in cols:\n    print('В столбце {0} {1} для теста и {2} для трейна уникальных значений'.format(\n        col, len(df_test[col].unique()), len(df_train[col].unique())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# В признаке состояние лишь 1 автомобиль битый, удалим этот элемент и сам признак.\ndf_train[df_train.Состояние == 'Битый / не на ходу']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.drop([6372], inplace=True)\ndf_train.drop(['Состояние'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_train[df_train.complectation_dict != '{\"id\":\"0\"}'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Проверка выборочных редких значений bodyType показала, что в них нет ошибки, просто это действительно редкие виды автомобильных кузовов, оставим этот признак как есть.\n- В тренировочном датасете всего по несколько пропусков в различных признаках.\n- Есть порпуски в признаке \"пробег\"(mileage). \n- В тренировочном и тестовом датасетах есть много пропусков в признаках complectation_dict и equipment_dict. В трейне виден 1 пропуск, но по факту все значения '{\"id\":\"0\"}' являются пропуском. ","metadata":{}},{"cell_type":"code","source":"# Просто удалим пропуски в признаках, где их мало\ndf_train.dropna(subset=['vehiclePassport',\n                        'complectation_dict', 'owners'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# В тестовом столбце есть 1 пропуск в признаке vehiclePassport,\n# заменим его наиболее часто встречающимся значением.\ndf_test.vehiclePassport.fillna('Оригинал', inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"По данным агентства «Автостат» автомобили в России за год в среднем проезжают 17,5 тыс. км, заполним пропуски в признаке \"пробег\" с учетом этой информации.","metadata":{}},{"cell_type":"code","source":"df_train['mileage'].fillna(0, inplace=True)\nfor i in range(len(df_train)):\n    if df_train['mileage'].iloc[i]==0:\n        df_train['mileage'].iloc[i] = int((2021 - df_train['productionDate'].iloc[i])*17500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# заменим нулевые данные 'complectation_dict' на данные пододные ненулевым\nfor i in range(len(df_train)):\n    if df_train['complectation_dict'].iloc[i] == '{\"id\":\"0\"}':\n        df_train['complectation_dict'].iloc[i] = '{\"id\":\"unknown\",\"name\":\"unknown\",\"available_options\":[\"unknown\"]}'\ndf_test.complectation_dict.fillna(\n    '{\"id\":\"unknown\",\"name\":\"unknown\",\"available_options\":[\"unknown\"]}', inplace=True)\ndf_test.equipment_dict.fillna('\"unknown\"', inplace=True)\ndf_train.equipment_dict[df_train.equipment_dict == '{}'] = '\"unknown\"'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Преобразуем признак со словарем в более удобный\n# Признак \"имя комплектации\" сохранять не буду, т.к. вариантов огромное множество\n# для трейна\noptions_list = []\nfor i in range(len(df_train['complectation_dict'])):\n    options_list.append(re.split(r'\\]', re.split(\n        r'\"available_options\":\\[', df_train['complectation_dict'].iloc[i])[1])[0])\ndf_train['available_options'] = options_list\n\n# для теста\noptions_list = []\nfor i in range(len(df_test['complectation_dict'])):\n    options_list.append(re.split(r'\\]', re.split(\n        r'\"available_options\":\\[', df_test['complectation_dict'].iloc[i])[1])[0])\ndf_test['available_options'] = options_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вытащим из признака super_gen 3 дополнительных числовых признака:\n# ускорение, клиренс, а также рейтинг расхода топлива\n# в тесте\naccel_list = []\nfor i in range(len(df_test.super_gen)):\n    if '\"acceleration\":' in df_test.super_gen.iloc[i]:\n        accel_list.append(float(re.split(r',', re.split(\n            r'\"acceleration\":', df_test.super_gen.iloc[i])[1][:4])[0].replace('}', '')))\n    else:\n        accel_list.append(0)\ndf_test['acceleration'] = accel_list\n\nclearance_list = []\nfor i in range(len(df_test.super_gen)):\n    if '\"clearance_min\":' in df_test.super_gen.iloc[i]:\n        clearance_list.append(float(re.split(r',', re.split(\n            r'\"clearance_min\":', df_test.super_gen.iloc[i])[1][:5])[0].replace('}', '')))\n    else:\n        clearance_list.append(0)\ndf_test['clearance'] = clearance_list\n\nfuel_rate_list = []\nfor i in range(len(df_test.super_gen)):\n    if '\"fuel_rate\":' in df_test.super_gen.iloc[i]:\n        if ',' in re.split(r'\"fuel_rate\":', df_test.super_gen.iloc[i])[1][:5]:\n            fuel_rate_list.append(float(re.split(r',', re.split(\n                r'\"fuel_rate\":', df_test.super_gen.iloc[i])[1][:5])[0]))\n        elif '}' in re.split(r'\"fuel_rate\":', df_test.super_gen.iloc[i])[1][:5]:\n            fuel_rate_list.append(float(re.split(r'}', re.split(\n                r'\"fuel_rate\":', df_test.super_gen.iloc[i])[1][:5])[0]))\n    else:\n        fuel_rate_list.append(0)\ndf_test['fuel_rate'] = fuel_rate_list\n\n# в трейне\naccel_list = []\nfor i in range(len(df_train.super_gen)):\n    if '\"acceleration\":' in df_train.super_gen.iloc[i]:\n        accel_list.append(float(re.split(r',', re.split(\n            r'\"acceleration\":', df_train.super_gen.iloc[i])[1][:4])[0].replace('}', '')))\n    else:\n        accel_list.append(0)\ndf_train['acceleration'] = accel_list\n\nclearance_list = []\nfor i in range(len(df_train.super_gen)):\n    if '\"clearance_min\":' in df_train.super_gen.iloc[i]:\n        clearance_list.append(float(re.split(r',', re.split(\n            r'\"clearance_min\":', df_train.super_gen.iloc[i])[1][:5])[0].replace('}', '')))\n    else:\n        clearance_list.append(0)\ndf_train['clearance'] = clearance_list\n\nfuel_rate_list = []\nfor i in range(len(df_train.super_gen)):\n    if '\"fuel_rate\":' in df_train.super_gen.iloc[i]:\n        if ',' in re.split(r'\"fuel_rate\":', df_train.super_gen.iloc[i])[1][:5]:\n            fuel_rate_list.append(float(re.split(r',', re.split(\n                r'\"fuel_rate\":', df_train.super_gen.iloc[i])[1][:5])[0]))\n        elif '}' in re.split(r'\"fuel_rate\":', df_train.super_gen.iloc[i])[1][:5]:\n            fuel_rate_list.append(float(re.split(r'}', re.split(\n                r'\"fuel_rate\":', df_train.super_gen.iloc[i])[1][:5])[0]))\n    else:\n        fuel_rate_list.append(0)\ndf_train['fuel_rate'] = fuel_rate_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Очистим признак equipment_dict от лишних символов\ndf_train.equipment_dict[df_train.equipment_dict !=\n                        '\"unknown\"'] = df_train.equipment_dict[df_train.equipment_dict !=\n                                                               '\"unknown\"'].apply(lambda x: x.replace(':true', '').replace('{', '').replace('}', ''))\ndf_test.equipment_dict[df_test.equipment_dict !=\n                       '\"unknown\"'] = df_test.equipment_dict[df_test.equipment_dict !=\n                                                             '\"unknown\"'].apply(lambda x: x.replace(':true', '').replace('{', '').replace('}', ''))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Значения available_options тесно пересекаются со значениями equipment_dict\n# преобразуем их в списки\nfor i in range(len(df_train['available_options'])):\n    df_train['available_options'].iloc[i] = list(re.split(',', df_train.available_options.iloc[i].replace('\"', '')))\n    df_train['equipment_dict'].iloc[i] = list(re.split(',', df_train.equipment_dict.iloc[i].replace('\"', '')))\nfor i in range(len(df_test['available_options'])):\n    df_test['available_options'].iloc[i] = list(re.split(',', df_test.available_options.iloc[i].replace('\"', '')))\n    df_test['equipment_dict'].iloc[i] = list(re.split(',', df_test.equipment_dict.iloc[i].replace('\"', '')))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Для минимизации пропусков в обоих признаков,\n# сольем их значения в призкаке available_options\nfor i in range(len(df_train)):\n    for word in df_train.equipment_dict.iloc[i]:\n        if word not in df_train.available_options.iloc[i]:\n            df_train.available_options.iloc[i].append(word)\n            \nfor i in range(len(df_test)):\n    for word in df_test.equipment_dict.iloc[i]:\n        if word not in df_test.available_options.iloc[i]:\n            df_test.available_options.iloc[i].append(word) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Удалим из признака available_options лишние значение \"unknown\"\nfor i in range(len(df_train)):\n    if len(df_train['available_options'].iloc[i]) > 1:\n        if 'unknown' in df_train['available_options'].iloc[i]:\n            df_train['available_options'].iloc[i].remove('unknown')\n            \nfor i in range(len(df_test)):\n    if len(df_test['available_options'].iloc[i]) > 1:\n        if 'unknown' in df_test['available_options'].iloc[i]:\n            df_test['available_options'].iloc[i].remove('unknown')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Удалим признаки, которые имеют только одно значение. Это столбцы Таможня и priceCurrency. \n2. Столбец владение имеет очень много пропусков (большинство значений) и, видимо, является необязательным к заполнению на auto.ru, также он не несет какой-либо важной информации, так что его мы тоже удалим.\n3. Также мы удалим признак vehicleConfiguration, так как по факту другие признаки дублируют информацию из него.\n4. Так как я не знаю, как продуктивно можно использовать фото автомобилей, то колонку с ссылками на них мы тоже удалим, а вместе с ним удалим признак с ссылками на конкретные объявления о продаже. \n5. Удалим признак complectation_dict, так как всю полезную информацию мы из него вытащили и он больше не нужен. Тоже самое с признаком equipment_dict, так как его данные мы соединили с available_options.","metadata":{}},{"cell_type":"code","source":"df_train.drop(['priceCurrency', 'Таможня', 'Владение',\n               'vehicleConfiguration', 'car_url', 'image', 'complectation_dict', 'equipment_dict'], axis=1, inplace=True)\ndf_test.drop(['priceCurrency', 'Состояние', 'Таможня', 'Владение',\n              'vehicleConfiguration', 'car_url', 'image', 'complectation_dict', 'equipment_dict'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обработаем числовые признаки\ndf_train['engineDisplacement'] = df_train['engineDisplacement'].apply(lambda x: float(x.replace(' LTR', '0')))\ndf_test['engineDisplacement'] = df_test['engineDisplacement'].apply(lambda x: float(x.replace(' LTR', '0')))\ndf_train['enginePower'] = df_train['enginePower'].apply(lambda x: int(x.replace(' N12', '')))\ndf_test['enginePower'] = df_test['enginePower'].apply(lambda x: int(x.replace(' N12', '')))\ndf_train['mileage'] = df_train['mileage'].apply(lambda x: int(x))\ndf_train['modelDate'] = df_train['modelDate'].apply(lambda x: int(x))\ndf_train['modelDate'] = df_train['modelDate'].apply(lambda x: int(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Признак numberOfDoors категориальный, но не ординальный, поэтому целесообразно переименовать\n# числвоые значения в слова и в последствии использовать label encoding\ndf_train['numberOfDoors'] = df_train['numberOfDoors'].apply(lambda x: 'Ноль' if x == 0 else 'Одна' if x ==\n                                                            1 else 'Две' if x == 2 else 'Три' if x ==\n                                                            3 else 'Четыре' if x == 4 else 'Пять' if x ==\n                                                            5 else x)\n# машин с одной дверью всего одна, удаим это значение, чтобы уровнять количество значений\ndf_train.drop(df_train[df_train.numberOfDoors == 'Одна'].index, inplace = True)\ndf_test['numberOfDoors'] = df_test['numberOfDoors'].apply(lambda x: 'Ноль' if x == 0 else 'Две' if x == 2 else 'Три' if x ==\n                                                          3 else 'Четыре' if x == 4 else 'Пять' if x ==\n                                                          5 else x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# удалим этот признак, т.к. он несет в себе только уже присутствующие в датасете данные\ndf_test.drop(['name'], axis=1, inplace = True)\ndf_train.drop(['name'], axis=1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Для целей данного проекта мы можем убрать модели, не представленные в тестовом датасете в категорию other.\n- Учитывая, что мы собрали марки, отличные от тестового датасета, в категорию other, будет разумно в обучающем датасете собрать модели в такую же категорию.\n- Столбец vendor означает страну производства. Данные без пропусков, но в обучающем датасете из 7, а в тестовом 2. Учитывая, что мы схлопнули наименования марок в категорию other, будет логично сделать также и для vendor. ","metadata":{}},{"cell_type":"code","source":"brand = list(pd.DataFrame(df_test['brand'].value_counts()).index)\ndf_train['brand'] = df_train['brand'].apply(lambda x: x if x in brand else 'other')\nfor i in range(len(df_train)):\n    if df_train['brand'].iloc[i]=='other':\n        df_train['model_name'].iloc[i]='other'\nfor i in range(len(df_train)):\n    if df_train['vendor'].iloc[i] not in ['EUROPEAN', 'JAPANESE']:\n        df_train['vendor'].iloc[i]='other'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# в трейновом признаке bodyType на 3 уникальных значения больше, но так как\n# они в сумме занимают всего 15 значений, то мы их удалим\nindexes = []\nindexes.append(df_train[df_train.bodyType == 'спидстер'].index.values)\nindexes.append(df_train[df_train.bodyType == 'хэтчбек 4 дв.'].index.values)\nindexes.append(df_train[df_train.bodyType == 'универсал 3 дв.'].index.values)\nflat_index = [item for sublist in indexes for item in sublist]\nprint(len(df_train[df_train.bodyType == 'спидстер'])+\n      len(df_train[df_train.bodyType == 'хэтчбек 4 дв.'])+\n      len(df_train[df_train.bodyType == 'универсал 3 дв.']))\ndf_train.drop(flat_index, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Данные в признаке model_info также повторяют уже существующие, удалим эти признаки в датасетах\ndf_train.drop(['model_info'], axis=1, inplace = True)\ndf_test.drop(['model_info'], axis=1, inplace = True)\n# а также далим признак super_gen\ndf_train.drop(['super_gen'], axis=1, inplace = True)\ndf_test.drop(['super_gen'], axis=1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В данной работе не будем применять анализ самого текста в описании, т.к.вряд ли кто-либо будет продавать автомобиль, при этом негативно о нем отзываясь.Пропусков нет, следовательно, пункт обязательный к заполнению. Создадим новые признаки с количеством слов из описания, предполагая,что люди описывающие свой товар более длинно хотят его продать дороже, а также это могут быть целые компании по перепродаже авто.","metadata":{}},{"cell_type":"code","source":"df_train['word_cnt'] = df_train['description'].apply(lambda x: len(re.findall(r'\\w+', x)))\ndf_test['word_cnt'] = df_test['description'].apply(lambda x: len(re.findall(r'\\w+', x)))\n# Теперь удалим признак description\ndf_train.drop(['description'], axis=1, inplace = True)\ndf_test.drop(['description'], axis=1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Признак \"owners\" я считаю ординальным, т.к. чем менье было владельцев у автомобиля, тем луче, соответственно вручную поменяем значения признака.","metadata":{}},{"cell_type":"code","source":"df_train.owners = df_train.owners.apply(lambda x: int(1 if x == '3 или более' else 2 if x ==\n                                                      '2 владельца' else 3 if x == '1 владелец' else x))\ndf_test.owners = df_test.owners.apply(lambda x: int(1 if x == '3 или более' else 2 if x ==\n                                                    '2\\xa0владельца' else 3 if x == '1\\xa0владелец' else x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавим новый признак: количество доступных \"наворотов\" в автомобиле\ndf_train['options_cnt'] = df_train['available_options'].apply(lambda x: len(x))\ndf_test['options_cnt'] = df_test['available_options'].apply(lambda x: len(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Распределим признаки по категориям,\n# также уберем available_options, т.к. с ним будем работать отдельно, также вынесем за скобки признак owners\nnum_cols_p = ['engineDisplacement', 'enginePower', 'mileage',\n            'modelDate', 'parsing_unixtime', 'price', 'productionDate',\n            'acceleration', 'clearance', 'fuel_rate', 'word_cnt',\n            'options_cnt']\nnum_cols = ['engineDisplacement', 'enginePower', 'mileage',\n            'modelDate', 'parsing_unixtime', 'productionDate',\n            'acceleration', 'clearance', 'fuel_rate',\n            'word_cnt', 'options_cnt']\ncat_cols = ['bodyType', 'brand', 'color', 'fuelType', 'model_name',\n            'numberOfDoors', 'vehicleTransmission', 'vendor',\n            'gear_type']\nbin_cols = ['vehiclePassport', 'wheel']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Поработаем с пропусками в acceleration, clearance и fuel_rate","metadata":{}},{"cell_type":"code","source":"# Создадим словарь где каждой марке автомобиля будет соответствовать среднее ускорение по этой марке\naccel_dict_train = dict(df_train[df_train.acceleration != 0].groupby(\n    ['brand'])['acceleration'].mean())\naccel_dict_test = dict(df_test[df_test.acceleration != 0].groupby(\n    ['brand'])['acceleration'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Машин марки ADLER, DELAGE, АС и BRABUS представлено всего по одной,\n# удалим их из датасета\ndf_train.drop(df_train[df_train.brand == 'ADLER'].index, inplace = True)\ndf_train.drop(df_train[df_train.brand == 'DELAGE'].index, inplace = True)\ndf_train.drop(df_train[df_train.brand == 'AC'].index, inplace = True)\ndf_train.drop(df_train[df_train.brand == 'BRABUS'].index, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Заменим неизвестные значения признака acceleration на средние для каждой марки\nfor i in df_train.brand[df_train.acceleration == 0]:\n    df_train.acceleration[df_train.acceleration == 0] = accel_dict_train[i]\nfor i in df_test.brand[df_test.acceleration == 0]:\n    df_train.acceleration[df_train.acceleration == 0] = accel_dict_test[i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Удалим неизвестные значения из признака clearance, тк их всего 67 и они скорее всего связаны\n# с эксклюзивными машинами, а не с потоковыми\nindexes = []\nfor i in range(len(df_train[df_train.clearance == 0])):\n    indexes.append(df_train[df_train.clearance == 0].index[i])\ndf_train.drop(indexes, inplace = True)\n# в тестовой выборке произведем те же манипуляции как и с призаком acceleration\nclear_dict_test = dict(df_test[df_test.clearance != 0].groupby(\n    ['brand'])['clearance'].mean())\nfor i in df_test.brand[df_test.clearance == 0]:\n    df_train.clearance[df_train.clearance == 0] = clear_dict_test[i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Также заполним пропущенные значения в fuel_rate\nfuel_dict_train = dict(df_train[df_train.fuel_rate != 0].groupby(\n    ['brand'])['fuel_rate'].mean())\nfuel_dict_test = dict(df_test[df_test.fuel_rate != 0].groupby(\n    ['brand'])['fuel_rate'].mean())\nfor i in df_train.brand[df_train.fuel_rate == 0]:\n    df_train.fuel_rate[df_train.fuel_rate == 0] = fuel_dict_train[i]\nfor i in df_test.brand[df_test.fuel_rate == 0]:\n    df_train.fuel_rate[df_train.fuel_rate == 0] = fuel_dict_test[i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in num_cols_p:\n    statistic(i, df_train)\n# Почти в каждом числовом признаке есть выбросы","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# как и в тесте\nfor i in num_cols:\n    statistic(i, df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in(num_cols_p):\n    graph_num(col, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В принципе, все указанные выбросы не вляются ошибкой и имеют право на жизнь, так, например, в обьявлении с самым длинным текстом действительно куча осмысленного текста, который в основном, описывает почему человек не хочет продавать свою машину дешевле установленной цены. Отальные качественные данные автомобилей, такие как объем двигателя или мощность, являясь выбросом, при этом не являются ошибкой, т.к. нам представленны сильно отличающиеся друг от друга автомобили.","metadata":{}},{"cell_type":"markdown","source":"Очень заметно, что отличаются с точки зрения выбросов столбцы с информацией о времени парсинга объяления. Тестовый столбец очевидно собирался в разное время, в то время как обучающий датасет парсился единым блоком за один раз. В связи с этим будет разумно удалить столбцы из датасетов, т.к. модель скорее исказится.","metadata":{}},{"cell_type":"code","source":"df_train.drop(['parsing_unixtime'], axis='columns', inplace=True)\ndf_test.drop(['parsing_unixtime'], axis='columns', inplace=True)\nnum_cols.remove('parsing_unixtime')\nnum_cols_p.remove('parsing_unixtime')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Построим тепловую матрицу корреляций для обучающего датасета\nplt.figure(figsize=(8, 7), dpi=80)\nsns.heatmap(df_train[num_cols_p].corr().abs(), vmin=0,\n            vmax=1, annot=True, cmap='inferno')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Построим тепловую матрицу корреляций для тестового датасета\nplt.figure(figsize=(8, 7), dpi= 80)\nsns.heatmap(df_test[num_cols].corr().abs(), vmin=0, vmax=1, annot=True, cmap = 'inferno')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Мы видим серьёзную корерляцию между датой модели и датой производства. Это логично, т.к. модели создаются, выпускаются, а потом снимаются с производства, когда появляется новое поколение моделей. Удалим столбец дата модели, т.к. он менее информативный. Также наблюдается значительная корреляция между объёмом двигателя и его мощностью, оставим оба параметра, т.к. они оказывают влияние и на дальнейшую стоимость владения(транспортный налог), что также является базой для принятия решения.","metadata":{}},{"cell_type":"code","source":"df_train.drop(['modelDate'], axis='columns', inplace=True)\ndf_test.drop(['modelDate'], axis='columns', inplace=True)\nnum_cols_p.remove('modelDate')\nnum_cols.remove('modelDate')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на распределение бинарных признаков\nfig, axes = plt.subplots(2, 1, figsize=(10,4))\naxes = axes.flatten()\nfor i in range(len(bin_cols)):\n    sns.countplot(x=bin_cols[i], data=df_train, ax=axes[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Объединяем трейн и тест в один датасет\n#Сразу отделяем столбец \ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['price'] = 0\ndf_train_d = df_train.copy()\ndf_test_d = df_test.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# объединяем трейн с тестом для дальнейшей работы с ними\ndata = df_test_d.append(df_train_d, sort=False).reset_index(drop=True) \ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data.to_csv('data.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data = pd.read_csv('./data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#num_cols = ['engineDisplacement', 'enginePower', 'mileage', 'productionDate',\n#            'acceleration', 'clearance', 'fuel_rate',\n#            'word_cnt', 'options_cnt', 'owners']\n#cat_cols = ['bodyType', 'brand', 'color', 'fuelType', 'model_name',\n#            'numberOfDoors', 'vehicleTransmission', 'vendor',\n#            'gear_type']\n#bin_cols = ['vehiclePassport', 'wheel']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Перекодируем значения бинарных признаков, а также признак model_name, в котором очень много уникальных элементов\nle = LabelEncoder()\nfor col in bin_cols:\n    le.fit(data[col]) \n    data[col] = le.transform(data[col])\n    data[col] = data[col].astype('uint8')\ndata['model_name'] = data['model_name'].astype('category').cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# добавим новые признаки, которые являются комбинациями числовых признаков\npoly = PolynomialFeatures(2, include_bias=False)\npoly_data = poly.fit_transform(data[num_cols])[:, len(num_cols):]\npoly_cols = poly.get_feature_names()[len(num_cols):]\npoly_df = pd.DataFrame(poly_data, columns=poly_cols)\ndata = data.join(poly_df,  how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на значимость числовых признаков к искомому\n#plt.figure(figsize=(10, 20), dpi=80)\n#F, _ = f_regression(data[data['sample'] == 1][num_cols +\n#                                              poly_cols], data[data['sample'] == 1]['price'])\n#pd.Series(F, index=[num_cols+poly_cols]\n#          ).sort_values(ascending=False).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Удалим наименее значимые числовые признаки\n#data.drop(['x2 x8', 'x0 x4', 'x4 x9', 'x4 x7', 'x2 x7', 'x7^2', 'x1 x2'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим манекены для категориальных признаков с малым количеством уникальных элементов\n#dummy_cols = []\n#for i in pd.get_dummies(\n#    data, columns=['bodyType', 'brand', 'color', 'fuelType',\n#                  'numberOfDoors', 'vehicleTransmission', 'vendor',\n#                   'gear_type'], dummy_na=False).columns[72:]:\n#    dummy_cols.append(i)\ndata = pd.get_dummies(\n   data, columns=['fuelType','numberOfDoors', 'vehicleTransmission', 'vendor',\n                  'gear_type', 'bodyType', 'brand', 'color'], dummy_na=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим манекены на опции автомобилей,\n# на 150 самых часто встречающихся опций\noption_list = []\nfor i in data.available_options:\n    option_list.append(i)\n#        list(i.replace('[', '').replace(']', '').replace(\"'\", '').split(', ')))\n# Если сохранять и запускать data для быстрой последующей обработки,\n# датафрейм перестает хранить признак available_options как список\nflat_opt = [item for sublist in option_list for item in sublist]\nopt_dict = Counter(flat_opt)\nlist_opt = list(opt_dict.items())\nlist_opt.sort(key=lambda i: i[1])\ndf = pd.DataFrame()\ndf = df.append(list_opt[143:])\noption_cols = []\nfor i in df[0]:\n    option_cols.append(i)\nfor i in option_cols:\n    data['option:'+i] = 0\nfor i in tqdm(option_cols):\n    for n in range(len(data.available_options)):\n        if i in data.available_options.iloc[n]:\n            data['option:'+i].iloc[n] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим на значимость категориальных признаков к искомому\n#plt.figure(figsize=(16, 40), dpi=100)\n#mi = mutual_info_regression(\n#    data[data['sample'] == 1][option_cols], data[data['sample'] == 1]['price'])\n#pd.Series(mi, index=[option_cols]\n#          ).sort_values(ascending=True).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#option_list = []\n#df = pd.DataFrame()\n#for i in data.available_options:\n#    for n in i:\n#        if n not in option_list:\n#            option_list.append(n)\n#for i in option_list:\n#    data['option:'+i] = 0\n#for i in tqdm(option_list):\n#    for n in range(len(data.available_options)):\n#        if i in data.available_options.iloc[n]:\n#            data['option:'+i].iloc[n] = 1    \n#option_cols = []\n#for i in option_list:\n#    option_cols.append('option:'+i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создавать из available_option манекены - очень сильно разширить датасет,\n# что с ним еще можно сделть помимо простого подсчета достоинств я не знаю,\n# так что прото удалим этот признак\ndata.drop(['available_options'], axis='columns', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Разделим объединённый датасет на тестовый и обучающий, как было изначально.\ndf_train = data.query('sample == 1').drop(['sample'], axis=1)\ndf_test = data.query('sample == 0').drop(['sample', 'price'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.reset_index(inplace=True)\ndf_test.reset_index(inplace=True)\ndf_train.drop(['index'], axis = 1, inplace = True)\ndf_test.drop(['index'], axis = 1, inplace = True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sell_id = df_test.sell_id\nY = df_train['price']\nX = df_train.drop([\"sell_id\", \"price\"], axis=1)\ntest = df_test.drop([\"sell_id\"], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, Y, test_size=0.20, random_state=42, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Подготовим датафрейм, в который мы будем аккумулировать результаты по моделям,\n# чтобы записывать результаты и сравнивать их в единой таблице.\ndf_cum = pd.DataFrame(columns=['MAPE','model'])\ndf_cum.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Создадим \"наивную\" модель \nЭта модель будет предсказывать среднюю цену по модели двигателя (engineDisplacement). \nC ней будем сравнивать другие модели.\n\n\n","metadata":{}},{"cell_type":"code","source":"tmp_train = X_train.copy()\ntmp_train['price'] = y_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Находим median по экземплярам engineDisplacement в трейне и размечаем тест\npredict = X_test['engineDisplacement'].map(tmp_train.groupby('engineDisplacement')['price'].median())\n\n#оцениваем точность\nm = mape(y_test, predict.values)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'Наивная', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost   \nУ нас в данных практически все признаки категориальные. Специально для работы с такими данными была создана очень удобная библиотека CatBoost от Яндекса.","metadata":{"papermill":{"duration":0.037164,"end_time":"2020-10-26T12:47:03.997616","exception":false,"start_time":"2020-10-26T12:47:03.960452","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_cb = CatBoostRegressor(iterations = 5000,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          silent=True,\n                         )\nmodel_cb.fit(X_train, y_train,\n         #cat_features=cat_features_ids,\n         eval_set=(X_test, y_test),\n         verbose_eval=0,\n         use_best_model=True,\n         #plot=True\n         )\n# оцениваем точность\npredict = model_cb.predict(X_test)\nm = mape(y_test, predict)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{"papermill":{"duration":67.991521,"end_time":"2020-10-26T12:48:12.178488","exception":false,"start_time":"2020-10-26T12:47:04.186967","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'Cat_boost', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost логарифмированный\nПопробуем прологарифмировать таргет и посмотреть на результаты.","metadata":{}},{"cell_type":"code","source":"model_cbl = CatBoostRegressor(iterations = 5000,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          silent=True,\n                         )\nmodel_cbl.fit(X_train, np.log(y_train),\n         #cat_features=cat_features_ids,\n         eval_set=(X_test, np.log(y_test)),\n         verbose_eval=0,\n         use_best_model=True,\n         #plot=True\n         )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_test = np.exp(model_cbl.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Логарифмирование улучшило результат. Попробуем засабмиттить результат на лидерборд.","metadata":{}},{"cell_type":"code","source":"predict_submission = np.exp(model_cbl.predict(test))\nsub['price'] = predict_submission\nsub.to_csv('sub_cbl.csv', index=False)\nsub.sample(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'Cat_boost, логарифмированный', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DecisionTreeRegressor - Деревья регрессии¶\nПопробуем запустить решающее дерево и оценить результат.","metadata":{}},{"cell_type":"code","source":"model_dtr = DecisionTreeRegressor(random_state=RANDOM_SEED)\nmodel_dtr.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(model_dtr.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'DecisionTree', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNeighborsRegressor - Метод k-ближайших соседей (регрессия)","metadata":{}},{"cell_type":"code","source":"model_knr = KNeighborsRegressor(n_neighbors=5)\nmodel_knr.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(model_knr.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'KNeighborsRegressor', m)\ndf_cum","metadata":{"papermill":{"duration":0.082055,"end_time":"2020-10-26T12:48:14.270602","exception":false,"start_time":"2020-10-26T12:48:14.188547","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBRegressor","metadata":{}},{"cell_type":"code","source":"xgb_reg = XGBRegressor(alpha=1, n_estimators=150)\nxgb_reg.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(xgb_reg.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'XGBRegressor', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RandomForestRegressor","metadata":{"papermill":{"duration":0.08168,"end_time":"2020-10-26T12:48:14.435554","exception":false,"start_time":"2020-10-26T12:48:14.353874","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_rfr = RandomForestRegressor(150, random_state=RANDOM_SEED, verbose=True)\nmodel_rfr.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(model_rfr.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{"papermill":{"duration":0.080788,"end_time":"2020-10-26T12:48:14.596978","exception":false,"start_time":"2020-10-26T12:48:14.51619","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'RandomForest', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ExtraTreesRegressor","metadata":{}},{"cell_type":"code","source":"model_etr = ExtraTreesRegressor(n_estimators=130, random_state=RANDOM_SEED)\nmodel_etr.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(model_etr.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'ExtraTreesRegressor', m)\ndf_cum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_submission = np.exp(model_etr.predict(test))\nsub['price'] = predict_submission\nsub.to_csv('sub_etr.csv', index=False)\nsub.sample(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BaggingRegressor","metadata":{}},{"cell_type":"code","source":"model_br = BaggingRegressor(n_estimators=150,n_jobs=10, random_state=RANDOM_SEED)\nmodel_br.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(model_br.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'BaggingRegressor', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GradientBoosting","metadata":{}},{"cell_type":"code","source":"model_gb = GradientBoostingRegressor(n_estimators=150,random_state =RANDOM_SEED)\nmodel_gb.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(model_gb.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'GradientBoosting', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AdaBoostRegressor","metadata":{}},{"cell_type":"code","source":"model_ab = AdaBoostRegressor(n_estimators=150,random_state =RANDOM_SEED)\nmodel_ab.fit(X_train, np.log(y_train))\n\npredict_test = np.exp(model_ab.predict(X_test))\nm = mape(y_test, predict_test)\nprint(f\"Точность модели по метрике MAPE: {m}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Запишем эти данные в таблицу\ndf_cum = cumulated_res(df_cum, 'AdaBoost', m)\ndf_cum","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Отсортируем результаты по убыванию MAPE","metadata":{}},{"cell_type":"code","source":"df_cum.sort_values('MAPE', ascending=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Интересно, что CatBoost, показав лучшую МАРЕ, в лидерборде оказался вторым, уступив ExtraTreesRegressor. Важно, что при сабмите не происходит значительного ухудшения результата, это значит, что модель не переобучена. Ближе к дедлайну появилась идея: через тексты описаний отбраковать новые машины компаний, которые продают их в категории 'поддержанные' (которые стоят как новые), но времени уже не хватило. -)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}