{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook deals with audio classification using librosa and tensorflow","metadata":{}},{"cell_type":"markdown","source":"## There are a lot of ways by which we can process an audio file to feed it in a neural network. Though there are multiple ways but all work on a single principal which is to manipulate the data into tha data which we require( tabular -> numerical form) and then feed it to a neural network. ","metadata":{}},{"cell_type":"markdown","source":"### In this notebook I have explained the method of working with a audio files to convert it to a tabular form for building a model.","metadata":{}},{"cell_type":"markdown","source":"### Importing the required modules","metadata":{}},{"cell_type":"code","source":"import IPython.display as ipd \nimport librosa\nimport pandas as pd\nimport os\nimport numpy as np\nfrom tqdm import tqdm\n\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import LabelEncoder\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense , Activation , Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading the data","metadata":{}},{"cell_type":"code","source":"# reading the files\naudio_dataset_path = '../input/urbansound8k/'\n\n# loading the csv\nmeta_data = pd.read_csv('../input/urbansound8k/UrbanSound8K.csv')\nmeta_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting features using librosa","metadata":{}},{"cell_type":"code","source":"# do feature extraction using librosa\ndef features_extract(file):\n    # load the audio file\n    audio,sample_rate = librosa.load(file_name,res_type='kaiser_fast')\n    \n    # extract the features\n    feature = librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=50)\n    \n    # feature scaling\n    scaled_feature = np.mean(feature.T,axis=0)\n    \n    # return the scaled features\n    return scaled_feature\n\n# list containg all the features\nextracted = []\n\n# for each row in the csv\nfor index_num,row in tqdm(meta_data.iterrows()):\n    \n    # get the file \n    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row['slice_file_name']))\n    \n    # get file label\n    final_class_labels = row['class']\n    \n    # extract feature\n    data= features_extract(file_name)\n    \n    # store it in a list\n    extracted.append([data,final_class_labels])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a new dataframe from the extracted features","metadata":{}},{"cell_type":"code","source":"# create na new dataframe\nextracted_df = pd.DataFrame(extracted,columns=['feature','class'])\n\n# display first fivve rows of the dataframe\nextracted_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribute the data to X and Y","metadata":{}},{"cell_type":"code","source":"# get the data as a list and send it to np.array() \n# function to convert it into an array \nx = np.array(extracted_df['feature'].tolist())\ny = np.array(extracted_df['class'].tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use encoding to encode the string labels to an integer","metadata":{}},{"cell_type":"code","source":"# label encoding to get encoding\nle = LabelEncoder()\n\n# transform each category with it's respected label\nY = to_categorical(le.fit_transform(y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split the data into train and test sets","metadata":{}},{"cell_type":"code","source":"# split the data to train and test set\nx_train, x_test, y_train, y_test = train_test_split(x, Y, test_size=0.2, random_state = 42)\n\n# print the details\nprint(\"Number of training samples = \", x_train.shape[0])\nprint(\"Number of testing samples = \",x_test.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Built the model","metadata":{}},{"cell_type":"code","source":"# Construct model \nnum_labels = Y.shape[1]\nmodel = Sequential()\n\nmodel.add(Dense(256, input_shape=(50,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128))\n\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile the model \n#### optimizer-> adam\n#### loss function -> Categorical Cross Entropy","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=['accuracy'],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting the model with a batch size of 32 for 150 epochs","metadata":{}},{"cell_type":"code","source":"num_epochs = 150\nnum_batch_size = 32\n\nmodel.fit(\n          x_train, \n          y_train, \n          batch_size=num_batch_size, \n          epochs=num_epochs,\n          validation_data=(x_test, y_test),\n         )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the model","metadata":{}},{"cell_type":"markdown","source":"### Create a function to extract feature from test audio","metadata":{}},{"cell_type":"code","source":"# function to extract features from the audion file\ndef extract_feature(file_name):\n    # load the audio file\n    audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n    \n    # get the feature \n    feature = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=50)\n    \n    # scale the features\n    feature_scaled = np.mean(feature.T,axis=0)\n    \n    # return the array of features\n    return np.array([feature_scaled])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print the result of test audio by feeding it to model","metadata":{}},{"cell_type":"code","source":"# function to predict the feature\ndef print_prediction(file_name):\n    \n    # extract feature from the function defined above\n    prediction_feature = extract_feature(file_name) \n    \n    # get the id of label using argmax\n    predicted_vector = np.argmax(model.predict(prediction_feature), axis=-1)\n    \n    # get the class label from class id\n    predicted_class = le.inverse_transform(predicted_vector)\n    \n    # display the result\n    print(\"The predicted class is:\", predicted_class[0], '\\n') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### testing an audio","metadata":{}},{"cell_type":"code","source":"# File name\nfile_name = '../input/urbansound8k/fold8/103076-3-0-0.wav'\n\n# get the output\nprint_prediction(file_name)\n\n# play the file\nipd.Audio(file_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}