{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#lets load the required packages and libraries for data analysis\nimport numpy as np \nimport pandas as pd\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#For data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the training and test datasets\ntrain_df = pd.read_csv('../input/train.csv')\n\ntest_df = pd.read_csv('../input/test.csv')                                                               \n              ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets take a look at our training data\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now the test dataset\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets see what kind of data we have to work with\ntrain_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing out a list of all the columns in our training dataset\ntrain_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing summary statistics\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe(include='O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()/ len(train_df) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum()/ len(test_df) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot('Sex',data=train_df)\ntrain_df['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparing the Sex feature against Survived\nsns.barplot(x='Sex',y='Survived',data=train_df)\ntrain_df.groupby('Sex',as_index=False).Survived.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparing the Pclass feature against Survived\nsns.barplot(x='Pclass',y='Survived',data=train_df)\ntrain_df[[\"Pclass\", \"Survived\"]].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparing the Embarked feature against Survived\nsns.barplot(x='Embarked',y='Survived',data=train_df)\ntrain_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Parch',y='Survived',data=train_df)\ntrain_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='SibSp',y='Survived',data=train_df)\ntrain_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's start off by dropping the coulmns we will not be needing\ndrop_list=['Cabin','Ticket','PassengerId']\n\ntrain_df = train_df.drop(drop_list,axis=1)\ntest_passenger_df = pd.DataFrame(test_df.PassengerId)\ntest_df = test_df.drop(drop_list,axis=1)\n\ntest_passenger_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling the missing Embarked values in train and test datasets\ntrain_df.Embarked.fillna('S',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling the missing values in the Age column\ntrain_df.Age.fillna(28, inplace=True)\ntest_df.Age.fillna(28, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filling the null Fare values in test dataset\ntest_df.Fare.fillna(test_df.Fare.median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining train and test dataframes to work with them simultaneously\nCombined_data = [train_df, test_df]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extracting the various title in Names column\nfor dataset in Combined_data:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n#Plotting the various titles extracted from the names    \nsns.countplot(y='Title',data=train_df)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Refining the title feature by merging some titles\nfor dataset in Combined_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Special')\n\n    dataset['Title'] = dataset['Title'].replace({'Mlle':'Miss','Ms':'Miss','Mme':'Mrs'})\n    \ntrain_df.groupby('Title',as_index=False)['Survived'].mean().sort_values(by='Survived',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets see the distribution of the title feature\nsns.countplot(y='Title',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mapping the title names to numeric values\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Special\": 5}\nfor dataset in Combined_data:\n    dataset['Title'] = dataset.Title.map(title_mapping)\n    dataset['Title'] = dataset.Title.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a new feature IsAlone from the SibSp and Parch columns\nfor dataset in Combined_data:\n    dataset[\"Family\"] = dataset['SibSp'] + dataset['Parch']\n    dataset[\"IsAlone\"] = np.where(dataset[\"Family\"] > 0, 0,1)\n    dataset.drop('Family',axis=1,inplace=True)\ntrain_df.head()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the Name,SibSP and Parch columns\nfor dataset in Combined_data:\n    dataset.drop(['SibSp','Parch','Name'],axis=1,inplace=True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating another feature if the passenger is a child\nfor dataset in Combined_data:\n    dataset[\"IsMinor\"] = np.where(dataset[\"Age\"] < 15, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Old_Female'] = (train_df['Age']>50)&(train_df['Sex']=='female')\ntrain_df['Old_Female'] = train_df['Old_Female'].astype(int)\n\ntest_df['Old_Female'] = (test_df['Age']>50)&(test_df['Sex']=='female')\ntest_df['Old_Female'] = test_df['Old_Female'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting categorical variables into numerical ones\ntrain_df2 = pd.get_dummies(train_df,columns=['Pclass','Sex','Embarked'],drop_first=True)\ntest_df2 = pd.get_dummies(test_df,columns=['Pclass','Sex','Embarked'],drop_first=True)\ntrain_df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating Age bands\ntrain_df2['AgeBands'] = pd.qcut(train_df2.Age,4,labels=False) \ntest_df2['AgeBands'] = pd.qcut(test_df2.Age,4,labels=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating Fare bands\ntrain_df2['FareBand'] = pd.qcut(train_df2.Fare,7,labels=False)\ntest_df2['FareBand'] = pd.qcut(test_df2.Fare,7,labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the Age and Fare columns\ntrain_df2.drop(['Age','Fare'],axis=1,inplace=True)\ntest_df2.drop(['Age','Fare'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2.head()\n#sns.barplot('AgeBands','Survived',data=train_df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting out training data into X: features and y: target\nX = train_df2.drop(\"Survived\",axis=1) \ny = train_df2[\"Survived\"]\n\n#splitting our training data again in train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\ny_pred = logreg.predict(X_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nacc_logreg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's perform some K-fold cross validation for logistic Regression\ncv_scores = cross_val_score(logreg,X,y,cv=5)\n \nnp.mean(cv_scores)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree Classifier\n\ndecisiontree = DecisionTreeClassifier()\ndep = np.arange(1,10)\nparam_grid = {'max_depth' : dep}\n\nclf_cv = GridSearchCV(decisiontree, param_grid=param_grid, cv=5)\n\nclf_cv.fit(X, y)\nclf_cv.best_params_,clf_cv.best_score_*100\nprint('Best value of max_depth:',clf_cv.best_params_)\nprint('Best score:',clf_cv.best_score_*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest CLassifier\n\nrandom_forest = RandomForestClassifier()\nne = np.arange(1,20)\nparam_grid = {'n_estimators' : ne}\n\nrf_cv = GridSearchCV(random_forest, param_grid=param_grid, cv=5)\n\nrf_cv.fit(X, y)\nprint('Best value of n_estimators:',rf_cv.best_params_)\nprint('Best score:',rf_cv.best_score_*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbk = GradientBoostingClassifier()\nne = np.arange(1,20)\ndep = np.arange(1,10)\nparam_grid = {'n_estimators' : ne,'max_depth' : dep}\n\ngbk_cv = GridSearchCV(gbk, param_grid=param_grid, cv=5)\n\ngbk_cv.fit(X, y)\nprint('Best value of parameters:',gbk_cv.best_params_)\nprint('Best score:',gbk_cv.best_score_*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final = clf_cv.predict(test_df2)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_passenger_df[\"PassengerId\"],\n        \"Survived\": y_final\n    })\nsubmission.head()\nsubmission.to_csv('titanic.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}