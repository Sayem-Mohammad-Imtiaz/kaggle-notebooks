{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **1. Introduction**\n\n\nAs it is being a part of our lives, Covid-19 has been most popular topic in the world for about one year. Thus, Covid-19 Dataset is used for this study. The most neccessary and basic tools were be explained in this notebook. Moreover, outputs were examined and and try to be explained.\n\nThis notebook has now some basic applications and it will be developed in time.","metadata":{}},{"cell_type":"markdown","source":"## Contents:\n\n1. [First look at data](#1)\n2. [Correlations between features](#2)\n3. [Basic Visualization Practices](#3)\n4. [Other Visualization Tools](#4)\n      * [Seaborn](#5)\n\n\n#### Also look at this topics: [(filtering pandas dataframe)](#filter) [(list comprehension)](#lc) [(creating dataframe from list)](#creatingdataframefromlist)...","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdate\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T18:58:24.960883Z","iopub.execute_input":"2021-05-25T18:58:24.961381Z","iopub.status.idle":"2021-05-25T18:58:24.970018Z","shell.execute_reply.started":"2021-05-25T18:58:24.961348Z","shell.execute_reply":"2021-05-25T18:58:24.968809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/covid_19_data.csv\") #importing dataframe as data","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:24.971495Z","iopub.execute_input":"2021-05-25T18:58:24.971833Z","iopub.status.idle":"2021-05-25T18:58:25.29459Z","shell.execute_reply.started":"2021-05-25T18:58:24.971804Z","shell.execute_reply":"2021-05-25T18:58:25.293454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"1\"> </a><br>\n# 1. First Look at Data\n\nAfter importing our dataframe, we use functions like head(), info(), columns, describe() for the first examination.\n\n\n<span style=\"color:red\">head() :</span> Our imported dataframe normally has lots of rows, but we may want a quick look. We use head() to look determined number of rows of our dataframe.\n\n<span style=\"color:red\">info() :</span> It is used to see which columns takes which type of value. Also, it shows which features has how many non-nan value in default parameter.\n\n<span style=\"color:red\">columns :</span> In order to see features' -columns- names, it is used.\n\n<span style=\"color:red\">describe() :</span> It gives some statistical data of our features such as mean value and quartiles. ","metadata":{}},{"cell_type":"code","source":"print(data.head(3)) # first look at data, it gives us first 3 rows of dataframe  \nprint(\"-------------------------------------------------------------------------\")\nprint(\"-------------------------------------------------------------------------\")\nprint(data.info(null_counts = False)) # Look at columns and their types\nprint(\"-------------------------------------------------------------------------\")\nprint(\"-------------------------------------------------------------------------\")\nprint(data.columns)  # Shows dataframe's features -columns- .\nprint(\"-------------------------------------------------------------------------\")\nprint(\"-------------------------------------------------------------------------\")\nprint(data.describe())\n\n# data.tail()  # It is kind of reverse of head() function, it gives last 5 rows of dataframe\n\n\"\"\"\ndata.head(n): \"n\" rows will be returned. Default \"n\" is 5.\ndata.info(null_counts = False) : If it is True, null_counts parameter shows non null counts.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:25.296609Z","iopub.execute_input":"2021-05-25T18:58:25.29696Z","iopub.status.idle":"2021-05-25T18:58:25.367916Z","shell.execute_reply.started":"2021-05-25T18:58:25.296931Z","shell.execute_reply":"2021-05-25T18:58:25.366816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To see how many different terms are avaliable for a feature, we use unique() function\n\n\ndata[\"Country/Region\"].unique()  # Shows unique \"Countries/Regions\" terms in our dataframe.\n\n\n# pd.unique(data[\"Country/Region\"])  #2nd way to use it . both way works","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:25.370335Z","iopub.execute_input":"2021-05-25T18:58:25.370644Z","iopub.status.idle":"2021-05-25T18:58:25.400804Z","shell.execute_reply.started":"2021-05-25T18:58:25.370614Z","shell.execute_reply":"2021-05-25T18:58:25.3997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you see, there would be lots of unique terms in a feature. If we want to determine how many different value in  a feature, we can use for loop to determine it. An \"for loop\" construction can be found below for our example.","metadata":{}},{"cell_type":"code","source":"# Number of different \"Country/Region\" is;\n\nsay = data[\"Country/Region\"].unique()\ncount = 0\n\nfor i in say: \n    count = count + 1\nprint(\"Number of different Country/Region:\",count)\n\n# As a result, we see there is 226 different \"Country/Region\" in this dataframe.","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:25.402255Z","iopub.execute_input":"2021-05-25T18:58:25.402552Z","iopub.status.idle":"2021-05-25T18:58:25.43081Z","shell.execute_reply.started":"2021-05-25T18:58:25.402523Z","shell.execute_reply":"2021-05-25T18:58:25.429646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"2\"> </a><br>\n# 2. Correlations between Features\n\nTo understand relations between numerical values, correlations methods have been developed. Thus, we may need this correlations when we ara mess around with some complicated data. Finding this correlation coefficient enable us to know if two numerical features are directly proportional or not.\n\nTo see correlation, we can use corr() function in pandas. In our dataframe, there is 4 numerical features (it is seen above with datainfo()). But one of them is unnecessary to investigate (the \"SNo\" feature). Thus we'll drop this feature before calculate the correlation coefficients.","metadata":{}},{"cell_type":"code","source":"data_corre = data.drop(\"SNo\", axis = 1) # \"SNo\" column and its values dropped. \n\n# corr() method enables us to calculate correlation with different methods by using its method parameter. \n\ncorre1 = data_corre.corr(method ='pearson')   # standard correlation coefficient\ncorre2 = data_corre.corr(method ='kendall')   # Kendall Tau correlation coefficient\ncorre3 = data_corre.corr(method ='spearman')  # Spearman rank correlation\n\n\nprint(\"Standard Correlation Coefficients\")\nprint(corre1)\nprint(\"-------------------------------------\")\nprint(\"Kendall Tau Correlation Coefficients\")\nprint(corre2)\nprint(\"-------------------------------------\")\nprint(\"Spearman Rank Correlation Coefficients\")\nprint(corre3)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:25.43243Z","iopub.execute_input":"2021-05-25T18:58:25.43275Z","iopub.status.idle":"2021-05-25T18:58:25.861858Z","shell.execute_reply.started":"2021-05-25T18:58:25.432722Z","shell.execute_reply":"2021-05-25T18:58:25.860719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also visualize this correlation with correlation map.\n\nCorrelation Map according to standard correlation method is figured below;","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(15, 13))   # Adjusting size of figure.\nsns.heatmap(corre1, annot= True, fmt= '.2f',cmap=\"YlGnBu\") \nplt.show()\n\n# The parameters that is used;\n# annot : Gives the numerical values in map.\n# fmt : used to formatting the value.\n# cmap : Changes the color of map. There are lots of options. E.g. \"spring\",\"bwr\",\"hsv\",\"Greens\"...","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:25.863097Z","iopub.execute_input":"2021-05-25T18:58:25.863373Z","iopub.status.idle":"2021-05-25T18:58:26.106241Z","shell.execute_reply.started":"2021-05-25T18:58:25.863347Z","shell.execute_reply":"2021-05-25T18:58:26.105017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nSimply, there is higher correlation when there is a closer correlation coefficient to 1.As you guess, there is a high correlation level between confirmed covid-19 cases and covid-19 deaths.\n\n\nI also thought there would be a high correlation coefficient between confirmed covid-19 cases and recovered covid 19. \n\n\nTo understand understand why the correlation coefficient is low, I investigated the data. And, I found some issues that mislead our data analysis. When I filtered data for just USA, I realised, the Recovered column of dataframe mostly takes the \"0\" value. The number of recovered patients was not indicated with confirmed cases and deaths. The recovered patients were indicated in different rows. The recovered patients were given as sum of all Provinces/States and was shown as different \"Province/State\" below \"Province/State\". \n\n<a href=\"https://ibb.co/LhzZ1rg\"><img src=\"https://i.ibb.co/XkZCtD5/kaggle.png\" alt=\"kaggle\" border=\"0\" /></a>\n\nIt is obvious that this condition spoils our correlation coefficients for \"Recovered\" value. To get better correlation chart, we can drop this value. However, I need investigate if there is \"Recovered\" value in the other columns like the column  \"Province/State\".\n\nTo determine that, we may use for loop. The for loop construcion was coded below.","metadata":{}},{"cell_type":"code","source":"for a in data.columns:\n    \n    list1 = list(data[a])\n    \n    count = 0\n    \n    for i in list1:\n        if(i == \"Recovered\"):\n            count= count + 1\n        else:\n            count = count\n    \n    print(\" The number of \"\"'Recovered'\"\" value inside {} column is {}\".format(a,count))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:26.107772Z","iopub.execute_input":"2021-05-25T18:58:26.108087Z","iopub.status.idle":"2021-05-25T18:58:26.703052Z","shell.execute_reply.started":"2021-05-25T18:58:26.10806Z","shell.execute_reply":"2021-05-25T18:58:26.702026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We detected just \"Province/State\" has \"Recovered\" value. Also taking account of the fact that we discussed above, we understood some countries like USA share their recovered patienst data as sum of all states in different rows. Thus, calculating correlation coefficients after dropping this countries from dataframe will give better results. That is why we firstly need detecting this countries and we will be able drop them.\n\nTo detect this countries we will use filtering. Filtering dataframe is used for access some rows of dataframe which is in desired condition.\n\n<a id = \"filter\"> </a><br>\n### How to Filter Pandas Dataframe\n\nFor our case, we need  rows whose \"Province/State\" column's values are \"Recovered\" . So our filter is;\n\n\nfilter1 =  data[\"Province/State\"] == \"Recovered\"  \n\n\nAnd we apply this filter to our dataframe.\n\n\nfiltered_data = data[filter1]\n","metadata":{}},{"cell_type":"code","source":"filter1 = data[\"Province/State\"] == \"Recovered\"\nfiltered_data = data[filter1]\nfiltered_data.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:26.704759Z","iopub.execute_input":"2021-05-25T18:58:26.705088Z","iopub.status.idle":"2021-05-25T18:58:26.762285Z","shell.execute_reply.started":"2021-05-25T18:58:26.705057Z","shell.execute_reply":"2021-05-25T18:58:26.761351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After we get filtered dataframe, we need to detect which countries are included in our filtered dataframe. Thus we will make use of unique() function. After we detect the countries, we will filtered our original dataframe and apply corr() function on it to obtain correlation coefficint for cleared data.","metadata":{}},{"cell_type":"code","source":"filtered_data[\"Country/Region\"].unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:26.763481Z","iopub.execute_input":"2021-05-25T18:58:26.763915Z","iopub.status.idle":"2021-05-25T18:58:26.77312Z","shell.execute_reply.started":"2021-05-25T18:58:26.76387Z","shell.execute_reply":"2021-05-25T18:58:26.771979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you see, \"US\" and \"Canada\" are the only countries that mislead our correlation calculations. Thus we will recalculate correlations coefficients by excluding \"US\" and \"Canada\".\n","metadata":{}},{"cell_type":"code","source":"datacleared = data[(data[\"Country/Region\"] != \"US\") & (data[\"Country/Region\"] != \"Canada\")]\ndata_correlation = datacleared.drop(\"SNo\",axis=1) # dropping SNo column for correlations calculations\n\n\ndata_correlation.corr() ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:26.77427Z","iopub.execute_input":"2021-05-25T18:58:26.774552Z","iopub.status.idle":"2021-05-25T18:58:26.897377Z","shell.execute_reply.started":"2021-05-25T18:58:26.774524Z","shell.execute_reply":"2021-05-25T18:58:26.896387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result, our correlation coefficient between \"Confirmed\" and \"Recovered\" rise to 0.82 after we cleared our dataframe.\n\n\nOur dataframe includes the first announcements of the countries, but there will delay for that there will be someone who recovered after first case was confirmed.\n\nFor example, we take first 11 days of Turkey;\n\n<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/pjRjpf8/kaggle2.png\" alt=\"kaggle2\" border=\"0\" /></a>\n\n\n\n\nAs it is seen, there are 1872 confirmed patient while there is no recovered one in the second week. There is no recovered one until 2 week last. Thus, we understand that there is a delay between confirmed status and recovered. Scientifically, this is about 10-12 days. And this fact leads our correlation between \"Confirmed\" and \"Recovered\". For a better correlation we need next 10 days' recovered data. Otherwise, we can ignore 10-12 days after the countries' first announcements.\n\nHowever, we will simply ignore the rows that has \"0\" \"Recovered\" value. And we will see how it affects our correlation coefficient.","metadata":{}},{"cell_type":"code","source":"datacleared2 = data[(data[\"Country/Region\"] != \"US\") & (data[\"Country/Region\"] != \"Canada\") & (data[\"Recovered\"] != 0 ) ]\ndata_correlation2 = datacleared2.drop(\"SNo\",axis=1)\ndata_correlation2.corr() ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:26.901996Z","iopub.execute_input":"2021-05-25T18:58:26.902294Z","iopub.status.idle":"2021-05-25T18:58:27.023641Z","shell.execute_reply.started":"2021-05-25T18:58:26.902265Z","shell.execute_reply":"2021-05-25T18:58:27.022553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"3\"> </a><br>\n# 3. Basic Visualization Tools\n\nWhile we examine the dataframe, visualization of data is so vital. To accomplish this we will practice some types of plots by using pandas.DataFrame.plot() and matplotlib library.\n\nIn this section we will see;\n\n* [Line Plot](#line) \n* [Scatter Plot](#scatter)\n* [Bar Plot](#bar)\n* [Histogram Plot](#hist)\n* [Pie Chart](#pie)\n* [Boxplot](#box)","metadata":{}},{"cell_type":"markdown","source":"As a result, our correlation coefficient between \"Confirmed\" and \"Recovered\" rise to 0.82 after we cleared our dataframe.\n\n\nOur dataframe includes the first announcements of the countries, but there will delay for that there will be someone who recovered after first case was confirmed.\n\nFor example, we take first 11 days of Turkey;\n\n<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/pjRjpf8/kaggle2.png\" alt=\"kaggle2\" border=\"0\" /></a>\n\n\n\n\nAs it is seen, there are 1872 confirmed patient while there is no recovered one in the second week. There is no recovered one until 2 week last. Thus, we understand that there is a delay between confirmed status and recovered. Scientifically, this is about 10-12 days. And this fact leads our correlation between \"Confirmed\" and \"Recovered\". For a better correlation we need next 10 days' recovered data. Otherwise, we can ignore 10-12 days after the countries' first announcements.\n\nHowever, we will simply ignore the rows that has \"0\" \"Recovered\" value. And we will see how it affects our correlation coefficient.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"line\"> </a><br>\n### Line Plot\n\nLine plot is probably the most basic plot and the simplest way of visualization.\n\n\nIt can be used for the purpose of attaining some mathematical functions like (y=x^2).\n","metadata":{}},{"cell_type":"code","source":"x = np.linspace(1,100, 100)  # creating an array by numpy for x-axis values\n\nplt.plot(x, x**2)  # y = x^2\nplt.xlabel(\"x values\")  # naming x axis\nplt.ylabel(\"y values\")  # naming y axis\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:27.026342Z","iopub.execute_input":"2021-05-25T18:58:27.026812Z","iopub.status.idle":"2021-05-25T18:58:27.17715Z","shell.execute_reply.started":"2021-05-25T18:58:27.026766Z","shell.execute_reply":"2021-05-25T18:58:27.175941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In our dataframe, our data values change depends on date. Thus, the line plots are also perfect tools to visualize in this condition.\n\nBefore visualization, we filter our dataframe for just one country and examine its \"Confirmed\" values and \"Recovered\" values changing by time.","metadata":{}},{"cell_type":"code","source":"data_turkey = data[data[\"Country/Region\"]== \"Turkey\"]  # Firstly, data is filtered. \n\n# Plot generated with filtered is created with code below;\n\nf,ax = plt.subplots(figsize=(15, 10)) # Adjusting size of figure.\nplt.plot(data_turkey['ObservationDate'],data_turkey['Confirmed'], label = \"Confirmed Covid-19\",color = \"red\") \nplt.plot(data_turkey['ObservationDate'],data_turkey['Recovered'], label = \"Recovered Covid-19\", color =\"green\",linestyle = 'dotted')\nlocator = mdate.MonthLocator()                # 1*\nplt.gca().xaxis.set_major_locator(locator)    # 2*\nplt.legend(loc='upper left')  # loc parameters determine the location of the legend\nplt.xlabel('time')            # naming x axis\nplt.ylabel('value * 10^6,')   # naming y axis\nplt.title('Confirmed and Recovered Covid-19 values for months')   # naming title of plot         \nplt.show()\n\n# (1) and (2) code line is used to change x axis from \"day by day\" to monthly. \n# Without this arrangement, x axis cannot be read.\n# To do this, I also imported \"matplotlib.dates\"","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:27.178567Z","iopub.execute_input":"2021-05-25T18:58:27.178878Z","iopub.status.idle":"2021-05-25T18:58:27.58417Z","shell.execute_reply.started":"2021-05-25T18:58:27.17885Z","shell.execute_reply":"2021-05-25T18:58:27.583319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we look at the plot, there is a sudden increase to 1.75 million in December. To learn what happened in December, we'll search what happened in Turkey with the key words \"Turkey\" \"covid\" \"increase\" \"december\" \"case\" \"1.75 million\". After a quick investigation we'll see that Turkey goverment did not count asymptomatic cases as confirmed case and did not share this number. Thus, a misleading occured in our data. After all cases(including asymptomatic cases) was anounced as confirmed case, it ended up with sudden increase.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"scatter\"> </a><br>\n### Scatter Plot\n\nBy using scatter plots, we have closer look at two numerical variable and see the relations between them. For example, we detected high correlation between \"Confirmed\" and \"Deaths\" values above. We can see this high correlation between this two features.","metadata":{}},{"cell_type":"code","source":"data_turkey.plot(kind = \"scatter\", x='Deaths',y='Confirmed',grid = True,color = \"black\", s = 10 ,figsize=(15,10))\nplt.xlabel('Deaths')             \nplt.ylabel('Confirmed')\nplt.title('Scatter Plot')  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:27.58538Z","iopub.execute_input":"2021-05-25T18:58:27.58596Z","iopub.status.idle":"2021-05-25T18:58:27.789182Z","shell.execute_reply.started":"2021-05-25T18:58:27.585915Z","shell.execute_reply":"2021-05-25T18:58:27.788388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We generate this plot by using pandas.DataFrame.plot. We also get same plot by using matplotlib.**","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(15, 10))\nplt.scatter(data_turkey[\"Deaths\"],data_turkey[\"Confirmed\"],color = \"red\")\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:27.790422Z","iopub.execute_input":"2021-05-25T18:58:27.79099Z","iopub.status.idle":"2021-05-25T18:58:27.993527Z","shell.execute_reply.started":"2021-05-25T18:58:27.790949Z","shell.execute_reply":"2021-05-25T18:58:27.992037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a discontinuity in the scatter plot. This because of the same reason that leads sudden increase in line plot above. That Turkey anounced all cases made number of \"Confirmed\" case increase while it has no impact on number of \"Deaths\". After all cases anounced, confirmed case suddenly rise up to 1.75 million, but there is no such increase in deaths\n\nAs a comparison, if we look at the neighbouring countries of Turkey -Bulgaria and Greece-, there are full continuities in their plots. That confirms our comments.","metadata":{}},{"cell_type":"code","source":"data_greece = data[(data[\"Country/Region\"]== \"Greece\") ] \n\ndata_greece.plot(kind = \"scatter\", x='Deaths',y='Confirmed',grid = True,color = \"blue\",figsize=(10,7),marker = \"v\")\nplt.xlabel('Deaths')             \nplt.ylabel('Confirmed')\nplt.title('Scatter Plot') \nplt.show()\n\ndata_bulgaria = data[(data[\"Country/Region\"]== \"Bulgaria\") ]\n\ndata_bulgaria.plot(kind = \"scatter\", x='Deaths',y='Confirmed',grid = True,color = \"green\",figsize=(10,7),marker = \"d\",s = 40)\nplt.xlabel('Deaths')             \nplt.ylabel('Confirmed')\nplt.title('Scatter Plot')\nplt.show()\n\n\n# Parameters of plot;\n# kind: determines the whether it is scatter plot or bar plot or something else......\n# x,y: determines what x axis and y axis indicates\n# grid: actives the grids in the backgrounds.\n# color: Color can be changed with this parameter.\n# figsize=(x,y): determines the width(x) and height(y) of plot\n# marker: determines the type of marker\n# s: determines the size of marker","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:27.994975Z","iopub.execute_input":"2021-05-25T18:58:27.995299Z","iopub.status.idle":"2021-05-25T18:58:28.435664Z","shell.execute_reply.started":"2021-05-25T18:58:27.995267Z","shell.execute_reply":"2021-05-25T18:58:28.434718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"bar\"> </a><br>\n### Bar Plot\n\nBar plots is used in order to obtain a categorical feature terms' distribution for numerical feature.\n\nIn our dataframe, we have USA data for all States. So we can obtain recent \"Confirmed\" case distribution in terms of States of America. Also, same plot was obtained for China where pandemic started. ","metadata":{}},{"cell_type":"code","source":"data_usa = data[(data[\"Country/Region\"]== \"US\") & (data[\"ObservationDate\"]== \"01/19/2021\")]  # filtering dataframe for most recent situation and USA\n\n# data_usa= data[(filter1) & (filter2)] that is how we apply more than one filter to our dataframe\n\n\nf,ax = plt.subplots(figsize=(20, 10)) # Adjusting size of figure.\nplt.bar(data_usa[\"Province/State\"],data_usa[\"Confirmed\"])\nplt.xticks(rotation=90)  # Rotates x axis label 90 degree.            \nplt.ylabel('Confirmed Cases (10^6)')\nplt.show()\n\n\ndata_china = data[(data[\"Country/Region\"]== \"Mainland China\") & (data[\"ObservationDate\"]== \"01/19/2021\") ]\n\nf,ax = plt.subplots(figsize=(20, 10))\nplt.bar(data_china[\"Province/State\"],data_china[\"Confirmed\"])\nplt.xticks(rotation=90)\nplt.ylabel('Confirmed Cases')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:28.439026Z","iopub.execute_input":"2021-05-25T18:58:28.439323Z","iopub.status.idle":"2021-05-25T18:58:30.0246Z","shell.execute_reply.started":"2021-05-25T18:58:28.439295Z","shell.execute_reply":"2021-05-25T18:58:30.023797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After compared two countries, China seems to beat coronavirus as we hear from news.\n\nPlotting this bar plot by seperately is enough to compare two country, but seeing them in one figure would be better for our understanding. So we will combine two dataframe and visulaze from it.\n\nTo do this we have two options; append() and concat() functions.\n\nTo promote visualization, we also change color of bar depends on country. To do that we code a loop or as a better choice we will make use of list comprehension.\n\n<a id = \"lc\"> </a><br>\n### List Comprehension\n\nWhen we want to create other list from a list, list comprehension is very helpful tool to achive that. We can code this command in just one line while we normally use for-while to do that.\n\nFor example;\n\nlist1 = [1,2,3,4,5]\n\nIn a case that we need a list that contains squares of number from list1, we normally can use for loop;\n\nlist=[]\nfor i in list1\n    list2.append(i**2)\n\nBut we can use list comprehension instead of this. It will reduce our code line into 1 with a easy sytnax.\n\nlist2 = [ i**2 for i in list1]\n\nAlso we can use if conditionals while using list comprehension.\n\nlist3 = [ i**3 if i<3 else i if i == 3 else i**2 for i in list1 ] \n\n\nIn our case, we we add new feature(color) by using list comprehension. Then USA will be blue and China will be red in plot. ","metadata":{}},{"cell_type":"code","source":"data_combined_usa_china = data_usa.append(data_china)  # combining two dataframes(for USA and China) by append()\ndata_combined_usa_china2 = pd.concat([data_usa,data_china],axis = 0 )  # combining two dataframes(for USA and China) by concatenating\n\ndata_combined_usa_china[\"color\"] = [ \"blue\" if i == \"US\" else \"red\" for i in data_combined_usa_china[\"Country/Region\"]]    #  using list comprehension with pandas dataframe\ndata_combined_usa_china2[\"color\"] = [ \"blue\" if i == \"US\" else \"red\" for i in data_combined_usa_china[\"Country/Region\"]]   #  using list comprehension with pandas dataframe\n\n\npd.concat([data_combined_usa_china.head(3),data_combined_usa_china.tail(3)],axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:30.025524Z","iopub.execute_input":"2021-05-25T18:58:30.025801Z","iopub.status.idle":"2021-05-25T18:58:30.054199Z","shell.execute_reply.started":"2021-05-25T18:58:30.025774Z","shell.execute_reply":"2021-05-25T18:58:30.051649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(20, 10))\nplt.bar(data_combined_usa_china[\"Province/State\"],data_combined_usa_china[\"Confirmed\"], color = data_combined_usa_china.color)\nplt.ylabel('Confirmed Cases')\nplt.xticks(rotation=90)\nplt.title(\"Bar Plot of combined data by appending\")\nplt.show()\n\n\nf,ax = plt.subplots(figsize=(20, 10))\nplt.bar(data_combined_usa_china2[\"Province/State\"],data_combined_usa_china2[\"Confirmed\"],color = data_combined_usa_china2[\"color\"])\nplt.ylabel('Confirmed Cases')\nplt.xticks(rotation=90)\nplt.title(\"Bar Plot of combined data by concatenating\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:30.055942Z","iopub.execute_input":"2021-05-25T18:58:30.056618Z","iopub.status.idle":"2021-05-25T18:58:32.734306Z","shell.execute_reply.started":"2021-05-25T18:58:30.056553Z","shell.execute_reply":"2021-05-25T18:58:32.73349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"hist\"> </a><br>\n### Histogram Plot\n\nHistogram plot is a type of bar plot. It is great to obtain how often a value has repeated in a feature.\n\nOur dataframe is not perfect to understand histogram plots, so we will not use our dataframe to take get it.","metadata":{}},{"cell_type":"code","source":"x = [1,1,2,5,1,3,5,9,5,7,8,6,8,1,5,3,4,6,8,7,9,5,8]\nprint(\"we will have bar plot of x: {} \".format(x))\n\nf,ax = plt.subplots(figsize=(20, 10))\nplt.hist(x, bins = 50)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:32.735548Z","iopub.execute_input":"2021-05-25T18:58:32.735848Z","iopub.status.idle":"2021-05-25T18:58:32.993442Z","shell.execute_reply.started":"2021-05-25T18:58:32.73582Z","shell.execute_reply":"2021-05-25T18:58:32.99246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"pie\"> </a><br>\n### Pie Chart\n\nPie charts are statistical graphics shaped like pie as the its name indicates. Every slice of pie represents a different term of a categorie. Percentages of each term is visuluazed in the chart.\n\nIn this part, you'll firs find a pie chart example belowe. Then we'll arrange our dataframe. After that, visualize it by pie chart. ","metadata":{}},{"cell_type":"code","source":"labels = [\"Bus\",\"Plane\",\"Boat\"]\nvalues = [620,340,50]\n\nf,ax = plt.subplots(figsize=(10, 10))\nplt.pie(values, labels = labels,autopct='%1.1f%%')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:32.994636Z","iopub.execute_input":"2021-05-25T18:58:32.994895Z","iopub.status.idle":"2021-05-25T18:58:33.109047Z","shell.execute_reply.started":"2021-05-25T18:58:32.99487Z","shell.execute_reply":"2021-05-25T18:58:33.108191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From our data, we visualize confirmed covid-19 percantages for three countries (US, China, Turkey) at their last announcement.\n\n\nWe need also import other csv file for this application to code it easier. The new dataframe is below:","metadata":{}},{"cell_type":"code","source":"data2 = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_confirmed.csv\") # importing the other data\ndata2.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:33.110305Z","iopub.execute_input":"2021-05-25T18:58:33.11061Z","iopub.status.idle":"2021-05-25T18:58:33.337776Z","shell.execute_reply.started":"2021-05-25T18:58:33.110567Z","shell.execute_reply":"2021-05-25T18:58:33.336751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen in dataframe, this dataset gives all announcement in one row. By using this dataframe, we'll take countries last announcement and we combine rows of a country that has several states.","metadata":{}},{"cell_type":"code","source":"a = data2.groupby(\"Country/Region\").sum()\nlast_announcements = a.iloc[:,[-1]]  # taking their last announcement\nlast_announcements.rename(columns={'{}'.format(last_announcements.columns[0]) : \"Confirmed\"},inplace=True) # changing the column name \nprint(last_announcements)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:33.338983Z","iopub.execute_input":"2021-05-25T18:58:33.339383Z","iopub.status.idle":"2021-05-25T18:58:33.358934Z","shell.execute_reply.started":"2021-05-25T18:58:33.339339Z","shell.execute_reply":"2021-05-25T18:58:33.357633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now, we can get \"US\",\"China\" and \"Turkey\" from this dataframe. To pick this countries for loop will be used.","metadata":{}},{"cell_type":"code","source":"countries = [\"US\",\"Turkey\",\"China\"]\n\nfor i in last_announcements.index:\n    if i in countries:\n        continue\n    else:\n        last_announcements.drop(last_announcements.index[last_announcements.index == i],inplace=True)\n        \nprint(last_announcements)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:33.360069Z","iopub.execute_input":"2021-05-25T18:58:33.360354Z","iopub.status.idle":"2021-05-25T18:58:33.473812Z","shell.execute_reply.started":"2021-05-25T18:58:33.360325Z","shell.execute_reply":"2021-05-25T18:58:33.472872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n  # This works to explode our chart as figured below\nlabels = last_announcements.index  # labels assigned to index (\"Country/Region\")\nf,ax = plt.subplots(figsize=(13, 13))\nplt.pie(last_announcements[\"Confirmed\"], labels= labels ,explode=(0.15,0.1,0.1),autopct='%1.1f%%' )\nplt.title(\"Proportion of Confirmed Covid-19 among 3 Country\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:33.475096Z","iopub.execute_input":"2021-05-25T18:58:33.475375Z","iopub.status.idle":"2021-05-25T18:58:33.711773Z","shell.execute_reply.started":"2021-05-25T18:58:33.475347Z","shell.execute_reply":"2021-05-25T18:58:33.710846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"box\"> </a><br>\n### Boxplot\n\nBoxplot shows us median, quartiles, max, min and outliers of the numerical data.\n\n\nFor a example:\n\nlist1 = [10,20,30,35,36,38,42,48,63,72,73,75,79,99,250] \n\n\n(Median and quartiles of this list are respectively 48,35,75.) ","metadata":{}},{"cell_type":"code","source":"list1 = [10,20,30,35,36,38,42,48,63,72,73,75,79,99,250] \n\nf,ax = plt.subplots(figsize=(7, 7))\nplt.boxplot(list1)\nplt.title(\"Boxplot\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:33.713254Z","iopub.execute_input":"2021-05-25T18:58:33.713672Z","iopub.status.idle":"2021-05-25T18:58:33.832771Z","shell.execute_reply.started":"2021-05-25T18:58:33.71363Z","shell.execute_reply":"2021-05-25T18:58:33.831742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"4\"> </a><br>\n# 4. Other Visualization Tools\n\nWe learnt before basic plot types by making use of matplotlib. As we know basic plot, we can move on with the other visulization libraries for better analysis.\n\nAnd this section consists;\n* [Seaborn](#5)\n\n.... will be added soon.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"5\"> </a><br>\n## Seaborn\n\n\n* [Barplot](#seabornbarplot)\n* [Point Plot](#seabornpointplot)\n* [Joint Plot](#seabornjointplot)\n* [Lm Plot](#seabornlmplot)\n* [Kde Plot](#seabornkdeplot)\n* [Violin Plot](#seabornviolinplot)\n* [Box Plot](#seabornboxplot)\n* [Swarm Plot](#seabornswarmplot)\n* [Count Plot](#seaborncountplot)","metadata":{}},{"cell_type":"markdown","source":"<a id = \"seabornbarplot\"> </a><br>\n### Barplot\n\nPlotting barplot in seaborn is similiar to matplotlib. Its code is below.","metadata":{}},{"cell_type":"code","source":"data_usa = data[(data[\"Country/Region\"]== \"US\") & (data[\"ObservationDate\"]== \"01/19/2021\") ]\n\nnewindex = data_usa['Deaths'].sort_values(ascending=True).index\ndata_usa_sorted = data_usa.reindex(newindex)\n\nf,ax = plt.subplots(figsize=(18, 13))\nsns.barplot(data = data_usa_sorted, x= 'Province/State', y = 'Deaths', palette = 'Blues')\nplt.xticks(rotation=90) \nplt.show()\n\n# palette : changes color gradients of plot.\n# data    : attends data_usa as data, so we can code just  for x=\"feature1\" and y=\"feature2\" instead of x = data.feature1 and y = data.feature2","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:33.834197Z","iopub.execute_input":"2021-05-25T18:58:33.834564Z","iopub.status.idle":"2021-05-25T18:58:34.993831Z","shell.execute_reply.started":"2021-05-25T18:58:33.834531Z","shell.execute_reply":"2021-05-25T18:58:34.992865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Several features can be plotted at the same time, so we can see confirmed, deaths at same plot.\n\nAlso, horizontal bars can be achieved.","metadata":{}},{"cell_type":"code","source":"data_china = data[(data[\"Country/Region\"]== \"Mainland China\") & (data[\"ObservationDate\"]== \"01/19/2021\") ]\n\nf,ax = plt.subplots(figsize=(13, 13))\nsns.barplot(data = data_china, y= 'Province/State', x = 'Confirmed', color = \"yellow\",label = \"Confirmed\")\nsns.barplot(data = data_china, y= 'Province/State', x = 'Recovered',  color = \"green\",label = \"Recovered\")\nax.legend(loc='upper right',frameon = True)\nplt.xlabel('')             \nplt.ylabel('Province/State')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:34.995119Z","iopub.execute_input":"2021-05-25T18:58:34.995707Z","iopub.status.idle":"2021-05-25T18:58:35.638748Z","shell.execute_reply.started":"2021-05-25T18:58:34.99567Z","shell.execute_reply":"2021-05-25T18:58:35.637806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"seabornpointplot\"> </a><br>\n### Point Plot\n\nPoint plot is like line plot, but it also gives exact value in data.\n\nIn this example, we'll code for changing confirmed case of Turkey in time. For that, \"matplotlib.dates\" will be used.","metadata":{}},{"cell_type":"code","source":"data_turkey2 = data[data[\"Country/Region\"]== \"Turkey\"]\ndata_turkey2.drop(\"SNo\", axis = 1, inplace = True)\ndate_list = [i for i in data_turkey2[\"ObservationDate\"]] # creating a list that consists \"ObservationDate\" values\ndatetime_object = pd.to_datetime(date_list)  # creating datetimeindex from the list \ndata_turkey2[\"ObservationDate\"] = datetime_object # transforming \"ObservationDate\" type to datetime64\ndata_turkey2.set_index(\"ObservationDate\", inplace = True) \nturkeyaylıkort = data_turkey2.resample(\"M\").mean() # mean numerical values for months\n\n\nf,ax = plt.subplots(figsize=(18, 13))\nsns.pointplot(x = turkeyaylıkort.index , y = turkeyaylıkort.Confirmed , markers = \"X\" , color = \"red\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:35.640097Z","iopub.execute_input":"2021-05-25T18:58:35.640389Z","iopub.status.idle":"2021-05-25T18:58:35.992663Z","shell.execute_reply.started":"2021-05-25T18:58:35.640362Z","shell.execute_reply":"2021-05-25T18:58:35.991389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"seabornjointplot\"> </a><br>\n### Joint Plot\n\nJoint plots gives a relationship between two variables. In default kind, joint plot is so similiar to scatter plot (Also, there are other kinds).\n\nIt will be more clearer with sample.","metadata":{}},{"cell_type":"markdown","source":"In [Scatter Plot](#scatter), we plotted Turkey's \"Confirmed\" and \"Deaths\" relations. And this time, we will plot same relation by joint plot's \"reg\" kind. But, we now be able to have regression line thanks to \"reg\" kind of joint plot.\n\nIn joint plot, we can also see which number has been repeated how many times.","metadata":{}},{"cell_type":"code","source":"sns.jointplot(data= data_turkey, x= \"Confirmed\",y=\"Deaths\", kind = \"reg\", height=10)\n# sns.jointplot(data= data_turkey, x= \"Confirmed\",y=\"Deaths\", kind = \"kde\", height=10)\n# sns.jointplot(data= data_turkey, x= \"Confirmed\",y=\"Deaths\", kind = \"hist\", height=10)\n# sns.jointplot(data= data_turkey, x= \"Confirmed\",y=\"Deaths\", kind = \"hex\", height=10)\n# sns.jointplot(data= data_turkey, x= \"Confirmed\",y=\"Deaths\", kind = \"resid\", height=10)\n# sns.jointplot(data= data_turkey, x= \"Confirmed\",y=\"Deaths\", height=10)\n\n\"\"\"\nkind: Determines what kind of plot we will get. Kinds of jointplots are “scatter”, “kde”, “hist”, “hex”, “reg”, and “resid”.\nheight: Determines the size (height), it will be square.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:35.995463Z","iopub.execute_input":"2021-05-25T18:58:35.995829Z","iopub.status.idle":"2021-05-25T18:58:36.643864Z","shell.execute_reply.started":"2021-05-25T18:58:35.995796Z","shell.execute_reply":"2021-05-25T18:58:36.643041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another important parameter in joint plot is \"hue\". Attending another feature by \"hue\" provides us that we can also see distribution for this feature.\n\nWe will again look at relation between \"Confirmed\" and \"Deaths\". Probably \"Province/State\" feature is the only sensible feature to use this parameter(\"hue\"). In our data, we have 226 countries; however, most of them has no \"Province/State\" (they have Nan). Some of them has more than one unique \"Province/State\" term, there is nan among this terms. For example, France has 14 \"Province/State\"; however one of them is nan. Also the country like Turkey has just nan value in \"Province/State\" column.","metadata":{}},{"cell_type":"code","source":"print(\"----------------France----------------\")\ndata_france = data[data[\"Country/Region\"] == \"France\"]\nprint(data_france[\"Province/State\"].unique())\nprint(\"-----------------------------------\")\nprint(\"\")\nprint(\"----------------Turkey----------------\")\nprint(data_turkey[\"Province/State\"].unique())\nprint(\"-----------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:36.644884Z","iopub.execute_input":"2021-05-25T18:58:36.645262Z","iopub.status.idle":"2021-05-25T18:58:36.693949Z","shell.execute_reply.started":"2021-05-25T18:58:36.645234Z","shell.execute_reply":"2021-05-25T18:58:36.692953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before using \"hue\" parameter, we will find countries which has no nan in their \"Province/State\" column like USA and China (we looked USA and China above, and there was no nan values in their \"Province/State\" column). After finding these contries, we will use best suitable country for using \"hue\" parameter. ","metadata":{}},{"cell_type":"code","source":"list_country = data[\"Country/Region\"].unique()\nlista = []\n\nfor i in list_country: # This for loop is appending \"1\" or \"0\" values in empty list named \"lista\" for every country.\n                       # 0 means there is no nan value for the country.\n    \n    filter_country = data[\"Country/Region\"] == i \n    filtereddata = data[filter_country]\n    list_uniqueprovince = filtereddata[\"Province/State\"].unique()\n    \n    a=0\n    for  k in list_uniqueprovince:\n        \n        if pd.isna(k):  # pandas.isna returns True if the k value is nan \n            \n            a = a+1\n\n        else:\n            \n            a = a\n        \n    lista.append(a)\n\nindexvariable = 0\n    \nfor i in list_country: # This for loop prints desirable countries and their \"Province/State\" number.\n    \n    filter_country = data[\"Country/Region\"] == i \n    filtereddata = data[filter_country]\n    list_uniqueprovince = filtereddata[\"Province/State\"].unique()\n    \n    if lista[indexvariable] > 0:\n   \n        pass\n        \n    else:\n\n        print(\" {} has {} unique Province/State \".format(i,len(list_uniqueprovince)))\n\n    indexvariable = indexvariable + 1","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:36.695456Z","iopub.execute_input":"2021-05-25T18:58:36.696013Z","iopub.status.idle":"2021-05-25T18:58:53.426254Z","shell.execute_reply.started":"2021-05-25T18:58:36.695962Z","shell.execute_reply":"2021-05-25T18:58:53.425196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Macau and Hong Kong is actually in China, but somewhere they are taken as a country in the dataset. Normally, China was \"Mainland China\" in the dataset, but this time, there are 48 meaningless row for China (for the dataset in May 25, 2021). Thus we have actually 4 different \"Country/Region\"; US, China, Canada and Others. Among these countries, USA has lots of provinces and counties. Using US data will lead very confusing legend in plot. \"Others\" has 2 \"Province/State\", but one of 2 has almost no effect besides the other. And we have just China and Canada. By having smaller number (22), Canada is more suitable for our \"hue\" example. Thus, relation between \"Confirmed\" and \"Deaths\" for \"Province/State\" in Canada will be plotted.","metadata":{}},{"cell_type":"code","source":"data_canada = data[data[\"Country/Region\"] == \"Canada\"]\nsns.jointplot(data = data_canada, x= \"Deaths\", y= \"Confirmed\",hue = \"Province/State\", height = 12)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:53.427486Z","iopub.execute_input":"2021-05-25T18:58:53.427955Z","iopub.status.idle":"2021-05-25T18:58:55.244637Z","shell.execute_reply.started":"2021-05-25T18:58:53.427919Z","shell.execute_reply":"2021-05-25T18:58:55.243521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result of this joint plot, we can see Ontario and Quabec is in the worst condition for death and confirmed cases (in May 25 2021). But their ratio of Deaths/Confirmed Case is falling.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"seabornlmplot\"> </a><br>\n### Lm Plot\n\nLm plot is very useful tool to see linear regression.","metadata":{}},{"cell_type":"code","source":"sns.lmplot(data=data_turkey,x=\"Confirmed\",y=\"Deaths\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:55.246192Z","iopub.execute_input":"2021-05-25T18:58:55.246489Z","iopub.status.idle":"2021-05-25T18:58:55.579202Z","shell.execute_reply.started":"2021-05-25T18:58:55.24646Z","shell.execute_reply":"2021-05-25T18:58:55.578169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(data=data_canada,x=\"Confirmed\",y=\"Deaths\",hue=\"Province/State\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:55.580769Z","iopub.execute_input":"2021-05-25T18:58:55.581163Z","iopub.status.idle":"2021-05-25T18:58:59.681755Z","shell.execute_reply.started":"2021-05-25T18:58:55.581128Z","shell.execute_reply":"2021-05-25T18:58:59.6807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"seabornkdeplot\"> </a><br>\n### Kde Plot\n\nKde plot is very useful tool to distribution of features' values.","metadata":{}},{"cell_type":"code","source":"sample_list = [1,1,1,2,2,2,2,4,5,6,11,50,55,53,52,50,52,100,101,75,500]\nsns.kdeplot(data=sample_list)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:59.683375Z","iopub.execute_input":"2021-05-25T18:58:59.683815Z","iopub.status.idle":"2021-05-25T18:58:59.827145Z","shell.execute_reply.started":"2021-05-25T18:58:59.683772Z","shell.execute_reply":"2021-05-25T18:58:59.82609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data=data_turkey,x=\"Confirmed\",y=\"Deaths\",fill=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:58:59.828414Z","iopub.execute_input":"2021-05-25T18:58:59.828725Z","iopub.status.idle":"2021-05-25T18:59:00.445951Z","shell.execute_reply.started":"2021-05-25T18:58:59.828694Z","shell.execute_reply":"2021-05-25T18:59:00.445108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"seabornviolinplot\"> </a><br>\n### Violin Plot\n\nViolin plot is so similiar to [Boxplot](#box).","metadata":{}},{"cell_type":"markdown","source":"<a id = \"creatingdataframefromlist\"> </a><br>\n#### Creating Dataframe from List\n\n\nCreating a dataframe from one list is done like below;\n\nlistsample = [\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\"]\ndf = pd.DataFrame(listsample)\n\nNote: For creating a dataframe from more than one list, we need to use \"zip\".\n\n","metadata":{}},{"cell_type":"code","source":"liste_price = [500,420,480,650,80,75,68,83,96,1215,1600,1350,1225,1800,1650,1100]\nticketclass = [\"B\",\"B\",\"A\",\"A\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"A\",\"B\",\"B\",\"A\",\"A\",\"B\"]\nvehiclelist= [\"plane\",\"plane\",\"plane\",\"plane\",\"bus\",\"bus\",\"bus\",\"bus\",\"bus\",\"boat\",\"boat\",\"boat\",\"boat\",\"boat\",\"boat\",\"boat\"]\n\ndf = pd.DataFrame(list(zip(vehiclelist,liste_price, ticketclass)), columns =[\"Vehicle\",'Price', 'Class']) # Creating dataframe from lists above.\ndf\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:59:00.446988Z","iopub.execute_input":"2021-05-25T18:59:00.44738Z","iopub.status.idle":"2021-05-25T18:59:00.466042Z","shell.execute_reply.started":"2021-05-25T18:59:00.447351Z","shell.execute_reply":"2021-05-25T18:59:00.464815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.violinplot(data=df,x=\"Vehicle\",y=\"Price\",hue=\"Class\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:59:00.468175Z","iopub.execute_input":"2021-05-25T18:59:00.470004Z","iopub.status.idle":"2021-05-25T18:59:00.745809Z","shell.execute_reply.started":"2021-05-25T18:59:00.469949Z","shell.execute_reply":"2021-05-25T18:59:00.744779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"seabornboxplot\"> </a><br>\n### Boxplot","metadata":{}},{"cell_type":"code","source":"sns.boxplot(data=df,x=\"Vehicle\",y=\"Price\",hue=\"Class\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:59:00.747321Z","iopub.execute_input":"2021-05-25T18:59:00.747772Z","iopub.status.idle":"2021-05-25T18:59:01.017193Z","shell.execute_reply.started":"2021-05-25T18:59:00.74772Z","shell.execute_reply":"2021-05-25T18:59:01.016057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"seabornswarmplot\"> </a><br>\n### Swarm Plot","metadata":{}}]}