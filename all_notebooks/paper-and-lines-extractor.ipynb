{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Aim of the Notebook \n\n* Given a Query, Search for related papers. \n* Papers are searched using their Title and Abstract \n* Once potential papers are searched, find specific lines in the Papers talking about the given query.\n* Using BM25 Algorithm, used for creating search engines and also to search lines in Potential papers.  \n  Read about the algorithm: [https://en.wikipedia.org/wiki/Okapi_BM25]\n* FINAL OUTCOME: Find the right papers for a given query, and then highlight/find right lines in the paper.\n* Discliamer: Data Analysis / Visualization is not done extensively. THE FOCUS IS ON CREATING ALGORITHM WHICH AND FIND RIGHT LINES IN THE PAPERS DEALING WITH THE GIVEN QUERY.\n\n    "},{"metadata":{},"cell_type":"markdown","source":"### Download the Dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install rank_bm25 nltk\n!pip install scispacy\n!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_md-0.2.4.tar.gz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport os\nimport json\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\nimport re\nimport string\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom rank_bm25 import BM25Okapi\nimport spacy\nimport  scispacy\nfrom nltk.tokenize import sent_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load All Papers (Jsons) in a Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(columns=['paper_id', 'title', 'abstract', 'body_text'])\ni = 0\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.endswith('.json')==True:\n            dic = json.loads(open(os.path.join(dirname, filename), 'r').read())\n            id  = dic['paper_id']\n            title = dic['metadata']['title']\n            if title.strip()=='':\n                title = None\n            abstract = dic['abstract']\n            abstract_list = []\n            for a in abstract:\n                t = a['text']\n                abstract_list.append(t)\n            abstract_string = '\\n'.join(abstract_list)\n            \n            if abstract_string == '':\n                abstract_string = None\n\n            body_text = dic['body_text']\n            body_texts_list = []\n            for text in body_text:\n                t = text['text']\n                body_texts_list.append(t)\n                \n            body_text_string = '\\n'.join(body_texts_list)\n            body_text_string = body_text_string.strip()\n            if body_text_string == '':\n                body_text_string = None\n                \n            df.loc[i] = [id, title, abstract_string, body_text_string]\n            i+=1\n                \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set the paper id as the index\ndf = df.set_index('paper_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Remove the null values\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Create a copy of the dataframe and work on that\ndf_work = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"# medium model\nimport en_core_sci_md\nnlp = en_core_sci_md.load(disable=[\"tagger\", \"parser\", \"ner\"])\nnlp.max_length = 2000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New stop words list \ncustomize_stop_words = [\n    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.',\n    'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da',  'dell',  'non', 'si'\n]\n\n# Mark them as stop words\nfor w in customize_stop_words:\n    nlp.vocab[w].is_stop = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = nlp.Defaults.stop_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spacy_tokenizer(sentence):\n    return [word.lemma_ for word in nlp(sentence) if not (word.like_num or word.is_stop or word.is_punct or word.is_space or len(word)==1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = ' i am a good-boy , i (am rishav) ?'\nspacy_tokenizer(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_work['body_text'] = df_work['body_text'].apply(spacy_tokenizer)\ndf_work['abstract'] = df_work['abstract'].apply(spacy_tokenizer)\ndf_work['title'] = df_work['title'].apply(spacy_tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_work['body_text'] = df_work['body_text'].apply(lambda x: ' '.join(x))\ndf_work['abstract'] = df_work['abstract'].apply(lambda x: ' '.join(x))\ndf_work['title'] = df_work['title'].apply(lambda x: ' '.join(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_work.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Paper to index mapping"},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"paper_ids = df_work.index\nid_2_paper = {}\nfor i, id in enumerate(paper_ids):\n    id_2_paper[i] = id\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's take title and abstract for paper search"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_work['append_title_abstract'] = df_work['title'] + ' ' + df_work['abstract'] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create a index of the Papers"},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = df_work['append_title_abstract'].tolist()\ntokenized_corpus = [doc.split(\" \") for doc in corpus]\nbm25 = BM25Okapi(tokenized_corpus)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Potential papers which could contain what we want"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display, Markdown","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def markdown_print(line):\n    print(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def suggestPapers(query):\n    top_20_papers = []\n    query_pre = spacy_tokenizer(query)\n    doc_scores = bm25.get_scores(query_pre)\n    doc_scores = [(score, ind) for ind, score in enumerate(doc_scores)]\n    doc_scores = sorted(doc_scores, reverse = True)\n    doc_score_top_20 = doc_scores[:20]\n    for d in doc_score_top_20:\n        i = d[1]\n        top_20_papers.append((paper_ids[i], d[0]))\n        \n    suggested_papers_dict = {}\n    for ele in top_20_papers:\n        suggested_papers_dict[ele[0]] = ele[1]\n        \n    for paper in top_20_papers[:5]:\n        markdown_print (\"Paper Id: \" +paper[0])\n        markdown_print(\"Title: \"+df.loc[paper[0]]['title'])\n        markdown_print (\"-----\")\n    return top_20_papers, suggested_papers_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stop_words,\n        max_words=200,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(12, 12))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's find the lines in the Paper talking about the given Query\n* Here, we are picking all the top 20 papers and forming a coupus of all pair from them. \n* This will be our corpus where we will be searching our query on."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_paper_lines(suggested_papers):\n    paper_lines = []\n    for paper in suggested_papers:\n        text = df.loc[paper[0]]['abstract']\n        sentences = [(sent.strip(), paper[0]) for sent in sent_tokenize(text)]\n        sentences_2_s = []\n        for i in range(0, len(sentences)-1):\n            sent1 = sentences[i][0]\n            sent2 = sentences[i+1][0]\n            sent = sent1 + ' ' + sent2\n            sentences_2_s.append((sent, sentences[i][1]))\n        paper_lines.extend(sentences_2_s)\n    return paper_lines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_wordcloud(paper_lines):\n    word_cloud_data = []\n    for line, id in paper_lines:\n        word_cloud_data.append(line)\n    show_wordcloud(word_cloud_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mapping(paper_lines):\n    id_paper_line_paper_id = {}\n    for i, tup in enumerate(paper_lines):\n        id_paper_line_paper_id[i] = (tup[0], tup[1])\n    return id_paper_line_paper_id\n\ndef create_paper_lines_index(paper_lines):\n    paper_lines_fmtd = []\n    for line in paper_lines:\n        paper_lines_fmtd.append(\" \".join(spacy_tokenizer(line[0])))\n    tokenized_paper_lines = [doc.split(\" \") for doc in paper_lines_fmtd]\n    bm25_task1 = BM25Okapi(tokenized_paper_lines)\n    return bm25_task1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def top_lines_suggestor(task, bm25_task1, id_paper_line_paper_id):\n    top_50_lines = []\n    task1_pre = spacy_tokenizer(task)\n    line_scores = bm25_task1.get_scores(task1_pre)\n    line_scores = [(score, ind) for ind, score in enumerate(line_scores)]\n    line_scores = sorted(line_scores, reverse = True)\n    line_scores_top_50 = line_scores[:50]\n    for l in line_scores_top_50:\n        i = l[1]\n        paper_id = id_paper_line_paper_id[i][1]\n        actual_line = id_paper_line_paper_id[i][0]\n        line_score = l[0]\n        paper_score = suggested_papers_dict[paper_id]\n        net_score = paper_score * line_score\n        top_50_lines.append((actual_line, net_score, paper_id))\n    top_ten_sorted = sorted(top_50_lines, key = lambda x: x[1], reverse=True)[:20]\n    for line in top_ten_sorted:\n        markdown_print (\"Paper line: \" +line[0])\n        markdown_print (\"Paper id: \" +  line[2])\n        markdown_print (\"Similarity Score: \" + str(line[1]))\n        markdown_print (\"-----\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis of Incubation periods and Recovery time"},{"metadata":{"trusted":true},"cell_type":"code","source":"task1 = 'Range of incubation periods for the disease in humans (and how this varies across age and health status) \\\nand how long individuals are contagious,even after recovery.'\nsuggested_papers, suggested_papers_dict = suggestPapers(task1)  ### TOP SUGGESTED PAPERS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task1, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prevalence of asymptomatic shedding and transmission (e.g., particularly children).**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"task2 = 'Prevalence of asymptomatic shedding and transmission (e.g., particularly children).'\nsuggested_papers, suggested_papers_dict = suggestPapers(task2)  ### TOP SUGGESTED PAPERS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task1, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).\n"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"task3 = 'Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).'\nsuggested_papers, suggested_papers_dict = suggestPapers(task3)  ### TOP SUGGESTED PAPERS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task3, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Immune response and immunity"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"task4 = 'Immune response and immunity'\nsuggested_papers, suggested_papers_dict = suggestPapers(task4)  ### TOP SUGGESTED PAPER4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task4, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Natural history of the virus and shedding of it from an infected person**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"task5 = 'Natural history of the virus and shedding of it from an infected person'\nsuggested_papers, suggested_papers_dict = suggestPapers(task5)  ### TOP SUGGESTED PAPER4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task5, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}