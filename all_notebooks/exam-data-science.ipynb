{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Understanding"},{"metadata":{},"cell_type":"markdown","source":"# Shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read summery dataset NY 2020 data from csv file\nsummery_dataset_NY_2020 = pd.read_csv('/kaggle/input/new-york-city-airbnb-2020/listings_newYork_2020_from_Airbnb.csv')\nprint(\"Shape of summery dataset NY City 2020 :\" , summery_dataset_NY_2020.shape)\n# Read summery dataset Jersey City 2020 data from csv file\nsummery_dataset_JC_2020 = pd.read_csv('/kaggle/input/jersey-city-airbnb-2020-summary/listings (4).csv')\nprint(\"Shape of summery dataset Jersey City 2020 :\" , summery_dataset_JC_2020.shape)\nsummery_dataset_LND_2020 = pd.read_csv('/kaggle/input/london-airbnb-2020-summary/london_summary.csv')\nprint(\"Shape of summery dataset London 2020 :\" , summery_dataset_LND_2020.shape)\n# Read detailed dataset NY 2020 data from csv file\ndetailed_dataset_NY_2020 = pd.read_csv('/kaggle/input/new-york-city-airbnb-2020-detailed/listings.csv')\nprint(\"Shape of detailed dataset NY City 2020 :\" , detailed_dataset_NY_2020.shape)\n# Read detailed dataset Jersey City 2020 data from csv file\ndetailed_dataset_JC_2020 = pd.read_csv('/kaggle/input/jersey-city-airbnb-2020-detailed/listings.csv')\nprint(\"Shape of detailed dataset Jersey City 2020 :\" , detailed_dataset_JC_2020.shape)\ndetailed_dataset_LND_2020 = pd.read_csv('/kaggle/input/london-airbnb-detailed/listings.csv')\nprint(\"Shape of detailed dataset London 2020 :\" , detailed_dataset_LND_2020.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_NY_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_NY_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_JC_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_LND_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prices(dataset):    \n    dataset['price'] = dataset['price'].str.replace('$', '')\n    dataset['price'] = dataset['price'].str.replace(',', '')\n    dataset['price'] = dataset['price'].astype(float)\n\nprices(detailed_dataset_NY_2020)\nprices(detailed_dataset_LND_2020)\nprices(detailed_dataset_JC_2020)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# corrolation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = detailed_dataset_NY_2020.corr()\ncorr.style.background_gradient()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(corr[\"price\"])\ncor_target.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = detailed_dataset_JC_2020.corr()\ncorr.style.background_gradient()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(corr[\"price\"])\ncor_target.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = detailed_dataset_LND_2020.corr()\ncorr.style.background_gradient()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(corr[\"price\"])\ncor_target.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Statistic details - mean, std, count,min, max,25%, 75%, 50% "},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_NY_2020.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_JC_2020.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_LND_2020.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count how many missing value in each column\nprint(\"detailed_dataset_NY_2020\")\ndetailed_dataset_NY_2020.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count how many missing value in each column\nprint(\"detailed_dataset_JC_2020\")\ndetailed_dataset_JC_2020.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count how many missing value in each column\nprint(\"detailed_dataset_LND_2020\")\ndetailed_dataset_LND_2020.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Price Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(detailed_dataset_NY_2020['price']).set_title('Price Distribution - New York City')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(detailed_dataset_JC_2020['price']).set_title('Price Distribution - Jersey City')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(detailed_dataset_LND_2020['price'] * 1.284145).set_title('Price Distribution - London')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Abnormal data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"detailed_dataset_JC_2020 num of records that price =0 :\")\nprint(len(detailed_dataset_JC_2020[detailed_dataset_JC_2020['price'] == 0]))\nprint(\"detailed_dataset_NY_2020 num of records that price =0 :\")\nprint(len(detailed_dataset_NY_2020[detailed_dataset_NY_2020['price'] == 0]))\nprint(\"detailed_dataset_LND_2020 num of records that price =0 :\")\nprint(len(detailed_dataset_LND_2020[detailed_dataset_LND_2020['price'] == 0]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Histograms"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pylab as pl\nplts = detailed_dataset_NY_2020\nplts.drop(['id', 'name', 'host_id', 'host_name','license','calendar_updated','scrape_id','bathrooms',\n       'neighbourhood','room_type','neighbourhood_group_cleansed'] ,axis=1).hist(bins=50, figsize=(80,100))\npl.suptitle(\"Histogram for each numeric input variable - detailed_dataset_NY_2020\")\nplt.savefig('detailed_dataset_NY_2020')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pylab as pl\nplts = detailed_dataset_JC_2020\nplts.drop(['id', 'name', 'host_id', 'host_name','license','calendar_updated','scrape_id','bathrooms',\n       'neighbourhood','neighbourhood_group_cleansed','room_type'] ,axis=1).hist(bins=50, figsize=(80,100))\npl.suptitle(\"Histogram for each numeric input variable - detailed_dataset_JC_2020\")\nplt.savefig('detailed_dataset_JC_2020')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pylab as pl\nplts = detailed_dataset_LND_2020\nplts.drop(['id', 'name', 'host_id', 'host_name', 'license','calendar_updated','scrape_id','bathrooms','neighbourhood_group_cleansed'\n       ,'neighbourhood','room_type'] ,axis=1).hist(bins=50, figsize=(80,100))\npl.suptitle(\"Histogram for each numeric input variable - detailed_dataset_LND_2020\")\nplt.savefig('detailed_dataset_LND_2020')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = detailed_dataset_NY_2020[detailed_dataset_NY_2020.room_type == 'Shared room']\nsns.distplot(df['price'], hist = False, kde = True, label='Shared room')\n\n\ndf = detailed_dataset_NY_2020[detailed_dataset_NY_2020.room_type == 'Private room']\nsns.distplot(df['price'], hist = False, kde = True, label='Private room')\n\ndf = detailed_dataset_NY_2020[detailed_dataset_NY_2020.room_type == 'Hotel room']\nsns.distplot(df['price'], hist = False, kde = True, label='Hotel room')\n\ndf = detailed_dataset_NY_2020[detailed_dataset_NY_2020.room_type == 'Entire home/apt']\nsns.distplot(df['price'], hist = False, kde = True, label='Entire home/apt')\n\n# Plot formatting\nplt.legend(prop={'size': 12})\nplt.title('price vs room type - New York')\nplt.xlabel('Price')\nplt.ylabel('Density') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_NY_2020.room_type.value_counts().sort_values().plot(kind = 'barh')\nprint(\"room type in New York\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_NY_2020.host_identity_verified.value_counts().sort_values().plot(kind = 'barh')\nprint(\"host identity verified in New York\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_NY_2020.host_is_superhost.value_counts().sort_values().plot(kind = 'barh')\nprint(\"host is superhost in New York\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndetailed_dataset_NY_2020.instant_bookable.value_counts().sort_values().plot(kind = 'barh')\nprint(\"instant bookable in New York\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ndef dataPreperation(dataset):\n    \n    # For entries without last review date, I filled in the missing entries in the column of the number of reviews per month = 0\n    dataset['reviews_per_month'] =dataset['reviews_per_month'].fillna(0)\n    \n    # room_type is categorial variable thus, we tranform this column to dummies\n    df2 = pd.get_dummies(dataset.room_type)\n    df2\n    dataset = pd.concat([dataset, df2], axis = 1)\n    dataset = dataset.drop('room_type',axis=1)\n    \n\n    # Clean all records with price = 0\n    len(dataset[dataset['price'] == 0])\n    dataset = dataset[dataset.price != 0]\n\n    # converted into logarithm of the prices to mitigate the impact of the outliers in the dataset\n    dataset['natural_log_price'] = np.log(dataset['price']) \n    dataset = dataset.drop('price',axis=1)\n    \n    #Normalaize\n    norm_fetures = ['calculated_host_listings_count','latitude','longitude','minimum_nights','number_of_reviews','reviews_per_month','availability_365' ]\n\n    for i in norm_fetures:\n        scaler = MinMaxScaler()\n        x = dataset[i].values.reshape(-1,1)\n        x_scaled = scaler.fit_transform(x)\n        dataset[i] = x_scaled\n    \n    # remove unnecessary columns\n    dataset = dataset.drop('id',axis=1)\n    dataset = dataset.drop('host_id',axis=1)\n    dataset = dataset.drop('name',axis=1)\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_NY_2020 = dataPreperation(summery_dataset_NY_2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_JC_2020 = dataPreperation(summery_dataset_JC_2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_LND_2020 = dataPreperation(summery_dataset_LND_2020)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xg \nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import make_scorer\nfrom sklearn.kernel_ridge import KernelRidge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_JC_2020 = summery_dataset_JC_2020.drop(['host_name','neighbourhood','last_review','neighbourhood_group'],axis=1)\nsummery_dataset_JC_2020.isnull().sum()\nsummery_dataset_JC_2020['Country'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_NY_2020 = summery_dataset_NY_2020.drop(['host_name','neighbourhood','last_review','neighbourhood_group'],axis=1)\nsummery_dataset_NY_2020.isnull().sum()\nsummery_dataset_NY_2020['Country'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_LND_2020 = summery_dataset_LND_2020.drop(['host_name','neighbourhood','last_review','neighbourhood_group'],axis=1)\nsummery_dataset_LND_2020.isnull().sum()\nsummery_dataset_LND_2020['Country'] = 1\nsummery_dataset_LND_2020 = summery_dataset_LND_2020.sample(n=1462)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_LND_2020.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_LND_NY_2020 = pd.concat([summery_dataset_LND_2020, summery_dataset_NY_2020])\nsummery_dataset_LND_NY_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summery_dataset_2020 = pd.concat([summery_dataset_JC_2020, summery_dataset_NY_2020])\nsummery_dataset_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def linearregression(X_train, X_test, y_train, y_test):\n    mlModel = LinearRegression()\n    mlModel.fit(X_train, y_train)\n    predTest = mlModel.predict(X_test)\n    print(\"Linear Regression R^2 on test split:\",r2_score(y_test,predTest))\n    print(\"Linear Regression MSE on test split:\",mean_squared_error(y_test,predTest))\n    print(\"Linear Regression MAE on test split:\",mean_absolute_error(y_test,predTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kernel_ridge(X_train, X_test, y_train, y_test):\n#     parameters = {\n#         'kernel': ['linear', 'polynomial', 'rbf']\n#          }\n#     best_params,best_score = CV_model(KernelRidge(),parameters, X_train, y_train)\n    \n#     kernelRidge = KernelRidge(**best_params)\n    kernelRidge = KernelRidge(kernel='polynomial')\n    kernelRidge.fit(X_train, y_train)\n    predTest = kernelRidge.predict(X_test)\n    print(\"kernelRidge best params:\",best_params)\n    print(\"kernelRidge R^2 on test split:\",r2_score(y_test,predTest))\n    print(\"kernelRidge MSE on test split:\",mean_squared_error(y_test,predTest))\n    print(\"kernelRidge MAE on test split:\",mean_absolute_error(y_test,predTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CV_model(model, parameters, X_train, y_train):\n    # Type of scoring used to compare parameter combinations\n    scorer = make_scorer(mean_squared_error,greater_is_better=False)\n    # Run the grid search\n    grid_obj = GridSearchCV(model, parameters, scoring=scorer, n_jobs=1, verbose=4) # 5-folds cv\n    grid_obj = grid_obj.fit(X_train, y_train)\n    return (grid_obj.best_params_, grid_obj.best_score_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_forest_regressor(X_train, X_test, y_train, y_test):\n    regr = RandomForestRegressor()\n    regr.fit(X_train, y_train)\n    predTest = regr.predict(X_test) \n    print(\"Random Forest Regressor R^2 on test split:\",r2_score(y_test,predTest))\n    print(\"Random Forest Regressor MSE on test split:\",mean_squared_error(y_test,predTest))\n    print(\"Random Forest Regressor MAE on test split:\",mean_absolute_error(y_test,predTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gradientboostingregressor(X_train, X_test, y_train, y_test):\n    GBoost = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.01)\n    GBoost.fit(X_train,y_train)\n    predTest=GBoost.predict(X_test)\n    print(\"Gradient Boosting Regressor R^2 on test split:\",r2_score(y_test,predTest))\n    print(\"Gradient Boosting Regressor MSE on test split:\",mean_squared_error(y_test,predTest))\n    print(\"Gradient Boosting Regressor MAE on test split:\",mean_absolute_error(y_test,predTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lasso(X_train, X_test, y_train, y_test):\n    lasso = Lasso(alpha=0.01)\n    lasso.fit(X_train, y_train) \n    predTest=lasso.predict(X_test)\n    print(\"Lasso R^2 on test split:\",r2_score(y_test,predTest))\n    print(\"Lasso MSE on test split:\",mean_squared_error(y_test,predTest))\n    print(\"Lasso MAE on test split:\",mean_absolute_error(y_test,predTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef xgb(X_train, X_test, y_train, y_test):\n    xgb_model = XGBRegressor()\n    xgb_model.fit(X_train, y_train) \n    predTest=xgb_model.predict(X_test)\n    print(\"xgb R^2 on test split:\",r2_score(y_test,predTest))\n    print(\"xgb MSE on test split:\",mean_squared_error(y_test,predTest))\n    print(\"xgb MAE on test split:\",mean_absolute_error(y_test,predTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modeling(X,y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n    print(X_train.shape)\n    print(X_test.shape)\n    print(y_train.shape)\n    print(y_test.shape)\n#     kernel_ridge(X_train, X_test, y_train, y_test)\n    linearregression(X_train, X_test, y_train, y_test)\n    xgb(X_train, X_test, y_train, y_test)\n    random_forest_regressor(X_train, X_test, y_train, y_test)\n    gradientboostingregressor(X_train, X_test, y_train, y_test)\n    lasso(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moddeling for summery_dataset_NY_2020 ( NYC)\ny = summery_dataset_NY_2020['natural_log_price']\nfetures = summery_dataset_NY_2020\nfetures = fetures.drop(['natural_log_price','Country'], axis=1)\nX = fetures\nmodeling(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moddeling for summery_dataset_2020 (NYC+JC)\ny = summery_dataset_2020['natural_log_price']\nfetures = summery_dataset_2020\nfetures = fetures.drop(['natural_log_price'], axis=1)\nX = fetures\nmodeling(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moddeling for summery_dataset_2020 (NYC+LND)\ny = summery_dataset_LND_NY_2020['natural_log_price']\nfetures = summery_dataset_LND_NY_2020\nfetures = fetures.drop(['natural_log_price'], axis=1)\nX = fetures\nmodeling(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read detailed dataset NY 2020 data from csv file\ndetailed_dataset_NY_2020 = pd.read_csv('/kaggle/input/new-york-city-airbnb-2020-detailed/listings.csv')\nprint(\"Shape of detailed dataset NY City 2020 :\" , detailed_dataset_NY_2020.shape)\n# Read detailed dataset Jersey City 2020 data from csv file\ndetailed_dataset_JC_2020 = pd.read_csv('/kaggle/input/jersey-city-airbnb-2020-detailed/listings.csv')\nprint(\"Shape of detailed dataset Jersey City 2020 :\" , detailed_dataset_JC_2020.shape)\ndetailed_dataset_LND_2020 = pd.read_csv('/kaggle/input/london-airbnb-detailed/listings.csv')\nprint(\"Shape of detailed dataset London 2020 :\" , detailed_dataset_LND_2020.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\n\ndef dataPreperationDetailed(dataset):\n    \n#     # Remove $ sign and change type to int\n    dataset['price'] = dataset['price'].str.replace('$', '')\n    dataset['price'] = dataset['price'].str.replace(',', '')\n    dataset['price'] = dataset['price'].astype(float)\n\n    # For entries without last review date, I filled in the missing entries in the column of the number of reviews per month = 0\n    dataset['reviews_per_month'] =dataset['reviews_per_month'].fillna(0)\n    \n    # For entries without bedrooms , I filled in the missing entries = 1\n    dataset['bedrooms'] =dataset['bedrooms'].fillna(1)\n    \n    # room_type is categorial variable thus, we tranform this column to dummies\n    dataset['room_type'].fillna(dataset['room_type'].value_counts().index[0], inplace=True)\n    df2 = pd.get_dummies(dataset.room_type,prefix=\"room_type\")\n    df2\n    dataset = pd.concat([dataset, df2], axis = 1)\n    dataset = dataset.drop('room_type',axis=1)\n    \n    # instant_bookable is categorial variable-F/T thus, we tranform this column to dummies\n    dataset['instant_bookable'].fillna(dataset['instant_bookable'].value_counts().index[0], inplace=True)\n    le = preprocessing.LabelEncoder()\n    dataset['instant_bookable'] = le.fit_transform(dataset['instant_bookable'])\n\n    \n    # host_is_superhost is categorial variable-T/F thus, we tranform this column to dummies\n    dataset['host_is_superhost'].fillna(dataset['host_is_superhost'].value_counts().index[0], inplace=True)\n    le = preprocessing.LabelEncoder()\n    dataset['host_is_superhost'] = le.fit_transform(dataset['host_is_superhost'])\n    \n    # host_identity_verified is categorial variable-T/F thus, we tranform this column to dummies\n    dataset['host_identity_verified'].fillna(dataset['host_identity_verified'].value_counts().index[0], inplace=True)\n    le = preprocessing.LabelEncoder()\n    dataset['host_identity_verified'] = le.fit_transform(dataset['host_identity_verified'])\n    \n    \n    # Clean all records with price = 0\n    len(dataset[dataset['price'] == 0])\n    dataset = dataset[dataset.price != 0]\n\n    # converted into logarithm of the prices to mitigate the impact of the outliers in the dataset\n    dataset['natural_log_price'] = np.log(dataset['price']) \n    dataset = dataset.drop('price',axis=1)\n    \n    \n    #Fill NA values with mean\n#     features_NA = ['review_scores_rating', 'review_scores_accuracy','review_scores_cleanliness', 'review_scores_checkin','review_scores_communication', 'review_scores_location','review_scores_value','bedrooms', 'beds', 'host_total_listings_count','host_listings_count']\n    dataset = dataset.fillna(dataset.mean())\n    \n    #Normalaize\n    norm_fetures = ['review_scores_rating', 'minimum_nights_avg_ntm','maximum_minimum_nights', 'review_scores_accuracy','review_scores_cleanliness', 'review_scores_checkin','review_scores_communication', 'review_scores_location','review_scores_value','accommodates','bedrooms', 'beds', 'host_total_listings_count','host_listings_count','availability_30', 'availability_60', 'availability_90','calculated_host_listings_count_entire_homes','calculated_host_listings_count_shared_rooms','calculated_host_listings_count_private_rooms','calculated_host_listings_count','latitude','longitude','minimum_nights','number_of_reviews','reviews_per_month','availability_365' ]\n    for i in norm_fetures:\n        scaler = MinMaxScaler()\n        x = dataset[i].values.reshape(-1,1)\n        x_scaled = scaler.fit_transform(x)\n        dataset[i] = x_scaled\n    \n    # remove unnecessary columns\n    dataset = dataset.drop(['property_type','maximum_nights','bathrooms_text','host_verifications','host_since','number_of_reviews_ltm', 'number_of_reviews_l30d', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'has_availability','first_review','last_review','minimum_minimum_nights', 'minimum_maximum_nights','maximum_maximum_nights','maximum_nights_avg_ntm','amenities','neighbourhood','host_has_profile_pic','host_neighbourhood','host_thumbnail_url','host_acceptance_rate','host_response_rate','host_response_time','bathrooms','calendar_updated','calendar_last_scraped','host_location','host_about','neighborhood_overview','listing_url','description','license','host_name','last_scraped','host_url','picture_url','scrape_id','host_picture_url','id','host_id','name','listing_url'],axis=1)\n    \n    return dataset\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_NY_2020 = dataPreperationDetailed(detailed_dataset_NY_2020)\ndetailed_dataset_NY_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moddeling for summery_dataset_NY_2020 ( NYC)\ny = detailed_dataset_NY_2020['natural_log_price']\nfetures = detailed_dataset_NY_2020\nfetures = fetures.drop(['natural_log_price'], axis=1)\nX = fetures\nmodeling(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_JC_2020 = dataPreperationDetailed(detailed_dataset_JC_2020)\ndetailed_dataset_JC_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_LND_2020 = dataPreperationDetailed(detailed_dataset_LND_2020)\ndetailed_dataset_LND_2020 = detailed_dataset_LND_2020.sample(n=1462)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_2020 = pd.concat([detailed_dataset_JC_2020, detailed_dataset_NY_2020])\ndetailed_dataset_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moddeling for detailed_dataset_2020 ( NYC + JC )\ny = detailed_dataset_2020['natural_log_price']\nfetures = detailed_dataset_2020\nfetures = fetures.drop(['natural_log_price'], axis=1)\nX = fetures\nmodeling(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_dataset_2020_LNDNY = pd.concat([detailed_dataset_LND_2020, detailed_dataset_NY_2020])\ndetailed_dataset_2020_LNDNY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moddeling for detailed_dataset_2020_LNDNY ( NYC + LND )\ny = detailed_dataset_2020_LNDNY['natural_log_price']\nfetures = detailed_dataset_2020_LNDNY\nfetures = fetures.drop(['natural_log_price'], axis=1)\nX = fetures\nmodeling(X,y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}