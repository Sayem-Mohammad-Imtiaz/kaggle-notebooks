{"cells":[{"metadata":{"trusted":true,"_uuid":"c2ce5543d7a6a9ce1661097f8239cacfb9d93ac2"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97816728aefddf874ead9679bd3f617a295d8b0b"},"cell_type":"code","source":"dataset = pd.read_csv('../input/indian_liver_patient.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38afec7c12bf0de1101e22b1c3c209bd672548cb"},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"484e3a226e5f1031181217542e92181846e5d834"},"cell_type":"markdown","source":"from the above we can see that 'Albumin_and_Globulin_Ratio' prpoerty have some value missing"},{"metadata":{"trusted":true,"_uuid":"ff71ea37fc3bb17d6fa79adbb17026368571a6ad"},"cell_type":"code","source":"# fill the missing values with mean of the coressponding column\ndataset['Albumin_and_Globulin_Ratio'] = dataset.Albumin_and_Globulin_Ratio.fillna(value = dataset['Albumin_and_Globulin_Ratio'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6c9ceb5ba791c6c59391d1a31805dcb72c1a981"},"cell_type":"code","source":"# let's build a correlation matrix and use seaborn to plot the heatmap of these\n# correlation matrix\ncorr_matrix = dataset.corr()\nsns.heatmap(corr_matrix,cmap=\"YlGnBu\")\n# from the heatmap, dark shades represent positive correlation and light shades represent negative correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e022b4d8587f398ce8916687244c54b94f90bfb"},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(corr_matrix,cmap=\"YlGnBu\", annot=True, linewidths=.5, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88e699a38071f5aecd6116d62d0f803620d03fc9"},"cell_type":"markdown","source":"from the above heatmap following independent varaibles are highly correlated\n1. Total_Bilirubin &  Direct_Bilirubin\n2. Alamine_Aminotransferase & Aspartate_Aminotransferase\n3. Total_Proteins & Albumin\n4. Albumin & Albumin_and_Globulin_Ratio"},{"metadata":{"trusted":true,"_uuid":"865ca440dad813fbcb9908eeb5005f8a613f441a"},"cell_type":"code","source":"# classifying data into independent and dependent variable\nX = dataset.drop(['Dataset'],axis = 1).values\ny = dataset['Dataset'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2de2a6184e35457dca1833f128b01026cbbc16ea"},"cell_type":"code","source":"# encoding the categorical data of Gender varaible\nlabelencoder = LabelEncoder()\nX[:,1] = labelencoder.fit_transform(X[:,1])\nonehotencoder = OneHotEncoder(categorical_features = [1])\nX = onehotencoder.fit_transform(X).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f00d9559493e41a4ce370743b80a616effaf25dc"},"cell_type":"code","source":"# avoid dummy varaible trap\nX = X[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9b0c7a7d953be452b1bb178787df90eeecc4bda"},"cell_type":"code","source":"# creating test and training set data\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2540dc7297b68f63dbc5d27738f4e12cbfdebf66"},"cell_type":"code","source":"# feature scaling\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6158b59703737c3c0b6c995e4665c6cb9ab99cd4"},"cell_type":"code","source":"rf_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrf_classifier.fit(X_train,y_train)\ny_pred = rf_classifier.predict(X_test)\nrf_cm = confusion_matrix(y_test, y_pred)\nrf_cr = classification_report(y_test, y_pred)\nprint(\"Accuracy Score in percentage : \\n\",round(accuracy_score(y_test,y_pred) * 100,2))\nprint(\"Random Forrest Confusion Matrix : \\n\",rf_cm)\nprint(\"Random Forrest Classification Report : \\n\",rf_cr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6edb0b340da8b7c45ed74cc727323aa919200a84"},"cell_type":"markdown","source":"from the classification report, random forrest classifier is 71% accurate"},{"metadata":{"trusted":true,"_uuid":"ad78d7b2c55463281016dbc36993d6693114f817"},"cell_type":"code","source":"# let's remove the highly correlated params and apply random forrest see whether the precision improves\n# classifying data into independent and dependent variable\nX_dropped = dataset.drop(['Dataset','Direct_Bilirubin','Aspartate_Aminotransferase','Albumin'],axis = 1).values\ny_dropped = dataset['Dataset'].values\n\n# encoding the categorical data of Gender varaible\nlabelencoder = LabelEncoder()\nX_dropped[:,1] = labelencoder.fit_transform(X_dropped[:,1])\nonehotencoder = OneHotEncoder(categorical_features = [1])\nX_dropped = onehotencoder.fit_transform(X_dropped).toarray()\n\n# avoid dummy varaible trap\nX_dropped = X_dropped[:,1:]\n\n# creating test and training set data\nX_train_dropped,X_test_dropped,y_train_dropped,y_test_dropped = train_test_split(X_dropped, y_dropped, test_size = 0.2, random_state = 0)\n\n# feature scaling\nsc = StandardScaler()\nX_train_dropped = sc.fit_transform(X_train_dropped)\nX_test_dropped = sc.transform(X_test_dropped)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42e9e345f0d900d2b6c854c0474840de60b8f06c"},"cell_type":"code","source":"rf_classifier_dropped = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrf_classifier_dropped.fit(X_train_dropped,y_train_dropped)\ny_pred_dropped = rf_classifier_dropped.predict(X_test_dropped)\nrf_cm_dropped = confusion_matrix(y_test_dropped, y_pred_dropped)\nrf_cr_dropped = classification_report(y_test_dropped, y_pred_dropped)\nprint(\"Accuracy Score in percentage : \\n\",round(accuracy_score(y_test_dropped,y_pred_dropped) * 100,2))\nprint(\"Random Forrest Confusion Matrix : \\n\",rf_cm_dropped)\nprint(\"Random Forrest Classification Report : \\n\",rf_cr_dropped)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca99ca8d86f9a0ceb570ad96caa2626787a907b6"},"cell_type":"markdown","source":"after removing the correlated variables, accuracy decreased to 62% from 71%"},{"metadata":{"trusted":true,"_uuid":"9b67150f4bc0ae516ecc8cf12b9601d7f9ce8061"},"cell_type":"code","source":"# let's create Naive Bayes model and fit the dataset\nclassifier_NB = GaussianNB()\nclassifier_NB.fit(X_train,y_train)\ny_pred = classifier_NB.predict(X_test)\ngnb_cm = confusion_matrix(y_test, y_pred)\ngnb_cr = classification_report(y_test, y_pred)\nprint(\"Accuracy Score in percentage : \\n\",round(accuracy_score(y_test,y_pred) * 100,2))\nprint(\"Naive Bayes Confusion Matrix : \\n\",gnb_cm)\nprint(\"Naive Bayes Classification Report : \\n\",gnb_cr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58f246829d479a27f24df299b86213cafee85b24"},"cell_type":"markdown","source":"from the Naive Bayes model, accuracy is at 60%"},{"metadata":{"trusted":true,"_uuid":"485078844c94ddc3fbcb3236908ee514b6c02c9d"},"cell_type":"code","source":"# applying logistic regression model to training set\n# here we are considering dropped varaibles which are correlated\nclassifier_logistic = LogisticRegression()\nclassifier_logistic.fit(X_train_dropped,y_train_dropped)\ny_pred_dropped = classifier_logistic.predict(X_test_dropped)\nlog_cm = confusion_matrix(y_test_dropped, y_pred_dropped)\nlog_cr = classification_report(y_test_dropped, y_pred_dropped)\nprint(\"Accuracy Score in percentage : \\n\",round(accuracy_score(y_test_dropped,y_pred_dropped) * 100,2))\nprint(\"Logistic Regression Confusion Matrix : \\n\",log_cm)\nprint(\"Logistic Regression Classification Report : \\n\",log_cr)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11681020793dfb86b51ae06f96ba62a9f6616c42"},"cell_type":"markdown","source":"accuracy of logistic regression is 68%"},{"metadata":{"_uuid":"8646b066a4c86a767b6e3952bfc312b89cb417f6"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}