{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport cv2\nimport numpy as np\nimport os\nfrom glob import glob\nimport math\nimport matplotlib.pyplot as plt\n\nimport re\nimport html\nimport string\nimport unicodedata\nfrom nltk.tokenize import word_tokenize\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom keras.layers import Input, Dense, LSTM, TimeDistributed, Embedding, Lambda\nfrom keras.layers import  Bidirectional, Concatenate, Dot, Activation\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.backend as K\nfrom nltk.translate.bleu_score import corpus_bleu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n\n\n\nclass SeqSelfAttention(keras.layers.Layer):\n\n    ATTENTION_TYPE_ADD = 'additive'\n    ATTENTION_TYPE_MUL = 'multiplicative'\n\n    def __init__(self,\n                 units=32,\n                 attention_width=None,\n                 attention_type=ATTENTION_TYPE_ADD,\n                 return_attention=False,\n                 history_only=False,\n                 kernel_initializer='glorot_normal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 use_additive_bias=True,\n                 use_attention_bias=True,\n                 attention_activation=None,\n                 attention_regularizer_weight=0.0,\n                 **kwargs):\n        \"\"\"Layer initialization.\n        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n        :param units: The dimension of the vectors that used to calculate the attention weights.\n        :param attention_width: The width of local attention.\n        :param attention_type: 'additive' or 'multiplicative'.\n        :param return_attention: Whether to return the attention weights for visualization.\n        :param history_only: Only use historical pieces of data.\n        :param kernel_initializer: The initializer for weight matrices.\n        :param bias_initializer: The initializer for biases.\n        :param kernel_regularizer: The regularization for weight matrices.\n        :param bias_regularizer: The regularization for biases.\n        :param kernel_constraint: The constraint for weight matrices.\n        :param bias_constraint: The constraint for biases.\n        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n                                  in additive mode.\n        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n        :param attention_activation: The activation used for calculating the weights of attention.\n        :param attention_regularizer_weight: The weights of attention regularizer.\n        :param kwargs: Parameters for parent class.\n        \"\"\"\n        super(SeqSelfAttention, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.units = units\n        self.attention_width = attention_width\n        self.attention_type = attention_type\n        self.return_attention = return_attention\n        self.history_only = history_only\n        if history_only and attention_width is None:\n            self.attention_width = int(1e9)\n\n        self.use_additive_bias = use_additive_bias\n        self.use_attention_bias = use_attention_bias\n        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n        self.bias_initializer = keras.initializers.get(bias_initializer)\n        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n        self.bias_constraint = keras.constraints.get(bias_constraint)\n        self.attention_activation = keras.activations.get(attention_activation)\n        self.attention_regularizer_weight = attention_regularizer_weight\n        self._backend = keras.backend.backend()\n\n        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n            self.Wx, self.Wt, self.bh = None, None, None\n            self.Wa, self.ba = None, None\n        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n            self.Wa, self.ba = None, None\n        else:\n            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n\n    def get_config(self):\n        config = {\n            'units': self.units,\n            'attention_width': self.attention_width,\n            'attention_type': self.attention_type,\n            'return_attention': self.return_attention,\n            'history_only': self.history_only,\n            'use_additive_bias': self.use_additive_bias,\n            'use_attention_bias': self.use_attention_bias,\n            'kernel_initializer': keras.initializers.serialize(self.kernel_initializer),\n            'bias_initializer': keras.initializers.serialize(self.bias_initializer),\n            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n            'attention_activation': keras.activations.serialize(self.attention_activation),\n            'attention_regularizer_weight': self.attention_regularizer_weight,\n        }\n        base_config = super(SeqSelfAttention, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def build(self, input_shape):\n        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n            self._build_additive_attention(input_shape)\n        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n            self._build_multiplicative_attention(input_shape)\n        super(SeqSelfAttention, self).build(input_shape)\n\n    def _build_additive_attention(self, input_shape):\n        feature_dim = int(input_shape[2])\n\n        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n                                  name='{}_Add_Wt'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n                                  name='{}_Add_Wx'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        if self.use_additive_bias:\n            self.bh = self.add_weight(shape=(self.units,),\n                                      name='{}_Add_bh'.format(self.name),\n                                      initializer=self.bias_initializer,\n                                      regularizer=self.bias_regularizer,\n                                      constraint=self.bias_constraint)\n\n        self.Wa = self.add_weight(shape=(self.units, 1),\n                                  name='{}_Add_Wa'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        if self.use_attention_bias:\n            self.ba = self.add_weight(shape=(1,),\n                                      name='{}_Add_ba'.format(self.name),\n                                      initializer=self.bias_initializer,\n                                      regularizer=self.bias_regularizer,\n                                      constraint=self.bias_constraint)\n\n    def _build_multiplicative_attention(self, input_shape):\n        feature_dim = int(input_shape[2])\n\n        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n                                  name='{}_Mul_Wa'.format(self.name),\n                                  initializer=self.kernel_initializer,\n                                  regularizer=self.kernel_regularizer,\n                                  constraint=self.kernel_constraint)\n        if self.use_attention_bias:\n            self.ba = self.add_weight(shape=(1,),\n                                      name='{}_Mul_ba'.format(self.name),\n                                      initializer=self.bias_initializer,\n                                      regularizer=self.bias_regularizer,\n                                      constraint=self.bias_constraint)\n\n    def call(self, inputs, mask=None, **kwargs):\n        input_len = K.shape(inputs)[1]\n\n        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n            e = self._call_additive_emission(inputs)\n        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n            e = self._call_multiplicative_emission(inputs)\n\n        if self.attention_activation is not None:\n            e = self.attention_activation(e)\n        if self.attention_width is not None:\n            if self.history_only:\n                lower = K.arange(0, input_len) - (self.attention_width - 1)\n            else:\n                lower = K.arange(0, input_len) - self.attention_width // 2\n            lower = K.expand_dims(lower, axis=-1)\n            upper = lower + self.attention_width\n            indices = K.expand_dims(K.arange(0, input_len), axis=0)\n            e -= 10000.0 * (1.0 - K.cast(lower <= indices, K.floatx()) * K.cast(indices < upper, K.floatx()))\n        if mask is not None:\n            mask = K.expand_dims(K.cast(mask, K.floatx()), axis=-1)\n            e -= 10000.0 * ((1.0 - mask) * (1.0 - K.permute_dimensions(mask, (0, 2, 1))))\n\n        # a_{t} = \\text{softmax}(e_t)\n        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n        a = e / K.sum(e, axis=-1, keepdims=True)\n\n        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n        v = K.batch_dot(a, inputs)\n        if self.attention_regularizer_weight > 0.0:\n            self.add_loss(self._attention_regularizer(a))\n\n        if self.return_attention:\n            return [v, a]\n        return v\n\n    def _call_additive_emission(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size, input_len = input_shape[0], input_shape[1]\n\n        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n        q = K.expand_dims(K.dot(inputs, self.Wt), 2)\n        k = K.expand_dims(K.dot(inputs, self.Wx), 1)\n        if self.use_additive_bias:\n            h = K.tanh(q + k + self.bh)\n        else:\n            h = K.tanh(q + k)\n\n        # e_{t, t'} = W_a h_{t, t'} + b_a\n        if self.use_attention_bias:\n            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n        else:\n            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n        return e\n\n    def _call_multiplicative_emission(self, inputs):\n        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n        if self.use_attention_bias:\n            e += self.ba[0]\n        return e\n\n    def compute_output_shape(self, input_shape):\n        output_shape = input_shape\n        if self.return_attention:\n            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n            return [output_shape, attention_shape]\n        return output_shape\n\n    def compute_mask(self, inputs, mask=None):\n        if self.return_attention:\n            return [mask, None]\n        return mask\n\n    def _attention_regularizer(self, attention):\n        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n        input_len = K.shape(attention)[-1]\n        indices = K.expand_dims(K.arange(0, input_len), axis=0)\n        diagonal = K.expand_dims(K.arange(0, input_len), axis=-1)\n        eye = K.cast(K.equal(indices, diagonal), K.floatx())\n        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n            attention,\n            K.permute_dimensions(attention, (0, 2, 1))) - eye)) / batch_size\n\n    @staticmethod\n    def get_custom_objects():\n        return {'SeqSelfAttention': SeqSelfAttention}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_special_chars(text):\n    re1 = re.compile(r'  +')\n    x1 = text.lower().replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n    return re1.sub(' ', html.unescape(x1))\n\n\ndef remove_non_ascii(text):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n\n\ndef to_lowercase(text):\n    return text.lower()\n\ndef remove_punctuation(text):\n    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\n\ndef replace_numbers(text):\n    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n    return re.sub(r'\\d+', '', text)\n\n\ndef remove_whitespaces(text):\n    return text.strip()\n\n\ndef remove_stopwords(words, stop_words):\n    \"\"\"\n    :param words:\n    :type words:\n    :param stop_words: from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n    or\n    from spacy.lang.en.stop_words import STOP_WORDS\n    :type stop_words:\n    :return:\n    :rtype:\n    \"\"\"\n    return [word for word in words if word not in stop_words]\n\n\ndef stem_words(words):\n    \"\"\"Stem words in text\"\"\"\n    stemmer = PorterStemmer()\n    return [stemmer.stem(word) for word in words]\n\ndef lemmatize_words(words):\n    \"\"\"Lemmatize words in text\"\"\"\n\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in words]\n\ndef lemmatize_verbs(words):\n    \"\"\"Lemmatize verbs in text\"\"\"\n\n    lemmatizer = WordNetLemmatizer()\n    return ' '.join([lemmatizer.lemmatize(word, pos='v') for word in words])\n\ndef text2words(text):\n    return word_tokenize(text)\n\ndef normalize_text( text):\n    text = remove_special_chars(text)\n    text = remove_non_ascii(text)\n    #text = remove_punctuation(text)\n    text = to_lowercase(text)\n    text = replace_numbers(text)\n    #words = text2words(text)\n    #stop_words = stopwords.words('english')\n    #words = remove_stopwords(words, stop_words)\n    #words = stem_words(words)# Either stem ovocar lemmatize\n    #words = lemmatize_words(words)\n    #words = lemmatize_verbs(words)\n\n    return text\n  \ndef normalize_corpus(corpus):\n    return [normalize_text(t) for t in corpus]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class det_gen(tensorflow.keras.utils.Sequence):\n    'Generates data from a Dataframe'\n    def __init__(self,df, tok, max_len,images_path, dim=(256,256), batch_size=8,preprocess_func=None,hist_eq=False,normalize=False,augmentation=False):\n        self.df=df\n        self.dim = dim\n        self.images_path = images_path\n        self.tok= tok\n        self.max_len = max_len\n        self.batch_size = batch_size\n        self.hist_eq = hist_eq\n        self.normalize=normalize\n        self.augmentation = augmentation\n        \n        self.nb_iteration = math.ceil((self.df.shape[0])/self.batch_size)\n        self.preprocess_func = preprocess_func\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return self.nb_iteration\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.df=self.df.sample(frac=1)\n    \n    def load_img(self, img_path):\n        \n        img = cv2.imread(img_path)\n        img =cv2.resize(img,(self.dim))\n        if self.preprocess_func is not None:\n            img=self.preprocess_func(img)\n        \n        if self.augmentation == 'train':\n            aug= AUGMENTATIONS_TRAIN(image=img)\n            img=aug['image']\n        \n        \n        if self.hist_eq:\n            img= exposure.equalize_adapthist(img)\n            \n        if self.normalize and img.max()>1:\n            img=np.array(img,np.float32)/255\n            \n        return img\n        \n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        \n        indicies = list(range(index*self.batch_size, min((index*self.batch_size)+self.batch_size ,(self.df.shape[0]))))\n        \n        images = []\n        for img_path in self.df['filename'].iloc[indicies].tolist():\n            img = self.load_img(os.path.join(self.images_path,img_path))\n            images.append(img)\n            \n            \n        \n        \n        x_batch = self.df['findings_cleaned'].iloc[indicies].tolist()\n        \n        x_batch_input = [sample[:-len(\" endseq\")] for sample in x_batch]\n        \n        x_batch_gt = [sample[len(\" startseq\"): ] for sample in x_batch]\n        \n        \n        x_batch_input = np.array(pad_sequences( self.tok.texts_to_sequences (x_batch_input),\n                          maxlen=self.max_len-1 ,\n                          padding='post',\n                          truncating='post'))\n        \n        x_batch_gt = np.array(pad_sequences( self.tok.texts_to_sequences (x_batch_gt),\n                          maxlen=self.max_len-1 ,\n                          padding='post',\n                          truncating='post'))\n        \n        \n        \n        \n        \n        \n        return [np.array(images), np.array(x_batch_input)] , np.array(x_batch_gt)   \n\n\ndef get_train_validation_generator(csv_path1,csv_path2,img_path, vocab_size,max_len,batch_size=8\n                                   , dim=(256,256),shuffle=True ,preprocess = None , \n                                   validation_split=0.1,augmentation=False,normalize=False,hist_eq =False):\n    \n    df1= pd.read_csv(csv_path1)\n    df2= pd.read_csv(csv_path2)\n    \n    df2 = df2[df2['projection']=='Frontal']\n    \n    df  =pd.merge(df1,df2,  on=['uid'])\n    \n    \n    df= df.dropna(subset=['findings'])\n    df['findings_cleaned'] = df['findings'].apply(normalize_text)\n    df['findings_cleaned'] = 'startseq '+df['findings_cleaned']+' endseq'\n    \n    vocab_size = vocab_size\n    max_len = max_len\n    tok = Tokenizer(num_words=vocab_size,  oov_token='UNK' )\n    tok.fit_on_texts(df['findings_cleaned'].tolist())\n    vocab_size = len(tok.word_index) + 1\n    \n    \n    df = df.sample(frac=1,random_state=42)\n    df_train = df.iloc[:-int(df.shape[0]*validation_split)]\n    df_val   = df.iloc[-int(df.shape[0]*validation_split):]\n    \n    if augmentation == True:\n        augmentation='train'\n        \n    train_dataloader =  det_gen(df_train, tok, max_len,img_path,dim=dim,batch_size=batch_size,preprocess_func=preprocess,normalize=normalize,hist_eq=hist_eq,augmentation=augmentation  )\n    \n    if augmentation == 'train':\n        augmentation='validation'\n    \n    val_dataloader =  det_gen(df_val, tok, max_len,img_path,dim=dim,batch_size=batch_size,preprocess_func=preprocess,normalize=normalize,hist_eq=hist_eq,augmentation=augmentation  )\n    \n\n    return train_dataloader, val_dataloader, vocab_size, tok","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_path1=\"/kaggle/input/chest-xrays-indiana-university/indiana_reports.csv\"\ncsv_path2= \"/kaggle/input/chest-xrays-indiana-university/indiana_projections.csv\"\nimg_path =\"/kaggle/input/chest-xrays-indiana-university/images/images_normalized/\"\ntrain_dataloader, val_dataloader, vocab_size, tok=get_train_validation_generator(csv_path1\n                                                                                 ,csv_path2,img_path, 10000,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len=100\n## Input layers\nimg_input = layers.Input(shape= (256,256,3)) \nreport_input= layers.Input(shape= (max_len-1,))\n\n## Encoder ######################\n\nDensenet_model = tf.keras.applications.DenseNet121(\n            include_top=False,\n            weights=None,#\"imagenet\",\n            input_shape=(256,256,3),\n        )\nnumber_of_encoder_layers=  len(Densenet_model.layers)\n\nencoder_output = Densenet_model(img_input)\nencoder_output = layers.Flatten()(encoder_output)\n\nX_img = layers.Dropout(0.5)(encoder_output)\nX_img = layers.Dense(300, use_bias = False, \n                        kernel_regularizer=regularizers.l2(1e-4),\n                        name = 'dense_img')(X_img)\nX_img = layers.BatchNormalization(name='batch_normalization_img')(X_img)\nX_img = layers.Lambda(lambda x : K.expand_dims(x, axis=1))(X_img)\n\n##decoder ########################\n\nX_text = layers.Embedding(vocab_size, 300, mask_zero = True, name = 'emb_text')(report_input)\nX_text = layers.Dropout(0.5)(X_text)\n\n# Initial States\n\n\nLSTMLayer = layers.LSTM(300, return_sequences = True, return_state = True, dropout=0.5, name = 'lstm')\n\n# Take image embedding as the first input to LSTM\n_, a, c = LSTMLayer(X_img)\n\nA, _, _ =LSTMLayer(X_text, initial_state=[a, c])\nattention = SeqSelfAttention(attention_activation='sigmoid')(A)\n\noutput = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax',\n                                 kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))\n                                , name = 'time_distributed_softmax')(attention)\n\n\n\n\nmodel  = Model(inputs=[img_input, report_input], outputs=output, name='NIC_greedy_inference_v2')\n\n\n##Inference models ################\n\n#encoder_inference model\nencoder_model = Model(img_input,[a,c])\n\n# Decoder model ###################\n\na0 = layers.Input(shape=(300,))\nc0 = layers.Input(shape=(300,))\n\nA, alast, clast = LSTMLayer(X_text, initial_state=[a0, c0])\nattention = SeqSelfAttention(attention_activation='sigmoid')(A)\noutput = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax',\n                                 kernel_regularizer = regularizers.l2(1e-4), \n                                 bias_regularizer = regularizers.l2(1e-4)), name = 'time_distributed_softmax')(attention)\n\n\n\ndecoder_model = Model([report_input,a0,c0],[output,alast,clast])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs =15\nlr=1e-4\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(lr))\nhist = model.fit_generator( train_dataloader,validation_data = val_dataloader,epochs = epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_predictions_from_data_loader(data_loader,tok,encoder_model, \n                                     decoder_model,max_len,start_token=\"startseq\",end_token='endseq', \n                                     inference_type='greedy',decoder_type='LSTM'):\n    \n    data_loader_iterator = data_loader.__iter__()\n    \n    pred_sentences = []\n    Gt_sentences = []\n    for index, (X,Y) in enumerate(data_loader_iterator):\n        for img,_,sample_y in zip(X[0],X[1],Y):\n            \n            if inference_type=='greedy':\n                pred_sentence = greedy_inference(img, tok,encoder_model, decoder_model,max_len,start_token=start_token,end_token=end_token,decoder_type=decoder_type)\n            \n            GT_sentence   = tokens_to_text(sample_y,tok)\n            \n            pred_sentences.append(pred_sentence)\n            Gt_sentences.append(GT_sentence)\n        \n        if index == data_loader.nb_iteration -1:\n            break\n        print(\"Done with batch number: \", index)\n        \n    return Gt_sentences, pred_sentences\n\ndef calculate_bleu_evaluation(GT_sentences, predicted_sentences):\n    BLEU_1 = corpus_bleu(GT_sentences, predicted_sentences, weights=(1.0, 0, 0, 0))\n    BLEU_2 = corpus_bleu(GT_sentences, predicted_sentences, weights=(0.5, 0.5, 0, 0))\n    BLEU_3 = corpus_bleu(GT_sentences, predicted_sentences, weights=(0.3, 0.3, 0.3, 0))\n    BLEU_4 = corpus_bleu(GT_sentences, predicted_sentences, weights=(0.25, 0.25, 0.25, 0.25))\n    \n    return BLEU_1,BLEU_2,BLEU_3,BLEU_4\n   \ndef evaluate_from_dataloader(data_loader,tok,encoder_model, decoder_model,max_len,start_token=\"startseq\",\n                             end_token='endseq', inference_type='greedy',decoder_type=\"LSTM\"):\n    Gt_sentences, pred_sentences = get_predictions_from_data_loader(data_loader,tok,encoder_model\n                                                                    , decoder_model,max_len\n                                                                    ,start_token=start_token\n                                                                    ,end_token=end_token, \n                                                                    inference_type=inference_type,\n                                                                    decoder_type=decoder_type)\n    BLEU_1,BLEU_2,BLEU_3,BLEU_4 = calculate_bleu_evaluation(Gt_sentences, pred_sentences)\n    \n    return BLEU_1,BLEU_2,BLEU_3,BLEU_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokens_to_text(tokens,tok,end_token='endseq'):\n    sentence=\"\"\n    for token in tokens:\n        if token ==0:\n            break\n        \n        word = tok.index_word[token]\n        \n        if word==end_token:\n            break\n            \n        sentence+= word+\" \"\n        \n    sentence = sentence.strip()\n    \n    return sentence\n\n\ndef greedy_inference(input_img, tok,encoder_model, decoder_model,max_len,start_token=\"startseq\",end_token='endseq'\n                     ,decoder_type=\"LSTM\"):\n    if decoder_type=='LSTM':\n        a0,c0  =encoder_model(np.expand_dims(input_img,axis=0))\n    elif decoder_type=='GRU': \n        hidden_layer  =encoder_model(np.expand_dims(input_img,axis=0))\n        \n    word = tok.word_index[start_token]\n    \n    words = []\n    \n    for index in range(max_len):\n        if decoder_type=='LSTM':\n            word_probs , a0,c0 = decoder_model.predict([[np.array([word]),a0,c0]])\n        elif decoder_type=='GRU': \n            word_probs , hidden_layer = decoder_model.predict([[np.array([word]),hidden_layer]])\n            hidden_layer=hidden_layer[0]\n        \n        word = np.argmax(word_probs)\n        \n        try:\n            if tok.index_word[word]==end_token:\n                break\n        except:\n            pass\n        \n        words.append(word)\n        \n    words = tokens_to_text(words,tok,end_token)\n    return words\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gt, pred = get_predictions_from_data_loader(val_dataloader,tok,encoder_model, decoder_model,max_len,\n                                                                    start_token=\"startseq\",end_token='endseq'\n                                                                 , inference_type='greedy',decoder_type=\"LSTM\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index=0\nprint(Gt[index])\nprint((\"=====================================\"))\nprint(pred[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index=1\nprint(Gt[index])\nprint((\"=====================================\"))\nprint(pred[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BLEU_1,BLEU_2,BLEU_3,BLEU_4 = calculate_bleu_evaluation(Gt, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(BLEU_1)\nprint('-------')\nprint(BLEU_2)\nprint('-------')\nprint(BLEU_3)\nprint('-------')\nprint(BLEU_4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}