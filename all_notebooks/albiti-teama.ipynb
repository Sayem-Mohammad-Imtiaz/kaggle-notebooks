{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Albiti-4th-Week-TeamA\n**- 김서연, 신예진, 최정윤 -**\n\n1. 목표 : 당뇨 관련 지표들에 대한 이해 – open data 및 meta info.\n2. 기한 : 2021.05.31 ~ 2021.06.06.\n3. Task 1. Pima dataset을 사용한 분류모델 구축.\n    - Kaggle에서 Pima dataset 다운로드.   \n    - Accuracy 70% 이상, F1 70% 이상 모델 구축! \n4. Task 2. Higher and higher.\n    - Accuracy 85% 이상, F1 85% 이상.\n_____________","metadata":{"toc":true}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.ticker import PercentFormatter\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:48.801695Z","iopub.execute_input":"2021-06-06T17:03:48.802004Z","iopub.status.idle":"2021-06-06T17:03:49.686226Z","shell.execute_reply.started":"2021-06-06T17:03:48.801927Z","shell.execute_reply":"2021-06-06T17:03:49.685314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:49.687944Z","iopub.execute_input":"2021-06-06T17:03:49.688226Z","iopub.status.idle":"2021-06-06T17:03:49.737953Z","shell.execute_reply.started":"2021-06-06T17:03:49.6882Z","shell.execute_reply":"2021-06-06T17:03:49.737254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Column 이해하기","metadata":{}},{"cell_type":"markdown","source":"`Pregnancies`  : Number of times pregnant\n\n`Glucose` : Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\n`BloodPressure` : Diastolic blood pressure (mm Hg)\n\n`SkinThickness` : Triceps skin fold thickness (mm)\n\n`Insulin` : 2-Hour serum insulin (mu U/ml)\n\n`BMI` : Body mass index (weight in kg/(height in m)^2)\n\n`DiadbetesPedigreeFunction` : Diabetes pedigree function\n\n`Age` : Age (years)\n\n`Outcome` : Class variable (0 or 1) 268 of 768 are 1, the others are 0","metadata":{}},{"cell_type":"markdown","source":"### Null & DType 확인\n- 결측치 없음.\n- object column 없음.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:52.537113Z","iopub.execute_input":"2021-06-06T17:03:52.537439Z","iopub.status.idle":"2021-06-06T17:03:52.555831Z","shell.execute_reply.started":"2021-06-06T17:03:52.537411Z","shell.execute_reply":"2021-06-06T17:03:52.555152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 기초 통계량\n- min이 0인 column이 많은 것을 확인할 수 있다.\n- 그런데, 대다수의 column은 0이라는 값을 가질 수 없다. (eg. BloodPressure)","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:52.801876Z","iopub.execute_input":"2021-06-06T17:03:52.802142Z","iopub.status.idle":"2021-06-06T17:03:52.840345Z","shell.execute_reply.started":"2021-06-06T17:03:52.802117Z","shell.execute_reply":"2021-06-06T17:03:52.839358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Outcome 별 Distribution Plot\n- 0 값을 가지는 data가 상당히 많다는 것을 확인할 수 있다. (eg. Insulin)\n- Outcome의 비율이 2:1 정도로 imbalance 한 것도 확인할 수 있다.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 3, figsize=(12,10))\n\nfor i in range(len(df.columns)-1):\n    name = df.columns[i]\n    sns.distplot(df[df['Outcome'] == 0][name], color='green', ax=ax[i//3, i%3])\n    sns.distplot(df[df['Outcome'] == 1][name], color='red', ax=ax[i//3, i%3])\n    ax[i//3, i%3].set_title(f'Healthy vs Diabetic by {name}')\n\nax[2, 2] = sns.countplot(x='Outcome', data=df)\nax[2, 2].set_title('Outcome')\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:53.080942Z","iopub.execute_input":"2021-06-06T17:03:53.081372Z","iopub.status.idle":"2021-06-06T17:03:55.0455Z","shell.execute_reply.started":"2021-06-06T17:03:53.081349Z","shell.execute_reply":"2021-06-06T17:03:55.044854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box Plot\n- 몇 feature들에게서 엄청나게 많은 outlier들을 확인할 수 있다.\n- 0 값의 영향을 받은 것처럼 보이는 feature도 존재한다.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 3, figsize=(12,8))\n\nfor i in range(len(df.columns)-1):\n    name = df.columns[i]\n    sns.boxplot(x= df[name], ax=ax[i//3, i%3])\n    ax[i//3, i%3].set_title(f'{name} Box Plot')\n\nax[2, 2] = sns.countplot(x='Outcome', data=df)\nax[2, 2].set_title('Outcome')\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:55.046652Z","iopub.execute_input":"2021-06-06T17:03:55.04697Z","iopub.status.idle":"2021-06-06T17:03:55.929511Z","shell.execute_reply.started":"2021-06-06T17:03:55.046934Z","shell.execute_reply":"2021-06-06T17:03:55.928306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 상관계수\n- 변수 삭제는 하지 않는 것으로 하였다.","metadata":{}},{"cell_type":"code","source":"cor = df.corr()\ncor = cor.corr(method = 'pearson')\nmask = np.triu(np.ones_like(cor, dtype=bool))\nfig, ax = plt.subplots(figsize=(6, 6))  \ncorr_heatmap = sns.heatmap(cor, mask = mask, cbar = True, annot = True, annot_kws={'size' : 9}, fmt = '.2f', square = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:55.930503Z","iopub.execute_input":"2021-06-06T17:03:55.930706Z","iopub.status.idle":"2021-06-06T17:03:56.331041Z","shell.execute_reply.started":"2021-06-06T17:03:55.930686Z","shell.execute_reply":"2021-06-06T17:03:56.330319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 전처리\n### 0(zero) 값 처리","metadata":{}},{"cell_type":"markdown","source":"- 0 값을 가질 수 없는 data 처리의 필요성이 느껴짐\n- 대상 Column: Glucose, BloodPressure, SkinThickness, Insulin, BMI","metadata":{}},{"cell_type":"code","source":"lst_null = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\ndf[lst_null] = df[lst_null].replace(0, np.nan)\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:56.332282Z","iopub.execute_input":"2021-06-06T17:03:56.332517Z","iopub.status.idle":"2021-06-06T17:03:56.345918Z","shell.execute_reply.started":"2021-06-06T17:03:56.332494Z","shell.execute_reply":"2021-06-06T17:03:56.345013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace를 위한 dataframe\noutcome_mean_df = df.groupby('Outcome').mean()\noutcome_mean_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:56.348158Z","iopub.execute_input":"2021-06-06T17:03:56.348467Z","iopub.status.idle":"2021-06-06T17:03:56.370168Z","shell.execute_reply.started":"2021-06-06T17:03:56.348441Z","shell.execute_reply":"2021-06-06T17:03:56.369106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in lst_null:\n    df[col] = np.where((df[col].isnull())&(df['Outcome']==0), outcome_mean_df[col].iloc[0], df[col])\n    df[col] = np.where((df[col].isnull())&(df['Outcome']==1), outcome_mean_df[col].iloc[1], df[col])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:56.371639Z","iopub.execute_input":"2021-06-06T17:03:56.371975Z","iopub.status.idle":"2021-06-06T17:03:56.388193Z","shell.execute_reply.started":"2021-06-06T17:03:56.371946Z","shell.execute_reply":"2021-06-06T17:03:56.387011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 3, figsize=(12,10))\n\nfor i in range(len(df.columns)-1):\n    name = df.columns[i]\n    sns.distplot(df[df['Outcome'] == 0][name], color='green', ax=ax[i//3, i%3])\n    sns.distplot(df[df['Outcome'] == 1][name], color='red', ax=ax[i//3, i%3])\n    ax[i//3, i%3].set_title(f'Healthy vs Diabetic by {name}')\n\nax[2, 2] = sns.countplot(x='Outcome', data=df)\nax[2, 2].set_title('Outcome')\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:56.390873Z","iopub.execute_input":"2021-06-06T17:03:56.391168Z","iopub.status.idle":"2021-06-06T17:03:58.659153Z","shell.execute_reply.started":"2021-06-06T17:03:56.39114Z","shell.execute_reply":"2021-06-06T17:03:58.658041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 변수 변환\n- 로그 변환, 제곱근 변환, boxcox 변환 모두 시도\n- boxcox 후에 정규분포 모양으로 변환이 더 잘 이루어졌음\n- 최종적으로 boxcox 변환 사용","metadata":{}},{"cell_type":"code","source":"# 변수 변환\nfrom sklearn import preprocessing\nfrom scipy.stats import boxcox\nskewed_cols = ['Pregnancies', 'Insulin', 'DiabetesPedigreeFunction', 'Age']\n\nfor col in skewed_cols :\n    df[col] = preprocessing.scale(boxcox(df[col]+1)[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:58.660537Z","iopub.execute_input":"2021-06-06T17:03:58.66089Z","iopub.status.idle":"2021-06-06T17:03:58.839696Z","shell.execute_reply.started":"2021-06-06T17:03:58.660854Z","shell.execute_reply":"2021-06-06T17:03:58.838887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 3, figsize=(12,10))\n\nfor i in range(len(df.columns)-1):\n    name = df.columns[i]\n    sns.distplot(df[df['Outcome'] == 0][name], color='green', ax=ax[i//3, i%3])\n    sns.distplot(df[df['Outcome'] == 1][name], color='red', ax=ax[i//3, i%3])\n    ax[i//3, i%3].set_title(f'Healthy vs Diabetic by {name}')\n\nax[2, 2] = sns.countplot(x='Outcome', data=df)\nax[2, 2].set_title('Outcome')\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:03:58.840655Z","iopub.execute_input":"2021-06-06T17:03:58.840891Z","iopub.status.idle":"2021-06-06T17:04:00.586726Z","shell.execute_reply.started":"2021-06-06T17:03:58.840865Z","shell.execute_reply":"2021-06-06T17:04:00.586003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 스케일링\n- RobustScaler, MinMaxScaler, StandardScaler 모두 시도\n- 최종적으로 모델 성능이 근소하게 더 높게 나온 RobustScaler 사용","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df.drop(['Outcome'], axis=1)\ny = df.Outcome","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:00.587851Z","iopub.execute_input":"2021-06-06T17:04:00.588195Z","iopub.status.idle":"2021-06-06T17:04:00.655958Z","shell.execute_reply.started":"2021-06-06T17:04:00.588162Z","shell.execute_reply":"2021-06-06T17:04:00.65531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nrobust_scaler = RobustScaler()\n\nX_robust_scaled = robust_scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:00.656945Z","iopub.execute_input":"2021-06-06T17:04:00.657339Z","iopub.status.idle":"2021-06-06T17:04:00.668104Z","shell.execute_reply.started":"2021-06-06T17:04:00.657305Z","shell.execute_reply":"2021-06-06T17:04:00.667189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 오버 샘플링\n- 예측 변수의 클래스 개수를 보면 '0'이 '1'보다 더 많음\n- 데이터 불균형을 해소하기 위해 오버 샘플링 기법인 SMOTE 사용\n- '0'과 '1' 클래스의 개수를 동일하게 맞춰줌","metadata":{}},{"cell_type":"code","source":"# 오버 샘플링\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(sampling_strategy='auto', random_state=1234)\nX_resampled, y_resampled= sm.fit_resample(X_robust_scaled,y)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_resampled.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(X_resampled.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_resampled==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_resampled==0)))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:00.669698Z","iopub.execute_input":"2021-06-06T17:04:00.669933Z","iopub.status.idle":"2021-06-06T17:04:01.208145Z","shell.execute_reply.started":"2021-06-06T17:04:00.669901Z","shell.execute_reply":"2021-06-06T17:04:01.207517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 모델","metadata":{}},{"cell_type":"markdown","source":"### Confusion Matrix Function\n- model : fit 하기 전 모델\n- X : X 데이터 (전체 데이터)\n- y : y 데이터 (전체 데이터)\n- name : dataframe의 index명 설정","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import KFold, cross_val_predict\n\n# data의 70%로 학습\ndef model_confusion(model, X, y, name):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n    model.fit(X_train, y_train)\n\n    pred = model.predict(X_test).reshape(-1,)\n    result_dict = {'Accuracy': [accuracy_score(y_test, pred)], \n                   'Precision': [precision_score(y_test, pred)], \n                   'Recall': [recall_score(y_test, pred)], \n                   'F1 score': [f1_score(y_test, pred)]}\n    \n    result = pd.DataFrame(result_dict, index=[name])\n    return result\n\n# Kfold 학습\ndef Kfold_model_confusion(model, X, y, name):\n    y_pred = cross_val_predict(model, X_resampled, y_resampled, cv=10)\n    result_dict = {'Accuracy': [accuracy_score(y_resampled, y_pred)], \n                  'Precision': [precision_score(y_resampled, y_pred)], \n                  'Recall': [recall_score(y_resampled, y_pred)], \n                  'F1 score': [f1_score(y_resampled, y_pred)]}\n    result = pd.DataFrame(result_dict, index=[name])\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:01.209337Z","iopub.execute_input":"2021-06-06T17:04:01.209593Z","iopub.status.idle":"2021-06-06T17:04:01.220009Z","shell.execute_reply.started":"2021-06-06T17:04:01.209567Z","shell.execute_reply":"2021-06-06T17:04:01.218993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import Modules","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nimport xgboost","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:01.221039Z","iopub.execute_input":"2021-06-06T17:04:01.221334Z","iopub.status.idle":"2021-06-06T17:04:01.620903Z","shell.execute_reply.started":"2021-06-06T17:04:01.221304Z","shell.execute_reply":"2021-06-06T17:04:01.619949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Models we tried\n- Logistic Regression\n- SVM\n- Gaussian NB\n- Random Forest\n- Gradient Boosting\n- AdaBoost\n- Decision Tree\n- LGBM\n- XGBoost\n- Ensemble with Random Forest, Gradient Boost, XGBoost, LGBM\n- Ensemble with all models we tried","metadata":{}},{"cell_type":"code","source":"lr_clf = LogisticRegression()\nsvm_clf = svm.SVC(kernel='linear', C=0.7, gamma=5)\nnb_clf = GaussianNB()\nforest_clf = RandomForestClassifier(n_estimators=500)\ngra_clf = GradientBoostingClassifier(n_estimators=500)\nada_clf = AdaBoostClassifier(n_estimators=500)\ndt_clf = DecisionTreeClassifier(random_state=1234)\nlgbm_clf = LGBMClassifier(n_estimators=500)\nxgb_clf = xgboost.XGBClassifier(n_estimators=500, learning_rate=0.2, \n                                gamma=0.5, max_depth=20, verbosity=0)\nen_clf = VotingClassifier(estimators=[('rf', forest_clf), ('gb', gra_clf), ('xgb', xgb_clf), ('lgbm', lgbm_clf)],\n                         voting='soft',weights=[2, 3, 5, 4])\nall_clf = VotingClassifier(estimators=[('lr', lr_clf), ('svm', svm_clf), ('nb', nb_clf), ('for', forest_clf),\n                                      ('gra', gra_clf), ('ada', ada_clf), ('dt', dt_clf), ('lgbm', lgbm_clf),\n                                      ('xgb', xgb_clf)], voting='hard', weights=[1,2,2,8,5,4,4,5,6])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:01.622021Z","iopub.execute_input":"2021-06-06T17:04:01.622313Z","iopub.status.idle":"2021-06-06T17:04:01.632057Z","shell.execute_reply.started":"2021-06-06T17:04:01.622285Z","shell.execute_reply":"2021-06-06T17:04:01.631408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 결과 도출\n1. Train Data : Test Data = 7 : 3 으로 학습\n    - Scaling과 Over Sampling 하지 않은 데이터\n    - Scaling과 Over Sampling 한 데이터\n2. K-fold Cross Validation 학습","metadata":{}},{"cell_type":"code","source":"print(\"< 7:3 split dataset before scaling and over sampling >\")\n\nresult1 = model_confusion(lr_clf, X, y, 'Logistic Regression')\nresult1 = pd.concat([result1, model_confusion(svm_clf, X, y, 'SVM')])\nresult1 = pd.concat([result1, model_confusion(nb_clf, X, y, 'Gaussian NB')])\nresult1 = pd.concat([result1, model_confusion(forest_clf, X, y, 'Random Forest')])\nresult1 = pd.concat([result1, model_confusion(gra_clf, X, y, 'Gradient Boosting')])\nresult1 = pd.concat([result1, model_confusion(ada_clf, X, y, 'AdaBoosting')])\nresult1 = pd.concat([result1, model_confusion(dt_clf, X, y, 'Decision Tree')])\nresult1 = pd.concat([result1, model_confusion(lgbm_clf, X, y, 'LGBM')])\nresult1 = pd.concat([result1, model_confusion(xgb_clf, X, y, 'XGBoost')])\nresult1 = pd.concat([result1, model_confusion(en_clf, X, y, 'Ensemble')])\nresult1 = pd.concat([result1, model_confusion(all_clf, X, y, 'Ensemble_all')])\nresult1","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:04.168187Z","iopub.execute_input":"2021-06-06T17:04:04.168568Z","iopub.status.idle":"2021-06-06T17:04:12.849305Z","shell.execute_reply.started":"2021-06-06T17:04:04.168542Z","shell.execute_reply":"2021-06-06T17:04:12.848265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"< 7:3 split dataset after scaling and over sampling >\")\n\nresult2 = model_confusion(lr_clf, X, y, 'Logistic Regression')\nresult2 = pd.concat([result2, model_confusion(svm_clf, X_resampled, y_resampled, 'SVM')])\nresult2 = pd.concat([result2, model_confusion(nb_clf, X_resampled, y_resampled, 'Gaussian NB')])\nresult2 = pd.concat([result2, model_confusion(forest_clf, X_resampled, y_resampled, 'Random Forest')])\nresult2 = pd.concat([result2, model_confusion(gra_clf, X_resampled, y_resampled, 'Gradient Boosting')])\nresult2 = pd.concat([result2, model_confusion(ada_clf, X_resampled, y_resampled, 'AdaBoosting')])\nresult2 = pd.concat([result2, model_confusion(dt_clf, X_resampled, y_resampled, 'Decision Tree')])\nresult2 = pd.concat([result2, model_confusion(lgbm_clf, X_resampled, y_resampled, 'LGBM')])\nresult2 = pd.concat([result2, model_confusion(xgb_clf, X_resampled, y_resampled, 'XGBoost')])\nresult2 = pd.concat([result2, model_confusion(en_clf, X_resampled, y_resampled, 'Ensemble')])\nresult2 = pd.concat([result2, model_confusion(all_clf, X_resampled, y_resampled, 'Ensemble_all')])\nresult2","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:12.850432Z","iopub.execute_input":"2021-06-06T17:04:12.850651Z","iopub.status.idle":"2021-06-06T17:04:24.315224Z","shell.execute_reply.started":"2021-06-06T17:04:12.850631Z","shell.execute_reply":"2021-06-06T17:04:24.314603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"< K-fold Cross Validation after scaling and over sampling >\")\n\nresult3 = Kfold_model_confusion(lr_clf, X_resampled, y_resampled, 'Logistic Regression')\nresult3 = pd.concat([result3, Kfold_model_confusion(svm_clf, X_resampled, y_resampled, 'SVM')])\nresult3 = pd.concat([result3, Kfold_model_confusion(nb_clf, X_resampled, y_resampled, 'Gaussian NB')])\nresult3 = pd.concat([result3, Kfold_model_confusion(forest_clf, X_resampled, y_resampled, 'Random Forest')])\nresult3 = pd.concat([result3, Kfold_model_confusion(gra_clf, X_resampled, y_resampled, 'Gradient Boosting')])\nresult3 = pd.concat([result3, Kfold_model_confusion(ada_clf, X_resampled, y_resampled, 'AdaBoosting')])\nresult3 = pd.concat([result3, Kfold_model_confusion(dt_clf, X_resampled, y_resampled, 'Decision Tree')])\nresult3 = pd.concat([result3, Kfold_model_confusion(lgbm_clf, X_resampled, y_resampled, 'LGBM')])\nresult3 = pd.concat([result3, Kfold_model_confusion(xgb_clf, X_resampled, y_resampled, 'XGBoost')])\nresult3 = pd.concat([result3, Kfold_model_confusion(en_clf, X_resampled, y_resampled, 'Ensemble')])\nresult3 = pd.concat([result3, Kfold_model_confusion(all_clf, X_resampled, y_resampled, 'Ensemble_all')])\nresult3","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:04:24.316186Z","iopub.execute_input":"2021-06-06T17:04:24.316511Z","iopub.status.idle":"2021-06-06T17:06:08.809996Z","shell.execute_reply.started":"2021-06-06T17:04:24.316484Z","shell.execute_reply":"2021-06-06T17:06:08.80896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 최종 결과\n\n#### Train:Test=7:3 Split","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(result2[result2['F1 score']==max(result2['F1 score'])])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:06:52.522743Z","iopub.execute_input":"2021-06-06T17:06:52.523076Z","iopub.status.idle":"2021-06-06T17:06:52.533476Z","shell.execute_reply.started":"2021-06-06T17:06:52.523048Z","shell.execute_reply":"2021-06-06T17:06:52.532389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### K-fold Cross Validation","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(result3[result3['F1 score']==max(result3['F1 score'])])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T17:07:00.508246Z","iopub.execute_input":"2021-06-06T17:07:00.508641Z","iopub.status.idle":"2021-06-06T17:07:00.518067Z","shell.execute_reply.started":"2021-06-06T17:07:00.508606Z","shell.execute_reply":"2021-06-06T17:07:00.516655Z"},"trusted":true},"execution_count":null,"outputs":[]}]}