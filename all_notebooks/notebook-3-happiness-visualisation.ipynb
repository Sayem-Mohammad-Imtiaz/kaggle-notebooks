{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', \n                      category=FutureWarning)      # suppress warnings\nimport numpy as np                                 # linear algebra\nimport pandas as pd                                # data analysis\nimport matplotlib.pyplot as plt                    # visualization - plt means we don't have to use the full pyplot every time we use it.\n%matplotlib inline\nimport seaborn as sns                              # visualization\nimport scipy.stats as scipystats                   # statistics  \nimport statsmodels.formula.api as smf              # statistics\nfrom statsmodels.api import add_constant           # statistics\nfrom sklearn.feature_selection import SelectKBest  # feature selection\nfrom sklearn.feature_selection import f_regression # feature selection\n\npd.set_option('display.float_format', lambda x: '%.1f' % x) # format decimals\nsns.set(font_scale=1.5) # increse font size for seaborn charts\n\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"file_path = \"../input/world-happiness/2019.csv\"\ndata = pd.read_csv(file_path)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check NA\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(a=data['Score'], label=\"Score\", kde=False)\nsns.distplot(a=data['Social support'], label=\"Social support\", kde=False)\nsns.distplot(a=data['Generosity'], label=\"Generosity\", kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x=\"Score\", y=\"Social support\", data=data, alpha, scatter_kws={'alpha':0.15})\nsns.set_style(\"darkgrid\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=, lowess=True, data=df, scatter_kws={'alpha':0.15}, line_kws={'color': 'red'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.plot(data['Social support'], data['Perceptions of corruption'], color='#c3fdff', marker='.', linestyle='--')\nplt.title('Perceptions of corruption vs generosity')\nplt.xlabel('Corruption')\nplt.ylabel('Generosity')\nax = plt.axes()\nax.set_facecolor('#2f3952') #Change background colour\nplt.style.use('fivethirtyeight')\n\nplt.legend()  #Automatically the label from the top will be put into the legend.\n\nplt.style.available\n#plt.savefig('plot.png') #- save it to current directory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 3, figsize=(8, 5))\nplt.rcParams['figure.dpi'] = 200\nplt.tight_layout()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = (data.dtypes == 'object') #TAKE OUT COUNTRY OR REGION\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encoding of Categorical Variables\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    data[col] = label_encoder.fit_transform(data[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()['Score'].sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GDP seems to be the most highly correlated factor.\nLet's visualise on a heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#First select the top 10 based on overall rank\ntop_10 = data.loc[data['Overall rank'] <= 10]\ntop_10\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To improve\nsns.heatmap(top_10, linewidths=0.1,cbar=True, annot=True, square=True, fmt='.1f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2D Kernel Density Plot to investigate social security and total score\nsns.jointplot(x=data['Score'], y=data['Social support'], kind=\"kde\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Generosity').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MORE VISUALISATION\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Random Forest\nfrom sklearn.model_selection import train_test_split\ny=data.Score\nhappiness_features = ['Generosity', 'Social support', 'Perceptions of corruption']\nX = data[happiness_features]\nX.describe\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define Model\nfrom sklearn.tree import DecisionTreeRegressor\nbasic_model=DecisionTreeRegressor(random_state=1)\nbasic_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predictions\nprint(\"Making predictions for happiness scores:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(basic_model.predict(X.head()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Basic Validation using in-sample score\nfrom sklearn.metrics import mean_absolute_error\n\npredicted_happiness_scores = basic_model.predict(X)\nmean_absolute_error(y, predicted_happiness_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n\nbasic_model = DecisionTreeRegressor()\n\nbasic_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nbasic_val_predictions = basic_model.predict(val_X)\nbasic_score = mean_absolute_error(val_y, basic_val_predictions)\nprint(basic_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(train_X, train_y)\nhappiness_preds = rf_model.predict(val_X)\nrf_score = mean_absolute_error(val_y, happiness_preds)\nprint(rf_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate max leaf nodes to optimise model\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Pipelines before using Cross-Validation and XGBoosting to optimise predictions\n#First we bundle preprocessing and modelling\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n#NUMERICAL DATA\n#numerical_transformer = SimpleImputer(strategy='constant')\n#CATEGORICAL DATA\n#categorical_transformer = Pipeline(steps=[\n#    ('imputer', SimpleImputer(strategy='most_frequent')),\n#    ('one hot', OneHotEncoder())\n#])\n\n#PREPROCESSING\n#preprocessor = ColumnTransformer(\n#transformers=[\n#    ('num', numerical_transformer, numerical_cols)\n#    ('cat', categorical_transformer, categorical_cols)\n#])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define Model\n#from sklearn.ensemble import RansomForestRegressor\n#model = RandomForestRegressor(n=estimators=100, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bundle preprocessing and modelling into pipeline\n\nfrom sklearn.metrics import mean_absolute_error\n\n#Preprocessing and model bundled\n#my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n #                            ('model', model)\n  #                           ])\n\n#fit model to training data\n#my_pipeline.fit(X_train, y_train)\n\n#Get Preds\n#preds = my_pipeline.predict(X_valid)\n\n#Evaluate\n#score = mean_absolute_error(y_valid, preds)\n#print(score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}