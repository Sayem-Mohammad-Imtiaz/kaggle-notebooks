{"cells":[{"metadata":{"_uuid":"77a86bc37570e03687db2417ae0b4e6c072c8b20","_cell_guid":"e631224f-9240-4d5e-9394-4e23558df2d4","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom pandas import datetime\nfrom sklearn import preprocessing\nfrom math import sqrt\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense, Dropout, Activation\nimport math, time\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"0d7c5eccf7745a49b4138a19473600cf570de130","_cell_guid":"7cd8cabc-4341-4679-88b2-18c51805aed9","collapsed":true,"trusted":true},"cell_type":"code","source":"def normalize_data(df):\n    \"\"\" Normalize the data in the input dataframe\"\"\"\n    min_max_scaler = preprocessing.MinMaxScaler()\n    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n    return [df,min_max_scaler]","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"be0f157c5226cc8a3af0c48e5aabd03f5e031711","_cell_guid":"ea95f6e2-fafa-4f86-8fa1-af2ff532ba63","collapsed":true,"trusted":true},"cell_type":"code","source":"def load_data(stock, seq_len):\n    amount_of_features = len(stock.columns) # 5\n    data = stock.as_matrix() \n    sequence_length = seq_len + 1 # index starting from 0\n    result = []\n    \n    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n        result.append(data[index: index + sequence_length]) # index : index + 22days\n    \n    result = np.array(result)\n    row = round(0.9 * result.shape[0]) # 90% split\n    train = result[:int(row), :] # 90% data, all features\n    \n    x_train = train[:, :-1] \n    y_train = train[:, -1][:,-1]\n    \n    x_test = result[int(row):, :-1] \n    y_test = result[int(row):, -1][:,-1]\n    \n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n\n    return [x_train, y_train, x_test, y_test]","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"2c46b86cb86ef9202e05a5d243587947219a490b","_cell_guid":"325a2d76-1d8a-489b-a5df-dc12a85b094c","collapsed":true,"trusted":true},"cell_type":"code","source":"def nn_model():\n    model = Sequential()\n    model.add(Dense(100, input_dim=X_train_NN.shape[1], activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(25, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(1, activation='linear'))\n\t# Compile model\n    model.compile(loss='mse', optimizer='adam')\n    return model","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"0aaee960e6c7a7585f729c7b66bfa91f4c380745","_cell_guid":"c4e0223b-40a6-480e-8264-007ee44fc96d","collapsed":true,"trusted":true},"cell_type":"code","source":"def build_model(layers):\n    \"\"\" Build the LSTM RNN model \"\"\"\n    d = 0.2\n    model = Sequential()\n    model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=True))\n    model.add(Dropout(d))\n    model.add(LSTM(64, input_shape=(layers[1], layers[0]), return_sequences=False))\n    model.add(Dropout(d))\n    model.add(Dense(16,kernel_initializer='uniform',activation='relu'))  \n    model.add(Dense(1,kernel_initializer='uniform',activation='linear'))\n    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n        \n    start = time.time()\n    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n    print(\"Compilation Time : \", time.time() - start)\n    return model","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"1be34b9cc9d7b139cf83c9fafa5473ada8b26875","_cell_guid":"fb393c51-9d57-4dcc-9d7f-da055b9b2354","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/spindexstarttomay2018/SPIndex-latest.csv\", index_col = 0)\n# old one df = pd.read_csv(\"../input/SPIndex.csv\", index_col = 0)\ndf[\"adj close\"] = df.adjclose # Moving close to the last column\ndf.drop(['close','adjclose'], 1, inplace=True) # Moving close to the last column\ndf.head()","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"065fd906b22e4ba27abb11ff3166348b14d7a795","_cell_guid":"dc68a5ac-1ee8-4e7c-bc63-23c303f3f625","trusted":true},"cell_type":"code","source":"df,min_max_scaler = normalize_data(df)\nwindow=7\nX_train, y_train, X_test, y_test = load_data(df, window)\n\nX_train_NN = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\nX_test_NN = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"7c0666eeebee93c180a93841d02c13ce1d67c553","_cell_guid":"e4620d17-e957-4b5a-a42c-a424a96d5e2a","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nlogreg = linear_model.LinearRegression()\nres = logreg.fit(X_train_NN,y_train)\ny_lr=res.predict(X_test_NN)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"85ff010152cf4798c7e59012db6471dc0fd97992","_cell_guid":"d536faa3-a0c6-43d6-8af8-3770dcfe454d","trusted":true},"cell_type":"code","source":"#Fitting to the ANN'\nclassifier = nn_model()\nclassifier.fit(X_train_NN,y_train,epochs=100, batch_size=10)\ny_pred=classifier.predict(X_test_NN)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"8e0b2d9a8a76e99ebd0a7306fc6c7d948fda32b9","_cell_guid":"625dcc20-177f-4832-8f3f-4081aba304a5","trusted":true},"cell_type":"code","source":"model = build_model([5,window,1])\nhistory = model.fit(X_train,y_train,batch_size=512,epochs=150,validation_split=0.1,verbose=1)\ny_lstm = model.predict(X_test)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"09dcb9b822b450221e414810556154cfae119ecd","_cell_guid":"eea04f09-4914-4bd6-a29e-b2360c87f5ae","trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend(['train','validation'])","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"e904b165d438d5c3afd3a883278937e878f03c51","_cell_guid":"5bae48ae-3095-4527-8ba4-8362a1ab9b20","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt2\nplt2.plot(y_pred,color='red', label='y_mlp')\nplt2.plot(y_test,color='blue', label='y_test')\nplt2.plot(y_lstm,color='green',label='y_lstm')\nplt2.legend(loc='upper left')\nplt2.show()","execution_count":12,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}