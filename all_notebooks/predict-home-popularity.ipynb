{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Введение\nВ соревновании была задача предсказать популярность объявления о продаже дома. Тут я попытаюсь рассказать о некоторых методах, которые применялись участниками и посмотреть, какие из них дали наибольший результат.\n\nВ ходе этого ноутбука мы:\n* исследуем данные\n* создадим много новых фич\n* проанализируем важность фич с помощью shap\n\nВ конце есть интересный вывод!\n\nReferences\n\nПри работе с геоданными, вдохновился [этим ноутбуком](https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367?scriptVersionId=1515342) от Белуги, грандмастера на Каггле","metadata":{}},{"cell_type":"markdown","source":"## Загрузка библиотек и вспомогательных функций","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score","metadata":{"id":"wUJVD96DTl0Z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/gusigagaga/train-2.csv', sep = ',')\ntest = pd.read_csv('../input/gusigagaga/test-2.csv', sep = ',')","metadata":{"id":"pJs5RWi3UQPB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train.drop(['TARGET'], axis = 1)\ny_train = train['TARGET']\nX_test = test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head(3)","metadata":{"id":"zt8nNpmGYUCQ","outputId":"3bfa5fa5-9c60-4253-8d33-a04bc1cd1506","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как улучшить бейзлайн? \n- created. Со временем популярность любого объявления снижается. \n- features. Сделать отдельную колонку под каждую фичу. \n- latitude, longitude, street_address. Посмотреть на карте, где расположены самые популярные здания.\n\n\n\n\n","metadata":{"id":"qUvIKIkpfjRN"}},{"cell_type":"markdown","source":"## Стратегия для валидации\nСначала посмотрим на различия train и test.","metadata":{}},{"cell_type":"code","source":"print(X_train.created.min())\nprint(X_test.created.min())\n\nprint(X_train.created.max())\nprint(X_test.created.max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"city_long_border = (-74.03, -73.75)\ncity_lat_border = (40.63, 40.85)\nfig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\nN = 10000\nax[0].scatter(X_train['longitude'].values[:N], X_train['latitude'].values[:N],\n              color='blue', s=1, label='train', alpha=0.1)\nax[1].scatter(X_test['longitude'].values[:N], X_test['latitude'].values[:N],\n              color='green', s=1, label='test', alpha=0.1)\nfig.suptitle('Train and test area complete overlap.')\nax[0].legend(loc=0)\nax[0].set_ylabel('latitude')\nax[0].set_xlabel('longitude')\nax[1].set_xlabel('longitude')\nax[1].legend(loc=0)\nplt.ylim(city_lat_border)\nplt.xlim(city_long_border)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В этом случае разделение на train и test было случайнымпо геоданным, это позволит нам использовать обучение без учителя и feature extraction на всем датасете","metadata":{}},{"cell_type":"markdown","source":"## Feature engineering","metadata":{}},{"cell_type":"markdown","source":"Чтобы модель искала нелинейные зависимости добавим функции от признаков и полиномиальные признаки:","metadata":{}},{"cell_type":"code","source":"from itertools import combinations\ndef add_functions_and_polynoms(X):\n    X = X.copy()\n    columns_to_poly = list(X.select_dtypes(include=np.number).columns)\n    for combination in combinations(columns_to_poly, 2):\n        X[f'poly_{combination[0]}_{combination[1]}'] = X[combination[0]] * X[combination[1]]\n    for column in columns_to_poly:\n        X[f'x**2_{column}'] = X[column] ** 2\n        X[f'log_{column}'] = np.log(X[column])\n        X[f'sqrt_{column}'] = np.sqrt(X[column])\n        X[f'1 / {column}'] = 1 / X[column]\n        X[f'sin_{column}'] = np.sin(X[column])\n        X[f'cos_{column}'] = np.cos(X[column])\n        X[f'sin^2_{column}'] = np.sin(X[column]) ** 2\n        X[f'cos^2_{column}'] = np.cos(X[column]) ** 2\n    X = X.replace(np.nan, 0)\n    X = X.replace(np.inf, 0)\n    X = X.replace(-np.inf, 0)\n    return X\nX_train = add_functions_and_polynoms(X_train)\nX_test = add_functions_and_polynoms(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Тут пытаюсь разобраться с колонкой features. Делаем one-hot encoding, чтобы по каждому объявлению мы знали, например, есть ли в этом доме лифт или нет","metadata":{"id":"6kLO9TYtoRio"}},{"cell_type":"code","source":"listy = list(X_test.columns)\n\ndef add_features_onehot(X):\n    X = X.copy()\n    X['features'] = X.features.apply(lambda x: x[1:-1].lower().replace(\"'\", \"\").replace('\"', \"\").split(', '))\n    \n    X = X.join(X.features.str.join('|').str.get_dummies())\n    return X\n\nX_train = add_features_onehot(X_train)\nX_test = add_features_onehot(X_test)\n","metadata":{"id":"YmcCDCXSu6_o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"из признака features оставим только те признаки, которые есть как в train, так и test. При One-hot encoding было выяснилось, что в колонке features люди добавляли много уникальных значений, которые никак не помогут модели.","metadata":{}},{"cell_type":"code","source":"X_test[X_test.columns.intersection(X_train.columns)].columns","metadata":{"id":"8pHWn75fWe5C","outputId":"298310a6-5152-46da-e326-d096dd7403ed","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"вот так красиво теперь выглядит признак features","metadata":{}},{"cell_type":"markdown","source":"### работа с геоданными\nЧтобы обработать геоданные, я использовал PCA и Agglomerative clustering.\nМы используем PCA для преобразования координат долготы и широты. В данном случае речь не идет об уменьшении размерности, поскольку мы преобразуем 2D-> 2D. Ротация может помочь при расщеплении дерева решений в catboost.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\ncoords = np.vstack((X_train[['latitude', 'longitude']].values, X_test[['latitude', 'longitude']].values))\npca = PCA().fit(coords)\n\ndef add_PCA_i(X, i):\n    X = X.copy()\n    X[f'pca{i}'] = pca.transform(X[['latitude', 'longitude']])[:, i]\n    return X\n\nX_train = add_PCA_i(X_train, 0)\nX_test = add_PCA_i(X_test, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AgglomerativeClustering используем для обычного разделения точек на плоскости","metadata":{}},{"cell_type":"code","source":"\n\n#train.TARGET = pd.factorize(train['TARGET'])[0] + 1\n\nfrom sklearn.cluster import AgglomerativeClustering\n\n# creates 40 clusters using hierarchical clustering.\ni = 40\nagc = AgglomerativeClustering(n_clusters =i, affinity='euclidean', linkage='ward')\n\ndef add_agglomerative_clusters(X):\n    X = X.copy()\n    X['cluster'] = np.where(((X.longitude > -73.775) |\n                             (X.longitude < -74.050) |\n                             (X.latitude > 40.930)   |\n                             (X.latitude < 40.55)), i, agc.fit_predict(X[['latitude','longitude']]))\n    X = X.join(pd.get_dummies(X.cluster))\n    return X\n\nX_train = add_agglomerative_clusters(X_train)\nX_test = add_agglomerative_clusters(X_test)\n","metadata":{"id":"xRb2T_jK7aj5","outputId":"d18bea65-45fe-4f45-ebe6-dcb129f91e29","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Житейская мудрость - price_per_bedroom, считаем популярность риэлтора и building_id","metadata":{}},{"cell_type":"code","source":"def wordlinnes(X):\n    X = X.copy()\n    X['price_per_bedroom'] = X[\"price\"] / X[\"bedrooms\"]\n    X[\"price_per_bathroom\"] = X[\"price\"] / X[\"bathrooms\"]\n    X = X.drop(['bedrooms','bathrooms'], axis=1)\n    return X\nX_train = wordlinnes(X_train)\nX_test = wordlinnes(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обрабатываем building_id и manager_id, они дали высокое влияние на выход модели.С manager_id это можно логически объяснить - хороший риэлтор умеет правильно подкрутить объявление так,чтобы оно было популярным. А вот почему listing_id дает буст в скоре - непонятно, все-таки в этом признаке все элементы уникальные.","metadata":{}},{"cell_type":"code","source":"building_ids = X_train['building_id'].value_counts()\nmanager_ids = X_train['manager_id'].value_counts()\ndef countsy(X):\n    X = X.copy()\n    X['manager_ids_count'] = X['manager_id'].apply(lambda x: manager_ids[x] if x in manager_ids else 0)\n    X['building_ids_count'] = X['building_id'].apply(lambda x: building_ids[x] if x in building_ids else 0)\n    return X\nX_train = countsy(X_train)\nX_test = countsy(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Время","metadata":{}},{"cell_type":"code","source":"def timelines(X):\n    X[\"created\"] = X[\"created\"].astype(\"datetime64\")\n    X['Weekday'] = X.created.dt.weekday\n    X['day_of_month'] = X.created.dt.day\n    X['hour'] = X.created.dt.hour\n    X['is_weekend'] = X.created.apply(lambda x: 1 if x.date().weekday() in (5, 6) else 0)\n    X['month'] = X.created.dt.month\n    X['week'] = X.created.dt.week\n\n    X['hour_weekofyear'] = X.created.dt.weekofyear\n    X['minute'] = X['created'].dt.minute\n    X['pickup_week_hour'] = X['Weekday'] * 24 + X['hour']\n\n    basedate = pd.Timestamp('2016-06-29 18:30:41')\n    X['days_since_last'] = X.created.apply(lambda x: (basedate - x).days)\n    return X\nX_train = timelines(X_train)\nX_test = timelines(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1 = X_test[X_test.columns.intersection(X_train.columns)]\ntrain1 = X_train[X_train.columns.intersection(X_test.columns)].merge(train.TARGET, left_index=True, right_index=True)\n\nfeats_list1 = ['price'] + list(test1[test1.columns.intersection(train1.columns)].columns)[15:]","metadata":{"id":"OeBIcvlKnU9w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\nX_train = train1.loc[:, feats_list1]\nX_test = test1.loc[:, feats_list1]\n\ny_train = train1.loc[:, 'TARGET'].values\n\nclasses = np.unique(y_train)\nweights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\nclass_weights = dict(zip(classes, weights))\n\nmodel = CatBoostClassifier(class_weights=class_weights, loss_function='MultiClass', \n                           eval_metric='Accuracy', custom_loss='Accuracy', verbose = 250)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nshap.initjs()\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(Pool(X_train, y_train))\nshap.summary_plot(shap_values, X_train, plot_type=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Тут изображен топ признаков, которые больше всего повлияли на модель. В топе по влиянию оказались перемноженные признаки, производные от признака features, pca0 повлиял сравнительно неплохо, но AGC никак не повлиял. Отдельно можно заметить, что если указано, что в объявлении есть hardwood floors (паркетные полы), то это значительно влияет на популярность объявления, потому что class 2 имеет самую большую относительную долю в этом признаке.\nТеперь посмотрим, как эти признаки повлияли на модель: положительно или отрицательно.","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values[1], X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"На приведенном ниже графике объекты сортируются по сумме величин значений SHAP по всем выборкам и используются значения SHAP, чтобы показать распределение влияний каждого объекта на выходные данные модели. Цвет представляет значение функции (красный высокий, синий низкий). Это показывает, например, что высокий признак no fee (1 - есть плата, 0 - нет платы) снижает прогнозируемую популярность объявления. Отдельно стоить заметить,что price_per_bedroom только мешает модели, этот признак не дает никакой информации о том, какой класс нужно дать конкретному элементу. Фича из житейской мудрости слишком коррелирует с признаком price.","metadata":{}},{"cell_type":"markdown","source":"## Основной вывод:\nосновной буст дали нелогичные фичи: poly_listing_id_price - это просто перемноженные listing_id и price. В чем вообще физический смысл этого признака? А в чем смысла признака pca_0? Почему listing_id вообще имеет высокое влияние, если каждое значение этого признака уникальное? Почему логичные признаки типа hour, Это всё мы ведем к тому, что на таких соревнованиях не нужно опираться на здравый смысл при создании фич, они могут не иметь логики, но значительно помочь модели.","metadata":{}},{"cell_type":"markdown","source":"### Последний интересный момент в SHAP","metadata":{}},{"cell_type":"code","source":"def plot_shap(row_to_show):\n    row_to_show = row_to_show\n    data_for_prediction = X_train.iloc[[row_to_show]]  # use 1 row of data here. Could use multiple rows if desired\n    data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\n    model.predict_proba(data_for_prediction_array)\n    print(model.predict_proba(data_for_prediction_array))\n    print(train.iloc[[row_to_show]].TARGET)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(data_for_prediction)\n\n    shap.initjs()\n    return shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)\nplot_shap(7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как это интерпретировать?\n\nПризнаки, которые увеличивают популярность, указаны синим, а которые уменьшают - розовым. Так можно посмотреть на каждое из объявлений и понять, почему модель решила дать этому элементу тот или иной класс популярности.\n\nЧем левее от base_value значение f(x), тем более популярным считается это объявление. f(x) - вывод модели по данному объявлению, base_value - средний вывод модели по переданному нами набору обучающих данных. Справа непопулярные объявления, слева популярные.","metadata":{}},{"cell_type":"code","source":"plot_shap(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Значение f(x) у классов medium и high часто одинаковое - эти классы отличаются совсем чуть-чуть по значению f(x), но отличаются признаки, которые указывают на один из этих классов.","metadata":{}},{"cell_type":"code","source":"plot_shap(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Но в классе low предсказанное значение f(x) всегда намного правее","metadata":{}}]}