{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Simple Regression Example\n## Importing Necessary Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport category_encoders as ce\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom eli5.sklearn.explain_prediction import explain_prediction_linear_regressor\nfrom eli5.sklearn.explain_prediction import explain_prediction_tree_regressor\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Path of the file to read\niowa_file_path = '/kaggle/input/housing/AmesHousing.csv'\nhome_data = pd.read_csv(iowa_file_path)\nhome_data_copy = home_data.copy()\n\n# Create target object and call it y\ny = home_data.SalePrice\n# Create X\nX = home_data[home_data.columns[:-1]]\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nval_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_X.copy()\ntrain_df['SalePrice'] = train_y\nval_df = val_X.copy()\ntrain_df.to_csv('train.csv', index=False)\nval_df.to_csv('test.csv', index=False)\n\ntarget = pd.DataFrame({'Order': val_df.Order, 'SalePrice': val_y})\ntarget.to_csv('target.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(val_X[\"Year Built\"], val_y, color = \"darkblue\", alpha=.8)\nplt.title(\"Sale Price vs Year Built (Validation set)\")\nplt.xlabel(\"Year Built\")\nplt.ylabel(\"Sale Price\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turning Categorical Features into Numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn categorical features into numeric using count encoding\ncat_features = home_data.select_dtypes(exclude=['int64','float64']).columns\nnon_cat_features = home_data.select_dtypes(include=['int64','float64']).columns[:-1]\ncount_enc = ce.CountEncoder(cols=cat_features)\n\n# Learn encoding from the training set\ncount_enc.fit(train_X[cat_features])\n\n# Apply encoding to the train and validation sets\ntrain_X = train_X[non_cat_features].join(count_enc.transform(train_X[cat_features]).add_suffix('_count'))\nval_X = val_X[non_cat_features].join(count_enc.transform(val_X[cat_features]).add_suffix('_count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_plot = val_X.copy()\nto_plot['cost_over_150000'] = val_y >= 150000\nsns.pairplot(to_plot, vars=['Year Built', 'Overall Qual', 'Overall Cond'], hue='cost_over_150000')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filling in the Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Deal with missing values\ntrain_X = train_X.fillna(method='bfill')\nval_X = val_X.fillna(method='bfill')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the model\nl_model = LinearRegression()\n# fit the model\nl_model.fit(train_X, train_y)\n\npreds = l_model.predict(val_X)\n\n# Calculate the mean absolute error of the Random Forest model on the validation data\nl_val_mae = mean_absolute_error(val_y, preds)\nl_val_rmse = np.sqrt(mean_squared_error(val_y, preds))\nprint(\"Validation MAE for Linear Model: {}\".format(l_val_mae))\nprint(\"Validation RMSE for Linear Model: {}\".format(l_val_rmse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the model\nrf_model = RandomForestRegressor(random_state=1)\n# fit the model\nrf_model.fit(train_X, train_y)\n\npreds = rf_model.predict(val_X)\n\n# Calculate the mean absolute error of the Random Forest model on the validation data\nrf_val_mae = mean_absolute_error(val_y, preds)\nrf_val_rmse = np.sqrt(mean_squared_error(val_y, preds))\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\nprint(\"Validation RMSE for Random Forest Model: {}\".format(rf_val_rmse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nxg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 100)\nxg_reg.fit(train_X, train_y)\n\npreds = xg_reg.predict(val_X)\n\nxgb_val_mae = mean_absolute_error(val_y, preds)\nxgb_val_rmse = np.sqrt(mean_squared_error(val_y, preds))\nprint(\"Validation MAE for XGBoost model: {}\".format(xgb_val_mae))\nprint(\"Validation RMSE for XGBoost model: {}\".format(xgb_val_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_predictions = pd.DataFrame({'Order': val_df.Order, 'SalePrice': preds})\nmy_predictions.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}