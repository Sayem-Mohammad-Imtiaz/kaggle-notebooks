{"cells":[{"metadata":{},"cell_type":"markdown","source":"Feature reduction on IRIS Data SEt "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import datasets\n#iris = datasets.load_iris()\n\n#from sklearn \nfrom sklearn.datasets import load_iris\nimport numpy as np\nimport pandas as pd \n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris = load_iris()\niris.data.shape\niris.target.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris.feature_names\n\niris.target_names\n\niris.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.DataFrame(iris.data)\ny = iris.target\n\nx.columns = iris.feature_names\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape\n## 150 rows and 4 columns \n##(150, 4)\ny.shape\n## 150 rows and 1 column ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test =  train_test_split(x,y,test_size = 0.2,random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking tthe shape of train aand test data \nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\n\nlr1 = LogisticRegression(penalty='l1')\n\n#A regression model that uses L1 regularization technique is called Lasso Regression and model which uses L2 is called Ridge Regression.\n#The key difference between these two is the penalty term.\n\n#The key difference between these techniques is that Lasso shrinks the less important featureâ€™s coefficient to zero thus, removing some feature altogether. So, this works well for feature selection in case we have a huge number of features.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = lr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_predict,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy)\n\n## Hence we can see our model created is predicting 83 % correct values \n## Now lets apply PCA and see if accuracy increases ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Creating PCA such that it will explain 95 % of the variance\nfrom sklearn.decomposition import PCA\n\nsklearn_pca = PCA(n_components = 0.95)\n\nsklearn_pca.fit(x_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Transforming using PCA \n\nx_train_transformed = sklearn_pca.transform(x_train)\nx_test_transformed = sklearn_pca.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_transformed.shape\nx_test_transformed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr1.fit(x_train_transformed,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict1 = lr1.predict(x_test_transformed)\naccuracy1 = accuracy_score(y_predict1,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy1)\n\n## Thsis is the accuracy of the new model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}