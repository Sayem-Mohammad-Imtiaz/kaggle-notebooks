{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport numpy as np\nimport matplotlib.font_manager\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.metrics.pairwise import linear_kernel\n%matplotlib inline\nsns.set(style=\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data exploration "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/netflix-shows/netflix_titles.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform the `date_added` column from object type to datetime type for ease of use"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"date_added\"] = pd.to_datetime(data[\"date_added\"])\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find missing data in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning data\nRemove unnecessary data for this analysis such as `show_id`, `director`, `cast`"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(labels=[\"show_id\",\"director\",\"cast\"], axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Impute the missing data in the countries with `United States` because `United States` is the most repeated value. And delete the `rating` and `date_added` rows since only `7` and `10` records were missing respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"country\"]=data[\"country\"].fillna(\"United States\")\ndata = data.dropna(subset=[\"rating\",\"date_added\"])\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"listed_in\"] = data[\"listed_in\"].apply(lambda x: x.split(\",\")[0])\ndata[\"country\"] = data[\"country\"].apply(lambda x: x.split(\",\")[0])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_catalog = data[[\"type\"]]\ntotal_catalog  = total_catalog .value_counts().reset_index(name=\"count\")\ntotal_catalog ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color_palette_list = [\"#76D7C4\", \"#D1F2EB\"]\n\nfig, ax = plt.subplots(figsize = (10,6))\nlabels = total_catalog.type.unique()\nax.pie(total_catalog[\"count\"],explode=(0.1,0),labels=labels,colors=color_palette_list[:], autopct=\"%1.0f%%\", \n       shadow=True, startangle=0)\nax.axis(\"equal\")\nax.set_title(\"Distribution of the netflix catalog by movies and tv show\", fontweight=\"bold\",size=14)\nax.legend(frameon=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"69% of netflix's total productions correspond to `movies` while the remaining 31% represent `tv show`."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_productions_per_year = data[['release_year']]\ntotal_productions_per_year = total_productions_per_year[total_productions_per_year['release_year'] >= 2010].value_counts().reset_index(name='counts')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vertical_show_values_on_bars(axs):\n    def _show_on_single_plot(ax):        \n        for p in ax.patches:\n            height = p.get_height() \n            width = p.get_width() \n            _x = p.get_x() + width / 2\n            _y = p.get_y() + height\n            ax.text(_x, _y, int(height), ha=\"center\") \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\n        \ndef horizontal_show_values_on_bars(axs):\n    def _show_on_single_plot(ax):\n        for p in ax.patches:\n            height = p.get_height() \n            width = p.get_width() \n            _x = width+3\n            _y =  p.get_y()+(height/2)\n            ax.text(_x, _y, int(width), va=\"center\") \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_content_peer_year = data\ntotal_content_peer_year = total_content_peer_year[['release_year']]\ntotal_content_peer_year = total_content_peer_year[total_content_peer_year['release_year'] \n>= 2010].value_counts().reset_index(name='counts')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.figure(figsize=(10,6))\nax = sns.barplot(data=total_content_peer_year,x='release_year',y = 'counts',alpha=0.8, palette=\"hls\")\nsns.despine()\nvertical_show_values_on_bars(ax)\nplt.title(\"Number total of content added\",fontweight='bold',size=14)\nplt.ylabel(\"Number of content added  in the year \",size=14)\nplt.xticks(size=14)\nplt.yticks(size=14)\nplt.xlabel(\"Years (2010 - 2021)\",size=14)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a higher amount of content added to the Netflix catalog in the years `2016 - 2020` with '2018' being its highest peak. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tv shows\ntv_shows_peer_year = data[data[\"type\"] == \"TV Show\"]\ntv_shows_peer_year = tv_shows_peer_year[[\"release_year\"]]\ntv_shows_peer_year = tv_shows_peer_year[tv_shows_peer_year[\"release_year\"] >= 2010].value_counts().reset_index(name=\"counts\")\n#Movies\nmovies_peer_year = data[data[\"type\"] == \"Movie\"]\nmovies_peer_year = movies_peer_year[[\"release_year\"]]\nmovies_peer_year = movies_peer_year[movies_peer_year[\"release_year\"] >= 2010].value_counts().reset_index(name=\"counts\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2 , figsize=(16, 8))\nfig.suptitle('Number of content added peer type',fontweight='bold')\naxes[0].set_title(\"Number of movies added\",fontsize=14)\naxes[1].set_title(\"Number of tv show added\",fontsize=14)\nsns.barplot(ax=axes[0] ,x='release_year',y = 'counts',data=movies_peer_year,alpha=0.8, palette=\"hls\")\nsns.barplot(ax=axes[1] ,x='release_year',y = 'counts',data=tv_shows_peer_year,alpha=0.8)\nsns.despine()\nplt.setp(axes[:], ylabel='Number of content added')\nplt.setp(axes[:], xlabel='Years 2010 - 2021')\nvertical_show_values_on_bars(axes[:])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThe number of content added in the period `2016 to 2018` increased but decreased in the period `2019 to 2021`, on the contrary, tv shows had a growth that has been increasing since `2016`, maintaining that trend, it can be concluded that there is a trend of Netflix users towards tv shows."},{"metadata":{"trusted":true},"cell_type":"code","source":"category = data[[\"listed_in\"]].value_counts().reset_index(name=\"count\")\nplt.figure(figsize=(12, 8))\nplt.title(\"Catalog of netflix by cateory\",size=14, fontweight='bold')\nax = sns.barplot(data=category,x = \"count\", y = \"listed_in\", alpha=0.6, palette=\"hls\")\nhorizontal_show_values_on_bars(ax)\nsns.despine()\nplt.xlabel(\"Number of movies and TV shows by category\",size=14)\nplt.ylabel(\"Categories\", size=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_by_countries = data[[\"country\"]].value_counts().reset_index(name=\"count\")[:15]\nplt.figure(figsize=(16, 8))\nplt.title(\"Top 15 countries creating content\",size=14, fontweight='bold')\nax = sns.barplot(data=content_by_countries,x = \"country\", y = \"count\", alpha=0.8, palette=\"hls\")\nvertical_show_values_on_bars(ax)\nsns.despine()\nplt.xlabel(\"Content-creating countries\",size=14)\nplt.ylabel(\"Number of content created\", size=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \" \".join(review for review in data.description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,6), facecolor='k')\nwordcloud = WordCloud(width=1080, height=480, colormap=\"Oranges_r\").generate(text)\nplt.title(\"WordCloud of description\")\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recommendation system using tf-idf"},{"metadata":{},"cell_type":"markdown","source":"The tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\n\nTo do so I made use of the following resources:\n* [tf–idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n* [Building a movie content based recommender using tf-idf](https://towardsdatascience.com/content-based-recommender-systems-28a1dbd858f5)\n* [Working With Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n* [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidfVec = TfidfVectorizer(use_idf=True,stop_words=\"english\")\ntfid_matrix = tfidfVec.fit_transform(data[\"description\"])\ntfid_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cosine_sim = linear_kernel(tfid_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space. It is defined to equal the cosine of the angle between them, which is also the same as the inner product of the same vectors normalized to both have length 1.\n<p align=\"center\">\n  <img width=\"400\" height=\"100\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1d94e5903f7936d3c131e040ef2c51b473dd071d\">\n</p> "},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = pd.Series(data.index, index=data['title']).drop_duplicates()\nindices.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_recommendations(title, cosine_sim=cosine_sim):\n    idx = indices[title]\n    similar_scores = list(enumerate(cosine_sim[idx]))\n    similar_scores = sorted(similar_scores, key=lambda x: x[1], reverse=True)\n    similar_scores = similar_scores[1:11]\n    movie_index = [i[0] for i in similar_scores]\n    return print(\"The recommendations are: \\n\",data[\"title\"].iloc[movie_index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_recommendations(\"Altered Carbon\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_recommendations(\"Marco Polo\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center> Thank you for reading the notebook if it helped you vote it </center>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}