{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import warnings\nimport warnings\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning\n\n### 1 - Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"deneyim\":[0.5,0,1,5,8,4,15,7,3,2,12,10,14,6],\n      \"maas\":[2500,2250,2750,8000,9000,6900,20000,8500,6000,3500,15000,13000,18000,7500]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x=df.deneyim,y=df.maas)\nplt.xlabel(\"Deneyim\")\nplt.ylabel(\"Maas\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sklearn kullanıcaz\nfrom sklearn.linear_model import LinearRegression\n\nlinear_reg = LinearRegression()\n\n# x = df.deneyim # type(x) ----> pandas.core.series.Series\n# Numpy kullanıcam. df.deneyim.values --> numpy çevirdik...\n# x.shape # (14,) linear regression için (14,1) şekline getirmeliyim yoksa anlamaz.\n\nx = df.deneyim.values.reshape(-1,1) # type(x) ----> numpy.ndarray\ny = df.maas.values.reshape(-1,1) # y.shape(14,1)\n\nlinear_reg.fit(x,y) # bana bir line fit et","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction (tahmin)\nb0 = linear_reg.predict([[0]])\nprint(\"b0 = \",b0)\n# line'nın y eksenini kestiği yer  intercept\n\nb0_ = linear_reg.intercept_\nprint(\"b0_ = \",b0_)\n\nb1 = linear_reg.coef_\nprint(\"b1 = \",b1) # eğim   slope  b1\n\n# maas = 1663 + 1138*deneyim  formülümüz\n# istediğimiz değeri predict edebiliriz.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maas_yeni = 1663 + 1138*11\nprint(maas_yeni)\n\nprint(linear_reg.predict([[11]]))\n# 11 yıllık deneyimi olanların maaşı 14181\n\nlinear_reg.predict([[13]]) # 13 yıllık maas tahmin ettik","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize line  ----> line görselleştircez.\narray = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]).reshape(-1,1)  \n# deneyimimi yani x değerlerim\n\nplt.scatter(x,y)\n\ny_head=linear_reg.predict(array) # maas\nplt.plot(array, y_head, color=\"red\")\n\nplt.show()\n\nprint(\"100 yıllık deneyim = maası\",linear_reg.predict([[100]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_head","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2 - Multiple Linear Regression\n\nBir y eksenine birden fazla şeyin etki etmesi"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic[\"yas\"] = [22,21,23,25,28,23,35,29,22,23,32,30,34,27]\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nx = df.iloc[:,[0,2]].values # deneyim ve yas\ny = df.maas.values.reshape(-1,1)\nmultiple_linear_regression = LinearRegression()\nmultiple_linear_regression.fit(x,y) # bana bir line fit et","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"b0:\",multiple_linear_regression.intercept_)\nprint(\"b1,b2:\", multiple_linear_regression.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict\nmultiple_linear_regression.predict(np.array([[10,35],[5,35]]))\n# yaşlar aynı ama deneyim farkı ile maas değiştiriyor.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3 - Polynomial Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"araba_fiyat\":[60,70,80,100,120,150,200,250,300,400,500,750,1000,2000,3000],\n      \"araba_max_hiz\":[180,180,200,200,200,220,240,240,300,350,350,360,365,365,365]}\n\ndf = pd.DataFrame(dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.araba_fiyat.values.reshape(-1,1)\ny = df.araba_max_hiz.values.reshape(-1,1)\n\nplt.scatter(x,y)\nplt.ylabel(\"araba_max_hiz\")\nplt.xlabel(\"araba_fiyat\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# linear regression =  y = b0 + b1*x\n# multiple linear regression   y = b0 + b1*x1 + b2*x2\n\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(x,y) # en uygun line'ı fit ediyoruz.\n\ny_head = lr.predict(x) # her bir değere göre tahmin(predict) yapıyotuz.\n\ny_head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x,y)\nplt.plot(x,y_head,\"r\")\nplt.show()\n\n# linear regression modeli fakat pek doğru değil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"10 milyon tl lik araba hizi tahmini: \",lr.predict([[10000]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# polynomial regression =  y = b0 + b1*x +b2*x^2 + b3*x^3 + ... + bn*x^n\n# x^2 elde etmeliyiz.\n\nfrom sklearn.preprocessing import PolynomialFeatures\npolynomial_regression = PolynomialFeatures(degree = 2)\n# degree(n) = 2  ---->  x^2'ye kadar\n\nx_polynomial = polynomial_regression.fit_transform(x)\nx_polynomial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\nlinear_regression2 = LinearRegression()\nlinear_regression2.fit(x_polynomial,y)\n\ny_head2 = linear_regression2.predict(x_polynomial)\n\nplt.scatter(x,y)\nplt.plot(x,y_head,color=\"red\", label = \"linear\")\nplt.plot(x,y_head2,color= \"green\",label = \"poly\")\nplt.legend()\nplt.show()\n\n# NOT = degree arttırırsak daha da iyileştirebiliriz. degree = 4 dene.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4 - Decision Tree Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"seviye\":[1,2,3,4,5,6,7,8,9,10],\n      \"fiyat\":[100,80,70,60,50,40,30,20,10,5]}\n\ndf = pd.DataFrame(dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.iloc[:,0].values.reshape(-1,1)\ny = df.iloc[:,1].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# decision tree regression\nfrom sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor() # random state = 0 ??\ntree_reg.fit(x,y)\n\n# ağaç yapısını oluşturduk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_head = tree_reg.predict(x)\n\ntree_reg.predict([[5.5]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize - görselleştirme\n\nplt.scatter(x,y,color = \"red\")\nplt.plot(x,y_head,color = \"green\")\nplt.xlabel(\"Tribun level\")\nplt.ylabel(\"ucret\")\nplt.show()\n\n# Oluşan grafik doğru değil çünkü bir leaf bulunan değerler aynı olmalı burda farklı farklı\n# örneğin 100 ile 80 arasında azalmış ama sabit olmalıydı","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_ = np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head = tree_reg.predict(x_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x,y,color = \"red\")\nplt.plot(x_,y_head,color = \"green\")\nplt.xlabel(\"Tribun level\")\nplt.ylabel(\"ucret\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 5 - Random Forest Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"seviye\":[1,2,3,4,5,6,7,8,9,10],\n      \"fiyat\":[100,80,70,60,50,40,30,20,10,5]}\n\ndf = pd.DataFrame(dic)\n\n# df = pd.read_csv(\"random_forest_regression_dataset.csv\",sep=\";\",header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.iloc[:,0].values.reshape(-1,1)\ny = df.iloc[:,1].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n\n# n_estimators 100 ağaç kullanıcam\n# random_state yapılan rastgele seçimi aynı olmasını sağlar. \n# Yani algoritmayı iki kez çalıştırırsak 1. ve 2. sonuçlar farklı olabilir çünkü rastgele seçim var bunu engelliyoruz.Hep aynı seçilde seçim yaptırıyoruz.\n# Aynı random değerlerinin seçilmesini sağlar.\n\nrf.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"7.8 seviyesinde fiyatın ne kadar olduğu = \", rf.predict([[7.8]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_ = np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head = rf.predict(x_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# görselleştirme\n\nplt.scatter(x,y,color=\"red\")\nplt.plot(x_,y_head,color=\"green\")\nplt.xlabel(\"Tribun level\")\nplt.ylabel(\"ucret\")\nplt.show()\n\n# Decision tree den farklı olarak 100 ağaç kulladık ve sonuçlar daha iyi çıktı.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6 - Evaluation Regression Models"},{"metadata":{},"cell_type":"markdown","source":"#### R-Square with Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"seviye\":[1,2,3,4,5,6,7,8,9,10],\n      \"fiyat\":[100,80,70,60,50,40,30,20,10,5]}\n\ndf = pd.DataFrame(dic)\n\nx = df.iloc[:,0].values.reshape(-1,1)\ny = df.iloc[:,1].values.reshape(-1,1)\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n\nrf.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_head = rf.predict(x)\n\ny_head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nprint(\"r_score: \", r2_score(y,y_head))\n\n# 1'e yakın, y'nin üzerinden predict (y_head) ettiğimiz değerlerin r-square değeri","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### R-Square with Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"deneyim\":[0.5,0,1,5,8,4,15,7,3,2,12,10,14,6],\n      \"maas\":[2500,2250,2750,8000,9000,6900,20000,8500,6000,3500,15000,13000,18000,7500]}\ndf = pd.DataFrame(dic)\n\nfrom sklearn.linear_model import LinearRegression\nlinear_reg = LinearRegression()\n\nx = df.deneyim.values.reshape(-1,1)\ny = df.maas.values.reshape(-1,1)\n\nlinear_reg.fit(x,y)\n\ny_head = linear_reg.predict(x)\n\nplt.scatter(x,y)\nplt.plot(x,y_head,color=\"red\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nprint(\"r_source: \",r2_score(y,y_head))\n\n# fark fazla olmasada random forest 1'e daha yakın\n# r-square with random forest , r_source: 0.9798724794092587","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}