{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook creates a very simple U-Net to segment clouds\nImportant remarks:\n- The test-set is not being used\n- The train set will be splitted into train and validation sets.\n- The dataset creation is discussed in: https://medium.com/@cordmaur/how-to-create-a-custom-dataset-loader-in-pytorch-from-scratch-for-multi-band-satellite-images-c5924e908edf\n- More information full explanation can can be found on the medium article: https://medium.com/@cordmaur/creating-a-very-simple-u-net-model-with-pytorch-for-semantic-segmentation-of-satellite-images-223aa216e705\n- The training phase with 50 epochs takes around 3:30hs. ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-22T18:10:52.680946Z","iopub.execute_input":"2021-05-22T18:10:52.681543Z","iopub.status.idle":"2021-05-22T18:10:53.329308Z","shell.execute_reply.started":"2021-05-22T18:10:52.681459Z","shell.execute_reply":"2021-05-22T18:10:53.328455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader, sampler\nfrom PIL import Image\nimport torch\nimport matplotlib.pyplot as plt\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:10:53.330766Z","iopub.execute_input":"2021-05-22T18:10:53.330996Z","iopub.status.idle":"2021-05-22T18:10:54.172871Z","shell.execute_reply.started":"2021-05-22T18:10:53.330962Z","shell.execute_reply":"2021-05-22T18:10:54.172069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n    \n!git clone https://github.com/usuyama/pytorch-unet.git\n\n!cd pytorch-unet","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:31:32.582829Z","iopub.execute_input":"2021-05-22T18:31:32.583207Z","iopub.status.idle":"2021-05-22T18:31:54.057622Z","shell.execute_reply.started":"2021-05-22T18:31:32.58316Z","shell.execute_reply":"2021-05-22T18:31:54.056572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the dataset","metadata":{}},{"cell_type":"code","source":"class CloudDataset(Dataset):\n    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True):\n        super().__init__()\n        \n        # Loop through the files in red folder and combine, into a dictionary, the other bands\n        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n        self.pytorch = pytorch\n        \n    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):\n        \n        files = {'red': r_file, \n                 'green':g_dir/r_file.name.replace('red', 'green'),\n                 'blue': b_dir/r_file.name.replace('red', 'blue'), \n                 'nir': nir_dir/r_file.name.replace('red', 'nir'),\n                 'gt': gt_dir/r_file.name.replace('red', 'gt')}\n\n        return files\n                                       \n    def __len__(self):\n        \n        return len(self.files)\n     \n    def open_as_array(self, idx, invert=False, include_nir=False):\n\n        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n                            np.array(Image.open(self.files[idx]['green'])),\n                            np.array(Image.open(self.files[idx]['blue'])),\n                           ], axis=2)\n    \n        if include_nir:\n            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n    \n        if invert:\n            raw_rgb = raw_rgb.transpose((2,0,1))\n    \n        # normalize\n        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n    \n\n    def open_mask(self, idx, add_dims=False):\n        \n        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n    \n    def __getitem__(self, idx):\n        \n        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n        x.resize_(3, 256, 256)\n        y.resize_(1, 256, 256)\n        return x, y\n    \n    def open_as_pil(self, idx):\n        \n        arr = 256*self.open_as_array(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')\n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:14.586161Z","iopub.execute_input":"2021-05-22T18:26:14.586473Z","iopub.status.idle":"2021-05-22T18:26:14.608463Z","shell.execute_reply.started":"2021-05-22T18:26:14.586413Z","shell.execute_reply":"2021-05-22T18:26:14.607489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = Path('../input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training')\ndata = CloudDataset(base_path/'train_red', \n                    base_path/'train_green', \n                    base_path/'train_blue', \n                    base_path/'train_nir',\n                    base_path/'train_gt')\nlen(data)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:14.950821Z","iopub.execute_input":"2021-05-22T18:26:14.95114Z","iopub.status.idle":"2021-05-22T18:26:25.606335Z","shell.execute_reply.started":"2021-05-22T18:26:14.951086Z","shell.execute_reply":"2021-05-22T18:26:25.605379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = data[1000]\nx.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:25.608182Z","iopub.execute_input":"2021-05-22T18:26:25.608668Z","iopub.status.idle":"2021-05-22T18:26:25.632147Z","shell.execute_reply.started":"2021-05-22T18:26:25.608603Z","shell.execute_reply":"2021-05-22T18:26:25.631151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(10,9))\nax[0].imshow(data.open_as_array(150))\nax[1].imshow(data.open_mask(150))","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:31.810307Z","iopub.execute_input":"2021-05-22T18:26:31.810606Z","iopub.status.idle":"2021-05-22T18:26:32.365413Z","shell.execute_reply.started":"2021-05-22T18:26:31.810556Z","shell.execute_reply":"2021-05-22T18:26:32.364107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, valid_ds = torch.utils.data.random_split(data, (6000, 2400))","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:35.599269Z","iopub.execute_input":"2021-05-22T18:26:35.599601Z","iopub.status.idle":"2021-05-22T18:26:35.60394Z","shell.execute_reply.started":"2021-05-22T18:26:35.599557Z","shell.execute_reply":"2021-05-22T18:26:35.6033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size=12, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=12, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:37.173472Z","iopub.execute_input":"2021-05-22T18:26:37.174017Z","iopub.status.idle":"2021-05-22T18:26:37.178699Z","shell.execute_reply.started":"2021-05-22T18:26:37.173972Z","shell.execute_reply":"2021-05-22T18:26:37.177893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb, yb = next(iter(train_dl))\nxb.shape, yb.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:39.500708Z","iopub.execute_input":"2021-05-22T18:26:39.501035Z","iopub.status.idle":"2021-05-22T18:26:40.445603Z","shell.execute_reply.started":"2021-05-22T18:26:39.500985Z","shell.execute_reply":"2021-05-22T18:26:40.444907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {\n    \"train\":train_dl,\n    \"val\": valid_dl  \n}","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:26:42.824153Z","iopub.execute_input":"2021-05-22T18:26:42.824452Z","iopub.status.idle":"2021-05-22T18:26:42.838081Z","shell.execute_reply.started":"2021-05-22T18:26:42.824408Z","shell.execute_reply":"2021-05-22T18:26:42.837059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models\n\n\ndef convrelu(in_channels, out_channels, kernel, padding):\n  return nn.Sequential(\n    nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n    nn.ReLU(inplace=True),\n  )\n\n\nclass ResNetUNet(nn.Module):\n  def __init__(self, n_class):\n    super().__init__()\n\n    self.base_model = torchvision.models.resnet18(pretrained=True)\n    self.base_layers = list(self.base_model.children())\n\n    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n    self.layer0_1x1 = convrelu(64, 64, 1, 0)\n    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n    self.layer1_1x1 = convrelu(64, 64, 1, 0)\n    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n    self.layer2_1x1 = convrelu(128, 128, 1, 0)\n    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n    self.layer3_1x1 = convrelu(256, 256, 1, 0)\n    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n    self.layer4_1x1 = convrelu(512, 512, 1, 0)\n\n    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n    self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n    self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n    self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n    self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n\n    self.conv_original_size0 = convrelu(3, 64, 3, 1)\n    self.conv_original_size1 = convrelu(64, 64, 3, 1)\n    self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n\n    self.conv_last = nn.Conv2d(64, n_class, 1)\n\n  def forward(self, input):\n    x_original = self.conv_original_size0(input)\n    x_original = self.conv_original_size1(x_original)\n\n    layer0 = self.layer0(input)\n    layer1 = self.layer1(layer0)\n    layer2 = self.layer2(layer1)\n    layer3 = self.layer3(layer2)\n    layer4 = self.layer4(layer3)\n\n    layer4 = self.layer4_1x1(layer4)\n    x = self.upsample(layer4)\n    layer3 = self.layer3_1x1(layer3)\n    x = torch.cat([x, layer3], dim=1)\n    x = self.conv_up3(x)\n\n    x = self.upsample(x)\n    layer2 = self.layer2_1x1(layer2)\n    x = torch.cat([x, layer2], dim=1)\n    x = self.conv_up2(x)\n\n    x = self.upsample(x)\n    layer1 = self.layer1_1x1(layer1)\n    x = torch.cat([x, layer1], dim=1)\n    x = self.conv_up1(x)\n\n    x = self.upsample(x)\n    layer0 = self.layer0_1x1(layer0)\n    x = torch.cat([x, layer0], dim=1)\n    x = self.conv_up0(x)\n\n    x = self.upsample(x)\n    x = torch.cat([x, x_original], dim=1)\n    x = self.conv_original_size2(x)\n\n    out = self.conv_last(x)\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:49:40.958621Z","iopub.execute_input":"2021-05-22T18:49:40.958972Z","iopub.status.idle":"2021-05-22T18:49:40.985017Z","shell.execute_reply.started":"2021-05-22T18:49:40.958896Z","shell.execute_reply":"2021-05-22T18:49:40.984022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndef double_conv(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n        nn.ReLU(inplace=True)\n    )   \n\n\nclass UNet(nn.Module):\n\n    def __init__(self, n_class):\n        super().__init__()\n                \n        self.dconv_down1 = double_conv(3, 64)\n        self.dconv_down2 = double_conv(64, 128)\n        self.dconv_down3 = double_conv(128, 256)\n        self.dconv_down4 = double_conv(256, 512)        \n\n        self.maxpool = nn.MaxPool2d(2)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n        \n        self.dconv_up3 = double_conv(256 + 512, 256)\n        self.dconv_up2 = double_conv(128 + 256, 128)\n        self.dconv_up1 = double_conv(128 + 64, 64)\n        \n        self.conv_last = nn.Conv2d(64, n_class, 1)\n        \n        \n    def forward(self, x):\n        conv1 = self.dconv_down1(x)\n        x = self.maxpool(conv1)\n\n        conv2 = self.dconv_down2(x)\n        x = self.maxpool(conv2)\n        \n        conv3 = self.dconv_down3(x)\n        x = self.maxpool(conv3)   \n        \n        x = self.dconv_down4(x)\n        \n        x = self.upsample(x)        \n        x = torch.cat([x, conv3], dim=1)\n        \n        x = self.dconv_up3(x)\n        x = self.upsample(x)        \n        x = torch.cat([x, conv2], dim=1)       \n\n        x = self.dconv_up2(x)\n        x = self.upsample(x)        \n        x = torch.cat([x, conv1], dim=1)   \n        \n        x = self.dconv_up1(x)\n        \n        out = self.conv_last(x)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:47:06.92343Z","iopub.execute_input":"2021-05-22T18:47:06.923984Z","iopub.status.idle":"2021-05-22T18:47:06.942458Z","shell.execute_reply.started":"2021-05-22T18:47:06.923907Z","shell.execute_reply":"2021-05-22T18:47:06.941456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n# import pytorch_unet\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device', device)\n\nmodel = ResNetUNet(2)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:47:07.29007Z","iopub.execute_input":"2021-05-22T18:47:07.290385Z","iopub.status.idle":"2021-05-22T18:47:27.53299Z","shell.execute_reply.started":"2021-05-22T18:47:07.29034Z","shell.execute_reply":"2021-05-22T18:47:27.531251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nimport torch.nn.functional as F\nfrom loss import dice_loss\n\ncheckpoint_path = \"checkpoint.pth\"\n\ndef calc_loss(pred, target, metrics, bce_weight=0.5):\n    bce = F.binary_cross_entropy_with_logits(pred, target)\n\n    pred = torch.sigmoid(pred)\n    dice = dice_loss(pred, target)\n\n    loss = bce * bce_weight + dice * (1 - bce_weight)\n\n    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n\n    return loss\n\ndef print_metrics(metrics, epoch_samples, phase):\n    outputs = []\n    for k in metrics.keys():\n        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n\n    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n\ndef train_model(model, optimizer, scheduler, num_epochs=25):\n    best_loss = 1e10\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        since = time.time()\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            metrics = defaultdict(float)\n            epoch_samples = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = calc_loss(outputs, labels, metrics)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                epoch_samples += inputs.size(0)\n\n            print_metrics(metrics, epoch_samples, phase)\n            epoch_loss = metrics['loss'] / epoch_samples\n\n            if phase == 'train':\n              scheduler.step()\n              for param_group in optimizer.param_groups:\n                  print(\"LR\", param_group['lr'])\n\n            # save the model weights\n            if phase == 'val' and epoch_loss < best_loss:\n                print(f\"saving best model to {checkpoint_path}\")\n                best_loss = epoch_loss\n                torch.save(model.state_dict(), checkpoint_path)\n\n        time_elapsed = time.time() - since\n        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n\n    print('Best val loss: {:4f}'.format(best_loss))\n\n    # load best model weights\n    model.load_state_dict(torch.load(checkpoint_path))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:50:35.741873Z","iopub.execute_input":"2021-05-22T18:50:35.742198Z","iopub.status.idle":"2021-05-22T18:50:35.773473Z","shell.execute_reply.started":"2021-05-22T18:50:35.742151Z","shell.execute_reply":"2021-05-22T18:50:35.772479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time\n\nnum_class = 2\nmodel = ResNetUNet(num_class).to(device)\n\n# freeze backbone layers\nfor l in model.base_layers:\n  for param in l.parameters():\n    param.requires_grad = False\n\noptimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.1)\n\nmodel = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\nmodel.eval()   # Set model to the evaluation mode\n\n# Create a new simulation dataset for testing\ntest_dataset = SimDataset(3, transform = trans)\ntest_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n\n# Get the first batch\ninputs, labels = next(iter(test_loader))\ninputs = inputs.to(device)\nlabels = labels.to(device)\nprint('inputs.shape', inputs.shape)\nprint('labels.shape', labels.shape)\n\n# Predict\npred = model(inputs)\n# The loss functions include the sigmoid function.\npred = torch.sigmoid(pred)\npred = pred.data.cpu().numpy()\nprint('pred.shape', pred.shape)\n\n# Change channel-order and make 3 channels for matplot\ninput_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n\n# Map each channel (i.e. class) to each color\ntarget_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\npred_rgb = [helper.masks_to_colorimg(x) for x in pred]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing one pass\nxb, yb = next(iter(train_dl))\nxb.shape, yb.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = unet(xb)\npred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom IPython.display import clear_output\n\ndef train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):\n    start = time.time()\n    model.cuda()\n\n    train_loss, valid_loss = [], []\n\n    best_acc = 0.0\n\n    for epoch in range(epochs):\n        print('Epoch {}/{}'.format(epoch, epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train(True)  # Set trainind mode = true\n                dataloader = train_dl\n            else:\n                model.train(False)  # Set model to evaluate mode\n                dataloader = valid_dl\n\n            running_loss = 0.0\n            running_acc = 0.0\n\n            step = 0\n\n            # iterate over data\n            for x, y in dataloader:\n                x = x.cuda()\n                y = y.cuda()\n                step += 1\n\n                # forward pass\n                if phase == 'train':\n                    # zero the gradients\n                    optimizer.zero_grad()\n                    outputs = model(x)\n                    loss = loss_fn(outputs, y)\n\n                    # the backward pass frees the graph memory, so there is no \n                    # need for torch.no_grad in this training pass\n                    loss.backward()\n                    optimizer.step()\n                    # scheduler.step()\n\n                else:\n                    with torch.no_grad():\n                        outputs = model(x)\n                        loss = loss_fn(outputs, y.long())\n\n                # stats - whatever is the phase\n                acc = acc_fn(outputs, y)\n\n                running_acc  += acc*dataloader.batch_size\n                running_loss += loss*dataloader.batch_size \n\n                if step % 100 == 0:\n                    # clear_output(wait=True)\n                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n                    # print(torch.cuda.memory_summary())\n\n            epoch_loss = running_loss / len(dataloader.dataset)\n            epoch_acc = running_acc / len(dataloader.dataset)\n\n            clear_output(wait=True)\n            print('Epoch {}/{}'.format(epoch, epochs - 1))\n            print('-' * 10)\n            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n            print('-' * 10)\n\n            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n\n    time_elapsed = time.time() - start\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n    \n    return train_loss, valid_loss    \n\ndef acc_metric(predb, yb):\n    return (predb.argmax(dim=1) == yb.cuda()).float().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\nopt = torch.optim.Adam(unet.parameters(), lr=0.01)\ntrain_loss, valid_loss = train(unet, train_dl, valid_dl, loss_fn, opt, acc_metric, epochs=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.plot(train_loss, label='Train loss')\nplt.plot(valid_loss, label='Valid loss')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_to_img(xb, idx):\n    img = np.array(xb[idx,0:3])\n    return img.transpose((1,2,0))\n\ndef predb_to_mask(predb, idx):\n    p = torch.functional.F.softmax(predb[idx], 0)\n    return p.argmax(0).cpu()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb, yb = next(iter(train_dl))\n\nwith torch.no_grad():\n    predb = unet(xb.cuda())\n\npredb.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 12\nfig, ax = plt.subplots(bs,3, figsize=(15,bs*5))\nfor i in range(bs):\n    ax[i,0].imshow(batch_to_img(xb,i))\n    ax[i,1].imshow(yb[i])\n    ax[i,2].imshow(predb_to_mask(predb, i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}