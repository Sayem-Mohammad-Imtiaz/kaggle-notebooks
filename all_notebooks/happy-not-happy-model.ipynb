{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/facial-expression/fer2013.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion=data['emotion'].values.tolist()\npixel=data['pixels'].values.tolist()\nusage=data['Usage'].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(emotion))\nprint(emotion[152])\nprint(type(usage[152]))\nif(usage[152]=='Testing'):\n    print(25)\nelse:\n    print(55)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_pixel=[]\nnew_train_emote=[]\nnew_test_pixel=[]\nnew_test_emote=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#custom dataset for or requirment\nfor i in range(0,len(emotion)):\n    if(emotion[i]==3 or emotion[i]==5):\n        if(usage[i]=='Training'):\n            new_train_pixel.append(pixel[i])\n            new_train_emote.append(0)\n        else:\n            new_test_pixel.append(pixel[i])\n            new_test_emote.append(0)\n            \n    elif(emotion[i]==0 or emotion[i]==4):\n        if(usage[i]=='Training'):\n            new_train_pixel.append(pixel[i])\n            new_train_emote.append(1)\n        else:\n            new_test_pixel.append(pixel[i])\n            new_test_emote.append(1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(new_train_pixel))\nprint(len(new_train_emote))\nprint(len(new_test_pixel))\nprint(len(new_test_emote))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(new_train_emote.count(0))\nprint(new_train_emote.count(1))\n#print(new_train_emote.count(2))\n\nprint(new_test_emote.count(0))\n\nprint(new_test_emote.count(1))\n\n#print(new_test_emote.count(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert(a):\n    l=len(a)\n    x=[]\n    for i in range(len(a)):\n        x.append(a[i].split(' '))\n    x=np.array(x)\n    x=x.astype('float32').reshape(l,48*48*1)\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=convert(new_train_pixel)\nprint(\"done converting train\")\nX_test=convert(new_test_pixel)\nprint(\"done converting test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nX_train = MinMaxScaler().fit_transform(X_train)\nX_test = MinMaxScaler().fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=np.reshape(X_test,(X_test.shape[0],48,48,1))\nX_train=np.reshape(X_train,(X_train.shape[0],48,48,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=np.array(new_train_emote)\ny_test=np.array(new_test_emote)\n\nfrom keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense,InputLayer,Activation,Dropout\nfrom keras.layers import Flatten,Dropout,BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\n\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size = (3,3), activation='relu',padding=\"same\", input_shape=(48, 48, 1)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size = (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size = (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, kernel_size = (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\nprint(\"Model Developed\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n\nopt = Adam()\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics = ['accuracy'])\n\n\nhistory = model.fit(X_train, y_train, batch_size=32, \n          epochs=100, verbose=1)\n\nprint(\"................TRAINING DONE....................\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_names = ['Happy','No_Happy']\ndef reports(X_test,y_test):\n    Y_pred = model.predict(X_test)\n    y_pred = np.argmax(Y_pred, axis=1)\n    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n    score = model.evaluate(X_test, y_test, batch_size=32)\n    Test_Loss = score[0]*100\n    Test_accuracy = score[1]*100\n    kc=cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n    return classification, confusion, Test_Loss, Test_accuracy ,kc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix,cohen_kappa_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score\nclassification, confusion, Test_loss, Test_accuracy,kc = reports(X_test,y_test)\nclassification = str(classification)\nconfusion_str = str(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"confusion matrix: \")\nprint('{}'.format(confusion_str))\nprint(\"KAppa Coeefecient=\",kc)\nprint('Test loss {} (%)'.format(Test_loss))\nprint('Test accuracy {} (%)'.format(Test_accuracy))\nprint(classification)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport itertools\n%matplotlib inline\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.get_cmap(\"Blues\")):\n    Normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    if normalize:\n        cm = Normalized\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    plt.imshow(Normalized, interpolation='nearest', cmap=cmap)\n    plt.colorbar()\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        thresh = cm[i].max() / 2.\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\nplt.figure(figsize=(5,5))\nplot_confusion_matrix(confusion, classes=target_names, normalize=False, \n                      title='Confusion matrix, without normalization')\nplt.show()\nplt.figure(figsize=(5,5))\nplot_confusion_matrix(confusion, classes=target_names, normalize=True, \n                      title='Normalized confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Model\nmodel.save('model_happy_detector.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2 \nimport dlib\nfrom PIL import Image\nfrom numpy import asarray\nfrom skimage import io\nimport matplotlib.pyplot as plt\nfrom glob import glob \n\npng = glob('../input/myfaces/*.png', recursive=True)\njpg = glob('../input/myfaces/*.jpg', recursive=True)\njpg2 = glob('../input/myfaces/*.JPG', recursive=True)\n\npaths=png+jpg+jpg2\n\nfor wind in paths:\n    image = io.imread(wind)\n    face_detector = dlib.get_frontal_face_detector()\n    detected_faces = face_detector(image, 1)\n    face_frames = [(x.left(), x.top(),\n                        x.right(), x.bottom()) for x in detected_faces]\n    Image1 = Image.open(wind)\n    to_test=[]\n    for i in range(0,len(face_frames)):\n        croppedIm = Image1.crop((face_frames[i]))\n        croppedIm = croppedIm.resize((48,48))\n        croppedIm = croppedIm.convert('L')\n        data = asarray(croppedIm)\n        #data = MinMaxScaler().fit_transform(data)\n        to_test.append(data)\n    kite = np.array(to_test)\n    kite=np.reshape(kite,(kite.shape[0],kite.shape[1],kite.shape[2],1))\n    final=model.predict(kite)\n    final = np.argmax(np.round(final),axis=1)\n    for i in range(0,len(final)):\n        if(final[i]==0):\n            x = kite[i].astype('float32').reshape(48, 48)\n            plt.imshow(x)\n            plt.show()\n            print(\"Customer\",i,\"was HAPPY\")\n        else:\n            x = kite[i].astype('float32').reshape(48, 48)\n            plt.imshow(x)\n            plt.show()\n            print(\"Customer\",i,\"was NOT HAPPY\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2 \nimport dlib\nfrom PIL import Image\nfrom numpy import asarray\nfrom skimage import io\nimport matplotlib.pyplot as plt\n\nimg_path = '../input/myfaces/test.jpg'\nimage = io.imread(img_path)\nface_detector = dlib.get_frontal_face_detector()\ndetected_faces = face_detector(image, 1)\nface_frames = [(x.left(), x.top(),\n                    x.right(), x.bottom()) for x in detected_faces]\nImage1 = Image.open(img_path)\nto_test=[]\nfor i in range(0,len(face_frames)):\n    croppedIm = Image1.crop((face_frames[i]))\n    croppedIm = croppedIm.resize((48,48))\n    croppedIm = croppedIm.convert('L')\n    data = asarray(croppedIm)\n    #data = MinMaxScaler().fit_transform(data)\n    to_test.append(data)\nkite = np.array(to_test)\nkite=np.reshape(kite,(kite.shape[0],kite.shape[1],kite.shape[2],1))\nfinal=model.predict(kite)\nfinal = np.argmax(np.round(final),axis=1)\nfor i in range(0,len(final)):\n    if(final[i]==0):\n        x = kite[i].astype('float32').reshape(48, 48)\n        plt.imshow(x)\n        plt.show()\n        print(\"Customer\",i,\"was HAPPY\")\n    else:\n        x = kite[i].astype('float32').reshape(48, 48)\n        plt.imshow(x)\n        plt.show()\n        print(\"Customer\",i,\"was NOT HAPPY\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}