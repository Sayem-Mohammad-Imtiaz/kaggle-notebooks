{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Material de aula - Aprendizado de Máquina"},{"metadata":{},"cell_type":"markdown","source":"\n## K-Means - Laboratório 02"},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KMEANS-LIB-01\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KMEANS-LIB-02\ndef tales(x1, x1_min, x1_max, x2_min, x2_max) :\n    '''\n    Esta função faz o escalamento de 1 amostra x1, que pertence ao intervalo [x1_min, x1_max], \n    dentro do intervalo [x2_min, x2_max]\n    \n    Parametros\n    -----------\n    x1     -> valor a ser normalizado\n    x1_min -> valor minimo atingido por x1\n    x1_max -> valor maximo atingido por x1\n    x2_min -> valor minimo da escala de destino\n    x2_max -> valor maximo da escala de destino    \n    \n    Retorno\n    -----------  \n    valor de x1, que pertence ao intervalo [x1_min, x1_max], projetado dentro do intervalo [x2_min, x2_max]\n    '''\n   \n    #Teorema de Tales\n    # ( x2 - x2_min ) / ( x2_max - x2_min ) = ( x1 - x1_min ) / (x1_max - % x1_min);\n    \n    #Definindo x1 como a escala do vetor dado e x2 como a escala de saída (variavel de interesse), isola-se x2:\n    x2 = ( ( x1 - x1_min ) / (x1_max - x1_min) )* ( x2_max - x2_min ) + x2_min\n    \n    return x2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KMEANS-LIB-03\ndef scale(x2_min, x2_max, sampleArray) :\n    '''\n    Esta função faz o escalamento de 1 vetor de amostras para dentro do intervalo [x2_min, x2_max]\n    Ela retorna um vetor com os dados normalizados dentro do dominio dado\n    \n    Parametros\n    -----------\n    x2_min      -> valor minimo da escala de destino\n    x2_max      -> valor maximo da escala de destino\n    sampleArray -> vetor a ser normalizado   \n    \n    Retorno\n    -----------  \n    vetor sampleArray projetado dentro do intervalo [x2_min, x2_max]   \n    '''    \n    x_max = max(sampleArray)\n    x_min = min(sampleArray)\n    \n    sampleArrayNorm = [tales(x, x_min, x_max, x2_min, x2_max) for x in sampleArray]\n    \n    return sampleArrayNorm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KMEANS-LIB-04\ndef euclidean_distance(v1, v2) :\n    '''\n    Esta função recebe 2 arrays (do tipo np.array) e retorna a distância euclidiana entre eles\n    \n    Parâmetros\n    ----------\n    v1 -> vetor de coordenadas do primeiro ponto\n    v2 -> vetor de coordenadas do segundo ponto\n    \n    Retorno\n    -------\n    Distância entre os dois pontos    \n    '''\n    return np.sqrt( sum((v1 - v2)**2) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KMEANS-LIB-05\ndef calcBestK(N) :\n    '''\n    Calcula, a título de \"chute inicial\", um valor para o número de clusters (K)\n    \n    Parametros\n    ----------\n    N -> número de amostras disponiveis\n    \n    Retorno\n    -------\n    Número de clusters a serem usados\n    '''\n    return int(np.sqrt(N/2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KMEANS-LIB-06\ndef kmeans(vData, nClusters) :\n    '''\n    Este método calcula os centroides dos clusters de um conjunto de dados a partir do algoritmo k-means\n    \n    Parâmetros\n    ----------\n    vData -> vetor de coordenadas N-Dimensionais dos dados. Cada posição do array deve ser uma lista de coordenadas\n        \n    Retorno\n    -------\n    Uma tupla (vPoints, vClusterCenters), onde:\n    \n    vPoints -> é um Array contendo a lista de pontos observados, onde cada posição do array corresponde a um clusterId. \n    Cada ponto do array de retorno é definido como um dicionário com a seguinte estrutura:\n        {\n         'pointCoord'  : coordenadas do ponto, \n         'centerCoord' : coordenadas de seu centroide, \n         'clusterId'   : identificador do cluster\n        }\n        \n    vClusterCenters -> é uma lista contendo as coordenadas de cada centróide, ordenadas de acordo com o índice 'clusterId'\n    '''\n\n    #Inicialização sequencial dos centroides\n    #vClusterCenters = [vData[i] for i in range(0, nClusters)]    \n    \n    #Inicialização usando kmeans++\n    vClusterCenters = [vData[0]]\n    for k in range(1, nClusters):\n        D2 = np.array([min([np.inner(c-x,c-x) for c in vClusterCenters]) for x in vData])\n        probs = D2/D2.sum()\n        cumprobs = probs.cumsum()\n        r = np.random.rand()\n        for j,p in enumerate(cumprobs):\n            if r < p:\n                i = j\n                break\n        vClusterCenters.append(vData[i])\n        \n    vPoints = [{'point':point, 'clusterId' : -1, 'centerCoord' : point*0} for point in vData]\n    \n    clusterIsChanging = True\n    while(clusterIsChanging == True) :\n    \n        clusterIsChanging = False\n\n        for dataPoint in vPoints :\n            #Calcula a distancia entre o ponto 'dataPoint' e todos os centroides\n            vDistances = [ euclidean_distance(dataPoint['point'], center) for center in vClusterCenters ]\n            #Define a menor distância\n            clusterIndex = np.argmin(vDistances)\n\n            #Verifica se houve mudança de atribuição e ativa o flag em caso afirmativo            \n            if( dataPoint['clusterId'] != clusterIndex ) :\n                dataPoint['clusterId']  = clusterIndex\n                clusterIsChanging = True\n\n        #Após a redistribuição dos pontos, recalcula os centroides\n        for clusterIndex, clusterCenter in enumerate(vClusterCenters) :\n            #Realiza o agrupamento dos pontos de um dado cluster\n            clusterData = [ point['point'] for point in vPoints if point['clusterId'] == clusterIndex ]\n            #atualiza centroide do cluster indicado pelo clusterIndex\n            vClusterCenters[clusterIndex] = np.mean(clusterData, axis=0) \n\n    #Atualiza as coordenadas dos centroides calculados pelo algoritmo   \n    for dataPoint in vPoints :\n        dataPoint['centerCoord'] = vClusterCenters[dataPoint['clusterId']]\n\n    return (vPoints, vClusterCenters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KMEANS-LIB-07\ndef cluster_distortion(vDataPoints, nClusters) :\n    '''\n    Esta função calcula a distorção intra-cluster\n    \n    Parâmetros\n    ----------\n    vDataPoints -> array contendo os pontos (dados observados). Cada ponto é definido como um dicionário com a seguinte estrutura\n        {'pointCoord' : coordenadas do ponto, 'centerCoord' : coordenadas de seu centroide, 'clusterId' : identificador do cluster}\n    \n    nClusters   -> quantidade de clusters utilizados\n    \n    \n    Retorno\n    -------\n    \n    Um array contendo a distorção intra-cluster de todos os clusters, onde cada posição do array corresponde ao clusterId    \n    '''\n    vClusterDist = []\n    \n    for i in range(nClusters):\n        #Realiza o agrupamento dos pontos de um dado cluster\n        vClusterPoints = [point for point in vDataPoints if point['clusterId']==i]\n        \n        #Calcula a soma das distâncias (elevadas ao quadrado) entre um cada ponto e o centro de seu respectivo cluster. \n        distance = sum([euclidean_distance(point['point'], point['centerCoord'])**2 for point in vClusterPoints])\n        vClusterDist.append(distance)\n        \n    return vClusterDist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CÉLULA KNN-LIB-01\nfrom collections import OrderedDict\ndef kNN(vData, nClasses, value, k) :\n    '''\n    Define a classe a qual pertence um dado valor baseado na quantidade k de vizinhos mais próximos\n    \n    Parâmetros\n    ----------\n    vData    -> array contendo os dados que compõem as observações e suas respectivas denominações (labels)\n    nClasses -> quantidade de classes (labels) utilizada\n    value    -> dado a ser classificado através do k-NN\n    k        -> quantidade de vizinhos necessários para a realização da votação (classificação)\n    \n    Retorno\n    -------\n    A função retorna um valor correspondente ao índice da classe vencedora ('0' -> classe 0, '1' -> classe 1, etc)\n    '''\n    \n    distances = [ {'dist' : euclidean_distance(v1['point'], value), 'class': v1['class']} for v1 in vData ]\n    print(distances)\n    sortedItemsbyDistance = sorted(distances, key=lambda k: k['dist'])\n    \n    selectedNeighbours = sortedItemsbyDistance[0:k]\n    \n    vClasses = np.zeros(nClasses)\n    \n    for neighbour in selectedNeighbours :\n        vClasses[ int(neighbour['class']) ] += 1\n    \n    print(selectedNeighbours)\n    print(vClasses)\n    \n    return np.argmax(vClasses) #indice da classe vencedora ('0' -> classe 0, '1' -> classe 1, etc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Descrição dos dados:\n\nEstes dados são o resultado de uma análise química de vinhos produzidos na mesma região da Itália, porém derivados de 3 cultivares distintos. As análises determinaram as quantidades de 13 constituentes encontrados em cada um dos 3 tipos de vinhos.\n\nOs atributos são:\n\n* Alcohol \n* Malic acid \n* Ash \n* Alcalinity of ash \n* Magnesium \n* Total phenols \n* Flavanoids \n* Nonflavanoid phenols \n* Proanthocyanins \n* Color intensity \n* Hue \n* OD280/OD315 of diluted wines \n* Proline"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(dfDataFile)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Análise Exploratória: faça a carga do arquivo Wine.csv, analise as colunas, as informações e o formato do dataset"},{"metadata":{},"cell_type":"markdown","source":"1. dfWine = pd.read_csv('../input/Wine.csv')"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":false},"cell_type":"code","source":"#IMPLEMENTE O CÓDIGO AQUI\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.  Remova a coluna 'Customer_Segment'"},{"metadata":{"trusted":false},"cell_type":"code","source":"#IMPLEMENTE O CÓDIGO AQUI\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.  Faça a normalização dos dados"},{"metadata":{"trusted":false},"cell_type":"code","source":"#IMPLEMENTE O CÓDIGO AQUI\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.  Execute o algoritmo k-means, imprima os valores dos centroides e distorção dos clusters"},{"metadata":{"trusted":false},"cell_type":"code","source":"#IMPLEMENTE O CÓDIGO AQUI\n#Use 3 clusters\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.  Calcule a dispersão inter cluster e intra cluster"},{"metadata":{"trusted":false},"cell_type":"code","source":"WSS =[] #Dispersão intra-cluster\n\nBSS = [] #dispersão inter cluster\nC = np.mean(dfArrayNorm, axis=0)\n\nfor nClusters in range(1,30) :\n    #Dispersão intra-cluster\n    (clusterData, vClusterCenters) = kmeans(dfArrayNorm, nClusters)\n    cd = cluster_distortion(clusterData, nClusters)\n    WSS.append(sum(cd))\n    \n    #Dispersão inter-cluster\n    B=0\n    for clusterId in range(len(vClusterCenters)) :\n        vDataPoints = [ point for point in clusterData if point['clusterId'] == clusterId]\n        nPoints = len(vDataPoints)\n        clusterCenter = vClusterCenters[clusterId]\n        \n        B += nPoints * euclidean_distance(C, clusterCenter) ** 2\n        \n    BSS.append(B)\n    \n#print(WSS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.  Plote os gráficos de BSS e WSS"},{"metadata":{"trusted":false},"cell_type":"code","source":"#IMPLEMENTE O CÓDIGO AQUI\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.  Usando a coluna 'Customer_segment'  verifique como ficou a clusterização"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Verificando se os dados foram bem clusterizados\n#Retorna a coluna de segmentos\ndfTrainData['Customer_Segment'] = colCustomerSegment\n\n#Fez meio fora de ordem (0, 2, 1)\n#Ou seja, clusterId = 0 -> customer segment = 1\n#Ou seja, clusterId = 2 -> customer segment = 2\n#Ou seja, clusterId = 1 -> customer segment = 3\nclusterCount = [0,0,0]\n# c0_Count = 0\n# c1_Count = 0\n# c2_Count = 0\nclusterDataError = []\nfor i, idVal in enumerate(vClusters):\n    if( idVal == 0 and dfTrainData['Customer_Segment'][i] == 1) :\n        clusterCount[idVal] += 1\n    elif( idVal == 1 and dfTrainData['Customer_Segment'][i] == 3) :\n        clusterCount[idVal] += 1\n    elif( idVal == 2 and dfTrainData['Customer_Segment'][i] == 2) :\n        clusterCount[idVal] += 1\n    else:\n        clusterDataError.append({'idCluster': idVal, 'customerSegment':dfTrainData['Customer_Segment'][i], 'data':dfTrainData.iloc[i, :]})\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clusterCount","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(sum(dfTrainData['Customer_Segment'] == 1))\nprint(sum(dfTrainData['Customer_Segment'] == 2))\nprint(sum(dfTrainData['Customer_Segment'] == 3))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}