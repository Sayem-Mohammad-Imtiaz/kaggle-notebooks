{"cells":[{"metadata":{"_uuid":"8516e4cfe5225b5c02a18f2be3c31313249b24c3","_cell_guid":"07597ed8-0117-4ce1-b5b4-725ae012da4e"},"cell_type":"markdown","source":"# Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Load libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load Data\ndf = pd.read_csv('../input/bitcoin-tweets/bitcointweets.csv', header=None)\npd.set_option('display.max_colwidth', -1)\ndf = df[[1,7]]\ndf.columns = ['tweet','label']\ndf.head()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"collapsed":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11317c6e054b4c596c16aff329af629e4939a5a9","_cell_guid":"fc76f9c9-1c5a-4963-b3a9-50fd7db6746f","trusted":false,"collapsed":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6aa550f242ac6d825be73e3beffc7d2446a0d1bd","_cell_guid":"f4f393bc-9b20-4468-a548-07619c807d21"},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"_uuid":"1054e6ff9eb6f740822d5f02b77df6be35e97a65","_cell_guid":"8d9635ce-a8b1-4a24-9053-3d7a330dfaea","trusted":false,"collapsed":true},"cell_type":"code","source":"# inspect sentiment\nsns.countplot(df['label'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f04659c5285e7235c14324c8558bc7f11e2922c","_cell_guid":"59b34b3d-fc77-4f75-98e9-cac3b7c87c8d","trusted":false,"collapsed":true},"cell_type":"code","source":"# text length\ndf['text_length'] = df['tweet'].apply(len)\ndf[['label','text_length','tweet']].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95a99136765d0708fb02670cb5969680373685d7","_cell_guid":"ee84e678-7cac-49e1-8dae-9d9567aa9ee5","trusted":false,"collapsed":true},"cell_type":"code","source":"df['text_length'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74a798caa157f18952d3a9ff84db0c50db2954a2","_cell_guid":"cc4001ae-92d2-4933-8ed1-c416e3d03d71","trusted":false,"collapsed":true},"cell_type":"code","source":"df['text_length'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e6145cab15f89de5c30421788fa2d6f02590b3d","_cell_guid":"cfbb9c2c-1e61-41a1-a3fb-a555932e3da2","trusted":false,"collapsed":true},"cell_type":"code","source":"g = sns.FacetGrid(df,col='label')\ng.map(plt.hist,'text_length')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da834b058cbbf98856041487f7352d9f1d36f451","_cell_guid":"8065251c-02b3-4156-9cf0-5204828012e7","trusted":true},"cell_type":"code","source":"# word cloud\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nimport re\n\ndef clean_text(s):\n    s = re.sub(r'http\\S+', '', s)\n    s = re.sub('(RT|via)((?:\\\\b\\\\W*@\\\\w+)+)', ' ', s)\n    s = re.sub(r'@\\S+', '', s)\n    s = re.sub('&amp', ' ', s)\n    return s\ndf['clean_tweet'] = df['tweet'].apply(clean_text)\n\ntext = df['clean_tweet'].to_string().lower()    \nwordcloud = WordCloud(\n    collocations=False,\n    relative_scaling=0.5,\n    stopwords=set(stopwords.words('english'))).generate(text)\n\nplt.figure(figsize=(12,12))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"ad7604d1c2ce4733b337943fc3179121a1525c93","_cell_guid":"ae254023-76fa-4976-b1e7-596b425a7567"},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"_uuid":"dfc7fa43bedb887a412fa15dae0373d191493c30","_cell_guid":"d9b27878-6a4c-4b79-8c94-9c4a341d6dcd","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Encode Categorical Variable\nX = df['clean_tweet']\ny = pd.get_dummies(df['label']).values\nnum_classes = df['label'].nunique()\ny","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"c03b31ef33dd73253965c3075c630a91917c7372","collapsed":true,"_cell_guid":"30510a0d-e1c9-46b6-893a-0a4096a7aabc","trusted":true},"cell_type":"code","source":"seed = 101 # fix random seed for reproducibility\nnp.random.seed(seed)","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"415d2b44f9905eff706857c3894b2d45955482f8","_cell_guid":"4048d2cb-e631-4852-ac50-c03e9e68535f","trusted":true},"cell_type":"code","source":"# Split Train Test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.2,\n                                                    stratify=y,\n                                                    random_state=seed)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"8d27d178270ca0ab0c39c1a57cfffee4dc2d9aca","_cell_guid":"5b5cc14e-35e6-4b79-aef6-b8601ddc9645","trusted":true},"cell_type":"code","source":"# Tokenize Text\nfrom keras.preprocessing.text import Tokenizer\nmax_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(X_train))\nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"86792d27e675741dbd0f8e2a4ddbcab191d482d2","_cell_guid":"7c49015e-51ef-458b-bdd1-3d3b33488446","trusted":true},"cell_type":"code","source":"totalNumWords = [len(one_comment) for one_comment in X_train]\nplt.hist(totalNumWords,bins = 30)\nplt.show()","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"f8d2555b18bc7afbf43502cc598265aecb79c6f0","_cell_guid":"f74a6fcd-49c0-4435-a9d1-b5a70838831c","trusted":true},"cell_type":"code","source":"from keras.preprocessing import sequence\nmax_words = 30\nX_train = sequence.pad_sequences(X_train, maxlen=max_words)\nX_test = sequence.pad_sequences(X_test, maxlen=max_words)\nprint(X_train.shape,X_test.shape)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"a8fcbf19ce01ea3997cf48c70ea4356ccb9b3ef3","_cell_guid":"3efeda82-66ce-421e-912d-fbe257f8ddeb"},"cell_type":"markdown","source":"# CNN-LSTM"},{"metadata":{"_uuid":"5c2c26dc04032b89654bc107c26303764de8f3e1","collapsed":true,"_cell_guid":"d2ffbbd7-aa39-4bc4-a077-bf29e7f9bd5b","trusted":true},"cell_type":"code","source":"import keras.backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,Conv1D,MaxPooling1D,LSTM\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\nbatch_size = 128\nepochs = 5","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"05ac8c08b25765831138ba6e05f4918acc10ffb4","collapsed":true,"_cell_guid":"96eade4b-a685-453d-bec1-18d3159fe03c","trusted":false},"cell_type":"code","source":"def get_model(max_features, embed_dim):\n    np.random.seed(seed)\n    K.clear_session()\n    model = Sequential()\n    model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1]))\n    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))    \n    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4636635907eb1230458a340d69add657b5044afe","collapsed":true,"_cell_guid":"d396c577-0a28-4e6f-8176-9b1391a96561","trusted":true},"cell_type":"code","source":"def model_train(model):\n    # train the model\n    model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                          epochs=epochs, batch_size=batch_size, verbose=2)\n    # plot train history\n    plot_model_history(model_history)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"7e066c122a4793b7c9c2748de87cb17188582dd3","collapsed":true,"_cell_guid":"66148c66-a1a9-4e77-a5be-e14c5a84be9d","trusted":true},"cell_type":"code","source":"def plot_model_history(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"cb85c144266881345db8d3ed41f0c4c428e99812","collapsed":true,"_cell_guid":"33de307c-ebad-4ae5-9c20-b02b8fe99240","trusted":true},"cell_type":"code","source":"def model_evaluate(): \n    # predict class with test set\n    y_pred_test =  model.predict_classes(X_test, batch_size=batch_size, verbose=0)\n    print('Accuracy:\\t{:0.1f}%'.format(accuracy_score(np.argmax(y_test,axis=1),y_pred_test)*100))\n    \n    #classification report\n    print('\\n')\n    print(classification_report(np.argmax(y_test,axis=1), y_pred_test))\n\n    #confusion matrix\n    confmat = confusion_matrix(np.argmax(y_test,axis=1), y_pred_test)\n\n    fig, ax = plt.subplots(figsize=(4, 4))\n    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n    for i in range(confmat.shape[0]):\n        for j in range(confmat.shape[1]):\n            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label')\n    plt.tight_layout()","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"7efa2853535be6785e7e7f199fcffcccd89cb198","_cell_guid":"866795f5-ce3f-4ec2-a55b-60a7853f9ab1","trusted":false,"collapsed":true},"cell_type":"code","source":"# train the model\nmax_features = 20000\nembed_dim = 100\nmodel = get_model(max_features, embed_dim)\nmodel_train(model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b26155f7452759c37eb6ffdecba73aaf52f304c","_cell_guid":"edaeed47-4f97-4008-a140-a1208abfa138","trusted":false,"collapsed":true},"cell_type":"code","source":"# evaluate model with test set\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81724a3c10f19c46a83c2d820eb209291b547588","_cell_guid":"68eadc9a-8717-46ef-9692-ca44302d7277"},"cell_type":"markdown","source":"# GloVe.6B.100d + CNN-LSTM"},{"metadata":{"_uuid":"d9c705b1883558fea2c0d6d3688a9d15bd58015a","collapsed":true,"_cell_guid":"8d4c7beb-1b13-4ffc-a14c-988dcf8c2930","trusted":true},"cell_type":"code","source":"def get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n    \ndef get_embed_mat(EMBEDDING_FILE, max_features=20000):\n    # word vectors\n    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n    print('Found %s word vectors.' % len(embeddings_index))\n\n    # embedding matrix\n    word_index = tokenizer.word_index\n    num_words = min(max_features, len(word_index) + 1)\n    all_embs = np.stack(embeddings_index.values()) #for random init\n    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n                                        (num_words, embed_dim))\n    for word, i in word_index.items():\n        if i >= max_features:\n            continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    max_features = embedding_matrix.shape[0]\n    \n    return max_features, embedding_matrix","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"3ec5bf7d279d4d554b338feeedcd35031b7f8201","collapsed":true,"_cell_guid":"0516c2a6-d944-4546-884b-6684e632dc7c","trusted":true},"cell_type":"code","source":"def get_model(max_features, embed_dim, embedding_matrix):\n    np.random.seed(seed)\n    K.clear_session()\n    model = Sequential()\n    model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],\n                       weights=[embedding_matrix]))#,trainable=False\n    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))    \n    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"39e4bc4df71558c82505c5bb91142a66556b1241","_cell_guid":"0ed0eee8-ddde-4f94-bd50-d69dcf82eb62","trusted":true},"cell_type":"code","source":"# embedding matrix\nEMBEDDING_FILE = '../input/glove6b100dtxt/glove.6B.100d.txt'\nembed_dim = 100 #word vector dim\nmax_features, embedding_matrix = get_embed_mat(EMBEDDING_FILE)\n\n# train the model\nmodel = get_model(max_features, embed_dim, embedding_matrix)\nmodel_train(model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e25ab5a61787aecf7209a5415b3aa563ea54c76","collapsed":true,"_cell_guid":"be87bb84-7b64-4f4e-bb46-765a949a7d58","trusted":false},"cell_type":"code","source":"# evaluate model with test set\nmodel_evaluate()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}