{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Personality Type Prediction  \n\nGiven *data about posts people have made*, let's try to predict the **personality type** of a given person.  \n  \nWe will use a TensorFlow RNN to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom nltk.corpus import stopwords\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/mbti-type/mbti_1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['type'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    \n    texts = df['posts'].copy()\n    labels = df['type'].copy()\n    \n    # Process text data\n    stop_words = stopwords.words('english')\n    \n    texts = [text.lower() for text in texts]\n    texts = [text.split() for text in texts]\n    texts = [[word.strip() for word in text] for text in texts]\n    texts = [[word for word in text if word not in stop_words] for text in texts]\n    \n    vocab_length = 10000\n    \n    tokenizer = Tokenizer(num_words=vocab_length)\n    tokenizer.fit_on_texts(texts)\n    \n    texts = tokenizer.texts_to_sequences(texts)\n    \n    max_seq_length = np.max([len(text) for text in texts])\n    \n    texts = pad_sequences(texts, maxlen=max_seq_length, padding='post')\n    \n    # Process label data\n    label_values = [\n        'INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'\n    ]\n    \n    label_mapping = {label: np.int(label[0] == 'E') for label in label_values}\n    \n    labels = labels.replace(label_mapping)\n    labels = np.array(labels)\n    \n    return texts, labels, max_seq_length, vocab_length, label_mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts, labels, max_seq_length, vocab_length, label_mapping = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Text sequences:\\n\", texts.shape)\nprint(\"\\nLabels:\\n\", labels.shape)\nprint(\"\\nMax sequence length:\\n\", max_seq_length)\nprint(\"\\nVocab length:\\n\", vocab_length)\nprint(\"\\nLabel mapping:\\n\", label_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, train_size=0.7, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 512\n\ninputs = tf.keras.Input(shape=(max_seq_length,))\n\nembedding = tf.keras.layers.Embedding(\n    input_dim=vocab_length,\n    output_dim=embedding_dim,\n    input_length=max_seq_length\n)(inputs)\n\ngru = tf.keras.layers.Bidirectional(\n    tf.keras.layers.GRU(\n        units=256,\n        return_sequences=True\n    )\n)(embedding)\n\nflatten = tf.keras.layers.Flatten()(gru)\n\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)\n\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\n\n\nhistory = model.fit(\n    texts_train,\n    labels_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=5,\n    callbacks=[\n        tf.keras.callbacks.ModelCheckpoint('./model.h5', save_best_only=True, save_weights_only=True)\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('./model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(texts_test, labels_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/s3g0MJcJZyA"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}