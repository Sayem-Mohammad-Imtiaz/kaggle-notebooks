{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n    # for filename in filenames:\n        # pass\n        # print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-10T08:30:28.427776Z","iopub.execute_input":"2021-09-10T08:30:28.428382Z","iopub.status.idle":"2021-09-10T08:30:28.432793Z","shell.execute_reply.started":"2021-09-10T08:30:28.428242Z","shell.execute_reply":"2021-09-10T08:30:28.431523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.spatial import distance, distance_matrix ","metadata":{"execution":{"iopub.status.busy":"2021-09-10T08:30:28.448212Z","iopub.execute_input":"2021-09-10T08:30:28.448619Z","iopub.status.idle":"2021-09-10T08:30:29.449267Z","shell.execute_reply.started":"2021-09-10T08:30:28.448585Z","shell.execute_reply":"2021-09-10T08:30:29.448083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imgLoader(path):\n    imgBL = Image.open(path).convert(\"L\")\n    arr = np.array(imgBL)\n    arr = np.where(arr<255,0,1)\n    return arr.astype(\"uint8\")\n\n# plt.subplots(figsize=(25,12)) # for banner\nplt.imshow(\n    np.concatenate(\n        [np.array(imgLoader(\"../input/candle-stick-patterns/cs3_0.png\")),\n        np.array(imgLoader(\"../input/candle-stick-patterns/cs3_10.png\")),\n        np.array(imgLoader(\"../input/candle-stick-patterns/cs3_20.png\")),\n        np.array(imgLoader(\"../input/candle-stick-patterns/cs3_30.png\")),\n        np.array(imgLoader(\"../input/candle-stick-patterns/cs3_40.png\"))],\n        1\n    ), \"gray\")\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T08:30:29.450838Z","iopub.execute_input":"2021-09-10T08:30:29.451169Z","iopub.status.idle":"2021-09-10T08:30:29.633583Z","shell.execute_reply.started":"2021-09-10T08:30:29.451135Z","shell.execute_reply":"2021-09-10T08:30:29.632465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfile_path = glob(\"../input/candle-stick-patterns/*.png\")\ndata_df = pd.DataFrame(file_path, columns=[\"file_path\"])\ndata_df[\"imgID\"] = data_df[\"file_path\"].str.extract(\"_(\\d+)\\.png\").astype(int)\ndata_df[\"imgData\"] = data_df[\"file_path\"].apply(imgLoader)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-10T08:30:29.635648Z","iopub.execute_input":"2021-09-10T08:30:29.635973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.to_pickle(\"data_df.pkl\")\nprint(data_df.shape)\ndata_df[:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{"execution":{"iopub.status.busy":"2021-09-09T10:43:29.948998Z","iopub.execute_input":"2021-09-09T10:43:29.94945Z","iopub.status.idle":"2021-09-09T10:43:30.706842Z","shell.execute_reply.started":"2021-09-09T10:43:29.949413Z","shell.execute_reply":"2021-09-09T10:43:30.705475Z"}}},{"cell_type":"code","source":"mat = data_df.sort_values(\"imgID\")[\"imgData\"].apply(lambda x: x.reshape(1,-1))\nmat = np.concatenate(mat.values)\nmat[:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identify Cluster Distribution","metadata":{}},{"cell_type":"code","source":"# sns.heatmap(mat[:1600,:1600])\n\n# sns.clustermap(mat[:1600,:1600], col_cluster=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndist_mat = distance_matrix(mat[:1600,:1600], mat[:1600,:1600], p=1)\nprint(dist_mat.shape)\ndist_mat[:5,:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.clustermap(dist_mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try AutoEncoder","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras import layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_model():\n    keras.backend.clear_session()\n\n    input_img = keras.Input(shape=(40, 40, 1))\n\n    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n\n    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n    x = layers.UpSampling2D((2, 2))(x)\n    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n    x = layers.UpSampling2D((2, 2))(x)\n    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n    x = layers.UpSampling2D((2, 2))(x)\n    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\n    autoencoder = keras.Model(input_img, decoded)\n    return encoded, decoded, autoencoder\n\nencoded, decoded, autoencoder = define_model()\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\nautoencoder.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_df.sort_values(\"imgID\")[\"imgData\"].apply(lambda x: x.reshape(1,40,40,1))\nX = np.concatenate(X.values)\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(X, X, \n                batch_size=32,\n                epochs=3,\n                verbose=1,\n                validation_split=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ref. https://blog.keras.io/building-autoencoders-in-keras.html","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}