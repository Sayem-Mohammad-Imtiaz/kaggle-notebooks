{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read the data into their respective dataframes","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/titanic-competion-data/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the shape of the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_shape = test.shape\ntrain_shape = train.shape\n\nprint('Output is in (row, col)')\nprint('test.csv: ', test_shape) \nprint('train.csv: ', train_shape) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize our data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsex_pivot = train.pivot_table(index=\"Sex\",values=\"Survived\")\nsex_pivot.plot.bar()\ntrain_pivot = train.pivot_table(index='Pclass', values='Survived')\n\ntrain_pivot.plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we cab see that more women than men survived and that there were a greater number of survivors from 1st class and with descending numbers of survivors down to third class.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Let's examine the age column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[\"Age\"].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survived = train[train[\"Survived\"] == 1]\ndied = train[train[\"Survived\"] == 0]\nsurvived[\"Age\"].plot.hist(alpha=0.5,color='red',bins=50)\ndied[\"Age\"].plot.hist(alpha=0.5,color='blue',bins=50)\nplt.legend(['Survived','Died'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At first glance it looks like the highest number of survivors were in the 18-40 year-old range\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Prepare the data for machine learning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Seperate the age ranges into survived and not survived in order to use for learning model.\n\nWhat ever changes I make to the train set I have to make to the test data set otherwise my learning model will not work. (i.e.) if I add or remove a column in the training set I have to do the same in the test set.\n\n#### Use Pandas \"cut\" to do the heavy lifting here\n\n(From Pandas documentation)\n\nUse cut when you need to segment and sort data values into bins. This function is also useful for going from a continuous variable to a categorical variable. For example, cut could convert ages to groups of age ranges. Supports binning into an equal number of bins, or a pre-specified array of bins.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_age(df,cut_points,label_names):\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n    return df\n\n# define the age cutoff for age classification\ncut_points = [-1,0,18,100] # the ages are in a list\nlabel_names = [\"Missing\",\"Child\",\"Adult\"] # the age categories are in a list\n\ntrain = process_age(train,cut_points,label_names)\ntest = process_age(test,cut_points,label_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_age(df,cut_points,label_names):\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n    return df\n    \ncut_points = [-1,0,5,12,18,35,60,100]\nlabel_names = [\"Missing\",\"Infant\", \"Child\", \"Teenager\", \"Young Adult\", \"Adult\", \"Senior\"] \n\ntrain = process_age(train,cut_points,label_names)\ntest = process_age(test,cut_points,label_names)   \n\npivot = train.pivot_table(index=\"Age_categories\", values=\"Survived\")\npivot.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The bar chart shows the rate of survival based on age group, ignoring sex.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Let's examine the Pclass variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Pclass\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Pclass\"].head(12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare the columns Pclass, Age and Sex for machine learning by creating dummy columns to better represent the data we want to learn from","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dummies(df,column_name):\n    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\ntrain = create_dummies(train,\"Pclass\")\ntest = create_dummies(test,\"Pclass\")\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dummies(df,column_name):\n    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\ntrain = create_dummies(train,\"Pclass\")\ntest = create_dummies(test,\"Pclass\")\n\ntrain = create_dummies(train,\"Sex\")\ntest = create_dummies(test,\"Sex\")\n\ntrain = create_dummies(train,\"Age_categories\")\ntest = create_dummies(test,\"Age_categories\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create the Logistic Regression machine-learning model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now train the model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior'] # The x variables\n\nlr.fit(train[columns], train['Survived']) # The y or target variable we want to predict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First, create a test set from our updated training set\n\nThe convention in machine learning is to call these two parts train and test. This can become confusing, since we already have our test dataframe that we will eventually use to make predictions to submit to Kaggle. To avoid confusion, from here on, we're going to call this Kaggle 'test' data holdout data, which is the technical name given to this type of data used for final predictions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout = test # from now on we will refer to this\n               # dataframe as the holdout data\n\nfrom sklearn.model_selection import train_test_split\n\ncolumns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\n\nall_X = train[columns]\nall_y = train['Survived']\n\ntrain_X, test_X, train_y, test_y = train_test_split(\n    all_X, all_y, test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fit the model on the new training set\n\n### and check the accuracy of the prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nlr = LogisticRegression()\nlr.fit(train_X, train_y)\npredictions = lr.predict(test_X) # here we make our predictions\naccuracy = accuracy_score(test_y, predictions)\n\nprint(\"Our model's accuracy is: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check if I'm overfitting with k-fold cross-validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nimport numpy as np\n\nlr = LogisticRegression()\nscores = cross_val_score(lr, all_X, all_y, cv=10)\n\naccuracy = np.mean(scores)\nprint('Scores = :', scores)\nprint('Accuracy = :', accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We are now ready to use the model we have built to train our final model and then make predictions on our unseen holdout data, or what Kaggle calls the 'test' data set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\nlr = LogisticRegression()\nlr.fit(all_X,all_y)\nholdout_predictions = lr.predict(holdout[columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now create the Kaggle submission file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout_ids = holdout[\"PassengerId\"]\nsubmission_df = {\"PassengerId\": holdout_ids,\n                 \"Survived\": holdout_predictions}\nsubmission = pd.DataFrame(submission_df)\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's save the submission.csv ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('submission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}