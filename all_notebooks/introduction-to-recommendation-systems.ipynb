{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Movie Recommendation system with Movielens Dataset\nA Recommender System can be defined as an algorithm that performs information filtering by trying to provide the most relevant and accurate items that fit a user's needs and interests from a large pool of Information. Recommendation systems could be used to recommend Movies, Products, Friends (on social media) and even articles, the list is endless. Compaines such as Facebook,Amazon, Netflix, Linkedin use recommendation systems to filter content.\n\n## Types of RS\n1. Collaborative filtering recommender systems\n2. Content-based recommender systems\n3. Hybrid recommender systems\n4. Context-aware recommender systems\n\nFor this example, we will focus on an introduction to building a Recommendation system using the Collaborative filtering:User-based collaborative filtering Approach. User-based Collaborative filtering is an algorithm which is used to make automatic predictions about a user's interests by compiling preferences from several simliar users.\n\nFor this introduction, we won't dive int the technicality of extracting features using Natural Language processing. We will focus on these features:\n* User ID\n* Movie ID\n* User's Rating for a specific Movie\n* Tag\n\nSo, lets import our dataset of rated movies and see what our data looks like."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import \"Movie Lens Small Latest Dataset\" dataset\n\nimport pandas as pd\nimport numpy as np\nimport warnings; warnings.simplefilter('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nlinks= pd.read_csv('../input/movie-lens-small-latest-dataset/links.csv')\nmovies=pd.read_csv('../input/movie-lens-small-latest-dataset/movies.csv')\nratings=pd.read_csv('../input/movie-lens-small-latest-dataset/ratings.csv')\ntags=pd.read_csv('../input/movie-lens-small-latest-dataset/tags.csv')\n\ndataset=movies.merge(ratings,on='movieId').merge(tags,on='movieId').merge(links,on='movieId')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we drop the columns we would not be using in this tutorial and view a summary of out table."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"to_drop=['title','genres','timestamp_x','timestamp_y','userId_y','imdbId','tmdbId']\n\ndataset.drop(columns=to_drop,inplace=True)\nprint(dataset.describe())\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.get_dummies(dataset) #encode the catergorical data\n\nprint(dataset)\ndataset.isnull().sum()# check the number of missing data cells","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the output above, we dont need to handle missing data since the dataset is complete. So the next step is to divide our datset into training and tests. We also need to seperate our features from our labels.\n\nFor this problem set, our label would be the \"ratings\" score."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Divide data into test,train and validation\n#train dataset\ntrain_dataset = dataset.sample(frac=0.9,random_state=0) #90% of the dataset\ntest_dataset=dataset.drop(train_dataset.index) #10% of the Dataset\n\n\n#seperate labels\ntrain_labels = train_dataset.pop('rating')\ntest_labels = test_dataset.pop('rating')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model\nWe are going to handle this as a regression problem because even though the possible range of ratings is enclosed in values 0-5, our dataset summary above shows we have ratings such as \"3.5\" in our dataset.\n\nWe will be building a Regression Model using the Random Forest Algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import metrics\n\n#scale the features\nsc = StandardScaler()\ntrain_dataset = sc.fit_transform(train_dataset)\ntest_dataset = sc.fit_transform(test_dataset)\n\n#train model\nregressor = RandomForestRegressor(n_estimators=10, random_state=0)\nregressor.fit(train_dataset, train_labels)\n\n#predict ratings on test data\npredicted_labels = regressor.predict(test_dataset)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_absolute_percentage_error(y_true, y_pred): \n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating Model Performance "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nactual_labels=np.array(test_labels)\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(actual_labels, predicted_labels))\nprint('Mean Squared Error:', metrics.mean_squared_error(actual_labels, predicted_labels))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(actual_labels, predicted_labels)))\nprint('Mean Average Percentage Error: ',mean_absolute_percentage_error(actual_labels,predicted_labels))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of Test Labels',actual_labels.size)\nprint('Size of Predicted Labels',predicted_labels.size)\n\n#create a new dataframe\npredicted_movies=pd.DataFrame({'Actual':actual_labels,'Predicted':predicted_labels}).reset_index()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is a Table showing Predicted User Ratings Vs the Actual ratings given by those users."},{"metadata":{"trusted":true},"cell_type":"code","source":"#print Table of Test Dataset\npredicted_movies.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize Prediction Results\n\n1. Histogram showing distribution of Prediction Errors"},{"metadata":{"trusted":true},"cell_type":"code","source":"difference=actual_labels-predicted_labels\nplt.hist(difference,normed=True,color='orange',bins=15,alpha=0.8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Line plot showing first 50 predictions in Test Dataset. A graph of **Actual** ( *in Blue*) vs **Predicted** (*in Orange*) User rating on movies."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nmapping=predicted_movies['Actual'][:50].plot(kind='line',x='Datetime',y='Volume BTC',color='blue',label='Actual')\npredicted_movies['Predicted'][:50].plot(kind='line',x='Datetime',y='Volume BTC',color='orange',label='Predicted',ax=mapping)\nmapping.set_xlabel('Users')\nmapping.set_ylabel('Ratings')\nmapping.set_title('Regression Graph show Actual vs Predicted ratings')\nmapping=plt.gcf()\nmapping.set_size_inches(20,12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Joint plot showing KDE graph of Actual vs Predicted Ratings."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(predicted_movies['Actual'],predicted_movies['Predicted'],predicted_movies,kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feedback\nIf you liked this notebook, have suggestions, recommendations or need clarifications,drop your comments  below. If this was helpful an upvote would be appreciated.\n\n### Contact Me:\nFeel free to contact me via samtheo1597@gmail.com, +2348151475929"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}