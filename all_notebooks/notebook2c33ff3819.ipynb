{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Importing Useful Libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\nwarnings.simplefilter('ignore', ConvergenceWarning)\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.exceptions import ConvergenceWarning\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom pandas import DataFrame\nfrom matplotlib import pyplot\nfrom pandas.plotting import autocorrelation_plot\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Base Time Series Load And Some Important Visualizations**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def parser(x):\n    return datetime.strptime('190'+x, '%Y-%m')\nseries = read_csv('../input/shampoo/shampoo1.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\nprint(series.head())\nseries.plot()\npyplot.show()\n\nautocorrelation_plot(series)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generating Other Time Series by adding noise to the base time series. \n\nWe have 5 time series here:\n\n1)- Four of them(series, series1, series2 and series3) are modelled as the sales of 4 different products.\n\n2)- combs series adds all the four series and hence make aggregate calculations for it**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnp.random.seed(0)\n\nseries1=series.copy()+np.random.randint(-50,50,len(series))+200\nseries2=series.copy()+np.random.randint(10,110,len(series))+150\nseries3=series.copy()+np.random.randint(-70,30,len(series))+100\ncombs = series1+series2+series3+series","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Plotting the four series individually to have a better look at data distribution**"},{"metadata":{"trusted":true},"cell_type":"code","source":"series.plot()\npyplot.title('series')\npyplot.show()\n\nseries1.plot()\npyplot.title('series1')\npyplot.show()\n\nseries2.plot()\npyplot.title('series2')\npyplot.show()\n\nseries3.plot()\npyplot.title('series3')\npyplot.show()\n\ncombs.plot()\npyplot.title('Aggregated Time Series')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a function that calculates the error. \n# The forecasts are made on an extended period using rolling SARIMAX"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"@ignore_warnings(category=ConvergenceWarning)\ndef repeated(series):\n    # pridiction \n    X = series.values\n    size = int(len(X) * 0.7)\n    train, test = X[0:size], X[size:len(X)]\n    history = [x for x in train]\n    predictions = list()\n    for t in range(len(test)):\n        model = SARIMAX(history, order=(1, 1, 1), seasonal_order=(1, 1, 1, 2))\n        model_fit = model.fit(disp=False)\n        output = model_fit.forecast()\n        yhat = output[0]\n        predictions.append(yhat)\n        obs = test[t]\n        history.append(obs)\n    error = sum([abs(i-j) for (i,j) in zip(test,predictions)])\n    return error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EVALUATING THE PERFORMANCE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"@ignore_warnings(category=ConvergenceWarning)\ndef Evaluation():\n    individual_series = [series, series1, series2, series3]\n    summed_indi_errors = 0\n    for i in individual_series:\n        error = repeated(i)\n        summed_indi_errors+=error\n    comb_error = repeated(combs)\n    diff = summed_indi_errors - comb_error\n    print(\"Difference between individual and combined error\",diff)\n    percentage_difference = (diff/summed_indi_errors)*100\n    print(\"percentage_difference\", percentage_difference)\nEvaluation()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **RESULTS**"},{"metadata":{},"cell_type":"markdown","source":"Thus we see that risk pooling(combining demands of four different products and then forecasting) reduced the error in forecasts.\n\nAs per above calculations, \n\n**(combined error - sum(individual errors)) almost 13.8% of the sum(individual errors)(variable according to seed set)\n**\n\nThis is a very good increase in performance and can lead to great monetary benefits."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}