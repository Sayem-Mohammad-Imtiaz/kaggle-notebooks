{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostClassifier, Pool\n#import datawig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/jobathon-analytics-vidhya/train.csv')\ntest = pd.read_csv('../input/jobathon-analytics-vidhya/test.csv')\nprint(df.shape,test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#categorizing features\nnum_attribs = ['ID','Region_Code','Upper_Age', 'Lower_Age','Reco_Policy_Premium']\ncat_attribs = ['City_Code','Accomodation_Type','Reco_Insurance_Type',\n               'Is_Spouse','Health Indicator','Holding_Policy_Duration','Holding_Policy_Type','Reco_Policy_Cat',]\ntarget = ['Response']\nlen(df.columns) == len(num_attribs)+len(cat_attribs)+len(target)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## EDA Part1"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"fig = df[num_attribs].hist(figsize=(20,15))\n# can combine upper age and lower age","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"fig = df[['Reco_Policy_Premium']].boxplot(figsize=(8,5))\n#presence of Outliers","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"fig = df[['Upper_Age','Lower_Age']].boxplot(figsize=(8,5))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"sns.countplot(x='Response',data=df)\n#Imbalanced dataset","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## baseline model"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"df['Response'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"num_attribs1 = [i for i in num_attribs if i not in ['Upper_Age', 'Lower_Age']]\nprint(num_attribs)\nprint(num_attribs1)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"# Baseline Model\n\ndef compare_model(data,testing):\n    \n    num_attribs = ['Region_Code','Upper_Age', 'Lower_Age','Reco_Policy_Premium']\n    cat_attribs = ['City_Code','Accomodation_Type','Reco_Insurance_Type',\n               'Is_Spouse','Health Indicator','Holding_Policy_Duration','Holding_Policy_Type','Reco_Policy_Cat']\n    target = ['Response']\n    \n    if testing==1:\n        #testing part\n        new_features_num = []\n        new_features_cat = []\n        drop_features = []\n        num_attribs = [i for i in num_attribs if i not in drop_features]\n        cat_attribs = [i for i in cat_attribs if i not in drop_features]\n        num_attribs = num_attribs + new_features_num\n        cat_attribs = cat_attribs + new_features_cat\n        data = data.drop(drop_features,axis=1)\n    \n    #preprocessing\n    \n    imputer  = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n    data['Health Indicator'] = imputer.fit_transform(data['Health Indicator'].values.reshape(-1,1))\n    data['Holding_Policy_Duration'] = imputer.fit_transform(data['Holding_Policy_Duration'].values.reshape(-1,1))\n    data['Holding_Policy_Type'] = imputer.fit_transform(data['Holding_Policy_Type'].values.reshape(-1,1))\n    \n    \n    print(\"num attribs :{}\".format(num_attribs))\n    print(\"cat attribs :{}\".format(cat_attribs))\n    \n    \n    X=data[num_attribs+cat_attribs]\n    \n    y=data[target]\n    \n    print('Data shape {} X shape {} y shape {} '.format(data.shape,X.shape,y.shape))\n\n    full_pipeline = ColumnTransformer([\n        (\"num\", StandardScaler(), num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs)\n    ],remainder='passthrough')\n    \n\n    X = full_pipeline.fit_transform(X)\n    \n    #Train-Test split\n    print(\"X shape {} and y shape {}\".format(X.shape,y.shape))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\n    print('X_train shape {} X_test shape {} y_train shape {} y_test shape {}'.format(X_train.shape,X_test.shape,y_train.shape,y_test.shape))\n    \n    #Model1\n    dc = DecisionTreeClassifier(random_state=0)\n    dc.fit(X_train,y_train)\n    y_pred_dc = dc.predict(X_test)\n    dc_acc = accuracy_score(y_test, y_pred_dc, normalize=True)\n    roc_auc_dc = roc_auc_score(y_test, dc.predict_proba(X_test)[:, 1])\n    \n    #Model2\n    rf = RandomForestClassifier(random_state=0)\n    rf.fit(X_train,y_train)\n    y_pred_rf = rf.predict(X_test)\n    rf_acc = accuracy_score(y_test, y_pred_rf, normalize=True)\n    roc_auc_rf = roc_auc_score(y_test, rf.predict_proba(X_test)[:,1])\n    \n    #Model3\n    lr = LogisticRegression(random_state=0).fit(X, y)\n    y_pred_lr = lr.predict(X_test)\n    lr_acc = accuracy_score(y_test, y_pred_lr, normalize=True)\n    roc_auc_lr = roc_auc_score(y_test, lr.decision_function(X_test))\n    \n    \n    print('Tree accuracy: {} , Forest accuracy:{} , Log Reg accuracy:{}'.format(round(dc_acc,4),round(rf_acc,4),round(lr_acc,4)))\n    print('Tree roc_auc: {} , Forest roc_auc:{} , Log Reg roc_auc:{}'.format(round(roc_auc_dc,4),round(roc_auc_rf,4),round(roc_auc_lr,4))) ","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"compare_model(df,0)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## EDA part2"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"cat_attribs","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"k=0\nfor i in cat_attribs:\n    print('Column : {}'.format(i))\n    print(df[i].value_counts())\n    print('**'*50)\n    k+=1\nprint(\"Total {} category columns are there\".format(k))\n\n#","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"def percent(axs,m):\n    k=0\n    for p in axs.patches:\n        k+=1\n        if k==1:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[0]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==3:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[0]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==2:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[1]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==4:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[1]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n            \n\ndef percent4(axs,m):\n    k=0\n    for p in axs.patches:\n        k+=1\n        if k==1:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[1]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==3:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[3]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==2:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[2]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==4:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[4]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==5:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[1]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==6:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[2]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==7:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[3]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')\n        if k==8:\n            percentage = '{:.1f}%'.format(100 * (p.get_height()/df[m].value_counts()[4]))\n            x = p.get_x() + p.get_width()/2\n            y = p.get_height()/2\n            axs.annotate(percentage, (x, y),ha='center')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"fig,axs = plt.subplots(2,2,figsize=(15,10))\nfig.suptitle('Visualising')\n\nax1 = sns.countplot(ax=axs[0,0],x=\"Accomodation_Type\",hue='Response',data=df)\npercent(ax1,\"Accomodation_Type\")\n\nax2 = sns.countplot(ax=axs[0,1],x=\"Reco_Insurance_Type\",hue='Response', data=df)\npercent(ax2,\"Reco_Insurance_Type\")\n\nax3 = sns.countplot(ax=axs[1,0],x=\"Is_Spouse\",hue='Response', data=df)\npercent(ax3,\"Is_Spouse\")\n\nax4=sns.countplot(ax=axs[1,1],x=\"Holding_Policy_Type\",hue='Response', data=df)\npercent4(ax4,\"Holding_Policy_Type\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"fig,axs = plt.subplots(2,2,figsize=(16,10))\nfig.suptitle('Visualising')\n\nax1 = sns.countplot(ax=axs[0,0],x='City_Code',hue='Response',data=df)\nax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\nax2 = sns.countplot(ax=axs[0,1],x='Health Indicator',hue='Response', data=df)\nax3 = sns.countplot(ax=axs[1,0],x='Holding_Policy_Duration',hue='Response', data=df)\nax4=sns.countplot(ax=axs[1,1],x='Reco_Policy_Cat',hue='Response', data=df)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"def yn_ratio(data,column):\n    dg = data[[column,'Response']].groupby([column])\n    dg = dg.Response.value_counts().to_frame() \n    \n    C,Yes,No=[],[],[]\n    for i in range(len(dg)):\n        if i%2!=0:\n            Yes.append(dg.iloc[i,0])\n        if i%2==0:\n            No.append(dg.iloc[i,0])\n            C.append(str(dg.index[i][0]))\n            \n    dic = {column:C,'Yes':Yes,'No':No}\n    dgv = pd.DataFrame(dic)\n    dgv['Y/N'] = dgv['Yes']/dgv['No']\n \n    plt.figure(figsize=(14,6))\n    ax = sns.barplot(dgv[column],dgv['Y/N'])\n    plt.xticks(rotation=45)\n    #return dgv","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"yn_ratio(df,'City_Code')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"yn_ratio(df,'Health Indicator')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"yn_ratio(df,'Holding_Policy_Duration')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"yn_ratio(df,'Reco_Policy_Cat')","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Feature Enginnering"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"#Test 1 : Averaging upper_age and lower_age\ndf1 = df.copy()\ndf1['mean_age'] = (df1.Upper_Age + df1.Lower_Age)/2\ndf1.head(1)\n\n#result : same roc in all, so not advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"#Test 2: Changing Region code to category\n\ndf1 = df.copy()\ndf1['reg_code'] = df1['Region_Code'].apply(lambda x : 'A' if x<=1000 else\n                                           ('B' if 1000<x<=2000 else\n                                            ('C' if 2000<x<=3000 else ('D' if 3000<x<=4000 \n                                                                       else ('E' if 4000<x<=5000 else 'F')))))\nsns.countplot(df1['reg_code'],order=['A','B','C','D','E','F'])\n\n#result1 : All 3 roc are lower than baseline, not advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"#Test 3 : Dropping Region Code\n#result : roc dropped by 2-3%, Not advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"#Test 4 : Difference of Upper and Lower Age\ndf1 = df.copy()\ndf1['mean_age'] = df1.Upper_Age - df1.Lower_Age\ndf1.head(1)\n#result : No such difference, not advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x='Response', y=\"Reco_Policy_Premium\")","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"#Test 5 : Removing outliers from Reco Policy Premium\ndf1 = df.copy()\ndf1 = df1.drop(df1.loc[df1.Reco_Policy_Premium>32000].index)\n#result : roc improved by 1% , Advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"#Test 6 : New feature showing 1 if Health indicator =X7 or Reco policy cat = 15 or city_code=c30\ndf1 = df.copy()\nnf = []\nfor i in range(len(df1)):\n    if (df1['Health Indicator'].iloc[i]=='X7' or df1['Reco_Policy_Cat'].iloc[i]== 15 or df1['City_Code'].iloc[i]=='C30'):\n        nf.append(1)\n    else:\n        nf.append(0)\ndf1['nf'] = nf\ndf1.loc[(df1['Health Indicator']=='X7') | (df1['Reco_Policy_Cat']== 15) | (df1['City_Code']=='C30')].head(2)\n\n#result : Same, not advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"#Test7 : replacing 'Health Indicator','Holding_Policy_Duration','Reco_Policy_Cat' and 'City_Code' by their y/n percentage\ndf1 = df.copy()\ndgv_cc = yn_ratio(df1,'City_Code').set_index('City_Code').to_dict()\ndgv_hi = yn_ratio(df1,'Health Indicator').set_index('Health Indicator').to_dict()\ndgv_hpd = yn_ratio(df1,'Holding_Policy_Duration').set_index('Holding_Policy_Duration').to_dict()\ndgv_rpc = yn_ratio(df1,'Reco_Policy_Cat').set_index('Reco_Policy_Cat').to_dict()\n\ncc,hi,hpd,rpc = [],[],[],[]\nfor i in range(len(df1)):\n    city = df1.City_Code.iloc[i]\n    yn_cc = (dgv_cc['Y/N'][city])\n    cc.append(yn_cc)\n    \n    health = df1['Health Indicator'].iloc[i]\n    yn_hi = (dgv_hi['Y/N'][health])\n    hi.append(yn_hi)\n    \n    hold = df1.Holding_Policy_Duration.iloc[i]\n    yn_hpd = (dgv_hpd['Y/N'][hold])\n    hpd.append(yn_hpd)\n    \n    reco = df1.Reco_Policy_Cat.iloc[i]\n    yn_rpc = (dgv_rpc['Y/N'][str(reco)])\n    rpc.append(yn_rpc)\n    \ndf1['cc'] = cc\ndf1['hi'] = hi\ndf1['hpd'] = hpd\ndf1['rpc'] = rpc\n\n#result : roc declined , not advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"df1.head(2)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"#Test8 : Imputing missing values by machine learning\ndf1 = df.copy()\npd.isnull(df1).sum().sort_values(ascending=False)\n\n#result : roc increased, advisable","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"# Imputing Data using DeepLearning by Datawig library\n\ndef impute(data):\n    col = ['Health Indicator','Holding_Policy_Duration','Holding_Policy_Type']\n    for name in col:\n        index_null=[]\n        imputed_list = []\n        completed = []\n        input_col = [ 'City_Code', 'Region_Code', 'Accomodation_Type',\n       'Reco_Insurance_Type', 'Upper_Age', 'Lower_Age', 'Is_Spouse','Reco_Policy_Cat', 'Reco_Policy_Premium'] + completed\n        \n        for i in range(len(data)):\n            if pd.isnull(data[name]).iloc[i]==True:\n                index_null.append(i)\n    \n        index_nn = list(set(data.index)-set(index_null))\n\n        df1_train, df1_test = data.loc[index_nn],data.loc[index_null]\n\n        #Initialize a SimpleImputer model\n        imputer = datawig.SimpleImputer(\n            input_columns= input_col,output_column= name, output_path = 'imputer_model_'+name+'_test')\n\n        #Fit an imputer model on the train data\n        imputer.fit(train_df=df1_train)\n\n        #Impute missing values and return original dataframe with predictions\n        imputed = imputer.predict(df1_test)\n        \n        imputed_list = []\n        for i in range(len(data)):\n            if i%5000==0:\n                print('J'+str(i))\n            if pd.isnull(data[name].iloc[i])==True:\n                idx = data.ID.iloc[i]\n                val = imputed.loc[imputed.ID==idx][name+'_imputed'].iloc[0]\n                imputed_list.append(val)\n            else:\n                val = data[name].iloc[i]\n                imputed_list.append(val)\n        data['imp_'+name] = imputed_list\n\n        completed.append('imp_'+name)\n        print('column {} is imputed with {} imputations'.format(name,len(imputed[name])))\n        \n        \n# Generated three new_features imp_Health Indicator,imp_Holding_Policy_Duration,imp_Holding_Policy_Type which contains the values of \n#'Holding_Policy_Duration', 'Holding_Policy_Type' and 'Health Indicator' alongwith their imputed values. \n#data is stored in ../input/avjobhack/df1.csv","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/avjobhack/df1.csv')\npd.isnull(df1).sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"# Test 9 : removing outliers from region_code\ndf1 = df.copy()\nsns.boxplot(df1['Region_Code'])\ndf1 = df1.drop(df1.loc[df1.Region_Code>5800].index)\n\n#result : roc decreased, not advisable","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"test['Holding_Policy_Type'] = np.where(pd.isnull(test['Holding_Policy_Type']),test['Holding_Policy_Type'],test['Holding_Policy_Type'].astype(str))\nimpute(test)\n\n# result is stored in ../input/avhacktest1/test_fin.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/avhacktest1/test_fin.csv')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/avjobhack/df1.csv')\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"train = train.drop(['Health Indicator', 'Holding_Policy_Duration', 'Holding_Policy_Type'],axis=1)\ntrain = train.drop(train.loc[train.Reco_Policy_Premium>32000].index)\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"def data_prep(data):\n    \n    num_attribs = ['Region_Code','Upper_Age', 'Lower_Age','Reco_Policy_Premium']\n    cat_attribs = ['City_Code','Accomodation_Type','Reco_Insurance_Type',\n               'Is_Spouse','imp_Health Indicator','imp_Holding_Policy_Duration','imp_Holding_Policy_Type','Reco_Policy_Cat',]\n    target = ['Response']\n    \n    print(\"num attribs :{}\".format(num_attribs))\n    print(\"cat attribs :{}\".format(cat_attribs))\n        \n    X=data[num_attribs+cat_attribs]\n    y=data[target]\n    \n    print('Data shape {} X shape {} y shape {} '.format(data.shape,X.shape,y.shape))\n\n    full_pipeline = ColumnTransformer([\n        (\"num\", StandardScaler(), num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs)\n    ],remainder='passthrough')\n    \n    X = full_pipeline.fit_transform(X) \n    \n    return X,y \n\nX_train,y_train = data_prep(train)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"print(type(X_train.toarray()))\nprint(type(y_train))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"heading_collapsed":true,"hidden":true},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"#XGBoost\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn import metrics     #Additional scklearn functions\nfrom sklearn.model_selection import GridSearchCV #Perforing grid search\n\ntrain \ndef modelfit(alg, X,y,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n    \n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(X, label=y.values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n        alg.set_params(n_estimators=cvresult.shape[0])\n    \n    #Fit the algorithm on the data\n    alg.fit(X, y,eval_metric='auc')\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(X)\n    dtrain_predprob = alg.predict_proba(X)[:,1]\n        \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y.values, dtrain_predictions))\n    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y, dtrain_predprob))\n      \n    return alg     \n    ","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"xgb1 = XGBClassifier(\n learning_rate =0.1,\n n_estimators=1000,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\n\nmodel_xgb1 = modelfit(xgb1,X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"model_xgb1","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"param_test1 = {\n 'max_depth':range(3,10,2),\n 'min_child_weight':range(1,6,2)\n}\ngsearch1 = GridSearchCV(estimator = model_xgb1, \n param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch1.fit(X_train,y_train)\n#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"gsearch1.best_params_, gsearch1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"param_test2 = {\n 'max_depth':[4,5,6],\n 'min_child_weight':[1,2,3,4,5,6,7]\n}\ngsearch2 = GridSearchCV(estimator = model_xgb1, \n param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch2.fit(X_train,y_train)\ngsearch2.best_params_, gsearch2.best_score_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"model_xgb1","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"param_test3 = {\n 'gamma':[i/10.0 for i in range(0,5)]\n}\ngsearch3 = GridSearchCV(estimator = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=6,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=237, n_jobs=4, nthread=4, num_parallel_tree=1,\n              objective='binary:logistic', random_state=27, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, seed=27, subsample=0.8,\n              tree_method='exact', use_label_encoder=True,\n              validate_parameters=1, verbosity=None), \n param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch3.fit(X_train,y_train)\ngsearch3.best_params_, gsearch3.best_score_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"model_xgb2 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.8, gamma=0.2, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=6,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=237, n_jobs=4, nthread=4, num_parallel_tree=1,\n              objective='binary:logistic', random_state=27, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, seed=27, subsample=0.8,\n              tree_method='exact', use_label_encoder=True,\n              validate_parameters=1, verbosity=None)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"param_test4 = {\n 'subsample':[i/10.0 for i in range(6,10)],\n 'colsample_bytree':[i/10.0 for i in range(6,10)]\n}\ngsearch4 = GridSearchCV(estimator = model_xgb2, \n param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch4.fit(X_train,y_train)\ngsearch4.best_params_, gsearch4.best_score_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"model_xgb3 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6, gamma=0.2, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=6,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=237, n_jobs=4, nthread=4, num_parallel_tree=1,\n              objective='binary:logistic', random_state=27, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, seed=27, subsample=0.9,\n              tree_method='exact', use_label_encoder=True,\n              validate_parameters=1, verbosity=None)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"param_test6 = {\n 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n}\ngsearch6 = GridSearchCV(estimator = model_xgb3, \n param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch6.fit(X_train,y_train)\ngsearch6.best_params_, gsearch6.best_score_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"model_xgb4 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6, gamma=0.2, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.01, max_delta_step=0, max_depth=6,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=237, n_jobs=4, nthread=4, num_parallel_tree=1,\n              objective='binary:logistic', random_state=27, reg_alpha=1e-05,\n              reg_lambda=1, scale_pos_weight=1, seed=27, subsample=0.9,\n              tree_method='exact', use_label_encoder=True,\n              validate_parameters=1, verbosity=None)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"model_xgb4.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"def pred(test,model):\n    test = pd.read_csv('test_fin.csv')\n    num_attribs = ['Region_Code','Upper_Age', 'Lower_Age','Reco_Policy_Premium']\n    cat_attribs = ['City_Code','Accomodation_Type','Reco_Insurance_Type',\n               'Is_Spouse','imp_Health Indicator','imp_Holding_Policy_Duration','imp_Holding_Policy_Type','Reco_Policy_Cat']    \n\n        \n    X=test[num_attribs+cat_attribs]\n\n    \n    print('Data shape {} X shape {}  '.format(test.shape,X.shape))\n\n    full_pipeline = ColumnTransformer([\n        (\"num\", StandardScaler(), num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs)\n    ],remainder='passthrough')\n    \n    X_test = full_pipeline.fit_transform(X) \n    print(X_test.shape)\n    \n    y_fin = model.predict(X_test)\n    \n    return y_fin","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"y_fin = pred(test,model_xgb4)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"y_fin","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"fin = pd.DataFrame(y_fin, columns = ['Response'])\nfin.head()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"fin.Response.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"fin['ID'] = test['ID']\nfin.head()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"fin.to_csv('fin_xgb2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true,"hidden":true},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"n_estimators = [100, 300, 500, 800, 1200]\nmax_depth = [5, 8, 15, 25, 30]\nmin_samples_split = [2, 5, 10, 15, 100]\nmin_samples_leaf = [1, 2, 5, 10] ","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [50,100, 300, 500, 800, 1200]\nmax_depth = [5, 8, 15, 25, 30]\nmin_samples_split = [2, 5, 10, 15, 100]\nmin_samples_leaf = [1, 2, 5, 10,15] \nmax_features = [2, 3, 4 , 5,6,7,8]\n\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf, max_features=max_features)\n\nforest = RandomForestClassifier()\n\ngridF = RandomizedSearchCV(forest, hyperF, cv = 3, verbose = 1, n_jobs = -1)\nbestF = gridF.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"bestF.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [40,45,50,55,60,65]\nmax_depth = [10,13,15,17,19]\nmin_samples_split = [2,3,1,4,5]\nmin_samples_leaf = [3,4, 5,7,9] \nmax_features = [5,6,7,8,9,10,11,12,13]\n\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf, max_features=max_features)\n\nforest = RandomForestClassifier()\n\ngridF = RandomizedSearchCV(forest, hyperF, cv = 3, verbose = 1, n_jobs = -1)\nbestF = gridF.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"bestF.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [55,60,65]\nmax_depth = [19,22,25]\nmin_samples_split = [5,8,10]\nmin_samples_leaf = [2,4,6] \nmax_features = [13,17,20]\n\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf, max_features=max_features)\n\nforest = RandomForestClassifier()\n\ngridFin = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, n_jobs = -1)\nbestF = gridFin.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"RF = bestF.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"RF.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"y_rf = pred(test,RF)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"fin = pd.DataFrame(y_rf, columns = ['Response'])\nfin.head()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"fin['ID'] = test['ID']\nfin.Response.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"fin.to_csv('fin_rf.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true,"hidden":true},"cell_type":"markdown","source":"### CatBoost Classifier"},{"metadata":{},"cell_type":"markdown","source":"A little story before we move on to this part, the Catboost classifier part was added after the competition to the notebook. I tried XGBoost, Random Forest but was stuck in 0.68 ROC-AUC. I even tried in another google colab notebook parallely Light GBM and KerasClassifier(Neural Network) but alas none could cross the 0.70 mark.\n\nBut then today in the competition forum discussion part I saw Shobhit saying a magic word can increase your score to 0.80 and then I applied CatBoost. What to do sometimes, luck is not on your side :)"},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"# Credit for below part : shobhit upadhyaya ,Github link : https://github.com/asingleneuron","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/avjobhack/df1.csv')\ntest = pd.read_csv('../input/avhacktest1/test_fin.csv')\ndf1 = df1.drop(df1.loc[df1.Reco_Policy_Premium>32000].index)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"df1['imp_Holding_Policy_Type'] = df1['imp_Holding_Policy_Type'].astype(str)\ntest['imp_Holding_Policy_Type'] = test['imp_Holding_Policy_Type'].astype(str)\n\ndf1['Reco_Policy_Cat'] = df1['Reco_Policy_Cat'].astype(str)\ntest['Reco_Policy_Cat'] = test['Reco_Policy_Cat'].astype(str)\n\ndf1['Region_Code'] = df1['Region_Code'].astype(str)\ntest['Region_Code'] = test['Region_Code'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"cols_to_remove = ['ID','Health Indicator','Holding_Policy_Duration','Holding_Policy_Type']\ntarget = 'Response'\n\n_X = df1.drop(cols_to_remove + [target], axis=1)\ny = df1[target]\n_XTEST = test.drop(cols_to_remove , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"_X.shape, _XTEST.shape","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X_all = pd.concat([_X, _XTEST]).reset_index(drop=True)\nX_all.shape","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X_all.info()","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"cat_columns = []\nfor col in X_all.select_dtypes('object').columns:\n    print(col)\n    cat_columns.append(col)\n    le = LabelEncoder()\n    X_all[col] = le.fit_transform(X_all[col])","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X = X_all[:len(y)]\nXTEST = X_all[len(y):]\nX.shape, XTEST.shape","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"NUM_OF_BOOST_ROUND = 10000\nEARLY_STOPPING = 300","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"cat_features_index = [i for i,col in enumerate(X.columns) if col in cat_columns]\ncat_features_index","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"X_train , X_valid, y_train, y_valid = train_test_split(X,y, \n                                                       test_size=0.2, \n                                                       random_state=56, \n                                                       stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"params = {\n    'cat_features': cat_features_index,\n    'eval_metric': 'AUC',\n    'random_seed': 56,\n    'n_estimators': NUM_OF_BOOST_ROUND,\n}","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"bst = CatBoostClassifier(**params, early_stopping_rounds=EARLY_STOPPING)\n_ = bst.fit(X_train, y_train, eval_set=(X_valid,y_valid), plot=True, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"ypred_cat = bst.predict_proba(X_valid)[:,1]\nroc_auc_score(y_valid, ypred_cat)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"f_importance_df = pd.DataFrame(bst.get_feature_importance(), columns=['importance'], index=X_valid.columns)\nf_importance_df = f_importance_df.sort_values(by='importance', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.barplot(x=f_importance_df.importance[:500], y=f_importance_df.index[:500]);","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"ypred_test = bst.predict_proba(XTEST)[:,1]\npred = pd.DataFrame(ypred_test)\npred.to_csv('pred.csv')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"sns.distplot(ypred_test)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"raw","source":"#### CatBoost Classifier gives almost 0.80 ROC_AUC_SCORE"},{"metadata":{"hidden":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}