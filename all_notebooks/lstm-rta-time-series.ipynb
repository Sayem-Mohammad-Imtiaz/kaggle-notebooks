{"cells":[{"metadata":{"_cell_guid":"2bf3fef2-aa3d-48be-b776-8478cc3f5178","_uuid":"3993b3b652381086077548529a7868cbb82329cc"},"cell_type":"markdown","source":"# LSTM RTA (road traffix accidents) Time Series analysis\n\n### Loading and plotting the data","execution_count":null},{"metadata":{"_cell_guid":"dc37e399-005d-4e56-a7e0-d14f2f7ed1c3","_uuid":"d35448b01a7670ccb2960b5da7d61588e0ac3cc0","trusted":true,"collapsed":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('../input/epolicija-eismo-ivykiai/sortedAccidents.csv')\ndata.head() ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0db37933-7393-497e-a588-48ce08fbc941","_uuid":"1d74c91ec1bbaaee05dc38d21d8b385e5c4ac6d5","trusted":true,"collapsed":true},"cell_type":"code","source":"# Let's load the required libs.\n# We'll be using the Tensorflow backend (default).\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c009c934-95e7-4bf2-ad33-ed57e30184bd","_uuid":"7411c5d1ef6e2720b8eeb880e76580f127a3706e","trusted":true,"collapsed":true},"cell_type":"code","source":"# Get the raw data values from the pandas data frame.\ndata_raw = data[[\"1\"]].astype(\"float32\")\n\n# We apply the MinMax scaler from sklearn\n# to normalize data in the (0, 1) interval.\nscaler = MinMaxScaler(feature_range = (0, 1))\ndataset = scaler.fit_transform(data_raw)\n\n# Print a few values.\ndataset[0:5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9a1fc345-2aca-4629-bece-be984d02cc22","_uuid":"8d5687ded354b39d1d5b281a8129d451d4d6db90","trusted":true,"collapsed":true},"cell_type":"code","source":"TRAIN_SIZE = 0.67\n\ntrain_size = int(len(dataset) * TRAIN_SIZE)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\nprint(\"Number of entries (training set, test set): \" + str((len(train), len(test))))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"19bc3b63-c65e-4c2c-8c2d-661a5a988df9","_uuid":"6aa6e8291b129f2ab7e3568cb1cae07a692efb4c","trusted":true,"collapsed":true},"cell_type":"code","source":"# FIXME: This helper function should be rewritten using numpy's shift function. See below.\ndef create_dataset(dataset, window_size = 1):\n    data_X, data_Y = [], []\n    for i in range(len(dataset) - window_size - 1):\n        a = dataset[i:(i + window_size), 0]\n        data_X.append(a)\n        data_Y.append(dataset[i + window_size, 0])\n    return(np.array(data_X), np.array(data_Y))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a5a0c704-fb34-4340-846b-f84ac457ddb3","_uuid":"f8b3f24ce79bdbfe7aa17b4a77cfe28bf0f592b7","trusted":true,"collapsed":true},"cell_type":"code","source":"# Create test and training sets for one-step-ahead regression.\nwindow_size = 1\ntrain_X, train_Y = create_dataset(train, window_size)\ntest_X, test_Y = create_dataset(test, window_size)\nprint(\"Original training data shape:\")\nprint(train_X.shape)\n\n# Reshape the input data into appropriate form for Keras.\ntrain_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\ntest_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\nprint(\"New training data shape:\")\nprint(train_X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def compile_model(train_X, train_Y, window_size = 1):\n    model = Sequential()\n    \n    model.add(LSTM(4, \n                   input_shape = (1, window_size)))\n    model.add(Dense(1))\n    model.compile(loss = \"huber_loss\", optimizer = \"Adam\")\n    return(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model1 = compile_model(train_X, train_Y, window_size)\nmodel1.summary()\n\n#import keras.backend as K\n#print('LR', K.eval(model1.optimizer.lr))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98db98ae-0354-4a97-9dcf-d1ed69929c09","_uuid":"55261632a34b1edc494392bfff6157cd9be6ae6e","trusted":true,"collapsed":true},"cell_type":"code","source":"# Fit the first model.\nmodel1.fit(train_X, \n          train_Y, \n              epochs = 100, \n              batch_size = 1, \n              verbose = 2)\n# Save model\nmodel1.save_weights('./model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#model1.load_weights('../input/models/model-msle-100e-adam')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d5fb618e-5319-435c-a5fa-dae9f1209658","_uuid":"536a96d4ee8a8d545ddee3c4feb92a430b27375e","trusted":true,"collapsed":true},"cell_type":"code","source":"def predict_and_score_mse(model, X, Y):\n    # Make predictions on the original scale of the data.\n    pred = scaler.inverse_transform(model.predict(X))\n    # Prepare Y data to also be on the original scale for interpretability.\n    orig_data = scaler.inverse_transform([Y])\n    score = mean_squared_error(orig_data[0], pred[:, 0])\n    return(score, pred)\n\ndef predict_and_score_rmse(model, X, Y):\n    mse_score, pred = predict_and_score_mse(model, X, Y)\n    rmse_score = math.sqrt(mse_score)\n    return(rmse_score, pred)\n\nrmse_train, train_predict = predict_and_score_rmse(model1, train_X, train_Y)\nrmse_test, test_predict = predict_and_score_rmse(model1, test_X, test_Y)\n\nmse_train, train_predict = predict_and_score_mse(model1, train_X, train_Y)\nmse_test, test_predict = predict_and_score_mse(model1, test_X, test_Y)\n\nprint(\"Training data score: %.2f RMSE\" % rmse_train)\nprint(\"Test data score: %.2f RMSE\" % rmse_test)\n\nprint(\"Training data score: %.2f MSE\" % mse_train)\nprint(\"Test data score: %.2f MSE\" % mse_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9cf786eb-9b85-45c6-adf5-2f52a3950007","_uuid":"b1a73da9fc4bfede19560d3a7c2c0d53a8913e9b","trusted":true,"collapsed":true},"cell_type":"code","source":"# Start with training predictions.\ntrain_predict_plot = np.empty_like(dataset)\ntrain_predict_plot[:, :] = np.nan\ntrain_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n\n# Add test predictions.\ntest_predict_plot = np.empty_like(dataset)\ntest_predict_plot[:, :] = np.nan\ntest_predict_plot[len(train_predict) + (window_size * 2) + 1:len(dataset) - 1, :] = test_predict\n\n# Create the plot.\nplt.figure(figsize = (15, 5))\nplt.xticks(range(0, len(train_predict) + len(test_predict), 365))\nplt.plot(scaler.inverse_transform(dataset), label = \"Tikri duomenys\")\nplt.plot(train_predict_plot, label = \"Mokymosi duomenų prognozė\")\nplt.plot(test_predict_plot, label = \"Validacijos duomenų prognozė\")\nplt.xlabel(\"Dienos (nuo 2013-01-01)\")\nplt.ylabel(\"Eismo įvykiai\")\nplt.title(\"Tikrų duomenų su modelio prognozėmis palyginimas\")\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}