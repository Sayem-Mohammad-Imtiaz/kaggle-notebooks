{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Here in this notebook I will forecast to 2021 using Deep learning RNN and LSTM for time series\n### The special case of RNN Time series is RNN takes batches from the time series and make a train at each one!\n### for example if we have a series from 0 to 9 : [0,1,2,3,4,5,6,7,8,9]\n### frist we will devide it into baches :\n![](https://scontent.faly3-1.fna.fbcdn.net/v/t1.0-9/121419725_824808158330800_8470839773498296736_n.jpg?_nc_cat=104&_nc_sid=730e14&_nc_ohc=f7BpQHJqLzUAX-JslIO&_nc_ht=scontent.faly3-1.fna&oh=7dfec2af80009b6043a0d429fa299da2&oe=5FA60AB5)\n\n### Second we take bach 1: [ 0,1,2,3] to predict 4\n### and bach 2 we take : [1,2,3,4] to predict 5 ...\n\n### For the forecasting it will be like :\n![](https://scontent.faly3-1.fna.fbcdn.net/v/t1.0-9/121238276_824808138330802_5818175079055679020_o.jpg?_nc_cat=106&_nc_sid=730e14&_nc_ohc=vbaF1YMJ0YsAX-qt-ZS&_nc_ht=scontent.faly3-1.fna&oh=8ff20dc08795ce0496593038023356ca&oe=5FA68116)"},{"metadata":{},"cell_type":"markdown","source":"#### 1- Importing:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2- Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('../input/real-manufacturing-and-trade-inventories-2020/INVCMRMT.csv', index_col='DATE', parse_dates=True)\ndf['INVCMRMT']=df['INVCMRMT'].astype(int)\ndf.index.freq= 'MS'\ndf['INVCMRMT'].plot(figsize=(12,6)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3- Train/ Test split:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"len(df) #We will grap the last year for forecasting\n\ntrain= df.iloc[:265]\ntest = df.iloc[265:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4- Scaling data :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler= MinMaxScaler()\nscaler.fit(train)\nscaled_train= scaler.transform(train)\nscaled_test= scaler.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5- Create Timesereies Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\nlength= 12 #batch size should be smaller than test size\ngenerator= TimeseriesGenerator(scaled_train,scaled_train,length=length,batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,LSTM\nn_features=1 # 1 variable and 1 col 'INVCMRMT'\n\nmodel= Sequential()\nmodel.add(LSTM(400,activation='relu', input_shape=(length,n_features))) #input shape of batch size\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam',loss='mse')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6- Create Early stop:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',patience=2) #patience is number of epochs with no improvment\nvalidation_generator= TimeseriesGenerator(scaled_test,scaled_test,length=length,batch_size=1)\nmodel.fit_generator(generator,epochs=10,validation_data=validation_generator,callbacks=early_stop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7- Loss Evaluation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"losses= pd.DataFrame(model.history.history)\nlosses.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Grap test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IGNORE WARNINGS\ntrue_predictions = scaler.inverse_transform(test_predictions)\ntest['Predictions'] = true_predictions\ntest.plot(figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Grap predections"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_predictions = scaler.inverse_transform(test_predictions)\ntest['Predictions'] = true_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.plot(figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8- Forecasting"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_scaler= MinMaxScaler()\nscaled_full_data=full_scaler.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length=12\ngenerator=TimeseriesGenerator(scaled_full_data,scaled_full_data,length=length,batch_size=1)\nmodel= Sequential()\nmodel.add(LSTM(400,activation='relu', input_shape=(length,n_features))) #input shape of batch size\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam',loss='mse')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator,epochs=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = []\n# Replace periods with whatever forecast length you want\nperiods = 12\n\nfirst_eval_batch = scaled_full_data[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(periods):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    forecast.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = scaler.inverse_transform(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" - Creating new time series for forecast"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_index = pd.date_range(start='2020-08-01',periods=periods,freq='MS')\nforecast_df = pd.DataFrame(data=forecast,index=forecast_index,columns=['Forecast'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- plot the forecast"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df.plot()\nforecast_df.plot(ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df.plot()\nforecast_df.plot(ax=ax)\nplt.xlim('2018-08-01','2021-08-01')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}