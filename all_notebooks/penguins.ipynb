{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n## About the notebook\n\nThis notebook was created for a friend, to show her some of the most used [pandas](https://pandas.pydata.org/) functions and answer her questions. It is basically a pandas tutorial on an interesting dataset, so if you are new to pandas as well, I hope that you can learn something from it as well.\n\n## About the dataset\n\nI will use the [penguin dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data) as it resembles the data of my friend. Instead of laboratory samples, it describes three species of penguins - Adelie, Chinstrap and Gentoo, living on three islands - Biscoe, Dream and Torgersen. For each penguin culmen length and depth, flipper length, body mass and their sex was recorded. You can find more about the dataset in the linked description."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Standard libraries\nimport glob\n\n# Specific imports from the standard library\nfrom pathlib import Path\n\n# Basic imports\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Load the data\ndf = pd.read_csv(\"/kaggle/input/palmer-archipelago-antarctica-penguin-data/penguins_size.csv\")\ndf = df.dropna()   # Drop rows with nulls, so we have easier work","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check out, how dataframe looks like\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Questions\n\nHere are some questions, my friend had and I will try to answer. I grouped some of them, as they can be solved using the same method.\n\n- Any other useful functions? (The last question, but I will begin with those)\n- How to select columns?\n- How to drop columns?\n- How to filter rows?\n    - How does `.loc` work?\n    - How to filter using values in a cells?\n    - How to divide a dataframe?\n- How to create sub-dataframes using?\n    - How to filter using for cycle?\n- How to concat a dataframe?\n- How does groupby work?\n- How does joining work?\n    - Is there anything else apart from concat to join dataframes?\n- How to color cells by the value?"},{"metadata":{},"cell_type":"markdown","source":"# Tutorial"},{"metadata":{},"cell_type":"markdown","source":"# Some useful functions to check the dataframe"},{"metadata":{},"cell_type":"markdown","source":"At first, you can get the list of all columns in a dataframe using `.columns`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can select `x` rows from the top of the dataframe using `.head`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can do the same with the bottom of the dataframe using `.tail`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get the size of the dataframe use `.shape`. It returns a tuple, where the first number corresponds to the number of rows and the second to the number of columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is also handy, to set default pandas settings, because often you may want to see all the rows or the first hundred or two. It is also usually not necessary to show six decimal digits."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 20)\npd.set_option('display.max_rows', 20)\npd.set_option(\"display.float_format\", '{:,.2f}'.format)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to select columns?"},{"metadata":{},"cell_type":"markdown","source":"The selection of columns depends on whether you want to select by a column name or its number. If you want to select using column names, you can either use `.loc` or simply write a list in square brackets. The following four selections are all equal:"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df[[\"species\", \"flipper_length_mm\"]]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"selected_columns = [\"species\", \"flipper_length_mm\"]\ndf[selected_columns]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df.loc[:, [\"species\", \"flipper_length_mm\"]]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"selected_columns = [\"species\", \"flipper_length_mm\"]\ndf.loc[:, selected_columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you want to select using the numbers of the columns, you need to use `.iloc` instead."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df.iloc[:, 2:]    # Select all, but the first two columns","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df.iloc[:, :2]    # Select the first two columns","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df.iloc[:, -3:]   # Select last three columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to drop columns?"},{"metadata":{},"cell_type":"markdown","source":"Columns can be dropped using `.drop` function, to which you pass a list of columns you want to be dropped and you also need to specify `axis=1` to drop columns. This function can be also used to drop rows, but it is rarely used, i.e. I have never seen somebody use it to drop rows, as there are easier methods to do it, e.g. using masks and `.loc`."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"cols_to_be_dropped = [\"body_mass_g\", \"sex\"]\ndf_with_less_columns = df.drop(cols_to_be_dropped, axis=1)\ndf_with_less_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note, that it is the same to drop a few columns as to select all other columns."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"selected_cols = [\"species\", \"island\", \"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\"]\ndf_with_less_columns = df[selected_cols]\ndf_with_less_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to filter rows"},{"metadata":{},"cell_type":"markdown","source":"You could have noticed that when we used `.loc`, we passed it two things a colon and a list of selected columns. The meaning of a colon is \"Select everything\" and as the first argument is for rows and the second for column, the colon for the first argument means \"Select all rows\". Instead of a colon, we can pass a mask to select only rows, which fulfill some condition. A mask is a Series of the same length as how many rows the dataframe has. Basically, the mask says for each row, whether it fulfills a condition and should be selected or not. \n\nFor example, we can see that at the beginning of the dataframe are Adelie penguins and at the end there are Gentoo penguins, so let's create a mask for selecting only Gentoo penguins."},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_is_gentoo = df[\"species\"]==\"Gentoo\"\nmask_is_gentoo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"You can see that in the beginning it is False, because at the beginning of the dataframe, there are no Gentoo penguins. However, there are Gentoo penguins at the end of the dataframe, so the values there are `True`. Now, we can apply the mask to get only rows with Gentoo penguins."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[mask_is_gentoo, :]   # We use colon as second argument, because we want to select all columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note, that masks can be joined together using `&` (AND) and `|` (OR) symbols. So we can for example create another mask to select only female penguins and combine it with Gentoo mask:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_is_female = df[\"sex\"] == \"FEMALE\"\nmask_is_female_gentoo = mask_is_female & mask_is_gentoo\n# mask_is_female_gentoo = (df[\"species\"]==\"Gentoo\") & (df[\"sex\"]==\"FEMALE\")   # Identical definition as on the row above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[mask_is_female_gentoo]   # You can also skip the second colon and all columns will be selected automatically","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of course, it is possible to use use `>`, `<`, `>=`, `<=` apart from `==` for numerical values. For string values, it is also handy to know about other methods apart from exact match (`==`) we used. We may for example want to select penguins that live on any of two islands. This can be done using two masks and `|` (OR) symbol, or we can use `.isin` and pass it a list."},{"metadata":{"trusted":true},"cell_type":"code","source":"# mask_island_TD = (df[\"island\"]==\"Torgersen\") | (df[\"island\"]==\"Dream\")   # Equivalent to the row below\nmask_island_TD = df[\"island\"].isin([\"Torgersen\", \"Dream\"])\ndf.loc[mask_island_TD, :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If a case you worked with a lot of strings, e.g. every row would have multiple tags, divided by commas, you can also create mask, checking whether a substring is contained in each row using `.str.contains` to which you pass a substring. If you knew how to use regular expressions, you can pass regular expression instead and add another argument `regex=True`."},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_rea_in_island_name = df[\"island\"].str.contains(\"rea\")   # In our case only Dream island contains \"rea\" substring\n\ndf.loc[mask_rea_in_island_name]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to create sub-dataframes?"},{"metadata":{},"cell_type":"markdown","source":"We may for example want to divide penguins by their species and island they live on to different dataframes and save them separately. Currently, the best way how to handle paths in Python is using `Path` object form `pathlib` library. "},{"metadata":{"trusted":true},"cell_type":"code","source":"path_to_output_folder = Path(\"/kaggle/out/\")   # Define path to folder\npath_to_output_folder.mkdir(parents=True, exist_ok=True)   # Create the folder if it does not exist\nfor species in df[\"species\"].unique():\n    for island in df[\"island\"].unique():\n        mask = (df[\"species\"] == species) & (df[\"island\"] == island)\n        sub_df = df.loc[mask]\n        if not sub_df.empty:\n            filename = f\"{species}_on_{island}.csv\"\n            path_to_file = path_to_output_folder / filename   # \"/\" sign joins parts of the path together\n            sub_df.to_csv(path_to_file, index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can check, which files were created e.g. using `glob` library. This library is used to traverse the filesystem and search for files fulfilling some criteria. The most common use is shown below, where we pass path to a folder `/kaggle/out/` and `*.csv` which means *any file having suffix .csv*."},{"metadata":{"trusted":true},"cell_type":"code","source":"glob.glob(\"/kaggle/out/*.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to concatenate dataframes"},{"metadata":{},"cell_type":"markdown","source":"If we were given dataframes with individual species on individual island (e.g. like we divided them in the previous part), we can join them using `.concat` function, to which we pass a list of dataframes to concatenate. Note, you have to have the same number of columns in dataframes or it won't work."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = pd.DataFrame()\nfor path in glob.glob(\"/kaggle/out/*.csv\"):\n    sub_df = pd.read_csv(path)\n    new_df = pd.concat([new_df, sub_df])\nnew_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# .groupby"},{"metadata":{},"cell_type":"markdown","source":"To find out information about a group, use `.groupby` function followed by `.agg`. I also always `.reset_index`, because if you don't then attributes you used for group by become new indices."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(by=[\"species\"]).agg(**{\"avg_flipper_length_mm\":(\"flipper_length_mm\", \"mean\"),\n                                  \"median_flipper_length_mm\":(\"flipper_length_mm\", \"median\"),\n                                  \"std_flipper_length_mm\":(\"flipper_length_mm\", \"std\")}).reset_index() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(by=[\"island\", \"species\"]).agg(**{\"cnt_penguins\":(\"species\", \"count\")}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How does joining work"},{"metadata":{},"cell_type":"markdown","source":"To answer the question, whether there is another way how to join dataframes - there actually is a function called `pd.merge`, but this one is usually used with indexed data or when you have information about samples or groups in different dataframes. \n\nTo demonstrate how this work, let me at first load more detailed dataframe about penguins to `df_detailed`. Then I split measurements and information about penguins like where the live or what species are they."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_detailed = pd.read_csv(\"/kaggle/input/palmer-archipelago-antarctica-penguin-data/penguins_lter.csv\")\ndf_detailed = df_detailed.loc[df_detailed[\"studyName\"]==\"PAL0708\"]\ndf_detailed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_indices = ['Individual ID']\ncols_about_penguins = ['Species', 'Region', 'Island', 'Stage', 'Clutch Completion', 'Date Egg']\ncols_measurements = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', \n                     'Sex', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)', 'Comments']\n\ndf_about_penguins = df_detailed[cols_indices+cols_about_penguins]\ndf_measurements = df_detailed[cols_indices+cols_measurements]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_about_penguins","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_measurements","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have information about penguins saved in two different dataframes. This is a common situation when you work with databases. It is not practical to save all the information in a single table and it is much better solution to split data and make them joinable through IDs.\n\nIn both dataframes, each penguin can be identified by `Individual ID`. Now, if we want to use `pd.merge`, we should at first check, whether this identifier is unique, because e.g. if in the first table was each `Individual ID` only once, but in the second table there were some duplicates, all duplicates will join and the final statistics will not be correct."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"{df_measurements.shape[0]} == {df_measurements.drop_duplicates(subset=['Individual ID']).shape[0]}\")\nprint(f\"{df_measurements.shape[0] == df_measurements.drop_duplicates(subset=['Individual ID']).shape[0]}\")\nprint()\nprint(f\"{df_about_penguins.shape[0]} == {df_about_penguins.drop_duplicates(subset=['Individual ID']).shape[0]}\")\nprint(f\"{df_about_penguins.shape[0] == df_about_penguins.drop_duplicates(subset=['Individual ID']).shape[0]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we are sure, that there are no duplicates and dataframes will join correctly, we will use `pd.merge`."},{"metadata":{"trusted":true},"cell_type":"code","source":"joined_df = pd.merge(df_about_penguins, df_measurements, how=\"inner\", on=[\"Individual ID\"])\njoined_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To `on` argument we pass the common column through which dataframes should be joined. To `how` we pass the type of join. There are five types of join:\n- Inner - Join and keep only rows where the index is present in both dataframes\n- Left - Same as inner, but also keeps records from the left dataframe if there is no correponding index in the right dataframe. Columns from the right dataframe are filled with None.\n- Right - The same as left, but keeps records from the right dataframe instead\n- Outer - Keep records from both dataframes, if there is no corresponding index on left/right fill columns with None.\n- Cross - Cartesian product, not really the same join as the previous"},{"metadata":{},"cell_type":"markdown","source":"# How to color cells by the value?"},{"metadata":{},"cell_type":"markdown","source":"Styling and coloring cells is done via `.style` attribute. Through it you access [Styler](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html) and you can set for example background gradient or create bar plots in the dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20).style.background_gradient(subset=[\"flipper_length_mm\", \"body_mass_g\"], cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20).style.bar(subset=[\"culmen_length_mm\", \"culmen_depth_mm\"], align='mid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}