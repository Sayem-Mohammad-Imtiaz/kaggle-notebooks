{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Recruit Restaurant Visitor Forecasting\n表題のコンペのコード<br>\n処理時間およそ30min<br>\n* 特徴量を作成(日付、店舗のピーク曜日、座標、カテゴリ)\n* カテゴリ変数を変換(店舗IDと店舗カテゴリ)\n* ラグ特徴量(7,14,21日前の平均と、直前の同じ曜日の来店者数)\n<br><br>\n【モデル学習方法】<br>\n* 3/15-4/22までを予測させるためのモデル39個のうちの1個目\n* 1日前までの情報を使って予測する","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/air_visit_data.csv\")\nweatherData = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/WeatherData.csv\")\ndate_info = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/date_info.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"date_info = date_info.rename(columns={'calendar_date': \"visit_date\"})\ndate_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(date_info, on=\"visit_date\",how=\"left\")\n# 曜日はあとで別の方法で加えるので、一旦削除\ntrain = train.drop(columns=\"day_of_week\")\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"set\"] = \"train\"\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = train.drop(columns = \"visitors\")\ntrain_y = pd.DataFrame()\ntrain_y[\"visitors\"] = train[\"visitors\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_yのvisitorsが200を超える場合は0にする\ntrain_y.loc[train_y[\"visitors\"] > 200, \"visitors\"] = 0\n# visitorsでソートして表示\ntrain_y.sort_values(by='visitors', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 日付を切り分ける\n毎月〇日は安い、とか、〇月はセール！とかありそうなので","metadata":{}},{"cell_type":"code","source":"# 2017-04-18\t\ndef back_year(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    return txt_split[0]\n\ndef back_month(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    #04月のような記述にならないように、int型で返す\n    return int(txt_split[1])\n\ndef back_day(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    return int(txt_split[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# year,month,dayの列を作成","metadata":{}},{"cell_type":"code","source":"# year列を新規に作成する。visit_date列の値をback_year関数に入れて処理する\ntrain_x.loc[:,\"year\"] = train_x[\"visit_date\"].apply(back_year)\ntrain_x.loc[:,\"month\"] = train_x[\"visit_date\"].apply(back_month)\ntrain_x.loc[:,\"day\"] = train_x[\"visit_date\"].apply(back_day)\ntrain_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n#月火水木金土日→[0,1,2,3,4,5,6]で返す\ndef back_day_of_the_week(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    dt = datetime.datetime(int(txt_split[0]), int(txt_split[1]), int(txt_split[2]))\n    return dt.weekday()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x.loc[:,\"day_of_the_week\"] = train_x[\"visit_date\"].apply(back_day_of_the_week)\n# visit_dateは削除\ntrain_x = train_x.drop(columns='visit_date')\ntrain_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sample submissionを読み込み、testデータに使う","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/sample_submission.csv\")\ntest[\"set\"] = \"test\"\ntest_x = test.drop(columns=\"visitors\")\ntest_y = pd.DataFrame()\ntest_y[\"visitors\"] = test[\"visitors\"]\n# test_yの来店者数は全て-1で埋める(→ラグ特徴量計算でマイナスを平均に加えるのは不適切と考えやめた)\n# test_y[\"visitors\"] = -1\ntest_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test_xのidを切り分ける\ntest_x(sample_submit)のidが、店舗名と日付で別々になっているので、<br>\ntrain_x(air_visit_data)と同じ形式(air_store_idとvisit_date)になるように<br>\n切り分けたい","metadata":{}},{"cell_type":"code","source":"def back_store_name(txt):\n    id = txt\n    #_区切りで右から1番目の文字を切り分ける\n    txt_split = txt.rsplit(\"_\",1)\n    # 切り分けた文字列のうち、0番目を返す\n    return txt_split[0]\n\ndef back_date_name(txt):\n    id = txt\n    txt_split = txt.rsplit(\"_\",1)\n    return txt_split[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 新しく作った変数(air_store_idとvisit_date)と祝日フラグを、test_xに追加する","metadata":{}},{"cell_type":"code","source":"#新しい列の名前 = 引数として関数に入れて処理する列の名前\ntest_x.loc[:,\"air_store_id\"] = test_x[\"id\"].apply(back_store_name)\ntest_x.loc[:,\"visit_date\"] = test_x[\"id\"].apply(back_date_name)\n# 祝日フラグを追加\ntest_x = test_x.merge(date_info, on=\"visit_date\",how=\"left\")\n# 曜日はあとで別の方法で加えるので、一旦削除\ntest_x = test_x.drop(columns=\"day_of_week\")\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 日付情報をYear,Month,Dayに変更","metadata":{}},{"cell_type":"code","source":"# year列を新規に作成する。visit_date列の値をback_year関数に入れて処理する\ntest_x.loc[:,\"year\"] = test_x[\"visit_date\"].apply(back_year)\ntest_x.loc[:,\"month\"] = test_x[\"visit_date\"].apply(back_month)\ntest_x.loc[:,\"day\"] = test_x[\"visit_date\"].apply(back_day)\ntest_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 日付情報から曜日を取得","metadata":{}},{"cell_type":"code","source":"test_x.loc[:,\"day_of_the_week\"] = test_x[\"visit_date\"].apply(back_day_of_the_week)\ntest_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test_xのGWを休日(土曜)に変更\ntest_xに含まれるGW(5/3-5/5)の曜日を変更する<br>\n条件によりday_of_the_weekを書き換える<br>\n当初日曜日にしていたが、土曜日の方がave_visitorsが多いので土曜に変えた","metadata":{}},{"cell_type":"code","source":"# test_dataの5/3-5/5までを日曜日に変更(日曜日=6)\ntest_x.loc[(test_x['month'] == 5) & (test_x['day'] == 3), 'day_of_the_week'] = 5\ntest_x.loc[(test_x['month'] == 5) & (test_x['day'] == 4), 'day_of_the_week'] = 5\ntest_x.loc[(test_x['month'] == 5) & (test_x['day'] == 5), 'day_of_the_week'] = 5\ntest_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# idとvisit_date行は削除\nidは不要。これで、test_xとtrain_xが同じ形式で取得できた<br>\nvisit_dateも、month,day,yearで代替しているので削除","metadata":{}},{"cell_type":"code","source":"test_x = test_x.drop(columns='id')\ntest_x = test_x.drop(columns='visit_date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# カテゴリ変数の変換\nカテゴリ変数をLabelEncoderで実施するために、<br>\n全てのカテゴリ変数(ここだと店舗名)を取得する<br>\n# まず、air_store_idだけをもつDataFrameを定義する","metadata":{}},{"cell_type":"code","source":"train_le = pd.DataFrame()\ntrain_le[\"air_store_id\"] = train_x.air_store_id\ntest_le = pd.DataFrame()\ntest_le[\"air_store_id\"] = test_x.air_store_id\ntest_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2つ(train_leとtest_le)を合体する","metadata":{}},{"cell_type":"code","source":"merge_data_le = pd.merge(train_le,test_le, how=\"outer\")\nmerge_data_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラベルエンコーディングをかける\ntrain_all_leというDataFrameにラベルエンコーディングをかける。<br>\nair_store_idにラベルエンコーディングがかけられて数値に変換される<br>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder #Library for LabelEncoding\n\nfor c in merge_data_le:\n    le = LabelEncoder()\n    le.fit(merge_data_le[c])\n    train_le[c] = le.transform(train_le[c])\n    test_le[c]= le.transform(test_le[c])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# エンコード前後の対応確認用、本筋とは関係ない\ntrain_x_enc = train_x.join(train_le, lsuffix='_enc')\ntest_x_enc = test_x.join(test_le, lsuffix='_enc')\n\n# エンコードしたものを入れる\ntrain_x = train_x.drop(columns = \"air_store_id\")\ntrain_x = train_x.join(train_le)\ntest_x = test_x.drop(columns = \"air_store_id\")\ntest_x = test_x.join(test_le)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# yearのデータ型をint64に変更\nxgboostで読める型に変更する","metadata":{}},{"cell_type":"code","source":"train_x[\"year\"] = train_x.year.astype(\"int64\")\ntest_x[\"year\"] = test_x.year.astype(\"int64\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train_xとtrain_yを結合してtrain_allにする","metadata":{}},{"cell_type":"code","source":"train_all = train_x.join(train_y)\ntrain_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test_yとtest_xを結合してtest_allにする","metadata":{}},{"cell_type":"code","source":"test_all = test_x.join(test_y)\ntest_all_wid = test_x.join(test.id)\ntest_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train_allとtest_allをマージしmerge_dataとする\nこれで、trainとtestが同じ形式で得られた。\n以降は、train_allとtest_allをマージしてmerge_dataにして特徴量を追加し、<br>\n最終的に切り分ける事にする","metadata":{}},{"cell_type":"code","source":"merge_data = pd.concat([train_all,test_all])\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train_allを使ってStore_idの入れ物をつくる","metadata":{}},{"cell_type":"code","source":"unique_stores = train_all['air_store_id'].unique()\nstores = pd.concat(\n    [\n        pd.DataFrame({\n            'air_store_id': unique_stores,\n            'day_of_the_week': [i] * len(unique_stores)\n        }) for i in range(7)\n    ],\n    axis=0,\n    ignore_index=True).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 入れ物の中身を入れていく","metadata":{}},{"cell_type":"code","source":"#sure it can be compressed...\ntmp = train_all.groupby(\n    ['air_store_id', 'day_of_the_week'],\n    as_index=False)['visitors'].min().rename(columns={\n        'visitors': 'min_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'day_of_the_week'])\n\ntmp = train_all.groupby(\n    ['air_store_id', 'day_of_the_week'],\n    as_index=False)['visitors'].mean().rename(columns={\n        'visitors': 'mean_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'day_of_the_week'])\n\ntmp = train_all.groupby(\n    ['air_store_id', 'day_of_the_week'],\n    as_index=False)['visitors'].median().rename(columns={\n        'visitors': 'median_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'day_of_the_week'])\n\ntmp = train_all.groupby(\n    ['air_store_id', 'day_of_the_week'],\n    as_index=False)['visitors'].max().rename(columns={\n        'visitors': 'max_visitors'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'day_of_the_week'])\n\ntmp = train_all.groupby(\n    ['air_store_id', 'day_of_the_week'],\n    as_index=False)['visitors'].count().rename(columns={\n        'visitors': 'count_observations'\n    })\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'day_of_the_week'])\n\nstores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# merge_dataにmergeする","metadata":{}},{"cell_type":"code","source":"merge_data = pd.merge(merge_data, stores, how='left', on=['air_store_id', 'day_of_the_week'])\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 【important】validationデータの指定\n3/15を予測する。<br>\nそれ以外の3/15-4-22の期間はmissデータとして、学習に利用しない","metadata":{}},{"cell_type":"code","source":"# 3/15-4/22をmissデータとする\nmerge_data.loc[(merge_data['year'] == 2017) & (merge_data['month'] == 3) & (merge_data['day'] >= 12), 'set'] = 'miss'\nmerge_data.loc[(merge_data['year'] == 2017) & (merge_data['month'] == 4) & (merge_data['day'] >= 1) & (merge_data['day'] <= 22), 'set'] = 'miss'\n\n# merge_dataの中で、予測したい日付を指定する\nmerge_data.loc[(merge_data['year'] == 2017) & (merge_data['month'] == 3) & (merge_data['day'] >= 18) & (merge_data['day'] <= 18),'set'] = 'va'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_miss_visitors = merge_data.loc[(merge_data.set == \"va\") | (merge_data.set == \"miss\"),\"visitors\"]\n# set=vaに選んだもののvisitorsを取得しておく\nva_visitors = merge_data.loc[(merge_data.set == \"va\"),\"visitors\"]\n\nmerge_data.loc[(merge_data.set == \"va\") | (merge_data.set == \"miss\"),\"visitors\"] = 0\nmerge_data.loc[(merge_data.set == \"va\") | (merge_data.set == \"miss\")]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 店舗情報を利用する","metadata":{}},{"cell_type":"code","source":"air_store_info = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/air_store_info.csv\")\n\nstore_le = pd.DataFrame()\nstore_le[\"air_store_id\"] = air_store_info.air_store_id\ngenre_le = pd.DataFrame()\ngenre_le[\"air_genre_name\"] = air_store_info.air_genre_name\narea_le = pd.DataFrame()\narea_le[\"air_area_name\"] = air_store_info.air_area_name\n\narea_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラベルエンコーディングで店舗のジャンルを分ける\n・store_id<br>\n・ジャンル<br>\n・エリア<br>\nに対してそれぞれラベルエンコーディングする","metadata":{}},{"cell_type":"code","source":"# store_idのラベルエンコーディング\nfor c in store_le:\n    store_le[c] = le.transform(store_le[c])\nstore_le\n\n# ジャンルのラベルエンコーディング\nfor c in genre_le:\n    le_g = LabelEncoder()\n    le_g.fit(genre_le[c])\n    genre_le[c] = le_g.transform(genre_le[c])\ngenre_le\n\nfor c in area_le:\n    le_a = LabelEncoder()\n    le_a.fit(area_le[c])\n    area_le[c] = le_a.transform(area_le[c])\narea_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラベルエンコーディングした特徴量を結合\nこれで、店舗IDごとに座標、エリア、ジャンルが入ったDataframe「air_store_info」を得られる","metadata":{}},{"cell_type":"code","source":"air_store_info = air_store_info.drop(columns = \"air_store_id\")\nair_store_info = air_store_info.join(store_le)\nair_store_info = air_store_info.drop(columns = \"air_genre_name\")\nair_store_info = air_store_info.join(genre_le)\nair_store_info = air_store_info.drop(columns = \"air_area_name\")\nair_store_info = air_store_info.join(area_le)\n# 最も来店者の多い曜日情報と結合するためにソートしindexをつけなおす\nair_store_info = air_store_info.sort_values(by='air_store_id')\n# indexをつけなおす\nair_store_info = air_store_info.reset_index(drop=True)\nair_store_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_visitors = train_all.groupby(['air_store_id']).visitors.agg([sum,len,max,min])\nstore_visitors[\"ave\"] = store_visitors[\"sum\"] // store_visitors[\"len\"]\n# 来店者数の平均でソート\nstore_visitors.sort_values(by='ave', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# merge_dataに店舗情報を追加\nvlookupみたいな操作をする。参照して追加するみたいな<br>\nmerge_dataには、trainもtestも、xもyも全部含まれる<br>\nair_store_infoの店舗IDごとの情報を、各データに追加する","metadata":{}},{"cell_type":"code","source":"merge_data = merge_data.merge(air_store_info, on=\"air_store_id\",how=\"left\")\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラグ特徴量の追加\n 7,14,21日周期のラグ特徴量を算出してlag_allに持たせる<br>\n testデータでは当日の情報を使ってラグ特徴量を作る事ができないので<br>\n 1日シフトさせて、前日からの1週間の平均を取得する","metadata":{}},{"cell_type":"code","source":"%%time\nstore_all_14_max = pd.DataFrame()\nstore_all_14 = pd.DataFrame()\nstore_all_21_max = pd.DataFrame()\nstore_all_21 = pd.DataFrame()\nstore_all_28_max = pd.DataFrame()\nstore_all_28 = pd.DataFrame()\nstore_all_35_max = pd.DataFrame()\nstore_all_35 = pd.DataFrame()\nstore_all_42_max = pd.DataFrame()\nstore_all_42 = pd.DataFrame()\n\nfor c in range(0,829,1):\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 14周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag14_max\"] = store[\"visitors\"].shift(8).rolling(window=7).max()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['max'][c]\n    store = store.fillna(ave)\n    store_all_14_max = pd.concat([store_all_14_max, store])\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 14周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag14\"] = store[\"visitors\"].shift(8).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_14 = pd.concat([store_all_14, store])\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 14周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag21_max\"] = store[\"visitors\"].shift(15).rolling(window=7).max()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['max'][c]\n    store = store.fillna(ave)\n    store_all_21_max = pd.concat([store_all_21_max, store])\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 21周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag21\"] = store[\"visitors\"].shift(15).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_21 = pd.concat([store_all_21, store])\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 14周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag28_max\"] = store[\"visitors\"].shift(22).rolling(window=7).max()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['max'][c]\n    store = store.fillna(ave)\n    store_all_28_max = pd.concat([store_all_28_max, store])\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 21周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag28\"] = store[\"visitors\"].shift(22).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_28 = pd.concat([store_all_28, store])\n    \n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 14周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag35_max\"] = store[\"visitors\"].shift(29).rolling(window=7).max()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['max'][c]\n    store = store.fillna(ave)\n    store_all_35_max = pd.concat([store_all_35_max, store])\n        \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 21周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag35\"] = store[\"visitors\"].shift(29).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_35 = pd.concat([store_all_35, store])\n    \n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 14周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag42_max\"] = store[\"visitors\"].shift(36).rolling(window=7).max()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['max'][c]\n    store = store.fillna(ave)\n    store_all_42_max = pd.concat([store_all_42_max, store])\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 21周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag42\"] = store[\"visitors\"].shift(36).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_42= pd.concat([store_all_42, store])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idでソートしなおす\nstore_all_14 = store_all_14.sort_index()\nstore_all_21 = store_all_21.sort_index()\nstore_all_28 = store_all_28.sort_index()\nstore_all_35 = store_all_35.sort_index()\nstore_all_42 = store_all_42.sort_index()\nstore_all_14_max = store_all_14_max.sort_index()\nstore_all_21_max = store_all_21_max.sort_index()\nstore_all_28_max = store_all_28_max.sort_index()\nstore_all_35_max = store_all_35_max.sort_index()\nstore_all_42_max = store_all_42_max.sort_index()\n# ラグ特徴量を結合してlag_all\nlag_all = pd.DataFrame()\nlag_all[\"lag14\"] = store_all_14.lag14\nlag_all[\"lag21\"] = store_all_21.lag21\nlag_all[\"lag28\"] = store_all_28.lag28\nlag_all[\"lag35\"] = store_all_35.lag35\nlag_all[\"lag42\"] = store_all_42.lag42\nlag_all[\"lag14_max\"] = store_all_14_max.lag14_max\nlag_all[\"lag21_max\"] = store_all_21_max.lag21_max\nlag_all[\"lag28_max\"] = store_all_28_max.lag28_max\nlag_all[\"lag35_max\"] = store_all_35_max.lag35_max\nlag_all[\"lag42_max\"] = store_all_42_max.lag42_max\nlag_all.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラグ特徴量をmerge_dataに追加","metadata":{}},{"cell_type":"code","source":"merge_data = merge_data.join(lag_all)\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# リークする危険があるのでか必ずtodayをdropして消す\n# merge_data = merge_data.drop(columns='today')\n# merge_data = merge_data.drop(columns='day_of_the_week_last')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in merge_data:\n    print(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 全期間のデータをmerge_data_allとして残す","metadata":{}},{"cell_type":"code","source":"#期間短くする前のmerge_dataは、merge_data_all(全期間のデータ)として残す\nmerge_data_all = merge_data\nmerge_data_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge_data_allへはここで修復できる\nmerge_data = merge_data_all\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data.loc[merge_data.month == 3].tail(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data.loc[merge_data.set == \"va\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data.loc[merge_data.set == \"miss\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学習データを減らして学習時間を削減する","metadata":{}},{"cell_type":"code","source":"merge_data = merge_data.loc[(merge_data['year'] == 2017)]\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 以上で、特徴量エンジニアリングは終了\nパラメータを調整し、予測できるようにする\n\n* vaデータとして使う日付を選択する\n* データをtrain_fitとtest_fitに分割する\n* xgboostのパラメータを指定 \n* xgboostで学習させる\n* vaデータでRMSLEを計算する\n","metadata":{}},{"cell_type":"markdown","source":"# model1","metadata":{}},{"cell_type":"markdown","source":"# テストデータの範囲を指定\nパラメータが定まり、4/22までのデータを全てtrainとして使う設定にした場合に行う","metadata":{}},{"cell_type":"code","source":"merge_data.loc[(merge_data['year'] == 2017) & (merge_data['month'] == 4) & (merge_data['day'] >= 24), 'set'] = 'test'\nmerge_data.loc[(merge_data['year'] == 2017) & (merge_data['month'] == 5) & (merge_data['day'] >= 1), 'set'] = 'test'\n\n# testのidを残したい\ntest_all_wid.loc[(test_all_wid['year'] == 2017) & (test_all_wid['month'] == 4) & (test_all_wid['day'] >= 30), 'set'] = 'test'\ntest_all_wid.loc[(test_all_wid['year'] == 2017) & (test_all_wid['month'] == 5) & (test_all_wid['day'] >= 1), 'set'] = 'test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train,test,vaに分ける\ntrain_fit = pd.DataFrame()\ntrain_fit = merge_data.loc[merge_data.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=\"visitors\")\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = merge_data.loc[merge_data.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")\n\ntest_id = pd.DataFrame()\ntest_id = test_all_wid.loc[test_all_wid.set == \"test\"]\n\nva_fit = pd.DataFrame()\nva_fit = merge_data.loc[merge_data.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=\"visitors\")\nva_fit_x = va_fit_x.drop(columns=\"set\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier as XGB\nfrom sklearn.metrics import mean_squared_log_error\n\nModel = XGB(n_estimators=10, random_state=71,max_depth=10,colsample_bylevel=0.4,\n           gamma=0.0,alpha=0.0, min_child_weight=4,subsample=0.8,colsample_bytree=0.95\n           )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 特徴量を落とす","metadata":{}},{"cell_type":"code","source":"# 落とす特徴量を選ぶ\ndrop_columns = [\"lag14\",\"month\",\"day\",\"lag21\",\"lag28\",\"lag35\",\"lag42\",\"lag14_max\",\"lag21_max\",\"lag28_max\",\"lag35_max\",\"lag42_max\"]\ntrain_fit_x = train_fit_x.drop(columns=drop_columns)\ntest_fit_x = test_fit_x.drop(columns=drop_columns)\nva_fit_x = va_fit_x.drop(columns=drop_columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fit_x.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nModel.fit(train_fit_x, train_fit_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# モデルで予測する\npred = Model.predict(va_fit_x)\n\n# 予測値からRMSLEを算出する\nscore = np.sqrt(mean_squared_log_error(va_visitors, pred))\nprint(\"---------------RMSLE-score----------------\")\nscore","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = [\"pred_visitors\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\ncolumns = [\"visitors\"]\nva_fit_d = pd.DataFrame(data=va_visitors, columns = columns)\nva_fit_d = va_fit_d.reset_index(drop=True)\n\nsns.scatterplot(x=va_fit_d['visitors'], y=pred_d['pred_visitors'])\nsns.scatterplot(x=va_fit_d['visitors'], y=va_fit_d['visitors']) #perfect fitting line","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 以下、何が予測できていないのか確認","metadata":{}},{"cell_type":"code","source":"va_fit_d[\"delta\"] = va_fit_d[\"visitors\"] - pred_d[\"pred_visitors\"]\nva_fit_d[\"RMSLE\"] = np.sqrt(np.log10(va_fit_d[\"visitors\"]+1) - np.log10(pred_d[\"pred_visitors\"]+1)**2)\nva_fit_x_reindex = va_fit_x.reset_index(drop=True)\nva_fit_d = va_fit_d.join(va_fit_x_reindex)\nva_fit_d = va_fit_d.join(pred_d)\nva_fit_d[\"delta_abs\"] = abs(va_fit_d[\"delta\"])\nva_fit_d = va_fit_d.sort_values(by='RMSLE', ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# va_fit_d_watch= va_fit_d[[\"RMSLE\",\"delta_abs\",\"visitors\",\"pred_visitors\",\"year\",\"month\",\"day\",\"air_store_id\",\"day_of_the_week\"]]\n# va_fit_d_watch.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=va_fit_d_watch['delta_abs'], y=va_fit_d_watch['RMSLE'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_d_bad = va_fit_d.sort_values(by='RMSLE', ascending=False).head(100)\nva_fit_d_watch_bad = va_fit_d_watch.sort_values(by='delta_abs', ascending=False).head(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_d_watch_bad.sort_values(by='day_of_the_week', ascending=False).head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(\n    va_fit_d_watch_bad['day_of_the_week'], bins=100, color='#123456', label='data',\n    kde=False,\n    rug=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# testデータの予測","metadata":{}},{"cell_type":"code","source":"# モデルで予測する\npred = Model.predict(test_fit_x)\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_ck = [[\"visitors\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\nsubmission_ck","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_id = test_id.reset_index(drop=True)\ntest_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"id\"] = test_id.id\nsubmission[\"visitors\"] = submission_ck.visitors\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission_week1.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}