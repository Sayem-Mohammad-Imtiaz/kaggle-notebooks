{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NOTES: \n* Change VOCAB_TYPE for specific experiment\n* DATASET_DIST: select specific dataset for the experiment\n\n```\nsynth: synthetic data only \nbs   : boise_state data only\nbw   : bangla writing data only\nbh   : BN-HTR data only\nall  : NOT FOR Research/Paper Case\n```\n* MODEL_NAME: The specific model to use\n* USE_PRETRAINED : use pretrained model with synthetic data \n* EARLY_STOP  :   Stop the training early","metadata":{}},{"cell_type":"code","source":"#------------------------------------\n# variables to consider\n#------------------------------------\nEPOCHS       = 50\nVOCAB_TYPE   =\"unicode\" # @param[\"grapheme\",\"unicode\"]\nDATASET_DIST =\"synth\" # @param[\"synth\",\"bs\",\"bw\",\"bh\",\"all\"] \nMODEL_NAME   =\"dense_crnn\" # param [dense_crnn] \nUSE_PRETRAINED   =False\nEARLY_STOP       =True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------\n# fixed params\n#------------------\nimg_height  =  64\nimg_width   =  512\nnb_channels =  3\n        \n#----------------\n# imports\n#---------------\nimport tensorflow as tf\nimport random\nimport json\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ast import literal_eval\nfrom kaggle_datasets import KaggleDatasets\nfrom glob import glob\nimport cv2\nfrom itertools import groupby\n%matplotlib inline\n#-------------\n# reproduceable \n#-------------\n\nseed_value=42\nos.environ['PYTHONHASHSEED']=str(seed_value)\nrandom.seed(seed_value)\nnp.random.seed(seed_value)\ntf.random.set_seed(seed_value)\n#-------------\n# config-globals\n#-------------\nwith open('../input/pgvu-crnn-ctc-tfrecords/vocab.json') as f:\n    vocab = json.load(f)\n    \ngvocab=vocab[\"gvocab\"]\ncvocab=vocab[\"cvocab\"]\n    \nif VOCAB_TYPE==\"unicode\":\n    vocab     =cvocab\n    pos_max   =20\n    LSTM_UNIT =1024\n    POOL_LEVEL=3\nelse:\n    vocab  =gvocab\n    pos_max=10\n    LSTM_UNIT =1024\n    POOL_LEVEL=4\n    \nprint(\"Vocab len:\",len(vocab))\nprint(\"Label len:\",pos_max)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------------------------------------------------------\n# Detect hardware, return appropriate distribution strategy\n#----------------------------------------------------------\n# TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')\nelse:\n    strategy = tf.distribute.get_strategy() \n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------------\n# GCS Paths and tfrecords\n#-------------------------\ndef get_tfrecs(_path):\n    gcs_pattern=os.path.join(_path,'*.tfrecord')\n    file_paths = tf.io.gfile.glob(gcs_pattern)\n    random.shuffle(file_paths)\n    return file_paths\n    \n\nGCS_PATH= KaggleDatasets().get_gcs_path('pgvu-crnn-ctc-tfrecords')+\"/crnn/tfrecords/\"\n\n#---------------------------------\n# dataset\n#---------------------------------\ngpbw_train=GCS_PATH+\"bw.train/\"\ngpbw_eval =GCS_PATH+\"bw.test/\"\n\ngpbh_train=GCS_PATH+\"bh.train/\"\ngpbh_eval =GCS_PATH+\"bh.test/\"\n\ngpbs_train=GCS_PATH+\"bs.train/\"\ngpbs_eval =GCS_PATH+\"bs.test/\"\ngpbn_synth=GCS_PATH+\"synth/\"\n\nbw_train_recs  =get_tfrecs(gpbw_train)\nbw_eval_recs   =get_tfrecs(gpbw_eval)\nbh_train_recs  =get_tfrecs(gpbh_train)\nbh_eval_recs   =get_tfrecs(gpbh_eval)\nbs_train_recs  =get_tfrecs(gpbs_train)\nbs_eval_recs   =get_tfrecs(gpbs_eval)\nbn_synth_recs  =get_tfrecs(gpbn_synth)\nprint(\"Synthetic Data:\",len(bn_synth_recs)*1024)\nprint(\"Bangla Writing Train Data:\",len(bw_train_recs)*1024)\nprint(\"Bangla Writing Eval Data:\",len(bw_eval_recs)*1024)\nprint(\"Boise State Train Data:\",len(bs_train_recs)*1024)\nprint(\"Boise State Eval Data:\",len(bs_eval_recs)*1024)\nprint(\"BN-HTR Train Data:\",len(bh_train_recs)*1024)\nprint(\"BN-HTR Eval Data:\",len(bh_eval_recs)*1024)\n\n#-------------\n# train-eval split\n#-------------\nprint(\"---------------------------------------------------------------\")\nprint(\"section:train-eval split\")\nprint(\"---------------------------------------------------------------\")\nif DATASET_DIST==\"synth\":\n    eval_recs=bn_synth_recs[:2]\n    train_recs=bn_synth_recs[2:]\nelif DATASET_DIST==\"bw\":\n    train_recs=bw_train_recs\n    eval_recs =bw_eval_recs\nelif DATASET_DIST==\"bs\":\n    train_recs=bs_train_recs\n    eval_recs =bs_eval_recs\nelif DATASET_DIST==\"bh\":\n    train_recs=bh_train_recs\n    eval_recs =bh_eval_recs\nelif DATASET_DIST==\"all\":\n    train_recs=[]\n    train_recs+=bw_train_recs\n    train_recs+=bs_train_recs\n    train_recs+=bh_train_recs    \n    eval_recs =bw_eval_recs\n\n# numbers\nnb_train  =int(len(train_recs)*1024)\nnb_eval   =int(len(eval_recs)*1024)\nprint(\"Train Data:\",nb_train,len(train_recs))\nprint(\"Eval Data:\",nb_eval,len(eval_recs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------------------\n# batching , strategy and steps\n#-------------------------------------\nif strategy.num_replicas_in_sync==1:\n    BATCH_SIZE = 32\nelse:\n    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\n# set    \nTOTAL_DATA      = nb_train+nb_eval\nSTEPS_PER_EPOCH = TOTAL_DATA//BATCH_SIZE\nEVAL_STEPS      = (nb_eval)//BATCH_SIZE\nprint(\"Steps:\",STEPS_PER_EPOCH)\nprint(\"Batch Size:\",BATCH_SIZE)\nprint(\"Eval Steps:\",EVAL_STEPS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#------------------------------\n# parsing tfrecords basic\n#------------------------------\ndef data_input_fn(recs): \n    '''\n      This Function generates data from gcs\n      * The parser function should look similiar now because of datasetEDA\n    '''\n    def _parser(example):   \n        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n                    'clabel'  : tf.io.FixedLenFeature([20],tf.int64),\n                    'glabel'  : tf.io.FixedLenFeature([10],tf.int64),\n        }    \n        parsed_example=tf.io.parse_single_example(example,feature)\n        # image\n        image_raw=parsed_example['image']\n        image=tf.image.decode_png(image_raw,channels=nb_channels)\n        image=tf.cast(image,tf.float32)/255.0\n        image=tf.reshape(image,(img_height,img_width,nb_channels))\n        #image=tf.image.resize(image, [img_height//2,img_width//2])\n        \n        # label\n        if VOCAB_TYPE==\"unicode\":\n            label=parsed_example['clabel']\n        else:\n            label=parsed_example['glabel']\n        label=tf.cast(label, tf.float32)    \n        \n        return image,label\n    \n      \n\n    # fixed code (for almost all tfrec training)\n    dataset = tf.data.TFRecordDataset(recs)\n    dataset = dataset.map(_parser)\n    dataset = dataset.shuffle(2048,reshuffle_each_iteration=True)\n    dataset = dataset.repeat()\n    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset\n\ntrain_ds  =   data_input_fn(train_recs)\neval_ds  =   data_input_fn(eval_recs)\n\n\n\n#------------------------\n# visualizing data\n#------------------------\n\n\nfor x,y in train_ds.take(1):\n    data=np.squeeze(x[0])\n    plt.imshow(data)\n    plt.show()\n    print(\"---------------------------------------------------------------\")\n    print(\"label:\",y[0])\n    print(\"---------------------------------------------------------------\")\n    print('Image Batch Shape:',x.shape)\n    print(\"---------------------------------------------------------------\")\n    print('Target Batch Shape:',y.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{"papermill":{"duration":0.011211,"end_time":"2021-07-10T04:37:08.885329","exception":false,"start_time":"2021-07-10T04:37:08.874118","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# #-----------------------\n# # CTC\n# #-----------------------\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\nclass CTCLoss(keras.losses.Loss):\n    \"\"\" A class that wraps the function of tf.nn.ctc_loss. \n    \n    Attributes:\n        logits_time_major: If False (default) , shape is [batch, time, logits], \n            If True, logits is shaped [time, batch, logits]. \n        blank_index: Set the class index to use for the blank label. default is\n            -1 (num_classes - 1). \n    \"\"\"\n\n    def __init__(self, logits_time_major=False, name='ctc_loss'):\n        super().__init__(name=name)\n        self.logits_time_major = logits_time_major\n\n    def call(self, y_true, y_pred):\n        \"\"\" \n            Computes CTC (Connectionist Temporal Classification) loss. \n        \"\"\"\n        y_true = tf.cast(y_true, tf.int32)\n        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\n        label_length = tf.fill([tf.shape(y_true)[0]], tf.shape(y_true)[1])\n        loss = tf.nn.ctc_loss(\n            labels=y_true,\n            logits=y_pred,\n            label_length=label_length,\n            logit_length=logit_length,\n            logits_time_major=self.logits_time_major,\n            blank_index=0)\n        return tf.math.reduce_mean(loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef densenet_style(x):\n    feat=tf.keras.applications.DenseNet121(input_tensor=x,weights=None,include_top=False)\n    x=feat.get_layer(name=f\"pool{POOL_LEVEL}_conv\").output\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    return x\n\n\ndef build_model(feat_extractor,inp,model_name):\n    x = tf.keras.layers.Permute((2, 1, 3))(inp)\n    x=feat_extractor(x)\n    # reshape\n    bs,d1,d2,d3=x.shape\n    reshape_dim=(d1,int(d2*d3))\n    x = tf.keras.layers.Reshape(reshape_dim)(x) \n    # bi-lstm\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LSTM_UNIT, return_sequences=True), name='bi_lstm1')(x)\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LSTM_UNIT, return_sequences=True), name='bi_lstm2')(x)\n    # logits\n    logits = layers.Dense(units=len(vocab), name='logits')(x)\n    \n    model= tf.keras.Model(inputs=inp, outputs=logits, name=model_name)\n    return model\n\n\n\n# # permute\n# x = keras.layers.Permute((2, 1, 3))(inp)\n\ndef get_model(model_name):\n    inp=tf.keras.layers.Input(shape=(img_height,img_width,nb_channels))\n    model=build_model(densenet_style,inp,model_name)\n\n    if USE_PRETRAINED:\n        print(\"loading synthetic weights\")\n        model.load_weights(f\"../input/pgvu-weights-and-histories/{MODEL_NAME}_{VOCAB_TYPE}_synth.h5\")\n    return model","metadata":{"papermill":{"duration":0.021578,"end_time":"2021-07-10T04:37:08.918623","exception":false,"start_time":"2021-07-10T04:37:08.897045","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------\n# callbacks\n#---------------\n# weight file path\nweight_path=f\"{MODEL_NAME}_{VOCAB_TYPE}_{DATASET_DIST}.h5\"\n\n# reduces learning rate on plateau\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,\n                                                  cooldown= 10,\n                                                  patience=10,\n                                                  verbose =1,\n                                                  min_lr=0.1e-7)\n# saves the model\nmodel_autosave = tf.keras.callbacks.ModelCheckpoint(filepath=weight_path, \n                                                   monitor='val_loss', \n                                                   verbose=1, \n                                                   save_best_only=True, \n                                                   mode='min')\n\n# early stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=30, \n                                                  verbose=1, \n                                                  mode = 'auto') \ncallbacks= [model_autosave,lr_reducer]\nif EARLY_STOP:\n    print(\"Early Stopping Enabled\")\n    callbacks+=[early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    # optimizer\n    optimizer = tf.keras.optimizers.Adam(lr=0.00001)\n    model=get_model(MODEL_NAME)\n    # compile\n    model.compile(optimizer=optimizer,loss=CTCLoss())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_ds,\n                    epochs=EPOCHS,\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    verbose=1, \n                    validation_data=eval_ds,\n                    validation_steps=EVAL_STEPS, \n                    callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncurves={}\nfor key in history.history.keys():\n    curves[key]=history.history[key]\ncurves=pd.DataFrame(curves)\ncurves.to_csv(f\"{MODEL_NAME}_{VOCAB_TYPE}_{DATASET_DIST}.csv\",index=False)\n\n","metadata":{"papermill":{"duration":0.0206,"end_time":"2021-07-10T04:37:08.950989","exception":false,"start_time":"2021-07-10T04:37:08.930389","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(f\"{MODEL_NAME}_{VOCAB_TYPE}_{DATASET_DIST}.csv\")","metadata":{"papermill":{"duration":35.68876,"end_time":"2021-07-10T07:02:59.123681","exception":false,"start_time":"2021-07-10T07:02:23.434921","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(weight_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}