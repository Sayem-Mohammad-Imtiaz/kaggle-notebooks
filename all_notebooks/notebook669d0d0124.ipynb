{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import optimizers, utils, Input, preprocessing\nfrom keras.utils import np_utils\nfrom keras import datasets\nfrom keras.layers import Conv2D, BatchNormalization, Dense, Activation, Dropout, MaxPooling2D, Flatten \nfrom keras.layers.experimental.preprocessing import Resizing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv', index_col=0)\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Have a look on the data structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(df))\nprint(df['Label'].unique())\nprint(df['Dataset_type'].unique())\nprint(df['Label_2_Virus_category'].unique())\nprint(df['Label_1_Virus_category'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of NA values in X_ray_image_name = ', df['X_ray_image_name'].isna().sum())\nprint('Number of NA values in Label = ', df['Label'].isna().sum())\nprint('Number of NA values in Label_2 = ', df['Label_2_Virus_category'].isna().sum())\nprint('Number of NA values in Label_1 = ', df['Label_1_Virus_category'].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of Normal values in Label = ', df.Label.value_counts()['Normal'], '-->',\n      df.Label.value_counts()['Normal']/df.Label.count(),'%')\nprint('Number of Pnemonia values in Label = ', df.Label.value_counts()['Pnemonia'], '-->',\n      df.Label.value_counts()['Pnemonia']/df.Label.count(),'%')\nprint('Number of COVID_19 values in Label_2 = ', df.Label_2_Virus_category.value_counts()['COVID-19'])\n\nsub_df = df[(df['Dataset_type']=='TRAIN') & (df['Label']=='Normal')]\nprint('Number of Normal label in the train dataset = ',len(sub_df.index), '-->',\n      len(sub_df.index)/df.Dataset_type.value_counts()['TRAIN'],'%')\n\nsub_df = df[(df['Dataset_type']=='TRAIN') & (df['Label']=='Pnemonia')]\nprint('Number of Pnemonia label in the train dataset = ',len(sub_df.index), '-->',\n      len(sub_df.index)/df.Dataset_type.value_counts()['TRAIN'],'%')\n\nsub_df = df[(df['Dataset_type']=='TEST') & (df['Label']=='Normal')]\nprint('Number of Normal label in the test dataset = ',len(sub_df.index), '-->',\n      len(sub_df.index)/df.Dataset_type.value_counts()['TEST'],'%')\n\nsub_df = df[(df['Dataset_type']=='TEST') & (df['Label']=='Pnemonia')]\nprint('Number of Pnemonia label in the test dataset = ',len(sub_df.index), '-->',\n      len(sub_df.index)/df.Dataset_type.value_counts()['TEST'],'%')\n\nsub_df = df[(df['Dataset_type']=='TEST') & (df['Label_2_Virus_category']=='SARS')]\nprint(len(sub_df.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_plot_percentage(df, col):\n    ax = sns.countplot(x = col, data = df)\n    total = len(df[col])\n    for p in ax.patches:\n        percentage = f'{100 * p.get_height() / total:.1f}%\\n'\n        x = p.get_x() + p.get_width() / 2\n        y = p.get_height()\n        ax.annotate(percentage, (x, y), ha='center', va='center')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_plot_percentage(df, 'Label')\ncount_plot_percentage(df, 'Label_2_Virus_category')\ncount_plot_percentage(df, 'Label_1_Virus_category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load train data\n\nX_train = []\ny_train = []\nfor _, _, filenames in os.walk('../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/' +\n                           'Coronahack-Chest-XRay-Dataset/train/'):\n    for filename in filenames:\n        row = df.loc[df['X_ray_image_name'] == filename]\n        if not row.empty:\n            im_path = os.path.join('../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/' +\n                               'Coronahack-Chest-XRay-Dataset/train/', filename)\n            im = cv2.imread(im_path, cv2.IMREAD_GRAYSCALE)\n            im = cv2.resize(im, (256, 256))\n            X_train.append(im)\n            if row.iloc[0]['Label'] == 'Normal':\n                y_train.append(0)\n            else:\n                y_train.append(1)\n\nX_train = np.array(X_train)\ny_train = np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = np.arange(X_train.shape[0])\nnp.random.shuffle(indices)\nX_train = X_train[indices]\ny_train = y_train[indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load test data\n\nX_test = []\ny_test = []\nfor _, _, filenames in os.walk('../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/' +\n                           'Coronahack-Chest-XRay-Dataset/test/'):\n    for filename in filenames:\n        row = df.loc[df['X_ray_image_name'] == filename]\n        if not row.empty:\n            im_path = os.path.join('../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/' +\n                               'Coronahack-Chest-XRay-Dataset/test/', filename)\n            im = cv2.imread(im_path, cv2.IMREAD_GRAYSCALE)\n            im = cv2.resize(im, (256, 256))\n            X_test.append(im)\n            if row.iloc[0]['Label'] == 'Normal':\n                y_test.append(0)\n            else:\n                y_test.append(1)\n\nX_test = np.array(X_test)\ny_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of X_train = ', X_train.shape)\nprint('Shape of Y_train = ', y_train.shape)\nprint('Shape of X_test = ', X_test.shape)\nprint('Shape of Y_test = ', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n# view some images from the train set\nplt.figure(figsize=(10,4))\nx, y = 5, 2\nfor i in range(10):  \n    plt.subplot(y, x, i+1)\n    plt.imshow(X_train[i],interpolation='nearest', cmap= 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(-1,256,256,1)\nX_test = X_test.reshape(-1,256,256,1)\ninput_dim = X_train.shape[1:]\ny_train = utils.to_categorical(y_train, 2)\ny_test = utils.to_categorical(y_test, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of X_train = ', X_train.shape)\nprint('Shape of Y_train = ', y_train.shape)\nprint('Shape of X_test = ', X_test.shape)\nprint('Shape of Y_test = ', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The model\nmodel = Sequential()\nmodel.add(Input(shape=input_dim))\nmodel.add(Conv2D(8, kernel_size=(3, 3), activation=\"relu\")) #padding=\"same\", \nmodel.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\"))\nmodel.add(Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, kernel_size=(5,5), activation=\"relu\"))\nmodel.add(Conv2D(256, kernel_size=(5,5), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n#\nmodel.add(Flatten())\nmodel.add(Dense(2048, activation=\"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1024, activation=\"relu\"))\nmodel.add(Dense(2, activation=\"sigmoid\"))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(123)\nopt = optimizers.Adam(learning_rate=1e-4)\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy', 'categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = {0: 4.,\n                1: 1.}\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.05, class_weight=class_weight, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\ny_pred = np.argmax(model.predict(X_test), axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show some predictions\nf, axes = plt.subplots(2, 5, figsize=(10, 4))\nindices = np.arange(len(y_pred))\nnp.random.shuffle(indices)\nfor i, ind in enumerate(indices[:10]):\n    label = int(y_pred[ind])\n    img = X_test[ind].reshape((256,256))\n    axes[i // 5, i % 5].imshow(img, cmap='gray')\n    axes[i // 5, i % 5].set_title(label)\n        \n[ax.set_axis_off() for ax in axes.ravel()]\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction score\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Another check\ntemp = sum(np.argmax(y_test, axis=None, out=None) == y_pred)\nprint(temp/len(y_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}