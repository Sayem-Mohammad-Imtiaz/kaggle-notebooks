{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas_profiling as pdp\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit , StratifiedKFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"traindf = pd.read_csv(\"../input/train_LZdllcl.csv\")\ntestdf = pd.read_csv(\"../input/test_2umaH9m.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e0f17891d7327807ad87fe4b8028a6dcb557e5d"},"cell_type":"code","source":"sample = pd.read_csv(\"../input/sample_submission_M0L0uXE.csv\")\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6c24efc7c9b6ed797af365250b9385fd4b28f339"},"cell_type":"code","source":"pdp.ProfileReport(traindf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"906a382d813ed5d6331862539c0a47be7373fdda"},"cell_type":"markdown","source":"From above profiling we got to know:\n1. education(Categorical variables: 4 categories) and previous_year_rating(Numeric) have missing values\n2. Age and length of service have good correlation. All score variables have decent coorelation with target variable.\n3. There are 70% males and 30% females."},{"metadata":{"trusted":true,"_uuid":"97328418066ec0bed22aeacc629a8fb6e4249104"},"cell_type":"code","source":"pdp.ProfileReport(testdf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b74f04845b42754ca64e441cbb22acf05c9d6f0"},"cell_type":"markdown","source":"Test data also has missing values in same variables."},{"metadata":{"trusted":true,"_uuid":"180ec878e45aff911586b8b1f50c94d47ebaafc2"},"cell_type":"code","source":"#Combing data\ny = traindf['is_promoted']\ntraindf_cop = (traindf.copy()).drop(['is_promoted'],axis=1)\nalldata = traindf_cop.append(testdf)\nalldata = alldata.drop(['employee_id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8bbbbd5435252cbd09a208eb9ddaf1ce1d73dd7"},"cell_type":"markdown","source":"To fill missing values:\nEducation is something which is sometimes dependent on gender so filing missing values accordingly.\nprevious_year_rating in a company should not be dependent on gender"},{"metadata":{"trusted":true,"_uuid":"c27b7c30e78c253cb7831adff4cc32354aecc0a5"},"cell_type":"code","source":"#Missing value imputation for categorical variables\nalldata['previous_year_rating'] = alldata[\"previous_year_rating\"].fillna(alldata[\"previous_year_rating\"].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52c5c68dedcf71fff3cef73812559c4a45230e9a"},"cell_type":"code","source":"pd.crosstab(alldata[\"education\"], alldata[\"gender\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29cf566e73b2ac833bd4cf208da8699a2d670d0c"},"cell_type":"markdown","source":"Mostly men and women have Bachelor's degree. So filing missing values by this only."},{"metadata":{"trusted":true,"_uuid":"313533f9ab02ad3622e6d0509658a010ae96ade7"},"cell_type":"code","source":"alldata[\"education\"] = alldata['education'].fillna(\"Bachelor's\")\n#alldata['education'].replace(\"Master's & above\",3,inplace=True)\n#alldata['education'].replace(\"Bachelor's\",2,inplace=True)\n#alldata['education'].replace(\"Below Secondary\",1,inplace=True)\n\n#alldata['sum_metric'] = alldata['awards_won?']+alldata['KPIs_met >80%'] + alldata['previous_year_rating']\n#alldata['tot_score'] = alldata['avg_training_score'] * alldata['no_of_trainings']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6a28747eb5e467a09de7f31c270fe6d1924de63"},"cell_type":"markdown","source":"We will create a new feature by dividing length of service by age variable, because higher the age , higher is the length of service is expected. This varibale will be like % of age spent in that particular oranization."},{"metadata":{"trusted":true,"_uuid":"b2e9f0a6fc805d851e6115b1dc5bcd2054226cd3"},"cell_type":"code","source":"alldata['life_spent_in_comp'] = alldata['length_of_service']/alldata['age']\nalldata['life_spent_in_comp2'] = alldata['age'] - alldata['length_of_service']\nalldata['perf'] = alldata['KPIs_met >80%']*alldata['awards_won?']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a09e9bbd2e34ce3c6412992a31236bbe01fdef6b"},"cell_type":"code","source":"age_bins = [10,20,30,40,50,60,100]\nage_labels = [1,2,3,4,5,6]  # this  is better than to do label encoding afterwards\nalldata['age_binned'] = pd.cut(alldata['age'], bins=age_bins, labels=age_labels)\nalldata['age_binned'] = alldata['age_binned'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bf4282e837292b5571449bf654786a07d860e98"},"cell_type":"code","source":"cols = ['department','region','gender','recruitment_channel','age_binned']\nint_cols = (alldata.dtypes[alldata.dtypes != \"object\"].index).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d44205f4d170841014870e5df4af725e70383f93"},"cell_type":"code","source":"sns.violinplot(x = 'department', y= 'is_promoted',  data=traindf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f48c5d86bd39b71e9902d3d97694bf59476cdb9"},"cell_type":"code","source":"sns.barplot(x = 'gender', y= 'is_promoted',  data=traindf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d473ca0ea31046dac9d55c55a6c53f39ee8549e"},"cell_type":"code","source":"sns.violinplot(y = 'KPIs_met >80%', x= 'is_promoted',  data=traindf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db933794df49463bf3d5a6b919e7b693aa9e2e06"},"cell_type":"markdown","source":"Above plot tells us that KPI is decently good indicator of is_promoted but not very strong indicator."},{"metadata":{"_uuid":"c25776c7747ee381f2290181045e765c8f6368ff"},"cell_type":"markdown","source":"Label encoding categorical values. Some of you might think why are we not directly converting them into one hot encoding vectors. This is because if we do that then we get lots of variables which might affect our performance. We will try that but also try by just label encoding."},{"metadata":{"trusted":true,"_uuid":"30d25771e14903eb3b2fd058da61ab061e5b2dbe"},"cell_type":"code","source":"#first we will make a copy of this data\nalldata_le = alldata.copy()\nalldata_oh = alldata.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7db3b9366cbde4b90cb1aeb2f5df56c9815582b5"},"cell_type":"code","source":"obj = (alldata_le.dtypes == (\"object\"))  + (alldata_le.dtypes == \"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71b4e1b9cd7375b62a1e8205ef11df6e7bc206fd"},"cell_type":"code","source":"alldata_le.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b972f254d3fd6ba29316e740e38768bd0999700d"},"cell_type":"code","source":"alldata_le.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38e23654923517d86d1c0bd3d3cbaea6de566a00"},"cell_type":"code","source":"obj = (alldata_le.dtypes=='object') + (alldata_le.dtypes=='category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d3161450acec3c2d769da007e0b8c33d75596c7"},"cell_type":"code","source":"le = LabelEncoder()\ncol = (alldata_le.dtypes[obj].index).tolist()\nfor i in range(0,len(col)):\n    l = col[i]\n    alldata_le[l] = le.fit_transform(alldata_le[l])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02af0be6c3d76c430f775f54e31a93be61abc6d7"},"cell_type":"markdown","source":"Now trying one hot encoding:"},{"metadata":{"trusted":true,"_uuid":"5f1f1d9b306152623c08a36bdd9360d52709f84d"},"cell_type":"code","source":"alldata_oh = alldata_oh.drop(['region'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40191922b10b10ac7059982e4188d0b07bd08992"},"cell_type":"code","source":"obj = (alldata_oh.dtypes=='object') + (alldata_oh.dtypes=='category')\ncol = (alldata_oh.dtypes[obj].index).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7310d67969f6dec81da4d92b0a538acad6348875"},"cell_type":"code","source":"alldata_oh = pd.get_dummies(alldata_oh,columns=col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90bd03f3ce51251fdac5776a6e83603df534feb0"},"cell_type":"code","source":"alldata_oh.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bba719544e6a249f333c84a76712bb7de9101c3"},"cell_type":"code","source":"print(\"Number of features in modified/label encoded dataframe : \" , len(alldata.columns))\nprint(\"Number of features after One hot encoding : \" , len(alldata_oh.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fe37d7adf3524ffe419b6db8b3fa362b36583ee"},"cell_type":"code","source":"# Let's check distribution of our numeric cols    \nm=1\nplt.figure(figsize = (15,15))\nfor i in int_cols:\n    plt.subplot(8,4,m)\n    sns.distplot(alldata[i],kde = True)\n    m = m+1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4154eaa33565cf635fb268fbb7f2e8e1a78ac3c9"},"cell_type":"markdown","source":"Our numeric variables are highly skewed. We will apply log transformations to these."},{"metadata":{"trusted":true,"_uuid":"6580cfe0a60cb5286fc7c246dc002783ea5b531c"},"cell_type":"code","source":"'''\nfrom scipy.stats import skew\nalldata_le_s = alldata_le.copy()\nalldata_le_s[int_cols] = np.log1p(alldata_le_s[int_cols])\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"251a91d47f9027f05e7b1f239f75f91567596243"},"cell_type":"code","source":"alldata_oh_s = alldata_oh.copy()\nalldata_oh_s[int_cols] = np.log1p(alldata_oh_s[int_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fad789e391c2ad5171f9d7d5e553c662d8bba3cd"},"cell_type":"code","source":"train_data = alldata_oh.iloc[:traindf.shape[0],:]\ntest_data = alldata_oh.iloc[traindf.shape[0]:,:]\nscaler = RobustScaler()\nscaler = scaler.fit(train_data[int_cols])\ntrain_data[int_cols] = scaler.transform(train_data[int_cols])\ntest_data[int_cols] = scaler.transform(test_data[int_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6fa3c5b0c8dca6322bfcca185f80c5a357f3591"},"cell_type":"code","source":"#  split X between training and testing set\nx_train, x_test, y_train, y_test = train_test_split(train_data,y, test_size=0.20, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03b4f4cadda12a77e2ecf815267c8947ac2f148e"},"cell_type":"code","source":"# Model-1: Using XGBClassifier\nxgb = XGBClassifier(n_estimators=600,min_child_weight=5,learning_rate=0.02,\n                   gamma=1,subsample=0.8,colsample_bytree=0.8,max_depth=10, random_state=123)\nxgb.fit(x_train, y_train, verbose=1)\nxgb_pred_prob = xgb.predict_proba(x_test)\nxgb_pred = [i[1] for i in xgb_pred_prob]\nthresholds = np.linspace(0.01, 0.99, 50)\nmcc = np.array([f1_score(y_test, xgb_pred>thr) for thr in thresholds])\n\nbest_threshold = thresholds[mcc.argmax()]\nprint(mcc.max())\nprint(best_threshold)\n#print('F1 score from XGB model: ', f1_score(forest_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34991a1ebcbcc4a1d75a2b35fafeb98e4f140872"},"cell_type":"code","source":"'''\nforest = GradientBoostingClassifier(loss='exponential',max_features='auto',n_estimators=500,random_state=22)\nforest.fit(x_train, y_train)\nforest_pred_prob = forest.predict_proba(x_test)\nforest_pred = [i[1] for i in forest_pred_prob]\nthresholds = np.linspace(0.01, 0.99, 50)\nmcc = np.array([f1_score(y_test, forest_pred>thr) for thr in thresholds])\n\nbest_threshold = thresholds[mcc.argmax()]\nprint(mcc.max())\nprint(best_threshold)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecb71cefb0fed48f6a3e0dbe6731c0625624d858"},"cell_type":"code","source":"clf = lgb.LGBMClassifier(max_depth= 8, learning_rate=0.0941, n_estimators=197, \n                         num_leaves= 17, reg_alpha=3.4492 , reg_lambda= 0.0422,random_state=223)\nclf.fit(x_train, y_train, verbose=1)\nlgb_pred_prob = clf.predict_proba(x_test)\nlgb_pred = [i[1] for i in lgb_pred_prob]\nthresholds = np.linspace(0.01, 0.99, 50)\nmcc = np.array([f1_score(y_test, lgb_pred>thr) for thr in thresholds])\n\nbest_threshold = thresholds[mcc.argmax()]\nprint(mcc.max())\nprint(best_threshold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87f1a865ee822d55585da535c800ca66b0169c15"},"cell_type":"code","source":"final_prob = (lgb_pred_prob +xgb_pred_prob)/2\nfinal_pred = [i[1] for i in final_prob]\nthresholds = np.linspace(0.01, 0.99, 50)\nmcc = np.array([f1_score(y_test, final_pred>thr) for thr in thresholds])\n\nbest_threshold = thresholds[mcc.argmax()]\nprint(mcc.max())\nprint(best_threshold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a60e634f8906be76f380fb4236e754fa70d06e1"},"cell_type":"code","source":"#test set\nlgb_pred_prob_test = clf.predict_proba(test_data)\nxgb_pred_prob_test = xgb.predict_proba(test_data)\nfinal_prob_test = (lgb_pred_prob_test +xgb_pred_prob_test)/2\nfinal_pred_prob = [i[1] for i in final_prob_test]\nfinal_pred = [1 if i>0.33 else 0 for i in final_pred_prob]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd517d13385ad166f4036c8bf118d609f4b9cd8a"},"cell_type":"markdown","source":"Results for label encoded data(Without skewness adjustment) using default parameters in model:\n* XGBoost: 0.513\n* Decision Tree: 0.417\n* Random Forest: 0.395\n* Light GB: 0.501 (at threshold of 0.25, also did few modifications)\n\nResults for label encoded data(With skewness adjustment) using default parameters in model:\n* XGBoost: 0.469\n* Decision Tree: 0.401\n* Random Forest: 0.32\n* Light GB: 0.47 (at threshold of 0.2, also did few modifications)\n\nResults for one hot encoded data(Without skewness adjustment) using default parameters in model:\n* XGBoost: 0.494\n* Decision Tree: 0.445\n* Random Forest: 0.38\n* Light GB: 0.504 (at threshold of 0.25, also did few modifications)\n\nResults for one hot encoded data(With skewness adjustment) using default parameters in model:\n* XGBoost: 514\n* Decision Tree: 0.441\n* Random Forest: 0.363\n* Light GB: 0.518 (at threshold of 0.2, also did few modifications)"},{"metadata":{"_uuid":"489bb31477607518fd01a1538d602310a7af8f72"},"cell_type":"markdown","source":"Decision Tree and Random Forest have consistently shown bad performace so commenting out their code.\nLight GBM also has not shown much improvement as compared to XGB so will only make further improvements on XGB model. \n> Also now I will make improvements on label encoded data without skewness adjustments and One hot encoded data with skewness adjustment as raw model trained on them gave good performance."},{"metadata":{"trusted":true,"_uuid":"36d41930ce363d5fc138c80419af82ed75591848"},"cell_type":"code","source":"sub = pd.DataFrame(data = testdf['employee_id'],columns =['employee_id'])\nsub['is_promoted'] = final_pred\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}