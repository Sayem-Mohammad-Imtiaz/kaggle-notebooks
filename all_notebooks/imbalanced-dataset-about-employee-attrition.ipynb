{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Setup\n\n# common:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport matplotlib.patches as mpatches\nfrom scipy.stats import norm\nfrom scipy import stats\nimport time\nimport folium\nimport collections\nimport eli5 # Feature importance evaluation\nimport urllib\nfrom PIL import Image\n\n# for ML:\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, average_precision_score, roc_curve, precision_recall_curve, classification_report, confusion_matrix, mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, ShuffleSplit, cross_validate, cross_val_score, cross_val_predict, RandomizedSearchCV, GridSearchCV, learning_curve\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, RobustScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\n\n# Imported Libraries\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom imblearn.pipeline import Pipeline\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# set some display options:\nsns.set(style=\"whitegrid\")\npd.set_option(\"display.max_columns\", 36)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data:\nfile_path = '/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv'\ndf = pd.read_csv(file_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.float_format\", \"{:.2f}\".format)\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for missing values\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### To Drop:\n+ EmployeeCount: All values have the same value.\n+ EmployeeNumber: Irrelevant variable, it is only an employee identifier.\n+ Over18: All values have the same value.\n+ StandartHours: All values have the same value.","metadata":{}},{"cell_type":"code","source":"df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=\"columns\", inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Attrition = df.Attrition.astype('category').cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = []\nfor column in df.columns:\n    if df[column].dtype == object:\n        categorical_features.append(column)\n        print(f\"{column}\")\n        print(\"====================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_features = []\nfor column in df.columns:\n    if df[column].dtype != object:\n        numerical_features.append(column)\n        print(f\"{column}\")\n        print(\"====================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_features.remove('Attrition')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"### Attrition rate","metadata":{}},{"cell_type":"code","source":"# The classes are skewed we need to solve this issue later.\nprint('No Attrition', round(df['Attrition'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\nprint('Attrition', round(df['Attrition'].value_counts()[1]/len(df) * 100,2), '% of the dataset')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='Attrition', data=df)\nplt.title('Attrition Distributions \\n (0: No Attrition || 1: Attrition)', fontsize=14)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 40))\n\nfor i, feature in enumerate(numerical_features, 1):\n    plt.subplot(8, 3, i)\n    df[df[\"Attrition\"] == 0][feature].hist(bins=35, color='blue', label='Not Attrition', alpha=0.6)\n    df[df[\"Attrition\"] == 1][feature].hist(bins=35, color='red', label='Attrition', alpha=0.6)\n    plt.legend()\n    plt.xlabel(feature)\n    plt.ylabel('count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 15))\n\nfor i, feature in enumerate(categorical_features, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"Attrition\"] == 0][feature].hist(bins=35, color='blue', label='Not Attrition', alpha=0.6)\n    df[df[\"Attrition\"] == 1][feature].hist(bins=35, color='red', label='Attrition', alpha=0.6)\n    plt.legend()\n    plt.xlabel(feature)\n    plt.ylabel('count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusions:**\n\n***\n- `BusinessTravel` : The workers who travel a lot are more likely to quit than other employees.\n\n- `Department` : The worker in `Research & Development` are more likely to stay than the workers on other departement.\n\n- `EducationField` : The workers with `Human Resources` and `Technical Degree` are more likely to quit than employees from other fields of educations.\n\n- `Gender` : The `Male` are more likely to quit.\n\n- `JobRole` : The workers in `Laboratory Technician`, `Sales Representative`, and `Human Resources` are more likely to quit the workers in other positions.\n\n- `MaritalStatus` : The workers who have `Single` marital status are more likely to quit the `Married`, and `Divorced`.\n\n- `OverTime` : The workers who work more hours are likely to quit then others.\n\n*** ","metadata":{}},{"cell_type":"markdown","source":"### Correlation Matrix","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30, 24))\npalette = sns.diverging_palette(20, 220, n=256)\ncorr=df.corr(method='pearson')\nsns.heatmap(corr, annot=True, cmap=palette, vmax=.3, center=0, square=True, linewidths=.5, annot_kws={\"size\":15}, cbar_kws={'shrink': .5})\nplt.title('Correlation Matrix', size=15, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('Attrition', axis=1).corrwith(df.Attrition).plot(kind='barh', figsize=(10, 7))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML","metadata":{}},{"cell_type":"markdown","source":"## Normal","metadata":{}},{"cell_type":"code","source":"# Separate features and predicted value\nfeatures = numerical_features + categorical_features\nY = df['Attrition']\nX = df.drop('Attrition', axis=1)[features]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n# preprocess numerical feats:\n# for most num cols, except the dates, 0 is the most logical choice as fill value\n# and here no dates are missing.\nnum_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n    ('scaler', StandardScaler())])\n\n# Preprocessing for categorical features:\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical features:\npreprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, numerical_features),\n                                               (\"cat\", cat_transformer, categorical_features)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define base_models to test:\nbase_models = {\n    'LOR_model': LogisticRegression(),\n    'KNC_model': KNeighborsClassifier(),\n    'SVM_model': SVC(),\n    'DTR_model': DecisionTreeClassifier(),\n    'RFC_model': RandomForestClassifier(),\n    'ETC_model': ExtraTreesClassifier(),\n    'BAG_model': BaggingClassifier(),\n    'MLP_model': MLPClassifier(),\n    'XGB_model': XGBClassifier(),\n}\n\nnormal_model_score = {}\n\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\n# Preprocessing, fitting, making predictions and scoring for every model:\nfor name, model in base_models.items():\n    # pack preprocessing of data and the model in a pipeline:\n    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n    \n    # get cross validation score for each model:\n    cv_results = cross_val_score(model_steps, \n                                 X_train, Y_train, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    normal_model_score[name] = cv_results\n    \n    # output:\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} model cross validation accuracy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Under Sampling","metadata":{}},{"cell_type":"code","source":"# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n\n# Lets shuffle the data before creating the subsamples\n\ndf = df.sample(frac=1, random_state=42)\n\n# amount of fraud classes 492 rows.\nfraud_df = df.loc[df['Attrition'] == 1]\nnon_fraud_df = df.loc[df['Attrition'] == 0][:237]\n\nnormal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n\n# Shuffle dataframe rows\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nnew_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate features and predicted value\nfeatures = numerical_features + categorical_features\nY = normal_distributed_df['Attrition']\nX = normal_distributed_df.drop('Attrition', axis=1)[features]\n\nunder_X_train, under_X_test, under_Y_train, under_Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n# preprocess numerical feats:\n# for most num cols, except the dates, 0 is the most logical choice as fill value\n# and here no dates are missing.\nnum_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n    ('scaler', StandardScaler())])\n\n# Preprocessing for categorical features:\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical features:\npreprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, numerical_features),\n                                               (\"cat\", cat_transformer, categorical_features)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define base_models to test:\nbase_models = {\n    'LOR_model': LogisticRegression(),\n    'KNC_model': KNeighborsClassifier(),\n    'SVM_model': SVC(),\n    'DTR_model': DecisionTreeClassifier(),\n    'RFC_model': RandomForestClassifier(),\n    'ETC_model': ExtraTreesClassifier(),\n    'BAG_model': BaggingClassifier(),\n    'MLP_model': MLPClassifier(),\n    'XGB_model': XGBClassifier(),\n}\n\nunder_sampling_model_score = {}\n\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\n# Preprocessing, fitting, making predictions and scoring for every model:\nfor name, model in base_models.items():\n    # pack preprocessing of data and the model in a pipeline:\n    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n    \n    # get cross validation score for each model:\n    cv_results = cross_val_score(model_steps, \n                                 under_X_train, under_Y_train, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    under_sampling_model_score[name] = cv_results\n\n    # output:\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} model cross validation accuracy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Over sampling","metadata":{}},{"cell_type":"code","source":"# Separate features and predicted value\nfeatures = numerical_features + categorical_features\nY = df['Attrition']\nX = df.drop('Attrition', axis=1)[features]\n\nover_X_train, over_X_test, over_Y_train, over_Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n# preprocess numerical feats:\n# for most num cols, except the dates, 0 is the most logical choice as fill value\n# and here no dates are missing.\nnum_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n    ('scaler', StandardScaler())])\n\n# Preprocessing for categorical features:\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical features:\npreprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, numerical_features),\n                                               (\"cat\", cat_transformer, categorical_features)])\n\n# SMOTE Technique (OverSampling) After splitting and Cross Validating\nsm = SMOTE(sampling_strategy='minority', random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define base_models to test:\nbase_models = {\n    'LOR_model': LogisticRegression(),\n    'KNC_model': KNeighborsClassifier(),\n    'SVM_model': SVC(),\n    'DTR_model': DecisionTreeClassifier(),\n    'RFC_model': RandomForestClassifier(),\n    'ETC_model': ExtraTreesClassifier(),\n    'BAG_model': BaggingClassifier(),\n    'MLP_model': MLPClassifier(),\n    'XGB_model': XGBClassifier(),\n}\n\nover_sampling_model_score = {}\n\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\n# Preprocessing, fitting, making predictions and scoring for every model:\nfor name, model in base_models.items():\n    # pack preprocessing of data and the model in a pipeline:\n    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('smote', sm),\n                              ('model', model)])\n    \n    # get cross validation score for each model:\n    cv_results = cross_val_score(model_steps, \n                                 over_X_train, over_Y_train, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    over_sampling_model_score[name] = cv_results\n\n    # output:\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} model cross validation accuracy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_score = {\n    \"normal_model_score\": normal_model_score,\n    \"under_sampling_model_score\": under_sampling_model_score,\n    \"over_sampling_model_score\": over_sampling_model_score\n}\n\nfigure = plt.figure(figsize=(15,12))\nfor name, score_dict in model_score.items():\n    mean_score = []\n    lower_mean_socre = []\n    upper_mean_socre = []\n    model_name = []\n    for model, score in score_dict.items():\n        mean_score.append(round(np.mean(score), 4))\n        lower_mean_socre.append(round(np.mean(score), 4) - round(np.std(score), 4))\n        upper_mean_socre.append(round(np.mean(score), 4) + round(np.std(score), 4))\n        model_name.append(model)\n    plt.plot(model_name, mean_score, 'o-', label=f\"{name}\")\n    plt.fill_between(model_name, lower_mean_socre, upper_mean_socre, alpha=0.1)\nplt.title(\"Sampling Score Curve\", fontsize=14)\nplt.xlabel('model name')\nplt.ylabel('Score')\nplt.grid(True)\nplt.legend(loc=\"best\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, we select the over sampling method.","metadata":{}},{"cell_type":"code","source":"print(\"Normal Model\\n\")\nmodel = RandomForestClassifier(random_state=42, n_jobs=-1,)\n\nmodel_steps = Pipeline(steps=[\n                            ('preprocessor', preprocessor),\n                            ('model', model)])\n\n# fit model(pipeline) so values can be accessed:\nmodel_steps.fit(X_train, Y_train)\n\nY_pred = model_steps.predict(X_test)\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\nlabels = ['No Attrition', 'Attrition']\nprint(classification_report(Y_test, Y_pred, target_names=labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Over Sampling Model\\n\")\nmodel = RandomForestClassifier(random_state=42, n_jobs=-1,)\n\nmodel_steps = Pipeline(steps=[\n                            ('preprocessor', preprocessor),\n                            ('model', model)])\n\n# fit model(pipeline) so values can be accessed:\nmodel_steps.fit(over_X_train, over_Y_train)\n\nover_Y_pred = model_steps.predict(over_X_test)\nActVPred = pd.DataFrame({'Actual': over_Y_test, 'Predicted': over_Y_pred})\nprint(ActVPred)\n\nlabels = ['No Attrition', 'Attrition']\nprint(classification_report(over_Y_test, over_Y_pred, target_names=labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Names of all (encoded) features are needed.\n# Get names of columns from One Hot Encoding:\nonehot_columns = list(model_steps.named_steps['preprocessor'].\n                      named_transformers_['cat'].\n                      named_steps['onehot'].\n                      get_feature_names(input_features=categorical_features))\n\n# Add num_features for full list.\n# Order must be as in definition of X, where num_features are first: \nfeat_imp_list = numerical_features + onehot_columns\n\n# show 10 most important features, provide names of features:\nfeat_imp_df = eli5.formatters.as_dataframe.explain_weights_df(\n    model_steps.named_steps['model'],\n    feature_names=feat_imp_list)\nfeat_imp_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}