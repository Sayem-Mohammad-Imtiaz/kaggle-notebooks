{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Lots of code was used from Huseyinefe's kernel, to help me with reading/processing data\n#Import the necessary packages\nimport tensorflow as tf\nimport keras\nimport numpy as np\nimport matplotlib\nimport sklearn\nimport cv2\nimport os\nimport glob\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split, KFold\nfrom keras import models\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Flatten, Dropout\nfrom keras.optimizers import Adam, SGD\nfrom PIL import Image\nfrom keras.utils import to_categorical\n\n#-----Define important functions that will be used to process data-----\n\ndef read_images(path, number_of_images):\n    arr = np.zeros((number_of_images, 224, 224, 3))\n    i = 0\n    for image in os.listdir(path): #image will be the name of the file\n        image_path = path + \"/\" + image #creating a full path for the image \n        image = Image.open(image_path, mode='r')\n        image_data = np.asarray(image, dtype='uint8')\n        arr[i] = image_data\n        i += 1\n    return arr\n\n#Read the images in a path for each of the different categories\n#0: No DR, 1: Mild, 2: Moderate, 3: Proliferate, 4: Severe\ndef read_images_in_path(category):\n    if category == 0: #No_DR\n        path = r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/No_DR\"\n    elif category == 1: #Mild\n        path = r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Mild\"\n    elif category == 2: #Moderate\n        path = r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Moderate\"\n    elif category == 3: #Proliferate_DR\n        path = r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Proliferate_DR\"\n    elif category == 4: #Severe\n        path = r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Severe\"\n    else:\n        raise ValueError('Invalid category')\n    end_path = path + '/*'\n    num_in_path = len(glob.glob(end_path))\n    images = read_images(path, num_in_path)\n    images = images.astype('uint8')\n    return num_in_path, images\n\n#Normalizes pixels for faster training\ndef normalize_pixels(images):\n    images = images.astype('float32')\n    images = images/255\n    return images\n\n#Decreases square image to res x res\ndef decrease_res(images, num_images, res):\n    new_images = np.zeros((num_images, res, res, 3))\n    i = 0\n    for image in images:\n        new_image     = cv2.resize(image, (res,res))\n        new_images[i] = new_image\n        i += 1\n    return new_images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we get the number of images in each category, as well as the images."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"No_DR_num, No_DR_images   = read_images_in_path(0) #1805\nMild_num, Mild_images     = read_images_in_path(1) #370\nMod_num, Mod_images       = read_images_in_path(2) #999\nProlif_num, Prolif_images = read_images_in_path(3) #295\nSevere_num, Severe_images = read_images_in_path(4) #193","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"We view one of the images."},{"metadata":{"trusted":true},"cell_type":"code","source":"pyplot.imshow(Mild_images[29])\npyplot.axis(\"off\")\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we normalize the pixels so that their values are in between 0 and 1, instead of 0 and 255. We do this to accelerate learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"No_DR_images  = normalize_pixels(No_DR_images)\nMild_images   = normalize_pixels(Mild_images)\nMod_images    = normalize_pixels(Mod_images)\nProlif_images = normalize_pixels(Prolif_images)\nSevere_images = normalize_pixels(Severe_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now generate a corresponding label vector that will match images to a category."},{"metadata":{"trusted":true},"cell_type":"code","source":"no_DR  = np.zeros(No_DR_num)\nmild   = np.ones(Mild_num)\nmod    = np.full(Mod_num, 2)\nprolif = np.full(Prolif_num, 3)\nsevere = np.full(Severe_num, 4)\nlabels = np.concatenate((no_DR, mild, mod, prolif, severe), axis=0)\nlabels = to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We encode data in a way that we can get a one-to-one correspondence with the labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.concatenate((No_DR_images, Mild_images, Mod_images, Prolif_images, Severe_images))\ny = labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's split x into training, validation, and testing data. We will use 20% of the data as a held-out test set that will evaluate the model. Within the 80% remaining data, we will use 20% of that data as a validation set, so that we can evaluate how good our model is and update parameters before finally applying the model to our held-out test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we decrease the resolution of each image from 224x224 to 64x64. There are two reasons for this. Firstly, having fewer pixels will increase training time significantly. Secondly, we are building a VGG8 architecture from scratch, which takes in inputs of size 64x64."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train  = decrease_res(x_train, np.shape(x_train)[0], res=64)\nx_val    = decrease_res(x_val, np.shape(x_val)[0], res=64)\nx_test   = decrease_res(x_test, np.shape(x_test)[0], res=64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's print out the shapes to see the dimensions of the training, validation, and test sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(x_train))\nprint(np.shape(x_val))\nprint(np.shape(x_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get around to defining the VGG8 model, whose architecture is like a compact version of the VGG16 model. Documentation can be found [here](https://books.google.com/books?id=YfvHDwAAQBAJ&pg=PA347&lpg=PA347&dq=%22vgg+8%22+architecture&source=bl&ots=AEJ6W_yNaO&sig=ACfU3U3dXUXmucNmRTwKDqRDeArvPhO8UQ&hl=en&sa=X&ved=2ahUKEwjT_5WE3cLoAhWWAZ0JHT0SDtIQ6AEwC3oECAgQAQ#v=onepage&q=%22vgg%208%22%20architecture&f=false)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_VGG8():\n    model = Sequential()\n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(64,64,3)))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform'))\n    model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform'))\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform'))\n    model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    model.add(Flatten())\n    model.add(Dense(512, activation = 'relu', kernel_initializer = 'he_uniform'))\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation = 'softmax'))\n    opt = SGD(lr=0.01, momentum=0.9)\n    model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These functions will fit the model to the training set, then will evaluate performance on the validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(trainX, trainY, valX, valY, model, batch_size, epochs):\n    hist = model.fit(trainX, trainY, batch_size, epochs, verbose=1, validation_data=(valX, valY))\n    _, train_score = model.evaluate(trainX,trainY)\n    _, val_score  = model.evaluate(valX,valY)\n    return hist, train_score, val_score\n\n#Summarizing results of a particular model\ndef results_summary(hist):\n    pyplot.subplot(2,1,1)\n    pyplot.title('Loss')\n    pyplot.plot(hist.history['loss'], color='blue',label='Train')\n    pyplot.plot(hist.history['val_loss'], color='orange', label='Validation')\n    pyplot.subplot(2,1,2)\n    pyplot.title('Accuracy')\n    pyplot.plot(hist.history['accuracy'], color='blue', label='Train')\n    pyplot.plot(hist.history['val_accuracy'], color='orange', label = 'Validation')\n    pyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, let's fit the model to the training data and evaluate performance on the validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"model   = define_VGG8()\nhist, train_score, val_score = evaluate_model(x_train, y_train, x_val, y_val, model, batch_size=32, epochs=75)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"results_summary(hist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly, the model is overfitting, as the validation loss continues to go up. However, the validation acucuracy is fairly stable. We should try changing hyperparameters such decreasing batch size and epochs. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = define_VGG8()\nmodel3 = define_VGG8()\nmodel4 = define_VGG8()\n\nhist2, train_score2, val_score2 = evaluate_model(x_train, y_train, x_val, y_val, model2, batch_size=32, epochs=30)\nhist3, train_score3, val_score3 = evaluate_model(x_train, y_train, x_val, y_val, model3, batch_size=16, epochs=30)\nhist4, train_score4, val_score4 = evaluate_model(x_train, y_train, x_val, y_val, model4, batch_size= 8, epochs=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's look at the performance of these new models"},{"metadata":{"trusted":true},"cell_type":"code","source":"results_summary(hist2)\nresults_summary(hist3)\nresults_summary(hist4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Out of the models, Model 4 seems to perform the best. It doesn't seem to overfit and achieves the best performance. Let's use these specifications to create the final model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(x_train, y_train, model, batch_size, epochs):\n    history = model.fit(x_train, y_train, batch_size, epochs, verbose=1)\n    _, train_score = model.evaluate(x_train, y_train)\n    model.save('Diabetic_Retinopathy_Model.h5')\n    return history, train_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = define_VGG8()\nhist, train_score = fit_model(x_train, y_train, final_model, batch_size=8, epochs=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's finally see how the model runs on the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = models.load_model('Diabetic_Retinopathy_Model.h5')\n_, score = final_model.evaluate(x_test, y_test)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}