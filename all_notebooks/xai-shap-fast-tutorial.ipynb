{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Motivation\n\n\"Explainable AI (XAI) refers to methods and techniques in the application of artificial intelligence technology (AI) such that the results of the solution can be understood by humans.\" \n\nSource - [Wikipedia](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)\n\nI discovery this lib called [SHAP](https://github.com/slundberg/shap) that can help you understand how a prediction is made.\n\nThis notebook book is just an example of \"how to use\" very similar than the documentations if you prefer you just can go there and see by your self.","metadata":{}},{"cell_type":"code","source":"!pip install nb_black -q","metadata":{"execution":{"iopub.execute_input":"2020-09-12T00:35:33.043294Z","iopub.status.busy":"2020-09-12T00:35:33.042468Z","iopub.status.idle":"2020-09-12T00:35:44.297652Z","shell.execute_reply":"2020-09-12T00:35:44.296797Z"},"papermill":{"duration":11.291507,"end_time":"2020-09-12T00:35:44.297799","exception":false,"start_time":"2020-09-12T00:35:33.006292","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext nb_black","metadata":{"execution":{"iopub.execute_input":"2020-09-12T00:35:44.368815Z","iopub.status.busy":"2020-09-12T00:35:44.368006Z","iopub.status.idle":"2020-09-12T00:35:44.665165Z","shell.execute_reply":"2020-09-12T00:35:44.66571Z"},"papermill":{"duration":0.335382,"end_time":"2020-09-12T00:35:44.665852","exception":false,"start_time":"2020-09-12T00:35:44.33047","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing dataset and Model to use SHAP library.\n\nImporting the dataset 'churn modeling' to try explain what can help or not.\n\n#### Data porfile\n- There is 10 columns;\n- No missing values;\n- Exited column is the target;\n\n#### Columns meaning\n- CreditScore: Customer score in financial context;\n- Geography: Represets the customer contry;\n- Gender: Just customer's sex;\n- Age: Just Age;\n- Tenure: How much time as customer;\n- Balance: How much money in the bank;\n- NumOfProducts: How much products the customer uses;\n- HasCrCard: Does have the customer a credit card?\n- IsActiveMember: Is the customer an active member?\n- EstimetedSalary: How much is the customer salary?\n- Exited: Client churn flag","metadata":{"papermill":{"duration":0.032057,"end_time":"2020-09-12T00:35:44.730792","exception":false,"start_time":"2020-09-12T00:35:44.698735","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\ndata = pd.read_csv(\"/kaggle/input/churn-modeling-dataset/Churn_Modelling.csv\").drop(\n    [\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1\n)\ndata.head()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-12T00:35:44.803968Z","iopub.status.busy":"2020-09-12T00:35:44.803181Z","iopub.status.idle":"2020-09-12T00:35:54.749528Z","shell.execute_reply":"2020-09-12T00:35:54.748983Z"},"papermill":{"duration":9.98641,"end_time":"2020-09-12T00:35:54.749643","exception":false,"start_time":"2020-09-12T00:35:44.763233","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data formatation\n\n- StandardScaler -> Standardize features by removing the mean and scaling to unit variance The standard score of a sample x is calculated as: z = (x - u) / s.\n\n- LabelEncoder -> Encode target labels with value between 0 and n_classes-1.\n\n- OneHotEncoder -> Encode categorical features as a one-hot numeric array.\n\n\nThe data transformation is not my focus now so I just got the work that I did in this [notebook](https://www.kaggle.com/mcarujo/churn-prediction-ann-over-under-sampling) to be use with SHAP.","metadata":{"papermill":{"duration":0.064039,"end_time":"2020-09-12T00:35:59.198158","exception":false,"start_time":"2020-09-12T00:35:59.134119","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n\nenc = OneHotEncoder(handle_unknown=\"ignore\")\nminmax_scaler = MinMaxScaler()\nlabel_encoder = LabelEncoder()\n\nX = np.concatenate(\n    (\n        ## OneHotEncoder\n        enc.fit_transform(data[[\"Geography\"]]).toarray(),\n        ## Stander Scaler\n        minmax_scaler.fit_transform(\n            data[\n                [\n                    \"CreditScore\",\n                    \"Age\",\n                    \"Tenure\",\n                    \"Balance\",\n                    \"NumOfProducts\",\n                    \"EstimatedSalary\",\n                ]\n            ]\n        ),\n        ## LabelEncoder\n        label_encoder.fit_transform(data[[\"Gender\"]]).reshape(-1, 1),\n        ## No formatation\n        data[[\"HasCrCard\", \"IsActiveMember\"]].values,\n    ),\n    axis=1,\n)\n\ny = data.Exited.values\nX.shape\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.05, random_state=42, stratify=y\n)","metadata":{"execution":{"iopub.execute_input":"2020-09-12T00:35:59.355433Z","iopub.status.busy":"2020-09-12T00:35:59.354704Z","iopub.status.idle":"2020-09-12T00:35:59.398356Z","shell.execute_reply":"2020-09-12T00:35:59.397746Z"},"papermill":{"duration":0.136038,"end_time":"2020-09-12T00:35:59.398475","exception":false,"start_time":"2020-09-12T00:35:59.262437","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Geting the name of our new columns after transformed...","metadata":{"papermill":{"duration":0.065382,"end_time":"2020-09-12T00:35:59.529972","exception":false,"start_time":"2020-09-12T00:35:59.46459","status":"completed"},"tags":[]}},{"cell_type":"code","source":"columns = (\n    [el for el in enc.categories_[0]]\n    + [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \"EstimatedSalary\",]\n    + [\"Gender\"]\n    + [\"HasCrCard\", \"IsActiveMember\"]\n    + [\"Exited\"]\n)","metadata":{"execution":{"iopub.execute_input":"2020-09-12T00:35:59.671001Z","iopub.status.busy":"2020-09-12T00:35:59.670346Z","iopub.status.idle":"2020-09-12T00:35:59.680611Z","shell.execute_reply":"2020-09-12T00:35:59.680076Z"},"papermill":{"duration":0.083402,"end_time":"2020-09-12T00:35:59.680717","exception":false,"start_time":"2020-09-12T00:35:59.597315","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation Matrix\nLooking at the correlation matrix is not so easy to how the impact of the features in the target variable, however, we can see a few of them.\n\nGermany is a country where people like to churn in this dataset.\n\n'Age' and 'Exited' have a relationship.\n\n'Balance' has a relation with 'Germany' then because this with 'Exited'.\n\n'France' and 'EstimatedSalary' have a relation with 'Exited' too.","metadata":{"papermill":{"duration":0.067815,"end_time":"2020-09-12T00:35:59.815721","exception":false,"start_time":"2020-09-12T00:35:59.747906","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ntable = pd.DataFrame(np.concatenate([X, y.reshape(-1, 1)], axis=1))\ntable.columns = columns\ntable = table.corr()\nwith sns.axes_style(\"white\"):\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(10, 10))\n    sns.heatmap(\n        round(table, 2),\n        cmap=\"Reds\",\n        mask=mask,\n        vmax=table.max().max(),\n        vmin=table.min().min(),\n        linewidths=0.5,\n        annot=True,\n        annot_kws={\"size\": 12},\n    ).set_title(\"Correlation Matrix App behavior dataset\")\n\ncolumns.remove(\"Exited\")","metadata":{"execution":{"iopub.execute_input":"2020-09-12T00:35:59.959893Z","iopub.status.busy":"2020-09-12T00:35:59.952475Z","iopub.status.idle":"2020-09-12T00:36:00.953106Z","shell.execute_reply":"2020-09-12T00:36:00.952531Z"},"papermill":{"duration":1.070096,"end_time":"2020-09-12T00:36:00.953236","exception":false,"start_time":"2020-09-12T00:35:59.88314","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RandomForestClassifier\n\nIn my last notebook used an ANN, however, get a simpler model is good in this case. Random Forest, for example, is simpler than ANN and also faster. :)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n\nmodel_rfc = RandomForestClassifier()\nmodel_rfc.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just using the training dataset to fit because I would like to see how the SHAPE can explain a prediction of a data which never was seen before.\n\n# SHAP\n\nHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations).\n\n[Docs here.](https://shap.readthedocs.io/en/latest/examples.html#kernel-explainer)\n\n\nJust taking one sample of our test dataset to be predicted and explained.\n","metadata":{}},{"cell_type":"code","source":"sample = pd.DataFrame(X_test[0]).T\nsample.columns = columns\nsample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explainer, who should explain what happens here.\nTreeExplainer recevies your model then start to explain how works your model. There are similars Explainers...\n- [TreeExplainer](https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html#shap.TreeExplainer) -> Uses Tree SHAP algorithms to explain the output of ensemble tree models.\n- [Kernel Explainer](https://shap.readthedocs.io/en/latest/generated/shap.KernelExplainer.html#shap.KernelExplainer) -> Uses the Kernel SHAP method to explain the output of any function.\n- [Deep Explainer](https://shap.readthedocs.io/en/latest/generated/shap.DeepExplainer.html#shap.DeepExplainer) -> Meant to approximate SHAP values for deep learning models.\n- [Gradient Explainer](https://shap.readthedocs.io/en/latest/generated/shap.GradientExplainer.html#shap.GradientExplainer) -> Explains a model using expected gradients (an extension of integrated gradients).\n- [Linear Explainer](https://shap.readthedocs.io/en/latest/generated/shap.LinearExplainer.html#shap.LinearExplainer) -> Computes SHAP values for a linear model, optionally accounting for inter-feature correlations.\n- [Partition Explainer](https://shap.readthedocs.io/en/latest/generated/shap.PartitionExplainer.html#shap.PartitionExplainer) -> Uses the Partition SHAP method to explain the output of any function.","metadata":{}},{"cell_type":"code","source":"import shap\n\nshap.initjs()  # Just to create better graphs =D\nexplainer = shap.TreeExplainer(model_rfc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For me 'explainer' is a variable which is able to explain a prediction, in an informal way, is just that. \n\nJust to have in mind the model prediction on the next cell.","metadata":{}},{"cell_type":"code","source":"prediction = model_rfc.predict_proba(sample)\nprint(\"Direct print:\", prediction)\nprint(\n    \"Probability to be class 0:\",\n    prediction[0][0],\n    \"\\nProbability to be class 1:\",\n    prediction[0][1],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Just to image how are Model predict our sample","metadata":{}},{"cell_type":"markdown","source":"SHAP start the analisys from a 'baseline' in terms of class prediction.\n\nexpected_value return our baselines and from there we see the impact of our features.\n> This is the reference value that the feature contributions start from. For SHAP values it should\n> be the value of explainer.expected_value. \n> \n[Docs here.](https://github.com/slundberg/shap/blob/06c9d18f3dd014e9ed037a084f48bfaf1bc8f75a/shap/plots/force.py#L31)","metadata":{}},{"cell_type":"code","source":"print(explainer.expected_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The expected_value is an array with 2 floats: where the size of the array means our classes 0 and 1 (binary) and the float number itself means the probability of class N.\n#### JUST A OPINION\n> In my point of view, the baseline for the SHAP is strongly influenced by the bias in your model. Carujo.","metadata":{}},{"cell_type":"code","source":"print(\"How is the target balance?\", y_train.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I wanna know about the sample...\nNow let just se how we can 'understand' a prediction of a sample","metadata":{}},{"cell_type":"code","source":"shap_values = explainer.shap_values(sample.loc[0])\nshap_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I mean in a familiar way to understand....","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(shap_values, columns=columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### BaseLine + Contribuitions = Probability Predicted","metadata":{}},{"cell_type":"code","source":"print(\"Direct prediction:\", prediction)\naux = shap_values[0].sum() + explainer.expected_value[0]\nprint(\"Sum of Baseline + Feature Contribuitions:\", aux)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot possibilities\n\n#### Probability to be class 0\n","metadata":{}},{"cell_type":"code","source":"shap.force_plot(explainer.expected_value[0], shap_values[0], sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Probability to be class 1","metadata":{}},{"cell_type":"code","source":"shap.force_plot(explainer.expected_value[1], shap_values[1], sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Think about to put in production\n\nWhen we train our model we also can train the SHAP to always be ready to exaplain as you need predict.","metadata":{}},{"cell_type":"code","source":"import shap\nimport pandas as pd\nimport numpy as np\n\n\n# Train your shap to understand your model\ndef explain_train(model):\n    return shap.TreeExplainer(model)\n\n\n# Here you pass the return of the last function and also the dataframe with the columns model\ndef explain_this(explainer, sample):\n    columns = sample.columns\n    shap_values = explainer.shap_values(sample.iloc[0])\n    aux = pd.DataFrame(shap_values, columns=columns)\n    aux[\"_BASELINE\"] = explainer.expected_value\n    aux[\"_CLASSES\"] = explainer.expected_value\n    return aux","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = explain_train(model_rfc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values = explain_this(explainer, sample)\nshap_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Going to the [documentations](https://github.com/slundberg/shap) you can see so many types of graphs that you can use and explore to help you in your work. \n\nI strongly recommend you go there and check the options.","metadata":{}}]}