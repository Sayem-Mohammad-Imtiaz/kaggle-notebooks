{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importando os módulos necessários\nimport pandas as pd\nimport datetime\nimport time\nimport nltk\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.ai.textanalytics import TextAnalyticsClient\nfrom leia import SentimentIntensityAnalyzer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom pandas_profiling import ProfileReport\nfrom textblob import TextBlob\nnltk.download('vader_lexicon')\n\n# Carregando o arquivo .CSV\ndfnoticias = pd.read_csv(r'Historico_de_materias.csv')\n\n# Criando um objeto para extrair o perfil dos dados\nperfil = ProfileReport(\n    dfnoticias,\n    title='Perfil dos dados',\n    html={\n        'style': {\n            'full_width': True}})\n\n# Exibindo o perfil dos dados brutos\nperfil.to_file(output_file=\"dadosbrutos.html\")\n\n# Remove alguns caracteres especiais nos textos\ndfnoticias.replace(to_replace=r'[\\n\\r\\t]', value='', regex=True, inplace=True)\n\n# Remove as linhas duplicadas\ndfnoticias.drop_duplicates(subset=['titulo'], keep='first', inplace=True)\ndfnoticias.drop_duplicates(\n    subset=['conteudo_noticia'],\n    keep='first',\n    inplace=True)\n\n# Remove as linhas com conteúdo vazio\ndfnoticias.replace(\"\", float(\"NaN\"), inplace=True)\ndfnoticias.dropna().empty\ndfnoticias.drop(dfnoticias[dfnoticias['data'].isnull()].index, inplace=True)\ndfnoticias.drop(\n    dfnoticias[dfnoticias['conteudo_noticia'].isnull()].index, inplace=True)\n\n# Convertendo o objeto para data\ndfnoticias['data_convertida'] = pd.to_datetime(dfnoticias['data'])\n\n# Alterando a máscara de visualização da data para dia/mês/ano\ndfnoticias['data_convertida'].apply(lambda x: x.strftime('%d/%m/%Y'))\n\n# Atualiza o índice\ndfnoticias.reset_index(drop=True, inplace=True)\n\n# Verificando a quantidade de registros após a limpeza\nlen(dfnoticias)\n\n# Criando um objeto para extrair o perfil dos dados após a remoção da sujeira\nperfil = ProfileReport(\n    dfnoticias,\n    title='Perfil dos dados',\n    html={\n        'style': {\n            'full_width': True}})\n\n# Gera um arquivo HTML com o perfil dos dados depois da remoção da sujeira\nperfil.to_file(output_file=\"limpo.html\")\n\n# Configurando o endereço da API dos serviços cognitivos do Azure\nendpoint = ''\nkey = ''\n\n# Executando a autenticação no Azure\ndef authenticate_client():\n    ta_credential = AzureKeyCredential(key)\n    text_analytics_client = TextAnalyticsClient(\n        endpoint=endpoint, credential=ta_credential)\n    return text_analytics_client\n\nclient = authenticate_client()\n\n# Criando uma função que consome a API do Azure e retorna valores\n# relacionados à análise de sentimentos\ndef sentiment_analysis(client, doc):\n    documents = [doc]\n    response = client.analyze_sentiment(documents=documents)[0]\n    return response\n\n# Função para extrair a polaridade do texto consumido pela API do Azure\ndef sentiment_label(text):\n    try:\n        return sentiment_analysis(client, text).sentiment\n    except BaseException:\n        return None\n\n# Rodando a função de classificação do texto\ndfnoticias['polaridade_azure_titulo'] = dfnoticias['titulo'].apply(\n    sentiment_label)\ndfnoticias['polaridade_azure_noticia'] = dfnoticias['conteudo_noticia'].apply(\n    sentiment_label)\n\n# Criando as colunas vazias que armazenarão os textos traduzidos\ndfnoticias['content'] = ''\ndfnoticias['title'] = ''\n\n# Traduzindo a coluna de assuntos\nfor index, row in (dfnoticias.iterrows()):\n    if dfnoticias.at[index, str(\n            'title')] == '':  # verifica se a tradução foi feita\n        # armazena o texto em português que será traduzido\n        translation = TextBlob(dfnoticias.iloc[index]['titulo'])\n        # usa a API do Google para fazer a tradução\n        en_blob = translation.translate(from_lang='pt', to='en')\n        # essa pausa é obrigatória para evitar o bloqueio do IP por excesso de\n        # uso\n        time.sleep(0.25)\n        dfnoticias.at[index, str('title')] = str(\n            en_blob)  # grava o texto traduzido\n\n# Traduzindo a coluna de notícias\nfor index, row in (dfnoticias.iterrows()):\n    if dfnoticias.at[index, str(\n            'content')] == '':  # verifica se a tradução foi feita\n        # armazena o texto em português que será traduzido\n        translation = TextBlob(dfnoticias.iloc[index]['conteudo_noticia'])\n        # usa a API do Google para fazer a tradução\n        en_blob = translation.translate(from_lang='pt', to='en')\n        # essa pausa é obrigatória para evitar o bloqueio do IP por excesso de\n        # uso\n        time.sleep(0.25)\n        dfnoticias.at[index, str('content')] = str(\n            en_blob)  # grava o texto traduzido\n\n# Função para trazer os valores de polaridade e subjetividade de um texto\n# usando TextBlob\ndef sentiment_calc_textblob(text):\n    try:\n        return TextBlob(text).sentiment\n    except BaseException:\n        return None\n\n# Extraindo a pontuação de sentimento das colunas de assunto e notícias (traduzidos\n# para o inglês)\ndfnoticias['pontuacao_titulo'] = dfnoticias['title'].apply(\n    sentiment_calc_textblob)\ndfnoticias['pontuacao_noticia'] = dfnoticias['content'].apply(\n    sentiment_calc_textblob)\n\n# Colocando os valores de polaridade e subjetividade em suas respectivas\n# colunas\ndfnoticias[['textblob_titulo', 'subjetividade_textblob_titulo']] = pd.DataFrame(\n    dfnoticias.pontuacao_titulo.tolist(), index=dfnoticias.index)\ndfnoticias[['textblob_noticia', 'subjetividade_textblob_noticia']] = pd.DataFrame(\n    dfnoticias.pontuacao_noticia.tolist(), index=dfnoticias.index)\n\n# Remove as colunas de pontuação, uma vez que já são desnecessárias\ndfnoticias.drop(\n    columns=[\n        'pontuacao_titulo',\n        'pontuacao_noticia'],\n    inplace=True)\n\n# Cria uma instância da função de análise de sentimento usando NTLK/VADER\nsid = SentimentIntensityAnalyzer()\n\n# Função para trazer os valores de polaridade e subjetividade de um texto\n# usando NTLK/VADER\ndef sentiment_calc_vader(text):\n    try:\n        ss = sid.polarity_scores(text)['compound']\n        return ss\n    except BaseException:\n        return None\n\n# Extraindo a pontuação de sentimento das colunas de assunto e notícias (traduzidos para o\n# inglês)\ndfnoticias['vader_en_titulo'] = dfnoticias['title'].apply(\n    sentiment_calc_vader)\ndfnoticias['vader_en_noticia'] = dfnoticias['content'].apply(\n    sentiment_calc_vader)\n\n# Carregando o módulo de análise de sentimento da biblioteca LeIA\ns = SentimentIntensityAnalyzer()\n\n# Função para trazer os valores de polaridade e subjetividade de um texto\n# usando LeIA\ndef sentiment_calc_leia(text):\n    try:\n        ss = s.polarity_scores(text)['compound']\n        return ss\n    except BaseException:\n        return None\n\n# Extraindo a pontuação de sentimento das colunas de assunto e notícias em\n# português\ndfnoticias['vader_pt_titulo'] = dfnoticias['titulo'].apply(\n    sentiment_calc_leia)\ndfnoticias['vader_pt_noticia'] = dfnoticias['conteudo_noticia'].apply(\n    sentiment_calc_leia)\n\n# Selecionando as colunas relevantes antes de exportá-las para um arquivo\n# CSV.\ndfnoticias = dfnoticias[['data_convertida',\n                         'url_noticia',\n                         'url_noticia_curto',\n                         'assunto',\n                         'titulo',\n                         'conteudo_noticia',\n                         'title',\n                         'content',\n                         'polaridade_azure_titulo',\n                         'polaridade_azure_noticia',\n                         'textblob_titulo',\n                         'textblob_noticia',\n                         'vader_en_titulo',\n                         'vader_en_noticia',\n                         'vader_pt_titulo',\n                         'vader_pt_noticia']]\n\n# Exportando as classificações para um arquivo .CSV.\ndfnoticias.to_csv(r'resultado.csv', sep=';',\n                  index=False, decimal=',')\n\n# Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based\n# Model for Sentiment Analysis of Social Media Text. Eighth International\n# Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June\n# 2014.\n\n# @misc{Almeida2018,\n# author = {Almeida, Rafael J. A.},\n# title = {LeIA - Léxico para Inferência Adaptada},\n# year = {2018},\n# publisher = {GitHub},\n# journal = {GitHub repository},\n# howpublished = {\\url{https://github.com/rafjaa/LeIA}}\n# }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}