{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Analisis Data Penerbangan Amerika Serikat**"},{"metadata":{},"cell_type":"markdown","source":"**1. Mengimpor Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading dataset\n\ndf = pd.read_csv('../input/2008.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mengecek nilai yang hilang (NaN)\n\ndata_nan = df.isnull().sum(axis=0).reset_index()\ndata_nan.columns = ['variable', 'missing values']\ndata_nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nan['filling factor (%)'] = (df.shape[0] - data_nan['missing values'])/df.shape[0]*100.\ndata_nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nan.sort_values(by='filling factor (%)').reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Year'].map(str)+'-'+df['Month'].map(str)+'-'+df['DayofMonth'].map(str))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_tanggal (dataframe):\n    if pd.isnull(dataframe):\n        return np.nan\n    else:\n        if dataframe == 2400: dataframe = 0\n        dataframe = \"{0:04d}\".format(int(dataframe))\n        tanggal = datetime.time(int(dataframe[0:2]), int(dataframe[2:4]))\n        return tanggal\n\ndef combine_date(x):\n    if pd.isnull(x[0]) or pd.isnull(x[1]):\n        return np.nan\n    else:\n        return datetime.datetime.combine(x[0],x[1])\n\ndef create_flight_time(data, col):    \n    liste = []\n    for index, cols in data[['Date', col]].iterrows():    \n        if pd.isnull(cols[1]):\n            liste.append(np.nan)\n        elif float(cols[1]) == 2400:\n            cols[0] += datetime.timedelta(days=1)\n            cols[1] = datetime.time(0,0)\n            liste.append(combine_date(cols))\n        else:\n            cols[1] = format_tanggal(cols[1])\n            liste.append(combine_date(cols))\n    return pd.Series(liste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CRSDepTime'] = create_flight_time(df, 'CRSDepTime')\ndf['DepTime'] = df['DepTime'].apply(format_tanggal)\ndf['CRSArrTime'] = df['CRSArrTime'].apply(format_tanggal)\ndf['ArrTime'] = df['ArrTime'].apply(format_tanggal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:5, ['CRSDepTime', 'CRSArrTime', 'DepTime',\n             'ArrTime', 'DepDelay', 'ArrDelay']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mengekstrak parameter statistik dari fungsi groupby\ndef get_stats(group):\n    return {'min': group.min(), 'max': group.max(),\n            'count': group.count(), 'mean': group.mean()}\n\n# membuat dataframe dengan info statistik dari setiap pesawat\nglobal_stats = df['DepDelay'].groupby(df['UniqueCarrier']).apply(get_stats).unstack()\nglobal_stats = global_stats.sort_values('count')\nglobal_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mengelompokkan penerbangan yang mengalami delay\ndelay_type = lambda x:((0,1)[x > 5],2)[x > 45]\ndf['DelayLvl'] = df['DepDelay'].apply(delay_type)\n\nfig = plt.figure(1, figsize=(10,7))\nax = sns.countplot(y=\"UniqueCarrier\", hue='DelayLvl', data=df)\n\n# mengatur label dari plot yang akan dibuat\nplt.setp(ax.get_xticklabels(), fontsize=12, weight = 'normal', rotation = 0);\nplt.setp(ax.get_yticklabels(), fontsize=12, weight = 'bold', rotation = 0);\nax.yaxis.label.set_visible(False)\nplt.xlabel('Flight count', fontsize=16, weight = 'bold', labelpad=10)\n\n# mengatur legenda dari plot yang akan dibuat\nL = plt.legend()\nL.get_texts()[0].set_text('on time (t < 5 min)')\nL.get_texts()[1].set_text('small delay (5 < t < 45 min)')\nL.get_texts()[2].set_text('large delay (t > 45 min)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.where(df.dtypes.values == np.dtype('float64'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df.iloc[:, np.where(df.dtypes.values == np.dtype('float64'))[0]]\nnew_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(new_df.columns)):\n    if (new_df.isnull().iloc[:,i].shape[0]>0):\n        print('\\nAttribute-',i,' (before) :',new_df.isnull().iloc[:,i].shape[0])\n        new_df.iloc[:,i].fillna(new_df.iloc[:,i].mean(), inplace=True)\n        print('\\nAttribute-',i,' (after) :',new_df.isnull().iloc[:,i].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the dictionary of models our script can use\n# the key to the dictionary is the name of the model\n# (supplied via command line argument) and the value is the model itself\nmodels = {\n    \"knn\": KNeighborsClassifier(n_neighbors=1),\n    \"naive_bayes\": GaussianNB(),\n    \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n    \"svm\": SVC(kernel=\"linear\", gamma=\"auto\"),\n    \"decision_tree\": DecisionTreeClassifier(),\n    \"random_forest\": RandomForestClassifier(n_estimators=100),\n    'mlp': MLPClassifier()\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Diverted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform a training testing split, using 75% of the data for\n# training and 25% for evaluation\n(trainX, testX, trainY, testY) = train_test_split(new_df.values, df.Diverted, random_state=3, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the Random Forest model\nprint(\"[INFO] using '{}' model\".format(\"random_forest\"))\nmodel = models[\"random_forest\"]\nmodel.fit(trainX, trainY)\n# make predictions on our data and show a classification report\nprint(\"[INFO] evaluating...\")\npredictions = model.predict(testX)\nprint(classification_report(testY, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(testY, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}