{"cells":[{"metadata":{"colab_type":"raw","id":"eDFWtk9W7NZI"},"cell_type":"markdown","source":"Autores: \n- Adauto Donizetti de Paula\n- Aline Regina de Oliveira\n- Antonio Luciano Lopes Uliana"},{"metadata":{"colab_type":"text","id":"jBKEX8zV7NZL"},"cell_type":"markdown","source":"# Introdução"},{"metadata":{"colab_type":"text","id":"oC_IFpwy7NZM"},"cell_type":"markdown","source":"Recentemente, a quantidade de dados produzidos dentro de empresas, universidades, comércio e no mercado tem ganhado grande relevância, tanto pela quantidade de dados produzidos devido ao fácil compartilhamento, envio e recebimento, quanto pela necessidade de entender esses dados e transformá-los em informação útil para apoio na tomada de decisão dentro dessas entidades. Nesse processo de compreensão dos dados, existem téncias denonminadas mineração de dados, que visam explorar grandes quantidades de dados com o intuito de encontrar padrões relevantes e consistentes no relacionamento entre os atributos (basicamente, colunas de tabelas) dessas bases de dados. \n\nUma das primeiras técnicas desenvolvidas nesse sentido foi o  KDD (em inglês, *Knowledge Discovery in Database*), desenvolvido durante o final da década de 1980. A extração de conhecimento a partir de uma base de dados é dividida em fases: coleta de dados -> tratamento dos dados -> resultado final (transformação dos dados em informações e posteriormente em conhecimento).\n\nO processo KDD foi constituído visando automatizar o processo de extração de conhecimento a partir de uma grande base de dados. É um processo iterativo, isto é, cada etapa pode ser repetida até que se tenham os resultados satisfatórios. \n\nAs etapas do KDD, segundo Fayyad et al (1996) são as seguintes:\n\n- Seleção: é a etapa de agrupamento dos dados de modo organizado. É uma etapa muito importante, pois é nela que serão decididos quais os conjuntos de dados que serão relevantes para que sejam obtidos resultados com informações uteis.\n- \tPré-processamento: neste momento os dados passam por uma adequação. Ao final do processo, devem possuir o formato correto e não apresentar duplicidade, entre outras características. Consiste numa a limpeza dos dados e seleção de atributos. Nesta etapa, informações ausentes, errôneas ou inconsistentes nas bases de dados devem ser corrigidas de forma a não comprometer a qualidade dos modelos de conhecimento a serem extraídos ao final do processo de KDD.\n-\tTransformação: é a etapa de armazenamento dos dados de forma a facilitar o uso das técnicas de Data Mining. Esta etapa analisa os dados obtidos na etapa anterior e os reorganiza de uma forma especifica para que possam ser interpretados na etapa seguinte.\n-\tMineração de Dados: é a principal atividade do processo de descoberta do conhecimento. Nesta fase  são aplicados algoritmos de descoberta de padrões. A mineração faz com que meros dados sejam transformados em informações.\n-\tInterpretação e avaliação: esta fase consiste em interpretar os dados gerados e verificar se possuem alguma validade para o problema proposto. Esta é a fase na qual as regras indicadas pelo processo anterior serão interpretadas e avaliadas. Após a interpretação poderão surgir padrões, relacionamentos e descoberta de novos fatos, que podem ser utilizados para pesquisas, otimização e outros.\n\nNeste trabalho, pode-se entender as fases do KDD para uma base de dados na qual existe uma série de atributos de análise de imagens de células na região do câncer feitos com ultrassonografia para prever se um câncer de mama é benigno ou malígno. Basicamente, os tumores benignos são constituídos por células bem semelhantes às que os originaram e não possuem a capacidade de provocar metástases. Já os malignos são agressivos e possuem a capacidade de infiltrar outros órgãos.\nFonte: https://www.einstein.br/noticias/noticia/cancer-benigno-maligno\n\nApós a extração dos dados da plataforma Kaggle (www.kaggle.com) foi realizado um pré-processamento para garantir que os dados lidos e interpretados sejam relevantes para o processo de extração de conhecimento. Após isso, foi implementada a transformação dos dados em si, através do algoritmo KNN. Por fim, foram feitas as previsões a partir de novos dados, isto é, após o aprendizado realizado pelo algoritmo KNN sobre a base de dados, novas entradas de dados buscaram classificar se uma nova entrada de fotos de células seria um câncer beingno ou maligno, baseado no aprendizado anterior. Foi traçada uma avaliação para essas previsões, de modo a se obter uma acurácia e concluir se o modelo contruído é bom ou ruim nas suas previsões.\n\n\nCada classificação foi calculada a partir de uma imagens digitalizadas de uma região de células afetadas nas glândulas mamárias. Essas imagens descrevem características dos núcleos celulares presentes e das células.\n\nAs seguintes seções desse trabalho se referem às etapas do KDD e a conclusão do trabalho:\n- Seleção dos dados, \n- Pré-processamento , \n- Transformação, \n- Mineração de Dados, \n- Avaliação (do modelo),\n- Conclusão\n"},{"metadata":{"colab_type":"text","id":"nKHkTsri7NZM"},"cell_type":"markdown","source":"# Seleção dos Dados"},{"metadata":{"colab_type":"text","id":"X440QNVO7NZN"},"cell_type":"markdown","source":"A fase de seleção dos dados é a primeira no processo de descoberta do conhecimento nas atividades de *machine learning* e ciências dos dados.\nNesta fase é escolhido o conjunto de dados contendo todas as possíveis variáveis, também chamadas de características ou atributos, que farão parte da análise.\nA etapa de seleção possui impacto significante sobre a qualidade do resultado do processo.\n\nOs dados que iremos utilizar pertencem a uma base de dados sobre diagnóstico de câncer de mama disponível na plataforma Kaggle . (https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"ip6cTtcA7NZO","outputId":"e314e1c8-1e00-461b-f868-a727f7385f90","trusted":false},"cell_type":"code","source":"# Carregar as bibliotecas necessárias: \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score \nimport sklearn.metrics\n\n\n# Carregar a base de dados:\nrout_path = \"../input/data.csv\"\ndados = pd.read_csv(rout_path)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"Qkn9GMez7NZS"},"cell_type":"markdown","source":"# Pré-processamento "},{"metadata":{"colab_type":"text","id":"JR9qUAOG7NZS"},"cell_type":"markdown","source":"A etapa de pre-processamento é crucial no processo, pois a qualidade dos dados vai determinar a eficiência dos algoritmos de mineração.\nNesta etapa são realizadas tarefas que eliminam dados redundantes e inconsistentes, recuperem dados incompletos e avaliam possíveis dados discrepantes ao conjunto (*outliers*). \nNesta etapa também são utilizados métodos de redução ou transformação para diminuir o número\nde variáveis envolvidas no processo, visando com isto melhorar o desempenho do algoritmo que será usado na análise dos dados.\n\n"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"colab_type":"code","id":"wcQUCXqi7NZT","outputId":"bc5e125e-3778-4a35-bc90-f1baa449b820","trusted":false},"cell_type":"code","source":"# Mostrar detalhes dos 5 primeiros registros da base:\n\ndados.head() ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"kS1eDPBi7NZZ"},"cell_type":"markdown","source":"A seguir, a classe objetivo, no caso a coluna \"diagnosis\", é separada dos demais atributos, que são efetivamente os dados que serão analisados\n\nTambém são removidas as colunas com informações que não são relevantes: 'id' (número de identificação do registro) e 'Unnamed: 32' (coluna com valor faltante para todos os registros).\n\nNos parâmetros exibidos a seguir, é notória a diferença entre os valores absolutos de alguns atributos, como por exemplo o valor da área e o valor da concavidade. Desse modo, para algumas exibições gráficas nas seções adiante, será necessária a normalização dos dados."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"colab_type":"code","id":"t50g-YrG7NZa","outputId":"7c125407-95dc-4457-8358-a159ec33368e","trusted":false},"cell_type":"code","source":"# Colocar no vetor Y os valores da classe objetivo\n\nY = dados.diagnosis                         \n\n\n# Fazer a remoção das colunas desnecessárias\n\nlist = ['Unnamed: 32','id','diagnosis']        # lista com as colunas a serem removidas\nX = dados.drop(list,axis = 1 )          \nX.head()\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"wuW51rWtJfqO"},"cell_type":"markdown","source":"## Visualização\n"},{"metadata":{"colab_type":"text","id":"1Z43YOdiJqoK"},"cell_type":"markdown","source":"Para visualizar os dados será utilizada a biblioteca seaborn para plotar graficos úteis para compreensão das informações a respeito dos atributos da base de dados.\n"},{"metadata":{"colab_type":"text","id":"0XKRqiX2KiwG"},"cell_type":"markdown","source":"### Número total de registros para cada classe \n\n\n"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"colab_type":"code","id":"eJeNwxB47NZg","outputId":"583502ff-397d-4055-ae09-5814c15238d1","trusted":false},"cell_type":"code","source":"ax = sns.countplot(Y,label=\"Quantidade\")       # M = 212, B = 357\nB, M = Y.value_counts()\nprint('Quantidade de Benignos: ',B)\nprint('Quantidade de Malignos: ',M)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"_JamFxBi7NZk"},"cell_type":"markdown","source":"### Ver como os dados se comportam"},{"metadata":{"colab_type":"text","id":"MjTwbOF87NZl"},"cell_type":"markdown","source":"Para uma melhor compreensão dos dados podemos observar como eles se comportam. \nApós a execução a primeira tabela a seguir mostrará os seguintes dados estatísticos sobre os dados:\nsoma, média, desvio padrão, valor 25% 50%(mediana) e 75% , máximo e mínimo ."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"colab_type":"code","id":"KIPkWnOF7NZl","outputId":"79a6b708-afc7-43a1-f91d-c196c81a6269","trusted":false},"cell_type":"code","source":"# mostra soma, média , desvio padrão, min, max, valor dos 25%, 50%(mediana) e 75%\n\nX.describe() ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"RaNztHdUq8GS"},"cell_type":"markdown","source":"### Explicação dos atributos\n\nOs atributos são divididos em três grupos: Mean, SE e Worst.\n\n> Mean: média de todas as células;\n\n> SE: *Standard Error* (erro padrão de todas as células);\n\n> Worst: média dos três piores valores medidos das células. Na verdade, é considerado \"pior\" porque são medidas indicativas de células não saudáveis; na realidade o \"pior\" significa os maiores valores medidos para raio, perímetro, textura etc.\n\nCada grupo tem 10 atributos: \n- radius (raio da célula)\n- texture (textura da célula - medida pelo desvio padrão de escalas de cinza, que ajudam a indicar se a célula é saudável ou não)\n-\tperimeter (perímetro)\n-\tarea (área)\n-\tsmoothness (variação local em comprimentos de raio)\n- compactness (campactude = perimetro²/area - 1)\n- concavity (gravidade das porções côncavas das células)\n- concave points (número de porções côncavas no contorno da célula),\n- symmetry (simetria) \n- fractal_dimension (dimensão fractal). \n\n\n\n"},{"metadata":{"colab_type":"text","id":"TWFoV9eo7NZq"},"cell_type":"markdown","source":"\n## **Mapa de calor para os dados limpos**\n\nNo mapa de calor é feita uma regressão linear de todos os atributos combinados 2 a 2, e o valor que aparece nas células do mapa de calor são os coeficientes angulares de um atributo em relação ao outro, resultante da regressão linear. \nPara exemplificar, o valor que aparece nas células da diagonal principal, é o coeficiente angular de um atributo em relação a ele mesmo, logo o valor é 1. Se o coefiente angular é positivo, significa que quando o atributo do eixo horizontal cresce, o atributo do eixo vertical também cresce com taxa de variação igual ao valor do coeficiente angular. Se o coeficiente angular é negativo,  significa que quando o atributo do eixo horizontal cresce, o do eixo vertical  decresce com taxa de variação igual ao módulo do coeficiente angular. Por fim, caso o coeficiente seja zero, significa que as duas variáveis não dependem linearmente uma da outra. Nesses casos pode existir uma dependência não-linear, que seria necessário investigá-la por outros meios. \n\n\n\n"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"pm6qxLIu7NZr","outputId":"441dbdf5-6e82-4580-b07f-76f849ad3978","trusted":false},"cell_type":"code","source":"# Mostrar mapa de calor \n\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(X.corr(), annot=True, fmt= '.1f', cmap ='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"j2KKAK_IZQvw"},"cell_type":"markdown","source":"Para melhor visualizar o mapa de calor, foram separados os grupos Mean, SE e Worst.\n\nA ideia do heatmap aqui é entender como os atributos se relacionam. Caso tenham grande correlação, é um indicativo de multicolinearidade, que pode levar a resultados distorcidos. Existem várias maneiras de lidar com esse problema, como por exemplo o uso de PCA (*Principal Component Analysis*). Contudo, a abordagem utilizada será mais simples, que é a de simplesmente escolher um dos atributos para manter na base e eliminar os outros que tenham alta correlação com ele. \n\nPS: algoritmos que usam ávores de decisão evitam problemas de multicolinearidade naturalmente em sua implementação."},{"metadata":{"colab_type":"text","id":"7MSdeN0waZ16"},"cell_type":"markdown","source":"A decisão de implementação foi de deletar os atributos com correlação maior ou igual a 0.9."},{"metadata":{"colab":{},"colab_type":"code","id":"MU0NEyIBlhYC","trusted":false},"cell_type":"code","source":"droplist_se_worst = ['radius_se', \t'texture_se',\t'perimeter_se',\t'area_se',\t'smoothness_se',\t'compactness_se',\t'concavity_se',\t'concave points_se',\t'symmetry_se',\t'fractal_dimension_se', 'radius_worst',\t'texture_worst',\t'perimeter_worst',\t'area_worst',\t'smoothness_worst',\t'compactness_worst',\t'concavity_worst',\t'concave points_worst',\t'symmetry_worst',\t'fractal_dimension_worst']\n\nsomente_mean = X.drop(droplist_se_worst, axis = 1)\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(somente_mean.corr(), annot=True, linewidths=.5, fmt= '.3f', cmap ='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"xbqP5LKNaxHv"},"cell_type":"markdown","source":"- Os atributos radius_mean, perimeter_mean e\tarea_mean possuem correlação acima de 0.9, então iremos remover os atributos radius_mean e perimeter_mean (escolha arbitrária)\n- Os atributos concavity_mean e concave points_mean possuem correlação acima de 0.9, então iremos remover o atributo concavity_mean (escolha arbitrária)\n\nPortanto, nesse primeiro grupo, os atributos que continuarão serão: area_mean, texture_mean, smoothness_mean, compactness_mean, concave points_mean, symmetry_mean e fractal_dimension_mean\n\n"},{"metadata":{"colab":{},"colab_type":"code","id":"aNBwZsuIkfjY","trusted":false},"cell_type":"code","source":"droplist_mean_worst = ['radius_mean', 'texture_mean',\t'perimeter_mean',\t'area_mean', \t'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean',\t'symmetry_mean',\t'fractal_dimension_mean', 'radius_worst',\t'texture_worst',\t'perimeter_worst',\t'area_worst',\t'smoothness_worst',\t'compactness_worst',\t'concavity_worst',\t'concave points_worst',\t'symmetry_worst',\t'fractal_dimension_worst']\n\nsomente_se = X.drop(droplist_mean_worst, axis = 1)\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(somente_se.corr(), annot=True, linewidths=.5, fmt= '.3f', cmap ='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"s8iidRUcdcpf"},"cell_type":"markdown","source":"- Os atributos radius_se, perimeter_se e  area_se possuem correlação acima de 0.9, então iremos remover os atributos perímetro e raio (escolha arbitrária)\n\nPortanto, nesse segundo grupo, os atributos que continuarão serão: area_se, texture_se, smoothness_se, compactness_se, concavity_se, concave points_se, symmetry_se e fractal_dimension_se"},{"metadata":{"colab":{},"colab_type":"code","id":"lueVJGc3lJnm","trusted":false},"cell_type":"code","source":"droplist_mean_se = ['radius_mean', 'texture_mean',\t'perimeter_mean',\t'area_mean', \t'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean',\t'symmetry_mean',\t'fractal_dimension_mean', 'radius_se', \t'texture_se',\t'perimeter_se',\t'area_se',\t'smoothness_se',\t'compactness_se',\t'concavity_se',\t'concave points_se',\t'symmetry_se',\t'fractal_dimension_se']\n\nsomente_worst = X.drop(droplist_mean_se, axis = 1)\nf,ax = plt.subplots(figsize=(10, 10))\n\n\nsns.heatmap(somente_worst.corr(), annot=True, linewidths=.5, fmt= '.3f', cmap ='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"JUMCwm0SeneO"},"cell_type":"markdown","source":"- Os atributos radius_worst, perimeter_worst e  area_worst possuem correlação acima de 0.9, então iremos remover os atributos perímetro e raio (escolha arbitrária)\n\nPortanto, nesse primeiro terceiro, os atributos que continuarão serão: area_worst, texture_worst, smoothness_worst, compactness_worst, concavity_worst, concave points_worst, symmetry_worst e fractal_dimension_worst"},{"metadata":{"colab_type":"text","id":"gSnmUyp2VBIL"},"cell_type":"markdown","source":"## **Plotagem de Violino**"},{"metadata":{"colab_type":"text","id":"6k_jiy7UPeD7"},"cell_type":"markdown","source":"A plotagem de violino nos mostra a distribuição dos dados de acordo com cada classe e cada atributo. Para cada atributo à esquerda do eixo é apresentada a distribuição dos dados para a classe Maligno,  e à direita a distribuição para a classe Benigno.\n\nAtravés da observação da plotagem de violino podemos inferir que os atributos area_mean , concave points_mean, area_se, area_worst, concavity_worst e concave points_worst são bons atributos para a separação das classes, visto que a distribuição dos dados das classes é bem distinto. "},{"metadata":{"colab":{},"colab_type":"code","id":"EevQph-G7NZy","trusted":false},"cell_type":"code","source":"droplist_final = ['radius_mean', \t'perimeter_mean',\t'concavity_mean',\t'radius_se', \t'perimeter_se',\t'radius_worst',\t'perimeter_worst']\n\n\ndata_dia = Y\ndata = X.drop(droplist_final, axis = 1)                     #retirada de atributos \ndata_n_2 = (data - data.mean()) / (data.std())              # normalização\ndata = pd.concat([Y,data_n_2],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"Atributos\",\n                    value_name='Valores')\nplt.figure(figsize=(15,15))\nsns.violinplot(x=\"Atributos\", y=\"Valores\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"RYK3Lrv-VU_z"},"cell_type":"markdown","source":"## **Gráfico de pares de atributos**"},{"metadata":{"colab_type":"text","id":"49slMbPq7NZ3"},"cell_type":"markdown","source":"Os gráficos abaixo mostram as correlações entre os atributos (*mean, se* e *worst*) e as classes. \n\nObservando os gráficos da diagonal principal (histogramas referente à distribuição dos dados de acordo com o atributo em si) podemos inferir que os atributos area_mean ,  concave points_mean , area_se , concave points_worst e area_worst são bons atributos para a separação das classes, visto que a distribuição dos dados das classes é bem distinto.\n"},{"metadata":{"colab":{},"colab_type":"code","id":"XMslgFT0Rfj2","trusted":false},"cell_type":"code","source":"# Mostrar correlação entre classes e atributos 'mean'\nsns.pairplot(dados, kind=\"scatter\", diag_kind=\"hist\", hue=\"diagnosis\" ,  markers=[\"o\", \"D\"], vars=[\"area_mean\", \"texture_mean\", \"smoothness_mean\", \"compactness_mean\", \"concave points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\"] ) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"k9d0HlZpSP9_","trusted":false},"cell_type":"code","source":"# Mostrar correlação entre classes e atributos 'se'\nsns.pairplot(dados, kind=\"scatter\", diag_kind=\"hist\", hue=\"diagnosis\" ,  markers=[\"o\", \"D\"], vars=[\"area_se\", \"texture_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\"] ) \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"L1eP86p4SYoN","trusted":false},"cell_type":"code","source":"# Mostrar correlação entre classes e atributos 'worst'\nsns.pairplot(dados, kind=\"scatter\", diag_kind=\"hist\", hue=\"diagnosis\" ,  markers=[\"o\", \"D\"], vars=[\"area_worst\", \"texture_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\" , \"fractal_dimension_worst\"] ) \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"30exUteh7NZ8"},"cell_type":"markdown","source":"# Transformação"},{"metadata":{"colab_type":"text","id":"BBIB7xzQ7NZ9"},"cell_type":"markdown","source":"Transformação é a etapa de armazenamento dos dados de forma a facilitar o uso das técnicas de Data Mining. \n\nNessa etapa nos separamos a base de dados em duas partes: \n- Treino : dados que serão usados para treinar o modelo.\n- Teste : dados que serão usados para calcular a qualidade do modelo gerado."},{"metadata":{"colab":{},"colab_type":"code","id":"RJkyCZSi7NZ-","trusted":false},"cell_type":"code","source":"# Remoção dos atributos que tinham alta correlação\n\ndroplist_final = ['radius_mean', \t'perimeter_mean',\t'concavity_mean',\t'radius_se', \t'perimeter_se',\t'radius_worst',\t'perimeter_worst']\n\ndata = X.drop(droplist_final, axis = 1)                     #retirada de atributos \n\n\n# Separar dados em Treino e Teste \n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=10) # random_state=10 foi mantido para questão de REPRODUCIBILIDADE. (Separar os dados da mesma forma independente da execução). \n\nprint('Quantidade de registros para treino: ', x_train.shape[0]) \nprint('Quantidade de registros para teste: ',x_test.shape[0]) #qtd de registros para teste\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"gDM_vs7s7NaB"},"cell_type":"markdown","source":"# Mineração de Dados"},{"metadata":{"colab_type":"text","id":"4K9xaXpH7NaC"},"cell_type":"markdown","source":"*Data mining* é a principal atividade do conhecimento, aplicando, para este fim, algoritmos de descoberta de padrões.\nIremos fazer uso do algoritmo KNN (do inglês,  *K-nearest neighbor*),  que determina a classe(o rótulo de classificação)  de uma amostra baseado nas k amostras vizinhas mais próximas advindas de um conjunto de treinamento."},{"metadata":{"colab_type":"text","id":"f1GaYXyn7NaY"},"cell_type":"markdown","source":"Para fazer a escolha do K ideal calculamos a acurácia para k de 1 até 15 com *cross validation*.\n> ***Cross Validation*** (validação cruzada) é o particionamento do conjunto de dados em subconjuntos mutualmente exclusivos, e posteriormente, utiliza-se alguns destes subconjuntos para a estimação dos parâmetros do modelo (dados de treinamento) e o restante dos subconjuntos (dados de validação ou de teste) são empregados na validação do modelo."},{"metadata":{"colab":{},"colab_type":"code","id":"kT9KXi6H7Naa","trusted":false},"cell_type":"code","source":"# Calcular a acurácia para K de 1 a 15 utilizando Cross Validation\ntr_acc = []\nk_set = range(1,15)\n\nfor n_neighbors in k_set:\n  knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n  scores = cross_val_score(knn, x_train, y_train, cv=10) #testa eficacia com cross validation na base de treinamento\n  tr_acc.append(scores.mean())\n  \nbest_k = np.argmax(tr_acc) #retorna o indice do maior\nprint('Melhor k no treinamento com Cross Validation: ', k_set[best_k]) #mostra melhor k do treinamento com cross validation","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"FLvjThVD7Nae"},"cell_type":"markdown","source":" Depois calculamos a acurácia para  cada k de 1 até 15 aplicando o modelo nos dados de treinamento e fazendo o teste com os dados de teste. \n"},{"metadata":{"colab":{},"colab_type":"code","id":"6s_9LxWs7Naf","trusted":false},"cell_type":"code","source":"te_acc = []\nk_set = range(1,15)\n\nfor n_neighbors in k_set:\n  knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n  knn.fit(x_train, y_train)\n  y_pred = knn.predict(x_test) #aplica x_test no modelo\n  te_acc.append(sklearn.metrics.accuracy_score(y_test, y_pred)) #compara y_test com y_pred\n    \nmelhor_k =np.argmax(te_acc)\nprint('Melhor k nos testes: ', k_set[melhor_k]) #melhor k do treinamento normal + teste","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"pR6qqfie7Nal"},"cell_type":"markdown","source":"\nA seguir é mostrado um gráfico para comparar a acurácia de cada valor de K no treino e no teste."},{"metadata":{"colab":{},"colab_type":"code","id":"n8yP3ifC7Nam","trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(k_set,tr_acc, label='Treino')\nplt.plot(k_set,te_acc, label='Teste')\nplt.ylabel('Acurácia')\nplt.xlabel('k')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"y2mmbmtb7Nao"},"cell_type":"markdown","source":"Assim assumiremos que o melhor K para esse modelo é 7, pois o treino apresenta sua maior acurácia. "},{"metadata":{"colab_type":"text","id":"P17n0aw27Nap"},"cell_type":"markdown","source":"# Avaliação"},{"metadata":{"colab_type":"text","id":"d2VVNVA17Naq"},"cell_type":"markdown","source":"Como o próprio nome diz, esta fase consiste em interpretar os dados gerados e verificar se possuem alguma validade para o problema proposto.\n\nIremos apresentar o Score , Acurácia e Tabela de Confusão  do modelo quando aplicado para K = 7. As observações que podemos tirar acerca desses cálculos é:\n\n- Score: podemos perceber que na maioria dos casos o algoritmo possui muita 'certeza' da classificação efetuada.\n- Acurácia: o modelo apresenta  cerca de 93% de acurácia.\n- Matriz de confusão: no teste do modelo existem 4  casos de falso positivo, ou seja, que foram preditos como benignos quando na verdade eram malignos. E 5 casos de falso positivo , ou seja, que foram preditos como benignos quando na verdade eram malignos. Além dos restantes 134 casos que foram corretamente preditos.\n"},{"metadata":{"colab_type":"text","id":"SJeo-FJ_7Nas"},"cell_type":"markdown","source":"## Cálculo de score"},{"metadata":{"colab":{},"colab_type":"code","id":"MzjU_xHk7Nat","trusted":false},"cell_type":"code","source":"# Reaplicar o modelo com k=7 , que é o melhor k\nclf = KNeighborsClassifier(n_neighbors = 11)\nclf.fit(x_train, y_train)\n\n\n# Mostrar Score\npred_scores = clf.predict_proba(x_test)\nprint(pred_scores)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"JuRfwi-S7Naw"},"cell_type":"markdown","source":"## Cálculo da acurácia"},{"metadata":{"colab":{},"colab_type":"code","id":"sRadbpBf7Naw","trusted":false},"cell_type":"code","source":"# Calcular a acurácia do modelo aplicado nos dados de teste\ny_pred = clf.predict(x_test)\nte_acc= (sklearn.metrics.accuracy_score(y_test, y_pred)) \nprint ('Acurácia obtida: ', te_acc)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"aexCFH0o7Naz"},"cell_type":"markdown","source":"## Matriz de confusão \n"},{"metadata":{"colab":{},"colab_type":"code","id":"HGM7kuh07Na0","trusted":false},"cell_type":"code","source":"conf_mat = sklearn.metrics.confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(conf_mat, index = [i for i in ['maligno', 'benigno']],\n                  columns = [i for i in ['maligno', 'benigno']])\n\ncmap = sns.light_palette(\"navy\", as_cmap=True)\nplt.figure()\nsns.heatmap(df_cm, annot=True, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"z2bL0_nD7Na3"},"cell_type":"markdown","source":"# Conclusão"},{"metadata":{"colab_type":"text","id":"q8IaaI817Na4"},"cell_type":"markdown","source":"Realizamos todas as etapas do KDD  (Seleção dos dados, Pré-processamento, Transformação, Mineração de Dados, Avaliação) na abordagem do algoritmo de aprendizado de máquina KNN aplicado na base de dados referente ao diagnóstico de câncer de mama. \n\nÉ possível concluir que a acurácia de 93% obtida pelo modelo  é satisfatória. \n\nNuma próxima abordagem poderiam ser definidos quais são os atributos mais relevantes para a separação das classes a fim de atribuir um peso maior a esses atributos no momento da classificação de um novo dado. Atributos que seriam candidatos a um peso maior são os que foram comentados na seção da Plotagem de violino (area_mean ,  concave points_mean , area_se , concave points_worst e area_worst )  e na seção de Gráfico de pares de atributos (area_mean ,  concave points_mean , area_se , concave points_worst e area_worst ).\n"}],"metadata":{"colab":{"name":"KNN.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}