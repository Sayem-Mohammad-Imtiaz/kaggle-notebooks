{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport ast\nimport torch\nimport PIL\nfrom tqdm.auto import tqdm\nimport shutil as sh\nfrom pathlib import Path\nimport random\n\nfrom IPython.display import Image, clear_output\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n!git clone https://github.com/ultralytics/yolov5  # clone repo\n!pip install -qr yolov5/requirements.txt  # install dependencies\n!cp yolov5/requirements.txt ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = Path('../input/airbus-aircrafts-sample-dataset')\nimg_list = list(DATA_DIR.glob('images/*.jpg'))\npickone = random.choice(img_list)\nimg = PIL.Image.open(pickone)\ndisplay(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"only_files = [DATA_DIR / f.name for f in img_list if os.path.isfile(f) and f.name[-4:] == \".jpg\"]\nprint(\"Found {} images files in {}\".format(len(only_files), DATA_DIR))\n\nIMAGE_HEIGHT, IMAGE_WIDTH = img.size\nnum_channels = len(img.mode)\nprint(\"Image size: {}\".format((IMAGE_HEIGHT, IMAGE_WIDTH)))\nprint(\"Num channels: {}\".format(num_channels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(DATA_DIR / 'annotations.csv')\n# convert a string record into a valid python object\ndef f(x): \n    return ast.literal_eval(x.rstrip('\\r\\n'))\n\ndf = pd.read_csv(DATA_DIR / \"annotations.csv\", \n                converters={'geometry': f})\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getBounds(geometry):\n    try: \n        arr = np.array(geometry).T\n        xmin = np.min(arr[0])\n        ymin = np.min(arr[1])\n        xmax = np.max(arr[0])\n        ymax = np.max(arr[1])\n        return (xmin, ymin, xmax, ymax)\n    except:\n        return np.nan\n\ndef getWidth(bounds):\n    try: \n        (xmin, ymin, xmax, ymax) = bounds\n        return np.abs(xmax - xmin)\n    except:\n        return np.nan\n\ndef getHeight(bounds):\n    try: \n        (xmin, ymin, xmax, ymax) = bounds\n        return np.abs(ymax - ymin)\n    except:\n        return np.nan\n\n# Create bounds, width and height\ndf.loc[:,'bounds'] = df.loc[:,'geometry'].apply(getBounds)\ndf.loc[:,'width'] = df.loc[:,'bounds'].apply(getWidth)\ndf.loc[:,'height'] = df.loc[:,'bounds'].apply(getHeight)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a list of images used for validation\nfold = 1\nnum_fold = 5\nindex = df['image_id'].unique()\nval_indexes = index[len(index)*fold//num_fold:len(index)*(fold+1)//num_fold]\nprint(val_indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nimport tqdm.notebook\n\n# Create 512x512 tiles with 64 pix overlap in /kaggle/working\nTILE_WIDTH = 512\nTILE_HEIGHT = 512\nTILE_OVERLAP = 64\nTRUNCATED_PERCENT = 0.3\n_overwriteFiles = True\n\nTILES_DIR = {'train': Path('/kaggle/working/train/images/'),\n             'val': Path('/kaggle/working/val/images/')}\nfor _, folder in TILES_DIR.items():\n    if not os.path.isdir(folder):\n        os.makedirs(folder)\n\nLABELS_DIR = {'train': Path('/kaggle/working/train/labels/'),\n              'val': Path('/kaggle/working/val/labels/')}\nfor _, folder in LABELS_DIR.items():\n    if not os.path.isdir(folder):\n        os.makedirs(folder)\n\n# Save one line in .txt file for each tag found inside the tile\ndef tag_is_inside_tile(bounds, x_start, y_start, width, height, truncated_percent):\n    x_min, y_min, x_max, y_max = bounds\n    x_min, y_min, x_max, y_max = x_min - x_start, y_min - y_start, x_max - x_start, y_max - y_start\n\n    if (x_min > width) or (x_max < 0.0) or (y_min > height) or (y_max < 0.0):\n        return None\n    \n    x_max_trunc = min(x_max, width) \n    x_min_trunc = max(x_min, 0) \n    if (x_max_trunc - x_min_trunc) / (x_max - x_min) < truncated_percent:\n        return None\n\n    y_max_trunc = min(y_max, width) \n    y_min_trunc = max(y_min, 0) \n    if (y_max_trunc - y_min_trunc) / (y_max - y_min) < truncated_percent:\n        return None\n        \n    x_center = (x_min_trunc + x_max_trunc) / 2.0 / width\n    y_center = (y_min_trunc + y_max_trunc) / 2.0 / height\n    x_extend = (x_max_trunc - x_min_trunc) / width\n    y_extend = (y_max_trunc - y_min_trunc) / height\n    \n    return (0, x_center, y_center, x_extend, y_extend)\n            \nfor img_path in tqdm.notebook.tqdm(img_list):\n    # Open image and related data\n    pil_img = PIL.Image.open(img_path, mode='r')\n    np_img = np.array(pil_img, dtype=np.uint8)\n\n    # Get annotations for image\n    img_labels = df[df[\"image_id\"] == img_path.name]\n    #print(img_labels)\n\n    # Count number of sections to make\n    X_TILES = (IMAGE_WIDTH + TILE_WIDTH + TILE_OVERLAP - 1) // TILE_WIDTH \n    Y_TILES = (IMAGE_HEIGHT + TILE_HEIGHT + TILE_OVERLAP - 1) // TILE_HEIGHT\n    \n    # Cut each tile\n    for x in range(X_TILES):\n        for y in range(Y_TILES):\n\n            x_end = min((x + 1) * TILE_WIDTH - TILE_OVERLAP * (x != 0), IMAGE_WIDTH)\n            x_start = x_end - TILE_WIDTH\n            y_end = min((y + 1) * TILE_HEIGHT - TILE_OVERLAP * (y != 0), IMAGE_HEIGHT)\n            y_start = y_end - TILE_HEIGHT\n            #print(x_start, y_start)\n\n            folder = 'val' if img_path.name in val_indexes else 'train'\n            save_tile_path = TILES_DIR[folder].joinpath(img_path.stem + \"_\" + str(x_start) + \"_\" + str(y_start) + \".jpg\")\n            save_label_path = LABELS_DIR[folder].joinpath(img_path.stem + \"_\" + str(x_start) + \"_\" + str(y_start) + \".txt\")\n                \n            # Save if file doesn't exit\n            if _overwriteFiles or not os.path.isfile(save_tile_path):\n                cut_tile = np.zeros(shape=(TILE_WIDTH, TILE_HEIGHT, 3), dtype=np.uint8)\n                cut_tile[0:TILE_HEIGHT, 0:TILE_WIDTH, :] = np_img[y_start:y_end, x_start:x_end, :]\n                cut_tile_img = PIL.Image.fromarray(cut_tile)\n                cut_tile_img.save(save_tile_path)\n\n            found_tags = [\n                tag_is_inside_tile(bounds, x_start, y_start, TILE_WIDTH, TILE_HEIGHT, TRUNCATED_PERCENT)\n                for i, bounds in enumerate(img_labels['bounds'])]\n            found_tags = [el for el in found_tags if el is not None]\n\n            # save labels\n            with open(save_label_path, 'w+') as f:\n                for tags in found_tags:\n                    f.write(' '.join(str(x) for x in tags) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tensorboard (optional)\n#%load_ext tensorboard\n#%tensorboard --logdir runs/train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CONFIG = \"\"\"\n# train and val datasets (image directory or *.txt file with image paths)\ntrain: /kaggle/working/train/\nval: /kaggle/working/val/\n\n# number of classes\nnc: 1\n\n# class names\nnames: ['Aircraft']\n\"\"\"\n\nwith open(\"dataset.yaml\", \"w\") as f:\n    f.write(CONFIG)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf /kaggle/working/runs\n!rm -rf /kaggle/working/wandb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wandb\nwandb.login()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python /kaggle/working/yolov5/train.py --img 512 --batch 16 --epochs 10 --data /kaggle/working/dataset.yaml --weights yolov5s.pt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python /kaggle/working/yolov5/detect.py --source ../input/airbus-aircrafts-sample-dataset/extras/ --img-size 2560 --weights /kaggle/working/runs/train/exp/weights/best.pt --conf 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = Path('/kaggle/working/runs/detect/exp/')\nimg_list = list(DATA_DIR.glob('*.jpg'))\npickone = random.choice(img_list)\nimg = PIL.Image.open(pickone)\ndisplay(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}