{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import glob\nimport numpy as np \nimport cv2\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\nimport tensorflow as tf \n%matplotlib inline \nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DIR = \"../input/covid-19-x-ray-10000-images/dataset\"\nos.listdir(DIR)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gather Normal Images \nnormal_images = []\nfor img_path in glob.glob(DIR + '/normal/*'):\n    normal_images.append(cv2.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('Normal X- Ray Image')\nplt.imshow(normal_images[0], cmap='gray') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GRAB cOVID iMAGES \ncovid_images = []\nfor img_path in glob.glob(DIR + '/covid/*'):\n    covid_images.append(cv2.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('Covid X-Ray Image')\nplt.imshow(covid_images[0], cmap='gray') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(covid_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the lenghth of the two lists of images \nprint(f\"Number of Normal Images :{format(len(normal_images))}\")\nprint(f\"Number of Covid Images  :{format(len(covid_images))}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W = 150 # Width of Images \nH= 150  # height of Images \nC= 3    # Number of Channels . 3 for RGB \n\ninput_shape= (W, H, C)\nN_CLASSES = 2\nEPOCHS = 20\nBATCH_SIZE = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build the Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## The Neural network archiecture will be like this :\n ##1 convlution layer\n ##2 relu layer\n ##3 pooling layer\n ##4 fully connected\n\nmodel = Sequential()\n# First Layer \nmodel.add(Conv2D(filters = 64, kernel_size = (3,3) ,activation ='relu', \n                 input_shape = input_shape))\nmodel.add(Conv2D(filters = 56, kernel_size = (3,3),activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#Second alyer \nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),activation ='relu'))\nmodel.add(Conv2D(filters = 48, kernel_size = (3,3),activation ='relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#Third Layer \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\n\nmodel.compile(Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show model summary \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator = ImageDataGenerator(rotation_range=30, # rotate the image 30 degrees\n                               width_shift_range=0.1, # Shift the pic width by a max of 10%\n                               height_shift_range=0.1, # Shift the pic height by a max of 10%\n                               rescale=1/255, # Rescale the image by normalzing it.\n                               shear_range=0.2, # Shear means cutting away part of the image (max 20%)\n                               zoom_range=0.2, # Zoom in by 20% max\n                               horizontal_flip=True, # Allo horizontal flipping\n                               fill_mode='nearest', # Fill in missing pixels with the nearest filled value\n                               validation_split=0.25)\n\ntrain_generator= data_generator.flow_from_directory(\n                        DIR,\n                        target_size=(H, W),\n                       \n                        class_mode='binary',\n                        subset='training')\n\ntest_generator= data_generator.flow_from_directory(\n    DIR, \n    target_size=(H,W),\n    class_mode='binary',\n    shuffle= False,\n    subset='validation')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train our Model \nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples // BATCH_SIZE,\n    epochs = 10 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the Results ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history.params['metrics']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot training loss vs validation loss \nplt.figure()\nfig,(ax1, ax2)=plt.subplots(1,2,figsize=(19,7))\nax1.plot(history.history['loss'])\nax1.plot(history.history['val_loss'])\nax1.legend(['training','validation'])\nax1.set_title('loss')\nax1.set_xlabel('epochs')\n## plot training accuracy vs validation accuracy \nax2.plot(history.history['accuracy'])\nax2.plot(history.history['val_accuracy'])\nax2.legend(['training','validation'])\nax2.set_title('Acurracy')\nax2.set_xlabel('epochs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds= model.predict(test_generator)\npredicted_class_indices=np.argmax(preds,axis=1)\nlabels = (test_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# put them on a Serie List \npredicted_values = pd.Series(predictions)\n# create a submission dataframe \nsubmission = pd.DataFrame({'Image Id':predicted_values.index,'Status':predicted_values })\nsubmission.set_index('Image Id',inplace=True)\n# save to a csv file \nsubmission.to_csv('covid19_xray_submission.csv', index=False)\nprint(\" Submission  successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}