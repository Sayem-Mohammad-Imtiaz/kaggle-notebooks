{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#LSTM from Udemy Deep Learning course \n# Part 1 - Data Preprocessing\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n \n# Importing Training Set\ndataset_train = pd.read_csv('../input/google-stock-price/Google_Stock_Price_Train.csv')\n \ncols = list(dataset_train)[1:5]\n \n#Preprocess data for training by removing all commas\n \ndataset_train = dataset_train[cols].astype(str)\nfor i in cols:\n    for j in range(0,len(dataset_train)):\n        dataset_train[i][j] = dataset_train[i][j].replace(\",\",\"\")\n \ndataset_train = dataset_train.astype(float)\n \n \ntraining_set = dataset_train.as_matrix() # Using multiple predictors.\n \n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n \nsc = StandardScaler()\ntraining_set_scaled = sc.fit_transform(training_set)\n \nsc_predict = StandardScaler()\n \nsc_predict.fit_transform(training_set[:,0:1])\n \n# Creating a data structure with 60 timesteps and 1 output\nX_train = []\ny_train = []\n \nn_future = 1  # Number of days you want to predict into the future\nn_past = 60  # Number of past days you want to use to predict the future\n \nfor i in range(n_past, len(training_set_scaled) - n_future + 1):\n    X_train.append(training_set_scaled[i - n_past:i, 0:5])\n    y_train.append(training_set_scaled[i+n_future-1:i + n_future, 0])\n \nX_train, y_train = np.array(X_train), np.array(y_train)\n \n# Part 2 - Building the RNN \n# Import Libraries and packages from Keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n \n# Initializing the RNN\nlstmNeurons = 50\nregressor = Sequential()\n \n# Adding fist LSTM layer and Drop out Regularization\nregressor.add(LSTM(units=lstmNeurons, return_sequences=True, input_shape=(n_past, 4)))\nregressor.add(Dropout(0.2))\nregressor.add(LSTM(units=lstmNeurons, return_sequences=True))\nregressor.add(Dropout(0.2))\nregressor.add(LSTM(units=lstmNeurons, return_sequences=True))\nregressor.add(Dropout(0.2))\nregressor.add(LSTM(units=lstmNeurons))\nregressor.add(Dropout(0.2))\n \n# Output layer\nregressor.add(Dense(units=1))\n \n# Compiling the RNN\nregressor.compile(optimizer='adam', loss=\"mean_squared_error\")  # Can change loss to mean-squared-error if you require.\n \n# Fitting RNN to training set using Keras Callbacks. Read Keras callbacks docs for more info. \nes = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\nrlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\nmcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\ntb = TensorBoard('logs')\ncustomCallbacks = [es, rlr,mcp, tb]\n \nhistory = regressor.fit(X_train, y_train, shuffle=True, epochs=100, validation_split=0.2, verbose=1, batch_size=64)\n#history = regressor.fit(X_train, y_train, callback = customCallbacks, shuffle=True, epochs=100, validation_split=0.2, verbose=1, batch_size=64)\n \n \n# Predicting the future.\n#--------------------------------------------------------\n# The last date for our training set is 30-Dec-2016.\n# Lets now try predicting the stocks for the dates in the test set.\n \n# The dates on our test set are:\n# 3,4,5,6,9,10,11,12,13,17,18,19,20,23,24,25,26,27,30,31-Jan-2017\n \n# Now, the latest we can predict into our test set is to the 19th since the last date on training is 30-Dec-2016. \n# 20 days into the future from the latest day in our training set is 19-Dec-2016. Right?\n# Notice that we dont have some days in our test set, what we can do is to take the last 20 samples from the training set. \n# (Remember the last sample of our training set will predict the 19th of Jan 2017, the second last will predict the 18th, etc)\n \n \n# Lets first import the test_set.\ndataset_test = pd.read_csv('../input/google-stock-price/Google_Stock_Price_Test.csv')\ny_test = np.array(dataset_test['Open'])\n#Trim the test set to first 12 entries (till the 19th)\ny_test = y_test[0:12]\npredictions = regressor.predict(X_train[-20:])\n \n \n# We skip the 31-Dec, 1-Jan,2-Jan, etc to compare with the test_set\npredictions_to_compare = predictions[[3,4,5,6,9,10,11,12,13,17,18,19]]\ny_pred = sc_predict.inverse_transform(predictions_to_compare)\n \n \nhfm, = plt.plot(y_pred, 'r', label='predicted_stock_price')\nhfm2, = plt.plot(y_test,'b', label = 'actual_stock_price')\n \nplt.legend(handles=[hfm,hfm2])\nplt.title('Predictions and Actual Price')\nplt.xlabel('Sample index')\nplt.ylabel('Stock Price Future')\nplt.savefig('graph.png', bbox_inches='tight')\nplt.show()\nplt.close() \n \n \nhfm, = plt.plot(sc_predict.inverse_transform(y_train), 'r', label='actual_training_stock_price')\nhfm2, = plt.plot(sc_predict.inverse_transform(regressor.predict(X_train)),'b', label = 'predicted_training_stock_price')\n \nplt.legend(handles=[hfm,hfm2])\nplt.title('Predictions vs Actual Price')\nplt.xlabel('Sample index')\nplt.ylabel('Stock Price Training')\nplt.savefig('graph_training.png', bbox_inches='tight')\nplt.show()\nplt.close()\n\nimport math\nfrom sklearn.metrics import mean_squared_error\nrmse = math.sqrt(mean_squared_error(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}