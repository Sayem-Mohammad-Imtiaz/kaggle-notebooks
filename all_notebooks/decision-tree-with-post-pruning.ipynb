{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\n\n%matplotlib inline\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df=pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analyzing Quantitative variables.\nplt.figure(figsize=(30, 30))\nsns.set(font_scale=1.5)\nind = 1\n\nfor col in df.columns:\n    plt.subplot(4, 3, ind)\n    sns.boxplot(x=df[col])\n    ind += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(x=df.quality)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y=df.quality.replace({3:0, 4:0, 5:0, 6:0, 7:1, 8:1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axes = plt.subplots(4, 3, figsize = (15,15))\naxes = axes.flatten()\n\nfor i in range(0,len(df.columns)-1):\n    sns.barplot(x=y, y=df.iloc[:,i], data=df, orient='v', ax=axes[i])\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.quality=df.quality.replace({3:0, 4:0, 5:0, 6:0, 7:1, 8:1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.pairplot(data=df, hue='quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Data Pre-processing with different normalization options.\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef data_preprocess(X,y,std_scale=False,minmax_scale=False):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n    \n    if std_scale or minmax_scale:\n        if std_scale:\n            scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n        else:\n            scaler = MinMaxScaler(copy=True,feature_range=(0,1))\n            \n        scaler.fit(X_train)\n\n        train_scaled = scaler.transform(X_train)\n        test_scaled = scaler.transform(X_test)\n    else:\n        train_scaled, test_scaled = X_train, X_test\n    \n    return(train_scaled, test_scaled, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\ndef logistic_regression(X_train,X_test,y_train,y_test,cls_weight=None):\n    logreg = LogisticRegression(class_weight=cls_weight).fit(X_train, y_train)\n    print(\"Training set score: {:.3f}\".format(logreg.score(X_train,y_train)))\n    print(\"Test set score: {:.3f}\".format(logreg.score(X_test,y_test)))\n    return(logreg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, matthews_corrcoef\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\")\n        print(\"_______________________________________________\")\n        print(f\"MCC: {matthews_corrcoef(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\")\n        print(\"_______________________________________________\")\n        print(f\"MCC: {matthews_corrcoef(y_test, pred)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Heatmap\nplt.figure(figsize=(len(df.columns), len(df.columns)-7))\nsns.heatmap(df.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"X=df.drop('quality',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test=data_preprocess(X,y,std_scale=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"log_reg=logistic_regression(X_train,X_test,y_train,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"logit_model = sm.Logit(y_train, X_train)\nresult = logit_model.fit()\nresult.summary2()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression - Iteration 2"},{"metadata":{"trusted":false},"cell_type":"code","source":"X=df.drop(labels=['citric acid','chlorides','free sulfur dioxide', 'total sulfur dioxide','pH','quality'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test=data_preprocess(X,y,std_scale=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"log_reg=logistic_regression(X_train,X_test,y_train,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"logit_model = sm.Logit(y_train, X_train)\nresult = logit_model.fit()\nresult.summary2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = log_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print_score(log_reg,X_train,y_train,X_test,y_test,train=True)\nprint_score(log_reg,X_train,y_train,X_test,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n# predict probabilities\nlr_probs = log_reg.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nlr_auc = roc_auc_score(y_test, lr_probs)\nprint('Logistic: ROC AUC=%.3f' % (lr_auc))\n# calculate roc curves\nlr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n# plot the roc curve for the model\nplt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DT"},{"metadata":{"trusted":false},"cell_type":"code","source":"X=df.drop('quality',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test=data_preprocess(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree_clf = DecisionTreeClassifier(random_state=0)\ntree_clf.fit(X_train, y_train)\n\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"path = tree_clf.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\nprint(ccp_alphas)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\nax.set_xlabel(\"effective alpha\")\nax.set_ylabel(\"total impurity of leaves\")\nax.set_title(\"Total Impurity vs effective alpha for training set\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clfs = []\nfor ccp_alpha in ccp_alphas:\n    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    clf.fit(X_train, y_train)\n    clfs.append(clf)\nprint(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n      clfs[-1].tree_.node_count, ccp_alphas[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clfs = clfs[:-1]\nccp_alphas = ccp_alphas[:-1]\n\nnode_counts = [tree_clf.tree_.node_count for tree_clf in clfs]\ndepth = [tree_clf.tree_.max_depth for tree_clf in clfs]\nfig, ax = plt.subplots(1, 2,figsize=(20,8))\nax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle=\"steps-post\")\nax[0].set_xlabel(\"alpha\")\nax[0].set_ylabel(\"number of nodes\")\n\nax[1].plot(ccp_alphas, depth, marker='o', drawstyle=\"steps-post\")\nax[1].set_xlabel(\"alpha\")\nax[1].set_ylabel(\"depth of tree\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_scores = [tree_clf.score(X_train, y_train) for tree_clf in clfs]\ntest_scores = [tree_clf.score(X_test, y_test) for tree_clf in clfs]\n\nfig, ax = plt.subplots(figsize=(15,5))\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n        drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n        drawstyle=\"steps-post\")\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tree_clf = DecisionTreeClassifier(random_state=0,ccp_alpha=0.006)\ntree_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Feature Importance.\nfeat_importances = pd.Series(tree_clf.feature_importances_,index=X.columns)\nfeat_importances[feat_importances.values>0].sort_values(ascending=False).plot(kind='bar')\nplt.show()\n\nprint(feat_importances[feat_importances.values>0].sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tree_clf = DecisionTreeClassifier(random_state=0,ccp_alpha=0.006)\ntree_clf.fit(X_train[['volatile acidity','sulphates','alcohol']], y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print_score(tree_clf, X_train[['volatile acidity','sulphates','alcohol']], y_train, \n            X_test[['volatile acidity','sulphates','alcohol']], y_test, train=True)\nprint_score(tree_clf, X_train[['volatile acidity','sulphates','alcohol']], y_train, \n            X_test[['volatile acidity','sulphates','alcohol']], y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tree_clf.predict([np.array([0.88, 0.56, 9.4])])[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision tree with post pruning gave the best possible result"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}