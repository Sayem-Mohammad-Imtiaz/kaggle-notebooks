{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n\nThis notebook shows a hands on approach to use Stacking for tabular data. Stacking is a very powerful method when it comes to extracting the last bit of performance from a group of already decent estimators.  \n\nI want to acknowledge [@abhishek](https://www.kaggle.com/abhishek) for his k-fold dataset (used for training in this notebook) and his [awesome playlist](https://www.youtube.com/playlist?list=PL98nY_tJQXZnP-k3qCDd1hljVSciDV9_N) on Youtube which covers most of the pre-requisites and concepts used here.\n\nNote:- I have directly used the optimised parameters for L0 models here. Majority of which I tuned on my own in a separate Kernel and some of which I found in [this](https://www.kaggle.com/abhishek/blending-blending-blending) kernel shared by [@abhishek](https://www.kaggle.com/abhishek)","metadata":{"id":"O36SoF_kiifx"}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nfrom pandas.core.common import SettingWithCopyWarning\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=SettingWithCopyWarning)\nwarnings.filterwarnings('ignore', category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport random\nimport gc\nimport itertools\ngc.enable()\n\n# Visialisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\n# Machine Learning\n# Utils\nfrom sklearn import preprocessing\nimport category_encoders as ce\n# Regression Models\nfrom sklearn.linear_model import LinearRegression, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n#Metrics\nfrom sklearn.metrics import mean_squared_error\n\n# Deep Learning\nimport torch\n\n# Fixing Seed\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    GPU = True\nelse:\n    GPU = False\n    \nprint(f'GPU Available: {GPU}')","metadata":{"id":"s7PugG6migOs","outputId":"a9490784-f8cd-468a-f3ba-60f268f2c32c","execution":{"iopub.status.busy":"2021-08-27T18:31:57.481813Z","iopub.execute_input":"2021-08-27T18:31:57.482585Z","iopub.status.idle":"2021-08-27T18:32:02.479144Z","shell.execute_reply.started":"2021-08-27T18:31:57.482437Z","shell.execute_reply":"2021-08-27T18:32:02.477516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{"id":"jjiDKp8bkw4b"}},{"cell_type":"code","source":"data_dir = '../input/30-days-of-ml'\n\ntrain_file_path = '../input/30days-folds/train_folds.csv'\ntest_file_path = os.path.join(data_dir, 'test.csv')\nsample_sub_file_path = os.path.join(data_dir, 'sample_submission.csv')\n\nprint(f'Train file: {train_file_path}')\nprint(f'Test file: {test_file_path}')\nprint(f'Sample Sub file: {sample_sub_file_path}')","metadata":{"id":"w8ZkFuPJkvuN","outputId":"189d63e4-641a-4136-cabd-9307e9d503cb","execution":{"iopub.status.busy":"2021-08-27T18:32:02.481471Z","iopub.execute_input":"2021-08-27T18:32:02.481814Z","iopub.status.idle":"2021-08-27T18:32:02.488826Z","shell.execute_reply.started":"2021-08-27T18:32:02.481783Z","shell.execute_reply":"2021-08-27T18:32:02.487487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(test_file_path)\nsub_df = pd.read_csv(sample_sub_file_path)","metadata":{"id":"Tk3hKq44lQ_P","execution":{"iopub.status.busy":"2021-08-27T18:32:02.492054Z","iopub.execute_input":"2021-08-27T18:32:02.492662Z","iopub.status.idle":"2021-08-27T18:32:07.630391Z","shell.execute_reply.started":"2021-08-27T18:32:02.492605Z","shell.execute_reply":"2021-08-27T18:32:07.629285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = ['target']\nnot_features = ['id', 'kfold', 'target']\ncols = list(train_df.columns)\nfeatures = [feat for feat in cols if feat not in not_features]","metadata":{"id":"xO-NM32K2Dr9","execution":{"iopub.status.busy":"2021-08-27T18:32:07.632267Z","iopub.execute_input":"2021-08-27T18:32:07.632609Z","iopub.status.idle":"2021-08-27T18:32:07.638452Z","shell.execute_reply.started":"2021-08-27T18:32:07.632574Z","shell.execute_reply":"2021-08-27T18:32:07.637374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_features = []\nnumerical_features = []\n\nfor i in features:\n    if train_df[i].dtype in numerics:\n        numerical_features.append(i)\n    else:\n        categorical_features.append(i)\n        \nprint(f'Numeric features: {numerical_features}')\nprint(f'Categorical features: {categorical_features}')","metadata":{"id":"SwUAjXPE2DuY","outputId":"6755fe0c-a99f-4324-e922-e82400f9cb9d","execution":{"iopub.status.busy":"2021-08-27T18:32:07.640655Z","iopub.execute_input":"2021-08-27T18:32:07.641041Z","iopub.status.idle":"2021-08-27T18:32:07.67106Z","shell.execute_reply.started":"2021-08-27T18:32:07.641004Z","shell.execute_reply":"2021-08-27T18:32:07.669634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"high_cardinality_cat_feat = []\nlow_cardinality_cat_feat = []\n\nfor col in categorical_features:\n    if train_df[col].nunique() > 5:\n        high_cardinality_cat_feat.append(col)\n    else:\n        low_cardinality_cat_feat.append(col)\n\nprint(f'High Cardinality Categorical Features: {high_cardinality_cat_feat}')\nprint(f'Low Cardinality Categorical Features:  {low_cardinality_cat_feat}')","metadata":{"id":"oMpL5sFF2HxD","outputId":"a7d9ae04-ed96-4a39-b89c-c507f82ff62c","execution":{"iopub.status.busy":"2021-08-27T18:32:07.672764Z","iopub.execute_input":"2021-08-27T18:32:07.673337Z","iopub.status.idle":"2021-08-27T18:32:08.202584Z","shell.execute_reply.started":"2021-08-27T18:32:07.673298Z","shell.execute_reply":"2021-08-27T18:32:08.201046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Encoding","metadata":{"id":"L6Ui4uVjl340"}},{"cell_type":"code","source":"def ordinal_enc(train_df, valid_df, test_df, features):\n    ord_enc = preprocessing.OrdinalEncoder()\n    \n    train_df[features] = ord_enc.fit_transform(train_df[features])\n    valid_df[features] = ord_enc.transform(valid_df[features])\n    test_df[features] = ord_enc.transform(test_df[features])\n            \n    return train_df, valid_df, test_df","metadata":{"id":"c2eDoh90npka","execution":{"iopub.status.busy":"2021-08-27T18:32:08.20399Z","iopub.execute_input":"2021-08-27T18:32:08.204486Z","iopub.status.idle":"2021-08-27T18:32:08.210671Z","shell.execute_reply.started":"2021-08-27T18:32:08.204436Z","shell.execute_reply":"2021-08-27T18:32:08.209703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_hot_enc(train_df, valid_df, test_df, features):\n    OH_enc = preprocessing.OneHotEncoder(sparse=False)\n    OH_cols_train = pd.DataFrame(OH_enc.fit_transform(train_df[features]))\n    OH_cols_valid = pd.DataFrame(OH_enc.transform(valid_df[features]))\n    OH_cols_test = pd.DataFrame(OH_enc.transform(test_df[features]))\n    \n    OH_cols_train.index = train_df[features].index\n    OH_cols_valid.index = valid_df[features].index\n    OH_cols_test.index = test_df[features].index\n    \n    train_df = train_df.drop(features, axis=1)\n    valid_df = valid_df.drop(features, axis=1)\n    test_df = test_df.drop(features, axis=1)\n    \n    train_df = pd.concat([train_df, OH_cols_train], axis=1)\n    valid_df = pd.concat([valid_df, OH_cols_valid], axis=1)\n    test_df = pd.concat([test_df, OH_cols_test], axis=1)\n    \n    return train_df, valid_df, test_df","metadata":{"id":"YIe2nBnEqUhV","execution":{"iopub.status.busy":"2021-08-27T18:32:08.211669Z","iopub.execute_input":"2021-08-27T18:32:08.212014Z","iopub.status.idle":"2021-08-27T18:32:08.226304Z","shell.execute_reply.started":"2021-08-27T18:32:08.211979Z","shell.execute_reply":"2021-08-27T18:32:08.225021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def catboost_enc(train_df, valid_df, test_df, features):\n    cb_enc = ce.CatBoostEncoder(cols=features)\n    cb_enc.fit(train_df[features], train_df['target'])\n    \n    train_df = train_df.join(cb_enc.transform(train_df[features]).add_suffix('_cb'))\n    valid_df = valid_df.join(cb_enc.transform(valid_df[features]).add_suffix('_cb'))\n    test_df = test_df.join(cb_enc.transform(test_df[features]).add_suffix('_cb'))\n    \n    train_df = train_df.drop(features, axis=1)\n    valid_df = valid_df.drop(features, axis=1)\n    test_df = test_df.drop(features, axis=1)\n    \n    return train_df, valid_df, test_df","metadata":{"id":"ZFO8JSanqUkU","execution":{"iopub.status.busy":"2021-08-27T18:32:08.230103Z","iopub.execute_input":"2021-08-27T18:32:08.230487Z","iopub.status.idle":"2021-08-27T18:32:08.244287Z","shell.execute_reply.started":"2021-08-27T18:32:08.230453Z","shell.execute_reply":"2021-08-27T18:32:08.243503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# L0 Models","metadata":{"id":"suv-jDlxqYW6"}},{"cell_type":"markdown","source":"## 1. XGBoost","metadata":{"id":"uwwhquMXno96"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = catboost_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    if GPU:\n        xgb_params = {\n            'learning_rate': 0.03336420518893778,\n            'n_estimators': 9801,\n            'reg_lambda': 1.861341724045207e-07,\n            'reg_alpha': 41.069310465195315,\n            'max_depth': 4,\n            'subsample': 0.7889762678652061,\n            'colsample_bytree': 0.11946885793267677,\n            'booster': 'gbtree',\n            'random_state': RANDOM_SEED,\n            'verbosity': 0,\n            'tree_method':'gpu_hist',\n            'gpu_id': 0,\n            'predictor': 'gpu_predictor'\n        }\n        reg = XGBRegressor(**xgb_params)\n    else:\n        xgb_params = {\n            'learning_rate': 0.03336420518893778,\n            'n_estimators': 9801,\n            'reg_lambda': 1.861341724045207e-07,\n            'reg_alpha': 41.069310465195315,\n            'max_depth': 4,\n            'subsample': 0.7889762678652061,\n            'colsample_bytree': 0.11946885793267677,\n            'booster': 'gbtree',\n            'random_state': RANDOM_SEED,\n            'verbosity': 0,\n            'n_jobs': -1\n        }\n        reg = XGBRegressor(**xgb_params)\n      \n    reg.fit(train[features].values, train[target].values,\n            eval_set = [(valid[features].values, valid[target].values)],\n            eval_metric = 'rmse',\n            early_stopping_rounds = 300,\n            verbose=False)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_1']\nvalid_pred_all.to_csv('train_pred_1.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_1'] = test_pred_all\nsub_2.to_csv('test_pred_1.csv', index=False)","metadata":{"id":"9Z3bf8kTnQu7","outputId":"4efb71a3-cfbb-42b9-8c15-a598f694ae07","execution":{"iopub.status.busy":"2021-08-27T18:32:08.246324Z","iopub.execute_input":"2021-08-27T18:32:08.246645Z","iopub.status.idle":"2021-08-27T18:32:08.256403Z","shell.execute_reply.started":"2021-08-27T18:32:08.246613Z","shell.execute_reply":"2021-08-27T18:32:08.254822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. LightGBM","metadata":{"id":"XxiS_Oo7aq6u"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = one_hot_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = catboost_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n\n    lgbm_params = {\n        'learning_rate': 0.02685940133369163,\n        'n_estimators': 7981,\n        'reg_lambda': 0.0014864508341972096,\n        'reg_alpha': 0.011093263193854072,\n        'max_depth': 2,\n        'num_leaves': 106,\n        'min_data_in_leaf': 543,\n        'subsample_freq': 9,\n        'bagging_fraction': 0.8639703294516574,\n        'pos_bagging_fraction': 0.7927447639915055,\n        'neg_bagging_fraction': 0.8037410861863784,\n        'colsample_bytree': 0.9798011192356275,\n        'objective': 'regression',\n        'metric': 'l2',\n        'verbose': -1,\n        'n_jobs': -1,\n        'random_state': RANDOM_SEED\n    }\n\n    reg = LGBMRegressor(**lgbm_params)\n    reg.fit(train[features].values, train[target].values)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_2']\nvalid_pred_all.to_csv('train_pred_2.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_2'] = test_pred_all\nsub_2.to_csv('test_pred_2.csv', index=False)","metadata":{"id":"oPCYneWcatdT","outputId":"615b5726-9f07-4a4e-9486-a1231103be9a","execution":{"iopub.status.busy":"2021-08-27T18:32:08.257828Z","iopub.execute_input":"2021-08-27T18:32:08.258138Z","iopub.status.idle":"2021-08-27T18:32:08.273686Z","shell.execute_reply.started":"2021-08-27T18:32:08.258108Z","shell.execute_reply":"2021-08-27T18:32:08.272469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. XGBoost 2 ( Abhisek's Parameters)","metadata":{"id":"QrFmVlzZnFFR"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n\n    if GPU:\n        xgb_params = {\n            'learning_rate': 0.03628302216953097,\n            'n_estimators': 10000,\n            'reg_lambda': 0.0008746338866473539,\n            'reg_alpha': 23.13181079976304,\n            'max_depth': 3,\n            'subsample': 0.7875490025178415,\n            'colsample_bytree': 0.11807135201147481,\n            'booster': 'gbtree',\n            'random_state': 1,\n            'verbosity': 0,\n            'tree_method':'gpu_hist',\n            'gpu_id': 0,\n            'predictor': 'gpu_predictor'\n        }\n        reg = XGBRegressor(**xgb_params)\n    else:\n        xgb_params = {\n            'learning_rate': 0.03628302216953097,\n            'n_estimators': 10000,\n            'reg_lambda': 0.0008746338866473539,\n            'reg_alpha': 23.13181079976304,\n            'max_depth': 3,\n            'subsample': 0.7875490025178415,\n            'colsample_bytree': 0.11807135201147481,\n            'booster': 'gbtree',\n            'random_state': 1,\n            'verbosity': 0,\n            'n_jobs': 4\n        }\n        reg = XGBRegressor(**xgb_params)\n      \n    reg.fit(train[features].values, train[target].values,\n            eval_set = [(valid[features].values, valid[target].values)],\n            eval_metric = 'rmse',\n            early_stopping_rounds = 300,\n            verbose=False)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_3']\nvalid_pred_all.to_csv('train_pred_3.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_3'] = test_pred_all\nsub_2.to_csv('test_pred_3.csv', index=False)","metadata":{"id":"Ei4BcKzvnOaj","outputId":"3bc159a0-5360-47c3-fc1f-136c59ad695b","execution":{"iopub.status.busy":"2021-08-27T18:32:08.275481Z","iopub.execute_input":"2021-08-27T18:32:08.276095Z","iopub.status.idle":"2021-08-27T18:32:08.289508Z","shell.execute_reply.started":"2021-08-27T18:32:08.276043Z","shell.execute_reply":"2021-08-27T18:32:08.287855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. XGBoost 3 ( Abhisek's Parameters)","metadata":{"id":"hrwItF9jo5g0"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    if GPU:\n        xgb_params = {\n            'learning_rate': 0.07853392035787837,\n            'n_estimators': 5000,\n            'reg_lambda': 1.7549293092194938e-05,\n            'reg_alpha': 14.68267919457715,\n            'max_depth': 3,\n            'subsample': 0.8031450486786944,\n            'colsample_bytree': 0.170759104940733,\n            'random_state': i,\n            'verbosity': 0,\n            'tree_method':'gpu_hist',\n            'gpu_id': 0,\n            'predictor': 'gpu_predictor'\n        }\n        reg = XGBRegressor(**xgb_params)\n    else:\n        xgb_params = {\n            'learning_rate': 0.07853392035787837,\n            'n_estimators': 5000,\n            'reg_lambda': 1.7549293092194938e-05,\n            'reg_alpha': 14.68267919457715,\n            'max_depth': 3,\n            'subsample': 0.8031450486786944,\n            'colsample_bytree': 0.170759104940733,\n            'random_state': i,\n            'verbosity': 0,\n            'n_jobs': 4\n        }\n        reg = XGBRegressor(**xgb_params)\n      \n    reg.fit(train[features].values, train[target].values,\n            eval_set = [(valid[features].values, valid[target].values)],\n            eval_metric = 'rmse',\n            early_stopping_rounds = 300,\n            verbose=False)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_4']\nvalid_pred_all.to_csv('train_pred_4.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_4'] = test_pred_all\nsub_2.to_csv('test_pred_4.csv', index=False)","metadata":{"id":"byAXPi7No5oy","outputId":"28f6da0f-315f-406c-f71a-c0aa696d1487","execution":{"iopub.status.busy":"2021-08-27T18:32:08.292097Z","iopub.execute_input":"2021-08-27T18:32:08.292972Z","iopub.status.idle":"2021-08-27T18:32:08.312403Z","shell.execute_reply.started":"2021-08-27T18:32:08.292866Z","shell.execute_reply":"2021-08-27T18:32:08.310792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Linear Regression","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    reg = LinearRegression()\n    reg.fit(train[features].values, train[target].values)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_5']\nvalid_pred_all.to_csv('train_pred_5.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_5'] = test_pred_all\nsub_2.to_csv('test_pred_5.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T18:32:08.31454Z","iopub.execute_input":"2021-08-27T18:32:08.315059Z","iopub.status.idle":"2021-08-27T18:32:08.338575Z","shell.execute_reply.started":"2021-08-27T18:32:08.315004Z","shell.execute_reply":"2021-08-27T18:32:08.337327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Random Forest","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    reg = RandomForestRegressor(n_estimators=500, n_jobs=4)\n    reg.fit(train[features].values, train[target].values)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    del reg\n    gc.collect()\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_6']\nvalid_pred_all.to_csv('train_pred_6.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_6'] = test_pred_all\nsub_2.to_csv('test_pred_6.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T18:32:08.339932Z","iopub.execute_input":"2021-08-27T18:32:08.340394Z","iopub.status.idle":"2021-08-27T18:32:31.162618Z","shell.execute_reply.started":"2021-08-27T18:32:08.340342Z","shell.execute_reply":"2021-08-27T18:32:31.159214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. ElasticNet","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    reg = ElasticNet(random_state=RANDOM_SEED)\n    reg.fit(train[features].values, train[target].values)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_7']\nvalid_pred_all.to_csv('train_pred_7.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_7'] = test_pred_all\nsub_2.to_csv('test_pred_7.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T18:32:31.164298Z","iopub.status.idle":"2021-08-27T18:32:31.17193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. XGBoost 4 (Public Params)\n\n[Here](https://www.kaggle.com/aditidutta/tutorial-30days-rf-xgb-lgbm-catboost-eda)","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    xgb_params = {\n        'objective': 'reg:squarederror',\n        'n_estimators': 10000,\n        'learning_rate': 0.036,\n        'subsample': 0.926,\n        'colsample_bytree': 0.118,\n        'grow_policy':'lossguide',\n        'max_depth': 3,\n        'booster': 'gbtree', \n        'reg_lambda': 45.1,\n        'reg_alpha': 34.9,\n        'random_state': 42,\n        'reg_lambda': 0.00087,\n        'reg_alpha': 23.132,\n        'n_jobs': 4\n    }\n    \n    reg = XGBRegressor(**xgb_params)\n    reg.fit(train[features].values, train[target].values)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_8']\nvalid_pred_all.to_csv('train_pred_8.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_8'] = test_pred_all\nsub_2.to_csv('test_pred_8.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. XGBoost 5 (Public Params)\n\n[Here](https://www.kaggle.com/aditidutta/tutorial-30days-rf-xgb-lgbm-catboost-eda)","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    xgb_params = {\n        'objective': 'reg:squarederror',\n        'n_estimators': 5000,\n        'learning_rate': 0.12,\n        'subsample': 0.96,\n        'colsample_bytree': 0.12,\n        'max_depth': 2,\n        'booster': 'gbtree', \n        'reg_lambda': 65.1,\n        'reg_alpha': 15.9,\n        'random_state':40\n    }\n    \n    reg = XGBRegressor(**xgb_params)\n    reg.fit(train[features].values, train[target].values)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_9']\nvalid_pred_all.to_csv('train_pred_9.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_9'] = test_pred_all\nsub_2.to_csv('test_pred_9.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10. XGBoost 6 (Public Params)\n\n[Here](https://www.kaggle.com/aditidutta/tutorial-30days-rf-xgb-lgbm-catboost-eda)","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = ordinal_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = ordinal_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n    \n    xgb_params = {\n        'random_state': 1, \n        'n_jobs': 4,\n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.0362,\n        'reg_lambda': 0.000874,\n        'reg_alpha': 23.131,\n        'subsample': 0.787,\n        'colsample_bytree': 0.118,\n        'max_depth': 3\n    }\n    \n    reg = XGBRegressor(**xgb_params)\n    reg.fit(train[features].values, train[target].values)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_10']\nvalid_pred_all.to_csv('train_pred_10.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_10'] = test_pred_all\nsub_2.to_csv('test_pred_10.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11. LGBM (Public Params)\n\n[Here](https://www.kaggle.com/sumukhar/light-gbm-hyperparameters-tuned)","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    train, valid, test = one_hot_enc(train, valid, test, low_cardinality_cat_feat)\n    train, valid, test = catboost_enc(train, valid, test, high_cardinality_cat_feat)\n\n    valid_ids = valid.id.values.tolist()\n\n    cols = list(train.columns)\n    features = [feat for feat in cols if feat not in not_features+target]\n\n    lgbm_params = {\n        'max_depth': 5,\n        'learning_rate': 0.05,\n        'metric': 'rmse', \n        'n_jobs': 4,\n        'n_estimators': 10000,\n        'reg_alpha': 17,\n        'reg_lambda': 21,\n        'colsample_bytree': 0.225,\n        'subsample': 0.75,\n        'num_leaves': 64,\n        'min_child_samples': 15,\n        'max_bin': 250\n    }\n\n    reg = LGBMRegressor(**lgbm_params)\n    reg.fit(train[features].values, train[target].values, early_stopping_rounds=75,\n            eval_set = [(valid[features].values, valid[target].values)], verbose=False)\n    \n    valid_pred = reg.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = reg.predict(test[features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_11']\nvalid_pred_all.to_csv('train_pred_11.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_11'] = test_pred_all\nsub_2.to_csv('test_pred_11.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blending (L1 Models)","metadata":{"id":"4Gz76iDSZEFi"}},{"cell_type":"code","source":"train_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(test_file_path)\nsub_df = pd.read_csv(sample_sub_file_path)","metadata":{"id":"4SagSbvvuEFX","execution":{"iopub.status.busy":"2021-08-27T18:32:31.173792Z","iopub.status.idle":"2021-08-27T18:32:31.174602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev_features = list(train_df.columns)","metadata":{"id":"5ZwbE2TZhgKb","execution":{"iopub.status.busy":"2021-08-27T18:32:31.176289Z","iopub.status.idle":"2021-08-27T18:32:31.176953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('train_pred_1.csv')\ndf2 = pd.read_csv('train_pred_2.csv')\ndf3 = pd.read_csv('train_pred_3.csv')\ndf4 = pd.read_csv('train_pred_4.csv')\ndf5 = pd.read_csv('train_pred_5.csv')\ndf6 = pd.read_csv('train_pred_6.csv')\ndf7 = pd.read_csv('train_pred_7.csv')\ndf8 = pd.read_csv('train_pred_8.csv')\ndf9 = pd.read_csv('train_pred_9.csv')\ndf10 = pd.read_csv('train_pred_10.csv')\ndf11 = pd.read_csv('train_pred_11.csv')\n\ndf_test1 = pd.read_csv('test_pred_1.csv')\ndf_test2 = pd.read_csv('test_pred_2.csv')\ndf_test3 = pd.read_csv('test_pred_3.csv')\ndf_test4 = pd.read_csv('test_pred_4.csv')\ndf_test5 = pd.read_csv('test_pred_5.csv')\ndf_test6 = pd.read_csv('test_pred_6.csv')\ndf_test7 = pd.read_csv('test_pred_7.csv')\ndf_test8 = pd.read_csv('test_pred_8.csv')\ndf_test9 = pd.read_csv('test_pred_9.csv')\ndf_test10 = pd.read_csv('test_pred_10.csv')\ndf_test11 = pd.read_csv('test_pred_11.csv')","metadata":{"id":"ilz0c-p_ZFu7","execution":{"iopub.status.busy":"2021-08-27T18:32:31.178304Z","iopub.status.idle":"2021-08-27T18:32:31.17897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.merge(df1, on='id', how='left')\ntrain_df = train_df.merge(df2, on='id', how='left')\ntrain_df = train_df.merge(df3, on='id', how='left')\ntrain_df = train_df.merge(df4, on='id', how='left')\ntrain_df = train_df.merge(df5, on='id', how='left')\ntrain_df = train_df.merge(df6, on='id', how='left')\ntrain_df = train_df.merge(df7, on='id', how='left')\ntrain_df = train_df.merge(df8, on='id', how='left')\ntrain_df = train_df.merge(df9, on='id', how='left')\ntrain_df = train_df.merge(df10, on='id', how='left')\ntrain_df = train_df.merge(df11, on='id', how='left')\n\ntest_df = test_df.merge(df_test1, on='id', how='left')\ntest_df = test_df.merge(df_test2, on='id', how='left')\ntest_df = test_df.merge(df_test3, on='id', how='left')\ntest_df = test_df.merge(df_test4, on='id', how='left')\ntest_df = test_df.merge(df_test5, on='id', how='left')\ntest_df = test_df.merge(df_test6, on='id', how='left')\ntest_df = test_df.merge(df_test7, on='id', how='left')\ntest_df = test_df.merge(df_test8, on='id', how='left')\ntest_df = test_df.merge(df_test9, on='id', how='left')\ntest_df = test_df.merge(df_test10, on='id', how='left')\ntest_df = test_df.merge(df_test11, on='id', how='left')","metadata":{"id":"SenzLkPWgv4c","execution":{"iopub.status.busy":"2021-08-27T18:32:31.180953Z","iopub.status.idle":"2021-08-27T18:32:31.181861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = list(train_df.columns)\nblend_features = [feat for feat in cols if str(feat).startswith('pred')]\nprint(blend_features)","metadata":{"id":"uWdWgYBlhARg","execution":{"iopub.status.busy":"2021-08-27T18:32:31.193604Z","iopub.status.idle":"2021-08-27T18:32:31.194677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Linear Regression","metadata":{"id":"vP2ibWn5qSLL"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = LinearRegression()\n    model.fit(train[blend_features].values, train[target].values)\n\n    valid_pred = model.predict(valid[blend_features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict(test[blend_features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_1']\nvalid_pred_all.to_csv('L1_train_pred_1.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_1'] = test_pred_all\nsub_2.to_csv('L1_test_pred_1.csv', index=False)","metadata":{"id":"v-5Q5fsyhATg","execution":{"iopub.status.busy":"2021-08-27T18:32:31.196301Z","iopub.status.idle":"2021-08-27T18:32:31.197216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Random Forest","metadata":{"id":"fpi2ifRxrvkd"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = RandomForestRegressor(n_estimators=500, n_jobs=4, max_depth=3)\n    model.fit(train[blend_features].values, train[target].values)\n\n    valid_pred = model.predict(valid[blend_features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict(test[blend_features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_2']\nvalid_pred_all.to_csv('L1_train_pred_2.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_2'] = test_pred_all\nsub_2.to_csv('L1_test_pred_2.csv', index=False)","metadata":{"id":"NgfQ1Lrxruz8","execution":{"iopub.status.busy":"2021-08-27T18:32:31.198684Z","iopub.status.idle":"2021-08-27T18:32:31.199614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Gradient Boosting Regressor","metadata":{"id":"rTZDO2pSsMdJ"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = GradientBoostingRegressor(n_estimators=500, max_depth=3)\n    model.fit(train[blend_features].values, train[target].values)\n\n    valid_pred = model.predict(valid[blend_features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict(test[blend_features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_3']\nvalid_pred_all.to_csv('L1_train_pred_3.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_3'] = test_pred_all\nsub_2.to_csv('L1_test_pred_3.csv', index=False)","metadata":{"id":"NWp38NozqtTh","execution":{"iopub.status.busy":"2021-08-27T18:32:31.201093Z","iopub.status.idle":"2021-08-27T18:32:31.202018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. XGBoost","metadata":{"id":"Gme_r7GEsdj-"}},{"cell_type":"code","source":"test_pred_all = None\nvalid_pred_all = {}\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = XGBRegressor(\n        random_state = 1,\n        booster = 'gbtree',\n        n_estimators = 7000,\n        learning_rate = 0.03,\n        max_depth = 2,\n        n_jobs = 4\n    )\n    model.fit(train[blend_features].values, train[target].values,\n              eval_set = [(valid[blend_features].values, valid[target].values)],\n              eval_metric = 'rmse',\n              early_stopping_rounds = 300,\n              verbose=False)\n\n    valid_pred = model.predict(valid[blend_features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict(test[blend_features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_4']\nvalid_pred_all.to_csv('L1_train_pred_4.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_4'] = test_pred_all\nsub_2.to_csv('L1_test_pred_4.csv', index=False)","metadata":{"id":"oQ_MV50Cse-2","execution":{"iopub.status.busy":"2021-08-27T18:32:31.20365Z","iopub.status.idle":"2021-08-27T18:32:31.214875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking (L2 Model)","metadata":{"id":"sGAOHlvFtbOc"}},{"cell_type":"code","source":"train_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(test_file_path)\nsub_df = pd.read_csv(sample_sub_file_path)","metadata":{"id":"4Jqnt-MsuIua","execution":{"iopub.status.busy":"2021-08-27T18:32:31.216548Z","iopub.status.idle":"2021-08-27T18:32:31.217521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev_features = list(train_df.columns)","metadata":{"id":"o2YkEWtgtyv3","execution":{"iopub.status.busy":"2021-08-27T18:32:31.21902Z","iopub.status.idle":"2021-08-27T18:32:31.219941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('L1_train_pred_1.csv')\ndf2 = pd.read_csv('L1_train_pred_2.csv')\ndf3 = pd.read_csv('L1_train_pred_3.csv')\ndf4 = pd.read_csv('L1_train_pred_4.csv')\n\ndf_test1 = pd.read_csv('L1_test_pred_1.csv')\ndf_test2 = pd.read_csv('L1_test_pred_2.csv')\ndf_test3 = pd.read_csv('L1_test_pred_3.csv')\ndf_test4 = pd.read_csv('L1_test_pred_4.csv')","metadata":{"id":"85Pt1iIYtajh","execution":{"iopub.status.busy":"2021-08-27T18:32:31.22133Z","iopub.status.idle":"2021-08-27T18:32:31.222231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.merge(df1, on='id', how='left')\ntrain_df = train_df.merge(df2, on='id', how='left')\ntrain_df = train_df.merge(df3, on='id', how='left')\ntrain_df = train_df.merge(df4, on='id', how='left')\n\ntest_df = test_df.merge(df_test1, on='id', how='left')\ntest_df = test_df.merge(df_test2, on='id', how='left')\ntest_df = test_df.merge(df_test3, on='id', how='left')\ntest_df = test_df.merge(df_test4, on='id', how='left')","metadata":{"id":"DrOTfJVrtyyg","execution":{"iopub.status.busy":"2021-08-27T18:32:31.223854Z","iopub.status.idle":"2021-08-27T18:32:31.224865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = list(train_df.columns)\nstack_features = [feat for feat in cols if str(feat).startswith('pred')]\nprint(stack_features)","metadata":{"id":"rtcYFTT9ty3a","execution":{"iopub.status.busy":"2021-08-27T18:32:31.22648Z","iopub.status.idle":"2021-08-27T18:32:31.227526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_all = None\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    model = LinearRegression()\n    model.fit(train[stack_features].values, train[target].values)\n\n    valid_pred = model.predict(valid[stack_features].values)\n    test_pred = model.predict(test[stack_features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)} Coeff: {model.coef_[0]}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['target'] = test_pred_all\nsub_2.to_csv('Stacked_Submission_1.csv', index=False)","metadata":{"id":"gCyvaekxty5l","execution":{"iopub.status.busy":"2021-08-27T18:32:31.229102Z","iopub.status.idle":"2021-08-27T18:32:31.230105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_all = None\nall_rmse = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    model = RandomForestRegressor(n_estimators=600, n_jobs=4, max_depth=5)\n    model.fit(train[stack_features].values, train[target].values)\n\n    valid_pred = model.predict(valid[stack_features].values)\n    test_pred = model.predict(test[stack_features].values)\n    rmse = mean_squared_error(valid[target].values, valid_pred, squared=False)\n    all_rmse.append(rmse)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} RMSE: {round(rmse, 4)}')\n    \nprint('')\nprint(f'Average RMSE: {round(np.mean(all_rmse), 4)} Std: {round(np.std(all_rmse), 4)}')\ntest_pred_all /= train_df['kfold'].nunique()\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['target'] = test_pred_all\nsub_2.to_csv('Stacked_Submission_2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T18:32:31.23189Z","iopub.status.idle":"2021-08-27T18:32:31.233021Z"},"trusted":true},"execution_count":null,"outputs":[]}]}