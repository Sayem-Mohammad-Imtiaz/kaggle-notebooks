{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Temporal feature selection with shap values\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade 'lightgbm>=3.0.0'\n!pip install \"pycaret\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport pdb\nimport warnings\nimport seaborn as sns\nimport shap\n\nfrom sklearn import metrics\nfrom pycaret.classification import *\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import log_loss, f1_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.feature_extraction import stop_words\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom lightgbm import LGBMClassifier\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (12, 4)\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STOP_WORDS = ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'é', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estão', 'você', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'será', 'nós', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\nCLUB_WORDS = [\"verdão\", \"tricolor\", \"fla\", \"timão\", \"rubro\", \n              \"negro\", \"flamengo\", \"paulo\", \"palmeirense\", \"paulista\", \n              \"inter\", \"colorado\", \"internacional\", \"colorados\", \"colorada\"]\nSTOP_WORDS += CLUB_WORDS\nMAX_VOCABULARY = 1000\npositive_case = \"flamengo\"\ntrain_end_date = \"2018-01\"\nholdout_end_date = \"2020-10\"\ntarget = \"target\"\ntime_column = \"year-month\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_small_data_period(data):\n    data = data[(data[\"year-month\"] < \"2015-12\") | (data[\"year-month\"] > \"2016-08\")]   \n    return data \n\ndef exclude_periods_without_positive_case(data, positive_case, period_column, threshold=20):\n    df = data.groupby(period_column)[\"club\"].apply(lambda x: np.sum(x == positive_case))\n    df = df[df > threshold]\n    return data[data[period_column].isin(df.index)]\n    \ndef clean_club_name_from_article(data):\n    data[\"text\"] = data.apply(lambda x: x[\"text\"].lower().replace(x[\"club\"].replace(\"-\", \" \"), \"\"), axis=1)\n    return data\n\ndef exclude_numbers(data):\n    data[\"text\"] = data[\"text\"].apply(lambda x: ''.join([i for i in x.lower() if not i.isdigit()]))\n    return data\n\ndef drop_multiple_teams_news(data):\n    multiple_team_news = data.groupby(\"link\", as_index=False)[\"club\"].count()\n    multiple_team_news = multiple_team_news[multiple_team_news[\"club\"] > 1][\"link\"]\n    return data[~data[\"link\"].isin(multiple_team_news)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/ge-soccer-clubs-news/ge_news.csv\", index_col=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = clean_club_name_from_article(data)\ndata = exclude_numbers(data)\ndata = drop_multiple_teams_news(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[:, \"year\"] = data[\"date\"].apply(lambda x: x.split(\"/\")[-1])\ndata.loc[:, \"month\"] = data[\"date\"].apply(lambda x: x.split(\"/\")[1])\ndata.loc[:, \"date\"] = pd.to_datetime(data[\"date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Monthly context\ndata[\"year-month\"] = data[\"year\"] + \"-\" + data[\"month\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"target\"] = data[\"club\"].apply(lambda x: 1 if x == positive_case else 0)\n\nprint(\"The fraction of positive cases is {:.2f}\".format(data[\"target\"].mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = exclude_periods_without_positive_case(data, positive_case, \"year-month\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_time = data[data[\"year-month\"] < train_end_date]\n\ntrain, test = train_test_split(in_time, \n                               test_size=0.2, \n                               random_state=42)\n\nout_of_time = data[(data[\"year-month\"] >= train_end_date) & (data[\"year-month\"] <= holdout_end_date)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dataset shapes:\")\nprint(\"Train: {}\".format(train.shape))\nprint(\"Test: {}\".format(test.shape))\nprint(\"Out of time: {}\".format(out_of_time.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculating Features instability"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=MAX_VOCABULARY,\n                                 stop_words=STOP_WORDS,\n                                 binary=True,\n                                 use_idf=True)\n\nvectorizer = vectorizer.fit(train[\"text\"])\n\ntrain_vectors = pd.DataFrame(vectorizer.transform(train[\"text\"]).toarray(), columns=vectorizer.vocabulary_)\ntest_vectors = pd.DataFrame(vectorizer.transform(test[\"text\"]).toarray(), columns=vectorizer.vocabulary_)\noot_vectors = pd.DataFrame(vectorizer.transform(out_of_time[\"text\"]).toarray(), columns=vectorizer.vocabulary_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier()\nmodel.fit(train_vectors, train[\"target\"].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"experiment_dict = {}\nfor period in in_time[time_column].unique():\n    print(period)\n    in_time_period = in_time[in_time[time_column] == period]\n    test_period = test[test[time_column] == period]\n\n    test_vectors_ = pd.DataFrame(vectorizer.transform(test_period[\"text\"]).toarray(), columns=vectorizer.vocabulary_)\n    predictions = model.predict(test_vectors_, pred_contrib=True)\n    experiment_dict[period] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance = []\nfor key, value in experiment_dict.items():\n    shap_contrib = np.abs(value[:, :-1]).mean(0)\n    df = pd.DataFrame(shap_contrib.reshape(1, MAX_VOCABULARY), columns=vectorizer.vocabulary_)\n    df[\"period\"] = key\n    importance.append(df)\n\nimportance = pd.concat(importance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average = importance.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deviation = importance.std() / average","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deviation.fillna(0, inplace=True)\ndeviation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_average_contrib = average.median()\nmedian_std_contrib = deviation.median()\n\nmedian_average_contrib = np.percentile(average, 50)\nmedian_std_contrib = np.percentile(deviation, 80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(average, deviation)\n\nxmin, xmax, ymin, ymax = plt.axis()\nplt.hlines(median_std_contrib, xmin, xmax, linestyle=\"dotted\", color=\"red\")\nplt.vlines(median_average_contrib, ymin, ymax, linestyle=\"dotted\", color=\"red\")\nplt.legend(bbox_to_anchor=(1.05, 1.0))\nplt.title(\"Contribution x Instability\")\nplt.ylabel(\"Instability\")\nplt.xlabel(\"Contribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggregate_importance = pd.DataFrame()\naggregate_importance[\"average\"] = average.values\naggregate_importance[\"instability\"] = deviation.values\naggregate_importance.index = average.index\n\naggregate_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = (aggregate_importance[\"average\"] >= median_average_contrib) & (aggregate_importance[\"instability\"] <= median_std_contrib)\nstable_features = aggregate_importance[mask].index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing a model using stable features Vs model using all features"},{"metadata":{},"cell_type":"markdown","source":"### Benchmark (All features)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_vectors = pd.DataFrame(vectorizer.transform(train[\"text\"]).toarray(), columns=vectorizer.vocabulary_)\ntest_vectors = pd.DataFrame(vectorizer.transform(test[\"text\"]).toarray(), columns=vectorizer.vocabulary_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_time_data = pd.DataFrame(vectorizer.transform(in_time[\"text\"]).toarray(), columns=vectorizer.vocabulary_)\nin_time_data[target] = in_time[target].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = setup(in_time_data, target=target,\n                      session_id=123, \n                      log_experiment=True, \n                      experiment_name=\"exp1\",\n            silent=True)\n\nlgbm = create_model(\"lightgbm\")\n\ntuned_lgbm = tune_model(lgbm,\n                        fold=5,\n                        n_iter=50,\n                        optimize=\"AUC\")\n\nbest = automl(optimize = 'AUC')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = best\nmodel.fit(train_vectors, train[\"target\"].values)\npredictions = model.predict_proba(test_vectors)[:, 1]\ntest[\"benchmark\"] = predictions\nroc_auc_score(test[\"target\"], predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_proba(oot_vectors)[:, 1]\nout_of_time[\"benchmark\"] = predictions\nroc_auc_score(out_of_time[\"target\"], predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_of_time.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"benchmark\"])).plot()\nplt.title(\"AUC for the out of time set (unseen future data)\")\nplt.xlabel(\"Period (monthly)\")\nplt.ylabel(\"AUC\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_of_time.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"benchmark\"])).rolling(6).mean().plot()\nplt.title(\"Moving average AUC with a 6 months window in the out of time set\")\nplt.ylabel(\"AUC\")\nplt.xlabel(\"Period (monthly)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stable features model (challenger)"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf2 = setup(in_time_data[list(stable_features) + [target]], target=target,\n                      session_id=123, \n                      log_experiment=True, \n                      experiment_name=\"exp1\",\n                     silent=True)\n\nlgbm = create_model(\"lightgbm\")\n\ntuned_lgbm = tune_model(lgbm,\n                        fold=5,\n                        n_iter=50,\n                        optimize=\"AUC\")\n\nbest = automl(optimize = 'AUC')\nmodel = best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_vectors[stable_features], train[\"target\"].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_proba(test_vectors[stable_features], pred_contrib=True)\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(test_vectors[stable_features])\nshap.summary_plot(shap_values, test_vectors[stable_features], plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_proba(test_vectors[stable_features])[:, 1]\ntest[\"temporal_prediction\"] = predictions\nprint(roc_auc_score(test[\"target\"], predictions))\npredictions = model.predict_proba(oot_vectors[stable_features])[:, 1]\nout_of_time[\"temporal_prediction\"] = predictions\nprint(roc_auc_score(out_of_time[\"target\"], predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([test, out_of_time]).groupby(\"year\").apply(lambda x: roc_auc_score(x[target], x[\"benchmark\"])).plot(label=\"All features (benchmark)\")\npd.concat([test, out_of_time]).groupby(\"year\").apply(lambda x: roc_auc_score(x[target], x[\"temporal_prediction\"])).plot(label=\"Stable features(challenger)\", \n                                                                                                                        color=\"green\")\nplt.legend()\nplt.title(\"AUC\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([test, out_of_time]).groupby(\"year\").apply(lambda x: log_loss(x[target], x[\"benchmark\"])).plot(label=\"All features (benchmark)\")\npd.concat([test, out_of_time]).groupby(\"year\").apply(lambda x: log_loss(x[target], x[\"temporal_prediction\"])).plot(label=\"Stable features(challenger)\", color=\"green\")\nplt.legend()\nplt.title(\"Log loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"benchmark\"])).plot(label=\"All features (benchmark)\")\npd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"temporal_prediction\"])).plot(label=\"Stable features(challenger)\")\nplt.legend()\nplt.title(\"AUC\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 4))\npd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"benchmark\"])).rolling(6).mean().plot(label=\"All features (benchmark)\")\npd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"temporal_prediction\"])).rolling(6).mean().plot(label=\"Stable features (challenger)\", color=\"green\")\n\nxmin, xmax, ymin, ymax = plt.axis()\ntrain_end_date_position = np.argmax(np.sort(pd.concat([test, out_of_time])[time_column].unique()) == train_end_date)\nplt.vlines(train_end_date_position, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Out of time split\")\nplt.legend()\nplt.title(\"Moving average AUC with a 6 months window for both test and out of time periods\", pad=16)\nplt.ylabel(\"AUC\")\nplt.xlabel(\"Period (monthly)\")\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}