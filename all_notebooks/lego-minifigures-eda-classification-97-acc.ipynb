{"cells":[{"metadata":{},"cell_type":"markdown","source":"# *** LEGO Minifigures EDA + Classification (97% Accuracy) [Beginner-Friendly] ***\n# ![LEGO](https://www.kindpng.com/picc/m/115-1158040_lego-figures-png-transparent-lego-characters-png-png.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**In this guide, I will provide a full tutorial on how to do EDA / apply MobilNetV2 model to classify 22 Lego mini-figure classes, please put an upvote if you like this notebook**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> 1. Importing libraries\n> 2. Importing Dataset\n> 3. Exploratory Data Analysis (EDA)\n> 4. Data Generator Class\n> 5. Data Augmentation\n> 6. Train/Test splitting / Generators\n> 7. Model Definition (MobilNetV2)\n> 8. Training the model\n> 9. Accuracy / Loss visualization\n> 10. Final validation\n> 11. Confusion Matrix\n> 12. Visualizing good predictions\n> 13. Visualizing wrong predictions\n> 14. Reference","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport math\nimport seaborn as sn\nimport albumentations as A\nimport tensorflow as tf\nfrom tensorflow.keras.applications import mobilenet_v2 as tf_mobilenet_v2\nfrom tensorflow.keras import layers as tf_layers\nfrom tensorflow.keras import models as tf_models\nfrom tensorflow.keras import callbacks as tf_callbacks\nfrom sklearn import metrics as sk_metrics\nfrom IPython.display import YouTubeVideo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('7vtpUklKlsk', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_PATH = '../input/lego-minifigures-classification'\n\ndf_index = pd.read_csv(os.path.join(DATASET_PATH, 'index.csv'), index_col=0)\ndf_metadata = pd.read_csv(os.path.join(DATASET_PATH, 'metadata.csv'), index_col=0)\ndf_index = pd.merge(df_index, df_metadata[['class_id', 'minifigure_name']], on='class_id')\n\ndf_index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis (EDA)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Visualizing number of images per unique minifigure_name","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('iedmZlFxjfA', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df_index['minifigure_name'].value_counts().plot(\n    kind='bar',\n    figsize=(14,8),\n    title=\"Count of each mini-figure\",\n)\n\nax.set_xlabel(\"Mini-figure\")\nax.set_ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing image examples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('Ql8QPcp8818', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nfor ind, el in enumerate(df_index.sample(15).iterrows(), 1):\n    plt.subplot(3, 5, ind)\n    image = cv2.imread(os.path.join(DATASET_PATH, el[1]['path']))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.title(f\"{el[1]['class_id']}: {el[1]['minifigure_name']}\")\n    plt.xticks([])\n    plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing image examples for class \"Spider-Man'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nfor ind, el in enumerate(df_index[df_index['minifigure_name']=='SPIDER-MAN'].sample(15).iterrows(), 1):\n    plt.subplot(3, 5, ind)\n    image = cv2.imread(os.path.join(DATASET_PATH, el[1]['path']))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Generator Class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('oy5EeamF_M8', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(\n        self, \n        paths, \n        targets, \n        image_size=(224, 224), \n        batch_size=64, \n        shuffle=True, \n        transforms=None\n    ):\n        # the list of paths to files\n        self.paths = paths\n        # the list with the true labels of each file\n        self.targets = targets\n        # images size\n        self.image_size = image_size\n        # batch size (the number of images)\n        self.batch_size = batch_size\n        # if we need to shuffle order of files\n        # for validation we don't need to shuffle, for training - do\n        self.shuffle = shuffle\n        # Augmentations for our images. It is implemented with albumentations library\n        self.transforms = transforms\n        \n        # Call function to create and shuffle (if needed) indices of files\n        self.on_epoch_end()\n        \n    def on_epoch_end(self):\n        # This function is called at the end of each epoch while training\n        \n        # Create as many indices as many files we have\n        self.indexes = np.arange(len(self.paths))\n        # Shuffle them if needed\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __len__(self):\n        # We need that this function returns the number of steps in one epoch\n        \n        # How many batches we have\n        return len(self.paths) // self.batch_size\n    \n    \n    def __getitem__(self, index):\n        # This function returns batch of pictures with their labels\n        \n        # Take in order as many indices as our batch size is\n        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n        \n        # Take image file paths that are included in that batch\n        batch_paths = [self.paths[k] for k in indexes]\n        # Take labels for each image\n        batch_y = [self.targets[k] - 1 for k in indexes]\n        batch_X = []\n        for i in range(self.batch_size):\n            # Read the image\n            img = cv2.imread(batch_paths[i])\n            # Resize it to needed shape\n            img = cv2.resize(img, self.image_size)\n            # Convert image colors from BGR to RGB\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            # Normalize image\n            img = img / 255.\n            # Apply transforms (see albumentations library)\n            if self.transforms:\n                img = self.transforms(image=img)['image']\n            \n            batch_X.append(img)\n            \n        return np.array(batch_X), np.array(batch_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('hxLU32zhze0', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose(\n        [\n            A.Rotate(limit=30, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=20, max_w_size=20, fill_value=0, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=20, max_w_size=20, fill_value=1, p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.RandomContrast(p=0.5),\n            A.Blur(p=0.5),\n        ], \n        p=1.0\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-Test Splitting / Generators","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = '../input/lego-minifigures-classification/'\n\n# Read information about dataset\ndf = pd.read_csv('../input/lego-minifigures-classification/index.csv', index_col=0)\n\n# Get only train rows\ntmp_train = df[df['train-valid'] == 'train']\n# Get train file paths\ntrain_paths = tmp_train['path'].values\n# Get train labels\ntrain_targets = tmp_train['class_id'].values\n# Create full train paths (base dir + concrete file)\ntrain_paths = list(map(lambda x: os.path.join(BASE_DIR, x), train_paths))\n\n# Get only valid rows\ntmp_valid = df[df['train-valid'] == 'valid']\n# Get valid file paths\nvalid_paths = tmp_valid['path'].values\n# Get valid labels\nvalid_targets = tmp_valid['class_id'].values\n# Create full valid paths (base dir + concrete file)\nvalid_paths = list(map(lambda x: os.path.join(BASE_DIR, x), valid_paths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = (512, 512)\n\nTRAIN_BATCH_SIZE = 4\n\nVALID_BATCH_SIZE = 1 \n\n# Initialize the train data generator\ntrain_generator = DataGenerator(\n    train_paths, \n    train_targets, \n    batch_size=TRAIN_BATCH_SIZE, \n    image_size=IMAGE_SIZE,\n    shuffle=True, \n    transforms=get_train_transforms()\n)\n\n# Initialize the valid data generator\nvalid_generator = DataGenerator(\n    valid_paths, \n    valid_targets, \n    image_size=IMAGE_SIZE,\n    batch_size=VALID_BATCH_SIZE, \n    shuffle=False,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Definition (MobilNetV2)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('OO4HD-1wRN8', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We define the number of classes\nN_CLASSES = 22\n\n# We take pretrained MobileNetV2 (see Keras docs)\nbase_model = tf_mobilenet_v2.MobileNetV2()\n# Take penultimate layer of the MobileNetV2 model and connect this layer with Dropout\nx = tf_layers.Dropout(.5)(base_model.layers[-2].output)\n# Add additional Dense layer, with number of neurons as number of our classes\n# Use softmax activation because we have one class classification problem\noutputs = tf_layers.Dense(N_CLASSES, activation='softmax')(x)\n# Create model using MobileNetV2 input and our created output\nmodel = tf_models.Model(base_model.inputs, outputs)\n\n\n# Compile model using Adam optimizer and categorical crossentropy loss\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checkpoint to saving the best model by validation loss\ncallback_save = tf_callbacks.ModelCheckpoint(\n    'best.hdf5',\n    monitor=\"val_loss\",\n    save_best_only=True,\n    mode=\"min\",\n)\n\n# checkpoint to stop training if model didn't improve valid loss for 3 epochs\ncallback_early_stopping = tf_callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=3,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 25\n\n# Train model using data generators\nhistory = model.fit(\n    train_generator,\n    validation_data=valid_generator,\n    epochs=EPOCHS,\n    callbacks=[\n        callback_save, \n        callback_early_stopping\n    ],\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy / Loss visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('apmNSYWEEnw', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='valid loss')\nplt.grid()\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='valid acc')\nplt.grid()\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf_models.load_model('best.hdf5')\n\ny_pred = []\ny_valid = []\nfor _X_valid, _y_valid in valid_generator:\n    y_pred.extend(model.predict(_X_valid).argmax(axis=-1))\n    y_valid.extend(_y_valid)\n\nprint(f'Accuracy score on validation data:  {sk_metrics.accuracy_score(y_valid, y_pred)}')\nprint(f'Macro F1 score on validation data:  {sk_metrics.f1_score(y_valid, y_pred, average=\"macro\")}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"YouTubeVideo('Kdsp6soqA7o', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_metadata = pd.read_csv('../input/lego-minifigures-classification/metadata.csv')\nlabels = df_metadata['minifigure_name'].tolist()\n\nconfusion_matrix = sk_metrics.confusion_matrix(y_valid, y_pred)\ndf_confusion_matrix = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\nplt.figure(figsize=(12, 12))\nsn.heatmap(df_confusion_matrix, annot=True, cbar=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing good predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"true_images = []\ntrue_label = []\ntrue_pred = []\n\nfor _X_valid, _y_valid in valid_generator:\n    pred = model.predict(_X_valid).argmax(axis=-1)\n    if pred[0] == _y_valid:\n        true_images.extend(_X_valid)\n        true_label.extend(_y_valid)\n        true_pred.extend(pred)\n\ntrue_images = true_images[:4]\n\nfor ind, image in enumerate(true_images):\n    plt.subplot(math.ceil(len(true_images) / int(len(true_images) ** 0.5)), int(len(true_images) ** 0.5), ind + 1)\n    plt.imshow(image)\n    plt.title(f'Predicted: {labels[true_pred[ind]]} | Real: {labels[true_label[ind]]}')\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing wrong predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"error_images = []\nerror_label = []\nerror_pred = []\n\nfor _X_valid, _y_valid in valid_generator:\n    pred = model.predict(_X_valid).argmax(axis=-1)\n    if pred[0] != _y_valid:\n        error_images.extend(_X_valid)\n        error_label.extend(_y_valid)\n        error_pred.extend(pred)\n\nerror_images = error_images[:4]\n\nfor ind, image in enumerate(error_images):\n    plt.subplot(math.ceil(len(error_images) / int(len(error_images) ** 0.5)), int(len(error_images) ** 0.5), ind + 1)\n    plt.imshow(image)\n    plt.title(f'Predicted: {labels[error_pred[ind]]} | Real: {labels[error_label[ind]]}')\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reference","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I was highly inspired by the following notebooks by @ihelon\n1. [LEGO Minifigures - EDA](https://www.kaggle.com/ihelon/lego-minifigures-eda/notebook)\n2. [LEGO Minifigures - TF Modeling](https://www.kaggle.com/ihelon/lego-minifigures-tf-modeling)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}