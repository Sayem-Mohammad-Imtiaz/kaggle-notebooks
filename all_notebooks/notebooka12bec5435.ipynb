{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"224ac3c3-a3b7-7380-d8fc-9e337fa17cb2"},"outputs":[],"source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom random import seed\nfrom random import randrange\nfrom csv import reader\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a07e8548-4a31-a083-fa00-5bd15eb6f86d"},"outputs":[],"source":"# Load a CSV file\ndef load_csv(filename):\n\tfile = open(filename, \"r\")\n\tlines = reader(file)\n\tdataset = list(lines)\n\treturn dataset\n \n# Convert string column to float\ndef str_column_to_float(dataset, column):\n\tfor row in dataset:\n\t\trow[column] = float(row[column].strip())\n \n# Split a dataset into k folds\ndef cross_validation_split(dataset, n_folds):\n\tdataset_split = list()\n\tdataset_copy = list(dataset)\n\tfold_size = int(len(dataset) / n_folds)\n\tfor i in range(n_folds):\n\t\tfold = list()\n\t\twhile len(fold) < fold_size:\n\t\t\tindex = randrange(len(dataset_copy))\n\t\t\tfold.append(dataset_copy.pop(index))\n\t\tdataset_split.append(fold)\n\treturn dataset_split\n \n# Calculate accuracy percentage\ndef accuracy_metric(actual, predicted):\n\tcorrect = 0\n\tfor i in range(len(actual)):\n\t\tif actual[i] == predicted[i]:\n\t\t\tcorrect += 1\n\treturn correct / float(len(actual)) * 100.0\n \n# Evaluate an algorithm using a cross validation split\ndef evaluate_algorithm(dataset, algorithm, n_folds, *args):\n\tfolds = cross_validation_split(dataset, n_folds)\n\tscores = list()\n\tfor fold in folds:\n\t\ttrain_set = list(folds)\n\t\ttrain_set.remove(fold)\n\t\ttrain_set = sum(train_set, [])\n\t\ttest_set = list()\n\t\tfor row in fold:\n\t\t\trow_copy = list(row)\n\t\t\ttest_set.append(row_copy)\n\t\t\trow_copy[-1] = None\n\t\tpredicted = algorithm(train_set, test_set, *args)\n\t\tactual = [row[-1] for row in fold]\n\t\taccuracy = accuracy_metric(actual, predicted)\n\t\tscores.append(accuracy)\n\treturn scores\n \n# Split a dataset based on an attribute and an attribute value\ndef test_split(index, value, dataset):\n\tleft, right = list(), list()\n\tfor row in dataset:\n\t\tif row[index] < value:\n\t\t\tleft.append(row)\n\t\telse:\n\t\t\tright.append(row)\n\treturn left, right\n \n# Calculate the Gini index for a split dataset\ndef gini_index(groups, class_values):\n\tgini = 0.0\n\tfor class_value in class_values:\n\t\tfor group in groups:\n\t\t\tsize = len(group)\n\t\t\tif size == 0:\n\t\t\t\tcontinue\n\t\t\tproportion = [row[-1] for row in group].count(class_value) / float(size)\n\t\t\tgini += (proportion * (1.0 - proportion))\n\treturn gini\n \n# Select the best split point for a dataset\ndef get_split(dataset):\n\tclass_values = list(set(row[-1] for row in dataset))\n\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n\tfor index in range(len(dataset[0])-1):\n\t\tfor row in dataset:\n\t\t\tgroups = test_split(index, row[index], dataset)\n\t\t\tgini = gini_index(groups, class_values)\n\t\t\tif gini < b_score:\n\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n \n# Create a terminal node value\ndef to_terminal(group):\n\toutcomes = [row[-1] for row in group]\n\treturn max(set(outcomes), key=outcomes.count)\n \n# Create child splits for a node or make terminal\ndef split(node, max_depth, min_size, depth):\n\tleft, right = node['groups']\n\tdel(node['groups'])\n\t# check for a no split\n\tif not left or not right:\n\t\tnode['left'] = node['right'] = to_terminal(left + right)\n\t\treturn\n\t# check for max depth\n\tif depth >= max_depth:\n\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n\t\treturn\n\t# process left child\n\tif len(left) <= min_size:\n\t\tnode['left'] = to_terminal(left)\n\telse:\n\t\tnode['left'] = get_split(left)\n\t\tsplit(node['left'], max_depth, min_size, depth+1)\n\t# process right child\n\tif len(right) <= min_size:\n\t\tnode['right'] = to_terminal(right)\n\telse:\n\t\tnode['right'] = get_split(right)\n\t\tsplit(node['right'], max_depth, min_size, depth+1)\n \n# Build a decision tree\ndef build_tree(train, max_depth, min_size):\n\troot = get_split(train)\n\tsplit(root, max_depth, min_size, 1)\n\treturn root\n \n# Make a prediction with a decision tree\ndef predict(node, row):\n\tif row[node['index']] < node['value']:\n\t\tif isinstance(node['left'], dict):\n\t\t\treturn predict(node['left'], row)\n\t\telse:\n\t\t\treturn node['left']\n\telse:\n\t\tif isinstance(node['right'], dict):\n\t\t\treturn predict(node['right'], row)\n\t\telse:\n\t\t\treturn node['right']\n \n# Classification and Regression Tree Algorithm\ndef decision_tree(train, test, max_depth, min_size):\n\ttree = build_tree(train, max_depth, min_size)\n\tpredictions = list()\n\tfor row in test:\n\t\tprediction = predict(tree, row)\n\t\tpredictions.append(prediction)\n\treturn(predictions)\n \n# Test CART on Bank Note dataset\n#seed(1)\n# load and prepare data\nfilename = '../input/Pokemon.csv'\ndataset = load_csv(filename)\n# convert string attributes to integers\nfor i in range(len(dataset[2])):\n    if (i==0):\n        i++;\n\tstr_column_to_float(dataset, i)\n# evaluate algorithm\nn_folds = 5\nmax_depth = 5\nmin_size = 10\nscores = evaluate_algorithm(dataset, decision_tree, n_folds, max_depth, min_size)\nprint('Scores: %s' % scores)\nprint('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}