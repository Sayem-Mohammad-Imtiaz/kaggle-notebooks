{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re, string\nfrom requests import get\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import RegexpTokenizer\nimport spacy\nnlp = spacy.load('en_core_web_sm')\n\nfrom PIL import Image\nfrom io import BytesIO\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport warnings\n\nwarnings.simplefilter(action = \"ignore\", category = FutureWarning)\npd.options.mode.chained_assignment = None","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-03T16:40:53.660613Z","iopub.execute_input":"2021-08-03T16:40:53.661449Z","iopub.status.idle":"2021-08-03T16:40:57.924618Z","shell.execute_reply.started":"2021-08-03T16:40:53.661325Z","shell.execute_reply":"2021-08-03T16:40:57.923518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"episodes = pd.read_csv(\"../input/south-park-scripts-dataset/SouthPark_Episodes.csv\")\ndisplay(episodes.head())\nprint(episodes.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:57.926233Z","iopub.execute_input":"2021-08-03T16:40:57.926638Z","iopub.status.idle":"2021-08-03T16:40:57.975596Z","shell.execute_reply.started":"2021-08-03T16:40:57.926599Z","shell.execute_reply":"2021-08-03T16:40:57.974576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lines = pd.read_csv(\"../input/south-park-scripts-dataset/SouthPark_Lines.csv\")\ndisplay(lines.head())\nprint(lines.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:57.977249Z","iopub.execute_input":"2021-08-03T16:40:57.977564Z","iopub.status.idle":"2021-08-03T16:40:58.382499Z","shell.execute_reply.started":"2021-08-03T16:40:57.977533Z","shell.execute_reply":"2021-08-03T16:40:58.381217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title_episodelist = episodes.Title.tolist()\ntitle_lineslist = lines.Title.tolist()\n\n[x for x in title_episodelist if x not in title_lineslist]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:58.384462Z","iopub.execute_input":"2021-08-03T16:40:58.384916Z","iopub.status.idle":"2021-08-03T16:40:58.610347Z","shell.execute_reply.started":"2021-08-03T16:40:58.384878Z","shell.execute_reply":"2021-08-03T16:40:58.60931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rename_titles = {\"Imaginationland\": \"Imaginationland Episode I\",\n                 \"REHASH\": \"#REHASH\",\n                 \"HappyHolograms\": \"#HappyHolograms\",\n                 \"Shots\": \"Shots!!!\"}\n\nlines[\"Title\"].replace(rename_titles, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:58.611825Z","iopub.execute_input":"2021-08-03T16:40:58.61213Z","iopub.status.idle":"2021-08-03T16:40:58.647741Z","shell.execute_reply.started":"2021-08-03T16:40:58.6121Z","shell.execute_reply":"2021-08-03T16:40:58.646507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = episodes.merge(lines, on = \"Title\")\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:58.649196Z","iopub.execute_input":"2021-08-03T16:40:58.649682Z","iopub.status.idle":"2021-08-03T16:40:58.719271Z","shell.execute_reply.started":"2021-08-03T16:40:58.649618Z","shell.execute_reply":"2021-08-03T16:40:58.718454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df[\"Line\"].notnull()]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:58.720374Z","iopub.execute_input":"2021-08-03T16:40:58.720841Z","iopub.status.idle":"2021-08-03T16:40:58.764294Z","shell.execute_reply.started":"2021-08-03T16:40:58.720796Z","shell.execute_reply":"2021-08-03T16:40:58.76341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Act\"] = df.Line.apply(lambda x: re.findall(r\"\\[.*?]\", x) if \"[\" in x else \"None\")\ndf[\"Act\"] = df[\"Act\"].astype(str)\ndf[\"Act\"] = df[\"Act\"].str.replace(\"[\", \"\").str.replace(\"]\", \"\", regex = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:58.766496Z","iopub.execute_input":"2021-08-03T16:40:58.767012Z","iopub.status.idle":"2021-08-03T16:40:59.191928Z","shell.execute_reply.started":"2021-08-03T16:40:58.76696Z","shell.execute_reply":"2021-08-03T16:40:59.191072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Line2\"] = df[\"Line\"].str.replace(r\"\\[.*?]\", \"\", regex = True)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:59.193387Z","iopub.execute_input":"2021-08-03T16:40:59.193895Z","iopub.status.idle":"2021-08-03T16:40:59.36939Z","shell.execute_reply.started":"2021-08-03T16:40:59.193844Z","shell.execute_reply":"2021-08-03T16:40:59.368199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"contractions = { \n\"ain't\": \"am not / are not / is not / has not / have not\",\n\"aren't\": \"are not / am not\",\n\"can't\": \"can not\",\n\"can't've\": \"can not have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he had / he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he shall / he will\",\n\"he'll've\": \"he shall have / he will have\",\n\"he's\": \"he has / he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how has / how is / how does\",\n\"I'd\": \"I had / I would\",\n\"I'd've\": \"I would have\",\n\"I'll\": \"I shall / I will\",\n\"I'll've\": \"I shall have / I will have\",\n\"I'm\": \"I am\",\n\"I've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it had / it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it shall / it will\",\n\"it'll've\": \"it shall have / it will have\",\n\"it's\": \"it has / it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she had / she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she shall / she will\",\n\"she'll've\": \"she shall have / she will have\",\n\"she's\": \"she has / she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as / so is\",\n\"that'd\": \"that would / that had\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that has / that is\",\n\"there'd\": \"there had / there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there has / there is\",\n\"they'd\": \"they had / they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they shall / they will\",\n\"they'll've\": \"they shall have / they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had / we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what shall / what will\",\n\"what'll've\": \"what shall have / what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what has / what is\",\n\"what've\": \"what have\",\n\"when's\": \"when has / when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where has / where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who shall / who will\",\n\"who'll've\": \"who shall have / who will have\",\n\"who's\": \"who has / who is\",\n\"who've\": \"who have\",\n\"why's\": \"why has / why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you had / you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you shall / you will\",\n\"you'll've\": \"you shall have / you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\",\n\"wanna\": \"want to\",\n\"gonna\": \"going to\",\n\"gotta\": \"have got to\"\n}","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-03T16:40:59.370966Z","iopub.execute_input":"2021-08-03T16:40:59.371278Z","iopub.status.idle":"2021-08-03T16:40:59.389884Z","shell.execute_reply.started":"2021-08-03T16:40:59.371251Z","shell.execute_reply":"2021-08-03T16:40:59.388887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_stopwords = nlp.Defaults.stop_words\n\ndef tokenizer(text):\n    \n    text = text.replace(\"in'\", \"ing\")\n    text = text.replace(\"m'kay\", \"mkay\")\n    tokens = text.split()\n    tokens = [re.sub(token, contractions[token], token) if token in contractions.keys() else token for token in tokens]\n    tokens = [token.strip(string.punctuation) for token in tokens]    \n    tokens = [token.lower() for token in tokens]    \n    tokens = [token for token in tokens if token.isalpha()]\n    tokens = [token for token in tokens if len(token) > 1]\n    tokens = [token for token in tokens if token not in all_stopwords]\n\n#     n = lambda pos: pos[:2].startswith(\"N\")\n#     tokens = [word for (word, pos) in nltk.pos_tag(tokens) if n(pos)] \n    \n    lemmatizer = nltk.wordnet.WordNetLemmatizer()\n    lemmas = [lemmatizer.lemmatize(token, \"v\")  if token != \"butters\" else \"butters\" for token in tokens]\n    lemmas = [lemmatizer.lemmatize(token)  if token != \"butters\" else \"butters\" for token in lemmas]\n    lemmas = [lemma for lemma in lemmas if lemma not in [\"think\", \"know\", \"come\", \"want\", \"look\", \"right\", \"try\",\n                                                         \"need\", \"say\", \"yes\", \"good\", \"okay\", \"people\", \"time\", \"tell\",\n                                                         \"talk\", \"stop\", \"thing\", \"mean\", \"maybe\", \"let\"]]  \n    \n    lemmas = [lemma.replace(lemma, \"guys\") if lemma == \"guy\" else lemma for lemma in lemmas]    \n    return \" \".join(lemmas)\n\ndf[\"Lines_Final\"] = df[\"Line2\"].apply(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:40:59.391169Z","iopub.execute_input":"2021-08-03T16:40:59.391607Z","iopub.status.idle":"2021-08-03T16:41:09.202036Z","shell.execute_reply.started":"2021-08-03T16:40:59.391573Z","shell.execute_reply":"2021-08-03T16:41:09.201211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:, -4:]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:09.203061Z","iopub.execute_input":"2021-08-03T16:41:09.203483Z","iopub.status.idle":"2021-08-03T16:41:09.229882Z","shell.execute_reply.started":"2021-08-03T16:41:09.203452Z","shell.execute_reply":"2021-08-03T16:41:09.229051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_dict = {\"Cartman\": \"https://i.imgur.com/DtPNaXk.png\",\n            \"Kyle\": \"https://i.imgur.com/5vBEIri.png\",\n            \"Kenny\": \"https://i.imgur.com/IbHV3iA.png\",\n            \"Stan\": \"https://i.imgur.com/Pl94sMm.png\",\n            \"Randy\": \"https://i.imgur.com/EgMCfsr.png\",\n            \"Mr. Mackey\": \"https://i.imgur.com/bdJE2SB.png\",\n            \"Butters\": \"https://i.imgur.com/EQAUV7i.png\"}","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:09.231029Z","iopub.execute_input":"2021-08-03T16:41:09.231472Z","iopub.status.idle":"2021-08-03T16:41:09.23646Z","shell.execute_reply.started":"2021-08-03T16:41:09.231439Z","shell.execute_reply":"2021-08-03T16:41:09.235246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_wordcloud(character, max_words = 500):\n    \n    character_df = df[df.Character == character]\n    txt = \" \".join(character_df[\"Lines_Final\"].values)    \n    \n    im = Image.open(BytesIO(get(img_dict[character]).content))\n    mask = np.array(im)\n    colors = ImageColorGenerator(mask)\n    \n    fig, ax = plt.subplots(figsize = (15, 15))\n    \n    stopwords = set(STOPWORDS)\n    \n    wc = WordCloud(background_color = \"black\", \n                   max_words = max_words, \n                   mask = mask, # shape\n                   stopwords = stopwords, \n                   width = 1000, \n                   height = 1000,\n                   color_func = colors,\n                   collocations = True, #bigrams\n                   contour_color = 'white',\n                   contour_width = 1,\n                   normalize_plurals = False, #For Butters\n                   min_word_length = 3,\n                   random_state = 42).generate(txt)\n\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    plt.savefig(character + \".png\")\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:09.237961Z","iopub.execute_input":"2021-08-03T16:41:09.23839Z","iopub.status.idle":"2021-08-03T16:41:09.255083Z","shell.execute_reply.started":"2021-08-03T16:41:09.238357Z","shell.execute_reply":"2021-08-03T16:41:09.254002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(\"Cartman\", 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:09.256386Z","iopub.execute_input":"2021-08-03T16:41:09.256797Z","iopub.status.idle":"2021-08-03T16:41:12.347485Z","shell.execute_reply.started":"2021-08-03T16:41:09.256762Z","shell.execute_reply":"2021-08-03T16:41:12.346181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(\"Stan\", 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:12.348786Z","iopub.execute_input":"2021-08-03T16:41:12.349094Z","iopub.status.idle":"2021-08-03T16:41:14.726714Z","shell.execute_reply.started":"2021-08-03T16:41:12.349064Z","shell.execute_reply":"2021-08-03T16:41:14.725581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(\"Kenny\", 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:14.728058Z","iopub.execute_input":"2021-08-03T16:41:14.72837Z","iopub.status.idle":"2021-08-03T16:41:17.658302Z","shell.execute_reply.started":"2021-08-03T16:41:14.728332Z","shell.execute_reply":"2021-08-03T16:41:17.657223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(\"Kyle\", 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:17.659505Z","iopub.execute_input":"2021-08-03T16:41:17.659808Z","iopub.status.idle":"2021-08-03T16:41:20.159509Z","shell.execute_reply.started":"2021-08-03T16:41:17.659779Z","shell.execute_reply":"2021-08-03T16:41:20.158551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(\"Butters\", 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:20.160948Z","iopub.execute_input":"2021-08-03T16:41:20.161242Z","iopub.status.idle":"2021-08-03T16:41:22.30037Z","shell.execute_reply.started":"2021-08-03T16:41:20.161213Z","shell.execute_reply":"2021-08-03T16:41:22.29921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(\"Randy\", 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:22.301921Z","iopub.execute_input":"2021-08-03T16:41:22.30225Z","iopub.status.idle":"2021-08-03T16:41:24.296563Z","shell.execute_reply.started":"2021-08-03T16:41:22.302221Z","shell.execute_reply":"2021-08-03T16:41:24.295472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(\"Mr. Mackey\", 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T16:41:24.297862Z","iopub.execute_input":"2021-08-03T16:41:24.298147Z","iopub.status.idle":"2021-08-03T16:41:25.917432Z","shell.execute_reply.started":"2021-08-03T16:41:24.298121Z","shell.execute_reply":"2021-08-03T16:41:25.916231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}