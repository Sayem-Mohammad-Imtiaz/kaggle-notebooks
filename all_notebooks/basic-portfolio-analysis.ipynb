{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Basic Notions of Portfolio Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Installing Pyfolio and PyPortfolioOpt","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"! pip install pyfolio\n! pip install PyPortfolioOpt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### All Imports","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport pyfolio as pf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display, HTML\n\nfrom pypfopt.efficient_frontier import EfficientFrontier\nfrom pypfopt import risk_models\nfrom pypfopt import expected_returns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Useful Functions","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def join_df_list(df_list, tolerance):\n    \"\"\"\n    Performs the merge_asof in a list of dfs\n    using 'tolerance' as tolerance.\n\n    :param df_list: list of data frames\n    :type df_list: [pd.DataFrame]\n    :param tolerance: difference of days between\n                      data frames that can be\n                      tolerated\n    :type tolerance: pd.Timestamp\n    :return: merged dataframe\n    :rtype: pd.DataFrame\n    \"\"\"\n    size = len(df_list)\n    df = pd.merge_asof(df_list[0], df_list[1],\n                       left_index=True,\n                       right_index=True,\n                       tolerance=tolerance)\n    for i in range(2, size):\n        df = pd.merge_asof(df, df_list[i],\n                           left_index=True,\n                           right_index=True,\n                           tolerance=tolerance)\n    return df\n\n\ndef show_clean_p(p):\n    p_show = p.transpose()[p.transpose() > 0.001].dropna()\n    p_show = p_show.transpose()\n    p_show = (p_show.transpose()[0]).map(lambda x: \"{:.1%}\".format(x)).to_frame().transpose()\n    display(HTML(p_show.to_html()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## All Ibovespa Tickers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ibov = [\"ABEV3\", \"AZUL4\", \"B3SA3\", \"BBAS3\", \"BBDC3\", \"BBDC4\", \"BBSE3\", \"BPAC11\", \"BRAP4\",\n        \"BRDT3\", \"BRFS3\", \"BRKM5\", \"BRML3\", \"BTOW3\", \"CCRO3\", \"CIEL3\", \"CMIG4\", \"COGN3\", \"CRFB3\",\n        \"CSAN3\", \"CSNA3\", \"CVCB3\", \"CYRE3\", \"ECOR3\", \"EGIE3\", \"ELET3\", \"ELET6\", \"EMBR3\", \"ENBR3\",\n        \"EQTL3\", \"FLRY3\", \"GGBR4\", \"GNDI3\", \"GOAU4\", \"GOLL4\", \"HAPV3\", \"HGTX3\", \"HYPE3\", \"IGTA3\",\n        \"IRBR3\", \"ITSA4\", \"ITUB4\", \"JBSS3\", \"KLBN11\", \"LAME4\", \"LREN3\", \"MGLU3\", \"MRFG3\", \"MRVE3\", \"MULT3\",\n        \"NTCO3\", \"PCAR4\", \"PETR3\", \"PETR4\", \"QUAL3\", \"RADL3\", \"RAIL3\", \"RENT3\", \"SANB11\", \"SBSP3\", \"SMLS3\",\n        \"SULA11\", \"SUZB3\", \"TAEE11\", \"TIMP3\", \"TOTS3\", \"UGPA3\", \"USIM5\", \"VALE3\", \"VIVT4\", \"VVAR3\", \"WEGE3\", \"YDUQ3\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Market Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(path)\ndf.loc[:, \"datetime\"] = df.datetime.map(pd.Timestamp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting the tickers using a start date","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sort = df.set_index([\"ticker\", \"datetime\"]).sort_index()\nstart_date = \"2016-02-02\"\n\n\nibov_mini = []\nfor ticker in ibov:\n    ts = df_sort.xs(ticker)\n    if ts.index.min() <= pd.Timestamp(start_date):\n        ibov_mini.append(ticker)\n\ndel df_sort\n\nratio = len(ibov_mini)/len(ibov)\nprint(\"percentage of ibov's tickers that will be used in the analysis = {:.1%}\".format(ratio))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sort = df.set_index([\"datetime\"]).sort_index()\ndf_sort = df_sort[df_sort.index >= start_date]\ndf_sort = df_sort[df_sort.ticker.isin(ibov_mini)]\ndf_train = df_sort[df_sort.index < \"2019-01-01\"]\ndf_test = df_sort[df_sort.index >= \"2019-01-01\"]\n\ndel df_sort\n\ndf_train = df_train.reset_index().set_index([\"ticker\", \"datetime\"]).sort_index()\ndf_test = df_test.reset_index().set_index([\"ticker\", \"datetime\"]).sort_index()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Getting all close prices ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_prices = []\n\nfor ticker in ibov_mini:\n    series = df_train.xs(ticker).close\n    series.name = ticker\n    all_prices.append(series.to_frame())\n    \nall_prices = join_df_list(all_prices, tolerance=pd.Timedelta(\"10days\"))\n\n# dealing with missing data\nall_prices = all_prices.dropna(1)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First example, two naive types of portfolios:\n - **Portfolio 1**: Uniform weights\n - **Portfolio 2**: Concentrated on Banks ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ibov_mini = list(all_prices.columns)\n\nn_ibov = len(ibov_mini)\n\n\nuniform_weigths = np.ones((n_ibov)) / n_ibov\nbanks_weigths = np.ones((n_ibov))/ n_ibov\np1 = pd.DataFrame([uniform_weigths], columns=ibov_mini)\np2 = pd.DataFrame([banks_weigths], columns=ibov_mini)\n\np2.loc[:, \"ITSA4\"] = 0.2\np2.loc[:, \"ITUB4\"] = 0.2\np2.loc[:, \"BBDC3\"] = 0.2\np2.loc[:, \"BBDC4\"] = 0.2\n\np2 = p2 / p2.sum(1)[0]\n\nuniform_weigths = p1.values.flatten()\nbanks_weigths = p2.values.flatten()\n\n\n\n\nprint(\"\\nportfolio 1:\\n\")\np1_show = (p1.transpose()[0]).map(lambda x: \"{:.1%}\".format(x)).to_frame().transpose()\ndisplay(HTML(p1_show.to_html()))\n\nprint(\"\\nportfolio 2:\\n\")\np2_show = (p2.transpose()[0]).map(lambda x: \"{:.1%}\".format(x)).to_frame().transpose()\ndisplay(HTML(p2_show.to_html()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting Prices Drawdown","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ticker = \"BBDC4\"\nprices = all_prices[ticker]\nwindow = 250\n\ndef get_daily_max_drawdown(prices, window):\n    max_rolling = prices.rolling(min_periods=1, window=window).max()\n    daily_drawdown = (prices / max_rolling) - 1\n    max_daily_drawdown = daily_drawdown.rolling(min_periods=1, window=window).min()\n    return daily_drawdown,max_daily_drawdown\n\nmax_rolling = prices.rolling(min_periods=1, window=window).max()\n\ndaily_drawdown, max_daily_drawdown = get_daily_max_drawdown(prices, window)\ndaily_drawdown.name = \"{} daily drawdown\".format(ticker)  \n\nfig, ax = plt.subplots(figsize=(10,5))\ndaily_drawdown.plot();\nplt.legend(loc=\"best\");\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using the average daily return to calculate portfolio return","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"returns = all_prices.pct_change()\nmean_daily_returns = returns.mean().values\n\np1_return = np.dot(mean_daily_returns, uniform_weigths)\np2_return = np.dot(mean_daily_returns, banks_weigths)\n\nprint(\"portfolio 1 average daily return = {:.4%}\".format(p1_return))\nprint(\"portfolio 2 average daily return = {:.4%}\".format(p2_return))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Annualized return, variance and standart deviation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_annualized_return(prices, weigths):\n    months = (prices.index[-1] - prices.index[0]) / np.timedelta64(1, 'M')\n    months = np.floor(months)\n    total_return = (prices.iloc[-1].dot(weigths) - prices.iloc[0].dot(weigths)) / prices.iloc[0].dot(weigths)\n    annualized_return = ((1 + total_return) ** (12 / months)) - 1\n    return annualized_return\n\n\np1_annual_return = get_annualized_return(all_prices, uniform_weigths)\np2_annual_return = get_annualized_return(all_prices, banks_weigths)\n\ndef get_portfolio_variance(returns, weigths):\n    covariance_returns = returns.cov() * 250\n    return np.dot(weigths.T, np.dot(covariance_returns, weigths))\n\nuni_var = get_portfolio_variance(returns, uniform_weigths)\nbanks_var = get_portfolio_variance(returns, banks_weigths)\n\nprint(\"portfolio 1 annualized return = {:.4%}\".format(p1_annual_return))\nprint(\"portfolio 1 annualized variance = {:.1%}\".format(uni_var))\nprint(\"portfolio 1 annualized std = {:.1%}\".format(np.sqrt(uni_var)))\nprint()\nprint(\"portfolio 2 annualized return = {:.4%}\".format(p2_annual_return))\nprint(\"portfolio 2 annualized variance = {:.1%}\".format(banks_var))\nprint(\"portfolio 2 annualized std = {:.1%}\".format(np.sqrt(banks_var)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sharpe and Sortino ratio","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"uniform_returns = returns.dot(uniform_weigths)\nbanks_returns = returns.dot(banks_weigths)\n\nrfr = 0.0425\n\np1_vol = uniform_returns.std() * np.sqrt(250)\np2_vol = banks_returns.std() * np.sqrt(250)\n\np1_sharpe_ratio = ((p1_annual_return  - rfr) / p1_vol)\np2_sharpe_ratio = ((p2_annual_return  - rfr) / p2_vol)\n\ndef get_sortino(return_, target_return, rfr):\n    negative_return_ = return_.loc[return_ < target_return]\n    expected_return = return_.mean()\n    down_std = negative_return_.std()\n    sortino_ratio = (expected_return - rfr) / down_std\n    return sortino_ratio\n\n\np1_sortino_ratio = get_sortino(uniform_returns, target_return=0, rfr=rfr)\np2_sortino_ratio = get_sortino(banks_returns, target_return=0, rfr=rfr)\n\nprint(\"portfolio 1 sharpe ratio = {:.2f}\".format(p1_sharpe_ratio))\nprint(\"portfolio 1 sortino ratio = {:.2f}\".format(p1_sortino_ratio))\nprint()\nprint(\"portfolio 2 sharpe ratio = {:.2f}\".format(p2_sharpe_ratio))\nprint(\"portfolio 2 sortino ratio = {:.2f}\".format(p2_sortino_ratio))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the cummulative return","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"uniform_cum_returns = (1 + uniform_returns).cumprod()\nuniform_cum_returns.name = \"portifolio 1: uniform weights\"\n\nbanks_cum_returns = (1 + banks_returns).cumprod()\nbanks_cum_returns.name = \"portifolio 2: concentrated on banks\"\n\nfig, ax = plt.subplots(figsize=(16,8))\nbanks_cum_returns.plot(ax=ax, color=\"mediumorchid\");\nuniform_cum_returns.plot(ax=ax, color=\"red\");\n\nplt.legend(loc=\"best\");\nax.set_ylabel(\"cummulative return\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using PyportfolioOpt for portfolio optimization\n\n\n### Three types of optimized portfolios:\n\n   - Maximun Sharpe portfolios\n   - Minimum volatility portfolio\n   - Maximun Sharpe portfolios obtained by exponentially weighted returns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mu = expected_returns.mean_historical_return(all_prices)\nSigma = risk_models.sample_cov(all_prices)\nef = EfficientFrontier(mu,Sigma)\nbest_sharpe_p = pd.DataFrame(ef.max_sharpe(), index=[0])\n\nprint(\"max sharpe portfolio:\")\nshow_clean_p(best_sharpe_p)\n\n_ = ef.portfolio_performance(verbose=True, risk_free_rate=rfr)\n\nprint()\n\nmin_vol_p = pd.DataFrame(ef.min_volatility(), index=[0])\n\nprint(\"min vol portfolio:\")\nshow_clean_p(min_vol_p)\n\n_ = ef.portfolio_performance(verbose=True, risk_free_rate=rfr)\n\nmu_ema = expected_returns.ema_historical_return(all_prices, span=252, frequency=252)\nSigma_ew = risk_models.exp_cov(all_prices, span=180, frequency=252)\nef_ew = EfficientFrontier(mu_ema, Sigma_ew)\n\n\nmax_sharpe_ew_p = pd.DataFrame(ef_ew.max_sharpe(), index=[0])\n\nprint()\n\nprint(\"max sharpe portfolio with exponetially weighted returns:\")\nshow_clean_p(max_sharpe_ew_p)\n\n_ = ef_ew.portfolio_performance(verbose=True, risk_free_rate=rfr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Backtesting (2016-2018)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_sharpe_weights = best_sharpe_p.values.flatten()\nbest_sharpe_returns = returns.dot(best_sharpe_weights)\nbest_sharpe_cum_returns = (1 + best_sharpe_returns).cumprod()\nbest_sharpe_cum_returns.name = \"best sharpe portfolio\"\n\n\nbest_sharpe_ew_weights = max_sharpe_ew_p.values.flatten()\nbest_sharpe_ew_returns = returns.dot(best_sharpe_ew_weights)\nbest_sharpe_ew_cum_returns = (1 + best_sharpe_ew_returns).cumprod()\nbest_sharpe_ew_cum_returns.name = \"best sharpe portfolio by ew opt\"\n\n\n\n\nmin_vol_weights = min_vol_p.values.flatten()\nmin_vol_returns = returns.dot(min_vol_weights)\nmin_vol_cum_returns = (1 + min_vol_returns).cumprod()\nmin_vol_cum_returns.name = \"minimum volatility portfolio\"\n\n\nfig, ax = plt.subplots(figsize=(16,8))\nbest_sharpe_cum_returns.plot(ax=ax, color=\"darkorange\");\nmin_vol_cum_returns.plot(ax=ax, color=\"dodgerblue\")\nbest_sharpe_ew_cum_returns.plot(ax=ax, color=\"seagreen\")\nuniform_cum_returns.plot(ax=ax, color=\"red\");\nplt.legend(loc=\"best\");\nax.set_ylabel(\"cummulative return\");\nax.set_title(\"Backtest based on the data from 2016 to 2018\", fontsize=20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Eval (2019-2020)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_prices_test = []\n\nfor ticker in ibov_mini:\n    series = df_test.xs(ticker).close\n    series.name = ticker\n    all_prices_test.append(series)\n    \nreturns_test = pd.DataFrame(all_prices_test).transpose().pct_change()\n\nest_sharpe_weights = best_sharpe_p.values.flatten()\nbest_sharpe_returns = returns_test.dot(best_sharpe_weights)\nbest_sharpe_cum_returns = (1 + best_sharpe_returns).cumprod()\nbest_sharpe_cum_returns.name = \"best sharpe portfolio\"\n\nbest_sharpe_ew_weights = max_sharpe_ew_p.values.flatten()\nbest_sharpe_ew_returns = returns_test.dot(best_sharpe_ew_weights)\nbest_sharpe_ew_cum_returns = (1 + best_sharpe_ew_returns).cumprod()\nbest_sharpe_ew_cum_returns.name = \"best sharpe portfolio by ew opt\"\n\nmin_vol_weights = min_vol_p.values.flatten()\nmin_vol_returns = returns_test.dot(min_vol_weights)\nmin_vol_cum_returns = (1 + min_vol_returns).cumprod()\nmin_vol_cum_returns.name = \"minimum volatility portfolio\"\n\n\nuniform_returns = returns_test.dot(uniform_weigths)\nuniform_cum_returns = (1 + uniform_returns).cumprod()\nuniform_cum_returns.name = \"portifolio 1: uniform weights\"\n\n\nfig, ax = plt.subplots(figsize=(16,8))\nbest_sharpe_cum_returns.plot(ax=ax, color=\"darkorange\");\nmin_vol_cum_returns.plot(ax=ax, color=\"dodgerblue\")\nbest_sharpe_ew_cum_returns.plot(ax=ax, color=\"seagreen\")\nuniform_cum_returns.plot(ax=ax, color=\"red\");\nplt.legend(loc=\"best\");\nax.set_ylabel(\"cummulative return\");\nax.set_title(\"Evaluating the optimized portfolios using the data from 2019 to 2020\", fontsize=20);\n\nps_cum = [best_sharpe_cum_returns, min_vol_cum_returns, best_sharpe_ew_cum_returns]\nps = [best_sharpe_returns, min_vol_returns, best_sharpe_ew_returns]\n\nfinal_return = []\nfor p in ps_cum:\n    final_return.append(p.iloc[-1])\n    \nid_ = np.argmax(final_return)\nbest_p = ps[id_]\nbest_p.name = (ps_cum[id_]).name \n\nprint(\"Best portfolio: \",  best_p.name)\nprint(\"Final cumulative return: {:.2f} \".format(final_return[id_]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using Pyfolio to analyse the best portfolio for 2019-2020","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"uniform_returns.name = \"Benchmark: uniform weights\"\npf.create_returns_tear_sheet(best_p.dropna(), benchmark_rets=uniform_returns.dropna())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}