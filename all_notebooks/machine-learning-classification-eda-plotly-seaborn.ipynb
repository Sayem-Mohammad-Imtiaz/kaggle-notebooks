{"cells":[{"metadata":{"_uuid":"5aa1e76fe0e84f235ae275f63273d30c202dde3a"},"cell_type":"markdown","source":"# INTRODUCTION\n\n**In this kernel,**\nWe will apply the machine learning algorithms on our data.Then we will find which machine learning algorithm is the best for our data at the end of tutorial.\n\n\n**Content:**\n1. [Exploratory Data Analysis (EDA)](#1)\n2. [EDA Visualization](#2)\n   2. [Correlation Map](#3)\n   2. [Pair Plot](#4)\n   2. [Scatter Matrix](#5)\n   2. [Scatter Matrix-Abnormal Class](#23)\n   2. [Scatter Matrix-Normal Class](#24)\n3. [Data PreProcessing](#6)\n   3. [Normalization Data](#7)\n   3. [Train-Test Split Data](#8)\n4. [Machine Learning Classification Models](#9)\n      4. [Logistic Regression Classification](#10)\n      4. [K-Nearest Neighbors (KNN) Classification](#11)\n         4. [Model Complexity](#12)\n      4. [Support Vector Machine(SVM) Classification](#13)\n      4. [Naive Bayes Classification](#14)\n      4. [Decision Tree Classification](#15)\n      4. [Random Forest Classification](#16)\n5. [Evaluation Classification Models](#17)\n   5. [Confusion Matrixes Comparison](#18)\n   5. [Bar Charts Comparison](#19)\n6. [Conclusion](#20)   "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# plotly\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff # import figure factory\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89cd3afe3f6940af41642272b4ee4f08757f919f"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# Exploratory Data Analysis (EDA)"},{"metadata":{"_uuid":"32337491623096afbc96fc419200b20c9024b0ef"},"cell_type":"markdown","source":"### Import Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/column_2C_weka.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6abe13934a2fbff00b557a037f36e4a5d7946b1"},"cell_type":"code","source":"# to see features and target variable\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6b87c566da376cebbfc23cf8669566e8407e7db"},"cell_type":"code","source":"# Display the content of data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26efb0a05980e20efc078669c89d751479e34bad"},"cell_type":"markdown","source":"As you can see:\n\n* length: 310 (range index)\n* Features are float\n* Target variables are object that is like string"},{"metadata":{"trusted":true,"_uuid":"a996657a5becf0056b106dfa063a284a0084cd27"},"cell_type":"code","source":"# shape gives number of rows and columns in a tuple\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31c32f145a6e2309a509056bdc7cccd1cdf4268b"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc3830cac5eb35f625369d585a8274e72eb1e65d"},"cell_type":"code","source":"# Display positive and negative correlation between columns\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adb9c0e02a3e4c29ddf785946ebc474672a4ae64"},"cell_type":"code","source":"#sorts all correlations with ascending sort.\ndf.corr().unstack().sort_values().drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"400222e361aa9f75a9671b3771556fc757dc57d3"},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n# EDA Visualization"},{"metadata":{"_uuid":"e63575c6a77c4755bd738b056b1119b9fb348127"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n#### Correlation Map"},{"metadata":{"trusted":true,"_uuid":"9542d40506deeea08155bbe8eb8bee8b0ca2ccf9"},"cell_type":"code","source":"#correlation map\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(df.corr(), annot=True, linewidth=\".5\", cmap=\"RdPu\", fmt=\".2f\", ax = ax)\nplt.title(\"Correlation Map\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"21\"></a> <br>\n### Pair Plot"},{"metadata":{"trusted":true,"_uuid":"ecb0eedd64add6f7888d25f89e0733dabb0b0209"},"cell_type":"code","source":"sns.pairplot(data=df,hue=\"class\",palette=\"Set1\")\nplt.suptitle(\"Pair Plot of Data\",fontsize=20)\nplt.show()   # pairplot without standard deviaton fields of data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30f5dc6d2798ad14fc1b7f954705e68a2f2f1d1c"},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n### Scatter Matrix"},{"metadata":{"_uuid":"b3fc80a8f204cc17082ba5bf672abd21c0acb1c0"},"cell_type":"markdown","source":"**pd.plotting.scatter_matrix:**\n* green: *normal* and red: *abnormal*\n* c:  color\n* figsize: figure size\n* diagonal: histohram of each features\n* alpha: opacity\n* s: size of marker\n* marker: marker type "},{"metadata":{"trusted":true,"_uuid":"30de8bdea7c4955c77672a366aa50e24502e4e13"},"cell_type":"code","source":"color_list = [\"red\" if each==\"Abnormal\" else \"cyan\" for each in df.loc[:,\"class\"]]\npd.plotting.scatter_matrix(df.loc[:, df.columns != \"class\"],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal=\"hist\",\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = \"*\",\n                                       edgecolor= \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"baa717f62c6d7e44ccd79fcb234956add89dc4f8"},"cell_type":"markdown","source":"<a id=\"23\"></a> <br>\n### Scatter Matrix-Abnormal Class"},{"metadata":{"trusted":true,"_uuid":"d9c704a3699dc68b648c8dfce1a3a2ef2b8b41ca"},"cell_type":"code","source":"df_abnormal = df[df[\"class\"]==\"Abnormal\"]\npd.plotting.scatter_matrix(df_abnormal.loc[:, df_abnormal.columns != \"class\"],\n                                       c=\"red\",\n                                       figsize= [15,15],\n                                       diagonal=\"hist\",\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = \"*\",\n                                       edgecolor= \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2a0b79c24f61bc48f3b5d1a4c7da5434aab182c"},"cell_type":"markdown","source":"<a id=\"24\"></a> <br>\n### Scatter Matrix-Normal Class"},{"metadata":{"trusted":true,"_uuid":"d69e41068c24179c82e65e9f9e1df2064a0867ef"},"cell_type":"code","source":"df_normal = df[df['class']=='Normal']\npd.plotting.scatter_matrix(df_normal.loc[:, df_normal.columns != \"class\"],\n                                       c=\"cyan\",\n                                       figsize= [15,15],\n                                       diagonal=\"hist\",\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = \"*\",\n                                       edgecolor= \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad8224ad953dec474273108799ab701b8806f84c"},"cell_type":"code","source":"# prepare data\ndata1 = len(df[\"class\"][df[\"class\"] == \"Abnormal\"])\ndata2 = len(df[\"class\"][df[\"class\"] == \"Normal\"])\n\ndata = [go.Bar(\n            x=[\"Abnormal\",\"Normal\"],\n            y=[data1,data2],\n            marker=dict(color='rgb(158,202,225)',\n            line=dict(color='rgba(254, 69, 62, 1)',\n            width=1.5),\n        ),\n    opacity=0.6\n    )]\n\niplot(data, filename='text-hover-bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"519c165374c5073575b92ccffd4fed488a4099c1"},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n# Data PreProcessing "},{"metadata":{"trusted":true,"_uuid":"38b762fce4205ba799ca5cb7b5f3fe12877f5709"},"cell_type":"code","source":"df[\"class\"] = [0 if each == \"Abnormal\" else 1 for each in df[\"class\"]]\n\ny = df[\"class\"].values\nx_data = df.drop([\"class\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04d4ca541f4ab33034289df2bb7c8769668ed6d4"},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n### Normalization Data"},{"metadata":{"_uuid":"1c4a12ff15b89a939c899af81ca932dc20e2fd3c"},"cell_type":"markdown","source":"* Normalization Formula = (x - min(x))/(max(x)-min(x))"},{"metadata":{"trusted":true,"_uuid":"c6d259be9611fb2ae8a15150fba48b958d278c11"},"cell_type":"code","source":"x = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b3c0a7b31a1ce6e8f6f39f171111ba14568b7c3"},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3191ce2940c0ea10bb8f0746833806150b049b83"},"cell_type":"code","source":"x.isnull().sum() #Indicates values not defined in our data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21b4705478faeeed1fc1c4fe7f3b72ec22696fec"},"cell_type":"code","source":"x.isnull().sum().sum()  #Indicates sum of values in our data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"301600a4d3a797b21c9d8e97374b165372032e4d"},"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96f4434fa8011cf2e431d0db68ef1e38a8a6ec90"},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\n### Train-Test Split Data"},{"metadata":{"trusted":true,"_uuid":"81bff28a559560eda9fbca09014689a450a4445e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=1)\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_test: \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cf73f3c601dbca149041453368b9cf4f7d1ab84"},"cell_type":"markdown","source":"<a id=\"9\"></a> <br>\n# Machine Learning Classification Models"},{"metadata":{"_uuid":"49f85730196e6b5cefb3d0678e56509148f1a587"},"cell_type":"markdown","source":"<a id=\"10\"></a> <br>\n### Logistic Regression Classification"},{"metadata":{"trusted":true,"_uuid":"8689a67fbfcc6b99e199c4c2c5b14bee8446044d"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression()\nlr_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nlr_train_accuracy = lr_model.score(x_train,y_train)\nprint(\"lr_train_accuracy = \",lr_model.score(x_train,y_train))\n#Print Test Accuracy\nlr_test_accuracy = lr_model.score(x_test,y_test)\nprint(\"lr_test_accuracy = \",lr_model.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"296acf0a11381e40b4da91bf998a4fc9241becd0"},"cell_type":"code","source":"data = [go.Bar(\n            x=[\"lr_train_accuracy\",\"lr_test_accuracy\"],\n            y=[lr_train_accuracy,lr_test_accuracy],\n            marker=dict(color='rgb(158,202,225)',\n            line=dict(color='rgba(254, 69, 62, 1)',\n            width=1.5),\n        ),\n    opacity=0.6\n    )]\n\niplot(data, filename='text-hover-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca49e4e00bbe10a43a6774f6d9433eb92d58dcfb"},"cell_type":"code","source":"y_pred = lr_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_lr = confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(cm_lr, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='RdPu', ax = ax)\nplt.xlabel = ('y_pred')\nplt.ylabel = ('y_true')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp ,fp ,fn ,tn= cm_lr.ravel()\nprint(\"lr_RECALL = \",tp/(tp+fn))\nprint(\"lr_PRECISION = \",(tp/(tp+fp)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"683abad49fb95484251aafb38cd2346169263943"},"cell_type":"markdown","source":"<a id=\"11\"></a> <br>\n## K-Nearest Neighbors (KNN) Classification"},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":true,"_uuid":"2eb1b9af0569adf0208830653301aa9072c2ff73"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nknn_train_accuracy = knn_model.score(x_train,y_train)\nprint(\"knn_train_accuracy = \",knn_model.score(x_train,y_train))\n#Print Test Accuracy\nknn_test_accuracy = knn_model.score(x_test,y_test)\nprint(\"knn_test_accuracy = \",knn_model.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eaab5b679f9df6f850f11118628b88612d42d340"},"cell_type":"markdown","source":"<a id=\"12\"></a> <br>\n### Model Complexity"},{"metadata":{"_uuid":"8dc69e1fce37a7a2d0dc24ea359a04e9ebd12848"},"cell_type":"markdown","source":"<br> Now the question is why we choose K = 3 or what value we need to choose K. The answer is in model complexity\n\n<br> **Model complexity:**\n* K has general name. It is called a hyperparameter. For now just know K is hyperparameter and we need to choose it that gives best performace. \n* Literature says if k is small, model is complex model can lead to overfit. It means that model memorizes the train sets and cannot predict test set with good accuracy.\n* If k is big, model that is less complex model can lead to underfit. \n* At below, I range K value from 1 to 30(exclude) and find accuracy for each K value. As you can see in plot, when K is 1 it memorize train sets and cannot give good accuracy on test set (overfit). Also if K is 20 or 22, model is lead to underfit. Again accuracy is not enough. However look at when K is 20 or 22(best performance), accuracy has highest value almost 82%. "},{"metadata":{"trusted":true,"_uuid":"6c7c9c0b87f478861e441c20616133bd7fc5be7e"},"cell_type":"code","source":"# Model complexity\nneighboors = np.arange(1,30)\ntrain_accuracy = []\ntest_accuracy = []\n# Loop over different values of k\nfor i, k in enumerate(neighboors):\n    # k from 1 to 30(exclude)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # fit with knn\n    knn.fit(x_train, y_train)\n    train_accuracy.append(knn.score(x_train, y_train))           # train accuracy\n    test_accuracy.append(knn.score(x_test, y_test))              # test accuracy\n\n# import graph objects as \"go\"\nimport plotly.graph_objs as go\n\n# Creating trace1\ntrace1 = go.Scatter(\n                    x = neighboors,\n                    y = train_accuracy,\n                    mode = \"lines\",\n                    name = \"train_accuracy\",\n                    marker = dict(color = 'rgba(160, 112, 2, 0.8)'),\n                    text= \"train_accuracy\")\n# Creating trace2\ntrace2 = go.Scatter(\n                    x = neighboors,\n                    y = test_accuracy,\n                    mode = \"lines+markers\",\n                    name = \"test_accuracy\",\n                    marker = dict(color = 'rgba(80, 26, 80, 0.8)'),\n                    text= \"test_accuracy\")\ndata = [trace1, trace2]\nlayout = dict(title = 'K Value vs Accuracy',\n              xaxis= dict(title= 'Number of Neighboors',ticklen= 10,zeroline= True)\n             )\nfig = dict(data = data, layout = layout)\niplot(fig)\n\nknn_train_accuracy = np.max(train_accuracy)\nknn_test_accuracy = np.max(test_accuracy)\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy), 1+test_accuracy.index(np.max(test_accuracy))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10d61d0e0e43cee6b0087ad4c8ab922323097bfc"},"cell_type":"code","source":"data = [go.Bar(\n            x=[\"knn_train_accuracy\",\"knn_test_accuracy\"],\n            y=[knn_train_accuracy,knn_test_accuracy],\n            marker=dict(color='rgb(158,202,225)',\n            line=dict(color='rgba(254, 69, 62, 1)',\n            width=1.5),\n        ),\n    opacity=0.6\n    )]\n\niplot(data, filename='text-hover-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a6bdc1bdf5f3849e1fab95b6b5ad657c1272c00"},"cell_type":"code","source":"y_pred = knn_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_knn = confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(cm_knn, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='RdPu', ax = ax)\nplt.xlabel = (\"y_pred\")\nplt.ylabel = (\"y_true\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp ,fp ,fn ,tn= cm_knn.ravel()\nprint(\"knn_RECALL = \",tp/(tp+fn))\nprint(\"knn_PRECISION = \",(tp/(tp+fp)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f3a2095df85b830f23125c601ff401b9b733d3f"},"cell_type":"markdown","source":"<a id=\"13\"></a> <br>\n### Support Vector Machine(SVM) Classification"},{"metadata":{"trusted":true,"_uuid":"07ab9dcdcad2bf4e09e1d79fa5e6412fdb29c103"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm_model = SVC(random_state=1)\nsvm_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nsvm_train_accuracy = svm_model.score(x_train,y_train)\nprint(\"svm_train_accuracy = \",svm_model.score(x_train,y_train))\n#Print Test Accuracy\nsvm_test_accuracy = svm_model.score(x_test,y_test)\nprint(\"svmr_test_accuracy = \",svm_model.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88392f491c19fa03edaf273966e58ef5c1079125"},"cell_type":"code","source":"data = [go.Bar(\n            x=[\"svm_train_accuracy\",\"svm_test_accuracy\"],\n            y=[svm_train_accuracy,svm_test_accuracy],\n            marker=dict(color='rgb(158,202,225)',\n            line=dict(color='rgba(254, 69, 62, 1)',\n            width=1.5),\n        ),\n    opacity=0.6\n    )]\n\niplot(data, filename='text-hover-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b4c944f80589e464a3c0198319c2dba8f8270ae"},"cell_type":"code","source":"y_pred = svm_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_svm = confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(cm_svm, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='RdPu', ax = ax)\nplt.xlabel = (\"y_pred\")\nplt.ylabel = (\"y_true\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp ,fp ,fn ,tn= cm_svm.ravel()\nprint(\"svm_RECALL = \",tp/(tp+fn))\nprint(\"svm_PRECISION = \",(tp/(tp+fp)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c53a90bd36ba2601e304b21a815c8ab3b5d495f"},"cell_type":"markdown","source":"<a id=\"14\"></a> <br>\n### Naive Bayes Classification"},{"metadata":{"trusted":true,"_uuid":"c5fe4016d2021742d3e66e75f7c2c60fcda55375"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb_model = GaussianNB()\nnb_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nnb_train_accuracy = nb_model.score(x_train,y_train)\nprint(\"nb_train_accuracy = \",nb_model.score(x_train,y_train))\n#Print Test Accuracy\nnb_test_accuracy = nb_model.score(x_test,y_test)\nprint(\"nb_test_accuracy = \",nb_model.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddeee162175d1546839dbbb9721e78bd355ea659"},"cell_type":"code","source":"data = [go.Bar(\n            x=[\"nb_train_accuracy\",\"nb_test_accuracy\"],\n            y=[nb_train_accuracy,nb_test_accuracy],\n            marker=dict(color='rgb(158,202,225)',\n            line=dict(color='rgba(254, 69, 62, 1)',\n            width=1.5),\n        ),\n    opacity=0.6\n    )]\n\niplot(data, filename='text-hover-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d143a5615367a8591723bfea69c464b9a074774a"},"cell_type":"code","source":"y_pred = nb_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_nb = confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(cm_nb, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='RdPu', ax = ax)\nplt.xlabel = (\"y_pred\")\nplt.ylabel = (\"y_true\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp ,fp ,fn ,tn= cm_nb.ravel()\nprint(\"nb_RECALL = \",tp/(tp+fn))\nprint(\"nb_PRECISION = \",(tp/(tp+fp)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f14312a7d1aaee0ebf550ea4a86aeeb048856af8"},"cell_type":"markdown","source":"<a id=\"15\"></a> <br>\n### Decision Tree Classification"},{"metadata":{"trusted":true,"_uuid":"9807edaf0bbe4e20fd685004ab0e9fbb6ef67688"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n#if you remove random_state=1, you can see how accuracy is changing\n#Accuracy changing depends on splits\ndt_model = DecisionTreeClassifier(random_state=1)\ndt_model.fit(x_train,y_train)\n\n#Print Train Accuracy\ndt_train_accuracy = dt_model.score(x_train,y_train)\nprint(\"dt_train_accuracy = \",dt_model.score(x_train,y_train))\n#Print Test Accuracy\ndt_test_accuracy = dt_model.score(x_test,y_test)\nprint(\"dt_test_accuracy = \",dt_model.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d59a5b599778ed778c46e3910c91dba8aea9431b"},"cell_type":"code","source":"data = [go.Bar(\n            x=[\"dt_train_accuracy\",\"dt_test_accuracy\"],\n            y=[dt_train_accuracy,dt_test_accuracy],\n            marker=dict(color='rgb(158,202,225)',\n            line=dict(color='rgba(254, 69, 62, 1)',\n            width=1.5),\n        ),\n    opacity=0.6\n    )]\n\niplot(data, filename='text-hover-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c9666ea3ab9246adb8fc566cfaf77f86fe3505c"},"cell_type":"code","source":"y_pred = dt_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_dt = confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(cm_dt, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='RdPu', ax = ax)\nplt.xlabel = (\"y_pred\")\nplt.ylabel = (\"y_true\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp ,fp ,fn ,tn= cm_dt.ravel()\nprint(\"dt_RECALL = \",tp/(tp+fn))\nprint(\"dt_PRECISION = \",(tp/(tp+fp)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e62027accc48bf4968bea83f86829a50393240d"},"cell_type":"markdown","source":"<a id=\"16\"></a> <br>\n### Random Forest Classification"},{"metadata":{"trusted":true,"_uuid":"c478e541c4d36f25cdb7e5fd5563c684de8a1150"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n#n_estimators = 100 => Indicates how many trees we have\nrf_model = RandomForestClassifier(n_estimators=100, random_state=1)\nrf_model.fit(x_train,y_train)\n\n#Print Train Accuracy\nrf_train_accuracy = rf_model.score(x_train,y_train)\nprint(\"rf_train_accuracy = \",rf_model.score(x_train,y_train))\n#Print Test Accuracy\nrf_test_accuracy = rf_model.score(x_test,y_test)\nprint(\"rf_test_accuracy = \",rf_model.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a9384ef2114ef80c3079539e3d1f7248eb8c236"},"cell_type":"code","source":"data = [go.Bar(\n            x=[\"rf_train_accuracy\",\"rf_test_accuracy\"],\n            y=[rf_train_accuracy,rf_test_accuracy],\n            marker=dict(color='rgb(158,202,225)',\n            line=dict(color='rgba(254, 69, 62, 1)',\n            width=1.5),\n        ),\n    opacity=0.6\n    )]\n\niplot(data, filename='text-hover-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c91475258cb0cb8ccf1cce12e24d7979a5d5c032"},"cell_type":"code","source":"y_pred = rf_model.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\n\ncm_rf = confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(cm_rf, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='RdPu', ax = ax)\nplt.xlabel = (\"y_pred\")\nplt.ylabel = (\"y_true\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp ,fp ,fn ,tn= cm_rf.ravel()\nprint(\"rf_RECALL = \",tp/(tp+fn))\nprint(\"rf_PRECISION = \",(tp/(tp+fp)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9ed07be888a4dad2d47ba2c519a22a6e7ea56ff"},"cell_type":"markdown","source":"<a id=\"17\"></a> <br>\n# Evaluation Classification Models"},{"metadata":{"trusted":true,"_uuid":"4d61391a2193b7ae173cb6e75b87f84cebfcdcd4"},"cell_type":"markdown","source":"<a id=\"18\"></a> <br>\n### Confusion Matrixes Comparison"},{"metadata":{"trusted":true,"_uuid":"948ff136f9117578e314f64362a47b5851ef7efd"},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.suptitle(\"Confusion Matrixes of Classification Models\",fontsize=30)\n\nplt.subplot(2,3,1)\nplt.title(\"Logistic Regression Classification\")\nsns.heatmap(cm_lr,annot=True,cmap='YlGnBu',fmt=\".0f\",cbar=False)\n\nplt.subplot(2,3,2)\nplt.title(\"Decision Tree Classification\")\nsns.heatmap(cm_knn,annot=True,cmap='YlGnBu',fmt=\".0f\",cbar=False)\n\nplt.subplot(2,3,3)\nplt.title(\"K Nearest Neighbors(KNN) Classification\")\nsns.heatmap(cm_svm,annot=True,cmap='YlGnBu',fmt=\".0f\",cbar=False)\n\nplt.subplot(2,3,4)\nplt.title(\"Naive Bayes Classification\")\nsns.heatmap(cm_nb,annot=True,cmap='YlGnBu',fmt=\".0f\",cbar=False)\n\nplt.subplot(2,3,5)\nplt.title(\"Random Forest Classification\")\nsns.heatmap(cm_dt,annot=True,cmap='YlGnBu',fmt=\".0f\",cbar=False)\n\nplt.subplot(2,3,6)\nplt.title(\"Support Vector Machine(SVM) Classification\")\nsns.heatmap(cm_rf,annot=True,cmap='YlGnBu',fmt=\".0f\",cbar=False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a06feb80f4ceb26054239e2024a5a3a0ca23546c"},"cell_type":"markdown","source":"<a id=\"19\"></a> <br>\n### Bar Charts Comparison"},{"metadata":{"trusted":true,"_uuid":"daf010746fce6cb1848c7d48fed6a204748e53f7"},"cell_type":"code","source":"# create trace1 \ntrace1 = go.Bar(\n         x = np.array(\"Logistic Regression\"),\n         y = np.array(lr_test_accuracy),\n         name = \"Logistic Regression\",\n         marker = dict(color ='rgba(255, 77, 77, 1)',\n         line=dict(color='rgb(0,0,0)',width=1.5))\n                    )\n# create trace2 \ntrace2 = go.Bar(\n         x = np.array(\"KNN\"),\n         y = np.array(knn_test_accuracy),\n         name = \"KNN\",\n         marker = dict(color ='rgba(9, 220, 125, 1)',\n         line=dict(color='rgb(0,0,0)',width=1.5))\n                    )\n# create trace3 \ntrace3 = go.Bar(\n         x = np.array(\"SVM\"),\n         y = np.array(svm_test_accuracy),\n         name = \"SVM\",\n         marker = dict(color ='rgba(36, 44, 188, 1)',\n         line=dict(color='rgb(0,0,0)',width=1.5))\n                    )\n# create trace4 \ntrace4 = go.Bar(\n         x = np.array(\"Naive Bayes\"),\n         y = np.array(nb_test_accuracy),\n         name = \"Naive Bayes\",\n         marker = dict(color ='rgba(209, 0, 224, 1)',\n         line=dict(color='rgb(0,0,0)',width=1.5))\n                    )\n# create trace5 \ntrace5 = go.Bar(\n         x = np.array(\"Decision Tree\"),\n         y = np.array(dt_test_accuracy),\n         name = \"Decision Tree\",\n         marker = dict(color ='rgba(0, 224, 209, 1)',\n         line=dict(color='rgb(0,0,0)',width=1.5))\n                    )\n# create trace6 \ntrace6 = go.Bar(\n         x = np.array(\"Random Forest\"),\n         y = np.array(rf_test_accuracy),\n         name = \"Random Forest\",\n         marker = dict(color ='rgba(255, 255, 61, 1)',\n         line=dict(color='rgb(0,0,0)',width=1.5))\n                    )\n\ndata = [trace1,trace2,trace3,trace4,trace5,trace6]\nlayout = go.Layout(barmode = \"group\",title=\"Machine Learning Classification Models Comparison\")\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92177d95b5073d8066accb7b2a5fb61208a87d5c"},"cell_type":"markdown","source":"**As you can see,**\nthe best machine learning algorithm for our data is Random Forest Classification algorithm with 86%."},{"metadata":{"trusted":true,"_uuid":"15b19dd36f06055482a555870c1c940b07308f27"},"cell_type":"markdown","source":"<a id=\"20\"></a> <br>\n# Conclusion\n**If you like it, Please upvote my kernel.**<br>\n**If you have any question, I will happy to hear it**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}