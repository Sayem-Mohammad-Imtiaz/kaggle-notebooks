{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom torchvision import datasets, transforms, models\nimport os\nimport shutil\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn.functional as F\nimport torch.nn as nn\n#torchvision.utils.save_image\nfrom torchvision import datasets, transforms ,utils\nprint(os.listdir(\"../input\"))\nfrom PIL import Image\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom IPython.display import display, HTML \nfrom matplotlib.pyplot import imshow\nimport numpy as np\nfrom PIL import Image\nimport os\n##!pip install pretrainedmodels\n#import pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test_ApKoW4T.csv')\nsample = pd.read_csv('../input/sample_submission_ns2btKE.csv')\ntrain = pd.read_csv('../input/train/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convertlabeldict = {1: 'Cargo', \n2:'Military', \n3:'Carrier', \n4:'Cruise', \n5:'Tankers'}\ntrain['category_label'] = train['category'].map(convertlabeldict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['category_label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 2120 - 1217\nb = 2120 - 1167\nc = 2120 - 916\nd = 2120 - 832","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    \n#trainfilenames = train['image'].tolist()\nbasedir = '../input/train/images/'\ndestinationfolder = '../images'\nfor i,row in train.iterrows():\n    currentfileloc = basedir + row['image']\n    newdirname = destinationfolder + 'train/' + str(row['category'])\n    if not os.path.exists(newdirname):\n        os.makedirs(newdirname)\n    shutil.copy(currentfileloc, newdirname)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    \n#trainfilenames = train['image'].tolist()\nbasedir = '../input/train/images/'\ndestinationfolder = '../test/dummy'\nfor i,row in test.iterrows():\n    currentfileloc = basedir + row['image']\n    #newdirname = destinationfolder\n    if not os.path.exists(destinationfolder):\n        os.makedirs(destinationfolder)\n    shutil.copy(currentfileloc, destinationfolder)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!wget http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -ltr ../test/dummy | wc -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = '../test/dummy/2821132.jpg'\n#data = '../input/train/images/1007700.jpg'\npil_im = Image.open(data, 'r')\nimshow(np.asarray(pil_im))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_brightness(image):\n    # Convert 2 HSV colorspace from RGB colorspace\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    # Generate new random brightness\n    rand = random.uniform(0.6, 1.0)\n    hsv[:, :, 2] = rand*hsv[:, :, 2]\n    rand = random.uniform(1.0, 1.5)\n    hsv[:, :, 1] = rand*hsv[:, :, 1]\n    # Convert back to RGB colorspace\n    new_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    return new_img\n\n\ndef zoom(image,rows,cols):\n    zoom_pix = random.randint(5, 10)\n    zoom_factor = 1 + (2*zoom_pix)/rows\n    image = cv2.resize(image, None, fx=zoom_factor,\n                       fy=zoom_factor, interpolation=cv2.INTER_LINEAR)\n    top_crop = (image.shape[0] - rows)//2\n#     bottom_crop = image.shape[0] - top_crop - IMAGE_HEIGHT\n    left_crop = (image.shape[1] - cols)//2\n#     right_crop = image.shape[1] - left_crop - IMAGE_WIDTH\n    image = image[top_crop: top_crop+rows,\n                  left_crop: left_crop+cols]\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\ndef createaugimagesv2(dirname,no_of_images):\n    filename = os.listdir(dirname)\n    filename = random.sample(filename, no_of_images)\n    for images in filename:\n        if images[-8:]!='_enh.jpg' and images[-9:]!='_enh1.jpg':\n            imagepath = dirname + images\n            image = cv2.imread(imagepath)\n            rows,cols,channel = image.shape\n            image = np.fliplr(image)\n\n            op1 = random.randint(0, 1)\n            op2 = random.randint(0, 1)\n            op3 = random.randint(0, 1)\n            if op1:\n                image = random_brightness(image)\n            if op2:\n                image = zoom(image,rows,cols)\n            #if op3:\n            #    image = cv2.flip(image, 1)\n            newimagepath = dirname + images.split('.')[0] + '_enh.jpg'\n            try:\n                image = cv2.resize(image, (224, 224))\n                cv2.imwrite(newimagepath, image)\n            except:\n                print(\"file {0} is not converted\".format(images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef im_convert(tensor):\n    image = tensor.clone().detach().numpy()\n    image = image.transpose(1, 2, 0)\n    image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n    image = image.clip(0, 1)\n    return image\ndef createaugimages(dirname,no_of_images):\n    filename = os.listdir(dirname)\n    filename = random.sample(filename, no_of_images)\n    for images in filename:\n        if images[-9:]!='_enh1.jpg':\n            imagepath = dirname + images\n            pil_im = Image.open(imagepath, 'r').convert('RGB')\n            op1 = random.randint(0, 1)\n            if op1 ==1:\n                changeimg = transforms.Compose([ \n\n                                        #transforms.CenterCrop(274),\n                                        #transforms.RandomHorizontalFlip(),\n                                        transforms.RandomRotation(5),\n                                        transforms.Resize(224),\n                                        #transforms.RandomResizedCrop((224,224)),\n                                        #transforms.CenterCrop(224),\n                                        #transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n                                       # transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2),\n                                        transforms.ToTensor()\n                                        #transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                        #transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n                                       ])\n            else:\n                changeimg = transforms.Compose([ \n\n                            #transforms.CenterCrop(274),\n                            transforms.RandomHorizontalFlip(),\n                            transforms.RandomRotation(10),\n                            transforms.Resize(224),\n                            #transforms.RandomResizedCrop((224,224)),\n                            #transforms.CenterCrop(224),\n                            #transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n                            #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                            transforms.ToTensor()\n                            #transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                            #transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n                           ])\n\n            img = changeimg(pil_im)\n            newimagepath = dirname + images.split('.')[0] + '_enh1.jpg'\n            utils.save_image(img,newimagepath)          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resizeall(dirname):\n    filename = os.listdir(dirname)\n    non3channel = []\n    for images in filename:\n        imagepath = dirname + images\n        image = cv2.imread(imagepath)\n        if image.shape[2] !=3:\n            non3channel.append(images)\n    return non3channel\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convertlabeldict = {1: 'Cargo', \n2:'Military', \n3:'Carrier', \n4:'Cruise', \n5:'Tankers'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = '../imagestrain/5/'\nno_of_images = a\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../imagestrain/2/'\nno_of_images = b\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../imagestrain/3/'\nno_of_images = 916\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../imagestrain/4/'\nno_of_images = 832\ncreateaugimagesv2(dirname,no_of_images)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = '../imagestrain/1/'\nno_of_images = 500\ncreateaugimages(dirname,no_of_images)\ndirname = '../imagestrain/5/'\nno_of_images = 500\ncreateaugimages(dirname,no_of_images)\ndirname = '../imagestrain/2/'\nno_of_images = 500\ncreateaugimages(dirname,no_of_images)\ndirname = '../imagestrain/3/'\nno_of_images = 916\ncreateaugimages(dirname,no_of_images)\ndirname = '../imagestrain/4/'\nno_of_images = 832\ncreateaugimages(dirname,no_of_images)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = '../imagestrain/3/'\nno_of_images = 288\ncreateaugimagesv2(dirname,no_of_images)\ndirname = '../imagestrain/4/'\nno_of_images = 456\ncreateaugimagesv2(dirname,no_of_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dirname = '../imagestrain/3/'\n#no_of_images = 288\n#createaugimages(dirname,no_of_images)\n#dirname = '../imagestrain/4/'\n#no_of_images = 600\n#createaugimages(dirname,no_of_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dirname = '../imagestrain/1/'\n#file3 = resizeall(dirname)\n#print(len(file3))\n#dirname = '../imagestrain/2/'\n#file3 = resizeall(dirname)\n#print(len(file3))\n#dirname = '../imagestrain/3/'\n#file3 = resizeall(dirname)\n#print(len(file3))\n#dirname = '../imagestrain/4/'\n#file3 = resizeall(dirname)\n#print(len(file3))\n#dirname = '../imagestrain/5/'\n#file3 = resizeall(dirname)\n#print(len(file3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../imagestrain\n!ls ../imagestrain/1 | wc -l\n!ls ../imagestrain/5 | wc -l\n!ls ../imagestrain/2 | wc -l\n!ls ../imagestrain/4 | wc -l\n!ls ../imagestrain/3 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = '../imagestrain/5/2868105_enh.jpg'\npil_im = Image.open(data, 'r')\nimshow(np.asarray(pil_im))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = '../imagestrain/5/2878253.jpg'\npil_im = Image.open(data, 'r')\nimshow(np.asarray(pil_im))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_split_train_test(datadir, batch_size=32,valid_size = .3,image_size=224):\n    \n    #train_transforms = transforms.Compose([transforms.Resize((64,64)),\n    #                                  transforms.RandomHorizontalFlip(),\n    #                                  transforms.RandomRotation(10),\n    #                                  transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n    #                                  transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2),\n    #                                  transforms.ToTensor(),\n    #                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    #                           ])\n    #test_transforms = transforms.Compose([transforms.Resize((64,64)),\n    #                           transforms.ToTensor(),\n    #                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    #                           ])\n    #Grayscale(num_output_channels=1)\n    #train_transforms = transforms.Compose([transforms.RandomRotation(10),\n    #                                       transforms.RandomHorizontalFlip(),\n    #                                       transforms.Resize(316),\n    #                                       transforms.CenterCrop(256),\n    #                                       transforms.RandomResizedCrop((image_size,image_size)),\n    #                                       #transforms.RandomCrop(224),\n    #                                       #transforms.Resize(256),\n    #                                        #transforms.CenterCrop(224),\n    #                                       #transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n    #                                       #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    #                                        transforms.ToTensor(),\n    #                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n    #                                  ])\n    \n    #train_transforms = transforms.Compose([ \n    #                    transforms.RandomRotation(10),\n    #                    #transforms.RandomResizedCrop((224,224)),\n    #                    transforms.RandomHorizontalFlip(),\n    #                    #transforms.CenterCrop(224),\n    #                    #transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n    #                    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    #                    transforms.Scale(256),\n    #                    transforms.FiveCrop(224),\n    #                    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n    #                    transforms.Lambda(lambda crops: torch.stack([transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])(crop) for crop in crops]))\n                        #transforms.ToTensor(),\n                        #transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                        #transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n    #                   ])\n    #test_transforms = transforms.Compose([transforms.Resize(256),\n    #                                        transforms.CenterCrop(image_size), \n    #                                      #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    #                                      transforms.ToTensor(),\n    #                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n    #                                  ])\n    train_transforms = transforms.Compose([#transforms.RandomRotation(10),\n                                            #transforms.Resize(256),\n                                            transforms.RandomResizedCrop(256,scale=(0.8, 1.0),ratio=(0.75, 1.33)),\n                                            transforms.RandomRotation(degrees=15),\n                                            #transforms.RandomHorizontalFlip(),\n                                            transforms.CenterCrop(image_size),\n                                           #transforms.RandomHorizontalFlip(),\n                                           #transforms.Resize(256),\n                                           #transforms.CenterCrop(image_size),\n                                           #transforms.RandomResizedCrop((image_size,image_size)),\n                                           #transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n                                           #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                       ])\n    test_transforms = transforms.Compose([transforms.Resize(256),\n                                        transforms.CenterCrop(image_size), \n                                          #transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2),\n                                          transforms.ToTensor(),\n                                          transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                      ])\n    train_data = datasets.ImageFolder(datadir,transform=train_transforms)\n    test_data = datasets.ImageFolder(datadir,transform=test_transforms)\n    num_train = len(train_data)\n    indices = list(range(num_train))\n    split = int(np.floor(valid_size * num_train))\n    np.random.shuffle(indices)\n    from torch.utils.data.sampler import SubsetRandomSampler\n    train_idx, test_idx = indices[split:], indices[:split]\n    train_sampler = SubsetRandomSampler(train_idx)\n    test_sampler = SubsetRandomSampler(test_idx)\n    trainloader = torch.utils.data.DataLoader(train_data,\n                   sampler=train_sampler, batch_size=batch_size)\n    testloader = torch.utils.data.DataLoader(test_data,\n                   sampler=test_sampler, batch_size=batch_size)\n    return trainloader, testloader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nclass ImageDataset(Dataset):\n\n    def __init__(self, df,\n                 transforms=None,\n                 labels_=False):\n        self.labels = None\n        self.transforms = None\n        self.df = df\n        self.imagename = np.asarray(self.df.iloc[:, 0])\n        self.data_len = len(self.df.index)\n        if transforms is not None:\n            self.transforms = transforms\n\n    def __getitem__(self, index):\n        basedir = '../test/dummy/'\n        image_name = basedir + self.imagename[index]\n        #id_ = self.ids[index]\n        img_ = Image.open(image_name).convert('RGB')\n        if self.transforms is not None:\n            img_ = self.transforms(img_)[:3,:,:]\n            label = 0\n        return (img_,image_name)\n\n    def __len__(self):\n        return self.data_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ('Cargo', 'Military', 'Carrier', 'Cruise', 'Tankers') \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def definemodel(modelnumber,freezelonlylastlayer = 'yes',lr=0.0001):\n    data_dir = '../imagestrain'\n    valsize=0.2\n    if modelnumber == 0:\n        batch_size = 32\n        image_size=224\n        training_loader, validation_loader = load_split_train_test(data_dir,batch_size,valsize,image_size)\n        model  = models.densenet201(pretrained=True)\n        #criterion = nn.CrossEntropyLoss()        \n        if freezelonlylastlayer == 'yes':    \n            for param in model.parameters():\n                param.requires_grad = False\n            model.classifier = nn.Sequential(nn.Linear(1920, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.classifier.parameters(), lr = lr) \n        else:\n            model.classifier = nn.Sequential(nn.Linear(1920, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n        criterion = nn.CrossEntropyLoss()\n        modelname = 'densenet201'\n    elif modelnumber == 1:\n        batch_size = 64\n        image_size=224\n        training_loader, validation_loader = load_split_train_test(data_dir,batch_size,valsize,image_size)\n        model = models.resnet50(pretrained=True)\n        #for param in model2.parameters():\n        #    param.requires_grad = False\n\n        #criterion = nn.CrossEntropyLoss()\n        \n        if freezelonlylastlayer == 'yes':    \n            for param in model.parameters():\n                param.requires_grad = False\n            model.fc = nn.Sequential(nn.Linear(2048, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.fc.parameters(), lr = lr) \n        else:\n            model.fc = nn.Sequential(nn.Linear(2048, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n        modelname = 'resnet50'\n        criterion = nn.CrossEntropyLoss()\n    elif modelnumber == 2:\n        batch_size = 32\n        image_size=299\n        training_loader, validation_loader = load_split_train_test(data_dir,batch_size,valsize,image_size)\n        model = models.inception_v3(pretrained=True)\n        #for param in model5.parameters():\n        #    param.requires_grad = False\n        #criterion = nn.CrossEntropyLoss() \n        if freezelonlylastlayer == 'yes':    \n            for param in model.parameters():\n                param.requires_grad = False\n            model.fc = nn.Sequential(nn.Linear(2048, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.fc.parameters(), lr = lr) \n        else:\n            model.fc = nn.Sequential(nn.Linear(2048, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n        modelname = 'inception'\n        criterion = nn.CrossEntropyLoss()\n    elif modelnumber == 3:\n        batch_size = 32\n        image_size=224\n        training_loader, validation_loader = load_split_train_test(data_dir,batch_size,valsize,image_size)\n        model = models.densenet161(pretrained=True)\n        #for param in model5.parameters():\n        #    param.requires_grad = False\n        #criterion = nn.CrossEntropyLoss()      \n        if freezelonlylastlayer == 'yes':    \n            for param in model.parameters():\n                param.requires_grad = False\n            model.classifier = nn.Sequential(nn.Linear(2208, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.fc.parameters(), lr = lr) \n        else:\n            model.classifier = nn.Sequential(nn.Linear(2208, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n        modelname = 'densenet161'\n        criterion = nn.CrossEntropyLoss()\n        #model.to(device)\n        #model3.to(device)\n    elif modelnumber == 4:\n        batch_size = 64\n        image_size=224\n        training_loader, validation_loader = load_split_train_test(data_dir,batch_size,valsize,image_size)\n        model = models.resnet152(pretrained=True)\n        #for param in model2.parameters():\n        #    param.requires_grad = False\n\n        #criterion = nn.CrossEntropyLoss()\n        \n        if freezelonlylastlayer == 'yes':    \n            for param in model.parameters():\n                param.requires_grad = False\n            model.fc = nn.Sequential(nn.Linear(2048, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.fc.parameters(), lr = lr) \n        else:\n            model.fc = nn.Sequential(nn.Linear(2048, 720),\n                                nn.ReLU(),\n                                nn.Dropout(0.5),\n                                nn.Linear(720, 256),\n                                nn.ReLU(),\n                                nn.Dropout(0.4),\n                                nn.Linear(256, 64),\n                                nn.ReLU(),\n                                nn.Dropout(0.3),\n                                nn.Linear(64, 5))\n            optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n        modelname = 'resnet152'\n        criterion = nn.CrossEntropyLoss()\n    return model,criterion,optimizer,modelname,training_loader, validation_loader,image_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modeltrainv2(model,criterion,optimizer,training_loader,validation_loader,epochs = 10,modeltype = 'other'):\n    running_loss_history = []\n    running_corrects_history = []\n    val_running_loss_history = []\n    val_running_corrects_history = []\n    #batch = 0\n    \n    for e in range(epochs):\n        batch = 0\n        running_loss = 0.0\n        running_corrects = 0.0\n        val_running_loss = 0.0\n        val_running_corrects = 0.0\n  \n        for inputs, labels in training_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            batch = batch + len(inputs)\n            #bs, ncrops, c, h, w = inputs.size()\n            #outputs = model(input.view(-1, c, h, w))\n            #outputs = model(inputs)\n            \n            optimizer.zero_grad()\n            if modeltype == 'inception':\n                outputs = model.forward(inputs)[0]\n            else:\n                outputs = model.forward(inputs)\n            #optimizer.zero_grad()\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            #outputs = torch.exp(outputs)\n            _, preds = torch.max(outputs, 1)\n            #preds = preds + 1\n            #print(preds)\n            #print( labels.data)\n            #print('-------------------')\n            running_loss += loss.item()\n            #print(running_loss,loss.item())\n            running_corrects += torch.sum(preds == labels.data)\n            #print(f\"Epoch {e} has accuracy of \")\n            #print(torch.sum(preds == labels.data),len(inputs),int(torch.sum(preds == labels.data))/len(inputs))\n \n        else:\n            valbatch = 0\n            with torch.no_grad():\n                for val_inputs, val_labels in validation_loader:\n                    val_inputs = val_inputs.to(device)\n                    val_labels = val_labels.to(device)\n                    valbatch = valbatch + len(val_inputs)\n                    if modeltype == 'inception':\n                        val_outputs = model(val_inputs)[0]\n                    else:\n                        val_outputs = model(val_inputs)          \n                    val_loss = criterion(val_outputs, val_labels)\n                    #val_outputs = torch.exp(val_outputs)\n                    _, val_preds = torch.max(val_outputs, 1)\n                    #val_preds = val_preds + 1\n                    val_running_loss += val_loss.item()\n                    #print(val_loss.item(),val_running_loss)\n                    val_running_corrects += torch.sum(val_preds == val_labels.data)\n        #print(epoch_loss)  \n        #print(running_corrects.float())\n        #print('-----------')\n        epoch_loss = running_loss/len(training_loader)\n        epoch_acc = running_corrects.float()/ batch\n        running_loss_history.append(epoch_loss)\n        running_corrects_history.append(epoch_acc)\n        val_epoch_loss = val_running_loss/len(validation_loader)\n        val_epoch_acc = val_running_corrects.float()/ valbatch\n        val_running_loss_history.append(val_epoch_loss)\n        val_running_corrects_history.append(val_epoch_acc)\n        print('epoch :', (e+1))\n        print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))\n        print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modeltrain(model,criterion,optimizer,trainloader,testloader,epochs = 10,modeltype = 'others'):\n    #epochs = 1\n    steps = 0\n    running_loss = 0\n    print_every = 10\n    train_losses, test_losses = [], []\n    for epoch in range(epochs):\n        for inputs, labels in trainloader:\n            #print(labels)\n            steps += 1\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            if modeltype == 'inception':\n                logps = model.forward(inputs)[0]\n            else:\n                logps = model.forward(inputs)\n            loss = criterion(logps, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n            if steps % print_every == 0:\n                test_loss = 0\n                accuracy = 0\n                model.eval()\n                with torch.no_grad():\n                    for inputs, labels in testloader:\n                        inputs, labels = inputs.to(device),labels.to(device)\n                        logps = model.forward(inputs)\n                        batch_loss = criterion(logps, labels)\n                        test_loss += batch_loss.item()\n                        ps = torch.exp(logps)\n                        top_p, top_class = ps.topk(1, dim=1)\n                        equals = top_class == labels.view(*top_class.shape)\n                        accuracy +=torch.mean(equals.type(torch.FloatTensor)).item()\n                train_losses.append(running_loss/len(trainloader))\n                test_losses.append(test_loss/len(testloader))                    \n                print(f\"Epoch {epoch+1}/{epochs}.. \"\n                      f\"Train loss: {running_loss/print_every:.3f}.. \"\n                      f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n                      f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n                running_loss = 0\n                model.train()\n    modelpth = modeltype + '.pth'\n    torch.save(model, modelpth)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, test_image_name,transform,image_size,modeltype='other'):\n    test_image = Image.open(test_image_name).convert('RGB')\n    test_image_tensor = transform(test_image)\n    if torch.cuda.is_available():\n        test_image_tensor = test_image_tensor.view(1, 3, image_size, image_size).cuda()\n    else:\n        test_image_tensor = test_image_tensor.view(1, 3, image_size, image_size)\n    with torch.no_grad():\n        model.eval()\n        if modeltype == 'inception':\n            out = model(test_image_tensor)[0]\n        else:\n            out = model(test_image_tensor)\n        ps = torch.exp(out)\n    return test_image_name,ps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def addtensorcols(val):\n    return val['category1'] + val['category2']\n\ndef extractfilename(val):\n    return os.path.split(val)[1]\n\ndef maxtensorval(val):\n    #ps = torch.exp(val)\n    #ps = F.softmax(val,dim=1)\n    top_p, top_class = val.topk(1)\n    return top_class+1\n\n\nnewtestfinal = pd.DataFrame(columns=['image', 'category1'])\nfor modelnum in [0,1,2,3,4]: \n    #counter = 0\n    print('---------------------------------------------------------------------------------')\n    print('Defining model and creating data loaders for model number {0}'.format(modelnum))\n    model,criterion,optimizer,modelname,training_loader, validation_loader,image_size = definemodel(modelnum,freezelonlylastlayer = 'no',lr=0.0001)\n    #test_transforms = transforms.Compose([transforms.Resize(256),\n    #                                    transforms.CenterCrop(image_size),\n    #                                  #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    #                                transforms.ToTensor(),\n    #                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n    #                              ])\n    test_transforms = transforms.Compose([transforms.Resize(256),\n                                        transforms.CenterCrop(image_size), \n                                      #transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                  ])\n    print(\"Training of model {0} started\".format(modelname))\n    model.to(device)\n    model = modeltrainv2(model,criterion,optimizer,training_loader,validation_loader,epochs = 7,modeltype=modelname)   \n    basedir = '../test/dummy/'\n    newtest = pd.DataFrame(columns=['image', 'category2'])\n    #destinationfolder = '../images'\n    print(\"Prediction of model {0} started\".format(modelname))\n    for i,row in test.iterrows():\n        pathfile = basedir + row['image']\n        test_image_name,imagetype = predict(model, pathfile,test_transforms,image_size,modeltype=modelname)\n        newtest.loc[i] = [test_image_name,imagetype]\n    print(\"Prediction for model {0} completed\".format(modelname))\n    newtest['image']  = newtest['image'].apply(extractfilename)\n    del model,criterion,optimizer\n    torch.cuda.empty_cache()\n    if newtestfinal.shape[0]>0:\n        newtestfinal = pd.merge(newtestfinal, newtest, on='image')\n        newtestfinal['category1'] = newtestfinal.apply(addtensorcols, axis=1)\n        newtestfinal = newtestfinal[['image','category1']]\n    else:\n        newtestfinal = newtest.copy()\n        newtestfinal.columns=['image', 'category1']\n    print(\"Training of model {0} completed\".format(modelname))\n\nnewtestfinal['category'] = newtestfinal['category1'].apply(maxtensorval)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newtestfinal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newtestfinal['category'] = newtestfinal['category'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newtestfinal = newtestfinal[['image','category']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newtestfinal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(newtestfinal)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}