{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n%config Completer.use_jedi = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = pd.read_csv(\"../input/santander-customer-transaction-prediction-dataset/test.csv\")\ndata_train = pd.read_csv(\"../input/santander-customer-transaction-prediction-dataset/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print all the columns which is not present in test data but present in training data\n\nfor col in data_train.columns:\n    if col not in data_test.columns:\n        print(\"`{}` is not present in test data\".format(col))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the columns except the `target` column is present in test data. So we don't need to drop any columns in training data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training data contains all the variables that are continous except `ID_code` and `target` . No categorical variables. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_train.shape)\nprint(data_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = data_train.target.value_counts().index\nvals = data_train.target.value_counts().values\nfig, ax = plt.subplots()\nexplode = (0.1, 0)\nax.pie(vals, labels=idx, explode=explode, autopct='%1.1f%%')\nax.axis('equal')\nax.set_title('Santanber target labels')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see, the training data is heavily unbalanced, we've only 10% of `label 1`. This may require further action."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncorr = data_train.corr().abs()\ncorr[corr == 1] = 0\ns = corr.unstack().sort_values(ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(s.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see, the maximum correlation is in the scale of 0.08 which is near to zero, thus we affirm that the is no such noticable correlation with features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skewList = []\nfor colName in data_train.columns:\n    if colName not in ['ID_code', 'target']:\n        skewList.append([colName, abs(data_train[colName].skew())])\n\nskewList.sort(key=lambda x: x[1], reverse=True)\n\nskewdf = pd.DataFrame.from_records(skewList, columns=['colName', 'Skewness'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(skewdf.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The maximus skewness value is .34 which is in the range from -0.5 to 0.5, that means it is almost symmetrical. Let's plot `var_44` and confirm it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots( figsize=(4,4), )\n\nsns.distplot(data_train[\"var_44\"], ax=ax, color='r')\nax.set_title('Distribution of var_44', fontsize=14)\nax.set_xlim([min(data_train[\"var_44\"]), max(data_train[\"var_44\"])])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'var_44'\ntmp = pd.concat([data_train['target'], data_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='target', y=var, data=tmp)\nfig.axis(ymin= min(data_train[var]), ymax=max(data_train[var]));\nf.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus we don't have any issue with skewness. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data\ntotal = data_train.isnull().sum().sort_values(ascending=False)\npercent = (data_train.isnull().sum()/data_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no missing data as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of unique values in ID_code: \", data_train.ID_code.nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the values are unique in ID column, so we may use it as an index. Thus it can be dropped when modelling."},{"metadata":{"trusted":true},"cell_type":"code","source":"non_transaction_df = data_train.loc[data_train['target'] == 0]\nnon_transaction_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transaction_df = data_train.loc[data_train['target'] == 1]\ntransaction_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(transaction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since our classes are highly skewed we should make them equivalent in order to have \n# a normal distribution of the classes.\n\n# Lets shuffle the data before creating the subsamples\n\n# frac =1 sampling will help us to shuffle the dataframe\ndata_train = data_train.sample(frac=1)\n\n# amount of fraud classes 20098 rows.\ntransaction_df = data_train.loc[data_train['target'] == 1]\nnon_transaction_df = data_train.loc[data_train['target'] == 0][:len(transaction_df)]\n\nprint(\"Shape of transaction df: \", transaction_df.shape)\nprint(\"Shape of non transaction df: \", non_transaction_df.shape)\n\nnormal_distributed_df = pd.concat([transaction_df, non_transaction_df])\n# Shuffle dataframe rows\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nprint(\"Balanced data set dimension: \", new_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.drop(\"ID_code\", inplace=True, axis=1)\ndata_test.drop(\"ID_code\", inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport numpy as np\n\nX = new_df.drop('target', axis=1)\ny = new_df['target']\n\nsss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\nfor train_index, test_index in sss.split(X, y):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n    print('-' * 100)\n    print(\"\\nShape of original_Xtrain: \", original_Xtrain.shape)\n    print(\"\\nShape of original_Xtest: \", original_Xtest.shape)\n    print('-' * 100)\n    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n\n# We already have X_train and y_train for undersample data thats why I am using original to distinguish \n# and to not overwrite these variables.\n# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Check the Distribution of the labels\n\n\n# Turn into an array\noriginal_Xtrain = original_Xtrain.values\noriginal_Xtest = original_Xtest.values\noriginal_ytrain = original_ytrain.values\noriginal_ytest = original_ytest.values\n\n# See if both the train and test label distribution are similarly distributed\ntrain_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n\nprint('-' * 100)\n\nprint('Label Distributions: \\n')\nprint(train_counts_label/ len(original_ytrain))\nprint(test_counts_label/ len(original_ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import learning_curve\n\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n   \n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\ncv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\ntitle = \"Santanber training results\"\nplot_learning_curve(log_reg, title, X.values, y.values, None, cv=cv,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}