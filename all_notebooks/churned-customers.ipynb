{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score\nfrom xgboost import XGBClassifier\n\npd.set_option(\"display.max_columns\", 100)\npd.set_option('display.width', 1000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/credit-card-customers/BankChurners.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set_style(\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------------some pre data processing(quite obvious ones)-----------------------\ndf['Attrition_Flag'].replace({'Existing Customer':0, 'Attrited Customer':1},inplace=True)\ndf.drop(df.columns[[0,-1,-2]].values,axis=1,inplace=True)\n# print(df.head(2))\n# print(df.shape)\ndf.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----Data Analysis\nsizes = (df['Attrition_Flag'].value_counts()).tolist()\nplt.pie(sizes,explode=[0,0.1],shadow=True,autopct='%1.2f%%',labels=['Existing','Churned'])\nplt.show()\n\n#______gender based division\nsizes_f = df.loc[df['Gender']=='F']['Attrition_Flag'].value_counts()\nsizes_m = df.loc[df['Gender']=='M']['Attrition_Flag'].value_counts()\nfig,(ax1,ax2) = plt.subplots(1,2)\nax1.pie(sizes_f,explode=[0,0.1],shadow=True,autopct='%1.2f%%',labels=['Existing','Churned'])\nax1.title.set_text('Females')\nax2.pie(sizes_m,explode=[0,0.1],shadow=True,autopct='%1.2f%%',labels=['Existing','Churned'])\nax2.title.set_text('Males')\nplt.show()\n\nsizes_gender = df['Gender'].value_counts()    #not much difference. thus it's eually distributed.\nplt.pie(sizes_gender.tolist(),autopct='%1.2f%%',labels=sizes_gender.index.values,explode=[0.1,0],shadow=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conversion Of Categoraical variables into numericals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #ordinal to numerical\nmap_education_level = {'High School':1,'Graduate':3,'Uneducated':0,'College':2,'Post-Graduate':4,'Doctorate':5}\nmap_income_level = {'$60K - $80K':3,'Less than $40K':1, '$80K - $120K':4,'$40K - $60K':2,'$120K +':5}\nmap_card_category = {'Blue':1,'Gold':3,'Silver':2,'Platinum':4}\ndf['Education_Level'].replace(map_education_level,inplace=True)\ndf['Income_Category'].replace(map_income_level,inplace=True)\ndf['Card_Category'].replace(map_card_category,inplace=True)\n\n#\n# #hot encoding of gender category\ndf.insert(2,'Gender_M',df['Gender'],True)\ndf.rename({'Gender':'Gender_F'},axis=1,inplace=True)\ndf['Gender_M'].replace({'M':1,'F':0},inplace=True)\ndf['Gender_F'].replace({'M':0,'F':1},inplace=True)\n#\n# #hot encoding of marital status\ndf.insert(7,'Single',df['Marital_Status'],True)\ndf.insert(7,'Divorced',df['Marital_Status'],True)\ndf.insert(7,'Unknown',df['Marital_Status'],True)\ndf.rename({'Marital_Status':'Married'},axis=1,inplace=True)\ndf['Married'].replace({'Single':0, 'Married':1, 'Divorced':0, 'Unknown':0},inplace=True)\ndf['Single'].replace({'Single':1, 'Married':0, 'Divorced':0, 'Unknown':0},inplace=True)\ndf['Divorced'].replace({'Single':0, 'Married':0, 'Divorced':1, 'Unknown':0},inplace=True)\ndf['Unknown'].replace({'Single':0, 'Married':0, 'Divorced':0, 'Unknown':1},inplace=True)\n\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dealing With missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df.loc[df['Income_Category']!='Unknown']['Income_Category'])   # income is rightly skewed. so central value is median\nplt.show()\n\nplt.hist(df.loc[df['Education_Level']!='Unknown']['Education_Level'])   # education is normally distributed. so central value is mean\nplt.show()\n\n#Missing values in education column\neducatedDF = df.loc[df['Education_Level']!='Unknown']\nmean_education = educatedDF['Education_Level'].mean()\ndf['Education_Level'].replace({'Unknown':mean_education},inplace=True)\n\n#Missing values in income column\nsalariedDF = df.loc[df['Income_Category']!='Unknown']\nmedian_salaries = salariedDF['Income_Category'].median()\ndf['Income_Category'].replace({'Unknown':median_salaries},inplace=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataset Split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.iloc[:,1:]\ny = df.iloc[:,0]\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Upsampling using SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\n\n#-----Upsampling----\nfrom sklearn.utils import resample\nfrom collections import Counter\n\nprint(\"Before Upsampling:-\")\nprint(Counter(y_train))\n\n# X_train_upsampled, y_train_upsampled = resample(x_train[y_train == 1],\n#                                                 y_train[y_train == 1],\n#                                                 replace=True,\n#                                                 n_samples=x_train[y_train == 0].shape[0],\n#                                                 random_state=123)\n\n\n# Let's use SMOTE to oversample\nfrom imblearn.over_sampling import SMOTE\noversample = SMOTE()\nx_train_upsampled, y_train_upsampled = oversample.fit_resample(x_train,y_train)\n\nprint(\"After Upsampling:-\")\nprint(Counter(y_train_upsampled))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FITTING INTO MODEL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----Random Forest after upsampling------\nprint(\"\\n\\n\\n\\n AFTER UPSAMPLING\\n\\n\")\nclassifier = RandomForestClassifier(n_estimators = 50, random_state = 0)\nclassifier.fit(x_train_upsampled, y_train_upsampled)\n# Predicting result for training set and validation set\npredict_val_rf = classifier.predict(x_test)\n\n\n# Model Performance\n\nprint(\"Accuracy : \", accuracy_score(y_test, predict_val_rf) *  100)\nprint(\"Recall : \", recall_score(y_test, predict_val_rf) *  100)\nprint(\"Precision : \", precision_score(y_test, predict_val_rf) *  100)\nprint(confusion_matrix(y_test, predict_val_rf))\nprint(classification_report(y_test, predict_val_rf))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recall is 86%. ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}