{"cells":[{"metadata":{},"cell_type":"markdown","source":"*The red wine variant of the Portuguese \"Vinho Verde\" wine refers to Portuguese wine that originated in the historic Minho province in the far north of the country. The main goal of this problem is to find which features of these kinds of wine are the ones that provide the most information about its quality. We will also try to make a prediction of a wine's quality and check if it matches with the real quality. Although this dataset can be viewed as a classification (multiclass classification) or a regression problem, we will solve it using regression techniques.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#Split Data Train and Test\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n\n#Modelling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score, plot_roc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***The red wine industry shows a recent exponential growth as social drinking is on the rise. This is a time-consuming process and requires the assessment given by human experts, which makes this process very expensive. A vital factor in red wine certification and quality assessment is physicochemical tests, which are laboratory-based and consider factors like acidity, pH level, sugar, and other chemical properties. The red wine market would be of interest if the human quality of tasting can be related to wineâ€™s chemical properties so that certification and quality assessment and assurance processes are more controlled. This project aims to determine which features are the best quality red wine indicators and generate insights into each of these factors to red wine quality.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"redwine = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\nredwine.sample()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"redwine.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"redwine.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.scatterplot(x='density', y='alcohol', data= redwine, hue='quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 8))\nsns.heatmap(redwine.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\nplt.title('Correlation Map Of Red Wine Quality', fontdict={'fontsize':12}, pad=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PreProcessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"redwine['quality'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- *If the **quality value > 6**, it means the quality is **good** and I define it as **1**.*\n- *If the **quality value < 6,** it means the quality is **bad** and I define it as **0**.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"redwine['quality'] = np.where(redwine['quality'] > 6, 1, 0)\nredwine['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this actual data, there are **more bad qualities than good ones**. Also indicated that the data is **imbalanced**."},{"metadata":{},"cell_type":"markdown","source":"*Splitting Data*"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = redwine.drop(['quality'], axis = 1)\ny = redwine['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                   stratify = y,\n                                                   test_size = 0.3,\n                                                   random_state = 1111)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I use 0.3 as default score for test_size and X.shape for random_state so the data will be devided equally."},{"metadata":{},"cell_type":"markdown","source":"## *Find Best K-Score*"},{"metadata":{"trusted":true},"cell_type":"code","source":"k = range(1,50,2)\ntesting_accuracy = []\ntraining_accuracy = []\nscore = 0\n\nfor i in k:\n    knn = KNeighborsClassifier(n_neighbors = i)\n    pipe_knn = Pipeline([('scale', MinMaxScaler()), ('knn', knn)])\n    pipe_knn.fit(X_train, y_train)\n    \n    y_pred_train = pipe_knn.predict(X_train)\n    training_accuracy.append(accuracy_score(y_train, y_pred_train))\n    \n    y_pred_test = pipe_knn.predict(X_test)\n    acc_score = accuracy_score(y_test,y_pred_test)\n    testing_accuracy.append(acc_score)\n    \n    if score < acc_score:\n        score = acc_score\n        best_k = i\n        \nprint('Best Accuracy Score', score, 'Best K-Score', best_k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(k, testing_accuracy)\nsns.scatterplot(k, testing_accuracy)\n\nsns.lineplot(k, training_accuracy)\nsns.scatterplot(k, training_accuracy)\nplt.legend(['testing accuracy', 'training accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A large K value has benefits which include reducing the variance due to the noisy data, the side effect being developing a bias due to which the learner tends to ignore the smaller patterns which may have useful insights. The data indicates underfitting."},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"*Define Model Using Best K-Score*"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\npipe_knn = Pipeline([('scale', MinMaxScaler()), ('knn', knn)])\npipe_knn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Cross Validation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n    return model_cv\n\npipe_knn_cv = model_evaluation(pipe_knn, 'roc_auc')\n\nscore_mean = [pipe_knn_cv.mean()]\nscore_std = [pipe_knn_cv.std()]\nscore_roc_auc = [roc_auc_score(y_test, pipe_knn.predict(X_test))]\nmethod_name = ['K-Neighbors Classifier']\nsummary = pd.DataFrame({'method': method_name, 'mean score': score_mean,\n                        'std score': score_std, 'roc auc score': score_roc_auc})\nsummary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, see if the HyperParameter Tuning process can boost until getting the maximum score."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(pipe_knn, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HyperParameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nestimator = Pipeline([('scale', MinMaxScaler()), ('knn', knn)])\n\nhyperparam_space = {\n    'knn__n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17],\n    'knn__leaf_size': [10, 20, 30, 40, 50],\n    'knn__weights': ['uniform', 'distance']\n}\n\ngrid = GridSearchCV(\n                estimator,\n                param_grid = hyperparam_space,\n                cv = StratifiedKFold(n_splits = 5),\n                scoring = 'roc_auc',\n                n_jobs = -1)\n\ngrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('best score', grid.best_score_)\nprint('best param', grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After HyperParameter Tuning, the best score is 0.88616, which getting higher. Leaf size is 10, N neighbors is 17, and Weights is distance. Let's compare the result."},{"metadata":{},"cell_type":"markdown","source":"# Before VS After Tuning Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator.fit(X_train, y_train)\ny_pred_estimator = estimator.predict(X_test)\nprint(classification_report(y_test, y_pred_estimator))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_estimator_.fit(X_train, y_train)\ny_pred_grid = grid.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_pred_grid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = [roc_auc_score(y_test, y_pred_estimator), roc_auc_score(y_test, y_pred_grid)]\naccuracy = [score, accuracy_score(y_test, y_pred_grid)]\nmethod_name = ['K-Neighbors Classifier Before Tuning', 'K-Neighbors Classifier After Tuning']\nbest_summary = pd.DataFrame({\n    'method': method_name,\n    'roc auc score': score_list,\n    'accuracy score': accuracy\n})\nbest_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this score, I see that the roc auc score after tuning is getting lower, even the accuracy score is getting higher. First thing, the data is imbalanced, so it could cause this, and the second thing is the data indicates underfitting training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}