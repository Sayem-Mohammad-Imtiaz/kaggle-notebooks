{"cells":[{"metadata":{},"cell_type":"markdown","source":"Web crawling is a common task. Here I'm using some newer libraries to speed up the job and still keep simple code.\n\nA comparison shows these libraries can download 32 videos in 00:20, compared to about 02:00 using a synchronous, single-threaded pipeline."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%bash\n\npip uninstall -y typing  # trouble for gazpacho\npip install asks trio gazpacho","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\nimport asks\nimport trio\nimport gazpacho as gzp\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for existing videos."},{"metadata":{"trusted":true},"cell_type":"code","source":"Path('/home/vids').mkdir(exist_ok=True)\n\npath_gen = Path('../input/parler').glob('**/*.mp4')\nexisting = [p.name for p in path_gen]\nprint(f'{len(existing)} videos in the dataset.')\n      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use Gazpacho to get links from the index page."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_links(start_page):\n    html = gzp.get(start_page)\n    soup = gzp.Soup(html)\n    ancs = soup.find('a')\n    refs = [a.attrs['href'] for a in ancs]\n    vids_new = [r for r in refs if '.mp4' in r and \\\n                r not in existing][:32]  # testing\n    print(f'Getting {len(vids_new)} videos.')\n    return vids_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Asynchronous, multi-threaded way to download"},{"metadata":{"trusted":true},"cell_type":"code","source":"async def fetch_vid(s, vid):\n    url = f\"https://www.tommycarstensen.com/terrorism/{vid}\"\n    r = await s.get(url)\n    return r.content\n\n\nasync def save_vid(s, vid):\n    content = await fetch_vid(s, vid)\n    filename = f\"/home/vids/{vid}\"\n    with open(filename,'wb') as f:\n        f.write(content)\n\n    \nasync def main(start_page):\n    vids_new = get_links(start_page)\n    dname = '/'.join(start_page.split('/')[:3])\n    s = asks.sessions.Session(dname, connections=16)\n    async with trio.open_nursery() as n:\n        for vid in vids_new:\n            n.start_soon(save_vid, s, vid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nstart_page = 'https://www.tommycarstensen.com/terrorism/index.html'\ntrio.run(main, start_page)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Regular way to download"},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\n\ndef fetch_vid(vid):\n    url = f\"https://www.tommycarstensen.com/terrorism/{vid}\"\n    r = requests.get(url, stream=True)\n    return r.content\n\n\ndef save_vid(vid):\n    content = fetch_vid(vid)\n    filename = f\"/home/vids/{vid}\"\n    with open(filename,'wb') as f:\n        f.write(content)\n\n    \ndef main(start_page):\n    vids_new = get_links(start_page)\n    for vid in tqdm(vids_new):\n        save_vid(vid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_page = 'https://www.tommycarstensen.com/terrorism/index.html'\nmain(start_page)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\n\n# zip -r capitol_vids3.zip /home/vids/*.mp4\nls -U  /home/vids | head -10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}