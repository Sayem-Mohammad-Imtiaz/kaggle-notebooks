{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Employee turnover analysis project that is built by using Python’s Scikit-Learn library."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nhr = pd.read_csv('../input/HR_comma_sep.csv')\ncol_names = hr.columns.tolist()\nprint(\"Column names:\")\nprint(col_names)\nprint(\"\\nSample data:\")\nhr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Looking at the dataset, we can see the features that are there:\n\n1. **satisfaction_level** (0–1)\n2. **last_evaluation** (Time since last evaluation in years)\n3. **number_projects** (Number of projects completed while at work)\n4. **average_monthly_hours** (Average monthly hours at workplace)\n5. **time_spend_company** (Time spent at the company in years)\n6. **Work_accident** (Whether the employee had a workplace accident)\n7.**left** (Whether the employee left the workplace or not (1 or 0))\n8. **promotion_last_5years** (Whether the employee was promoted in the last five years)\n9.** sales **(Department in which they work for)\n10. **salary** (Relative level of salary)\n"},{"metadata":{},"cell_type":"markdown","source":"Let's rename the sales column to department."},{"metadata":{"trusted":true},"cell_type":"code","source":"hr=hr.rename(columns = {'sales':'department'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data looks clean. Let's look at its shape and types of columns.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The department column of the dataset has many categories and we need to reduce the categories for a better modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"hr['department'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us combine “technical”, “support” and “IT” together and call them “technical”"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nhr['department']=np.where(hr['department'] =='support', 'technical', hr['department'])\nhr['department']=np.where(hr['department'] =='IT', 'technical', hr['department'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr['department'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA EXPLORATION**"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Let us find out the number of employees who left the company and those who didn’t"},{"metadata":{"trusted":true},"cell_type":"code","source":"hr['left'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So 3571 employees left the company while 11428 stayed."},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.groupby('left').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average satisfaction level of employees who stayed with the company is higher than that of the employees who left."},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.groupby('department').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.groupby('salary').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Visualization**"},{"metadata":{},"cell_type":"markdown","source":"Bar chart for department and the frequency of turnover('left')"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\npd.crosstab(hr.department,hr.left).plot(kind='bar')\nplt.xlabel('Department')\nplt.ylabel('Frequency of Turnover')\nplt.savefig('department_bar_chart')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that department is a good indicator for frequency of turnover. Now let us see a Bar chart for employee salary level and the frequency of turnover"},{"metadata":{"trusted":true},"cell_type":"code","source":"table=pd.crosstab(hr.salary, hr.left)\ntable.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\nplt.title('Stacked Bar Chart of Salary Level vs Turnover')\nplt.xlabel('Salary Level')\nplt.ylabel('Proportion of Employees')\nplt.savefig('salary_bar_chart')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Salary is a good indicator as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_bins = 10\nhr.hist(bins=num_bins, figsize=(20,15))\nplt.savefig(\"hr_histogram_plots\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now for the categorical variables, salary and department, we need to create dummies."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_vars=['department','salary']\nfor var in cat_vars:\n    cat_list='var'+'_'+var\n    cat_list = pd.get_dummies(hr[var], prefix=var)\n    hr1=hr.join(cat_list)\n    hr=hr1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.drop(hr.columns[[8, 9]], axis=1, inplace=True)\nhr.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr_vars=hr.columns.values.tolist()\ny=['left']\nX=[i for i in hr_vars if i not in y]\nprint(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nrfe = RFE(model, 10)\nrfe = rfe.fit(hr[X], hr[y])\nprint(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=['satisfaction_level', 'last_evaluation', 'time_spend_company', 'Work_accident', 'promotion_last_5years', \n      'department_RandD', 'department_hr', 'department_management', 'salary_high', 'salary_low'] \nX=hr[cols]\ny=hr['left']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint('Logistic regression accuracy: {:.3f}'.format(accuracy_score(y_test, logreg.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Random Forest Accuracy: {:.3f}'.format(accuracy_score(y_test, rf.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\nprint('Support vector machine accuracy: {:.3f}'.format(accuracy_score(y_test, svc.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Random Forest is the most accurate one out of the three. Let's build a confusion matrix to infer more."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, rf.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nforest_cm = metrics.confusion_matrix(y_pred, y_test, [1,0])\nsns.heatmap(forest_cm, annot=True, fmt='.2f',xticklabels = [\"Left\", \"Stayed\"] , yticklabels = [\"Left\", \"Stayed\"] )\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.title('Random Forest')\nplt.savefig('random_forest')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}