{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nimport torch.optim as optim\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom skimage import io, transform\n\nimport pandas as pd \nimport numpy as np\n\nimport glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/house-prices-and-images-socal/socal2.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df['street']\ndel df['citi']\ndel df['n_citi']\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list = []\n# for i,ids in enumerate(df['image_id']):\n#     if i % 1000 == 0:\n#         print(i)\n#     paths = '../input/house-prices-and-images-socal/socal2/socal_pics/' + str(ids) + '.jpg'\n#     image = io.imread(paths)\n#     image = image / 255.0\n#     image = transform.resize(image,(64,64)).reshape(3,64,64)\n#     list.append(ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sample(256)\ndf.reset_index(inplace = True )\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df['index']\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for cols in ['sqft','price']:\n    df[cols] = (df[cols].max() - df[cols])/(df[cols].max() - df[cols].min())\n    \ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[0,4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[0,1:4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SocalDataset(Dataset):\n    \n    def __init__(self, dataframe, root_dir, transform=None):\n        \"\"\"\n        Args:\n            dataframe: pandas dataframe with features and target.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.features = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img_name = '{}{}.jpg'.format(str(self.root_dir), str(self.features.loc[idx,'image_id']))\n        image = io.imread(img_name)\n        image = image / 255.0\n        if len(image.shape) == 3:\n            house_features = self.features.iloc[idx, 1:]\n            house_features = np.array([house_features]).reshape(4)\n            sample = {'image': image, 'house_features': house_features}\n\n            if self.transform:\n                sample['image'] = transform.resize(sample['image'],(64,64)).reshape(3,64,64)\n                \n            sample['image'] = torch.from_numpy(sample['image']).float()\n            sample['house_features'] = torch.from_numpy(sample['house_features']).float()\n\n            return sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"house_dataset = SocalDataset(dataframe=df,\n                            root_dir='../input/house-prices-and-images-socal/socal2/socal_pics/',\n                            transform = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    sample = house_dataset[i]\n    print(i, sample['image'].shape, sample['house_features'].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets split the dataset into three parts (train 70%, test 30%)\ntest_size = 0.3\n\ntest_amount = int(house_dataset.__len__() * test_size)\n\ntrain_set, test_set = torch.utils.data.random_split(house_dataset,[\n            (house_dataset.__len__() - test_amount ), test_amount ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(\n            train_set,\n            batch_size=4,\n            shuffle=True,\n)\n\ntest_dataloader = torch.utils.data.DataLoader(\n            test_set,\n            batch_size=4,\n            shuffle=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"it = iter(train_dataloader)\nitems = next(it)\nprint(type(items))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(items['image'].shape)\nprint(items['house_features'].shape)\nprint(items['house_features'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"items['house_features'][:,3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"items['house_features'][:,:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TwoInputsNet(nn.Module):\n    def __init__(self):\n        super(TwoInputsNet, self).__init__()\n        self.conv = nn.Conv2d(3,8,kernel_size=3) \n        self.conv1 = nn.Conv2d(8,8,kernel_size=3)\n        self.conv2 = nn.Conv2d(8,8,kernel_size=3) \n        self.fc1 = nn.Linear(3,3)\n        self.fc2 = nn.Linear(26915,1024)\n        self.fc3 = nn.Linear(1024,32) \n        self.fc4 = nn.Linear(32,1) \n\n    def forward(self, input1, input2):\n        c = self.conv(input1)\n        c = self.conv1(c)\n        c = F.relu(c)\n        c = self.conv2(c)\n        c = F.relu(c)\n        f = self.fc1(input2)\n        # now we can reshape `c` and `f` to 2D and concat them\n        combined = torch.cat((c.view(c.size(0), -1),\n                          f.view(f.size(0), -1)), dim=1)\n        out = self.fc2(combined)\n        out = F.relu(out)\n        out = self.fc3(out)\n        out = F.relu(out)\n        out = self.fc4(out)\n\n        \n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network = TwoInputsNet()\nprint(network)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"items['image'][1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"items['house_features'][:,:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network.forward(items['image'],items['house_features'][:,:3]).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network.forward(items['image'],items['house_features'][:,:3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    network = network.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.01\nmomentum = 0.9\nn_epochs = 10\n\noptimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum)\n\nloss_func = torch.nn.MSELoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(\n            train_set,\n            batch_size=4,\n            shuffle=True,\n)\n\ntest_dataloader = torch.utils.data.DataLoader(\n            test_set,\n            batch_size=4,\n            shuffle=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader,epoch):\n    batch_idx = 0\n    for items in dataloader:\n        image = torch.FloatTensor(items['image'])\n        features = torch.FloatTensor(items['house_features'][:,:3])\n        price = torch.FloatTensor(items['house_features'][:,3])\n\n        if torch.cuda.is_available():\n            image = image.cuda()\n            features = features.cuda()\n            price = price.cuda()\n            \n        output = network(image,features)\n        output = output.reshape(4)\n        loss = loss_func(output, price)\n        optimizer.zero_grad()  \n        loss.backward()\n        optimizer.step()\n        \n        if batch_idx % 4 == 0: #every 25 * batchsize sample we print results\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n            epoch+1, batch_idx * image.shape[0], len(dataloader.dataset),\n            100. * batch_idx / len(dataloader), loss.item()))\n            \n        batch_idx = batch_idx + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epochs):\n    # train \n    train(train_dataloader,epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}