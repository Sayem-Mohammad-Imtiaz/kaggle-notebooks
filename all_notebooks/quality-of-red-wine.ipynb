{"cells":[{"metadata":{},"cell_type":"markdown","source":"****Import Necessary Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read & Load the file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Data=pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\n\nData.rename(columns ={'residual sugar':'residual_sugar'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"View Data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check attributes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Number Of Rows and Columns:\",Data.shape)\nprint(\"Data Size:\",Data.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for Null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Five POINT SUMMARY ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the range of quality","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(Data['quality']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(Data['quality']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Lets see the correlation between attributes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_corr(Data, size=15):\n    corr = Data.corr()\n    fig, ax = plt.subplots(figsize=(size, size))\n    ax.matshow(corr)\n    plt.xticks(range(len(corr.columns)), corr.columns)\n    plt.yticks(range(len(corr.columns)), corr.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_corr(Data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BOX PLOTS to see the outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (3,3))\nsns.boxplot(x=Data['fixed acidity'],color='orange')\nplt.figure(figsize= (3,3))\nsns.boxplot(x=Data['pH'],color='orange')\nplt.figure(figsize= (3,3))\nsns.boxplot(x=Data['alcohol'],color='orange')\nplt.figure(figsize= (3,3))\nsns.boxplot(x=Data['sulphates'],color='orange')\nplt.figure(figsize= (3,3))\nsns.boxplot(x=Data['citric acid'],color='orange')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Adding a column to classify wine quality which can be later used for Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def func(row):\n    if row[\"quality\"] > 6.5:\n        return(\"Good\")\n    else:\n        return(\"Bad\")\nData[\"quality_change\"]=Data.apply(func,axis=1)\nData.groupby('quality_change')['quality'].sum().plot.pie(autopct='%1.2f%%');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets see the significance of Alcohol in quality of the wine ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=Data['pH'],y=Data['alcohol'],hue=Data['quality_change']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as stats\n\nH0=\"Alcohol does have an impact on the quality of wine as the P_value is greater than 0.05 :\"\nHa=\"Alcohol does NOT have any significant impact on the quality of wine, as the P_value is less than 0.05 :\"\nGood_quality_Wine_OH=np.array(Data[Data.quality_change =='Good'].alcohol)\nBad_quality_wine_OH=np.array(Data[Data.quality_change =='Bad'].alcohol)\nt, p_value  = stats.ttest_ind(Good_quality_Wine_OH,Bad_quality_wine_OH,axis=0)\np_value\nif p_value < 0.5:\n    print(Ha,format(p_value))\nelse:\n    print(H0,format(p_value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ho=\"Residual Sugars have a significant role in quality of alchohol\"\nHa=\"Residual Sugars do not have significance on the quality of alcohol\" \n\nGood_Quality_Wine_Sugar=np.array(Data[Data.quality_change=='Good'].residual_sugar)\nBad_Quality_Wine_Sugar=np.array(Data[Data.quality_change=='Bad'].residual_sugar)\n\nf_stat,p_value=stats.f_oneway(Good_Quality_Wine_Sugar,Bad_Quality_Wine_Sugar)\nif p_value < 0.05:\n    print(Ha,\"since P_value is less than 0.05 with a value {}:\".format(p_value))\nelse:\n    print(Ho,\"since p_value is greater than 0.05 with a value of:{}\".format(p_value))\n    \nsns.scatterplot(x=Data['alcohol'],y=Data['quality'],hue=Data['residual_sugar']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ****Let's do a linear regression to see the dependency of quality with other variables, For this exercise our variable of interest would be quality and our independent variables would be other attributes other than quality.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Data_For_Linear=Data.drop(['quality_change'],axis=1)\nData_For_Linear.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Linear=Data_For_Linear.drop(['quality'],axis=1)\ny_Linear=Data_For_Linear['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Linear_train,X_Linear_test,y_Linear_train,y_Linear_test=train_test_split(X_Linear,y_Linear,test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nqual_linear=LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qual_linear.fit(X_Linear_train,y_Linear_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#qual_linear.coef_=pd.DataFrame(qual_linear.coef_,X_Linear.columns,columns=['Coefficients'])\nqual_linear.coef_\nfor idx,col_name in enumerate(X_Linear_train.columns):\n    print(\"The coefficient for {} is {}\".format(col_name,qual_linear.coef_[idx]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qual_linear.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Linear_Pred=qual_linear.predict(X_Linear_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"Actual\": y_Linear_test, \"Predicted\": Linear_Pred})\nTop_25= df.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top_25.plot(kind='bar',figsize=(15,10))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****As we can see , our Linear model has almost done the predictions but it is not that much accurate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"qual_linear.score(X_Linear_train,y_Linear_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qual_linear.score(X_Linear_test,y_Linear_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_Linear_test,Linear_Pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_Linear_test,Linear_Pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_Linear_test, Linear_Pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, Lets perform logistic regression on this same dataset, but our goal is to find out with all given parameters if a wine sample is Good or Bad. So, our variable of interest in this scenario is \"quality_chage\" which I added to the dataset based on the quality column from the original data. I am dropiing the quality column here as it may not be required for this model.****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Data_for_Logistic=Data.copy()\nData_for_Logistic.drop(['quality'],axis=1,inplace=True)\nData_for_Logistic.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spliting Our data using train_test_spli","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=Data_for_Logistic.drop(['quality_change'],axis=1)\ny=Data_for_Logistic['quality_change']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train,X_test,y_Train,y_test=train_test_split(X,y,test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LOG_REG=LogisticRegression(solver=\"liblinear\")\nLOG_REG.fit(X_Train,y_Train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, col_name in enumerate(X_Train.columns):\n    print(\"The coefficient for {} is {}\".format(col_name, LOG_REG.coef_[0][idx]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LOG_REG.intercept_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets calculate the accuracy score for our model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_log=LOG_REG.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred_log, y_test)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Though we have a accuracy score of 88.54% , In a classification problem, it is better to see the other metrics such as recall, precision,f1 score and ROC to ensure our model is good.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's create the confusion matrix ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ncm=metrics.confusion_matrix(y_test,y_pred_log,labels=[\"Good\", \"Bad\"])\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **From our confusion matrix what we infer :**\n* True  Positives: 15 (These are predicted numbers of good quality wine which were really good)\n* True Negatives: 410 (These are predicted numbers of bad quality wine which were really bad)\n* False Positives: 40 (These are predicted numbers of good quality wine which were really bad or the type 1 error)\n* False Negatives: 15 (These are predicted numbers of bad quality wine which were really good or the type 2 error)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,mean_squared_error\n\nprint(classification_report(y_test,y_pred_log))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Planning to further add ROC curve score, Fpr,tpr and AUC etc. Please share your thoughts and valuble comments","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}