{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"06427758-35c7-278f-29a7-5b8e8d9cbd28"},"source":"# Problem definition"},{"cell_type":"markdown","metadata":{"_cell_guid":"70316389-5b0d-f287-c57b-e08ba3ab281e"},"source":"The problem is to predict whether a cancer is benign or malignant using Breast Cancer Wisconsin dataset. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.They describe characteristics of the cell nuclei present in the image."},{"cell_type":"markdown","metadata":{"_cell_guid":"e6aac249-6da8-c433-7b9f-097202bda4db"},"source":"# Features Definition"},{"cell_type":"markdown","metadata":{"_cell_guid":"8c638bcd-9e67-b51a-be60-4dd16130ff89"},"source":"<ol>\n\t<li>ID number</li> \n    <li>Diagnosis (M = malignant, B = benign) </li>\n    <li> (3 - 32) :Ten real-valued features are computed for each cell nucleus: \n\t\t<ol type=\"a\">\n\t\t\t<li> radius (mean of distances from center to points on the perimeter)</li> \n\t\t\t<li>texture (standard deviation of gray-scale values)</li> \n            <li> perimeter</li>\n            <li> area </li>\n            <li> smoothness (local variation in radius lengths) </li>\n            <li> compactness (perimeter^2 / area - 1.0) </li>\n            <li> concavity (severity of concave portions of the contour) </li>\n            <li> concave points (number of concave portions of the contour) </li>\n            <li> symmetry</li>\n            <li> fractal dimension (\"coastline approximation\" - 1)</li>\n\t\t</ol>\n\t </li>\n</ol>"},{"cell_type":"markdown","metadata":{"_cell_guid":"0fa559d7-9a5a-b6be-8628-28f439dd38e1"},"source":"# Load Libraries"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae894509-29e0-af13-acd3-a690bba776d6"},"outputs":[],"source":"from pandas import read_csv\nfrom pandas import set_option\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score"},{"cell_type":"markdown","metadata":{"_cell_guid":"0faeccbc-7db1-7a8a-b9fe-a31cb3121b24"},"source":"# Load dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1f991c4-0a55-3dc6-3c0e-27d23824e0c1"},"outputs":[],"source":"dataset = read_csv(\"../input/data.csv\",header = 0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"57e9f12f-32e7-acd4-d7f4-99f23c716360"},"source":"# Analyze data"},{"cell_type":"markdown","metadata":{"_cell_guid":"b6766175-7ae2-95b3-a33b-63fce194fac0"},"source":"## Descriptive Statistics"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0856390c-ca04-0127-0e31-92182806b1a3"},"outputs":[],"source":"print('The dataset has {} instances and {} attributes.\\n'.format(dataset.shape[0], dataset.shape[1]))\nprint('The attributes are : \\n {} '.format(dataset.dtypes))\n\nset_option('display.width', 100)\nprint('The first 5 rows:\\n{}'.format(dataset.head(5)))\nprint('The last 5 rows:\\n{}'.format(dataset.tail(5)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f26bad9d-f53a-0675-44f7-7079fc634fd5"},"outputs":[],"source":"print(dataset.describe())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aec9c30c-5457-9447-6257-70151280b057"},"outputs":[],"source":"print('Class Distribution \\n{}'.format(dataset.groupby('diagnosis').size()))"},{"cell_type":"markdown","metadata":{"_cell_guid":"3ebd345a-2762-0209-f457-3e4e446a0ebe"},"source":"## Data cleaning"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06c9af22-6add-f868-0a09-a04fc636e437"},"outputs":[],"source":"dataset = dataset.drop('id', 1)\ndataset = dataset.drop('Unnamed: 32', 1)\nprint(dataset.head(5))\nprint(dataset.tail(5))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7459a04f-59e3-d600-d4bd-1d701215e444"},"outputs":[],"source":"print(dataset.describe())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11c93d43-df3a-6ee9-fc90-8f75c7611dde"},"outputs":[],"source":"dataset.isnull().sum().sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6728a890-610c-cee1-d301-362d3177b60e"},"source":"## Data Visualization"},{"cell_type":"markdown","metadata":{"_cell_guid":"182ff680-fed2-b451-9684-33e93281bc13"},"source":"### Histograms"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4d2565a-4d5c-f804-ff63-84325404bddc"},"outputs":[],"source":"dataset.hist(sharex=False, sharey=False,xlabelsize=1, ylabelsize=1 )\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f9511937-306b-f1ec-8f58-97616010e38b"},"source":"### Density plots"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d042e468-344a-32ad-1adf-444599e458be"},"outputs":[],"source":"dataset.plot(kind='density', subplots=True, layout=(8,8), sharex=False, legend=False, fontsize=1)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"5e4a33b3-d45a-5984-f9ae-75d4c365e112"},"source":"###  Box and Whisker plots"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2cd6bbdb-7256-cf60-17b8-d8c59a51e626"},"outputs":[],"source":"dataset.plot(kind= 'box' , subplots=True, layout=(8,8), sharex=False, sharey=False,\n    fontsize=1)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"1e01237b-8dc0-1774-232c-96933f19c7f3"},"source":"### Correlations between Attributes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7796db34-c994-4e26-8078-da68523dcb44"},"outputs":[],"source":"fig = pyplot.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none' )\nfig.colorbar(cax)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7c755231-be5a-0b56-3f1c-a985131b1729"},"source":"# Split the dataset\nLet's use 80% of our dataset for modelling and 20% for validation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c40260f0-208e-c2cb-1b8e-66466f4fc9f1"},"outputs":[],"source":"print(dataset.diagnosis.unique())\ndata = dataset.values\nX = data[:,1:31].astype(float)\nY = data[:,0]\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,\n    test_size=validation_size, random_state=seed)\nprint(Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49699217-9da1-bcbd-784c-6003e8b6657b"},"outputs":[],"source":"print(Y_validation)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aae4c577-2cf4-1803-1140-e79d6ff99c15"},"outputs":[],"source":"print(X_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68120ae0-3a8d-bda6-e48b-01b284bec70d"},"outputs":[],"source":"print(X_validation)"},{"cell_type":"markdown","metadata":{"_cell_guid":"884c296c-a06b-cbc4-df22-bbe41556a585"},"source":" # Prediction models"},{"cell_type":"markdown","metadata":{"_cell_guid":"3180cb04-3084-308a-e409-5575234b0b16"},"source":"We will evaluate six algorithms: \n<ol>\n\t<li>Logistic Regression : LR</li> \n    <li>Linear Discriminant Analysis : LDA</li>\n    <li>Classification and Regression Tree : CART</li>\n    <li>Support Vector Machine : SVM </li>\n    <li>Gaussian Naive Bayes : NB</li>\n    <li>K-Nearest Neighbors: KNN</li>\n</ol>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59e2eab3-b9ce-28f9-6ca8-689f2c94770b"},"outputs":[],"source":"models = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7fe9014f-7d92-f419-b783-aece7fa8f335"},"outputs":[],"source":"num_folds = 10\nseed = 7\nscoring = 'accuracy'\nresults = []\nnames = []\nprint('Mean and Standard Deviation accuracy with 10 folds')\nfor name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print('{}: {} ({})'.format(name, cv_results.mean(), cv_results.std()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca629ff4-e36d-5d88-4f47-4f8449ff7667"},"outputs":[],"source":"fig = pyplot.figure()\nfig.suptitle( 'Algorithm Comparison' )\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"09150957-111e-44cd-d0b6-cc5593c101e9"},"source":"The result shows a good accuracy for LDA, but SVM perform poorly. \nLet's standardize the input and see how it will affect the results"},{"cell_type":"markdown","metadata":{"_cell_guid":"9db44843-2c83-af42-5ace-027dae092903"},"source":"# Prediction model on standardize inputs"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7e0f9d8-c15f-60a1-0ea5-e43cc904801f"},"outputs":[],"source":"pipelines = []\npipelines.append(( 'S_LR' , Pipeline([( 'Scaler' , StandardScaler()),( 'LR' ,\n    LogisticRegression())])))\npipelines.append(( 'S_LDA' , Pipeline([( 'Scaler' , StandardScaler()),( 'LDA' ,\n    LinearDiscriminantAnalysis())])))\npipelines.append(( 'S_KNN' , Pipeline([( 'Scaler' , StandardScaler()),( 'KNN' ,\n    KNeighborsClassifier())])))\npipelines.append(( 'S_CART' , Pipeline([( 'Scaler' , StandardScaler()),( 'CART' ,\n    DecisionTreeClassifier())])))\npipelines.append(( 'S_NB' , Pipeline([( 'Scaler' , StandardScaler()),( 'NB' ,\n    GaussianNB())])))\npipelines.append(( 'S_SVM' , Pipeline([( 'Scaler' , StandardScaler()),( 'SVM' , SVC())])))\nresults = []\nnames = []\nprint(\"Mean and Standard Deviation Accuracy with 10 folds \")\nfor name, model in pipelines:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print('{}: {} ,  {}'.format(name, cv_results.mean(), cv_results.std()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8de98ad-846d-aab0-6aad-1aa7a5f8a090"},"outputs":[],"source":"fig = pyplot.figure()\nfig.suptitle( 'Scaled Algorithm Comparison' )\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"dee03144-bdea-ae23-4c20-756757b2aa5f"},"source":"With scaled input, SVM and LR perform better. \nLet's tune their parameter, and see if we can improve."},{"cell_type":"markdown","metadata":{"_cell_guid":"a5bf3d1e-deb9-5e5a-c02e-1532ab084414"},"source":"# Algorithm Tuning"},{"cell_type":"markdown","metadata":{"_cell_guid":"f7d2d6b1-d315-e242-4f8a-159fd393b396"},"source":"## Tuning Support Vector Machine"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b1b8a92-b28a-1214-33d1-d6fb987000dd"},"outputs":[],"source":"scaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nc_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\nkernel_values = [ 'linear' ,  'poly' ,  'rbf' ,  'sigmoid' ]\nparam_grid = dict(C=c_values, kernel=kernel_values)\nmodel = SVC()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(rescaledX, Y_train)\nprint(\"Best: {} using {}\".format(grid_result.best_score_, grid_result.best_params_))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c88f97f3-3121-c03f-5555-a65db5833220"},"source":"## Tuning Logistic Regression "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaf2a83e-4a42-8360-dfc3-83d96677f024"},"outputs":[],"source":"scaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nc_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\npenalty = ['l1', 'l2']\nparam_grid = dict(C=c_values, penalty=penalty)\nmodel = LogisticRegression()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(rescaledX, Y_train)\nprint(\"Best: {} using {}\".format(grid_result.best_score_, grid_result.best_params_))"},{"cell_type":"markdown","metadata":{"_cell_guid":"ae4fa69e-c209-7e48-5b6e-f87bc67ec884"},"source":"After tuning, Logistic regression has the highest accuracy score (98.24%), with an L2 penalty and a C value of 0.1."},{"cell_type":"markdown","metadata":{"_cell_guid":"367dde13-428b-7d03-1dd6-93e75a6953d9"},"source":"# Validate the model on the validation data"},{"cell_type":"markdown","metadata":{"_cell_guid":"27a2e01a-5351-9408-2192-167bf1dd94d1"},"source":"## Prepare the model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c5d9c50-db40-79ef-97fe-8f6c88d8cb22"},"outputs":[],"source":"scaler = StandardScaler().fit(X_train)\ns_X = scaler.transform(X_train)\nmodel = LogisticRegression(C=0.1, penalty='l2')\nmodel.fit(s_X, Y_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1d8e6219-b483-2699-88a9-4f4b02084dd2"},"source":"## Estimate Accuracy "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17688c95-e485-317a-69ff-a21f78002ac4"},"outputs":[],"source":" s_X_validation = scaler.transform(X_validation)\npredictions = model.predict(s_X_validation)\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be7bdd21-2f9e-f149-f501-8fe53cb9bae2","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}