{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom keras import optimizers\nimport itertools\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nimport matplotlib.pyplot as plt\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fulltrain_df=pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv',header=None)\ntest_df=pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv',header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fulltrain_df = fulltrain_df.sample(frac=1).reset_index(drop=True)\n\ntrain_df, val_df = train_test_split(fulltrain_df, test_size = 0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[187]=train_df[187].astype(int)\nequilibre=train_df[187].value_counts()\nprint(equilibre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" plt.plot(c.iloc[0,:186])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(c.iloc[1,:186])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(c.iloc[2,:186])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(c.iloc[3,:186])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(c.iloc[4,:186])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df[187])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[187]=train_df[187].astype(int)\nequilibre=train_df[187].value_counts()\nprint(equilibre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(equilibre, labels=['N','S','V','F','Q'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%',radius=1.5,textprops={'fontsize': 13})\np=plt.gcf()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\ndf_1=train_df[train_df[187]==1]\ndf_2=train_df[train_df[187]==2]\ndf_3=train_df[train_df[187]==3]\ndf_4=train_df[train_df[187]==4]\ndf_0=(train_df[train_df[187]==0]).sample(n=48483,random_state=42,replace=True)\n\ndf_1_upsample=resample(df_1,replace=True,n_samples=30000,random_state=123)\ndf_2_upsample=resample(df_2,replace=True,n_samples=30000,random_state=124)\ndf_3_upsample=resample(df_3,replace=True,n_samples=30000,random_state=125)\ndf_4_upsample=resample(df_4,replace=True,n_samples=30000,random_state=126)\n\ntrain_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[187]=train_df[187].astype(int)\nequilibre=train_df[187].value_counts()\nprint(equilibre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(c.iloc[0,:186] )\nplt.plot(c.iloc[1,:186] )\nplt.plot(c.iloc[2,:186] )\nplt.plot(c.iloc[3,:186] )\nplt.plot(c.iloc[4,:186] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(equilibre, labels=['N','S','V','F','Q'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%',radius=1.5,textprops={'fontsize': 13})\np=plt.gcf()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_train=train_df[187]\nY_train=to_categorical(target_train)\n\ntarget_val=val_df[187]\nY_val=to_categorical(target_val)\n\n\nX_train=train_df.iloc[:,:186].values\nX_val=val_df.iloc[:,:186].values\n\nX_train = X_train.reshape(len(X_train), X_train.shape[1],1)\nX_val = X_val.reshape(len(X_val), X_val.shape[1],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_test=test_df[187]\nY_test=to_categorical(target_test)\nX_test=test_df.iloc[:,:186].values\nX_test = X_test.reshape(len(X_test), X_test.shape[1],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input,Dense, Convolution1D, MaxPool1D, Flatten, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\ndef get_model():\n        im_shape=(X_train.shape[1],1)\n        inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n        \n\n        \n        x0 = keras.layers.Conv1D(128,8, activation='relu',input_shape=im_shape)(inputs_cnn)  \n        x0= keras.layers.BatchNormalization()(x0)\n        pool0=MaxPool1D(pool_size=(4), strides=(2), padding=\"same\")(x0)\n\n        \n\n        x1 = keras.layers.Conv1D(128,8, activation='relu',input_shape=im_shape)(pool0) \n        x1= keras.layers.BatchNormalization()(x1)\n        pool1=MaxPool1D(pool_size=(4), strides=(2), padding=\"same\")(x1)\n\n        \n        x2 = keras.layers.Conv1D(128,6, activation='relu',input_shape=im_shape)(pool1) \n        x2 = keras.layers.BatchNormalization()(x2)\n        pool2=MaxPool1D(pool_size=(3), strides=(2), padding=\"same\")(x2)\n\n        \n        x3 = keras.layers.Conv1D(128,6, activation='relu',input_shape=im_shape)(pool2) \n        x3 = keras.layers.BatchNormalization()(x3)\n        pool3=MaxPool1D(pool_size=(3), strides=(2), padding=\"same\")(x3)\n\n        \n        x4 = keras.layers.Conv1D(128,4, activation='relu',input_shape=im_shape)(pool3) \n        x4 = keras.layers.BatchNormalization()(x4)\n        pool4=MaxPool1D(pool_size=(3), strides=(1), padding=\"same\")(x4)\n\n        \n        x5 = keras.layers.Conv1D(128,2, activation='relu',input_shape=im_shape)(pool4) \n        x5 = keras.layers.BatchNormalization()(x5)\n        pool5=MaxPool1D(pool_size=(3), strides=(1), padding=\"same\")(x5)\n\n        \n        x6 = keras.layers.Conv1D(128,2, activation='relu',input_shape=im_shape)(pool5) \n        x6 = keras.layers.BatchNormalization()(x6)\n        pool6=MaxPool1D(pool_size=(2), strides=(1), padding=\"same\")(x6)\n\n        \n        x7 = keras.layers.Conv1D(128,2, activation='relu',input_shape=im_shape)(pool6) \n        x7 = keras.layers.BatchNormalization()(x7)\n        pool7=MaxPool1D(pool_size=(2), strides=(1), padding=\"same\")(x7)\n    \n    \n        x = Flatten()(pool7)\n        x = keras.layers.BatchNormalization()(x)\n        \n        dense_1 = Dense(32, activation='relu')(x)\n        dense_2 = Dense(32, activation='relu')(dense_1)\n\n        out = keras.layers.Dense(5, activation='softmax')(dense_2)\n        return keras.Model(inputs=inputs_cnn, outputs=out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_model()\n\n\n\nmodel.compile(optimizer = 'adam' ,loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])\nhistory=model.fit(X_train, Y_train,epochs=10, batch_size=32,validation_data=(X_val,Y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score, acc = model.evaluate(X_test, Y_test,\n                            batch_size=50)\nprint('Test score:', score)\nprint('Test accuracy:', acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss=history.history['loss']\nval_loss=history.history['val_loss']\ntrain_acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nxc=range(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1,figsize=(10,8),facecolor='skyblue')\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('Number of Epochs',fontsize=18)\nplt.ylabel('Loss',fontsize=18)\nplt.title('Training_loss vs Validation_loss',fontsize=20, fontweight='bold')\nplt.grid(True)\nplt.legend(['Training','Validation'])\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1,figsize=(10,8),facecolor='skyblue')\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('Number of Epochs',fontsize=18)\nplt.ylabel('Accuracy',fontsize=18)\nplt.title('Training_accuracy vs Validation_accuracy',fontsize=20, fontweight='bold')\nplt.grid(True)\nplt.legend(['Training','Validation'])\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,classification_report\n\ny_pred= model.predict(X_test)\n#print(X_test)\ny_pred=np.argmax(y_pred,axis=1)\n#print(y_pred)\n\n#y_pred=model.predict_classes(X_test)\n\n\n#target_names= classes['N', 'S', 'V', 'F', 'Q']\n#print(classification_report(np.argmax(y_test,axis=1),y_pred,target_names=))\nsns.set(font_scale=1.5)\ncm=confusion_matrix(np.argmax(Y_test,axis=1),y_pred)\nprint(cm)\n\nimport itertools\nfrom sklearn.metrics import plot_confusion_matrix\n\n    \n#plt.figure(figsize=(10, 10))\n#plot_confusion_matrix(cm, classes=['N', 'S', 'V', 'F', 'Q'],normalize=True,\n                     # title='Confusion matrix, with normalization')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n\nimport numpy as np\nrounded_labels=np.argmax(Y_test, axis=1)\nrounded_labels[1]\n\ncm = confusion_matrix(rounded_labels, y_pred)\n# Normalise\ncmn = cm.astype('float') /cm.sum(axis=1)[:, np.newaxis]\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cmn, annot=True, fmt='.2f', xticklabels= ['N', 'S', 'V', 'F', 'Q'], yticklabels=['N', 'S', 'V', 'F', 'Q'])\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show(block=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}