{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"The goal of given code is to compare different models'prediction on quite east dataset Mushroom."},{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_palette('husl')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport pandas_profiling\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import combinations\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier  # for K nearest neighbours\nfrom sklearn import svm  #for Support Vector Machine (SVM) Algorithm\nfrom sklearn import metrics #for checking the model accuracy\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom catboost import Pool, CatBoostClassifier\n\n\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom scipy.stats import skew \nfrom sklearn.preprocessing import StandardScaler\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndata=pd.read_csv('../input/mushroom-classification/mushrooms.csv')\ny=data['class'].copy()\n#y=data['class'].copy()\n#data=data.drop(['class'],axis=1)\n#All columns are object\n#22 columns\n\n#data.nunique()\nprint('Proportion of e/p','\\n',\n      data['class'].value_counts())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Graphs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#s.unstack(level=0)\nfor color in ['cap-color','gill-color','stalk-color-above-ring','stalk-color-below-ring','veil-color','spore-print-color']:\n    a=(pd.DataFrame(data.groupby([color,'class'])['class'].count()).unstack())\n    fig = plt.figure()\n    a.plot(kind='bar', legend=True, figsize=(9,3), title=color)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## By color graphs we see that in some prevale some type of mushrooms.For future models` improvement there is a sense to create features combination"},{"metadata":{},"cell_type":"markdown","source":"# Preparing data for model"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=data.drop(['class'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1= pd.get_dummies(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_mass_calc(X,y):\n\n    #Some parameters\n\n    svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n\n    #Split\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n    #Standartize\n\n    sc = StandardScaler()\n    sc.fit(X_train)\n    X_train_std = sc.transform(X_train)\n    X_test_std = sc.transform(X_test)\n    a=[]\n   \n    #Search knn_param\n    a_index=list(range(1,11))\n    knn=[1,2,3,4,5,6,7,8,9,10]\n    a=[]\n    for i in knn:\n        model=KNeighborsClassifier(n_neighbors=i) \n        model.fit(X_train_std, y_train)\n        prediction=model.predict(X_test_std)\n        a.append(pd.Series(metrics.accuracy_score(prediction,y_test)))\n\n\n    #Max_Score_KNN\n    knn=pd.DataFrame(knn)\n    a=pd.DataFrame(a)\n    knn_data=pd.concat([knn,a],axis=1)\n    knn_data.columns=['Neig','Score']\n    knn_take=int(knn_data[knn_data['Score']==knn_data['Score'].max()][:1]['Neig'])\n\n    #model\n    #SolveLater How to write names automat\n    x=['CatB','XGB','RandomF','NB','svm.SVC','Log','DTr',str('KN='+str(knn_take))]\n    #Form for cycle\n\n    models=[CatBoostClassifier(),XGBClassifier(),RandomForestClassifier(),GaussianNB(),svm,LogisticRegression(),DecisionTreeClassifier(),KNeighborsClassifier(n_neighbors=knn_take)]\n    a_index=list(range(1,len(models)+1))\n    a=[]\n    for model in models:\n\n        model.fit(X_train_std, y_train)\n        prediction=model.predict(X_test_std)\n        a.append(pd.Series(metrics.accuracy_score(prediction,y_test)))\n    plt.plot(x, a)\n    #plt.xticks(x)\n    #MAX_Score+Model\n    x=pd.DataFrame(x)\n    a=pd.DataFrame(a)\n    all_scores=pd.concat([x,a],axis=1)\n    all_scores.columns=['model','Score']\n    print('Max_score:',all_scores[all_scores['Score']==all_scores['Score'].max()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mass_calc(data1,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"Majority of models gave us excellent result!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}