{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Desenvolvido por Ronald Albert, 118021192\nimport pandas as pd\nimport numpy as np\nimport time\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T04:51:39.883119Z","iopub.execute_input":"2021-06-12T04:51:39.883434Z","iopub.status.idle":"2021-06-12T04:51:41.0409Z","shell.execute_reply.started":"2021-06-12T04:51:39.883405Z","shell.execute_reply":"2021-06-12T04:51:41.039851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pesquisa Nacional por Amostra de Domícilios - 2015\nA Pesquisa Nacional por Amostra de Domicílios - PNAD investiga anualmente, de forma permanente, características gerais da população, de educação, trabalho, rendimento e habitação e outras, com periodicidade variável, de acordo com as necessidades de informação para o país, como as características sobre migração, fecundidade, nupcialidade, saúde, segurança alimentar, entre outros temas. O levantamento dessas estatísticas constitui, ao longo dos 49 anos de realização da pesquisa, um importante instrumento para formulação, validação e avaliação de políticas orientadas para o desenvolvimento socioeconômico e a melhoria das condições de vida no Brasil.\n\n---\n\nPara trabalhar com a Árvore de Decisão, os dados numéricos que se caracterizam como contínuos serão discretizados, e dados que já são categorizados são substituidos exatamente pela categoria que eles representam, por exemplo, no dataset original a coluna 'Sexo', pode assumir os valores 1 e 0, sendo 1 -> Masculino e 0 -> Feminino, dessa forma esses valores serão substituídos, pelas strings que, de fato, definem tal categoria.\n\n---\n\nOs grupos de renda serão categorizados pelos grupos de classes sociais do IBGE:<br>\nE: renda menor do que 1 salario mínimo <br>\nD: renda entre 1 salario mínimo e 3 salários mínimos <br>\nC: renda entre 3 salários mínimos e 5 salários mínimos <br>\nB: renda entre 5 salários mínimos e 15 salários mínimos <br>\nA: renda maior do que 15 salários mínimos <br>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/testes/dados.csv')\n\ndef returnGender(g):\n    if(g == 1):\n        return \"Masculino\"\n    else:\n        return \"Feminino\"\n    \ndef returnUF(u):\n    return {\n        11: \"Rondônia\",\n        12: \"Acre\",\n        13: \"Amazonas\",\n        14: \"Roraima\",\n        15: \"Pará\",\n        16: \"Amapá\",\n        17: \"Tocantis\",\n        21: \"Maranhão\",\n        22: \"Piauí\",\n        23: \"Ceará\",\n        24: \"Rio Grande do Norte\",\n        25: \"Paraíba\",\n        26: \"Pernambuco\",\n        27: \"Alagoas\",\n        28: \"Sergipe\",\n        29: \"Bahia\",\n        31: \"Minas Gerais\",\n        32: \"Espírito Santo\",\n        33: \"Rio de Janeiro\",\n        35: \"São Paulo\",\n        41: \"Paraná\",\n        42: \"Santa Catarina\",\n        43: \"Rio Grande do Sul\",\n        50: \"Mato Grosso do Sul\",\n        51: \"Mato Grosso\",\n        52: \"Goias\",\n        53: \"Distrito Federal\"\n    }[u]\n\ndef returnEthnicGroup(e):\n    return {\n        0: \"Indígena\",\n        2: \"Branco\",\n        4: \"Negro\",\n        6: \"Asiático\",\n        8: \"Pardo\",\n        9: \"Sem Declaração\"\n    }[e]\n\ndef returnGruposDeIdade(i):\n    if(i <= 18):\n        return \"Menor de 18 anos\"\n    elif(i <= 25):\n        return \"Entre 18 e 25 anos\"\n    elif(i <= 40):\n        return \"Entre 25 e 40 anos\"\n    elif (i <= 60):\n        return \"Entre 40 e 60 anos\"\n    else:\n        return \"Maior de 60 anos\"\n\ndef returnAnosDeEstudo(e):\n    if(e == 17):\n        return \"Não Informado\"\n    return e - 1\n\ndef returnClasseSocial(r):\n    salario_minimo = 1100\n    if(r <= salario_minimo):\n        return \"E\"\n    elif(r <= salario_minimo*3):\n        return \"D\"\n    elif(r <= salario_minimo*5):\n        return \"C\"\n    elif(r <= salario_minimo*15):\n        return \"B\"\n    else:\n        return \"A\"\n\n\ndf['Sexo'] = df['Sexo'].apply(lambda x: returnGender(x))\ndf['UF'] = df['UF'].apply(lambda x: returnUF(x))\ndf['Cor'] = df['Cor'].apply(lambda x: returnEthnicGroup(x))\ndf['Idade'] = df['Idade'].apply(lambda x: returnGruposDeIdade(x))\ndf['Anos de Estudo'] = df['Anos de Estudo'].apply(lambda x: returnAnosDeEstudo(x))\ndf['Renda'] = df['Renda'].apply(lambda x: returnClasseSocial(x))","metadata":{"execution":{"iopub.status.busy":"2021-06-12T04:51:45.05418Z","iopub.execute_input":"2021-06-12T04:51:45.054515Z","iopub.status.idle":"2021-06-12T04:51:45.342135Z","shell.execute_reply.started":"2021-06-12T04:51:45.054484Z","shell.execute_reply":"2021-06-12T04:51:45.341098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Entropia e Indice de Gini\n\nSão definidos as funções para cáculo de entropia e ganho de determinada que serão usados na construção da Árvore de Decisão.","metadata":{}},{"cell_type":"code","source":"def calcularEntropia(df, coluna):\n    values = df[coluna].unique()\n    entropia = 0\n    for i in values:\n        pi = len(df[df[coluna].eq(i)])/len(df)\n        entropia += pi*np.log2(pi)\n    return -entropia\n    \ndef calcularGanho(df, resultado, coluna):\n    values = df[coluna].unique()\n    ganho = 0\n    for i in values:\n        pi = len(df[df[coluna].eq(i)])/len(df)\n        ganho += pi * calcularEntropia(df[df[coluna].eq(i)], resultado)\n    ganho = calcularEntropia(df, resultado) - ganho\n    return ganho\n\ndef calcularIndiceDeGiniParaValor(df, resultado, valor, coluna):\n    gini = 0\n    for value in df[resultado].unique():\n        pi = len(df[df[coluna].eq(valor) & df[resultado].eq(value)])/len(df[df[coluna].eq(valor)])\n        gini += pi * pi\n    gini = 1 - gini\n    return gini\n    \ndef calcularIndiceDeGini(df, resultado, coluna):\n    values = df[coluna].unique()\n    gini = 0\n    for i in values:\n        pi = len(df[df[coluna].eq(i)])/len(df)\n        gini += calcularIndiceDeGiniParaValor(df, resulado, i, coluna) * pi\n    \n    return gini","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A árvore de decisão\n\nA classe nó abaixo é a definição da arvóre, sendo a variável 'atributo' o atributo do dataset que representa aquele específico Nó, no caso do dataset em questão os possíveis atributos de um Nó são: ('Anos de Estudo', 'Sexo', 'Idade', 'Cor' e 'UF'), todo o nó final de uma arvóres terá como atributo um determinado valor da coluna que se procura prever, no caso do exemplo os atributos no ultimo nó de uma árvore podem ser ('A', 'B', 'C', 'D' e 'E') e a váriavel galho assumirá a string '.'<br>\n\nA variável galhos da classe Nó, representa os próximos níveis da árvore a partir do corrente nó, a variável é um dicionário, cuja as chaves são os possíveis valores do atributo daquele nó, e os valores de cada uma das chaves do dicionário 'galhos', são os nós do seguinte nível da árvores.\nComo exemplo uma variável galhos de um Nó, cujo atributo é 'Sexo', terá como valor:<br>\n`{\n    \"Masculino\": Proximo Nó,\n    \"Feminino\": Proximo Nó\n}`\n\n---\nO algoritmo de implementação da Árvore de Decisão, usa a variável funcao (definidas anteriormente, calcularGanho() e calcularIndiceDeGini()) para decidir qual a melhor coluna para caracterizar o primeiro nó da árvore, e constroi os seguintes nós a partir desse de forma recursiva com os critérios de parada sendo, o dataset se torna vazio, o dataframe ter somente um valor da coluna de resultado (no caso do exemplo, 'Renda'), e não existirem mais colunas para serem avalidas, desse forma a árvore retornará o nó inicial que por sua vez referencia todos os outros.","metadata":{}},{"cell_type":"code","source":"class No:\n    def __init__(self, atributo, galhos):\n        self.atributo = atributo\n        self.galhos = galhos\n        \ndef construirArvoreDeDecisao(df, colunas, resultado, resultadoAnterior=0, funcao=calcularGanho, dfOriginal=df):\n    if(len(df[resultado]) == 0):\n        return No(resultadoAnterior, '.')\n    elif(len(df[resultado].unique()) == 1):\n        return No(df[resultado].iloc[0], '.')\n    elif(len(colunas) == 0):\n        return No(df[resultado].value_counts().index[0], '.')\n    \n    maiorGanhoDeColunas = -np.inf\n    for i in colunas:\n        atualGanho = funcao(df, resultado, i)\n        if maiorGanhoDeColunas < atualGanho:\n            colunaEscolhida = i\n            maiorGanhoDeColunas = atualGanho\n    \n    galhos = {}\n    for i in dfOriginal[colunaEscolhida].unique():\n        galhos[i] = construirArvoreDeDecisao(df[df[colunaEscolhida].eq(i)], list(set(colunas) - set([colunaEscolhida])), resultado, df[resultado].value_counts().index[0], funcao, dfOriginal)\n        \n    return No(colunaEscolhida, galhos)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Buscar na Àrvore\n\nA função de buscar na árvore, desce pelos nó da árvore até encontrar o valor '.' na variável galhos, o que indica o final da árvore, tal busca é realizada de maneira recursiva.\n\n---\n\nA entrada para a função são a árvore e uma variável indivíduo, que é um dicionário cujas chaves são as colunas (com execeção da coluna resultado), e os valores são os valores que determinado indivíduo possui para aquelas colunas.","metadata":{}},{"cell_type":"code","source":"def buscarNaArvore(arvore, individuo):\n    if(arvore.galhos == '.'):\n        return arvore.atributo\n    else:\n        return buscarNaArvore(arvore.galhos[individuo[arvore.atributo]], individuo)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-Fold Validation\n\nNa seguinte célula são realizados 10 experimentos seguindo o 5-fold validation, são 5 experimentos de k-fold validation com k igual a 5 usando como função o cálculo de ganho e outros 5 usando como função o índice de gini.\n\n---\n\nO resultado de cada um dos experimentos é uma tabelas com linhas ['A', 'B', 'C', 'D', 'E', 'Total'] e colunas ['A', 'B', 'C', 'D', 'E', 'Total', 'Precisão', 'Reconhecimento'].<br>\nAs colunas referentes as classes e a coluna 'Total' representam todos os indivíduos do dataset que foram classificados daquela maneira, enquanto as linhas referentes as classes e a linha 'Total' representam todas os indivíduos do dataset, que foram classificados daquela maneira pela Árvore de Decisão. Como exemplo, o valor na coluna 'B' e linha 'C', representam todos os indivuos que são realmente da classe social 'B', mas que foram classificados como 'C' pela Árvore de Decisão. <br>\n\nA coluna 'Precisão' do dataframe na linha 'A', é a proporção de todos os indivíduos que o algoritmo corretamente classificou como 'A' pela quantidade de indivíduos classificados, pelo algoritmo como A.<br>\nA coluna 'Reconhecimento' do dataframe na linha 'A', é a proporção de todos os indivíduos que o algoritmo corretamente classificou como 'A' pela quantidade de indivíduos que são realmente da classe social 'A'.\n","metadata":{}},{"cell_type":"code","source":"def kFoldValidation(k, df, funcao=calcularGanho):\n    resto = len(df) % k\n    resultadosExperimentos = []\n    resultadosBusca = {}\n    \n    for i in range(0, k):\n        df = df.sample(frac=1)\n        teste = df.iloc[int((i/k)*len(df)):int(((i+1)/k)*len(df) + 1)]\n        treinamento = df.iloc[:int((i/k)*len(df))].append(df.iloc[int(((i+1)/k)*len(df) + 1):])\n        arvore = construirArvoreDeDecisao(treinamento, ['UF', 'Sexo', 'Idade', 'Cor', 'Anos de Estudo'], 'Renda', funcao)\n        for r in df['Renda'].unique():\n            resultadosBusca[r] = {}\n            for f in df['Renda'].unique():\n                resultadosBusca[r][f] = 0\n        for e in teste.values:\n            v = buscarNaArvore(arvore, {'UF': e[0], 'Sexo': e[1], 'Idade': e[2], 'Cor': e[3], 'Anos de Estudo': e[4]})\n            resultadosBusca[e[5]][v] += 1\n        \n        dfAux = pd.DataFrame.from_dict(resultadosBusca)\n        dfAux = dfAux.sort_index(ascending=True).sort_index(axis=1,ascending=True)\n        dfAux['Total'] = dfAux.sum(axis=1)\n        dfAux.loc['Total'] = dfAux.sum(axis=0)\n        dfAux['Precisão'] = np.divide(np.diag(dfAux), dfAux['Total'])\n        dfAux['Precisão']['Total'] = np.sum(np.diag(dfAux)[:-1])/dfAux['Total'].loc['Total']\n        dfAux['Reconhecimento'] = np.divide(np.diag(dfAux), dfAux.loc['Total'][:-1])\n        dfAux['Reconhecimento']['Total'] = np.sum(np.diag(dfAux)[:-1])/dfAux['Total'].loc['Total']\n        resultadosExperimentos.append(dfAux.copy())\n    \n    return resultadosExperimentos\n\nkfoldResultsEntropia = kFoldValidation(5, df)\nkfoldResultsIndiceDeGini = kFoldValidation(5, df, calcularIndiceDeGini)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resultados Entropia\n\nResultados dos experimento usando a função de ganho como parâmetro para escolher as colunas","metadata":{}},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[3])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[4])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resultados Indice de Gini\n\nResultados dos experimento usando o Indice de Gini como parâmetro para escolher as colunas","metadata":{}},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[3])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[4])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A seguir será construido o dataframe para trabalhar com o método de Árvore de decisão da biblioteca sklearn","metadata":{}},{"cell_type":"code","source":"sklearnDf = pd.get_dummies(df[['Sexo','UF','Cor','Idade', 'Anos de Estudo']])\nsklearnDf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = DecisionTreeClassifier(criterion=\"entropy\")\n\nclf = clf.fit(sklearnDf[:15368*4], df.Renda[:15368*4])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-Fold Validation Scikit\nAqui temos a implementação do método k-fold validation, como no exemplo anterior, com a exceção de que, dessa vez usamos o método com a ávore construida pela biblioteca do scikit learn.\n\n---\n\nApesar de usarmos um diferente método de construção de árvore o retorno dos experimentos é o mesma tabela.","metadata":{}},{"cell_type":"code","source":"def kFoldValidationScikit(k, df, criterio=\"entropy\"):\n    resto = len(df) % k\n    resultadosExperimentos = []\n    resultadosBusca = {}\n    \n    for i in range(0, k):\n        df = df.sample(frac=1)\n        teste = df.iloc[int((i/k)*len(df)):int(((i+1)/k)*len(df) + 1)]\n        treinamento = df.iloc[:int((i/k)*len(df))].append(df.iloc[int(((i+1)/k)*len(df) + 1):])\n        arvore = DecisionTreeClassifier(criterion=criterio).fit(pd.get_dummies(treinamento[['Sexo','UF','Cor','Idade', 'Anos de Estudo']]), treinamento['Renda'])\n        for r in df['Renda'].unique():\n            resultadosBusca[r] = {}\n            for f in df['Renda'].unique():\n                resultadosBusca[r][f] = 0\n        prediction = clf.predict(pd.get_dummies(teste[['Sexo','UF','Cor','Idade', 'Anos de Estudo']]))       \n        for e in range(len(prediction)):\n            resultadosBusca[teste['Renda'].iloc[e]][prediction[e]] += 1 \n        \n        dfAux = pd.DataFrame.from_dict(resultadosBusca)\n        dfAux = dfAux.sort_index(ascending=True).sort_index(axis=1,ascending=True)\n        dfAux['Total'] = dfAux.sum(axis=1)\n        dfAux.loc['Total'] = dfAux.sum(axis=0)\n        dfAux['Precisão'] = np.divide(np.diag(dfAux), dfAux['Total'])\n        dfAux['Precisão']['Total'] = np.sum(np.diag(dfAux)[:-1])/dfAux['Total'].loc['Total']\n        dfAux['Reconhecimento'] = np.divide(np.diag(dfAux), dfAux.loc['Total'][:-1])\n        dfAux['Reconhecimento']['Total'] = np.sum(np.diag(dfAux)[:-1])/dfAux['Total'].loc['Total']\n        resultadosExperimentos.append(dfAux.copy())\n    \n    return resultadosExperimentos\n\nkfoldResultsEntropia = kFoldValidationScikit(5, df, 'entropy')\nkfoldResultsIndiceDeGini = kFoldValidationScikit(5, df, 'gini')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resultados Entropia\n\nResultados dos experimento usando a função de ganho como parâmetro para escolher as colunas","metadata":{}},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[3])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsEntropia[4])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resultados Indice de Gini\n\nResultados dos experimento usando o Indice de Gini como parâmetro para escolher as colunas","metadata":{}},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[3])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.from_dict(kfoldResultsIndiceDeGini[4])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aplicando o post-prunning \n\nAs seguinte células, aplicam o método da biblioteca sklearn na árvore construida de cost_complexity_prunning_path, que nos retorna uma lista de valores de 0 a 1, tais valores que representam o quanto da árvore deve ser cortado para um melhor desempenho","metadata":{}},{"cell_type":"code","source":"path = clf.cost_complexity_pruning_path(pd.get_dummies(df[['Sexo','UF','Cor','Idade', 'Anos de Estudo']]), df['Renda']) \nalphas = path['ccp_alphas']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Depois de construida a lista de alphas realizamos o teste para cada um deles com as árvores diferentes árvores para cada, na célula seguinte","metadata":{}},{"cell_type":"code","source":"accuracy_train, accuracy_test = [], []\nfor i in alphas[alphas>0]:\n    i = i if i >= 0 else i*-1\n    \n    tree = DecisionTreeClassifier(ccp_alpha=i)\n    \n    tree.fit(sklearnDf[:15368*4], df.Renda[:15368*4])\n    y_train_pred = tree.predict(sklearnDf[:15368*4])\n    y_test_pred = tree.predict(sklearnDf[15368:])\n    \n    accuracy_train.append(metrics.accuracy_score(df.Renda[:15368*4], y_train_pred))\n    accuracy_test.append(metrics.accuracy_score(df.Renda[15368:], y_test_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Desempenho do Post-Pruning\nO seguinte gráfico nos mostra o desempenho do post-pruning para os exemplos de treino e de teste, o gráfico é um plot da AcuráciaXalpha de corte da Árvore.<br>\nPelo gráfico podemos perceber que o melhor desempenho do algoritmo aconteceu, quando o nosso valor para o alpha da árvore era igual a 0, ou seja, uma possível poda na Árvore pioraria o desempenho das suas previsões","metadata":{}},{"cell_type":"code","source":"sns.set()\nplt.figure(figsize=(14,7))\nsns.lineplot(y=accuracy_train, x=alphas[alphas>0])\nsns.lineplot(y=accuracy_test, x=alphas[alphas>0])\nplt.xticks(ticks=np.arange(0.00, 0.25, 0.01))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}