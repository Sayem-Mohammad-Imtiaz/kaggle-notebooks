{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split, cross_val_predict\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n%matplotlib inline\n\nSMALL_SIZE = 10\nMEDIUM_SIZE = 12\n\nplt.rc('font', size=SMALL_SIZE)\nplt.rc('axes', titlesize=MEDIUM_SIZE)\nplt.rc('axes', labelsize=MEDIUM_SIZE)\nplt.rcParams['figure.dpi']=150\n\n#sdss_df = pd.read_csv('Skyserver_SQL2_27_2018 6_51_39 PM.csv', skiprows=1)\nsdss_df = pd.read_csv('/kaggle/input/sloan-digital-sky-survey/Skyserver_SQL2_27_2018 6_51_39 PM.csv', skiprows=0)\n\nsdss_df.head()\n\nsdss_df.info()\n\nsdss_df.describe()\n\nsdss_df['class'].value_counts()\n\nsdss_df.columns.values\n\nsdss_df.drop(['objid', 'run', 'rerun', 'camcol', 'field', 'specobjid'], axis=1, inplace=True)\nsdss_df.head(1)\n\nfig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))\nax = sns.distplot(sdss_df[sdss_df['class']=='STAR'].redshift, bins = 30, ax = axes[0], kde = False)\nax.set_title('Star')\nax = sns.distplot(sdss_df[sdss_df['class']=='GALAXY'].redshift, bins = 30, ax = axes[1], kde = False)\nax.set_title('Galaxy')\nax = sns.distplot(sdss_df[sdss_df['class']=='QSO'].redshift, bins = 30, ax = axes[2], kde = False)\nax = ax.set_title('QSO')\n\nfig, axes = plt.subplots(nrows=1, ncols=1,figsize=(16, 4))\nax = sns.lvplot(x=sdss_df['class'], y=sdss_df['dec'], palette='coolwarm')\nax.set_title('dec')\n\nfig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))\nfig.set_dpi(100)\nax = sns.heatmap(sdss_df[sdss_df['class']=='STAR'][['u', 'g', 'r', 'i', 'z']].corr(), ax = axes[0], cmap='coolwarm')\nax.set_title('Star')\nax = sns.heatmap(sdss_df[sdss_df['class']=='GALAXY'][['u', 'g', 'r', 'i', 'z']].corr(), ax = axes[1], cmap='coolwarm')\nax.set_title('Galaxy')\nax = sns.heatmap(sdss_df[sdss_df['class']=='QSO'][['u', 'g', 'r', 'i', 'z']].corr(), ax = axes[2], cmap='coolwarm')\nax = ax.set_title('QSO')\n\nsns.lmplot(x='ra', y='dec', data=sdss_df, hue='class', fit_reg=False, palette='coolwarm', size=6, aspect=2)\nplt.title('Equatorial coordinates')\n\nsdss_df_fe = sdss_df\n\n# encode class labels to integers\nle = LabelEncoder()\ny_encoded = le.fit_transform(sdss_df_fe['class'])\nsdss_df_fe['class'] = y_encoded\n\n# Principal Component Analysis\npca = PCA(n_components=3)\nugriz = pca.fit_transform(sdss_df_fe[['u', 'g', 'r', 'i', 'z']])\n\n# update dataframe \nsdss_df_fe = pd.concat((sdss_df_fe, pd.DataFrame(ugriz)), axis=1)\nsdss_df_fe.rename({0: 'PCA_1', 1: 'PCA_2', 2: 'PCA_3'}, axis=1, inplace = True)\nsdss_df_fe.drop(['u', 'g', 'r', 'i', 'z'], axis=1, inplace=True)\nsdss_df_fe.head()\n\nscaler = MinMaxScaler()\nsdss = scaler.fit_transform(sdss_df_fe.drop('class', axis=1))\n\nX_train, X_test, y_train, y_test = train_test_split(sdss, sdss_df_fe['class'], test_size=0.33)\n\nknn = KNeighborsClassifier()\ntraining_start = time.perf_counter()\nknn.fit(X_train, y_train)\ntraining_end = time.perf_counter()\nprediction_start = time.perf_counter()\npreds = knn.predict(X_test)\nprediction_end = time.perf_counter()\nacc_knn = (preds == y_test).sum().astype(float) / len(preds)*100\nknn_train_time = training_end-training_start\nknn_prediction_time = prediction_end-prediction_start\nprint(\"Scikit-Learn's K Nearest Neighbors Classifier's prediction accuracy is: %3.2f\" % (acc_knn))\nprint(\"Time consumed for training: %4.3f seconds\" % (knn_train_time))\nprint(\"Time consumed for prediction: %6.5f seconds\" % (knn_prediction_time))\n\nfrom sklearn.preprocessing import MaxAbsScaler\nscaler_gnb = MaxAbsScaler()\nsdss = scaler_gnb.fit_transform(sdss_df_fe.drop('class', axis=1))\nX_train_gnb, X_test_gnb, y_train_gnb, y_test_gnb = train_test_split(sdss, sdss_df_fe['class'], test_size=0.33)\n\ngnb = GaussianNB()\ntraining_start = time.perf_counter()\ngnb.fit(X_train_gnb, y_train_gnb)\ntraining_end = time.perf_counter()\nprediction_start = time.perf_counter()\npreds = gnb.predict(X_test_gnb)\nprediction_end = time.perf_counter()\nacc_gnb = (preds == y_test_gnb).sum().astype(float) / len(preds)*100\ngnb_train_time = training_end-training_start\ngnb_prediction_time = prediction_end-prediction_start\nprint(\"Scikit-Learn's Gaussian Naive Bayes Classifier's prediction accuracy is: %3.2f\" % (acc_gnb))\nprint(\"Time consumed for training: %4.3f seconds\" % (gnb_train_time))\nprint(\"Time consumed for prediction: %6.5f seconds\" % (gnb_prediction_time))\n\nxgb = XGBClassifier(n_estimators=100)\ntraining_start = time.perf_counter()\nxgb.fit(X_train, y_train)\ntraining_end = time.perf_counter()\nprediction_start = time.perf_counter()\npreds = xgb.predict(X_test)\nprediction_end = time.perf_counter()\nacc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\nxgb_train_time = training_end-training_start\nxgb_prediction_time = prediction_end-prediction_start\nprint(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\nprint(\"Time consumed for training: %4.3f\" % (xgb_train_time))\nprint(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))\n\nrfc = RandomForestClassifier(n_estimators=10)\ntraining_start = time.perf_counter()\nrfc.fit(X_train, y_train)\ntraining_end = time.perf_counter()\nprediction_start = time.perf_counter()\npreds = rfc.predict(X_test)\nprediction_end = time.perf_counter()\nacc_rfc = (preds == y_test).sum().astype(float) / len(preds)*100\nrfc_train_time = training_end-training_start\nrfc_prediction_time = prediction_end-prediction_start\nprint(\"Scikit-Learn's Random Forest Classifier's prediction accuracy is: %3.2f\" % (acc_rfc))\nprint(\"Time consumed for training: %4.3f seconds\" % (rfc_train_time))\nprint(\"Time consumed for prediction: %6.5f seconds\" % (rfc_prediction_time))\n\nsvc = SVC()\ntraining_start = time.perf_counter()\nsvc.fit(X_train, y_train)\ntraining_end = time.perf_counter()\nprediction_start = time.perf_counter()\npreds = svc.predict(X_test)\nprediction_end = time.perf_counter()\nacc_svc = (preds == y_test).sum().astype(float) / len(preds)*100\nsvc_train_time = training_end-training_start\nsvc_prediction_time = prediction_end-prediction_start\nprint(\"Scikit-Learn's Support Vector Machine Classifier's prediction accuracy is: %3.2f\" % (acc_svc))\nprint(\"Time consumed for training: %4.3f seconds\" % (svc_train_time))\nprint(\"Time consumed for prediction: %6.5f seconds\" % (svc_prediction_time))\n\nresults = pd.DataFrame({\n    'Model': ['KNN', 'Naive Bayes', \n              'XGBoost', 'Random Forest', 'SVC'],\n    'Score': [acc_knn, acc_gnb, acc_xgb, acc_rfc, acc_svc],\n    'Runtime Training': [knn_train_time, gnb_train_time, xgb_train_time, rfc_train_time, \n                         svc_train_time],\n    'Runtime Prediction': [knn_prediction_time, gnb_prediction_time, xgb_prediction_time, rfc_prediction_time,\n                          svc_prediction_time]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Model')\nresult_df\n\nfrom sklearn.model_selection import cross_val_score\nrfc_cv = RandomForestClassifier(n_estimators=100)\nscores = cross_val_score(rfc_cv, X_train, y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())\n\nxgb_cv = XGBClassifier(n_estimators=100)\nscores = cross_val_score(xgb_cv, X_train, y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())\n\nimportances = pd.DataFrame({\n    'Feature': sdss_df_fe.drop('class', axis=1).columns,\n    'Importance': xgb.feature_importances_\n})\nimportances = importances.sort_values(by='Importance', ascending=False)\nimportances = importances.set_index('Feature')\nimportances\n\nimportances.plot.bar()\n\nscaler = MinMaxScaler()\nsdss = pd.DataFrame(scaler.fit_transform(sdss_df_fe.drop(['mjd', 'class'], axis=1)), columns=sdss_df_fe.drop(['mjd', 'class'], axis=1).columns)\nsdss['class'] = sdss_df_fe['class']\n\nsdss.head()\n\nsdss.to_csv('sdss_data.csv')\n\nX_train, X_test, y_train, y_test = train_test_split(sdss.drop('class', axis=1), sdss['class'],\n                                                   test_size=0.33)\n\nxgboost = XGBClassifier(max_depth=5, learning_rate=0.01, n_estimators=100, gamma=0, \n                        min_child_weight=1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.005)\n\nxgboost.fit(X_train, y_train)\npreds = xgboost.predict(X_test)\n\naccuracy = (preds == y_test).sum().astype(float) / len(preds)*100\n\nprint(\"XGBoost's prediction accuracy WITH optimal hyperparameters is: %3.2f\" % (accuracy))\n\nxgb_cv = XGBClassifier(n_estimators=100)\nscores = cross_val_score(xgb_cv, X_train, y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())\n\nunique, counts = np.unique(sdss['class'], return_counts=True)\ndict(zip(unique, counts))\n\npredictions = cross_val_predict(xgb, sdss.drop('class', axis=1), sdss['class'], cv=3)\nconfusion_matrix(sdss['class'], predictions)\n\nprint(\"Precision:\", precision_score(sdss['class'], predictions, average='micro'))\nprint(\"Recall:\",recall_score(sdss['class'], predictions, average='micro'))\n\nprint(\"F1-Score:\", f1_score(sdss['class'], predictions, average='micro'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}