{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Assignment-6,Regression"},{"metadata":{},"cell_type":"markdown","source":"Dataset-Housing sales prices prediction dataset\n\n1)\tRead dataset and perform necessary data cleaning\n\n2)\tSplit the data into test/train using 80:20 proportion\n\n3)\tPerform pre-processing and EDA on the train data\n\n4)\tUse feature selection techniques like correlation analysis / embedded method to identify the important features\n\n5)\tBuild multivariate linear regression model on train dataset using the important features identified in above step\n\n6)\tCapture the training performance of the model using RMSE score\n\n7)\tPrint out the coefficient of the features and explain how to interpret the model using top 2 features (features with highest positive / negative coefficient)\n\n8)\tBuild residual plot on train dataset-check if there is any pattern as far as errors are concerned\n\n9)\tApply pre-processing and feature transformation on test data (as done on train dataset)\n\n10)\tCapture the performance of the model on test data set using RMSE score\n\n11)\tBased on train and test performance, comment on modelâ€™s bias and variance prediction error\n\n12)\tCan you try and improve RMSE score by iterative process we discussed in previous sessions?\n\t (e.g. Scaling/Hot encoding/Feature engineering/Regularization)\n     \nNote-Make sure whatever feature scaling you do on train dataset, use same scaler to apply transformation on the test dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install feature_engine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as snb\nimport scipy.stats as stats\nimport statsmodels.api as sm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n\nfrom feature_engine.missing_data_imputers import MeanMedianImputer, CategoricalVariableImputer, AddMissingIndicator\nfrom feature_engine.categorical_encoders import OneHotCategoricalEncoder, RareLabelCategoricalEncoder,OrdinalCategoricalEncoder\nfrom feature_engine.outlier_removers import OutlierTrimmer\nfrom feature_engine import variable_transformers\nfrom feature_engine.discretisers import EqualWidthDiscretiser","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Getting data \n\ntrain = pd.read_csv(\"../input/usa-housing-dataset/housing_train.csv\")\ntest = pd.read_csv(\"../input/usa-housing-dataset/housing_test.csv\")\ntrain.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing ID Column\ntrain = train.drop(columns=[\"Id\"])\ntest = test.drop(columns=[\"Id\"])\ntrain.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Defining the functions for various usage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for plot and check Data Distribution\n\ndef diagnostic_plots(df, variable):\n    for i in variable: \n        plt.figure(figsize=(16, 4))\n\n        # histogram\n        plt.subplot(1, 3, 1)\n    \n        snb.distplot(df[i], bins=30)\n        plt.title('Histogram')\n\n        # Q-Q plot\n        plt.subplot(1, 3, 2)\n        stats.probplot(df[i], dist=\"norm\", plot=plt)\n        plt.ylabel('RM quantiles')\n\n        # boxplot\n        plt.subplot(1, 3, 3)\n        snb.boxplot(y=df[i])\n        plt.title('Boxplot')\n        \n        print(\"\\n***********{}**********\\n\".format(i))\n        print(\"**Skewness: \",df[i].skew())\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to plot relationship between Categorical Variable and Target\n#~ Function to plot relationship between Categorical Variable and Target\n\ndef explore_relation_catTotar(dataX,y,col_category):\n    temp = dataX.copy()\n    temp[\"target\"]=y\n    for i in col_category:\n        fig = plt.figure()\n        fig = temp.groupby([i])[\"target\"].mean().plot()\n        fig.set_title('Relationship between {} and Item_Outlet_Sales'.format(i))\n        fig.set_ylabel('Mean Item_Outlet_Sales')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic Functions for Outlier Detection - Skewed Distribution & Gaussian Distribution\n\n#Skewed Distribution\n\ndef skewed_outlier(df, variable):\n    \n    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n\n    lower_boundary = df[variable].quantile(0.25) - (IQR * 3)\n    upper_boundary = df[variable].quantile(0.75) + (IQR * 3)\n\n    return upper_boundary, lower_boundary\n\ndef calculating_outlier_skewed(df,variables):\n    dic = {}\n    for i in variables:\n        ub, lb = skewed_outlier(df,i)\n        ub_len = len(df[df[i]>ub])\n        lb_len = len(df[df[i]<lb])\n        per_total = ((ub_len + lb_len)/len(df))*100\n        if per_total != 0:\n            dic[i]=per_total\n    return dic\n\n\n# Gaussian Distribution\n\ndef gaussian_outlier(df,variable):\n    \n    upper_boundary = df[variable].mean() + 3 * df[variable].std()\n    lower_boundary = df[variable].mean() - 3 * df[variable].std()\n\n    return upper_boundary, lower_boundary\n\n\ndef calculating_outlier_gaussian(df,variables):\n    dic = {}\n    for i in variables:\n        ub, lb = gaussian_outlier(df,i)\n        ub_len = len(df[df[i]>ub])\n        lb_len = len(df[df[i]<lb])\n        per_total = ((ub_len + lb_len)/len(df))*100\n        if per_total != 0:\n            dic[i]=per_total\n    return dic","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Exploration & Data Cleaning**"},{"metadata":{},"cell_type":"markdown","source":"Handling Data/Year Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating number of years after house is sold\ntrain['SoldAfterYears'] = train['YrSold'] - train['YearBuilt']\ntest['SoldAfterYears'] = test['YrSold'] - test['YearBuilt']\n\n#Calculating Number of Months after house was sold\ntrain['SoldAfterMonths'] = ((train['YrSold'] - train['YearBuilt'])*12)  + train['MoSold']\ntest['SoldAfterMonths'] = ((test['YrSold'] - test['YearBuilt'])*12)  + test['MoSold']\n\n\n#calculating Renovation after years and difference in the renovations year and build year\ntrain['RenovationCalculation']=train['SoldAfterYears'] - (train['YearRemodAdd'] - train['YearBuilt'])\ntest['RenovationCalculation']=test['SoldAfterYears'] - (test['YearRemodAdd'] - test['YearBuilt'])\n\n\n\n#Adding New Renovation Column\n# 0 - No renovation\n# 1 - Renovation done\nrenovation_train = list(map(lambda x, y : 0 if x-y==0 else 1,train['YearRemodAdd'],train['YearBuilt']))\nrenovation_test = list(map(lambda x, y : 0 if x-y==0 else 1,test['YearRemodAdd'],test['YearBuilt']))\ntrain['Renovation_Done'] = renovation_train\ntest['Renovation_Done'] = renovation_test\n\n\n#updating garage status as per the Garage_built_year\ntrain[\"Garage_status\"] = train[\"GarageYrBlt\"] - train['YearBuilt']\ntrain['Garage_status'] = train.Garage_status.fillna(-1)\ntrain['Garage_status'] = train['Garage_status'].replace([i for i in range(-20,0)],'No_Garag')\ntrain['Garage_status'] = train['Garage_status'].replace(0,'Built-in')\ntrain['Garage_status'] = train['Garage_status'].replace([i for i in range (1,210)],'Built-Later')\n\ntest[\"Garage_status\"] = test[\"GarageYrBlt\"] - test['YearBuilt']\ntest['Garage_status'] = test.Garage_status.fillna(-1)\ntest['Garage_status'] = test['Garage_status'].replace([i for i in range(-20,0)],'No_Garag')\ntest['Garage_status'] = test['Garage_status'].replace(0,'Built-in')\ntest['Garage_status'] = test['Garage_status'].replace([i for i in range (1,210)],'Built-Later')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#due to wrong values some of the output getting in -ve. replacing these with 0\ntrain['RenovationCalculation'] = train['RenovationCalculation'].replace([-1],0)\ntest['RenovationCalculation'] = test['RenovationCalculation'].replace([-1,-2],0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the columns which are related to Date/Years after extracting the usefull informations\ntrain = train.drop(columns=['YearBuilt','YearRemodAdd','YrSold','GarageYrBlt','SoldAfterMonths'],axis=1)\ntest = test.drop(columns=['YearBuilt','YearRemodAdd','YrSold','GarageYrBlt','SoldAfterMonths'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating Numerical and Categorical Columns\ncol_number = [i for i in train.columns if train[i].dtype!='O']\ncol_category =[ i for i in train.columns if train[i].dtype=='O']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the Numerical columns which has less than 20 unique values\n# let's visualise the values of the discrete variables\ndiscrete = []\n\nfor var in col_number:\n    if len(train[var].unique()) < 20:\n        print(var, ' values: ', train[var].unique())\n        discrete.append(var)\nprint('\\nThere are {} discrete variables'.format(len(discrete)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are total 15 discrete variables out of that most of them are \"Ordinal Variables\" and some \"Nominal Data\"\n\nOut of those 15 variables below variables have good correlation with target so we keep them Numerical only and rest we will convert to string/catergorical\n\n'OverallQual','FullBath','TotRmsAbvGrd','GarageCars'"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_remove = ['OverallQual','FullBath','TotRmsAbvGrd','GarageCars']\nfor i in cols_to_remove:\n    discrete.remove(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert rest of discrete variables into Categorical.\ntrain[discrete] = train[discrete].astype(str)\ntest[discrete] = test[discrete].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below columns has vary low correlation with the target. Removing them.."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['1stFlrSF','BsmtFinSF2','LowQualFinSF','3SsnPorch','MiscVal','EnclosedPorch','ScreenPorch','SalePrice']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns=['1stFlrSF','BsmtFinSF2','LowQualFinSF','3SsnPorch','MiscVal','EnclosedPorch','ScreenPorch'],axis=1)\ntest = test.drop(columns=['1stFlrSF','BsmtFinSF2','LowQualFinSF','3SsnPorch','MiscVal','EnclosedPorch','ScreenPorch'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Analysing and Removing Outlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating Numerical and Categorical Columns\ncol_number = [i for i in train.columns if train[i].dtype!='O']\ncol_category =[ i for i in train.columns if train[i].dtype=='O']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete1 = []\n\nfor var in col_number:\n    if len(train[var].unique()) < 20:\n        print(var, ' values: ', train[var].unique())\n        discrete1.append(var)\nprint()\nprint('There are {} discrete variables'.format(len(discrete1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns will not be considered for outlier removal = ['OverallQual', 'FullBath', 'TotRmsAbvGrd', 'GarageCars']"},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing them from separated col_number list\n\nfor i in discrete1:\n    col_number.remove(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As per the skewness, seperating the \"Skewed Features\" & \"Gaussian Features\"\nskewnewss = dict(train[col_number].skew())\ngaussian_features =[]\nskewed_features =[]\nfor i,j in skewnewss.items():\n    if (skewnewss[i]<0.75) and (skewnewss[i]> -0.75):\n        gaussian_features.append(i)\n    else:\n        skewed_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating the outlier present in each column in (%) ~ functions are defined above\ngaussian_outlier_percentage = calculating_outlier_gaussian(train,gaussian_features)\nskewed_outlier_percentage = calculating_outlier_skewed(train,skewed_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting all those column names in the list\nskewed_outlier_cols_list = list(skewed_outlier_percentage.keys())\ngaussian_outlier_cols_list = list(gaussian_outlier_percentage.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns 'LotFrontage' and 'MasVnrArea' has got missing data. We will handle the outlier for this later"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['LotFrontage','MasVnrArea']:\n    skewed_outlier_cols_list.remove(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#before removing outliers\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Pipeline to remove the outliers\n\noutlier_trimmer_pipe = Pipeline(steps=[\n    ('Gaussian_Outliers',OutlierTrimmer(distribution='gaussian',tail='both',\n                                       fold=3, variables=gaussian_outlier_cols_list)),\n    (\"Skewed_Outlier\",OutlierTrimmer(distribution='skewed',tail='both',\n                                    fold=3, variables=skewed_outlier_cols_list))\n])\n\noutlier_trimmer_pipe.fit(train)\ntrain = outlier_trimmer_pipe.transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have removed 67 rows from the dataset in which outlier were present. THis has helped to increase the correlation of few of the columns as well with target ex - 'LoatArea"},{"metadata":{},"cell_type":"markdown","source":"# Splitting the data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"use_cols=list(train.columns)\nuse_cols.remove(\"SalePrice\")\n\nX_train, X_test, y_train, y_test = train_test_split(train[use_cols],train[\"SalePrice\"],\n                                                    test_size=0.25,random_state=2)\n\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Data Imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding those variable which has missing values \nmissing_data_var_Xtrain = [c for c in X_train.columns if X_train[c].isnull().mean() != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variable \"GarageCars\" from test set is not matching X_train\ntest['GarageCars'] = test['GarageCars'].replace(['nan'],'0')\ntest['GarageCars'] = test['GarageCars'].replace(['5.0'],'4')\ntest['GarageCars'] = test['GarageCars'].replace(['0.0'],'0')\ntest['GarageCars'] = test['GarageCars'].replace(['1.0'],'1')\ntest['GarageCars'] = test['GarageCars'].replace(['2.0'],'2')\ntest['GarageCars'] = test['GarageCars'].replace(['3.0'],'3')\ntest['GarageCars'] = test['GarageCars'].replace(['4.0'],'4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating Numerical and Categorical Columns from X_train missing_values columns\nmissing_number = [i for i in missing_data_var_Xtrain if X_train[i].dtype!='O']\nmissing_category =[ i for i in missing_data_var_Xtrain if X_train[i].dtype=='O']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_number","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_impute_pipeline = Pipeline(steps=[\n    (\"Missing Indicator\",AddMissingIndicator(variables=[\"LotFrontage\"])), #Addming missing indicator\n    (\"Median_imputation\",MeanMedianImputer(imputation_method=\"median\",variables=['LotFrontage',\"MasVnrArea\"]))\n])\n\nnum_impute_pipeline.fit(X_train)\nX_train = num_impute_pipeline.transform(X_train)\nX_test = num_impute_pipeline.transform(X_test)\ntest = num_impute_pipeline.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical variables which actually has missing data -\n\n'MasVnrType' & ''Electrical'\n\nCategorical variables which actually has missing Labels-\n\n'Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PoolQC','Fence', 'MiscFeature'"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_missing_data = ['MasVnrType','Electrical']\ncat_missing_labels = ['Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n                  'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PoolQC',\n                  'Fence', 'MiscFeature']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a Pipeline to impute the missing_values in categorical variables\ncategory_missing_pipe = Pipeline(steps=[\n    ('Frequent_category',CategoricalVariableImputer(imputation_method='frequent',\n                                                   variables=cat_missing_data)),\n    ('Missing_Labels',CategoricalVariableImputer(imputation_method='missing',\n                                                variables=cat_missing_labels))\n])\n\n\n#imputing the missing value\ncategory_missing_pipe.fit(X_train)\nX_train = category_missing_pipe.transform(X_train)\nX_test = category_missing_pipe.transform(X_test)\ntest = category_missing_pipe.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking if there are any missing date in Test Set now\nmissing_data_var_test = [c for c in test.columns if test[c].isnull().mean() != 0]\ntest[missing_data_var_test].isnull().mean()*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating Numerical and Categorical Columns from test missing_values columns\ntest_missing_number = [i for i in missing_data_var_test if test[i].dtype!='O']\ntest_missing_category =[ i for i in missing_data_var_test if test[i].dtype=='O']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test_missing_number].isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imputer_remaining = MeanMedianImputer(imputation_method=\"median\",\n                                          variables=test_missing_number)\n\ntest_imputer_remaining.fit(X_train)\ntest = test_imputer_remaining.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imputer_cat = CategoricalVariableImputer(imputation_method='frequent',\n                                             variables=test_missing_category)\n\ntest_imputer_cat.fit(X_train)\ntest = test_imputer_cat.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Collecting Continuous Variables for further transformation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating Numerical and Categorical Columns\ncol_number = [i for i in X_train.columns if X_train[i].dtype!='O']\ncol_category =[ i for i in X_train.columns if X_train[i].dtype=='O']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[col_number].describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_transform = ['LotFrontage','LotArea','GrLivArea'] #does not have 0\nbox_cox_transform = ['MasVnrArea','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF',\n                     '2ndFlrSF','GarageArea','WoodDeckSF','OpenPorchSF']\navoid = ['OverallQual','FullBath','TotRmsAbvGrd','GarageCars','LotFrontage_na']\nscalar_PCA = []\n\nfor i in col_number:\n    if i not in avoid:\n        scalar_PCA.append(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Categorical Data Encoding**"},{"metadata":{},"cell_type":"markdown","source":"Variables 'PoolArea','MSSubClass' has low cardinality & different values. We will use Discretiser on them."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[['PoolArea','MSSubClass']]=X_train[['PoolArea','MSSubClass']].astype(int)\nX_test[['PoolArea','MSSubClass']]=X_test[['PoolArea','MSSubClass']].astype(int)\ntest[['PoolArea','MSSubClass']]=test[['PoolArea','MSSubClass']].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disc_pipe = Pipeline(steps=[\n    ('PoolArea_disc',EqualWidthDiscretiser(bins = 2, variables=['PoolArea'])),\n    ('MSSubClass_disc',EqualWidthDiscretiser(bins=8,variables=['MSSubClass'])),   \n])\n\ndisc_pipe.fit(X_train)\nX_train = disc_pipe.transform(X_train)\nX_test = disc_pipe.transform(X_test)\ntest = disc_pipe.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_relation_catTotar(X_train,y_train,['MSSubClass'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'MSSubClass' is not following any monotonic relationship with the target so converting it back to categorical now and then perform target encoding on the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[['MSSubClass']]=X_train[['MSSubClass']].astype(str)\nX_test[['MSSubClass']]=X_test[['MSSubClass']].astype(str)\ntest[['MSSubClass']]=test[['MSSubClass']].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = X_train.copy()\nX_test1 = X_test.copy()\ntest1 = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating Numerical and Categorical Columns\ncol_number = [i for i in X_train1.columns if X_train1[i].dtype!='O']\ncol_category =[ i for i in X_train1.columns if X_train1[i].dtype=='O']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rare_encoder = RareLabelCategoricalEncoder(tol=0.05,\n                                                   n_categories=1,\n                                                    variables=col_category)\n\nrare_encoder.fit(X_train1)\nX_train1 = rare_encoder.transform(X_train1)\nX_test1 = rare_encoder.transform(X_test1)\ntest1 = rare_encoder.transform(test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordered =[]\none_hot=[]\nfor i in col_category:\n    if len(X_train1[i].unique())>=5:\n        ordered.append(i)\n    else:\n        one_hot.append(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Target Incoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_encoding = OrdinalCategoricalEncoder(encoding_method=\"ordered\",\n                                           variables=ordered)\n\ntarget_encoding.fit(X_train1,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = target_encoding.transform(X_train1)\nX_test1 = target_encoding.transform(X_test1)\ntest1 = target_encoding.transform(test1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One-Hot Encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot = OneHotCategoricalEncoder(top_categories=None,\n                                  variables=one_hot,\n                                  drop_last=True)\n\none_hot.fit(X_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = one_hot.transform(X_train1)\nX_test1 = one_hot.transform(X_test1)\ntest1 = one_hot.transform(test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1.shape, X_test1.shape,test1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  **Variable Transformation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2 = X_train1.copy()\nX_test2 = X_test1.copy()\ntest2 = test1.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2_scalar_pca = X_train2[scalar_PCA].copy()\nX_test2_scalar_pca = X_test1[scalar_PCA].copy()\ntest2_scalar_pca = test2[scalar_PCA].copy()\n\n\nX_train2 = X_train2.drop(columns=scalar_PCA,axis=1)\nX_test2 = X_test2.drop(columns=scalar_PCA,axis=1)\ntest2 = test2.drop(columns=scalar_PCA,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scalar = StandardScaler()\n\nscalar.fit(X_train2_scalar_pca)\nX_train2_scalar_pca = scalar.transform(X_train2_scalar_pca)\nX_test2_scalar_pca = scalar.transform(X_test2_scalar_pca)\ntest2_scalar_pca = scalar.transform(test2_scalar_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=11)\npca.fit(X_train2_scalar_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2_scalar_pca = pca.transform(X_train2_scalar_pca)\nX_test2_scalar_pca = pca.transform(X_test2_scalar_pca)\ntest2_scalar_pca = pca.transform(test2_scalar_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.cumsum(pca.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = []\nfor i in range (0,len(pca.explained_variance_ratio_)):\n    var = 'col'+ str(i)\n    cols.append(var)\n\nX_train_pca=pd.DataFrame(data=X_train2_scalar_pca,columns=cols)\nX_test_pca = pd.DataFrame(data=X_test2_scalar_pca,columns=cols)\ntest_pca = pd.DataFrame(data=test2_scalar_pca,columns=cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pca.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2 = X_train2.reset_index(drop=True)\nX_train2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_model = X_train2.merge(X_train_pca,left_index=True, right_index=True)\nX_train_model.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test2 = X_test2.reset_index(drop=True)\nX_test_model = X_test2.merge(X_test_pca,left_index=True, right_index=True)\nX_test_model.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = test2.reset_index(drop=True)\ntest_model = test2.merge(test_pca,left_index=True, right_index=True)\ntest_model.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_model.shape, X_test_model.shape,test_model.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_log = np.log(y_train)\ny_test_log = np.log(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train_model,y_train_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_train = lr.predict(X_train_model)\ny_predict_test = lr.predict(X_test_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nTraining RMSE and R-Square: \")\nprint(\"Root Mean Square Error :\",mean_squared_error(y_train_log,y_predict_train)**0.5)\nprint(\"R-square :\",lr.score(X_train_model,y_train_log))\n\nprint(\"\\nTesting RMSE and R-Square: \")\nprint(\"Root Mean Square Error :\",mean_squared_error(y_test_log,y_predict_test)**0.5)\nprint(\"R-square :\",lr.score(X_test_model,y_test_log))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get importance\nimportance = lr.coef_\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lasso**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.linear_model import Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Lasso(max_iter=20000)\n\n#define Model evealuation method\ncv = RepeatedKFold(n_splits=10,n_repeats=3, random_state=1)\n\n#define Grid\ngrid = {'alpha': [0.001,0.01,0.1,0.0012]}\n\nsearch = GridSearchCV(model, grid, scoring='neg_mean_squared_error', cv=6)\n\nresults=search.fit(X_train_model,y_train_log)\n\nprint('Config: %s' % results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_train = search.predict(X_train_model)\ny_predict_test = search.predict(X_test_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nTraining RMSE and R-Square: \")\nprint(\"Root Mean Square Error :\",mean_squared_error(y_train_log,y_predict_train)**0.5)\n\n\nprint(\"\\nTesting RMSE and R-Square: \")\nprint(\"Root Mean Square Error :\",mean_squared_error(y_test_log,y_predict_test)**0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XGBRegressor**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'objective':['reg:squarederror'],\n         'learning_rate': [0.1,0.11,0.12,0.13,0.15,0.2],\n        'max_depth': [1,2,3,4,5]}\n\nxgb1 = XGBRegressor()\n\nxgb_grid = GridSearchCV(xgb1, param, cv = 3)\n\nxgb_grid.fit(X_train_model, y_train_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_train = xgb_grid.predict(X_train_model)\ny_predict_test =  xgb_grid.predict(X_test_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nTraining RMSE and R-Square: \")\nprint(\"Root Mean Square Error :\",mean_squared_error(y_train_log,y_predict_train)**0.5)\n\n\nprint(\"\\nTesting RMSE and R-Square: \")\nprint(\"Root Mean Square Error :\",mean_squared_error(y_test_log,y_predict_test)**0.5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}