{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"55fe4d65-60d5-4629-133b-343ad3606c14"},"source":"**Glass Classification with Different Algorithm and Ensemble Modeling**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db63a4cb-ca65-3010-da67-6bea52ff2f2e"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60ac450f-d02e-b2eb-e5b4-7b1ab1468ccf"},"outputs":[],"source":"df=pd.read_csv(\"../input/glass.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1bea1182-430c-985f-6a92-473bd5427bd9"},"outputs":[],"source":"df.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b29af3d-563e-5f7b-c65e-32796ef0b35a"},"outputs":[],"source":"df.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"cfaea7e7-d311-aa33-38ee-9ade6581a111"},"source":"**Different kind of plotting for Data Analysis**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"42bc6423-9509-581e-6a43-646a2ec9d447"},"outputs":[],"source":"sns.countplot(df['Type'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d7c767d-7329-f7d4-5894-e7397eca2e86"},"outputs":[],"source":"sns.pairplot(df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3240c084-b4b0-ac07-15b0-4ea75c060680"},"outputs":[],"source":"plt.plot(df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f1744dd-011b-79f3-fbc2-61c510adb382"},"outputs":[],"source":"# One piece of information missing in the plots above is what species each plant is\n# We'll use seaborn's FacetGrid to color the scatterplot by species\nsns.FacetGrid(df, hue=\"Type\", size=5) \\\n   .map(plt.scatter, \"RI\", \"Na\") \\\n   .add_legend()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91768895-2d90-a4fb-5329-4cc61a9ae4ce"},"outputs":[],"source":"cl=df[['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ded7a5d6-23de-0ea1-3657-1ec07f6b0393"},"outputs":[],"source":"# We can look at an individual feature in Seaborn through a boxplot\nsns.boxplot(y='Na', x='Type', data=df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35f772f6-49ce-369d-93da-238956ce438d"},"outputs":[],"source":"sns.boxplot(y='RI', x='Type', data=df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1d9c075-6c70-784d-4130-48b0e45a7d43"},"outputs":[],"source":"sns.boxplot(y='Mg', x='Type', data=df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"61e87f1c-5573-24e1-ba25-f2846176b77e"},"outputs":[],"source":"ax = sns.boxplot(x=\"Type\", y=\"RI\", data=df)\nax = sns.stripplot(x=\"Type\", y=\"RI\", data=df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3a46833-1210-9e13-8262-2281cf8dfe29"},"outputs":[],"source":"sns.violinplot(x=\"Type\", y=\"Fe\", data=df, size=6)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"585b852e-7d27-1670-be02-61cdcbe8f1da"},"outputs":[],"source":"sns.pairplot(df,hue='Type')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81e9d0e9-3404-4ebb-c896-e4b2af0e80e3"},"outputs":[],"source":"# One cool more sophisticated technique pandas has available is called Andrews Curves\n# Andrews Curves involve using attributes of samples as coefficients for Fourier series\n# and then plotting these\nfrom pandas.tools.plotting import andrews_curves\nandrews_curves(df, \"Type\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"02095f96-457d-f165-0abf-7a79b87f95f1"},"outputs":[],"source":"# Another multivariate visualization technique pandas has is parallel_coordinates\n# Parallel coordinates plots each feature on a separate column & then draws lines\n# connecting the features for each data sample\nfrom pandas.tools.plotting import parallel_coordinates\nparallel_coordinates(df, \"Type\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10035edd-bf23-67fa-eca4-9f5b06761c31"},"outputs":[],"source":"# A final multivariate visualization technique pandas has is radviz\n# Which puts each feature as a point on a 2D plane, and then simulates\n# having each sample attached to those points through a spring weighted\n# by the relative value for that feature\nfrom pandas.tools.plotting import radviz\nradviz(df, \"Type\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8bb9a66-5b95-e650-09ae-6ceecafacda8"},"outputs":[],"source":"df.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"341158fe-ec4c-df53-77fd-50b29bef6ea1"},"outputs":[],"source":"df.skew()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ab589b3-9b62-e169-2e3f-95dd85670419"},"outputs":[],"source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nlabel = df.pop('Type')\n\nsc.fit(df)\n\ndf_scale = sc.transform(df)\n\nprint('After standardizing our features, the first 5 rows of our data now look like this:\\n')\nprint(pd.DataFrame(df_scale, columns=df.columns).head())\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"599063c0-9fae-1889-e31b-4595bdf4e2bb"},"outputs":[],"source":"pd.DataFrame(df_scale).skew()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2e6a1da-1e5a-c2f0-8a2f-2c82f2ed7327"},"outputs":[],"source":"#Train-Test split\nfrom sklearn.model_selection import train_test_split\n#label = df_scale.pop('Type')\ndata_train, data_test, label_train, label_test = train_test_split(df_scale, label, test_size = 0.3, random_state = 42)\n\n\nprint('There are {} samples in the training set and {} samples in the test set'.format(\ndata_train.shape[0], data_test.shape[0]))\nprint()"},{"cell_type":"markdown","metadata":{"_cell_guid":"11370d3e-5e5d-83fe-5837-29bef88ce81c"},"source":"**Apply different Machine Learning Algorithm**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a7f172a-3b2e-1129-4ac8-0990f51ba068"},"outputs":[],"source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\nsvm.fit(data_train, label_train)\nsv_train_score=svm.score(data_train, label_train)\nsv_test_score=svm.score(data_test, label_test)\nprint('The accuracy of the svm classifier on training data is {:.2f} out of 1'.format(svm.score(data_train, label_train)))\nprint('The accuracy of the svm classifier on test data is {:.2f} out of 1'.format(svm.score(data_test, label_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0b49be7-cd7e-672d-3f9f-baa92d1b70fb"},"outputs":[],"source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=7, p=2, metric='minkowski')\nknn.fit(data_train, label_train)\nknn_train_score=knn.score(data_train, label_train)\nknn_test_score=knn.score(data_test, label_test)\nprint('The accuracy of the knn classifier is {:.2f} out of 1 on training data'.format(knn.score(data_train, label_train)))\nprint('The accuracy of the knn classifier is {:.2f} out of 1 on test data'.format(knn.score(data_test, label_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"983426ad-07ce-d036-cd5c-db41e4e9e308"},"outputs":[],"source":"import xgboost as xgb\n\nxgb_clf = xgb.XGBClassifier()\nxgb_clf = xgb_clf.fit(data_train, label_train)\nxgb_train_score=xgb_clf.score(data_train, label_train)\nxgb_test_score=xgb_clf.score(data_test, label_test)\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on training data'.format(xgb_clf.score(data_train, label_train)))\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on test data'.format(xgb_clf.score(data_test, label_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e70ad3b4-5189-fe1a-22d3-90ee5a4f774d"},"outputs":[],"source":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogis = LogisticRegression()\nlogis.fit(data_train, label_train)\nlogis_score_train = logis.score(data_train, label_train)\nlogis_score_test = logis.score(data_test, label_test)\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on training data'.format(logis.score(data_train, label_train)))\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on test data'.format(logis.score(data_test, label_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2864a626-862f-654e-5c9c-fa69de8c0a83"},"outputs":[],"source":"#decision tree\nfrom sklearn import tree\ndt = tree.DecisionTreeClassifier()\ndt.fit(data_train, label_train)\ndt_score_train = dt.score(data_train, label_train)\ndt_score_test = dt.score(data_test, label_test)\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on training data'.format(dt.score(data_train, label_train)))\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on test data'.format(dt.score(data_test, label_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d83a5bfd-0178-8f8f-f4b9-1a176a10b49a"},"outputs":[],"source":"#decision tree\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(data_train, label_train)\nrf_score_train = rf.score(data_train, label_train)\nrf_score_test = rf.score(data_test, label_test)\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on training data'.format(rf.score(data_train, label_train)))\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on test data'.format(rf.score(data_test, label_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03a0ab64-65d0-bbb2-2536-c41732bf05df"},"outputs":[],"source":"#Model comparison\nmodels = pd.DataFrame({\n        'Model'          : ['Logistic Regression', 'SVM', 'kNN', 'Decision Tree', 'Random Forest','XGB'],\n        'Training_Score' : [logis_score_train, sv_train_score, knn_train_score, dt_score_train, rf_score_train,xgb_train_score],\n        'Testing_Score'  : [logis_score_test, sv_test_score, knn_test_score, dt_score_test, rf_score_test,xgb_test_score]\n    })\nmodels.sort_values(by='Testing_Score', ascending=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"105762b9-1656-2413-e3d5-235b617f6b17"},"source":"**Ensemble modeling to improve accuracy**\n\n 1. Random Forest + XGBoost + Decision Tree > XGBoost/RF >Prediction"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b79bc1a-2deb-c23a-44d8-7975be0adf04"},"outputs":[],"source":"#Prepare Ensemble train data\ny_predict_rf=rf.predict(data_train)\ny_predict_xgb=xgb_clf.predict(data_train)\ny_predict_dt=dt.predict(data_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ce1bd13-c729-57aa-d158-8f1008543cb3"},"outputs":[],"source":"#Prepare Ensemble test\ny_predict_rf_tst=rf.predict(data_test)\ny_predict_xgb_tst=xgb_clf.predict(data_test)\ny_predict_dt_tst=dt.predict(data_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e41727ef-8bf8-4a39-7333-b4cb42d4d77f"},"outputs":[],"source":"Ensemble_test=pd.DataFrame({'XGBoost' : y_predict_xgb_tst,'RF' :y_predict_rf_tst,'DT':y_predict_dt_tst})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e33cc76c-357a-6649-a25e-c111c3b99979"},"outputs":[],"source":"y_predict_dt.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92ded33a-e0f3-f8af-b993-09e0e6e8635f"},"outputs":[],"source":"Ensemble_train=pd.DataFrame({'XGBoost' : y_predict_xgb,'RF' :y_predict_rf,'DT':y_predict_dt,'Actual':label_train})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3a09e12-7cab-ebf4-decd-c847e8e7726a"},"outputs":[],"source":"Ensemble_train.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"124edb37-8f09-3061-bfd1-c28634e9df66"},"outputs":[],"source":"Ensemble_train.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b8bcb8d-4a89-3c3b-aa63-538aad81b01d"},"outputs":[],"source":"#Train-Test split for Ensemple train data\nfrom sklearn.model_selection import train_test_split\nlabel_esm = Ensemble_train.pop('Actual')\ndata_train_es, data_test_es, label_train_es, label_test_es = train_test_split(Ensemble_train, label_esm, test_size = 0.3, random_state = 42)\n\n\nprint('There are {} samples in the training set and {} samples in the test set'.format(\ndata_train_es.shape[0], data_test_es.shape[0]))\nprint()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a324df8-3b81-1490-4fc8-d9145cbc037d"},"outputs":[],"source":"#XGBBOST used for Ensemble modeling to get predicted output\nimport xgboost as xgb\nxgb = xgb.XGBClassifier()\nxgb.fit(data_train_es, label_train_es)\nxgb_score_train_es = xgb.score(data_train_es, label_train_es)\nxgb_score_test_es = xgb.score(data_test_es, label_test_es)\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on training data'.format(xgb.score(data_train_es, label_train_es)))\nprint('The accuracy of the xgb classifier is {:.2f} out of 1 on test data'.format(xgb.score(data_test_es, label_test_es)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c39312c1-7eb9-9db8-9644-f033803fa012"},"source":"**Seems not good only 74% instead of 76% in single model.This is because of less amount of data..U can use NN to get maximam accuracy**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d3fe6fb8-397f-add0-ca81-2bada1e91f5b"},"outputs":[],"source":"Ensemble_predict=xgb.predict(Ensemble_test)\nprint('The accuracy of the xgb ensemble classifier is {:.2f} out of 1 on test data'.format(xgb.score(Ensemble_test, label_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d42e1d3-47b2-eb88-2b03-b41a7dac6db6"},"outputs":[],"source":"pred=xgb.predict(Ensemble_test)\nout=pd.DataFrame({'Predicted' : pred ,'Actual' :label_test})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"068a3851-4b87-6ed0-ee4d-fa201eeb96fc"},"outputs":[],"source":"#Output\nout.head(5)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}