{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Board Game Review Prediction\n\n"},{"metadata":{},"cell_type":"markdown","source":"Data Link\n\ngit clone https://github.com/ThaWeatherman/scrapers.git"},{"metadata":{},"cell_type":"markdown","source":"### 1. Importing Libraries and Loading the Data\n\nAfter the .csv file 'games.csv' has been copied to the current directory, we can import the data as a Pandas DataFrame. As a DataFrame, we will be able to easily explore the type, amount, and distribution of data.  Furthermore, using a correlation matrix, we can explore the relationships between parameters.  This is an important step in determining the type of machine learning algorithm to utilize. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Read in the data.\ngames = pandas.read_csv(\"../input/games.csv\")\n# Print the names of the columns in games.\nprint(games.columns)\nprint(games.shape)\n\n# Make a histogram of all the ratings in the average_rating column.\nplt.hist(games[\"average_rating\"])\n\n# Show the plot.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngames.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding the nulll values \ngames.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding the colums that had average _rating=0 it means these games were never played \ndata=games.loc[games['average_rating']==0]\ndata[[\"average_rating\",\"yearpublished\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first we need to remove the nan values b replacing it with -1\ngames=games.replace(np.nan,-1)\ngames.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing the null values data from datset\ngames=games.loc[games['yearpublished']>=0]\ngames=games.loc[games['minplayers']>=0]\ngames=games.loc[games['maxplayers']>=0]\ngames=games.loc[games['playingtime']>=0]\ngames=games.loc[games['minplaytime']>=0]\ngames=games.loc[games['maxplaytime']>=0]\ngames=games.loc[games['minage']>=0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we need to remove the enteries of year published which is 0 becuase it means game is never published\nprint(games['yearpublished'].unique())\ngames=games.loc[games['yearpublished']>0]\nprint(games['yearpublished'].unique())\n# as you can see the enteries with yearpublished=0 has been removed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mapping the type of games\nprint(games['type'].unique())\ngames['type']=games['type'].map({\"boardgame\":1,\"boardgameexpansion\":2})\nprint(games['type'].unique())\nprint(games.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# playing with various averages and seeing them for any discrepancy\n# lets find out if all the  averages provided=0,maxplayng time=0 and user rated=0 that means game is never played\nd=games.loc[(games['bayes_average_rating']==0.0) & (games['average_rating']==0) & (games['users_rated']==0) & (games['playingtime']==0)]\nprint(d.shape)\nd[['bayes_average_rating','average_rating','users_rated','playingtime','maxplaytime']]\n# so u can clearly see that our dataset has such 7000+ enteries that must be removed to acheive generalisation ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games.describe()\nprint(games.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing thee inconsistency of data\ngames=games.loc[((games['average_rating']>0) & (games['playingtime']>0))]\ngames.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(games['users_rated'],games['average_rating'],color='g')\nplt.plot(games['average_rating'],games['bayes_average_rating'],color='r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a histogram of all the ratings in the average_rating column to ensure that most of rating with 0 have been removed and \n#only genuine cases have been left\nplt.hist(games[\"average_rating\"])\n\n# Show the plot.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = games.corr()\nfig = plt.figure(figsize = (12, 9))\nsns.heatmap(corrmat, square=True);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all the columns from the dataframe.\ncolumns = games.columns.tolist()\n# Filter the columns to remove ones we don't want.\ncolumns = [c for c in columns if c not in [\"average_rating\", \"name\", \"id\"]]\n\n# Store the variable we'll be predicting on.\ntarget = \"average_rating\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Linear Regression\n\nIn the following cells, we will deploy a simple linear regression model to predict the average review of each board game.  We will use the mean squared error as a performance metric.  Furthermore, we will compare and contrast these results with the performance of an ensemble method. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import a convenience function to split the sets.\nfrom sklearn.model_selection import train_test_split\n\n# Generate the training set.  Set random_state to be able to replicate results.\ntrain = games.sample(frac=0.8, random_state=1)\n# Select anything not in the training set and put it in the testing set.\ntest = games.loc[~games.index.isin(train.index)]\n# Print the shapes of both sets.\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the linear regression model.\nfrom sklearn.linear_model import LinearRegression\n\n# Initialize the model class.\nmodel = LinearRegression()\n# Fit the model to the training data.\nmodel.fit(train[columns], train[target])\n\n# Import the scikit-learn function to compute error.\nfrom sklearn.metrics import mean_squared_error\n\n# Generate our predictions for the test set.\npredictions = model.predict(test[columns])\n\n# Compute error between our test predictions and the actual values.\nprint(\"Mean square Error : \",mean_squared_error(predictions, test[target]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# SInce is predicted data is continuous so we cant find the accuracy and classification _report \n# Therefore calculating the mean squared error is best measure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the random forest model.\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Initialize the model with some parameters.\nmodel = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=1)\n# Fit the model to the data.\nmodel.fit(train[columns], train[target])\n# Make predictions.\npredictions = model.predict(test[columns])\n# Compute the error.\nmean_squared_error(predictions, test[target])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=pandas.DataFrame({'Prediction':predictions})\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# If u find it helpful please do upvote this kernel","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}