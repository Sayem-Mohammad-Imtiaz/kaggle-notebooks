{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow.keras as keras\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\n    '../input/twitter-airline-sentiment/Tweets.csv',\n    encoding='latin-1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= df[['airline_sentiment','text']].copy()\ndf.columns = ['Sentiment','SentimentText']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Sentiment.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapper = {'negative':0,\n         'neutral':1,\n         'positive':2}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Sentiment = df.Sentiment.map(mapper)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(text):\n# removendo link,user e caracteres e especiais\n# removing links,user and special characters\n    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.SentimentText = df.SentimentText.apply(lambda x: preprocess(x))\ndf.Sentiment = df.Sentiment.astype('int64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df,random_state=56)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = keras.utils.to_categorical(train['Sentiment'].astype('int64'))\ntrain_text = np.array(train['SentimentText'].tolist().copy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_valid = keras.utils.to_categorical(valid['Sentiment'].astype('int64'))\nvalid_text = np.array(valid['SentimentText'].tolist().copy())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = 1000\nembedding_dim = 16\nmax_length = 142\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\n\n\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(train_text)\nword_index = tokenizer.word_index\nsequences = tokenizer.texts_to_sequences(train_text)\npadded = pad_sequences(sequences,maxlen=max_length, padding=padding_type, \n                       truncating=trunc_type)\n\ntesting_sequences = tokenizer.texts_to_sequences(valid_text)\ntesting_padded = pad_sequences(testing_sequences,maxlen=max_length, \n                               padding=padding_type, truncating=trunc_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_padded","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n\ndef decode_review(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n\nprint(decode_review(padded[0]))\nprint()\nprint(train_text[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build a basic sentiment network\n# Note the embedding layer is first, \n# and the output is only 1 softmax layer [0, 1 or 2(negative, neutral or positive)]\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(3, activation='softmax')\n])\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#just adding some early stopping to prevent overfitting\nmonitor = keras.callbacks.EarlyStopping(patience=5,min_delta=0.01,monitor='val_accuracy',restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 30\nhistory = model.fit(padded, labels, epochs=num_epochs, validation_data=(testing_padded, labels_valid),\n         callbacks=[monitor]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(max(history.epoch)+1)\n \nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, label='Training loss')\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Running the prediction on the test split\npredictions = np.argmax(model.predict(testing_padded),-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can inverse our dict to easy apply map function to transform the numbers into classes again\nmapper_inverse = {v:k for v,k in zip(range(3),mapper)}\ndf_comp = pd.DataFrame()\ndf_comp['Pred'] = pd.Series(predictions).map(mapper_inverse)\ndf_comp['True'] = valid['Sentiment'].map(mapper_inverse).values\ndf_comp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's see our accuracy!\naccuracy_score(predictions,valid['Sentiment'].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}