{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Facial Expression Prediction\n\nFacial Expression Classification using CNN with Keras.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Generic Packages\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\n\n#Machine Learning Library\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import shuffle           \n\n#Plotting Libraries\nimport seaborn as sn; sn.set(font_scale=1.4)\nimport matplotlib.pyplot as plt             \n\n#openCV\nimport cv2                                 \n\n#Tensor Flow & Keras\nimport tensorflow as tf    \nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization\n\n#Train & Test Data Split\nfrom sklearn.model_selection import train_test_split\n\n#Garbage Collector\nimport gc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# FER File Location\nfer_file = '../input/facialexpressionrecognition/fer2013.csv'\n\n# Expression Labels\nexp_label = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\n#Column Names\ncol_names=['emotion','pixels','usage']\n\n#Dataset\ndata = pd.read_csv(fer_file,names=col_names, na_filter=False)\n\nim=data['pixels']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to read the file\ndef getData(file):\n    Y = []\n    X = []\n    first = True\n    for line in open(file):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) / 255.0, np.array(Y)\n    return X, Y\n\n# Load Data\nX, Y = getData(fer_file)\nnum_class = len(set(Y))\n#print(num_class)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape X dataset\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train & Test Data Split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build Model\n\ndef build_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Instantiate the Model\nmodel=build_model()\n\n#Model Architecture Summary\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel = build_model ()\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Train The Model\n# fit the model\nh=model.fit(x=X_train,y=y_train,batch_size=100,epochs=10,verbose=1,validation_data=(X_test,y_test),shuffle=True,callbacks=[ModelCheckpoint(filepath=path_model),])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the Accuracy\ntest_loss = model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\n#print(y_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def emotion_analysis(emotions):\n    objects = ['ang', 'dis', 'fear', 'hap', 'sad', 'sur', 'neu']\n    y_pos = np.arange(len(objects))\n    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n    plt.tick_params(axis='x', which='both', pad=10,width=20,length=15)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    plt.figure(figsize=(15,10))\n    plt.show()\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(X_test)\n#print(y_pred)\n#y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Randomly select an unseen image and predict the expression\n\nfrom skimage import io\n\ndirc = '../input/random-facial-expressions/'  #unseen random images folder\nrandom_img = random.choice(os.listdir(dirc))  # randomly select an image\n\n#img = image.load_img('../input/random-facial-expressions/5.jpg', grayscale=True, target_size=(48, 48))\n#show_img=image.load_img('../input/random-facial-expressions/5.jpg', grayscale=False, target_size=(400, 400))\n\nimg = image.load_img(dirc+random_img, grayscale=True, target_size=(48, 48))\nshow_img=image.load_img(dirc+random_img, grayscale=False, target_size=(400, 400))\n\n\n\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Predicted Expression:',objects[ind])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}