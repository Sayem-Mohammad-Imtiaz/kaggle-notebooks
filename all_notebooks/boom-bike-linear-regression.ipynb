{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BOOM_BIKE_LINEAR_REGRESSION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Problem Statement:\n\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\nA US bike-sharing provider BikeIndia has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\n\nIn such an attempt, BikeIndia aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\nWhich variables are significant in predicting the demand for shared bikes. How well those variables describe the bike demands Based on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\n\n\nBusiness Goal:Â¶\n\nWe are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market\n\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#importnumpy and pandas package and matplot lib and seaborn \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display 500 column and rows\npd.set_option('display.max_rows', 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the file\ndf=pd.read_csv(\"../input/bike-sharing/day.csv\").set_index(\"instant\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading first five rows of the file.\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the information of the file.\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dteday column is in  object data type--> change to datetimpe stamp\ndf['dteday']= pd.to_datetime(df['dteday'])\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the shape ofthe file \ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the statistics of the file.  \ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TO find co-relation of the dataframe\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing the columns with categoricalvalues\ndf[\"weathersit\"].replace(to_replace=(1,2,3,4),value=(\"cloudy\",\"mist\",\"snow\",\"rain\"),inplace=True)\ndf[\"season\"].replace(to_replace=(1,2,3,4),value=(\"spring\",\"summer\",\"fall\",\"winter\"),inplace=True)\ndf[\"mnth\"].replace(to_replace=(1,2,3,4,5,6,7,8,9,10,11,12),value=(\"jan\",\"feb\",\"March\",\"april\",\"may\",\"june\",\"july\",\"aug\",\"sept\",\"oct\",\"nov\",\"dec\"),inplace=True)\ndf[\"weekday\"].replace(to_replace=(0,1,2,3,4,5,6),value=(\"sun\",\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\"),inplace=True)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the unnecassary column\ndf.drop(['casual','registered',\"dteday\",\"atemp\"],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"casual and registered gives the column cnt so droping casual and registered. dteday is nor neceaasty so droping. atemp and temp almost give the same effect of model so decided to drop atemp.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# to see the co-relation values of the dataframe\nplt.figure(figsize = (16, 10))\ncor=df.corr()\nax=sns.heatmap(cor, annot = True, cmap=\"YlGnBu\")\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to read the missing values of unkonwn values\nprint(df[\"season\"].value_counts())\nprint(df[\"yr\"].value_counts())\nprint(df[\"mnth\"].value_counts())\nprint(df[\"holiday\"].value_counts())\nprint(df[\"weekday\"].value_counts())\nprint(df[\"workingday\"].value_counts())\nprint(df[\"weathersit\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# box plot for categorical variables\nplt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.boxplot(x=\"season\",y=\"cnt\",data=df)\nplt.subplot(2,3,2)\nsns.boxplot(x=\"weathersit\",y=\"cnt\",data=df)\nplt.subplot(2,3,3)\nsns.boxplot(x=\"mnth\",y=\"cnt\",data=df)\nplt.subplot(2,3,4)\nsns.boxplot(x=\"weekday\",y=\"cnt\",data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pair plot for numerical and binary values\nplt.figure(figsize=(30,40))\nsns.pairplot(df,x_vars=(\"temp\",\"hum\",\"windspeed\"),y_vars=\"cnt\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dummy variables for object type variables     \ndf = pd.get_dummies(df,drop_first=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test and train data split\nfrom sklearn.model_selection import train_test_split\ndf_train,df_test=train_test_split(df,train_size=.7,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to see  the shape of the dataframe\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the heap map for test dat\nplt.figure(figsize = (40, 40))\ncor=df_test.corr()\nax=sns.heatmap(cor, annot = True, cmap=\"YlGnBu\")\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to see the co-relation values for train data\nplt.figure(figsize = (30, 40))\ncor=df_train.corr()\nax=sns.heatmap(cor, annot = True, cmap=\"YlGnBu\")\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature scaling by using MinMax scaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply scaler tonumeric columns except dummy variables\nnum=['temp', 'hum', 'windspeed',\"cnt\"]\ndf_train[num]=scaler.fit_transform(df_train[num])\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#diving X and y for model\nX_train=df_train\ny_train=df_train.pop(\"cnt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building our model by using RFE\n\n# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 15\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             # running RFE and selecting 15 features best describing the price of cars\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to see top 15 columns from rfe\ncol = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to see other than top 15 columns from rfe\nX_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing stats model api and define the function  for lm summary\nimport statsmodels.api as sm\ndef fit_LRM(X_train):\n#Function to fit the linear regression model from the statmodel package\n# Creating X_train dataframe with the selected variables\n    # Adding a constant variable  \n    X_train = sm.add_constant(X_train)\n    lm = sm.OLS(y_train,X_train).fit() \n    print(lm.summary())\n    return lm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm=fit_LRM(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"all p-vales are less than 5,so calculating VIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the VIF values and define the function for VIF calculation for the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\ndef getVIF(X_train):\n    # Calculate the VIFs for the new model\n    vif = pd.DataFrame()\n    X = X_train\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the VIf values\ngetVIF(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"high VIF value is hum,so we have to drop it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the humas high VIF\nX_train2 = X_train_rfe.drop('hum', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to fine the linear regression model after dropping the hum\nlm1=fit_LRM(X_train2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No p values less than 5% so checkVIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting VIF for X_train2\ngetVIF(X_train2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Droping temp is not good idea because value of adjusted r squrae chnges from83.8 to 77.5.\nSO droping next variable i.e.working day","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# droping next variable i.e. working day\nX_train3 = X_train2.drop('workingday', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the linear regression model \nX_train4 = sm.add_constant(X_train3)\nlm3 = sm.OLS(y_train,X_train4).fit() \nprint(lm3.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"weeday_sat has high p valueso drop it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# droping weekday_sat\nX_train5=X_train4.drop(\"weekday_sat\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking linear rehression model\nX_train6 = sm.add_constant(X_train5)\nlm4 = sm.OLS(y_train,X_train6).fit() \nprint(lm4.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No high p values so checking VIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train6=X_train6.drop(\"const\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking VIF values\ngetVIF(X_train6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"drop the windspeed as high p value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# droping windspeed\nX_train7=X_train6.drop(\"windspeed\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking linear regression model\nX_train8 = sm.add_constant(X_train7)\nlm5 = sm.OLS(y_train,X_train8).fit() \nprint(lm5.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"mnth_jan as high pvalue,so remove it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the mnth_jan\nX_train9=X_train8.drop(\"mnth_jan\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking linear regression\nX_train10 = sm.add_constant(X_train9)\nlm6 = sm.OLS(y_train,X_train10).fit() \nprint(lm6.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"no pvalues are greater than 5%, so check VIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#get vif for train10\n#X_train10=X_train10.drop([\"const\"],axis=1)\ngetVIF(X_train10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"no VIF values greater than 5%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Residual Analysis of the train data So, now to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_cnt = lm6.predict(X_train10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_cnt), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"making predections","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num=['temp', 'hum', 'windspeed', 'cnt']\ndf_test[num] = scaler.transform(df_test[num])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test.pop('cnt')\nX_test = df_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Now let's use our model to make predictions.\n\n# Creating X_test_new dataframe by dropping variables from X_test\nX_train10= X_train10.drop(['const'], axis=1)\nX_test_new = X_test[X_train10.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lm6.predict(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrmse = sqrt(mean_squared_error(y_test, y_pred))\nprint('Model RMSE:',rmse)\n\nfrom sklearn.metrics import r2_score\nr2=r2_score(y_test, y_pred)\nprint('Model r2_score:',r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculation of adjusted R square for test data set \nX_test.shape\nn = X_test.shape[0]\np=X_test.shape[1]\nadjusted_r2_pred = 1-(1-r2)*(n-1)/(n-p-1)\nadjusted_r2_pred\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion: These are the variables influences the bike demand yr\nholiday\ntemp\nseason_spring\nseason_summer\nseason_winter\nmnth_july\nmnth_sept\nweathersit_mist\nweathersit_snow\n\nTrain data set, The R square is 82.4% The adjusted R square is 82% Test data set, The R square is 81% The adjusted R square is 78% There is 3% drop with respect to train and test data set, so model is accepted\n\nFinally we can conclude, As per our final Model, the top 3 predictor variables that influences the bike Sharing demand are: -Temperature (temp) - A coefficient value of â0.5029â indicated that a unit increase in temp variable increases the bike share demand numbers by 0.5029 units. -Year (yr) - A coefficient value of â0.2326â indicated that a unit increas e in yr variable increases the bike hire numbers by 0.2326 units -Season_winter - A coefficient value of â0.0829â indicated.\n\nNegative co-efficient variabels are\n\nholiday\nseason_spring\nmnth_july\nweathersit_mist\nweathersit_snow\nPositive co-efficient variables are,\n\nyear\ntemperature\nseason_summer\nseason_winter\nmnth_sept\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}