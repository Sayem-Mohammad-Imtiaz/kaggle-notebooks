{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n### Minería de datos: Curso 2020-2021\n* José Gabriel Ruiz Gomez\n* Francisco Javier Vicente Martínez"},{"metadata":{},"cell_type":"markdown","source":"# 1. Preliminares"},{"metadata":{},"cell_type":"markdown","source":"Cargamos las librerias necesarias"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom mlxtend.feature_selection import ColumnSelector\n\nimport numpy as np\nimport seaborn as sns\nsns.set()\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fijamos la semilla para que el experimento sea reproducible:"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Base de datos Pima"},{"metadata":{},"cell_type":"markdown","source":"# 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"La base de datos Pima Indians Diabetes contiene 768 entradas que corresponden a mujeres de descendencia india de al menos 21 años de edad. La base de datos las clasifica segun tengan diabetes o no con la variable de clase:\n\n* `Outcome`\n\nÉsta puede tomar el valor 0 o 1. Las variables predictoras para este problema son:\n\n* `Pregnancies`: Representa el numero de veces que quedo embarazada\n* `Glucose`: Concentracion de glucose en plasma a 2 horas de un examen de tolerancia de glucosa\n* `BloodPresure`: Presion arterial diastólica (mm Hg)\n* `SkinThickness`: Grosor de un pliegue de piel del triceps (mm)\n* `Insulin`: Serum de insulina de 2 horas (mu U/ml)\n* `BMI`: Indice de masa corporal\n* `DiabetesPedigreeFunction`: Indice obtenido a partir de familiares que padecen diabetes\n* `Age`: Edad "},{"metadata":{},"cell_type":"markdown","source":"Cargamos los datos de `Pima`: "},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\n\nindex = False\ntarget = \"Outcome\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se ha especificado la variable clase pero en esta base de datos no hay ninguna variable que sirva de identificador."},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se han cargado bien los datos, la funcion `head` puede que nos de una muestra sesgada pero mi objetivo es ver simplemente si el objeto data se ha creado correctamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos los datos en variables predictoras y resultado."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se han divido correctamente."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para evitar el sobreajuste a los datos vamos a dividirlos en conjunto de entrenamiento y de prueba en un ratio de 70% entrenamiento y 30% de prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      shuffle=True,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El conjunto de datos de pima no parece seguir ningun tipo de orden pero he decidido aleatorizarlo (`shuffle=True`) de todas formas."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Volvemos a juntar las variables predictoras con las objetivo para el analisis exploratorio:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)\ndata_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Análisis exploratorio de los datos"},{"metadata":{},"cell_type":"markdown","source":"### Descripcion del conjunto de datos"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestro conjunto de entrenamiento se compone de 537 casos con 9 variables, 8 predictoras 1 objetivo."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todas las variables son numericas, excepto la variable objetivo.\nTodas las variables son continuas, aunque el numero de embarazos podriamos considerarla discreta ya que por su naturaleza no va a tener muchos valores distintos."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestra variable clase tiene dos estados: 0 representa que no tiene diabetes y 1 representa que tiene diabetes."},{"metadata":{},"cell_type":"markdown","source":"### Visualizacion de las variables"},{"metadata":{},"cell_type":"markdown","source":"Ahora que ya conocemos el conjunto de datos debemos analizar la distribucion de las variables. En este caso vamos a analizar las variables mediante metodos univariados, en este caso concreto histogramas, ya que todas nuestras variables predictoras son numericas y un diagrama de barras para nuestra variable objetivo."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todos los atributos parecen distribuciones normales, en el caso de `pregnancies`, `insulin`, `diabetesPedigreeFunction` y `age` son distribuciones asimetricas.\n\nLos atributos `pregnancies`, `glucose`, `bloodPresure`, `BMI`, `DiabetesPedigreeFunction` y `Age` contienen algunos outliers.\n\nVariables como `glucose`, `bloodPresure` y `BMI` tienen unos cuantos valores perdidos, `Skin thickness` tiene muchos valores perdidos.\n\nLos valores perdidos estan representados por un 0, el caso de la variable `Insulin` es un tanto problematico porque los pacientes con diabetes de tipo 1 no producen nada de insulina, esto hace complicado distinguir valores perdidos de valores de insulina 0 reales, con lo cual es posible que no podamos usar esta variable, pero para esta practica voy a tratarlos todos como valores perdidos."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La muestra no esta balanceada hay mas casos en los que `Outcome` es 0."},{"metadata":{},"cell_type":"markdown","source":"A continuacion vamos a hacer un analisis multivariado con una matriz de gráficos. Para ver relaciones entre variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(data_train, target=\"Outcome\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A pesar de no poder verse bien hay un par de variables que tienen cierto poder discriminador combinadas con el resto: `Glucose` y `Pregnancies`. \n\nComo se puede ver, los valores para las dos posibilidades de la variable clase estan muy entremezcados, al no haber una distincion clara entre ambas podemos asumir que el modelo no va a salir demasiado bueno.\n\nOtras variables como `DiabetesPedigreeFunction` o `Insulin` seguramente sea mejor utilizarlas de forma independiente."},{"metadata":{},"cell_type":"markdown","source":"Este grafico al tener tantas variables y estar todos los casos tan apelotonados es poco util, para poder cuantificar la relacion entre las variables voy a utilizar un heatmap de coorelacion:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.px.imshow(data_train.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que `Age` y `Pregnancies` tienen bastante correlacion, ademas tambien `BMI` esta coorelacionado con `skinThickness`, `Glucose` y `BloodPresure`, lo cual es logico.\n\nPor otra parte tambien se puede observar una coorelacion positiva entre `skinThicness` e `Insulin` pero esto puede que se deba a la gran cantidad de valores perdidos (0) que tienen ambas."},{"metadata":{},"cell_type":"markdown","source":"# 4. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Para poder obtener un modelo que tenga sentido de nuestros datos primero tenemos que abordar dos problemas: la discretizacion (dado el caso) y los valores perdidos."},{"metadata":{},"cell_type":"markdown","source":"### Valores perdidos"},{"metadata":{},"cell_type":"markdown","source":"Tenemos el problema de que no podemos simplemente imputar los valores perdidos dentro del pipeline porque los valores perdidos se estan representando con un 0 y hay variables en las que 0 es un valor válido, sin ir mas lejos nuestra variable clase tiene 0 o 1, si sustituimos todos los 0 nos cargamoe el problema y todos los modelos van a estar mal, por lo cual no podemos utilizar por si solo un `SimpleImputer`."},{"metadata":{},"cell_type":"markdown","source":"En lugar de esto lo que vamos a utilizar es otro `estimator` que, en teoria, nos va a permitir aplicar nuestro `simpleImputer` tan solo a determinadas columnas, se trata de un `ColumnTransformer`."},{"metadata":{"trusted":true},"cell_type":"code","source":"simpleImputer = SimpleImputer(missing_values=0, strategy='most_frequent')\ncols = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n\nimputer = ColumnTransformer(\n    [(\"ImpMissing\", simpleImputer, cols)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hemos utilizado como estrategia para el `SimpleImputer` la moda porque en los datos hay outliers y la media se ve muy afectada por estos, la mediana se ve menos afectada, pero como hay valores tan extremos ceemos que es mejor utilizar la moda en su lugar. La moda, aunque menos, tambien se ve algo afectada por valores extremos.\n\nTambien podriamos haber usado correlacion con otras variables, pero no se ve una correlacion tan fuerte como para que valga la pena usar este método."},{"metadata":{},"cell_type":"markdown","source":"### Discretizacion"},{"metadata":{},"cell_type":"markdown","source":"Vista la distribucion de outcome y la naturaleza de los datos tiene mas sentido discretizar con la estratiegia de las k-medias en 2 intervalos."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"Creamos el pipeline para todos estimadores, primero siempre poniendo el transformador que imputa los valores perdidos y luego, en su caso, el transformador para la discretización. "},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = make_pipeline(imputer, DummyClassifier(strategy=\"most_frequent\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo CART"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = make_pipeline(imputer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(imputer, discretizer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En este caso no he modificado los hiperparametros de los modelos porque el hiperparameter tunning no forma parte de esta practica, asi que estan por defecto"},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluacion de modelos"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variables para analizar los modelos resultantes\nAlgoritmos=[]\nMetricas=[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)\nAlgoritmos.append(\"ZeroR\\t\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred, 1, 0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No hay mucho que decir del Zero-R, el porcentaje de acierto va a ser siempre exactamente igual a la proporcion de casos de la clase mayoritaria, se pueden utilizar los resultados del Zero-R como baseline, el modelo que se acierte mas o menos lo mismo o menos que un Zero-R no vale la pena."},{"metadata":{},"cell_type":"markdown","source":"### Arbol de clasificación"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)\nAlgoritmos.append(\"ArbolClas\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred, 1, 0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El arbol de clasificacion sin discretizar no lo ha hecho mucho mejor que el Zero-R, pero por lo menos clasifica algunos \"1\" correctamente"},{"metadata":{},"cell_type":"markdown","source":"### Arbol de clasificación discretizado"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)\nAlgoritmos.append(\"ArbolClasDiscr\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred, 1, 0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Discretizando hemos conseguido mejorar la precision."},{"metadata":{},"cell_type":"markdown","source":"# Conclusiones"},{"metadata":{},"cell_type":"markdown","source":"Respecto a los clasificadores obtenidos, son todos bastante malos, pero en base a los resultados discretizando hemos obtenido bastante mas precision aunque a costa de la tasa de verdaderos positivos, este clasificador podria valer para etiquetar correctamente verdaderos negativos, pero eso lo hace mejor el Zero-R.\n\nDe los 3 clasificadores el mejor para clasificar verdaderos positivos es el arbol sin discretizar, aunque tenga una precision parecida al Zero-R y bastantes falsos positivos, para este tipo de problema, desde el punto de vista de la salud creo que seria mejor etiquetar mal a los negativos que a los positivos."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.f1Tabla(Algoritmos, Metricas)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como se puede ver en la tabla anterior el arbol de clasificacion discretizado tiene mejor precision, pero, tal y como habiamos dicho antes, en nuestro caso el árbol de clasificacion sin discretizar es mejor para nuestro caso ya que tiene bastante mejor recall y en un problema como este en el que se estan prediciendo enfermedades preferimos clasificar bien antes a los positivos que a los negativos. Ademas la F1 score da mejor resultado para el arbol sin discretizar también."},{"metadata":{},"cell_type":"markdown","source":"# Base de datos Wisconsin"},{"metadata":{},"cell_type":"markdown","source":"# 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"El conjunto datos a utilizar es `Breast Cancer Wisconsin`. \nContiene 546 muestras que se clasifican en dos tipos de tumores:\n* `B = Benigno`\n* `M = Maligno`\n\nPara cada tumor se han realizado una serie de mediciones correspondientes a las variables predictoras del problema:\n* `radius` : media de distancias entre el centro de los puntos al perímetro\n* `texture` : desviación estandard de los valores de escala de grises\n* `perimeter` : perímetro\n* `area` : área\n* `smoothness` : variación local en la longitud de los radios\n* `compactness` : perímetro^2 / area - 1.0\n* `concavity` : severidad de las porciones cóncavas del contorno\n* `concave points` : numero de las porciones cóncavas del contorno\n* `symetry` : simetría\n* `fractal dimension` : aproximación de la línea de costa - 1\n\nEn las tablas se representa la media, la desviación típica y un valor \"worst\" que es la media de los tres mayores valores. Resultando 30 variables distribuidas de forma que el campo 3 es Media del Radio, el campo 13 desviación típica del Radio y campo 23 es \"worst\" del radio.\n\nEl objetivo sería clasificar una nueva instancia (cuya clasificación es desconocida) en función de sus variables."},{"metadata":{},"cell_type":"markdown","source":"Comenzamos cargando el conjunto de datos `Breast Cancer Wisconsin`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"\n\ndata = utils.load_data(filepath, index, target)\n#Eliminamos columna Unnamed\ndata = data.loc[:,data.columns !=\"Unnamed: 32\"]\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos el conjunto de datos en dos subconjuntos, uno con variables predictoras (X) y otro con la variable objetivo (y)."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Además debemos separar nuestro conjunto de datos en dos:\n\n* Una muestra de entrenamiento (típicamente, 70%)\n* Una muestra de prueba (típicamente, 30%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                     stratify=y, \n                                                     random_state=seed,\n                                                     train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para facilitar el análisis exploratorio de datos, volvemos a juntar las variables predictoras con la variable clase. Comenzamos con el conjunto de datos entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Contiunamos con el conjunto de datos de prueba"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Análisis exploratorio de los datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar el preprocesamiento es interesante observar las propiedades del conjunto de datos, analizando sus variables y la interacción entre estas. No obstante, no podemos usar el formato tabular directamente puesto que para un humano es casi imposible extraer conclusiones a partir del análisis de valores numéricos. Por ello, nos apoyaremos en gráficos y estadísticos."},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de realizar cualquier operación es fundamental conocer nuestro problema. Hay dos dimensiones básicas que deben ser exploradas:\n\n* Número de casos\n* Número de variables\n    * Tipo de las variables: Continuas (t.c.c. numéricas) o discretas (t.c.c. categóricas)\n\nPara ello, consultaremos las estructuras de datos correspondientes."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tal y como se puede observar, el conjunto de datos de entrenamiento está formado por 398 casos y 31 variables (30 variables predictoras y 1 variable clase)\n\nPara conocer cuál es el tipo de las variables, recurrimos al método `info`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todas las variables son numéricas, excepto la variable objetivo. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La variable clase tiene dos estados *(M y B)*."},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"Una vez conocemos con más detalle el conjunto de datos de entrenamiento, lo que debemos hacer es representar y analizar las distribuciones de las variables. Para ello, utilizaremos métodos univariados, esto es, histogramas para las variables numéricas y diagramas de barras para las variables categóricas. En particular:\n\n* Un histograma muestra la densidad de ejemplos para los distintos valores de una variable numérica.\n* Un diagrama de barras representa la frecuencia de cada estado de una variable categórica."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que la clase objetivo no tiene el mismo número de variables para cada clasificación por lo tanto no es un problema que se encuentre balanceado. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para que las gráficas sean más representativas dividimos el conjunto de datos de entrenamiento en tres subconjuntos, que representarán cada uno los valores de las medias (means_data), los valores de el error standard (SE_data) y los valores \"worst\" (worst_data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"means_data = data_train[[\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\", \"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"diagnosis\"]]\nSE_data = data_train[[\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\", \"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"diagnosis\"]]\nworst_data = data_train[[\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\", \"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\",\"diagnosis\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora representaremos en diferentes gráficas los datos para poder obtener más conocimiento"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(means_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(SE_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(worst_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Muchos de los valores guardan alta correlación entre sí, por ejemplo radio con perímetro y área o puntos cóncavos con la concavidad, lo cual es lógico porque son atributos que van bastante de la mano semánticamente hablando."},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(means_data, target=\"diagnosis\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(SE_data, target=\"diagnosis\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(SE_data, target=\"diagnosis\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Atendiendo a las gráficas podemos fijarnos en que se forman en todos los atributos como dos grandes grupos de datos que discriminarían la clasificación B de la clasificación M por lo que podría ser interesante discretizar en 2 intervalosn estos datos. "},{"metadata":{},"cell_type":"markdown","source":"# 4. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Dentro del preprocesamiento de datos, podemos destacar las siguientes tareas:\n\n* Limpieza de datos (imputación de valores perdidos, suavizado del ruido, etc.)\n* Integración de datos (a partir de múltiples fuentes)\n* Transformación de datos (normalización, construcción, etc.)\n* Reducción de datos (discretización de variables numéricas, selección de variables, selección de instancias, etc.)"},{"metadata":{},"cell_type":"markdown","source":"### Valores perdidos"},{"metadata":{},"cell_type":"markdown","source":"Para poder usar un pipeline y poder distinguir las variables con valores perdidos tenemos que \"modificar\" toda la base de datos, realmente no vamos a modificar los datos, simplemente vamos a indicar como nan los valores perdidos, de esta forma podemos aplicar el mismo pipeline al conjunto de entrenamiento, al conjunto de test y a los datos que vengan despues."},{"metadata":{},"cell_type":"markdown","source":"### Discretización"},{"metadata":{},"cell_type":"markdown","source":"Como hemos visto, la discretización permite transformar variables numéricas en categóricas, siendo este paso beneficioso para algunos algoritmos de aprendizaje, pues permite que modelos lineales resuelvan problemas no lineales.\n\n`scikit-learn` permite realizar tres tipos de discretización (`strategy`) mediante el transformador `KBinsDiscretizer`:\n\n* `uniform`: Igual anchura.\n* `quantile`: Igual frecuencia.\n* `kmeans`: Discretización basada en k-medias.\n\nTras el análisis exploratorio de datos realizado previamente, parece lógico realizar una discretización en 2 intevalos de igual anchura:"},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eliminar del conjunto de datos:"},{"metadata":{},"cell_type":"markdown","source":"# 5. Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = make_pipeline(imputer, DummyClassifier(strategy=\"most_frequent\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo CART "},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = make_pipeline(imputer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(imputer, discretizer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluacion de modelos"},{"metadata":{},"cell_type":"markdown","source":"### Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"Algoritmos.clear()\nMetricas.clear()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(zero_r_model,\n              X_train, X_test,\n              y_train, y_test)\nAlgoritmos.append(\"ZeroR\\t\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred, 'M', 'B'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Arbol de clasificación"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(tree_model,\n              X_train, X_test,\n              y_train, y_test)\nAlgoritmos.append(\"ArbolClas\")\nMetricas.append(utils.confMatMetricas(y_test, y_pred, 'M', 'B'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)\nAlgoritmos.append(\"ArbolClasDiscr\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred, 'M', 'B'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusiones"},{"metadata":{},"cell_type":"markdown","source":"Para esta base de datos, los clasificadores obtenidos tienen una mayor proporción de aciertos, no obstante, tenemos que fijarnos en la tasa de verdaderos positivos, ya que de nuevo es una clasificación basada en datos de salud donde nos interesa minimizar el error en éste parámetro.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.f1Tabla(Algoritmos, Metricas)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De nuevo basándonos en el Recall podemos ver que el algoritmo que mejor nos clasifica los resultados sería el Arbol de Clasificación sin discretizar. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}