{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Botnet Detection with an Autoencoder\n20 May 2021  \nThis notebook was created for a course at Istanbul Technical University.\n- We implement (a simplified version of) the autoencoder-based anomaly detection described in the N-BaIoT paper [1].\n\n[1] Meidan, Yair, et al. \"N-BaIoT—Network-based Detection of IoT Botnet Attacks Using Deep Autoencoders.\" IEEE Pervasive Computing 17.3 (2018): 12-22. https://arxiv.org/pdf/1805.03409  ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras import layers, losses, Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2021-06-27T19:36:10.968407Z","iopub.execute_input":"2021-06-27T19:36:10.968915Z","iopub.status.idle":"2021-06-27T19:36:13.093142Z","shell.execute_reply.started":"2021-06-27T19:36:10.96879Z","shell.execute_reply":"2021-06-27T19:36:13.092024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n1. N-BaIoT Dataset\n2. Autoencoder Architecture\n3. Python Reimlementation\n4. Conclusion\n\n---\n# 1. N-BaIoT Dataset\nhttps://archive.ics.uci.edu/ml/datasets/detection_of_IoT_botnet_attacks_N_BaIoT\n- Normal traffic was captured for 9 IoT devices connected to the network.\n- Then, they were infected with Mirai and BASHLITE (aka gafgyt) malware.\n- Traffic was captured for each device for different phases of the malware execution.\n- From the network traffic, 115 features were extracted as described in [1].\n\nFor now, we start with data from a smart doorbell: normal execution and the different phases of Mirai.","metadata":{}},{"cell_type":"code","source":"def load_nbaiot(filename):\n    return np.loadtxt(\n        os.path.join(\"/kaggle/input/nbaiot-dataset\", filename),\n        delimiter=\",\",\n        skiprows=1\n    )\n\nbenign = load_nbaiot(\"1.benign.csv\")\nX_train = benign[:40000]\nX_test0 = benign[40000:]\nX_test1 = load_nbaiot(\"1.mirai.scan.csv\")\nX_test2 = load_nbaiot(\"1.mirai.ack.csv\")\nX_test3 = load_nbaiot(\"1.mirai.syn.csv\")\nX_test4 = load_nbaiot(\"1.mirai.udp.csv\")\nX_test5 = load_nbaiot(\"1.mirai.udpplain.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-27T19:36:13.0956Z","iopub.execute_input":"2021-06-27T19:36:13.096045Z","iopub.status.idle":"2021-06-27T19:37:33.457727Z","shell.execute_reply.started":"2021-06-27T19:36:13.096001Z","shell.execute_reply":"2021-06-27T19:37:33.454466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n      X_test3.shape, X_test4.shape, X_test5.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T19:37:33.466328Z","iopub.execute_input":"2021-06-27T19:37:33.467503Z","iopub.status.idle":"2021-06-27T19:37:33.490832Z","shell.execute_reply.started":"2021-06-27T19:37:33.467353Z","shell.execute_reply":"2021-06-27T19:37:33.488548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 2. Autoencoder Architecture\nRelevant parts of [1] describing the autoencoder architecture:\n\n- The general idea is autoencoder-based anomaly detection, p. 4:\n> [W]e use deep autoencoders and maintain a  \n> model for each IoT device separately. An autoencoder is a neural  \n> network which is trained to reconstruct its inputs after some  \n> compression. The compression ensures that the network learns the  \n> meaningful concepts and the relation among its input features. If an  \n> autoencoder is trained on benign instances only, then it will succeed  \n> at reconstructing normal observations, but fail at reconstructing  \n> abnormal observations (unknown concepts). When a significant re-  \n> construction error is detected, then we classify the given  \n> observations as being an anomaly.\n\n- Details, p. 5:\n> Each autoencoder had an input layer whose dimension is equal to the  \n> number of features in the dataset (i.e., 115). As noted by [16] and  \n> [15], autoencoders effectively perform dimen- sionality reduction  \n> internally, such that the code layer be- tween the encoder(s) and  \n> decoder(s) efficiently compresses the input layer and reflects its  \n> essential characteristics. In our experiments, four hidden layers of  \n> encoders were set at decreasing sizes of 75%, 50%, 33%, and 25% of the  \n> input layer’s dimension. The next layers were decoders, with the same  \n> sizes as the encoders, however with an increasing order (starting from  \n> 33%).\n\n- Anomaly Detection threshold, p.4:\n> This anomaly threshold, above which an instance is considered  \n> anomalous, is calculated as the sum of the sample mean and standard  \n> deviation of [the mean squared error over the validation set].\n\n- Sequences of packets, p.4:\n> Preliminary experiments revealed that deciding whether a device’s  \n> packet stream is anomalous or not based on a single instance enables  \n> very accurate detection of IoT-based botnet attacks (high TPR).  \n> However, benign instances were too often (in approximately 5-7% of  \n> cases) falsely marked as anomalous. Thus we base the abnormality  \n> decision on a sequence of instances by implementing a majority vote on  \n> a moving window. We determine the minimal window size ws∗ as the  \n> shortest sequence of instances, a majority vote which produces 0% FPR  \n> on [the validation set].\n\n- Final hyperparameters for the Danmini smart doorbell, p. 5:  \n    - Learning rate: 0.012  \n    - Number of epochs: 800  \n    - Anomaly Threshold: 0.042  \n    - Window Size: 82\n\n---\n# 3. Python Reimplementation\nAdapting this Keras tutorial: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/autoencoder.ipynb","metadata":{}},{"cell_type":"code","source":"class Autoencoder(Model):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        self.encoder = Sequential([\n            layers.Dense(115, activation=\"relu\"),\n            layers.Dense(86, activation=\"relu\"),\n            layers.Dense(57, activation=\"relu\"),\n            layers.Dense(37, activation=\"relu\"),\n            layers.Dense(28, activation=\"relu\")\n        ])\n        self.decoder = Sequential([\n            layers.Dense(37, activation=\"relu\"),\n            layers.Dense(57, activation=\"relu\"),\n            layers.Dense(86, activation=\"relu\"),\n            layers.Dense(115, activation=\"sigmoid\")\n        ])\n    \n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","metadata":{"execution":{"iopub.status.busy":"2021-06-27T19:37:33.494254Z","iopub.execute_input":"2021-06-27T19:37:33.495035Z","iopub.status.idle":"2021-06-27T19:37:33.523976Z","shell.execute_reply.started":"2021-06-27T19:37:33.494949Z","shell.execute_reply":"2021-06-27T19:37:33.52124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How can we determine the hyperparameters?\n- In Keras, the fault learning rate for Adam optimizer is `0.001`. With that, training is relatively slow, so we quickly tried `0.01`.\n- We use Early Stopping to find the number of epochs.\n- The anomaly threshold is calculated as one standard deviation above the mean of training data losses.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nx = scaler.fit_transform(X_train)\n\nae = Autoencoder()\nae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\nmonitor = EarlyStopping(\n    monitor='val_loss',\n    min_delta=1e-9,\n    patience=5,\n    verbose=1,\n    mode='auto'\n)\nae.fit(\n    x=x,\n    y=x,\n    epochs=800,\n    validation_split=0.3,\n    shuffle=True,\n    callbacks=[monitor]\n)\n\ntraining_loss = losses.mse(x, ae(x))\nthreshold = np.mean(training_loss)+np.std(training_loss)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-27T19:37:33.528054Z","iopub.execute_input":"2021-06-27T19:37:33.528864Z","iopub.status.idle":"2021-06-27T19:38:17.941668Z","shell.execute_reply.started":"2021-06-27T19:37:33.528717Z","shell.execute_reply":"2021-06-27T19:38:17.940558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(x, threshold=threshold, window_size=82):\n    x = scaler.transform(x)\n    predictions = losses.mse(x, ae(x)) > threshold\n    # Majority voting over `window_size` predictions\n    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n                     for i in range(window_size, len(predictions)+1)])\n\ndef print_stats(data, outcome):\n    print(f\"Shape of data: {data.shape}\")\n    print(f\"Detected anomalies: {np.mean(outcome)*100}%\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T19:38:17.943524Z","iopub.execute_input":"2021-06-27T19:38:17.944013Z","iopub.status.idle":"2021-06-27T19:38:17.951641Z","shell.execute_reply.started":"2021-06-27T19:38:17.943964Z","shell.execute_reply":"2021-06-27T19:38:17.95043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5]\n\nfor i, x in enumerate(test_data):\n    print(i)\n    outcome = predict(x)\n    print_stats(x, outcome)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T19:42:56.117963Z","iopub.execute_input":"2021-06-27T19:42:56.118501Z","iopub.status.idle":"2021-06-27T19:44:26.795945Z","shell.execute_reply.started":"2021-06-27T19:42:56.118462Z","shell.execute_reply":"2021-06-27T19:44:26.794964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 4. Conclusion\nAccording to the above output, it seems to work well.\n\nThe following are some possibilities where to go from here:\n- Run on the full N-BaIoT dataset: all 9 devices, all attacks.\n- Implement (some of) the improvements from [2].\n- In [3], it is suggested to use a subset of 23 features instead of all 115. However, different algorithms were used.\n    - Question: Are these 23 features enough also for an autoencoder system like in [1] or [2]?\n- Run on the MedBIoT dataset [4].\n- Run on the IoT-23 dataset [5] after performing feature extraction.\n\n# References\n[1] Meidan, Yair, et al. \"N-BaIoT—Network-based Detection of IoT Botnet Attacks Using Deep Autoencoders.\" IEEE Pervasive Computing 17.3 (2018): 12-22. https://arxiv.org/pdf/1805.03409  \n[2] Mirsky, Yisroel et al. \"Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection\", NDSS (2018). https://arxiv.org/abs/1802.09089v2  \n[3] Alhowaide, Alaa, et al. \"Towards the design of real-time autonomous IoT NIDS.\" Cluster Computing (2021): 1-14. https://doi.org/10.1007/s10586-021-03231-5  \n[4] Guerra-Manzanares, Alejandro, et al. \"MedBIoT: Generation of an IoT Botnet Dataset in a Medium-sized IoT Network.\" ICISSP 1 (2020): 207-218. https://doi.org/10.5220/0009187802070218  \n[5] Garcia, Sebastian et al. \"IoT-23: A labeled dataset with malicious and benign IoT network traffic\" (2020). (Version 1.0.0) [Data set]. Zenodo. http://doi.org/10.5281/zenodo.4743746","metadata":{}}]}