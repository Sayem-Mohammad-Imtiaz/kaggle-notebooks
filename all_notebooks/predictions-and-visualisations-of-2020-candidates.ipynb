{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 2020 US Presidential Election\nToday, we will be visualising data about 27 of the US president candidates' information, such as their age and number of children. Then, we will be using their tweets to create a classifier that predicts which person wrote those tweets."},{"metadata":{},"cell_type":"markdown","source":"#### If you find my notebook helpful and enjoy it, please give it an upvote as it would help me make more of these."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom wordcloud import WordCloud\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier, LinearRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Putting together the dataset\nThe first step that we will be taking in visualising our data is cleaning it. To do this, we will create a new column for the candidates' age, fill the Not a Numbers for the 'announcement' column with zeros and replace the m's and f's in the 'sex' column with male and female."},{"metadata":{"trusted":true},"cell_type":"code","source":"info = pd.read_csv('../input/2020-united-states-presidential-election/candidates_info.csv')\n\ninfo['year born'] = pd.to_datetime(info['born']).dt.year\ninfo['announcement'] = info['announcement'].fillna('NaN 0')\ninfo['sex'] = np.where(info['sex']=='m', 'male', 'female')\ninfo['age'] = 2020-info['year born']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will also create another column called 'announcement month' which will store data on which month the people gave their announcements."},{"metadata":{"trusted":true},"cell_type":"code","source":"months = np.array([])\n\nfor i in info['announcement']:\n    month = i.split(' ')[0]\n    months = np.append(months, month)\n    \ninfo['announcement month'] = months\nmonth = info['announcement month']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the information that we are given about each candidate:"},{"metadata":{"trusted":true},"cell_type":"code","source":"info","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data visualisation"},{"metadata":{},"cell_type":"markdown","source":"### Age of candidates\nFirstly, we will use a bar chart to visualise the age of each candidate. The oldest person was 90 and the youngest 38."},{"metadata":{"trusted":true},"cell_type":"code","source":"name_and_age = pd.concat([info['name'], info['age']], axis=1)\nname_and_age = name_and_age.sort_values('age', ascending=False)\ncount = Counter(name_and_age)\n\nplt.figure(figsize=(15, 5))\nplt.bar(name_and_age['name'], name_and_age['age'], color='blue')\nplt.title('Age of candidates')\nplt.xlabel('Candidates')\nplt.ylabel('Age')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Number of children per candidate\nThe next plot is a pie chart which can accurately deliver a description of what percentage of the people have a certain amount of children."},{"metadata":{"trusted":true},"cell_type":"code","source":"count = Counter(info['children'])\n\ncount['0 children'] = count.pop(0)\ncount['1 child'] = count.pop(1)\ncount['2 children'] = count.pop(2)\ncount['3 children'] = count.pop(3)\ncount['4 children'] = count.pop(4)\ncount['5 children'] = count.pop(5)\n\nfig, ax = plt.subplots(1, 1, figsize=(7, 7))\nax.set_title('Number of children per candidate')\nax.pie(count.values(), labels=count.keys(), autopct=lambda p:f'{p:.2f}%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Candidates' state of origin\nNext is a bar chart which tells us what state the people come from. The state which most of them are from is New York, followed by a draw between Texas and California."},{"metadata":{"trusted":true},"cell_type":"code","source":"count = Counter(info['state of residence'])\ncount = pd.Series(count).sort_values(ascending=False)\n\nplt.bar(count.keys(), count, color='green')\nplt.title(\"Candidates' state of origin\")\nplt.xlabel('State')\nplt.ylabel('Number of candidates')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sex of the candidates\nSubsequently, we will now use a pie chart to take a look at how many people are male and female in the presidential election. We can see that the number of male candidates is more than triple of the number of female ones."},{"metadata":{"trusted":true},"cell_type":"code","source":"count = Counter(info['sex'])\nfig, ax = plt.subplots(1, 1, figsize=(7, 7))\nax.set_title('Sex of the candidates')\nax.pie(count.values(), labels=count.keys(), autopct=lambda p:f'{p:.2f}%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Months that candidates delivered their announcements\nAfterwards, we now use a bar chart to plot which months the people made their announcements. Using this, we see that the most frequent months were January and April, with 6 people each doing them then and the least popular were November and August, with only one person each doing their announcement then. However, those that did their speeches at that time did it in 2017, while everybody else did it in 2019."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(7, 5))\ncount = Counter(month)\ncount = pd.Series(count).sort_values(ascending=False)\n\nplt.bar(count.keys(), count, color='purple')\nplt.title('Months that candidates delivered their announcements')\nplt.xlabel('Month')\nplt.ylabel('Number of candidates')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/2020-united-states-presidential-election/twitter/'\ntext = []\ntwitter_names = []\n\nfor user in os.listdir(path):\n    profile = pd.read_csv(path+user)\n    text.append(profile['Text'])\n    twitter_names.append(user[:-4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Most commonly used words in twitter\nNow we switch over to twitter, checking to see which words are most mentioned by our users."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(9, 3, figsize=(30, 30))\n\ni = 0\nfor user in text:\n    flattened = list(np.concatenate(axes).flat)\n    words = user.sum()\n    words = [word for word in words.split() if 'http' not in word and 'co' not in word and 'amp' not in word]\n    words = ' '.join(words)\n    \n    wordcloud = WordCloud(background_color='white').generate(words)\n    flattened[i].imshow(wordcloud)\n    flattened[i].set_title(twitter_names[i], size=25)\n    flattened[i].axis('off')\n    fig.subplots_adjust(hspace=0.3)\n    \n    i+= 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we mush all of the tweets that our candidates have tweeted and find the most common used words there."},{"metadata":{"trusted":true},"cell_type":"code","source":"joined = ' '.join(list(np.concatenate(text).flat))\njoined = [word for word in joined.split() if 'http' not in word and 'co' not in word and 'amp' not in word]\njoined = ' '.join(joined)\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nwordcloud = WordCloud(background_color='white').generate(joined)\nax.imshow(wordcloud)\nax.axis('off')\nax.set_title('All candidates', size=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Twitter activity over the years\nThe next visualisations are 27 bar charts which show when the tweets in our dataset were tweeted, in relation to years. Note that our dataset spans only around 3,000 tweets per person, therefore it doesn't show the complete activity in our candidates' twitter accounts since they created it."},{"metadata":{},"cell_type":"markdown","source":"In order to create our graphs, we first loop over the candidates' names in the 'twitter' directory and store them in a numpy array. Then, we loop over the csv datasets of their twitter info, find when the tweets were created in the 'CreatedAt' feature and place that data into a 'years' numpy array."},{"metadata":{"trusted":true},"cell_type":"code","source":"names = np.array([])\nmonths = []\nyears = []\n\nfor i in os.listdir(path): \n    names = np.append(names, pd.read_csv(path+i)['Name'][0])\n\nfor user in os.listdir(path):\n    person = pd.read_csv(path+user)\n    temp_month = []\n    temp_year = []\n    \n    for date in person['Created At']:\n        temp_month.append(date[4:7])\n        temp_year.append(date[-4:])\n    \n    months.append(temp_month)\n    years.append(temp_year)\n    \ncounts = []\nfor user in years:\n    count = Counter(user)\n    counts.append(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfig, axes = plt.subplots(9, 3, figsize=(20, 30))\nflattened = list(np.concatenate(axes).flat)\n\nfor ax in flattened:\n    ax.bar(counts[i].keys(), counts[i].values(), color='blue')\n    ax.set_title(names[i])\n    ax.set_xlabel('Years')\n    ax.set_ylabel('Number of tweets')\n    fig.subplots_adjust(wspace=0.3, hspace=0.6)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Retweets in 2019 per candidate\nNext, we will take a look at how many retweets each candidate has got and display our data it with a bar chart."},{"metadata":{"trusted":true},"cell_type":"code","source":"retweets = np.array([])\ni = 0\n\nfor user in os.listdir(path):\n    person = pd.read_csv(path+user)\n    year = np.array(years[i]).astype(int)\n    \n    tweets_in_2019 = np.where(year==2019, 1, 0).sum()\n    retweets_in_2019 = person['Retweets'][len(year)-tweets_in_2019:].sum()\n    retweets = np.append(retweets, retweets_in_2019)\n\n    i += 1\n    \nnames_and_retweets = pd.concat([pd.Series(names), pd.Series(retweets)], axis=1)\nnames_and_retweets = names_and_retweets.sort_values(by=1, ascending=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As seen below, Donald Trump got retweeted ten times more than the person who is second-most retweeted."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.bar(names_and_retweets[0], names_and_retweets[1], color='red')\nplt.title('Retweets in 2019 per candidate')\nplt.ylabel('Retweets')\nplt.xlabel('Candidates')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there was such a huge unbalance of data in our last chart, we will do another graph which shows the amount of retweets each candidate received, however, this time without Donald Trump. This is useful in helping us see the difference in retweets for the other candidates."},{"metadata":{"trusted":true},"cell_type":"code","source":"djt = list(names_and_retweets[0]).index('Donald J. Trump')\nnames_and_retweets = names_and_retweets.drop(djt)\n\nplt.figure(figsize=(15,5))\nplt.bar(names_and_retweets[0], names_and_retweets[1], color='red')\nplt.title('Retweets per candidate without Donald J. Trump')\nplt.ylabel('Retweets')\nplt.xlabel('Candidates')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting twitter accounts\nFinally, we will now create a classifier that predicts which candidate has tweeted based on our twitter datasets."},{"metadata":{},"cell_type":"markdown","source":"The first step is taking all of the users' data in the 'twitter' directory and uniting them all into one dataset called df, which is then shuffled randomly."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame([])\n\nfor candidate in os.listdir(path):\n    twitter_info = pd.read_csv(path+candidate)\n    df = df.append(twitter_info)\n    \ndf = df.reset_index(drop=True)\ndf = df.sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An X and y are brought out from df, with the X representing the tweets for the users and the y representing the users' names. The y is preprocessed with a LabelEncoder, which transforms the textual data into numerical, and the X and y are split into train and test sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = df['Text'], df['Name']\n\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X train and test are textual, which cannot be inputted into the classifier. Therefore, we will use Natural Language Processing methods to convert it into a type which can be inputted to the model. This is done through the Bag of Words and the TFIDF methods."},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer()\ntfidf = TfidfTransformer()\n\nX_tr_cv = cv.fit_transform(X_train)\nX_te_cv = cv.transform(X_test)\n\nX_train = tfidf.fit_transform(X_tr_cv)\nX_test = tfidf.transform(X_te_cv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Furthermore, we loop over three models: a linear SVC, a naive bayes and a passive aggressive classifer. The accuracy and cross validation score are evaluated from each predictor so that we can analyse their performance. As seen below, the Linear SVC performs best, followed by the passive aggressive classifier and then the naive bayes. Therefore, the SVC will be used in our final prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in [LinearSVC(), MultinomialNB(), PassiveAggressiveClassifier()]:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    accuracy = model.score(X_test, y_test)\n    cross_val = cross_val_score(model, X_test, y_test).mean()\n    \n    print(str(model)[:-2] + ' accuracy:', accuracy, 'cross val score:', cross_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At last, we create a Linear SVC model, fit it to the X and y train, and then evaluate its performance with an accuracy and cross val score. The classifier manages to get an accuracy of 67% and a cross validation of 55%."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearSVC()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\naccuracy = model.score(X_test, y_test)\ncross_val = cross_val_score(model, X_test, y_test).mean()\n\nprint('LinearSVC accuracy score: ' + str(round(accuracy*100, 2)) + '% cross val score: ' + str(round(cross_val*100, 2)) + '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thank you for reading my notebook."},{"metadata":{},"cell_type":"markdown","source":"#### If you found my notebook helpful and enjoyed it, please give it an upvote as it would help me make more of these."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}