{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"4fa8fec5-1928-c936-c92d-04d45207ae52"},"source":"This notebook will apply a selection of 7 ML methods on this classic dataset."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d56ba967-d326-0dcf-8927-0e5581f077ab"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.optimizers import SGD, Adam\nfrom keras.utils import np_utils\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n\tplt.imshow(cm, interpolation='nearest', cmap=cmap)\n\tplt.title(title)\n\tplt.colorbar()\n\ttick_marks = np.arange(len(classes))\n\tplt.xticks(tick_marks, classes, rotation=45)\n\tplt.yticks(tick_marks, classes)\n\n\tprint(cm)\n\n\tthresh = cm.max() / 2.\n\tfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n\t\tplt.text(j, i, cm[i, j],\n\t\t\t\t horizontalalignment=\"center\",\n\t\t\t\t color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\tplt.tight_layout()\n\tplt.ylabel('True label')\n\tplt.xlabel('Predicted label')\n\tplt.show()\n\t\n\n# import mushroom data\nmushroom = pd.read_csv(\"../input/mushrooms.csv\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"57d7dc2d-9313-b544-d260-81919f4cb0b2"},"source":"Set up the numpy array by using LabelEncoder and take a train-test split. Using a random state since I will case this split again for the neural net."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ee77bbe-1ab9-a40f-20ba-b36572690065"},"outputs":[],"source":"# setting up data in numpy array\nlab = preprocessing.LabelEncoder()\nfor col in mushroom.columns:\n    mushroom[col] = lab.fit_transform(mushroom[col])\ny = mushroom[\"class\"]\nX = mushroom.drop(\"class\", axis = 1)\n\n# train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2215)\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"75fbc484-52f5-bf6b-c232-8477ab72b2db"},"source":"### Logistic regression"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29a530cd-7641-03a8-79a9-de0bb6e95f6e"},"outputs":[],"source":"logreg = LogisticRegression(C=1e5)\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nprint(classification_report(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = [\"y_true\", \"y_pred\"], title = \"Logistic Regression\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"c2e0da16-9417-5d21-b5e2-c59a0bdbfb54"},"source":"### K-Nearest Neighbour"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34a6f193-19a1-1c2b-00f0-9136c40ac0f8"},"outputs":[],"source":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(classification_report(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = [\"y_true\", \"y_pred\"], title = \"KNN\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"d5b6559a-5468-f423-3b3f-bbb75ebc5097"},"source":"### SVM"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19e2be49-070d-635c-69b9-dc705e359f47"},"outputs":[],"source":"svm = SVC()\nsvm.fit(X_train, y_train)\ny_pred = svm.predict(X_test)\nprint(classification_report(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = [\"y_true\", \"y_pred\"], title = \"SVM\")\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"c0188385-8fe8-087c-31bb-f5c599188ec1"},"source":"### Decision tree"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06cd466f-3e72-722f-5ef4-7196e4f925da"},"outputs":[],"source":"tree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)\ny_pred = tree.predict(X_test)\nprint(classification_report(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = [\"y_true\", \"y_pred\"], title = \"Decision Tree\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"ce7c2877-bc51-c343-fce8-197261c8b3c0"},"source":"### Random forest"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c730d427-19e5-36f7-85c9-dea933c17765"},"outputs":[],"source":"rf = RandomForestClassifier(n_estimators = 20)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nprint(classification_report(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = [\"y_true\", \"y_pred\"], title = \"Random Forest\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"98518330-e583-d6ec-91a8-2d1149cdb1dd"},"source":"### Gradient boosting"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c17478b-5098-96ea-34ec-cb84b8b3679b"},"outputs":[],"source":"gb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\ny_pred = gb.predict(X_test)\nprint(classification_report(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = [\"y_true\", \"y_pred\"], title = \"Gradient Boosting\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"2049cca9-71b6-71b3-5174-da408130c1d1"},"source":"### Neural Net with Keras"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a03c1dcc-ed4d-4fad-0e6e-5a845c6288e5"},"outputs":[],"source":"Y = pd.get_dummies(mushroom.iloc[:,0],  drop_first=False)\nX = pd.DataFrame()\nfor each in mushroom.iloc[:,1:].columns:\n    dummies = pd.get_dummies(mushroom[each], prefix=each, drop_first=False)\n    X = pd.concat([X, dummies], axis=1)\n\t\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 2215)\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=x_train.shape[1], kernel_initializer='uniform', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(2, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(0.1), metrics=['accuracy'])\n\nn_epochs = 10\nfor k in tqdm(range(n_epochs)):\n\thistory = model.fit(x_train.values, y_train.values, epochs=1, verbose=0, validation_data = (x_test.values, y_test.values))\n\n# calculate the loss and accuracy\nscore = model.evaluate(x_test.values, y_test.values, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\ny_pred = model.predict(x_test.values)\ny_true = np.array([np.argmax(y_test.values[k]) for k in range(y_test.shape[0])])\ny_pred = np.array([np.argmax(y_pred[k]) for k in range(y_pred.shape[0])])\nprint(classification_report(y_true, y_pred))\nplot_confusion_matrix(confusion_matrix(y_true, y_pred), classes = [\"y_true\", \"y_pred\"], title = \"Neural Net\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"9930ea46-cf35-4cb8-405f-11c5a90039cc"},"source":"Five out of seven methods here classify the death caps with 100% accuracy. This is a neat dataset to demonstrate the basic implementation of these methods."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}