{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-27T03:40:18.563683Z","iopub.execute_input":"2021-07-27T03:40:18.564125Z","iopub.status.idle":"2021-07-27T03:40:18.587193Z","shell.execute_reply.started":"2021-07-27T03:40:18.56404Z","shell.execute_reply":"2021-07-27T03:40:18.586055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"# <center> Import the libraries </center>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:18.59811Z","iopub.execute_input":"2021-07-27T03:40:18.598483Z","iopub.status.idle":"2021-07-27T03:40:19.69566Z","shell.execute_reply.started":"2021-07-27T03:40:18.59845Z","shell.execute_reply":"2021-07-27T03:40:19.694523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/sri-lanka-vehicle-prices-dataset/vehicle_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:19.697504Z","iopub.execute_input":"2021-07-27T03:40:19.697916Z","iopub.status.idle":"2021-07-27T03:40:20.356464Z","shell.execute_reply.started":"2021-07-27T03:40:19.697873Z","shell.execute_reply":"2021-07-27T03:40:20.355001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### Look at the head of the dataframe #######\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:20.359083Z","iopub.execute_input":"2021-07-27T03:40:20.359402Z","iopub.status.idle":"2021-07-27T03:40:20.402193Z","shell.execute_reply.started":"2021-07-27T03:40:20.359373Z","shell.execute_reply":"2021-07-27T03:40:20.401211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Checking the null values ######\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:20.403825Z","iopub.execute_input":"2021-07-27T03:40:20.404307Z","iopub.status.idle":"2021-07-27T03:40:20.446153Z","shell.execute_reply.started":"2021-07-27T03:40:20.404266Z","shell.execute_reply":"2021-07-27T03:40:20.443923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(df.isnull(),cbar=False,cmap=\"Set1\",yticklabels=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:20.447662Z","iopub.execute_input":"2021-07-27T03:40:20.447997Z","iopub.status.idle":"2021-07-27T03:40:21.184164Z","shell.execute_reply.started":"2021-07-27T03:40:20.447966Z","shell.execute_reply":"2021-07-27T03:40:21.183178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n######## Lets clean up the Title column ########\n\ndf[\"Title\"] = df[\"Title\"].apply(lambda x:x.split()[:2])\n\n\n###### Now Subtitle column ##############\n\n############## How i did this #################### \n####### Run this seperate cell and look it up whats going on ! #########\n\n######## df[\"Sub_title\"].iloc[5]   ############# \n############ Then use split() method on this ##########\n############ df[\"Sub_title\"].iloc[5].split(',')[-1] ##############\n\n### The final step use apply method on this #####\n\n\n#### Final code look likes  #####\n\ndf[\"Sub_title\"] = df['Sub_title'].apply(lambda x:x.split(',')[-1])\n\n\n\n\n####################### Now look at the price column ##############################\n\n###### Step one remove the spaces of the string #######\n##### Step two use replace() method and fill them into empty string #####\n###### Final step convert into astype of int or float whatever you want ######\n\n\n\ndf[\"Price\"]  = df[\"Price\"].apply(lambda x:x.split()[-1])\ndf[\"Price\"] = df[\"Price\"].apply(lambda x:x.replace(',',''))\ndf['Price'].astype(int)\n\n\n\n\n##################### Look at the null values #################\ndf[df['Edition'].isnull() ==True]\n\n\n\n################ Edition #######################\n\n######### Your choice you can remove Edition column or drop those missing values It's all up to you ! ; #########\n\ndf.drop(axis=1,columns='Edition',inplace=True)\n\n\n\n##### Transmisson run the both cell seperately ##########\n\ndf[df[\"Transmission\"] == \"Other transmission\"].count()[\"Transmission\"]\ndf[\"Transmission\"] = df[\"Transmission\"].apply(lambda x:x.replace(\"Other transmission\",'Other'))\n\n\n\n######### Fuel columns changing the Other fuel type to Others using replace() method ############\n\ndf['Fuel'] = df[\"Fuel\"].apply(lambda x:x.replace(\"Other fuel type\",'Others'))\n\n\n\n################## Capacity columns ############################\n\ndf[\"Capacity\"] = df[\"Capacity\"].apply(lambda x:int(x.split(\" \")[0].replace(',','')))\n\n\n\n################  Mileage column ###############\ndf[\"Mileage\"] = df[\"Mileage\"].apply(lambda x:int(x.split(\" \")[0].replace(\",\",'')))\n\n\n\n\n############################### Location column ################################\n\ndf[\"Location\"] = df[\"Location\"].apply(lambda x:x.strip().split(\",\")[0])\n\n\n\n############ Description column ###############\n## how to read full description use below code ## \ndf[\"Description\"].iloc[9]\n\n\n\n################# Replace Premium member to Premium #####################\ndf[\"Seller_type\"] = df[\"Seller_type\"].apply(lambda x:x.strip().replace(\"-Member\",\"\"))\n\n\n\n############# published_date column ###########\n## converting to datetime object ### ;\n\ndf[\"published_date\"] = pd.to_datetime(df['published_date'])\n\n\n\n##  creating a new column published_year and acesss the year attribute using apply method in python pandas ## \n\ndf[\"published_year\"] = df[\"published_date\"].apply(lambda x:x.year)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:21.185625Z","iopub.execute_input":"2021-07-27T03:40:21.185934Z","iopub.status.idle":"2021-07-27T03:40:21.569418Z","shell.execute_reply.started":"2021-07-27T03:40:21.185904Z","shell.execute_reply":"2021-07-27T03:40:21.568378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###### Now the data look likes ####### after cleaning ######### ðŸ’¥ðŸ’¥\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T03:40:21.570753Z","iopub.execute_input":"2021-07-27T03:40:21.571071Z","iopub.status.idle":"2021-07-27T03:40:21.597749Z","shell.execute_reply.started":"2021-07-27T03:40:21.57104Z","shell.execute_reply":"2021-07-27T03:40:21.596852Z"},"trusted":true},"execution_count":null,"outputs":[]}]}