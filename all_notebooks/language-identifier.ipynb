{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ncwd = os.getcwd()\nos.chdir('../input/language-identification-datasst/')\ndataset = pd.read_csv('dataset.csv')\nos.chdir(cwd)\nprint(dataset.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train / test split\nbreakpoint = int(0.8 * len(dataset))\ntrain_x = dataset['Text'][:breakpoint]\ntest_x = dataset['Text'][breakpoint:]\n\n# We will separate the ys later\nys = dataset['language']\n\n# Free up some memory\ndel(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some hyperparameters\nvocab_size = 40000\nembedding_dim = 64\nmax_length = 150\ntrunc_type ='post'\noov_tok = '<OOV>'\nnum_unique_languages = len(set(ys))\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Create the vocabulary and convert sentences to sequences\n\ntokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\ntokenizer.fit_on_texts(train_x)\nword_index = tokenizer.word_index\ntraining_sequences = tokenizer.texts_to_sequences(train_x)\ntraining_padded = pad_sequences(training_sequences, maxlen = max_length)\n\ntest_sequences = tokenizer.texts_to_sequences(test_x)\ntest_padded = pad_sequences(test_sequences, maxlen = max_length)\n\n# Tokenize labels too\n\nlabel_tokenizer = Tokenizer()\nlabel_tokenizer.fit_on_texts(ys)\nword_index_y = label_tokenizer.word_index\nlabel_sequences = label_tokenizer.texts_to_sequences(ys)\nlabel_padded = pad_sequences(label_sequences) # probably not necessary, as no language is 2 words long? oh well","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting to numpy arrays\ntraining_padded = np.array(training_padded)\ntest_padded = np.array(test_padded)\n\n# Now separate labels\ntraining_ys = np.squeeze(np.array(label_padded[:breakpoint]))\ntest_ys = np.squeeze(np.array(label_padded[breakpoint:]))\n\n# Problem: label tokenizer set range from 1 to num_unique_classes. Need range form 0 to num_unique_classes-1.\ntraining_ys = training_ys - 1\ntest_ys = test_ys - 1\n# Also fix the word index y dictionary\nfinal_y_index = dict()\nfor language, value in word_index_y.items():\n    final_y_index[language] = value - 1\nword_index_y = final_y_index\ndel(final_y_index)\n\n# one hot encode the ys as well\ntraining_ys = tf.keras.utils.to_categorical(training_ys, num_classes=num_unique_languages)\ntest_ys = tf.keras.utils.to_categorical(test_ys, num_classes=num_unique_languages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's make the model\nimport tensorflow.keras.layers as layers\nmodel = tf.keras.Sequential([\n    layers.Embedding(vocab_size, embedding_dim, input_length=max_length), # hyperparameters set above\n    layers.GlobalAveragePooling1D(),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(num_unique_languages, activation='sigmoid')\n])\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"num_epochs = 25\nhistory = model.fit(training_padded, training_ys, epochs=num_epochs, validation_data=(test_padded, test_ys), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Some nice plots!\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n  \nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's make a predict function\ndef predict(text, tokenizer, index_to_word_y, max_length, trunc_type):\n    sequences = tokenizer.texts_to_sequences(text)\n    padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n    predictions = model.predict(padded)\n    for prediction in predictions:\n        most_likely_lang = np.argmax(prediction)\n        print(index_to_word_y[most_likely_lang])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = ['Pedro Sánchez Pérez-Castejón (Madrid, 29 de febrero de 1972) es un político español, actual presidente del Gobierno de España.', \n            'Hallo Hans. Wie geht es heute? Hast du Mittagessen gegessen?', # The model doesn't know German exists!\n            'Emmanuel Macron, né le 21 décembre 1977 à Amiens, est un haut fonctionnaire, banquier d\\'affaires et homme d\\'État français. Il est président de la République française depuis le 14 mai 2017. ',\n            'กรุงเทพมหานคร เป็นเมืองหลวงและนครที่มีประชากรมากที่สุดของประเทศไทย เป็นศูนย์กลางการปกครอง การศึกษา การคมนาคมขนส่ง การเงินการธนาคาร การพาณิชย์ การสื่อสาร และความเจริญของประเทศ ตั้งอยู่บนสามเหลี่ยมปากแม่น้ำเจ้าพระยา มีแม่น้ำเจ้าพระยาไหลผ่านและแบ่งเมืองออกเป็น 2 ฝั่ง คือ ฝั่งพระนครและฝั่งธนบุรี กรุงเทพมหานครมีพื้นที่ทั้งหมด 1,568.737 ตร.กม.',\n            '你好!',\n            'Gallia  est  omnis  dīvīsa  in  partēs  trēs,  quārum ūnam  incolunt  Belgae,  aliam Aquītānī,  tertiam  quī  ipsōrum  linguā  Celtae,nostrā  Gallī  appellantur.  '\n           ]\nindex_to_word_y = dict([(value, key) for (key,value) in word_index_y.items()])\npredict(sentence, tokenizer, index_to_word_y, max_length, trunc_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I used a Kaggle dataset for this project, which you can find here:\n# https://www.kaggle.com/zarajamshaid/language-identification-datasst","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}