{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv(\"../input/taiwan-and-usa-stock-data/NVDA.csv\") #NVIDIA\ndata = data[::-1] #invert data\ndata = data.reset_index()\ndata.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T09:21:13.830961Z","iopub.execute_input":"2021-09-09T09:21:13.831573Z","iopub.status.idle":"2021-09-09T09:21:14.040603Z","shell.execute_reply.started":"2021-09-09T09:21:13.831472Z","shell.execute_reply":"2021-09-09T09:21:14.039374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:14.042665Z","iopub.execute_input":"2021-09-09T09:21:14.0431Z","iopub.status.idle":"2021-09-09T09:21:14.072355Z","shell.execute_reply.started":"2021-09-09T09:21:14.043064Z","shell.execute_reply":"2021-09-09T09:21:14.07073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(16,6))\nplt.title('Close Price History')\nplt.plot(data['Close'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price (USD)', fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:14.075366Z","iopub.execute_input":"2021-09-09T09:21:14.076318Z","iopub.status.idle":"2021-09-09T09:21:14.330601Z","shell.execute_reply.started":"2021-09-09T09:21:14.076255Z","shell.execute_reply":"2021-09-09T09:21:14.329358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_days = 60 # length of predicting days \n# Create a new dataframe with only the 'Close column \ndata = data.filter(['Close'])\n# Convert the dataframe to a numpy array\ndataset = data.values\n# Get the number of rows to train the model on\ntraining_data_len = int(len(dataset)*.7)\nvalidation_data_len = int(len(dataset)*0.2)\ntesting_data_len = len(dataset) - training_data_len - validation_data_len\n\nprint(\"The number of trainning dataset: \", training_data_len)\nprint(\"The number of validation dataset: \", validation_data_len)\nprint(\"The number of testing dataset: \", testing_data_len)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:14.332922Z","iopub.execute_input":"2021-09-09T09:21:14.333479Z","iopub.status.idle":"2021-09-09T09:21:14.344723Z","shell.execute_reply.started":"2021-09-09T09:21:14.333429Z","shell.execute_reply":"2021-09-09T09:21:14.343058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n# Create the training data set \n# Create the scaled training data set\ntrain_data = dataset[0:training_data_len, :]\n# Split the data into x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(pre_days, len(train_data)):\n    x_train.append(train_data[i-pre_days:i, 0])\n    y_train.append(train_data[i, 0])\n\n        \n# Convert the x_train and y_train to numpy arrays \nx_train, y_train = np.array(x_train), np.array(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:14.346602Z","iopub.execute_input":"2021-09-09T09:21:14.347076Z","iopub.status.idle":"2021-09-09T09:21:14.360763Z","shell.execute_reply.started":"2021-09-09T09:21:14.347017Z","shell.execute_reply":"2021-09-09T09:21:14.359283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the data\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler_x = MinMaxScaler(feature_range=(0,1))\ninput_sc = scaler_x.fit(x_train)\nx_train_norm = input_sc.transform(x_train)\n\ny_train = np.reshape(y_train,(y_train.shape[0], 1))\nscaler_y = MinMaxScaler(feature_range=(0,1))\noutput_sc = scaler_y.fit(y_train)\ny_train_norm = output_sc.transform(y_train)\n\n# Reshape the data\nx_train_norm = np.reshape(x_train_norm, (x_train_norm.shape[0], x_train_norm.shape[1], 1))\nprint(\"The shape of input data: \", x_train_norm.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:14.363118Z","iopub.execute_input":"2021-09-09T09:21:14.363774Z","iopub.status.idle":"2021-09-09T09:21:15.415695Z","shell.execute_reply.started":"2021-09-09T09:21:14.363721Z","shell.execute_reply":"2021-09-09T09:21:15.414391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the validation data set \n# Create the scaled validation data set\nval_data = dataset[training_data_len - pre_days: training_data_len + validation_data_len, :]\n# Split the data into x_val and y_val data sets\nx_val = []\ny_val = []\n\nfor i in range(pre_days, len(val_data)):\n    x_val.append(val_data[i-pre_days:i, 0])\n    y_val.append(val_data[i, 0])\n        \n# Convert the x_train and y_train to numpy arrays \nx_val, y_val = np.array(x_val), np.array(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:15.417192Z","iopub.execute_input":"2021-09-09T09:21:15.41755Z","iopub.status.idle":"2021-09-09T09:21:15.426424Z","shell.execute_reply.started":"2021-09-09T09:21:15.417517Z","shell.execute_reply":"2021-09-09T09:21:15.424783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val_norm = input_sc.transform(x_val)\ny_val = np.reshape(y_val, (y_val.shape[0], 1))\ny_val_norm = output_sc.transform(y_val)\n\n# Reshape the data\nx_val_norm = np.reshape(x_val_norm, (x_val_norm.shape[0], x_val_norm.shape[1], 1))\nprint(\"The shape of validation data: \", x_val_norm.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:15.430857Z","iopub.execute_input":"2021-09-09T09:21:15.431436Z","iopub.status.idle":"2021-09-09T09:21:15.448061Z","shell.execute_reply.started":"2021-09-09T09:21:15.431397Z","shell.execute_reply":"2021-09-09T09:21:15.446346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test 資料集處理， label處理\n# Create the testing data set \n# Create the scaled testing data set\ntest_data = dataset[training_data_len + validation_data_len - pre_days:, :]\n# Split the data into x_test and y_test data sets\nx_test = []\ny_test = []\n\nfor i in range(pre_days, len(test_data)):\n    x_test.append(test_data[i-pre_days:i, 0])\n    y_test.append(test_data[i, 0])\n        \n# Convert the x_train and y_train to numpy arrays \nx_test, y_test = np.array(x_test), np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:15.450403Z","iopub.execute_input":"2021-09-09T09:21:15.450958Z","iopub.status.idle":"2021-09-09T09:21:15.460446Z","shell.execute_reply.started":"2021-09-09T09:21:15.450904Z","shell.execute_reply":"2021-09-09T09:21:15.459163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_norm = input_sc.transform(x_test)\ny_test = np.reshape(y_test, (y_test.shape[0],1))\ny_test_norm = output_sc.transform(y_test)\n\n\n# Reshape the data\nx_test_norm = np.reshape(x_test_norm, (x_test_norm.shape[0], x_test_norm.shape[1], 1))\nprint(\"The shape of testing data: \", x_test_norm.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:15.462428Z","iopub.execute_input":"2021-09-09T09:21:15.463317Z","iopub.status.idle":"2021-09-09T09:21:15.478594Z","shell.execute_reply.started":"2021-09-09T09:21:15.463274Z","shell.execute_reply":"2021-09-09T09:21:15.477274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(200))\nmodel.add(Dense(1))\n\nmodel.summary()\nprint(\"\\n\")\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(x_train_norm, y_train_norm, batch_size = 16, epochs = 20, validation_data = (x_val_norm, y_val_norm))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:21:15.479966Z","iopub.execute_input":"2021-09-09T09:21:15.480542Z","iopub.status.idle":"2021-09-09T09:22:57.466345Z","shell.execute_reply.started":"2021-09-09T09:21:15.480505Z","shell.execute_reply":"2021-09-09T09:22:57.465069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the models predicted price values \npredictions_train = model.predict(x_train_norm)\npredictions_train = output_sc.inverse_transform(predictions_train)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions_train - y_train) ** 2)))\nprint(\"root mean squred error of trainning data: \", rmse)\n\npredictions_val = model.predict(x_val_norm)\npredictions_val = output_sc.inverse_transform(predictions_val)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions_val - y_val) ** 2)))\nprint(\"root mean squred error of validation data: \", rmse)\n\npredictions_test = model.predict(x_test_norm)\npredictions_test = output_sc.inverse_transform(predictions_test)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions_test - y_test) ** 2)))\nprint(\"root mean squred error of testing data: \", rmse)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:22:57.46835Z","iopub.execute_input":"2021-09-09T09:22:57.468831Z","iopub.status.idle":"2021-09-09T09:22:59.735687Z","shell.execute_reply.started":"2021-09-09T09:22:57.468791Z","shell.execute_reply":"2021-09-09T09:22:59.733909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len: training_data_len+validation_data_len]\ntest = data[training_data_len+validation_data_len:]\nvalid['Predictions'] = predictions_val\ntest['Predictions'] = predictions_test\n\n# Visualize the data\nplt.figure(figsize=(16,10))\nplt.subplot(2,1,1)\nplt.title('Close Price ML Predicton of NVDA')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price(USD)', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid['Close' ])\nplt.plot(test['Close'])\nplt.plot(valid['Predictions'],color=\"g\")\nplt.plot(test['Predictions'],color=\"c\")\nplt.legend(['Train', 'Val', 'Test', 'Val_prediction', 'Test_prediction'], loc='lower right')\nplt.show()\n\n\nplt.figure(figsize=(16,10))\nplt.subplot(2,1,2)\nplt.title('Close Price ML Predicton of NVDA')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price(USD)', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid[['Predictions']],color=\"g\")\nplt.plot(test[['Predictions']],color=\"c\")\nplt.legend([ 'Train', 'Val_prediction', 'Test_prediction'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:22:59.738223Z","iopub.execute_input":"2021-09-09T09:22:59.738897Z","iopub.status.idle":"2021-09-09T09:23:00.280572Z","shell.execute_reply.started":"2021-09-09T09:22:59.738829Z","shell.execute_reply":"2021-09-09T09:23:00.279286Z"},"trusted":true},"execution_count":null,"outputs":[]}]}