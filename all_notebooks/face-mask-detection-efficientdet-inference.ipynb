{"cells":[{"metadata":{},"cell_type":"markdown","source":"> ## The training kernel link whose outputs are used is below\nhttps://www.kaggle.com/imkaran23/face-mask-detection-efficientdet-d5-training","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' \n!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' \n!pip install effdet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\nsys.path.insert(0, \"../input/omegaconf\")\nsys.path.insert(0, \"../input/weightedboxesfusion\")\n\nimport torch\nimport os\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset,DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport gc\nfrom matplotlib import pyplot as plt\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchEval\nfrom effdet.efficientdet import HeadNet\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_all = pd.read_csv('../input/face-mask-detection-dataset/submission.csv')\ntest_img = pd.DataFrame(test_img_all.name.unique(),columns = ['name'])\ntest_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_ROOT_PATH = '../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n\nfrom PIL import Image\n\nl = []\nfor index in range(test_img.shape[0]):\n    image_id = test_img.loc[index,'name']\n#     image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR)\n    try:\n        img = Image.open(f'{DATA_ROOT_PATH}/{image_id}')\n        img.verify()\n    except:\n        l.append(index)\n\ntest_img = test_img.drop(index = l).reset_index(drop=True)\ntest_img.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_ROOT_PATH = '../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, image_ids, transforms=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = DatasetRetriever(\n    image_ids = test_img.name.values,\n    transforms=get_valid_transforms()\n)\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=8, \n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15, 15))\ncolumns = 5\nrows = 1\nfor i in range(1, columns*rows +1):\n    image, image_id = dataset[i]\n    numpy_image = image.permute(1,2,0).cpu().numpy()\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(numpy_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_net(checkpoint_path):\n    config = get_efficientdet_config('tf_efficientdet_d5')\n    net = EfficientDet(config, pretrained_backbone=False)\n\n    config.num_classes = 20\n    config.image_size= 512\n    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n\n    checkpoint = torch.load(checkpoint_path)\n    net.load_state_dict(checkpoint['model_state_dict'])\n\n    del checkpoint\n    gc.collect()\n\n    net = DetBenchEval(net, config)\n    net.eval()\n    return net.cuda()\n\nnet = load_net('../input/face-mask-detection-efficientdet-d5-training/effdet/last-checkpoint.bin')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_predictions(images, score_threshold=0.35):\n    images = torch.stack(images).cuda().float()\n    predictions = []\n    with torch.no_grad():\n        det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n        for i in range(images.shape[0]):\n            boxes = det[i].detach().cpu().numpy()[:,:4]    \n            scores = det[i].detach().cpu().numpy()[:,4]\n            classes = det[i].detach().cpu().numpy()[:,5]\n            indexes = np.where(scores > score_threshold)[0]\n            boxes = boxes[indexes]\n            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]         \n            predictions.append({\n                'boxes': boxes[indexes],\n                'scores': scores[indexes],\n                'classes': classes[indexes]\n            })\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nDATA_ROOT_PATH = '../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n\nl = []\nfor images, image_ids in tqdm(data_loader, total = len(test_img)/data_loader.batch_size):\n    all_predictions = make_predictions(images)    \n    for idx, predictions in enumerate(all_predictions):\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_ids[idx]}', cv2.IMREAD_COLOR)\n        for j in range (len (predictions['boxes'])):\n            l.append([image_ids[idx]] + predictions['boxes'][j].tolist() + [predictions['classes'][j]] + [image.shape[0]] + [image.shape[1]]) \n            \ntest_result = pd.DataFrame(l,columns = ['name','x1','y1','x2','y2','class','h','w'])\ntest_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result['x1'] = test_result['x1'].apply(lambda x1 : 0 if int(x1)<0 else x1)\ntest_result['y1'] = test_result['y1'].apply(lambda y1 : 0 if int(y1)<0 else y1)\ntest_result['x2'] = test_result['x2'].apply(lambda x2 : 512 if int(x2)>512 else x2)\ntest_result['y2'] = test_result['y2'].apply(lambda y2 : 512 if int(y2)>512 else y2)\n\n# Scale coordinates\ntest_result['x1'] = (test_result['x1']/512.0)*test_result['w']\ntest_result['x2'] = (test_result['x2']/512.0)*test_result['w']\ntest_result['y1'] = (test_result['y1']/512.0)*test_result['h']\ntest_result['y2'] = (test_result['y2']/512.0)*test_result['h']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/face-mask-detection-efficientdet-d5-training/classname.csv')\nclass_map = dict(zip(list(range(1,21)),df['classname'].unique()))\ntest_result['classname'] = test_result['class'].apply(lambda x : class_map[x])\ntest_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_ROOT_PATH = '../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n\nfig=plt.figure(figsize=(75, 75))\ncolumns = 2\nrows = 5\nfor i in range(1, columns*rows +1):\n    image_id = test_img['name'].values[i + 20]\n    img = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR).astype(np.float32)\n    img /= 255.0\n#     img = cv2.resize(img, (512, 512))\n    boxes = test_result[test_result['name'] == image_id][['x1','y1','x2','y2']].values.astype(np.int)\n    classnames = test_result[test_result['name'] == image_id]['classname'].values\n    for j,box in enumerate(boxes):\n        cv2.rectangle(img, (box[0], box[1]), (box[2],  box[3]), (0 , 255, 0), 2 )\n        cv2.putText(img , classnames[j] , (int(box[0]),int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result = test_result.drop(columns = ['class','h','w'])\ntest_result.to_csv('submission.csv', index = False)\ntest_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_result.classname.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}