{"cells":[{"metadata":{},"cell_type":"markdown","source":"# __Data Science Regression Project: Predicting Home Prices in Banglore__\n"},{"metadata":{},"cell_type":"markdown","source":"### For this project I have followed the tutorial available on \"https://www.youtube.com/watch?v=rdfbcdP75KI\". Special thanks to \"codebasics\" for providing free learning."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import the requires libraries\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib \nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ndf = pd.read_csv(\"../input/bengaluru-house-price-data/Bengaluru_House_Data.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count of flats with different areas type\ndf['area_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('area_type')['area_type'].agg('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop features that are not required and save it into df2\ndf2 = df.drop(['area_type','society','balcony','availability'],axis='columns')\ndf2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cheaking null values\ndf2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## __Data Cleaning: Handle NA values__"},{"metadata":{"trusted":true},"cell_type":"code","source":"# find the num values in each columns\ndf2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the null values\ndf3 = df2.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there will be no null values now\ndf3.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the total records of df2(with null values) and df3(removed null values)\nprint(df2.shape)\nprint(df3.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering </br>\n### Add new feature(integer) for bhk (Bedrooms Hall Kitchen)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# find all the distinct size of falts\ndf3['size'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to make the flat size uniform remove the strings literals and save it into new 'bhk' column\ndf3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\ndf3.bhk.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# these are the dummy data or corrupt data as for a 27bhk total_sqft is 8000 which is incorrect.\ndf3[df3.bhk>20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.total_sqft.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this function will change the total_sqft i.e flat area into float from string.\ndef is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3[~df3['total_sqft'].apply(is_float)].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 34.46Sq. Meter is incorrect values so, we will remove these incorrect data and then take the avg of\n# flat size\ndef convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) ==2:\n        return (float(tokens[0]) + float(tokens[1]))/2\n    try:\n        return float(x)\n    except:\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 = df3.copy()\ndf4.total_sqft = df4.total_sqft.apply(convert_sqft_to_num)\ndf4 = df4[df4.total_sqft.notnull()]\ndf4.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add new feature called price per square fee"},{"metadata":{"trusted":true},"cell_type":"code","source":"df5 = df4.copy()\ndf5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\ndf5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5_stats = df5['price_per_sqft'].describe()\ndf5_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5['location'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.location = df5.location.apply(lambda x: x.strip())\nlocation_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"location_stats_less_than_10 = location_stats[location_stats<=10]\nlocation_stats_less_than_10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# total unique records for location\nlen(df5.location.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for all the locations having flats less than 10 make it's location as other \ndf5.location = df5.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\nlen(df5.location.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5[df5.location == 'other'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5[df5.total_sqft/df5.bhk<300].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df6 = df5[~(df5.total_sqft/df5.bhk<300)]\ndf6.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outlier Removal Using Standard Deviation and Mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"df6.price_per_sqft.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('location'):\n        m = np.mean(subdf.price_per_sqft)\n        st = np.std(subdf.price_per_sqft)\n        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n    return df_out\ndf7 = remove_pps_outliers(df6)\ndf7.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check if for a given location how does the 2 BHK and 3 BHK property prices look like\ndef plot_scatter_chart(df,location):\n    bhk2 = df[(df.location==location) & (df.bhk==2)]\n    bhk3 = df[(df.location==location) & (df.bhk==3)]\n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(df7,\"Rajaji Nagar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter_chart(df7,\"Hebbal\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can remove those 2 BHK apartments whose price_per_sqft is less than mean price_per_sqft \n# of 1 BHK apartment\ndef remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n    return df.drop(exclude_indices,axis='index')\ndf8 = remove_bhk_outliers(df7)\n# df8 = df7.copy()\ndf8.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter_chart(df8,\"Rajaji Nagar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter_chart(df8,\"Hebbal\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df8.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8[df8.bath>10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is unusual to have 2 more bathrooms than number of bedrooms in a home\ndf8[df8.bath>df8.bhk+2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df9 = df8[df8.bath<df8.bhk+2]\ndf9.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df10 = df9.drop(['size','price_per_sqft'],axis='columns')\ndf10.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use One Hot Encoding For Location\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies = pd.get_dummies(df10.location)\ndummies.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')\ndf11.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df12 = df11.drop('location',axis='columns')\ndf12.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build a Model Now..."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df12.drop(['price'],axis='columns')\ny = df12.price\nprint(\"X_shape\", X.shape)\nprint(\"y_shape\", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)\n\nfrom sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train,y_train)\nlr_clf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use K Fold cross validation to measure accuracy of our LinearRegression model\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n\ncross_val_score(LinearRegression(), X, y, cv=cv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that in 5 iterations we get a score above 80% all the time. This is pretty good but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV for this purpose\n"},{"metadata":{},"cell_type":"markdown","source":"## Find best model using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find best model using GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'linear_regression' : {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n            }\n        },\n        'lasso': {\n            'model': Lasso(),\n            'params': {\n                'alpha': [1,2],\n                'selection': ['random', 'cyclic']\n            }\n        },\n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter': ['best','random']\n            }\n        }\n    }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n\nfind_best_model_using_gridsearchcv(X,y)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test the model for few properties\ndef predict_price(location,sqft,bath,bhk):    \n    loc_index = np.where(X.columns==location)[0][0]\n\n    x = np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = bhk\n    if loc_index >= 0:\n        x[loc_index] = 1\n\n    return lr_clf.predict([x])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_price('1st Phase JP Nagar',1000, 2, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}