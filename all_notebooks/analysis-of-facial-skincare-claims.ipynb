{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\n \n# NLP\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\n\n# Plotting\nimport plotly.express as px\nimport plotly.graph_objects as go\n!pip install chart_studio\nimport chart_studio.plotly as py\nfrom plotly.subplots import make_subplots\nimport cufflinks as cf\n%matplotlib inline\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\ncf.go_offline()\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('max_colwidth', None)\n\n\n# Import dataset\ndf = pd.read_csv('/kaggle/input/all-products-available-on-sephora-website/sephora_website_dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Manufacturers would claim tons of product benefits, in an attempt to convince customers to buy their brand. \n\nThis dataset made me curious how skincare products would position themselves - what are the most common product claims? And are there specific claims that effectively sway product ratings positively? \n\nThese questions are the main issues I shall attempt to address using this Sephora dataset, and with the help of NLP techniques."},{"metadata":{},"cell_type":"markdown","source":"## Part 1: Popular Terms Used in Product Descriptions"},{"metadata":{},"cell_type":"markdown","source":"The main variable to be analyzed here is called 'details' as this contains the product description - the benefit claims, ingredient callouts, clinical results, and other relevant product information. \n\nThis variable is open text data format, therefore some data cleaning and processing would be necessary before patterns can be observed.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['details'][:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This analysis shall focus on facial skin care products. Relevant categories are filtered.\nskin_care = ['Moisturizers', 'Face Serums', 'Face Wash & Cleansers', 'Face Masks', 'Eye Creams & Treatments', \\\n             'Toners', 'Face Oils', 'Face Sunscreen', 'Sheet Masks', 'Facial Peels', 'Skincare', 'Exfoliators' \\\n            'Face Sets', 'Anti-Aging', 'For Face']\n\ndf_skin = df[df['category'].isin(skin_care)].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to clean and tokenize the text data: \ndef clean_and_tokenize(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove punctuation characters\n    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n    text = text.strip('\\n')\n    # Remove titles\n    titles = '|'.join(['what it is', 'skin type', 'skincare concerns', 'formulation', 'highlighted ingredients', \\\n                      'ingredient callouts', 'what else you need to know', 'clinical results'])\n    text = re.sub(titles, \"\", text)\n    # Tokenize into words\n    tokens = nltk.word_tokenize(text)\n    # Remove stopwords\n    words = [x for x in tokens if x not in stopwords.words(\"english\")]\n    # Remove n's\n    words = [x for x in words if x != 'n']\n    # Lemmatize, but do not lemmatize 'sls' and 'sles' terms\n    lemmatizer = WordNetLemmatizer()\n    lemmatized = [lemmatizer.lemmatize(word) if word not in ['sls', 'sles'] else word for word in words]\n    return lemmatized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a set of clean words that will be used for analysis\nwords = clean_and_tokenize(''.join(str(df_skin['details'].to_list())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe for top words appearing in the descriptions\ndf_words = pd.Series(words).value_counts().reset_index().\\\n            rename(columns = {\"index\":\"word\", 0:\"counts\"})\n\n# Filter it only among top 10\ndf_words_10 = df_words[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the top words\nfig = px.bar(x = df_words_10.word,\n             y = df_words_10.counts,\n             labels = {\n                 'x' : 'Words',\n                 'y' : 'Counts'\n             },\n             title = 'Top words appearing in product descriptions',\n             template = 'simple_white'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of course, the most frequent word found in the descriptions would be \"skin\". Aside from this, ingredient-related terms are also frequently appearing (\"free\" and \"without\" most probably pertaining to the products being free from unwanted ingredients, \"ingredient\" and \"formulation\"). \"Parabens\" also appeared in the top 10, a well-known nasty ingredient that skincare products swear that they do not have. \n\nLooking at n-grams or chains of words successively mentioned together would help give more contextual information about these terms. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe for bigrams\ndf_bigrams = pd.Series(nltk.ngrams(words, 2)).value_counts().reset_index().rename(columns = {\"index\":\"bigrams\", 0:\"counts\"})\ndf_bigrams['bigrams'] = df_bigrams['bigrams'].astype(str)\n\n# Filter it only among top 10\ndf_bigrams_10 = df_bigrams[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the top bigrams\nfig = px.bar(x = df_bigrams_10.bigrams,\n             y = df_bigrams_10.counts,\n             labels = {\n                 'x' : 'Bigrams',\n                 'y' : 'Counts'\n             },\n             title = 'Top bigrams appearing in product descriptions',\n             template = 'simple_white')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The pair of words appearing most frequently: \"fine\" + \"line\". This, along with \"line\" and \"wrinkle\", say a lot about how products boast their anti-ageing benefits.\n\nIngredient claims still dominate, with \"formulated\" + \"without\" in the second place, and detailed nasty additives such as sls - sles, sulfate - sls, and sles - parabens appearing in the top 10.  \n\nWe also look at trigrams to expand the context more."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe for trigrams\ndf_trigrams = pd.Series(nltk.ngrams(words, 3)).value_counts().reset_index().rename(columns = {\"index\":\"trigrams\", 0:\"counts\"})\ndf_trigrams['trigrams'] = df_trigrams['trigrams'].astype(str)\n\n# Filter it only among top 10\ndf_trigrams_10 = df_trigrams[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the top trigrams\nfig = px.bar(x = df_trigrams_10.trigrams,\n             y = df_trigrams_10.counts,\n             labels = {\n                 'x' : 'trigrams',\n                 'y' : 'Counts'\n             },\n             title = 'Top trigrams appearing in product descriptions',\n             template = 'simple_white')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, ingredient claims, anti-ageing, and skin-type formulations appear as top trigrams.\n\nNext step: We will look at how these claims affect ratings of the products (if ever they really do)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}