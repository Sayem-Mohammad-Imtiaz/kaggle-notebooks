{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview \n\n## Dataset consists of 14 columns :\n\n* 'id': Id of the tweet posted\n* 'created_at': Date and Time of the tweet posted\n* 'retweet_count': Count of how many times the same tweet is re-tweeted.\n* 'source': From which platform the tweet was posted\n* 'user_id': Id of the user posting the tweet\n* 'user_name': Name of the user posting the tweet\n* 'user_description': Description of the user posting the tweet\n* 'userfollowercount': Count of how many followers does the user have\n* 'userfriendscount': Count of how many friends does the user have\n* 'user_location': Location from where the user posted the tweet\n* 'user_verified': Is the user verified by Twitter or not\n* 'user_url': URL of the user's profile\n* 'tweet': Tweet posted by user\n* 'lengthoftweet': The total length of the tweet posted by the user ( words ).\n\n## Steps I used in this kernel :\n> ### 1.Import libraries\n> ### 2.Read Files & Basic insights\n> ### 3.Preprocessing And Analysis\n> ### 4.Data Visualization\n> ### 5.Conclusion","metadata":{}},{"cell_type":"markdown","source":"# 1. Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Read Files & Basic insights","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Read CSV Files ","metadata":{}},{"cell_type":"code","source":"data= pd.read_csv(\"../input/neet-tweets-dataset/neet_data.csv\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* First 5 Rows","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Last 5 Rows","metadata":{}},{"cell_type":"code","source":"data.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Random 5 Rows","metadata":{}},{"cell_type":"code","source":"data.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Basic Insights","metadata":{}},{"cell_type":"code","source":"print(\"Shape of the dataset : \", data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Column Names : \\n\"+'-'*25)\nprint(data.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Unique values in every column \\n\"+'-'*25)\nfor i in data.columns:\n    print(\"\\t\"+i+\" = \",len(set(data[i])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Preprocessing & Analysis","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Clearing Null Values","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nullCount = ((data.isna().sum() / data.shape[0])* 100).reset_index().rename(columns = {\"index\": \"Columns\", 0: \"missing value percentage\"})\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Missing Value percentage\",fontsize=18)\nsns.heatmap(data.isna(),ax=axes[0])\nsns.barplot(nullCount['Columns'],nullCount['missing value percentage'],ax=axes[1])\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INFERENCE : \n#### user_url(\\~61%) has the most number of missing values followed by user_location(\\~36%) and user_description(\\~19%)","metadata":{}},{"cell_type":"markdown","source":"## 3.2 Imputation And Arranging","metadata":{}},{"cell_type":"code","source":"# replace nan of user_location with INDIA\ndata['user_location'].fillna('India',inplace=True)\n# replace nan of user_description with NO DESCRIPTION\ndata['user_description'].fillna('No Description',inplace=True)\n#check for all null values\ndata.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.boxplot()\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* So we do not have much outliers in our data.","metadata":{}},{"cell_type":"code","source":"# splitting date and time\ndf = data\ndate=[]\ntime=[]\nfor i in data['created_at']:\n    date.append(i.split(' ')[0])\n    time.append(i.split(' ')[1])\ndf['created_on']=date\ndf['created_at']=time\ndf.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lets drop user_url as it has many missing values and also not very useful","metadata":{}},{"cell_type":"code","source":"try:\n    data.drop('user_url',axis=1,inplace=True)\nexcept:\n    print(\"URL dropped\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now lets have a look on hashtags and the persons tagged in the tweet.","metadata":{}},{"cell_type":"code","source":"hashtags = []\nhashtags_count = []\nperson_tags = []\nperson_tags_count = []\nfor sen in data['tweet']:\n    hashes = []\n    tags = []\n    sen_list = sen.split(' ')\n    for word in sen_list:\n        if len(word)>1:\n            if word[0]=='#':\n                hashes.append(word)\n            if word[0]=='@':\n                tags.append(word)\n    hashtags.append(tuple(hashes))#converted to tuple as tuple is a hashable object\n    person_tags.append(tuple(tags))\n    hashtags_count.append(len(hashes))\n    person_tags_count.append(len(tags))\n      \nlen(person_tags),len(hashtags),len(hashtags_count),len(person_tags_count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['tagged_persons'] = tuple(person_tags)\ndf['hashtags'] = tuple(hashtags)\ndf['hashtags_count'] = hashtags_count\ndf['tagged_persons_count'] = person_tags_count\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Our dataset has {} persons tagged\".format(df['tagged_persons_count'].sum()))\nprint(\"In our dataset users used {} hashtags \".format(df['hashtags_count'].sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[[ 'user_id', 'user_name','user_description', 'user_follower_count', 'user_friends_count',\n              'user_location', 'user_verified', 'tweet', 'length_of_tweet', 'retweet_count', 'source',\n              'created_at',  'created_on', 'tagged_persons', 'hashtags', 'hashtags_count',\n              'tagged_persons_count']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The new shape of our Data is : \",df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Data Visualization ","metadata":{}},{"cell_type":"code","source":"hashData = df.hashtags.value_counts()[1:8].reset_index()\nfig,axes = plt.subplots(1,1,figsize=(14,5))\nplt.suptitle(\"Trending Hashtags Used\",fontsize=18)\nsns.barplot(data = hashData , y='index',x='hashtags')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tagData = df.tagged_persons.value_counts()[1:8].reset_index()\nfig,axes = plt.subplots(1,1,figsize=(14,5))\nplt.suptitle(\"Most Tagged Persons\",fontsize=18)\nsns.barplot(data = tagData , y='index',x='tagged_persons')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.user_location.value_counts()[:3].reset_index()\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Most Common Locations \",fontsize=18)\nsns.lineplot(x=df[\"index\"], y = df[\"user_location\"],ax=axes[1]) \nsns.barplot(y=df[\"index\"], x = df[\"user_location\"],ax=axes[0]) \nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference :-\n#### Most of the users are from India and preffered not to provide more detail about their location. ","metadata":{}},{"cell_type":"code","source":"fig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Verified Users \",fontsize=18)\nexplode = (0.4, 0)\nsns.countplot(data[\"user_verified\"],ax=axes[1])\ndata['user_verified'].value_counts().plot.pie(explode=explode,shadow=True, startangle=90,ax=axes[0])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference :- \n#### Very few users who are posting on #NEET are verified by Twitter.  ","metadata":{}},{"cell_type":"code","source":"retweeted=[]\nfor i in data.retweet_count:\n    if i>0:\n        retweeted.append('Retweeted')\n    else:\n        retweeted.append('Not Retweeted')\n\nretweeted=pd.Series(retweeted)\nuniq = data.retweet_count.unique()\nuniq","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes = plt.subplots(1,2,figsize=(15,5))\nplt.suptitle(\" Retweeted Counts \",fontsize=18)\nretweeted.value_counts().plot.pie(explode=(0.2,0),shadow=True, startangle=90,ax=axes[0])\nplt.pie(data.retweet_count.value_counts(),startangle=30, shadow=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.source.value_counts()[:7].reset_index()\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Common Sources Used by Users \",fontsize=18)\nsns.barplot(y=df[\"index\"], x = df[\"source\"],ax=axes[0]) \nsns.lineplot(x=df[\"index\"], y = df[\"source\"],ax=axes[1]) \nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference :-\n#### A major part of sources of posting tweet is from Android followed by Twitter Web App and then the rest.\n","metadata":{}},{"cell_type":"markdown","source":"# 5. CONCLUSION\n*  The data do not have much outliers.\n*  Users prefer to leave their descriptive information as the data has a lot of missing values in some columns(descriptive columns)\n*  Most of the users are from India and a few from other countries too.\n*  Most of the users posting on #NEET are not verified by Twitter.\n*  People prefer posting from Android devices followed by Twitter Web App and then the rest applications.\n*  The tweets posted has 203 persons tagged and users used 62 hashtags. \n*  Most tagged person is @neet_gill and most used hashtag is NEET.","metadata":{}},{"cell_type":"markdown","source":"### References: \n#### https://www.kaggle.com/sudarshanpatil/ipl-tweets-eda\n#### https://seaborn.pydata.org/     ,     https://towardsdatascience.com/exploratory-data-analysis-in-python-c9a77dfa39ce","metadata":{}},{"cell_type":"markdown","source":"## If You Like The Kernel Do Not Forget To Upvote And Add your Comments. \n# THANK YOU :D","metadata":{}}]}