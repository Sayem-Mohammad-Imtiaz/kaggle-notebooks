{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the Data\n\nThe Kreuz-Kreis-Plus-Minus-Gartenhag.csv dataset contains 28 x 28 pixel images of all black and white #, +, -, o and x handwritten characters.\nThe first column of the dataset contains the label of the image as integer:\n\n- 0 equals #\n- 1 equals +\n- 2 equals -\n- 3 equals o\n- 4 equals x\n\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/images/Kreuz-Kreis-Plus-Minus-Gartenhag.csv\", sep=',', header=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After reading, check if there are any null values in the dataset:","metadata":{}},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparation\n\nIn order to train different models, lets split the data set into x (all columns which contain pixel data) and y (the label).\n\nAfter that, split the data into a train and a test set:","metadata":{}},{"cell_type":"code","source":"x = df.iloc[:, df.columns != '0']\ny = df.iloc[:, :1]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y) # , train_size=11500","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare different algorithms\n\nNext up, I'm going to compare the following algorithms:\n\n- LogisticRegression\n- RandomForestClassifier\n- KNeighborsClassifier\n- Support Vector Machine\n- GaussianNB\n- XGBClassifier\n\nIm going to use 5-fold cross validation on the training set.\n\nIn addition I'm going to print a confusion matrix for every model:","metadata":{}},{"cell_type":"code","source":"dfs = []\n\nmodels = [\n    ('LogReg', LogisticRegression()),\n    ('RF', RandomForestClassifier()),\n    ('KNN', KNeighborsClassifier()),\n    ('SVM', SVC()),\n    ('GNB', GaussianNB()),\n    ('XGB', XGBClassifier())\n]\n\nresults = []\nnames = []\nscoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'] # , 'roc_auc'\n\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n    cv_results = model_selection.cross_validate(model, x_train.values, y_train.values, cv=kfold, scoring=scoring, error_score=\"raise\")\n    clf = model.fit(x_train, y_train)\n    y_pred = clf.predict(x_test)\n    results.append(cv_results)\n    names.append(name)\n    this_df = pd.DataFrame(cv_results)\n    this_df['model'] = name\n    dfs.append(this_df)\n    \n    confusion_matrix = plot_confusion_matrix(model, x_test, y_test)\n    confusion_matrix.ax_.set_title(name + ':')\n\nfinal = pd.concat(dfs, ignore_index=True)\nfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Collect metrics\n\nNext up I'm going to collect metrics by using the bootstrap method.\nThe bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.","metadata":{}},{"cell_type":"code","source":"bootstraps = []\nfor model in list(set(final.model.values)):\n    model_df = final.loc[final.model == model]\n    bootstrap = model_df.sample(n=30, replace=True)\n    bootstraps.append(bootstrap)\n        \nbootstrap_df = pd.concat(bootstraps, ignore_index=True)\nresults_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\ntime_metrics = ['fit_time','score_time'] # fit time metrics\n## PERFORMANCE METRICS\nresults_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\nresults_long_nofit = results_long_nofit.sort_values(by='values')\n## TIME METRICS\nresults_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\nresults_long_fit = results_long_fit.sort_values(by='values')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nsns.set(font_scale=2.5)\ng = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title('Comparison of Model by Classification Metric')\nplt.savefig('./benchmark_models_performance.png',dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nsns.set(font_scale=2.5)\ng = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_fit, palette=\"Set3\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title('Comparison of Model by Fit and Score Time')\nplt.savefig('./benchmark_models_time.png',dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = list(set(results_long_nofit.metrics.values))\nbootstrap_df.groupby(['model'])[metrics].agg([np.std, np.mean])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_metrics = list(set(results_long_fit.metrics.values))\nbootstrap_df.groupby(['model'])[time_metrics].agg([np.std, np.mean])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n\nBased on the experiment above, the Random Forest Classifier provides the best results.","metadata":{}}]}