{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Topics to be covered in this notebook\n• Which one is the best-selling book? <br>\n• Visualize order status frequency<br>\n• Find a correlation between date and time with order status<br>\n• Find a correlation between city and order status<br>\n• Find any hidden patterns that are counter-intuitive for a layman<br>\n• Can we predict number of orders, or book names in advance?<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import these libraries","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We have to follow these steps for this task\n* Load the data set\n* Understanding the data\n* Clean the data and removed null values \n* Split data order that contains multiple order in one order on the basis of /"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load the dataset we will use this dataset(GP Orders - 4.csv) as it contains correct values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf2 = pd.read_csv(\"../input/gufhtugu-publications-dataset-challenge/GP Orders - 5.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Understanding the data\ndf2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see first five values of our data\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lats five values of our data\ndf2.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#see the column name and if necessary change the name of columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#change the name of columns for our ease","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.columns = ['order_num', 'order_status', 'book_name', 'order_date', 'city', 'payment_method', 'items', 'weight']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we check the unique values in our dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can check for the unique values sepratly ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['order_status'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Info about our data, int64 = represent integer values, object = represent the string value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation & tasks so far**\nWe see our data contains 19187 rows/observation and 5 columns/variables <br>\nWe rename our columns and gives user friendly name <br>\nWe check the unique values from every column togather and seprately as well <br>\nWe also check the info of our data types"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Cleaning","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check the missing values in the data set. If you want to sort the data you cab use this sort_values(ascending = False)  otherwise you can use simple function df2.isnull().sum()"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We see that book_name has 2 missing values and City has 1, Now we locate where exactly these values are in our dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[df2['book_name'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[df2['city'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we drop these values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we see details of order_staus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.order_status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 1: Which one is the best-selling book?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here we split our orders on the basis of \"/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import chain\n\n# return list from series of comma-separated strings\ndef chainer(s):\n    return list(chain.from_iterable(s.str.split('/')))\n\n# calculate lengths of splits\nlens = df2['book_name'].str.split('/').map(len)\n\n# create new dataframe, repeating or chaining as appropriate\ndf2 = pd.DataFrame({'order_num': np.repeat(df2['order_num'], lens),\n                    'order_status': np.repeat(df2['order_status'], lens),\n                    'book_name': chainer(df2['book_name']),\n                    'order_date': np.repeat(df2['order_date'], lens),\n                    'city': np.repeat(df2['city'], lens)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now see our total rows increase from 19187 to 33091","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pyplot import figure\nfigure(num=None, figsize=(10, 10))\ndf2[df2[\"order_status\"]==\"Completed\"][\"book_name\"].value_counts()[:10].sort_values().plot.barh()\nplt.title(\"Top 10 purchased books\")\nplt.xlabel(\"Number of orders\")\nplt.ylabel(\"Name of books \")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 2: Visualize order status frequency"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using bar plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data = df2, x = 'order_status')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we see upper charts did not show the canceled order properly so see it with pie plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pal=['#349d6e','#faff00',\"#ff0000\"]\nsns.set_palette(pal)\nplt.figure(figsize=(10,10))\nplt.pie(df2['order_status'].value_counts())\nplt.legend(df2['order_status'].unique(),bbox_to_anchor=(0.00, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 3: correlation between date and time with order status"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['date'] = pd.to_datetime(df2['order_date']).dt.date\ndf2['time'] = pd.to_datetime(df2['order_date']).dt.time\n#other way to do this is bellow\n#data['Date'] = data.Order_Date.apply(lambda x: str(x).split(' ')[0])\n#data['Time'] = data.Order_Date.apply(lambda x: str(x).split(' ')[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Next steps <br>\n**-Find a correlation between date and time with order status<br>\n-Find a correlation between city and order status<br>\n-Find any hidden patterns that are counter-intuitive for a layman <br>\n-Can we predict number of orders, or book names in advance? <br>**"},{"metadata":{},"cell_type":"markdown","source":"# Please Upvote if you find the notebook interesting.\n# Follow me & let's rock together \n# Thank you."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}