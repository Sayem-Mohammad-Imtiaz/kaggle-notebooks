{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import Normalizer\nfrom tensorflow.keras import utils\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n#import tensorflow_federated as tff\nfrom tensorflow import keras\nfrom sklearn import preprocessing\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.backend import set_floatx\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing import timeseries_dataset_from_array\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, LSTM, Dropout, Dense, Bidirectional\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\nfrom keras import optimizers\n#!pip install --upgrade nest_asyncio\n#!pip install --upgrade tensorflow_federated\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"str_time = '10:15:41.0000001'\n\nsplit = str_time.split(':')\nnew_value = float(split[0]) * 60 * 60\nnew_value += float(split[1]) * 60\nnew_value += float(split[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('../input/smartilizer-dataset/Terra-D1-multi-labeled-interpolated.csv')\nprint('Before: ', df1['label'].size)\ndf1 = df1[np.all((df1.label.apply(float.is_integer), df1.label != 0), axis=0)]\nprint('After: ', df1['label'].size)\n\ndf2 = pd.read_csv('../input/commercial-vehicles-sensor-data-set/Terra-D2-multi-labeled-interpolated.csv')\nprint('Before: ', df2['label'].size)\ndf2 = df2[np.all((df2.label.apply(float.is_integer), df2.label != 0), axis=0)]\nprint('After: ', df2['label'].size)\n\n\n\nprint('Summary: ', df1['label'].size + df2['label'].size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df1[:300000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = df2.drop(['time'], axis = 1)\ndf2['label'] = df2['label'].astype(int) - 1\ndf2.to_csv('smartilizer-data.csv', sep = ',', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2[:865000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df1.drop(['time'], axis = 1)\ndf2 = df2.drop(['time'], axis = 1)\n\ndf1['label'] = df1['label'].astype(int) - 1\ndf2['label'] = df2['label'].astype(int) - 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset1_1 = df2[:570000]\nsubset1_2 = df2[570000:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset1_1_train = subset1_1[:int(subset1_1.shape[0] * 0.8)]\nsubset1_1_test = subset1_1[int(subset1_1.shape[0] * 0.8):]\n\n\nsubset1_2_train = subset1_2[:int(subset1_2.shape[0] * 0.8)]\nsubset1_2_test = subset1_2[int(subset1_2.shape[0] * 0.8):]\n\nset2_train = df1[:int(df1.shape[0] * 0.8)]\nset2_test = df1[int(df1.shape[0] * 0.8):]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set2_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_test = pd.concat([subset1_1_test,subset1_2_test,set2_test], axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\nt = subset1_1_train['time']\nl = subset1_1_train['label']\n\nt1 = subset1_1_test['time']\nl1 = subset1_1_test['label']\n\n\n\nt2 = subset1_2_train['time']\nl2 = subset1_2_train['label']\n\nt3 = subset1_2_test['time']\nl3 = subset1_2_test['label']\n\n\nt4 = set2_train['time']\nl4 = set2_train['label']\n\nt5 = set2_test['time']\nl5 = set2_test['label']\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t5 = df1['time']\nl5 = df1['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(23, 5))\nplt.title(\"Изменение состояний\") \nplt.xlabel(\"Время\") \nplt.ylabel(\"Состояние\") \nplt.xlim(0, 17200)\nplt.grid()      \n\nplt.plot(t1, l1, 'r')\nplt.plot(t2, l2, 'b')\nplt.plot(t3, l3, 'r')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(23, 5))\nplt.title(\"Изменение состояний\") \nplt.xlabel(\"Время\") \nplt.ylabel(\"Состояние\") \nplt.xlim(0, 6500)\nplt.grid()      \nplt.plot(t4, l4, 'b')\nplt.plot(t5, l5, 'r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset1_1_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#subset1_1_train.to_csv('subset1_1_train_6k.csv',sep = ',', index=True)\n#subset1_1_test.to_csv('subset1_1_test_6k.csv',sep = ',', index=True)\n\n#subset1_2_train.to_csv('subset1_2_train_6k.csv',sep = ',', index=True)\n#subset1_2_test.to_csv('subset1_2_test_6k.csv',sep = ',', index=True)\n\nset2_train.to_csv('set2_train_3k.csv',sep = ',', index=True)\nset2_test.to_csv('set2_test_3k.csv',sep = ',', index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset1_1_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"big_data_train = df2[:int(df2.shape[0] * 0.8)]\nbig_data_test =  df2[int(df2.shape[0] * 0.8):]\nsmall_data_train = df1[:int(df1.shape[0] * 0.8)]\nsmall_data_test =  df1[int(df1.shape[0] * 0.8):]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['time'].max() * 0.8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e = big_data_test['label'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"small_data_test.shape[0] + big_data_test.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"big_data_test.to_csv('sw_1_big_test.csv',sep = ',', index=False)\nbig_data_train.to_csv('sw_1_big_train.csv',sep = ',', index=False)\n\nsmall_data_test.to_csv('sw_2_small_test.csv',sep = ',', index=False)\nsmall_data_train.to_csv('sw_2_small_train.csv',sep = ',', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = '5.0'\nint(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classes\n\n**1 -  idle;** the vehicle is not busy with the engine on.\n\n**2 - driving;** the dumper is moving forward or backwards\n(both hauling and driving empty).\n\n**3 -  loading;** the dumper is being loaded with mass, generally\nidle with the engine on. The time between each bucket is\nusually around 25 seconds. Such in-between time is also\nlabeled as loading, i.e. not as idle.\n\n**4 - dumping;** the vehicle is loosing its mass from the bed.\nThis activity starts when the dumper begins tilting its bed\nand ends when the bed is back at its initial position.\n\n**5 - engine-off;** the dumper is inactive with the engine off.","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\"\"\"\nt = df1['time']\nl = df1['label']\nx = df1['wx']\ny = df1['wy']\nz = df1['wz']\n\nt2 = df2['time']\nl2 = df2['label']\nx2 = df2['wx']\ny2 = df2['wy']\nz2 = df2['wz']\n\"\"\"\n\nt = df1['time']\nl = df1['label']\nx = df1['gFx']\ny = df1['gFy']\nz = df1['gFz']\n\n\n\nt2 = df2['time']\nl2 = df2['label']\nx2 = df2['gFx']\ny2 = df2['gFy']\nz2 = df2['gFz']\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"4500 * 0.8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(23, 5))\nplt.title(\"Изменение состояний\") \nplt.xlabel(\"Время\") \nplt.ylabel(\"Состояние\") \nplt.xlim(0, 4000)\nplt.grid()      \nplt.plot(t, x)\nplt.plot(t, y)\nplt.plot(t, z)\nplt.plot(t, l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(23, 5))\nplt.title(\"Изменение состояний\") \nplt.xlabel(\"Время\") \nplt.ylabel(\"Состояние\") \nplt.xlim(0, 17000)\nplt.grid()      \nplt.plot(t2, x2)\nplt.plot(t2, y2)\nplt.plot(t2, z2)\nplt.plot(t2, l2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.concat([df1,df2],axis=0)\ndataset = dataset.drop(['time'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = dataset.label.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped.astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in grouped:\n    name = \"label%d\" % i\n    print(type(name))\n    globals()[name] = dataset[dataset['label'] == i]    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_name(df):\n    name =[x for x in globals() if globals()[x] is df][0]\n    return name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [label1,label2, label3, label4, label5]\n\nfor example in labels:\n    percent = example.shape[0] /  2053015\n    print(get_df_name(example), 'ratio is ', percent)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_ratio(labels):\n    grouped = labels.label.unique()\n    grouped = grouped.astype(int)\n    grouped.sort()\n    for example in grouped:\n        tmp = labels.loc[labels['label'] == example]\n        ratio = tmp.shape[0] / labels.shape[0]\n        print('Label ', example,' ratio is', ratio )\n    print(labels.shape[0])\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def divide_data(df, ratio1 = 0.2, ratio2 = 0.3):\n    \n    Y = df['label']\n    Y = Y.to_frame()\n    X = df.drop(['label'], axis = 1)\n    \n    shape = X.shape[0]\n    \n    train_X1, x, train_Y1, y = train_test_split(X, Y, test_size=(1-ratio1), random_state=1)\n    train_X2, x, train_Y2, y = train_test_split(x,y, test_size = 1 - (train_X1.shape[0] / x.shape[0]))\n    \n    train_X3, x, train_Y3, y = train_test_split(x,y, test_size = (1-ratio2), random_state=1)\n    train_X4, test_x, train_Y4, test_y = train_test_split(x,y, test_size = 1 - (train_X3.shape[0] / x.shape[0]))\n\n    \n    print('train_1 is ', train_X1.shape[0] / shape * 100, '% of all data')\n    print('train_2 is ', train_X2.shape[0] / shape * 100, '% of all data')\n    print('train_3 is ', train_X3.shape[0] / shape * 100, '% of all data')\n    print('train_4 is ', train_X4.shape[0] / shape * 100, '% of all data')\n    print('test is ', test_x.shape[0] / shape * 100, '% of all data')\n    \n    \n    return train_X1, train_Y1, train_X2,train_Y2,  train_X3,train_Y3, train_X4,train_Y4, test_x, test_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_labels(arr):\n    print('***************')\n    print('Check ratio for', get_name(arr))\n    check_ratio(arr)\n    print('***************')\n    arr = arr['label'] - 1\n    arr = utils.to_categorical(arr, 5)\n    return arr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X1, train_Y1, train_X2,train_Y2,  train_X3,train_Y3, train_X4,train_Y4, test_x, test_y = divide_data(dataset, ratio1=0.1)\n\ntrain_Y1 = process_labels(train_Y1)\ntrain_Y2 = process_labels(train_Y2)\ntrain_Y3 = process_labels(train_Y3)\ntrain_Y4 = process_labels(train_Y4)\ntest_y = process_labels(test_y)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = np.array(train_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_X0 = subset1_1_train.drop(['label'], axis = 1)\ntrain_Y0 = subset1_1_train['label']\ntrain_Y0 = utils.to_categorical(train_Y0, 5)\n\ntest_X0 = subset1_1_test.drop(['label'], axis = 1)\ntest_Y0 = subset1_1_test['label']\ntest_Y0 = utils.to_categorical(test_Y0, 5)\n\n\n\ntrain_X1 = subset1_2_train.drop(['label'], axis = 1)\ntrain_Y1 = subset1_2_train['label']\ntrain_Y1 = utils.to_categorical(train_Y1, 5)\n\ntest_X1 = subset1_2_test.drop(['label'], axis = 1)\ntest_Y1 = subset1_2_test['label']\ntest_Y1 = utils.to_categorical(test_Y1, 5)\n\n\n\ntrain_X2 = set2_train.drop(['label'], axis = 1)\ntrain_Y2 = set2_train['label']\ntrain_Y2 = utils.to_categorical(train_Y2, 5)\n\ntest_X2 = set2_test.drop(['label'], axis = 1)\ntest_Y2 = set2_test['label']\ntest_Y2 = utils.to_categorical(test_Y2, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.append(a, train_X1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = get_name(train_X1)[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_v = 'Dense'\ndef create_model(train_X, train_Y):\n  model = tf.keras.Sequential([\n      Dense(train_X.shape[1], input_shape=(train_X.shape[1],)),\n      BatchNormalization(),\n      Dense(256, activation='relu'),\n      Dropout(.2),\n      BatchNormalization(),\n      Dense(64, activation='relu'),\n      Dropout(.2),\n      Dense(train_Y.shape[1], activation='softmax')\n  ])\n  print(train_X.shape[1], train_Y.shape[1])\n  return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    exec('x = train_Y%s' % i)\n    print(x.shape)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    exec('train_X = train_X%s' % i)\n    exec('test_X = test_X%s' % i)\n    \n    exec('train_Y = train_Y%s' % i)\n    exec('test_Y = test_Y%s' % i)\n    \n    print('Training on set # ', i+1)\n    \n    print('Train data shape: ', train_X.shape)\n    print('Test data shape: ', test_X.shape)\n    \n\n\n    model_1 = create_model(train_X, train_Y)\n    opt = optimizers.SGD(learning_rate=0.01)\n    _opt = optimizers.Adam(learning_rate=0.01)\n\n    model_1.compile(optimizer=_opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n\n    print('Fitting model...')\n    #norm = Normalizer()\n    #train_X1 = norm.fit_transform(train_X1)\n    history = model_1.fit(train_X,train_Y, epochs=20, batch_size=32)\n\n\n    score, acc = model_1.evaluate(test_X, test_Y, batch_size = 32)\n    print('Loss: ', score, 'Acc: ', acc)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel_test = create_model(train_X2, train_Y2)\nopt = optimizers.SGD(learning_rate=0.01)\n_opt = optimizers.Adam(learning_rate=0.01)\n\nmodel_test.compile(optimizer=_opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nprint('Fitting model...')\n#norm = Normalizer()\n#train_X1 = norm.fit_transform(train_X1)\nhistory = model_test.fit(train_X2,train_Y2, epochs=20, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nscore, acc = model_test.evaluate(test_X2, test_Y2, batch_size = 32)\nprint('Loss: ', score, 'Acc: ', acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2 = create_model(train_X, train_Y)\nopt = optimizers.SGD(learning_rate=0.01)\n_opt = optimizers.Adam(learning_rate=0.01)\n\nmodel_2.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nprint('Fitting model...')\n#norm = Normalizer()\n#train_X1 = norm.fit_transform(train_X1)\nhistory = model_2.fit(train_X0,train_Y0, epochs=20, batch_size=32)\n\n\nscore, acc = model_2.evaluate(test_X1, test_Y1, batch_size = 32)\nprint('Loss: ', score, 'Acc: ', acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, acc = model_2.evaluate(test_X0, test_Y0, batch_size = 32)\nprint('Loss: ', score, 'Acc: ', acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'],\n        label = 'train')\nplt.plot(history.history['val_accuracy'],\n        label = 'validation')\nplt.xlabel('Epoch')\nplt.ylabel('% success')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x = norm.fit_transform(test_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, acc = model_1.evaluate(test_X, test_Y, batch_size = 32)\nprint('Loss: ', score, 'Acc: ', acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_Y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nt = set2_test['time']\nx = set2_test['label']\nplt.figure(figsize=(23, 5))\nplt.title(\"Изменение состояний\") \nplt.xlabel(\"Время\") \nplt.ylabel(\"Состояние\") \nplt.xlim(3000, 4000)\nplt.grid()      \n#plt.plot(t, x, 'ro')\nplt.plot(t, x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model_1.predict(test_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.array([])\ny = np.array([])\nfor i in range(test_Y.shape[0]):\n    x = np.append(x, np.argmax(test_Y[i]))\n    y = np.append(y, np.argmax(pred[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\n\nprint(confusion_matrix(x, y))\n\nprint('Classification Report')\ntarget_names = ['1', '2', '3','4','5']\nprint(classification_report(x, y, target_names=target_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Defining and fitting a DecisionTreeClassifier instance\ntree = DecisionTreeClassifier(max_depth = 19)\ntree.fit(train_X, train_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import export_graphviz\n\n# Creates dot file named tree.dot\nexport_graphviz(\n            tree,\n            out_file =  \"myTreeName.dot\",\n            feature_names = list(train_X.columns),\n            filled = True,\n            rounded = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = tree.predict(test_X)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_Y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.array([])\ny = np.array([])\nfor i in range(test_Y.shape[0]):\n    x = np.append(x, np.argmax(test_Y[i]))\n    y = np.append(y, np.argmax(pred[i]))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = np.array(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nt = subset1_2_test['time']\nplt.figure(figsize=(23, 5))\nplt.title(\"Изменение состояний\") \nplt.xlabel(\"Время\") \nplt.ylabel(\"Состояние\") \nplt.xlim(14000, 17000)\nplt.grid()      \n#plt.plot(t, x, 'ro')\nplt.plot(t,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(23, 5))\nplt.title(\"Изменение состояний\") \nplt.xlabel(\"Время\") \nplt.ylabel(\"Состояние\") \nplt.xlim(0, 17000)\nplt.grid()      \nplt.plot(t2, x2)\nplt.plot(t2, y2)\nplt.plot(t2, z2)\nplt.plot(t2, l2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[1000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.save('model1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.11001388674587255 * 77772 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2 = keras.models.load_model('model1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X3 = norm.fit_transform(train_X3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = model_2.fit(train_X3, train_Y3, epochs=20, validation_split = 0.1,batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history2.history['accuracy'],\n        label = 'train')\nplt.plot(history2.history['val_accuracy'],\n        label = 'validation')\nplt.xlabel('Epoch')\nplt.ylabel('% success')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, acc = model_2.evaluate(test_x, test_y, batch_size = 32)\nprint('Loss: ', score, 'Acc: ', acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data  =  df2.drop(['time'], axis = 1)\ndf2[:1050000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 1050000\n\ntrain_data = data[:number]\ntest_data = data[number:]\n\ntrain_data = train_data.sample(number)\n\ntest_Y = test_data['label']\ntest_Y = test_Y.to_frame()\ntest_X = test_data.drop(['label'], axis = 1)\n\ntrain_Y = train_data['label']\ntrain_Y = train_Y.to_frame()\ntrain_X = train_data.drop(['label'], axis = 1)\n\ntest_Y = process_labels(test_Y)\ntrain_Y = process_labels(train_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(train_X, train_Y)\nopt = optimizers.SGD(learning_rate=0.01)\n\nmodel.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_X, train_Y, epochs=10, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, acc = model.evaluate(test_X, test_Y, batch_size = 32)\nprint('Loss: ', score, 'Acc: ', acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **lstm network**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import timeseries_dataset_from_array\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom scipy import stats\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_points = 600\nBATCH_SIZE = 32\n\n#Sweden\narg_num = 8\nclass_num = 5\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('../input/smartilizer-dataset/Terra-D1-multi-labeled-interpolated.csv')\nprint('Before: ', df1['label'].size)\ndf1 = df1[np.all((df1.label.apply(float.is_integer), df1.label != 0), axis=0)]\nprint('After: ', df1['label'].size)\n\ndf2 = pd.read_csv('../input/commercial-vehicles-sensor-data-set/Terra-D2-multi-labeled-interpolated.csv')\nprint('Before: ', df2['label'].size)\ndf2 = df2[np.all((df2.label.apply(float.is_integer), df2.label != 0), axis=0)]\nprint('After: ', df2['label'].size)\n\n\n\nprint('Summary: ', df1['label'].size + df2['label'].size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['label'] = df2['label'].astype(int) - 1\nsubset1_1 = df2[:570000]\nsubset1_2 = df2[570000:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsubset1_2_train = subset1_2[:int(subset1_2.shape[0]*0.8)]\nsubset1_2_test = subset1_2[int(subset1_2.shape[0]*0.8):]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subset1_2_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef create_dataset(X, y, time_steps=1, step=1):\n    Xs, ys = [], []\n    for i in range(0, len(X) - time_steps, step):\n        v = X.iloc[i:(i + time_steps)].values\n        labels = y.iloc[i: i + time_steps]\n        Xs.append(v)\n        ys.append(stats.mode(labels)[0][0])\n    return np.array(Xs), np.array(ys).reshape(-1, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TIME_STEPS = 300\nSTEP = 100\n\ntrain_X, train_Y = create_dataset(\n    subset1_2_train[['gFx', 'gFy', 'gFz','wx', 'wy', 'wz', 'speed']],\n    subset1_2_train.label,\n    TIME_STEPS,\n    STEP\n)\n\ntest_X, test_Y = create_dataset(\n    subset1_2_test[['gFx', 'gFy', 'gFz','wx', 'wy', 'wz', 'speed']],\n    subset1_2_test.label,\n    TIME_STEPS,\n    STEP\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\nenc = enc.fit(train_Y)\n\ntrain_Y = enc.transform(train_Y)\ntest_Y = enc.transform(test_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_Y.max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc.categories_[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = optimizers.SGD(learning_rate=0.01)\n\nmodel_v = '0.1' #CONST\ndef create_model():\n  model = Sequential([\n    Bidirectional(\n    LSTM(128, activation='tanh',input_shape=[train_X.shape[1], train_X.shape[2]], dropout=0.5)),\n    Dense(128, activation='relu'),\n    Dense(train_Y.shape[1], activation='softmax')\n  ])\n\n  model.compile(\n    loss='categorical_crossentropy',\n    optimizer=opt,\n    metrics=['acc'],\n  )\n  return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test = create_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_test.fit(\n    train_X, train_Y,\n    epochs=20,\n    batch_size=32,\n    shuffle=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_test.evaluate(test_X, test_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.array([[[-34.1320000e-01, -2.0000000e-04,  9.5040000e-01, -6.2600000e-02,\n       -2.1800000e-02,  1.5560000e-01,  25.9824322e-01]]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_test.predict(test_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ndef plot_cm(y_true, y_pred, class_names):\n  cm = confusion_matrix(y_true, y_pred)\n  fig, ax = plt.subplots(figsize=(18, 16)) \n  ax = sns.heatmap(\n      cm, \n      annot=True, \n      fmt=\"d\", \n      cmap=sns.diverging_palette(220, 20, n=7),\n      ax=ax\n  )\n\n  plt.ylabel('Actual')\n  plt.xlabel('Predicted')\n  ax.set_xticklabels(class_names)\n  ax.set_yticklabels(class_names)\n  b, t = plt.ylim() # discover the values for bottom and top\n  b += 0.5 # Add 0.5 to the bottom\n  t -= 0.5 # Subtract 0.5 from the top\n  plt.ylim(b, t) # update the ylim(bottom, top) values\n  plt.show() # ta-da!","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc.categories_[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.array([0, 1, 2, 3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.array([])\nfor i in test_Y:\n    a = np.append(a,np.argmax(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_cm(\n  enc.inverse_transform(test_Y),\n  enc.inverse_transform(y_pred),\n  a\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}