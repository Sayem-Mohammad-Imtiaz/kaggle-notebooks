{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\nfrom tqdm import tqdm\nfrom skimage import io, transform\nfrom keras.utils import to_categorical\nimport time\nimport warnings\nimport shutil\n\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()\nfrom sklearn.model_selection import train_test_split\nseed = 333\nnp.random.seed(seed)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom tensorflow import lite\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport pandas as pd\nimport random, os\nimport shutil\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.metrics import categorical_accuracy, AUC\nfrom sklearn.model_selection import train_test_split\n\n\n!pip install tensorflow-addons==0.9.1\nimport tensorflow_addons\nfrom tensorflow_addons.metrics import F1Score, CohenKappa\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T20:02:55.701495Z","iopub.execute_input":"2021-06-06T20:02:55.701997Z","iopub.status.idle":"2021-06-06T20:03:26.621213Z","shell.execute_reply.started":"2021-06-06T20:02:55.701896Z","shell.execute_reply":"2021-06-06T20:03:26.61862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/retinoclasses/train (1).csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.623559Z","iopub.execute_input":"2021-06-06T20:03:26.623992Z","iopub.status.idle":"2021-06-06T20:03:26.65966Z","shell.execute_reply.started":"2021-06-06T20:03:26.623924Z","shell.execute_reply":"2021-06-06T20:03:26.658659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path to images\nimg_dir = \"../input/retino/\"\n\n#list all available images type\nprint(os.listdir(img_dir))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.68997Z","iopub.execute_input":"2021-06-06T20:03:26.690426Z","iopub.status.idle":"2021-06-06T20:03:26.707569Z","shell.execute_reply.started":"2021-06-06T20:03:26.690374Z","shell.execute_reply":"2021-06-06T20:03:26.706217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retinos = list(enumerate(os.listdir(img_dir)))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.709295Z","iopub.execute_input":"2021-06-06T20:03:26.709772Z","iopub.status.idle":"2021-06-06T20:03:26.715991Z","shell.execute_reply.started":"2021-06-06T20:03:26.709729Z","shell.execute_reply":"2021-06-06T20:03:26.714648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retinos","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.718032Z","iopub.execute_input":"2021-06-06T20:03:26.718688Z","iopub.status.idle":"2021-06-06T20:03:26.730878Z","shell.execute_reply.started":"2021-06-06T20:03:26.718638Z","shell.execute_reply":"2021-06-06T20:03:26.729635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nfor x in retinos:\n    data.append(x)\n\ndata","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.732858Z","iopub.execute_input":"2021-06-06T20:03:26.733828Z","iopub.status.idle":"2021-06-06T20:03:26.744063Z","shell.execute_reply.started":"2021-06-06T20:03:26.733781Z","shell.execute_reply":"2021-06-06T20:03:26.742477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path to images\nimg_dir = \"../input/retino/\"\n#list all available images type\nDATA_DIR = os.listdir(img_dir)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.746309Z","iopub.execute_input":"2021-06-06T20:03:26.748062Z","iopub.status.idle":"2021-06-06T20:03:26.756139Z","shell.execute_reply.started":"2021-06-06T20:03:26.748031Z","shell.execute_reply":"2021-06-06T20:03:26.75468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(img_dir):\n    X = []\n    y = []\n    labels = []\n    idx = 0\n    for i,folder_name in data:\n        if folder_name in DATA_DIR:\n            labels.append(folder_name)\n            for file_name in tqdm(os.listdir(f'{img_dir}/{folder_name}')):\n                if file_name.endswith('png'):\n                    im = io.imread(f'{img_dir}/{folder_name}/{file_name}')\n                    if im is not None:\n                        im = transform.resize(im, (100, 100))\n                        X.append(im)\n                        y.append(idx)\n\n        idx+=1\n    X = np.asarray(X)\n    y = np.asarray(y)\n    \n    diagnosis_dict_binary = {\n        0: 'No_DR',\n        1: 'DR',\n        2: 'DR',\n        3: 'DR',\n        4: 'DR'\n    }\n\n    diagnosis_dict = {\n        0: 'No_DR',\n        1: 'Mild',\n        2: 'Moderate',\n        3: 'Severe',\n        4: 'Proliferate_DR',\n    }\n\n\n    df['b_type'] =  df['diagnosis'].map(diagnosis_dict_binary.get)\n    df['type'] = df['diagnosis'].map(diagnosis_dict.get)    \n    print(X)\n    print(y)\n    labels = np.asarray(labels)\n    return X,y,labels","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.761043Z","iopub.execute_input":"2021-06-06T20:03:26.761753Z","iopub.status.idle":"2021-06-06T20:03:26.773832Z","shell.execute_reply.started":"2021-06-06T20:03:26.761687Z","shell.execute_reply":"2021-06-06T20:03:26.772159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X,y,labels = load_data(img_dir)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:03:26.776319Z","iopub.execute_input":"2021-06-06T20:03:26.777061Z","iopub.status.idle":"2021-06-06T20:04:50.567429Z","shell.execute_reply.started":"2021-06-06T20:03:26.777014Z","shell.execute_reply":"2021-06-06T20:04:50.566218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf=pd.read_csv('../input/select/csv_result-messidor_features.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:16:54.248173Z","iopub.execute_input":"2021-06-06T20:16:54.248588Z","iopub.status.idle":"2021-06-06T20:16:54.272013Z","shell.execute_reply.started":"2021-06-06T20:16:54.248558Z","shell.execute_reply":"2021-06-06T20:16:54.270757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:17:10.063234Z","iopub.execute_input":"2021-06-06T20:17:10.063647Z","iopub.status.idle":"2021-06-06T20:17:10.092033Z","shell.execute_reply.started":"2021-06-06T20:17:10.063618Z","shell.execute_reply":"2021-06-06T20:17:10.090282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, val = train_test_split(df, test_size = 0.15, stratify = df['type'])\ntrain, test = train_test_split(train_data, test_size = 0.15 / (1 - 0.15), stratify = train_data['type'])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:04:50.588635Z","iopub.execute_input":"2021-06-06T20:04:50.589298Z","iopub.status.idle":"2021-06-06T20:04:50.613279Z","shell.execute_reply.started":"2021-06-06T20:04:50.589251Z","shell.execute_reply":"2021-06-06T20:04:50.612275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_dir = ''\n\ntrain_dir = os.path.join(global_dir, 'train')\nval_dir = os.path.join(global_dir, 'val')\ntest_dir = os.path.join(global_dir, 'test')\n\ndef subdirw():\n    if os.path.exists(global_dir):\n        shutil.rmtree(global_dir)\n\n    if os.path.exists(train_dir):\n        shutil.rmtree(train_dir)\n    os.makedirs(train_dir)\n\n    if os.path.exists(val_dir):\n        shutil.rmtree(val_dir)\n    os.makedirs(val_dir)\n\n    if os.path.exists(test_dir):\n        shutil.rmtree(test_dir)\n    os.makedirs(test_dir)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:04:50.614761Z","iopub.execute_input":"2021-06-06T20:04:50.615198Z","iopub.status.idle":"2021-06-06T20:04:50.623617Z","shell.execute_reply.started":"2021-06-06T20:04:50.615155Z","shell.execute_reply":"2021-06-06T20:04:50.621889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subdirw()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:04:50.6256Z","iopub.execute_input":"2021-06-06T20:04:50.626357Z","iopub.status.idle":"2021-06-06T20:04:50.636301Z","shell.execute_reply.started":"2021-06-06T20:04:50.626263Z","shell.execute_reply":"2021-06-06T20:04:50.634751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_dir = '../input/retino/'\nfor index, row in train.iterrows():\n    diagnosis = row['type']\n    binary_diagnosis = row['b_type']\n    id_code = row['id_code'] + \".png\"\n    srcfile = os.path.join(main_dir, diagnosis, id_code)\n    dstfile = os.path.join(train_dir, binary_diagnosis)\n    os.makedirs(dstfile, exist_ok = True)\n    shutil.copy(srcfile, dstfile)\n\nfor index, row in val.iterrows():\n    diagnosis = row['type']\n    binary_diagnosis = row['b_type']\n    id_code = row['id_code'] + \".png\"\n    srcfile = os.path.join(main_dir, diagnosis, id_code)\n    dstfile = os.path.join(val_dir, binary_diagnosis)\n    os.makedirs(dstfile, exist_ok = True)\n    shutil.copy(srcfile, dstfile)\n\nfor index, row in test.iterrows():\n    diagnosis = row['type']\n    binary_diagnosis = row['b_type']\n    id_code = row['id_code'] + \".png\"\n    srcfile = os.path.join(main_dir, diagnosis, id_code)\n    dstfile = os.path.join(test_dir, binary_diagnosis)\n    os.makedirs(dstfile, exist_ok = True)\n    shutil.copy(srcfile, dstfile)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:04:50.638084Z","iopub.execute_input":"2021-06-06T20:04:50.638598Z","iopub.status.idle":"2021-06-06T20:04:54.676395Z","shell.execute_reply.started":"2021-06-06T20:04:50.638553Z","shell.execute_reply":"2021-06-06T20:04:54.675367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=42)\ntrain_img = X_train\ntrain_labels = y_train\ntest_img = X_test\ntest_labels = y_test\ntrain_img.shape, train_labels.shape, test_img.shape, test_labels.shape\nrand_14 = np.random.randint(0, train_img.shape[0],28)\nsample_img = train_img[rand_14]\nsample_labels = train_labels[rand_14]\nnum_rows, num_cols = 2, 14\nf, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),gridspec_kw={'wspace':0.03, 'hspace':0.01})\ntrain_path = 'train'\nval_path = 'val'\ntest_path = 'test'\n\ntrain_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224), shuffle = True)\nval_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224), shuffle = True)\ntest_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)\nfor r in range(num_rows):\n    for c in range(num_cols):\n        image_index = r * 7 + c\n        ax[r,c].axis(\"off\")\n        ax[r,c].imshow(sample_img[image_index])\n        ax[r,c].set_title('%s' % sample_labels[image_index])\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:04:54.677991Z","iopub.execute_input":"2021-06-06T20:04:54.678421Z","iopub.status.idle":"2021-06-06T20:04:56.859544Z","shell.execute_reply.started":"2021-06-06T20:04:54.678377Z","shell.execute_reply":"2021-06-06T20:04:56.858416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"class Metrics(Callback):\n    def __init__(self, xval, yval):\n        super().__init__()\n        self.xval = xval\n        self.yval = yval\n        \n    def on_train_begin(self, logs={}):\n        self.val_kappas = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val = self.xval\n        y_val = self.yval\n        \n        y_pred = self.model.predict(X_val)\n        y_pred = np.clip(y_pred,0,4)\n        y_pred = y_pred.astype(int)\n\n        _val_kappa = cohen_kappa_score(\n            y_val,\n            y_pred, \n            weights='quadratic'\n        )\n\n        self.val_kappas.append(_val_kappa)\n\n        print(f\"val_kappa: {_val_kappa:.4f}\")\n        \n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save('model.h5')\n\n        return\n    \nkappa_metrics = Metrics(X_val, y_val)","metadata":{}},{"cell_type":"code","source":"# a utility function that plots the losses and accuracies for training & validation sets across our epochs\ndef show_plots(history):\n    loss_vals = history['loss']\n    val_loss_vals = history['val_loss']\n    epochs = range(1, len(history['acc'])+1)\n    \n    f, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,4))\n    \n    # plot losses on ax[0]\n    ax[0].plot(epochs, loss_vals, color='navy',marker='o', linestyle=' ', label='Training Loss')\n    ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n    ax[0].set_title('Training & Validation Loss')\n    ax[0].set_xlabel('Epochs')\n    ax[0].set_ylabel('Loss')\n    ax[0].legend(loc='best')\n    ax[0].grid(True)\n    \n    # plot accuracies\n    acc_vals = history['acc']\n    val_acc_vals = history['val_acc']\n\n    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n    ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n    ax[1].set_title('Training & Validation Accuracy')\n    ax[1].set_xlabel('Epochs')\n    ax[1].set_ylabel('Accuracy')\n    ax[1].legend(loc='best')\n    ax[1].grid(True)\n    \n    plt.show()\n    plt.close()\n    \n    # delete locals from heap before exiting\n    del loss_vals, val_loss_vals, epochs, acc_vals, val_acc_vals","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:04:56.860964Z","iopub.execute_input":"2021-06-06T20:04:56.861404Z","iopub.status.idle":"2021-06-06T20:04:56.874264Z","shell.execute_reply.started":"2021-06-06T20:04:56.861342Z","shell.execute_reply":"2021-06-06T20:04:56.872941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ensembleCNN():\n    #create multiple cnn model for ensembling\n    model = Sequential()\n\n    model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (100, 100, 3)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(128, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, kernel_size = 3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n\n    model.add(Conv2D(256, kernel_size = 4, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    # use adam optimizer and categorical cross entropy cost\n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:04:56.876214Z","iopub.execute_input":"2021-06-06T20:04:56.877171Z","iopub.status.idle":"2021-06-06T20:04:56.895262Z","shell.execute_reply.started":"2021-06-06T20:04:56.877035Z","shell.execute_reply":"2021-06-06T20:04:56.893922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    layers.Conv2D(16, (3,3), padding=\"same\", input_shape=(224,224,3), activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(32, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n \n    layers.Conv2D(32, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(1,1)),\n    layers.BatchNormalization(),\n \n    layers.Conv2D(64, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(64, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(64, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(1,1)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(128, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(128, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n     layers.Conv2D(128, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(1,1)),\n    layers.BatchNormalization(),\n \n    \n    layers.Conv2D(256, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(256, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(1,1)),\n    layers.BatchNormalization(),\n    \n    layers.Flatten(),\n    layers.Dense(64, activation = 'relu'),\n    layers.Dropout(0.15),\n    layers.Dense(2, activation = 'softmax')\n    \n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-5),\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=['acc','AUC',tensorflow_addons.metrics.F1Score(num_classes=2, average='weighted'),tensorflow_addons.metrics.CohenKappa(num_classes=5)])\n\nhistory = model.fit(train_batches,\n                    epochs=15,\n                    validation_data=val_batches)\n                    \n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:05:42.688251Z","iopub.execute_input":"2021-06-06T20:05:42.688805Z","iopub.status.idle":"2021-06-06T20:09:10.756686Z","shell.execute_reply.started":"2021-06-06T20:05:42.688749Z","shell.execute_reply":"2021-06-06T20:09:10.755666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"my_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:05:32.810542Z","iopub.status.idle":"2021-06-06T20:05:32.813316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reconstructed_model = keras.models.load_model(\"my_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:05:32.818027Z","iopub.status.idle":"2021-06-06T20:05:32.81866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.plot(history.history['val_auc'])\nplt.plot(history.history['val_f1_score'])\n#plt.plot(history.history['TruePositive'])\nplt.ylabel('acc')\nplt.xlabel('epoch')\nplt.legend(['train', 'val_acc', 'val_f1_score', 'acc', 'val_cohen_kappa'])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:31:08.236212Z","iopub.execute_input":"2021-06-06T20:31:08.236651Z","iopub.status.idle":"2021-06-06T20:31:08.468595Z","shell.execute_reply.started":"2021-06-06T20:31:08.23662Z","shell.execute_reply":"2021-06-06T20:31:08.467127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model.load_weights(\"my_model.h5\")\ny_val_pred = model.predict(train_img)\n#clipping the value to range of 0-4, and round it to the nearest integer\ny_val_pred = np.clip(y_val_pred,0,4).astype(int)","metadata":{}},{"cell_type":"markdown","source":"labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\ncnf_matrix = confusion_matrix(df['diagnosis'].astype('int'), y_val_pred)\ndf_cm = pd.DataFrame(cnf_matrix, index=labels, columns=labels)\nplt.figure(figsize=(16, 7))\nsns.heatmap(df_cm, annot=True, cmap=\"Blues\")\nplt.show()","metadata":{}},{"cell_type":"markdown","source":"model.summary()","metadata":{}}]}