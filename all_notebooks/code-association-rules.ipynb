{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Association Rules\n\nThe goal of this notebook is to write an algorithm to calculate the association rules for a given set of frequent itemsets.\n\n> \"The quest to mine frequent patterns appears in many other domains. The prototypical application is market basket analysis, that is, to mine the sets of items that are frequently bought together at a supermarket by analyzing the customer shopping carts (the so-called “market baskets”). Once we mine the frequent sets, they allow us to extract association rules among the item sets, where we make some statement about how likely are two sets of items to co-occur or to conditionally occur.\" \n\n> ~ http://cs.ndsu.edu/~perrizo/saturday/Mohammad%20Zaki%20Data%20Mining.pdf\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nfrom mlxtend.frequent_patterns import apriori, fpgrowth\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom itertools import chain, permutations\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Itemsets and Tidsets\n\nLet $I = \\{x_1 , x_2 , . . . , x_m \\}$ be a set of elements called items. A set $X \\subseteq I$ is called an **itemset**. The set of items $I$ may denote, for example, the collection of all products sold at a supermarket, the set of all web pages at a website, and so on. An itemset of cardinality (or size) $k$ is called a $k$-itemset. Further, we denote by $I(k)$ the set of all $k$-itemsets, that is, subsets of $I$ with size $k$. \n\nLet $\\tau = \\{t_1,t_2,...,t_n\\}$ be another set of elements called transaction identifiers or tids. A set $T \\subseteq \\tau$ is called a **tidset**. We assume that itemsets and tidsets are kept sorted in lexicographic order.\n\nA **transaction** is a tuple of the form $⟨t,X⟩$, where $t \\in \\tau$ is a unique transaction identifier, and $X$ is an itemset. The set of transactions $\\tau$ may denote the set of all customers at a supermarket, the set of all the visitors to a website, and so on. For convenience, we refer to a transaction $⟨t,X⟩$ by its identifier $t$.\n\n> ~ http://cs.ndsu.edu/~perrizo/saturday/Mohammad%20Zaki%20Data%20Mining.pdf"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Create list of transaction data, i.e.\n#\n#                 \n# Transactions = [transaction-1-list, transaction-2-list, ... , transaction-n-list]\n# e.g.         = [[Eggs, Ham, Cheese], [Bread, Ham], ... , [Eggs, Bread, Milk, Butter]]\n#\n\n# Function to create the above\ndef transaction_data(data):\n    transactions = data['Transaction'].unique()\n    return [[y for y in data.loc[data['Transaction'] == x]['Item']] for x in transactions]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Database Representation\nA **binary database** $D$ is a binary relation on the set of tids and items, that is, $D \\subseteq \\tau × I$.\n\nWe say that tid $t \\in \\tau$ contains item $x \\in I$ $\\iff$ $(t,x) \\in D$.\n\nIn other words, $(t,x) \\in D$ $\\iff$ $x \\in X$ in the tuple $⟨t,X⟩$.\n\nWe say that tid $t$ contains itemset \n$X = \\{x_1,x_2,...,x_k\\}$ $\\iff$ ($t,x_i)$ $\\in$ $D$ $\\forall i = 1,2,...,k$.\n\n> ~ http://cs.ndsu.edu/~perrizo/saturday/Mohammad%20Zaki%20Data%20Mining.pdf"},{"metadata":{"trusted":true},"cell_type":"code","source":"# apriori & fpgrowth take a (pandas) binary transaction table, i.e.\n#\n#\n#               Item\n# Transaction   Eggs    Ham     Cheese\n#          t1   True    True    False\n#          t2   False   True    False\n#\n#\n\n# We can create this using the libraries built in TransactionEncoder function\ndef binary_transactions(data):\n    te = TransactionEncoder()\n    binary_data = te.fit(data).transform(data)\n    return pd.DataFrame(binary_data, columns=te.columns_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support\nThe support of an itemset $X$ in a dataset $D$, denoted $sup(X,D)$, is the number of transactions in $D$ that contain $X$:\n\n$$sup(X,D) = \\{t | ⟨t,i(t)⟩ \\in D \\mbox{ and } X \\subseteq i(t)\\} = |t(X)|$$\n\nwhere:\n* $i(t)$ is the set of items contained in tid $t \\in T$,\n* $t(x)$ is the set of tids that contain the single item $x \\in I$.\n\nIt is an estimate of the joint probability of the items comprising X."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate support:\ndef compute_support(item, itemset):\n    support = 0\n    for i in itemset:\n        if len(set(item) - set(i)) == 0:\n            support += 1\n    return support","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Frequent itemsets\n\nAn itemset $X$ is said to be **frequent** in $D$ if $sup(X,D) \\geq minsup$, where $minsup$ is a user defined **minimum support threshold**. \n\nWe use the set $F$ to denote the set of all **frequent itemsets**, and $F^{(k)}$ to denote the set of frequent $k$-itemsets\n\n> ~ http://cs.ndsu.edu/~perrizo/saturday/Mohammad%20Zaki%20Data%20Mining.pdf\n\n\n# Association Rule\n    \nAn **association rule** is an expression $X \\longrightarrow^{s,c} Y$, where $X$ and $Y$ are itemsets and they are disjoint, that is, $X$, $Y \\subseteq I$ , and $X \\cap Y$ $= \\emptyset$. Let the itemset $X \\cup Y$ be denoted as $XY$. \n\nThe **support** of the rule is the number of transactions in which both $X$ and $Y$ co-occur as subsets:\n\n$$s = sup(X \\longrightarrow Y) = |t(XY)| = sup(XY)$$\n\n# Confidence\n\nThe **confidence of a rule** is the conditional probability that a transaction contains $Y$ given that it contains $X$:\n\n$$c = conf(X \\longrightarrow Y) = P(Y|X) = \\frac{P(X \\cap Y)}{P(X)} = \\frac{sup(XY)}{sup(X)}$$\n\nA rule is frequent if the itemset $XY$ is frequent, that is, s$up(XY) \\geq minsup$ and a rule is strong if $conf \\geq minconf$, where $minconf$ is a user-specified **minimum confidence threshold**.\n\n> ~ http://cs.ndsu.edu/~perrizo/saturday/Mohammad%20Zaki%20Data%20Mining.pdf\n\n# Association Rules Algorithm:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-write itertools.combinations function to return list of list of strings not list of tuples of strings\ndef combinations(iterable, r):\n    pool = tuple(iterable)\n    n = len(pool)\n    for indices in permutations(range(n), r):\n        if sorted(indices) == list(indices):\n            yield [pool[i] for i in indices]\n\n\n# Definition to return antecedents of the frequent itemset (in order of decreasing string length)\ndef antecedents(freq_itemset):\n    s = list(freq_itemset)\n    return sorted(chain.from_iterable(combinations(s, r) for r in range(2, len(s))),\n                  key=lambda x: len(x), reverse=True)\n\n\n# Produce power set of itemset\ndef power_set(itemset, min_length=1, rev = False):\n    s = list(itemset)\n    return sorted(chain.from_iterable(combinations(s, r) for r in range(min_length, len(s)+1)),\n                  key=lambda x: len(x), reverse=rev)\n\n\n# Function to update antecedents by removing all subsets of an item:\ndef update_antecedents(ants, item):\n    powerset = power_set(item)\n    for i in powerset:\n        if i in ants:\n            ants = set(tuple(ant) for ant in ants).difference({tuple(i), })\n            ants = [list(x) for x in ants]\n    return ants\n\n\n# Function to return all viable association rules\ndef association_rules(freq_itemset, full_itemset, minconf):\n    result = []\n    antecs = antecedents(freq_itemset)\n    support = compute_support(freq_itemset, full_itemset)\n    for a in antecs:\n        overlap = list(set(freq_itemset).difference(a))\n        conf = support/compute_support(overlap, full_itemset)\n        if minconf != 0:\n            if conf >= minconf:\n                result.append([a, overlap, conf])\n            else:\n                antecs = update_antecedents(antecs, a)\n        else:\n            result.append([a, overlap, round(conf, 2)])\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read our data\ndata = pd.read_csv('/kaggle/input/the-bread-basket/bread basket.csv')\ntrans_data = transaction_data(data)\nbin_tran = binary_transactions(trans_data)\n\n# All items\nall_items = data['Item'].unique()\n\n# Minimum confidence\nmin_conf = 0.01","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apriori Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apriori\nprint(\"Apriori  with min_support = 0.1:\")\ntic1 = time.perf_counter()\na = apriori(bin_tran,min_support=min_conf,use_colnames=True)\ntoc1 = time.perf_counter()\nprint(a.sort_values(by='support',ascending=False))\nprint(f\"Apriori took {toc1 - tic1:0.4f} seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FPGrowth Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# FPGrowth\nprint(\"FPGrowth with min_support = 0.1:\")\ntic2 = time.perf_counter()\nfp = fpgrowth(bin_tran, min_support=min_conf, use_colnames=True)\ntoc2 = time.perf_counter()\nprint(fp.sort_values(by='support',ascending=False))\nprint(f\"FPGrowth took {toc2 - tic2:0.4f} seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Association Rules Algorithm\n\nLet's perform our association rules on the frequent itemset \\['Bread','Coffee','Tea','Cake'\\]:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's compute association rules using our algorithm.\nprint(\"Association rules in the form: [Antecedent, Target, Confidence] with min-confidence {n}:\".format(n=min_conf))\ntic3 = time.perf_counter()\nassoc = association_rules(['Bread','Coffee','Tea','Cake'], trans_data, min_conf)\ntoc3 = time.perf_counter()\nfor a in assoc:\n    print(a)\nprint(f\"Our association rules algorithm took {toc3 - tic3:0.4f} seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top Results\n\n|Antecedent|Target|Confidence|\n|---|---|---|\n|['Coffee', 'Tea']|['Cake', 'Bread']|0.0588|\n|['Bread', 'Coffee']|['Tea', 'Cake']|0.0578|\n|['Coffee', 'Cake']|['Tea', 'Bread']|0.0489|\n\n### Interpretation:\n\n$$P(\\mbox{Target} | \\mbox{Antecedent}) = \\mbox{Confidence}$$."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}