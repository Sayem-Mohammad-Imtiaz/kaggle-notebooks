{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Usual imports\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in data\ndf = pd.read_csv('../input/credit-card-customers/BankChurners.csv')\ndf.drop(df.columns[[21, 22]], axis = 1, inplace = True) # drop naives_bayes columns, as recommended in description\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using describe on the dataset we can see the average time on books is almost 3 years with a utilization ratio of 27%"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Less text on income bins\ndf['Income_Category'] = df['Income_Category'].replace('Less than $40K', '< 40K')\ndf['Income_Category'] = df['Income_Category'].replace('$40K - $60K', '40K - 60K')\ndf['Income_Category'] = df['Income_Category'].replace('$60K - $80K', '60K - 80K')\ndf['Income_Category'] = df['Income_Category'].replace('$80K - $120K', '80K - 120K')\ndf['Income_Category'] = df['Income_Category'].replace('$120K +', '>120K')\n\n# Setup target variable\ndf['churn'] = df['Attrition_Flag'].replace('Existing Customer',0).replace('Attrited Customer',1)\ndf.drop('Attrition_Flag',axis=1,inplace=True)\n\n# Check for Nulls\ndf.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"This data was pre-processed so a lot of the cleaning has already been done, but at this point you would do any cleaning (checking for nulls, data types, etc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import encoder to transform categorical data into numerical (for model)\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n# create a label encoder for columns with <2 unique values\nle = LabelEncoder()\n#count = 0\nfor col in df.columns[1:]:\n    if df[col].dtype == 'object':\n        if len(list(df[col].unique())) <= 2:\n            le.fit(df[col])\n            df[col] = le.transform(df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore numerical data\nEDA_df = df[['Customer_Age',\n             'Gender',\n             'Dependent_count',\n             'Months_on_book',\n             'Total_Revolving_Bal',\n             'Total_Amt_Chng_Q4_Q1',\n             'Avg_Utilization_Ratio',\n             'Contacts_Count_12_mon',\n            'Total_Relationship_Count']]\n\n    \nfig = plt.figure(figsize=(10, 10))\nplt.suptitle('Histograms of Numerical Columns\\n',\n             horizontalalignment=\"center\",\n             fontstyle = \"normal\",\n             fontsize = 24,\n             fontfamily = \"sans-serif\")\n\nfor i in range(EDA_df.shape[1]):\n    plt.subplot(3, 3, i + 1)\n    f = plt.gca()\n    f.set_title(EDA_df.columns.values[i])\n    vals = np.size(EDA_df.iloc[:, i].unique())\n    if vals >= 100:\n        vals = 100\n    plt.hist(EDA_df.iloc[:, i], \n         bins=vals,\n         color = '#AEC3B0')\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see a spike in ages at ~25, presumably you cannot get a credit card with this bank before then or perhaps they don't record lower than that. There is a second spike at ~50.\n\n* For Gender, there is a fairly even distribution.\n\n* Dependents are mostly 2/3 while the least are 0 or 5/greater than 5. \n\n* Months on book has a fairly even distribtion but a huge spike at ~36. Presumably there might be some common contract for 3 years\n\n* Total revolving balance appears to be commonly low with a lot of customers at 0, and at 2500 (maybe a limit?), otherwise and even distribution.\n\n* Total amount changed between quarter 4 and q 1 is commonly between 0.5 and 1, with some outliers going past that\n\n* Average Utilization Ratio is (apart from the 0 counts) right-skewed with a subtle spike around 0.05/0.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore categorical data\ncategories = ['Education_Level',\n              'Marital_Status',\n              'Income_Category',\n              'Card_Category']\n\nfig, ax = plt.subplots(4, figsize=(14, 7))\n\ni = 0\nfor cat in categories:\n    ax[i].hist(df[cat],color = '#AEC3B0')\n    ax[i].set_title(cat)\n    i += 1\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still not sure why the education graph has oddly spaced data, if you know I'd like to hear how to fix it!\n\n* Most credit card holders are Graduates\n* Divorcees are least likely to own a credit card\n* The most credit cards belong to people with an income under $40,000\n* I'd imagine that Blue is the standard credit card category, in which case it doesn't appear that other categories are being utilised correctly. Maybe due to high turn-over at the 3 year mark?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualise churn rate by categories\ncategories = ['Education_Level','Marital_Status','Income_Category','Card_Category']\n\nfor cat in categories:\n    temp_churn = df.groupby([cat,'churn']).size().unstack()\n    temp_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n    colors  = ['#598392','#AEC3B0']\n\n    ax = (temp_churn.T*100.0 / temp_churn.T.sum()).T.plot(\n        kind='bar',\n        figsize = (12,6),\n        width = 0.5,\n        stacked = True,\n        color = colors)\n\n    plt.ylabel('% of Customers')\n    plt.xlabel(cat)\n    plt.title(cat + ' Churn Rate')\n\n    plt.legend(loc='right', fontsize = \"medium\")\n    plt.xticks(rotation=0, horizontalalignment=\"center\")\n    plt.yticks(rotation=0, horizontalalignment=\"right\")\n    ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n    for p in ax.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        ax.text(x+width/2, \n                y+height/2, \n                '{:.1f}%'.format(height), \n                horizontalalignment='center', \n                verticalalignment='center')\n    ax.autoscale(enable=False, axis='both', tight=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The higher the customers education the more likely they are to churn\n* Married customers are less likely to churn\n* Those under 40K or over 120K have the highest chrun rate\n* Platinum card holders have a very high churn rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a bivariate correlation plot\nimport seaborn as sn\n\ncorr = df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(18, 15))\ncmap = sn.diverging_palette(220, 10, as_cmap=True)\nsn.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode the data\nID = df[\"CLIENTNUM\"] # Extract as we do not want to encode this unique identifier\ndf = df.drop(columns=\"CLIENTNUM\")\ndf = pd.get_dummies(df)\ndf = pd.concat([df, ID], axis = 1)\n\n# Split for training and test data\nresponse = df[\"churn\"]\ndf = df.drop(columns=\"churn\")\n\nfrom sklearn.model_selection import train_test_split\n# Split data into training and testing data (X), and training/testing labels (y) using a 20% test size, 80% train size\nX_train, X_test, y_train, y_test = train_test_split(df, response, stratify=response, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity = X_train['CLIENTNUM']\nX_train = X_train.drop(columns = ['CLIENTNUM'])\ntest_identity = X_test['CLIENTNUM']\nX_test = X_test.drop(columns = ['CLIENTNUM'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the data, better for skewed data as seen in the graphs above\nfrom sklearn.preprocessing import StandardScaler\n\nsc_X = StandardScaler()\nX_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\nX_train2.columns = X_train.columns.values\nX_train2.index = X_train.index.values\nX_train = X_train2\nX_test2 = pd.DataFrame(sc_X.transform(X_test))\nX_test2.columns = X_test.columns.values\nX_test2.index = X_test.index.values\nX_test = X_test2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import a variety of models with mostly basic parameters\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models and parameters to test\nmodels = []\nmodels.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0,class_weight='balanced')))\nmodels.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\nmodels.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\nmodels.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\nmodels.append(('Gaussian NB', GaussianNB()))\nmodels.append(('Decision Tree Classifier',DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\nmodels.append(('Random Forest', RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state = 0)))\n\n# Storing results of each model\nacc_results = []\nauc_results = []\nprecision = []\nrecall = []\nnames = []\ncol = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', 'Accuracy Mean', 'Accuracy STD','Recall','Precision']\nmodel_results = pd.DataFrame(columns=col)\n\n# Evaluate each model using k-fold cross-validation:\ni = 0\nfor name, model in models:\n    kfold = model_selection.KFold(\n        n_splits=10)\n    # accuracy scoring:\n    cv_acc_results = model_selection.cross_val_score(  \n    model, X_train, y_train, cv=kfold, scoring='accuracy')\n    # roc_auc scoring:\n    cv_auc_results = model_selection.cross_val_score(  \n    model, X_train, y_train, cv=kfold, scoring='roc_auc')\n    # Precision & Recall\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    precision.append(precision_score(y_test, pred))\n    recall.append(recall_score(y_test, pred))\n    # Storing Results\n    acc_results.append(cv_acc_results)\n    auc_results.append(cv_auc_results)\n    names.append(name)\n    model_results.loc[i] = [name,\n                        round(cv_auc_results.mean()*100, 2),\n                        round(cv_auc_results.std()*100, 2),\n                        round(cv_acc_results.mean()*100, 2),\n                        round(cv_acc_results.std()*100, 2),\n                        round(recall[i]*100, 2), # The one we want to focus on\n                        round(precision[i]*100, 2)]\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_results.sort_values(by=['Recall'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression(random_state = 0)\nclf.fit(X_train, y_train)\n\nfeature_importance = abs(clf.coef_[0])\nfeature_importance = 100.0 * (feature_importance / feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfeatfig = plt.figure(figsize=(15,5))\nfeatax = featfig.add_subplot(1, 1, 1)\nfeatax.barh(pos, feature_importance[sorted_idx], align='center')\nfeatax.set_yticks(pos)\nfeatax.set_yticklabels(np.array(X_train.columns)[sorted_idx], fontsize=8)\nfeatax.set_xlabel('Relative Feature Importance')\n\nplt.tight_layout()   \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = ['Total_Trans_Ct',\n        'Total_Trans_Amt',\n        'Total_Revolving_Bal',\n        'Total_Relationship_Count',\n        'Total_Ct_Chng_Q4_Q1',\n        'Contacts_Count_12_mon',\n        'Gender',\n        'Months_Inactive_12_mon']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train[test]\nX_test = X_test[test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0, class_weight='balanced')))\nmodels.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\nmodels.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\nmodels.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\nmodels.append(('Gaussian NB', GaussianNB()))\nmodels.append(('Decision Tree Classifier',DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\nmodels.append(('Random Forest', RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state = 0)))\n\nacc_results = []\nauc_results = []\nprecision = []\nrecall = []\nnames = []\ncol = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', 'Accuracy Mean', 'Accuracy STD','Recall','Precision']\nmodel_results2 = pd.DataFrame(columns=col)\ni = 0\n# Evaluate each model using k-fold cross-validation:\nfor name, model in models:\n    kfold = model_selection.KFold(\n        n_splits=10)\n    # accuracy scoring:\n    cv_acc_results = model_selection.cross_val_score(  \n    model, X_train, y_train, cv=kfold, scoring='accuracy')\n    # roc_auc scoring:\n    cv_auc_results = model_selection.cross_val_score(  \n    model, X_train, y_train, cv=kfold, scoring='roc_auc')\n    # Precision & Recall\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    precision.append(precision_score(y_test, pred))\n    recall.append(recall_score(y_test, pred))\n    # Storing Results\n    acc_results.append(cv_acc_results)\n    auc_results.append(cv_auc_results)\n    names.append(name)\n    model_results2.loc[i] = [name,\n                        round(cv_auc_results.mean()*100, 2),\n                        round(cv_auc_results.std()*100, 2),\n                        round(cv_acc_results.mean()*100, 2),\n                        round(cv_acc_results.std()*100, 2),\n                        round(recall[i]*100, 2),\n                        round(precision[i]*100, 2)]\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_results2.sort_values(by=['Recall'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results\nUsing the feature importance graph, I took a few of the best performing features (this could probably be extended) and scored the model using all features against the model with the highest performing features"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_results3.sort_values(by=['Recall'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}