{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor, Lambda, Normalize, Grayscale, Resize\n\nimport matplotlib.pyplot as plt\n\nimport os\nimport pandas as pd\nimport numpy as np\n\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transforms = torchvision.transforms.Compose([\n#     Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n    Grayscale(),\n    Resize((180, 180)),\n    ToTensor(),\n#     Lambda(lambda x: torch.squeeze(x, 0))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BanglaMNISTDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n        img_id = self.img_labels.iloc[idx, 1]\n        img = Image.open(os.path.join(self.img_dir, img_id)) \n        label = self.img_labels.iloc[idx, 2]\n        if self.transform:\n            img = self.transform(img)\n        return (img, label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bmnist = BanglaMNISTDataset(annotations_file='../input/banglamnist/labels.csv',\n                           img_dir='../input/banglamnist/bangla-mnist/labeled/',\n                           transform=transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dl = DataLoader(\n    bmnist,\n    batch_size=64,\n    shuffle=True,\n    num_workers=4\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_samples(data, targets):\n    data = data.numpy()\n    print(\"tensor shape: \" + str(data.shape))\n    \n    fig = plt.figure()\n    for i in range(9):\n        plt.subplot(3,3,i+1)\n        plt.tight_layout()\n\n        img = data[i]\n        img = np.moveaxis(img, 0, -1)\n        \n        plt.imshow(img, cmap='gray', interpolation='none')\n        plt.title(f\"{targets[i]}\")\n        \n        plt.xticks([])\n        plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = enumerate(dl)\n_, (sample_data, sample_targets) = next(dataiter)\n\nshow_samples(sample_data, sample_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}