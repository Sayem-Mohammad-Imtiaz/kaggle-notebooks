{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DIU - TD1 - Introduction au Machine Learning :"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('mon premier programme python')\nfor i in [0, 1, 2]:\n    print(\"valeur :\", i)\nprint(\"Fin\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(3):\n    print(\"valeur :\", i)\nprint(\"Fin\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# addition\na = 4 + 5\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#multiplication\n2*5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#puissance\n2**5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nx = np.arange(-6, 6, 0.3)\nx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Définir une fonction :  la fonction linéaire par exemple\n\nC'est une fonction simple de la forme: f(x) = ax ou f(x) = x. En gros, l'entrée passe à la sortie sans une très grande modification ou alors sans aucune modification. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt # pour afficher la figure\n\ndef linear(x):\n    a = []\n    for item in x:\n        a.append(item)\n    return a\n\ny = linear(x)\n\nplt.plot(x,y)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TP1 : Introduction à la fouille de données (Data mining)"},{"metadata":{},"cell_type":"markdown","source":"L’objectif ici est de montrer l’utilisation des méthodes de fouille de données pour les problèmes de classification et de régression en python. \n\nCe document reprend librement certains exemples montrés dans l’excellente documentation de Scikit-Learn."},{"metadata":{},"cell_type":"markdown","source":"### 1. La classification supervisée : \nC’est l’opération qui permet de placer chaque individu de la population dans une classe parmi l’ensemble des classes préétablies, en suivant un processus d’apprentissage supervisé. \nle choix de la classe d’un individu dépend de ses caractéristiques."},{"metadata":{},"cell_type":"markdown","source":"- Algorithme KPPV (K Nearest Neighbors)\n- Réseau de neurones\n- Arbre de décision\n- Forets aléatoires\n- Machine à vecteurs de support (SVM)\n- ..."},{"metadata":{},"cell_type":"markdown","source":"### Problématique:\n#### Données :\n- Une liste d’individus X {1..n} caractérisés par un ensemble d’attributs *P*. \n- Un ensemble C de classes préétablies.   \n- Les caractéristiques du nouvel individu «indiv».\n#### Question :\n-  Quelle est la classe appropriée à «indiv» ?\n"},{"metadata":{},"cell_type":"markdown","source":"### Jeu de données :\nLe jeu de données *Iris* , utilisé dans l''article de Fisher, publié en 1936, intitulé \"L'utilisation de plusieurs mesures dans des problèmes taxonomiques\", est également disponible dans le référentiel UCI Machine Learning.\n\nIl comprend trois espèces d’iris de 50 échantillons chacune, ainsi que des propriétés propres à chaque fleur. Une espèce de fleur est séparable linéairement des deux autres, mais les deux autres ne sont pas séparables linéairement l'une de l'autre.\n\nLes colonnes de cet ensemble de données sont:\n\n     Id\n     Longueur du Sépale Cm\n     Largeur du Sépale Cm\n     Longueur du Pétale cm\n     Largeur du Pétale Cm\n     Espèce : classe : Iris Setosa, Iris Versicolor ou Iris Virginica.\n\nUn échantillon : (4.9,3.6,1.4,0.1, “Iris-setosa”)"},{"metadata":{},"cell_type":"markdown","source":"### A. Importation des librairies\nAvec Pandas on peut manipuler lire (et/ou écrire) nos jeux de données, généralement avec une extension .csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importation des lib \n\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### B. Importation des données\nAvec la fonction *read_csv* de Pandas: on peut mettre dans notre dataframe le contenu du fichier csv, en indiquant comme paramètre (1: le chemin ou la source où se trouve le fichier csv, 2: les séparateurs entre les valeurs -dans notre cas ces des virgules- 3: un paramètre facultatif pour spécifier le type d'encodage de notre fichier exemple encoding =\"UTF8\")."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"../input/iriscsv/Iris.csv\")\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### QUESTION 1\nQuelle est la moyenne de la longueur des pétales de la setosa ?"},{"metadata":{},"cell_type":"markdown","source":"### Reponse 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Il y a plein de manière d'écrire cette commande\nrep = df[df[\"Species\"]=='Iris-setosa'].PetalLengthCm.mean()\n\n#df[df.Outcome==1].SkinThickness.mean()\n#df[df[\"Outcome\"]==1][\"SkinThickness\"].mean()\n\nrep","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## QUESTION 2\nQuelle est la longueur maximale des sépales de la sétosa ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"rep = df[df[\"Species\"]=='Iris-setosa'].SepalLengthCm.max()\n\nrep","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### C. Statistiques descriptives élémentaires\nLire les informations sur nos données (Types d'attributs, valeurs manquantes...).\nPandas nous permet de voir les informations sur notre benchmark exemple: avec dataframe.info() il nous affiche tous les attributs de notre fichier avec le type de donnée et le nombre de valeurs de chaque colonne\ndataframe.columns permet de citer les noms de toutes les colonnes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() #donner les infos de notre data frame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nOn peut supprimer la colonne ID :\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Id',axis=1,inplace=True) \n\n#dropping the Id column as it is unecessary, axis=1 specifies that it should be column wise, \n# inplace =1 means the changes should be reflected into the dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### D. préparation des données\nDans cette étape nous déterminons les attributs choisis pour l'entrainement et nous définissons l'attribut \"classe\" de notre benchmark"},{"metadata":{"trusted":true},"cell_type":"code","source":"# définir les attraibuts qui nous intéréssent \ndf_features = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm' ]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# définir l'attribut classe\ndf_labels = df[['Species']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Si on veut schématiser la distribution de nos classes, il suffit de faire appel à la libraire seaborn, en suite définir l'attribut concerné"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n# schématiser la distribution des classes\nsns.countplot(df['Species'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### E. Transformer la colonne des classes en labels numériques"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf[['Species']] = le.fit_transform(df[['Species']])\ndf_labels = df[['Species']]\n\ndf_labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F. Diviser le dataset en données d'entrainement et données de test\nCeci est réalisable avec *sklearn* qui permet de prendre aléatoirement des données de test à partir du benchmark et laisser le reste pour l'apprentissage.\nLa fonction *train_test_split(param1,param2,param3,param4)* prend 4 paramétres:\nle premier dédié à l'ensemble d'entrainement, le deuxième à l'ensemble de test, le troisième est le paramètre du % de l'ensemble de test (généralement entre 15 et 40%), et le 4 ème paramètre (facultatif) pour spécifier quel type de fonction random utiliser:\nsi vous utilisez random_state = some_number, vous pouvez garantir que la sortie de Run 1 sera égale à la sortie de Run 2, c'est-à-dire que votre split sera toujours le même. Peu importe ce que le nombre réel random_state est 42, 0, 21, ... L'important est que chaque fois que vous utilisez 42, vous obtiendrez toujours la même sortie la première fois que vous faites la division. Ceci est utile si vous voulez des résultats reproductibles, par exemple dans la documentation, afin que tout le monde puisse toujours voir les mêmes nombres lors de l'exécution des exemples.\n\nCette fonction retourne 4 sorties: \nLa 1ère est le sous-ensembles aléatoires d'entrainement \nLa 2éme est le vecteur de leurs labels (leurs classes).\nLa 3ème est le sous-ensemble aléatoire pour le test.\nLa 4ème est le vecteur de leurs labels (leurs classes).\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#decouper le data set en 30% pour test et 70% pour train\nX_train, X_test, y_train, y_test = train_test_split(df_features, df_labels, test_size=0.4, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".shape permet de savoir la dimension d'un ensemble."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('x_train shape:', X_train.shape) # .shape permet de voir la\nprint('x_test shape:', X_test.shape)\nprint('y_train shape:', y_train.shape)\nprint('y_test shape:', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Méthode des K plus proches Voisins ( K nearest neigbors)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.metrics import confusion_matrix,accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chargement d'un classifieur K-ppv\nmon_knn = KNeighborsClassifier(n_neighbors=2)\n\n# Apprentissage\nmon_knn.fit(X_train, y_train)#.values.ravel())\n\n# Orédiction\nypred = mon_knn.predict(X_test)\n\nprint ('KNN accuracy score')\n\nprint (accuracy_score(y_test, ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to plot confusion matrix\nimport matplotlib.pyplot as plt\nimport itertools\nimport numpy as np\n\ndef plot_confusion_matrix(cm, classes, normalize=False,  title=' confusion matrix ', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = mon_knn.predict(X_test)\n# Convert predictions classes to one hot vectors \n#Y_pred_classes = np.argmax(Y_pred , axis = 1) \n# Convert validation observations to one hot vectors\nY_true = y_test#np.argmax(y_test,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred)\n\n \n\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(3)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Méthode des machines a support de vecteurs (SVM)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVC est le Support vecteur machine classifieur\nfrom sklearn.svm import SVC \nclf = SVC()\nclf.fit(X_train, y_train)# values.ravel()\n\n#ypred\nypred = mon_knn.predict(X_test)\n\nprint ('SVM accuracy score')\n\nprint (accuracy_score(y_test, ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Méthode des Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(X_train, y_train)# values.ravel()\n\n#ypred\nypred = mon_knn.predict(X_test)\n\nprint ('Random Forest accuracy score')\n\nprint (accuracy_score(y_test, ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Méthode des arbres de décision"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn import tree\niris = load_iris()\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(iris.data, iris.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris.data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" tree.plot_tree(clf.fit(iris.data, iris.target)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree.export import export_text\niris = load_iris()\nX = iris['data']\ny = iris['target']\ndecision_tree = DecisionTreeClassifier(random_state=0, max_depth=3)\ndecision_tree = decision_tree.fit(X, y)\nr = export_text(decision_tree, feature_names=iris['feature_names'])\nprint(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict(iris.data[:1, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict_proba(iris.data[:1, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclf = tree.DecisionTreeClassifier(max_depth=1,min_samples_leaf=6)\nclf = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred = clf.predict(X_test)\n\nprint ('Tree accuracy score')\n\nprint (accuracy_score(y_test, ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_true, ypred)\n\n \n\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(3)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mtx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exercice 1 :\nEn se basant sur ce notebook :\n- Ajouter un code qui cherche les meilleurs paramètres pour chaque méthode. ( vous pouvez utiliser gridsearch)\n- Ajouter d'autre méthodes de classification à ce notebook ( exmple: Naive Bayes, SVM, Random Forest, ... etc)\n- Evaluer toutes vos méthodes par validation croisée (nbr de paquet = 5).\n- Afficher un tableau comparatif des méthodes utlisées avec les résultats obtenus."},{"metadata":{},"cell_type":"markdown","source":"### Exercice 2 : Challenge 1 : PRÉDICTION DE DIABÈTE  \n\nPour réaliser ce programme, vous pouvez utiliser en local sur vos machines l'environnement _Jupyter Notebook_ distribué par _anaconda_ https://www.anaconda.com/distribution/\n\nL’objectif fondamental est de prédire si oui ou non un patient est atteint du diabète à partir de certains attributs : âge, nombre de grossesses, taux d’insuline, etc.  \n\n_NB : la compétence à utiliser le langage Python n'est pas l'objectif de ce travail, même s'il va certainement vous permettre d'évoluer dans ce domaine. Nous vous conseillons la documentation officielle https://www.python.org/ et en particulier la description de sa syntaxe. Vous pouvez aisément connaître la version exécutée par votre plateforme grâce à la commande `print (sys.version)`_\n\n\nEn se basant sur ce notebook :\n- Refaire les memes étapes sur le dataset : prédiction du diabète (dont la description est ci-dessous)\n- Ajouter un code qui cherche les meilleurs paramètres pour chaque méthode. ( vous pouvez utiliser gridsearch)\n- Ajouter d'autre méthodes de classification à ce notebook ( exmple: Naive Bayes, SVM, Random Forest, ... etc)\n- Evaluer toutes vos méthodes par validation croisée (nbr de paquet = 5).\n- Afficher un tableau comparatif des méthodes utlisées avec les résultats obtenus.\n- Bonus : Celui qui obtient le meilleur taux d'accuracy en validation croisée gagne (+1 point).\n \n\n"},{"metadata":{},"cell_type":"markdown","source":"Cet ensemble de données provient d’une extraction fournie par un Institut du diabète. Vous pouvez le télécharger à partir [d'ici](https://drive.google.com/file/d/1lrROnXEB5b55IznkdDKKCK9rZgOCuETK/view). \nL'objectif de cet ensemble est de construire un outil permettant de réaliser un diagnostic positif ou négatif de la présence d'un diabète chez un patient. Plusieurs contraintes ont été placées sur la sélection de ces instances dans la base de données d'origine (bien plus volumineuse). En particulier, tous les patients ici sont des femmes âgées d'au moins 21 ans.\n\nLes ensembles de données comprennent plusieurs variables prédictives médicales et la variable cible « Outcome » dont la valeur 1 signifie que la patiente est diabétique et la valeur 0 qu'elle ne l'est pas.\nLes variables prédictives comprennent le nombre de grossesses que le patient a eues, son IMC, son taux d'insuline, son âge, etc.\n\nChaque ligne représente un patient et les colonnes sont :\n\n    - Grossesses : nombre de fois où la patiente a déjà été enceinte\n    - Glucose : concentration en glucose plasmatique 2 heures dans un test de tolérance au glucose par voie orale\n    - BloodPressure : pression artérielle diastolique (mm Hg)\n    - SkinThickness : épaisseur du pli cutané des triceps (mm)\n    - Insuline : insuline sérique de 2 heures (mu U / ml)\n    - IMC : indice de masse corporelle (poids en kg / (taille en m) ^ 2)\n    - DiabetesPedigreeFunction : Fonction pédigrée du diabète\n    - Age : age (ans)\n    - Outcome : Variable cible dont les états sont soit 1 (diabète), soit 0 (non diabète).\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":1}