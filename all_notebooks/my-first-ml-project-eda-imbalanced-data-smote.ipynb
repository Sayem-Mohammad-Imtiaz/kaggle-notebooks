{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is my very first project in machine learning using Python. \n\nThe purpose was to find the best model to predict stroke.\n\nI would like to thank the mentor who helped me with the oversampling method as well as the other authors who inspired me some lines of code 🙏","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\n\ndf = pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory analysis and data preparation","metadata":{}},{"cell_type":"code","source":"# First look at the dataset\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total number of rows and columns\n\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset consists of 10 metrics for a total of 5110 patients. We have demographic data (gender, age, marital status, type of work and residence) as well as health data including hypertension, heart disease, average glucose level, body mass index (BMI), smoking status and whether the patient has experienced a stroke.","metadata":{}},{"cell_type":"code","source":"# Data spread between people having experienced of a stroke or not\n\ndf['stroke'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the count of the target\n\nncount = len(df['stroke'])\nax = sns.countplot(x=df['stroke'])\nfor p in ax.patches:\n    x=p.get_bbox().get_points()[:,0]\n    y=p.get_bbox().get_points()[1,1]\n    ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), \n            ha='center', va='bottom') # set the alignment of the text\nplt.savefig('stroke_count.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of people having had a stroke in this dataset\n\nlen(df[df['stroke'] == 1])/len(df)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is very imbalanced => important to keep it in mind when cleaning and training, as well as when choosing the metrics.","metadata":{}},{"cell_type":"markdown","source":"### Handling missing values","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 201 null values in the 'bmi' column.","metadata":{}},{"cell_type":"code","source":"# Dropping the missing values\n\ndf.dropna(inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking \n\ndf.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After removing the null values, we have left with 4909 entries. ","metadata":{}},{"cell_type":"markdown","source":"### Drop the id column\nThe ID column was useful to identify the patients but it will not have any impact on the models, so we can drop it.","metadata":{}},{"cell_type":"code","source":"df.drop(columns=['id'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploring each variable","metadata":{}},{"cell_type":"markdown","source":"#### Gender","metadata":{}},{"cell_type":"code","source":"#Data spread between male and female\n\ndf['gender'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is 1 row with \"Other\", we can drop it. ","metadata":{}},{"cell_type":"code","source":"#Dropping 'Other' by selecting rows where gender 1= Other\n\ndf = df.loc[df[\"gender\"] != 'Other']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualise stroke counts gender wise\n\nsns.countplot(x=df[\"stroke\"], hue=df[\"gender\"])\nplt.savefig('stroke_gender.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Age","metadata":{}},{"cell_type":"code","source":"#Visualise the spread of the mean for the age variable\n\nfig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"age\", shade=True)\nfig.add_legend()\nplt.savefig('stroke_age.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's not suprising to see that there is a higher risk of stroke when the patient get older.","metadata":{}},{"cell_type":"markdown","source":"#### Hypertension","metadata":{}},{"cell_type":"code","source":"#Count hypertension\n\ndf['hypertension'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualise proportion of people having hypertension between the 2 groups\n\ndf_hypertension = df.groupby(['hypertension','stroke'])['hypertension'].count()\ndf_hypertension_total = df.groupby(['hypertension'])['hypertension'].count()\ndf_hypertension_fig = df_hypertension / df_hypertension_total * 100\ndf_hypertension_fig = df_hypertension_fig.unstack()\ndf_hypertension_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_hypertension.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In proportion, there are more people experiencing stroke in the group with hypertension.","metadata":{}},{"cell_type":"markdown","source":"#### Heart disease","metadata":{}},{"cell_type":"code","source":"#Count heart disease\n\ndf['heart_disease'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualise proportion of people having heart disease between the 2 groups\n\ndf_heart = df.groupby(['heart_disease','stroke'])['heart_disease'].count()\ndf_heart_total = df.groupby(['heart_disease'])['heart_disease'].count()\ndf_heart_fig = df_heart / df_heart_total * 100\ndf_heart_fig = df_heart_fig.unstack()\ndf_heart_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_heart.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same constatation as with the group having hypertension, there is a larger proportion of people experiencing stroke.","metadata":{}},{"cell_type":"markdown","source":"#### Marital status","metadata":{}},{"cell_type":"code","source":"#Count ever_married\n\ndf['ever_married'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting stacked bar to see the proportion of people having stroke in this group\n\ndf_married = df.groupby(['ever_married','stroke'])['ever_married'].count()\ndf_married_total = df.groupby(['ever_married'])['ever_married'].count()\ndf_married_fig = df_married / df_married_total * 100\ndf_married_fig = df_married_fig.unstack()\ndf_married_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_married.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The larger proportion of people experiencing stroke for this population can be correlated with what we have seen for age.","metadata":{}},{"cell_type":"markdown","source":"#### Work type","metadata":{}},{"cell_type":"code","source":"#Count work_type\n\ndf['work_type'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot\n\ndf_work = df.groupby(['work_type','stroke'])['work_type'].count()\ndf_work_total = df.groupby(['work_type'])['work_type'].count()\ndf_work_fig = df_work / df_work_total * 100\ndf_work_fig = df_work_fig.unstack()\ndf_work_fig.plot.bar(stacked=True, figsize=(7,7), width=0.75)\nplt.savefig('stroke_work.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Residence type","metadata":{}},{"cell_type":"code","source":"#Count residence_type\n\ndf['Residence_type'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot\n\ndf_residence = df.groupby(['Residence_type','stroke'])['Residence_type'].count()\ndf_residence_total = df.groupby(['Residence_type'])['Residence_type'].count()\ndf_residence_fig = df_residence / df_residence_total * 100\ndf_residence_fig = df_residence_fig.unstack()\ndf_residence_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_residence.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Environmental factors can be a risk factor for stroke but there is no difference in this dataset. ","metadata":{}},{"cell_type":"markdown","source":"#### Glucose level","metadata":{}},{"cell_type":"code","source":"#Spread avg_glucose_level\n\nfig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"avg_glucose_level\", shade=True)\nfig.add_legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.violinplot(x=\"stroke\", y=\"avg_glucose_level\", data=df)\nplt.savefig('stroke_glucose.png')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of average glucose level between the two classes is almost similar. There are only a slightly difference for the average glucose level above 150 where more people is experiencing stroke.","metadata":{}},{"cell_type":"markdown","source":"#### BMI","metadata":{}},{"cell_type":"code","source":"#Spread bmi\n\nfig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"bmi\", shade=True)\nfig.add_legend()\nplt.savefig('stroke_bmi.png')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no real difference between the two groups in terms of BMI.","metadata":{}},{"cell_type":"markdown","source":"#### Smoking status","metadata":{}},{"cell_type":"code","source":"#Count smoking_status\n\ndf['smoking_status'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot\n\ndf_smoking = df.groupby(['smoking_status','stroke'])['smoking_status'].count()\ndf_smoking_total = df.groupby(['smoking_status'])['smoking_status'].count()\ndf_smoking_fig = df_smoking / df_smoking_total * 100\ndf_smoking_fig = df_smoking_fig.unstack()\ndf_smoking_fig.plot.bar(stacked=True, figsize=(7,7), width=0.5)\nplt.savefig('stroke_smoking.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph confirms that smoking is a risk factor for stroke. ","metadata":{}},{"cell_type":"markdown","source":"### Encoding categorical data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc=LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoding gender variable\n\ndf['gender']=enc.fit_transform(df['gender'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoding marital status\n\ndf['ever_married']=enc.fit_transform(df['ever_married'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode variables with more than 2 Classes\n\ndf = pd.get_dummies(df, columns= [i for i in df.columns if df[i].dtypes=='object'],drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have now 4908 entries for 16 variables and all our data are either in numerical format so that we can perform the training later.\n","metadata":{}},{"cell_type":"markdown","source":"### Further exploratory analysis and visualisation","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df)\nplt.savefig('stroke_pairplot.png')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variables that have the highest correlation score with stroke are: age, heart disease, glucose level and hypertension, which is what we suspected.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(df.corr(),annot=True)\nplt.savefig('stroke_corr_heat.png')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nevertheless, the coefficients are very low (between .14 and .2)","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### 1. Set the independent (X) and the dependent variable (y)","metadata":{}},{"cell_type":"code","source":"y=df['stroke'].ravel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df.drop('stroke', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scaling X \n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scale=scaler.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scale[:5]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Split the data into training and testing sets ","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.3, stratify=y, shuffle=True, random_state=42)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Creating models","metadata":{}},{"cell_type":"markdown","source":"#### Logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr=LogisticRegression(random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_lr=lr.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, y_pred_lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred_lr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. With imbalanced data, the accuracy is not a metric that we can take into account because it is based on the the larger part of the target. In other words, this model is very accurate predincting when a people is not having a stroke, which is obviously what we don't need...\n2. The poor result in class 1 of the target is expected because of the imbalanced dataset as well as the limited correlation among the variables. ","metadata":{}},{"cell_type":"markdown","source":"#### Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf=RandomForestClassifier(random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_rf=rf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred_rf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test, y_pred_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt=DecisionTreeClassifier(random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_dt=dt.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred_dt))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test, y_pred_dt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn=KNeighborsClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_knn=knn.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred_knn))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test, y_pred_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling imbalanced data with sampling","metadata":{}},{"cell_type":"code","source":"#Using over-sampling method\n\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm = SMOTE()\nX_oversampled, y_oversampled = sm.fit_resample(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data after oversampling\n\nsns.countplot(x = y_oversampled, data = df)\nplt.savefig('stroke_oversampled.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train again with the new data\n\nX_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, test_size = 0.2, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\nlr = LogisticRegression(max_iter=1000, random_state=42)\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)\nprint(confusion_matrix(lr_pred, y_test))\nprint(classification_report(lr_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Decision Tree\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test)\nprint(confusion_matrix(dt_pred, y_test))\nprint(classification_report(dt_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nprint(confusion_matrix(knn_pred, y_test))\nprint(classification_report(knn_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random forest\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint(confusion_matrix(rf_pred, y_test))\nprint(classification_report(rf_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_mat = confusion_matrix(rf_pred, y_test)\nsns.heatmap(conf_mat.T, annot=True, fmt='d', cbar=False,\n          xticklabels=['No','Yes'],\n          yticklabels=['No','Yes'] )\nplt.xlabel('Actuals')\nplt.ylabel('Predicted')\nplt.savefig('stroke_over_rf_cm.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the feature importances dataframe\n\nfeature_importance = np.array(rf.feature_importances_)\nfeature_names = np.array(X.columns)\n\nfeat_imp = pd.DataFrame({'feature_names':feature_names,'feature_importance':feature_importance})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(x=feat_imp['feature_importance'], y=feat_imp['feature_names'])\nplt.savefig('stroke_feature_imp.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\n\nfn = df.columns\ncn = [\"Yes\",\"No\"]\n\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (40,15))\n\ntree.plot_tree(rf.estimators_[0],\n               feature_names = fn, \n               class_names=cn,\n               filled = True);\nplt.savefig('stroke_over_tree.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_prob1 = lr.predict_proba(X_test)\npred_prob2 = dt.predict_proba(X_test)\npred_prob3 = knn.predict_proba(X_test)\npred_prob4 = rf.predict_proba(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\n# roc curve for models\nfpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\nfpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\nfpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\nfpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\n# auc scores\nauc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\nauc_score2 = roc_auc_score(y_test, pred_prob2[:,1])\nauc_score3 = roc_auc_score(y_test, pred_prob3[:,1])\nauc_score4 = roc_auc_score(y_test, pred_prob4[:,1])\n\nprint(auc_score1)\nprint(auc_score2)\nprint(auc_score3)\nprint(auc_score4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\nplt.plot(fpr2, tpr2, linestyle='--',color='green', label='Decision Tree')\nplt.plot(fpr3, tpr3, linestyle='--',color='yellow', label='KNN')\nplt.plot(fpr4, tpr4, linestyle='--',color='red', label='Random Forest')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# title\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC',dpi=300)\nplt.show()\nfig.savefig('multiple_roc_curve.png')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After sampling, random forest leads to the best results in terms of metrics as we can see with the ROC curve and a F1 score of .96 ","metadata":{}}]}