{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Wellcome To My Kernel"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.\n\n*  I have processed some columns to get better meaning of them including the user_agent strings and I have created new csv file containing the parsed UA as it took time in parsing so I did not want others to waste their time on parsing it.\n* This project will make you understand lot of stuff & try to understand the problem statement by doing research,understanding each & every feature to play with it.\n\nProblem Statement : Build A Model that can detect the Non Human Traffic present in a website!"},{"metadata":{},"cell_type":"markdown","source":"# **At end please feadback my kernel.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/bot-detection/ibm_data.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Total num of rows and columns in data is  \",df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are some null values in data\",df[\"sec_lvl_domn\"].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['page_vw_ts'] = pd.to_datetime(df['page_vw_ts'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['page_vw_ts'].dt.year.head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Filtering and storing the date in data set"},{"metadata":{"trusted":true},"cell_type":"code","source":" df['crm_dt'] = df['page_vw_ts'].dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1.Delete the page_vw_ts column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('page_vw_ts', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1 DATA Preprocessing on ip_info Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=['city','st','operating_sys'], inplace=True)\ndf.device_type.fillna(value='unkown_device', inplace=True)\ndf.sec_lvl_domn.fillna(value='unkown_domain', inplace=True)\ndf.dropna(inplace=True)\ndf.drop(labels=['wk', 'mth', 'yr', 'crm_dt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding a Bounce_rate Column "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf[\"bounce_rate_%\"] = ((df.VISIT - df.ENGD_VISIT)/df.VISIT)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total of No. Of unique IP's is =\",df.ip_addr.nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can't work on all the ip's that visit our website in a day because many of them just visit only a single time So we try to filter those ip's that has high no. of views or visit too mant times, In rules Of detecting bot it is mentioned that bots show a similar pattern in visiting any website..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# IP Addres's that has total views greater than 24 in a day\nip_views = pd.DataFrame(df.groupby('ip_addr').VIEWS.sum().sort_values())\nunique_ip_address = list(ip_views[ip_views.VIEWS > 24].index)\n\n# Limiting the Dataset to those rows that contain one of the ip's present in unique_ip_address \nnew_data = df[df.ip_addr.isin(unique_ip_address)]\n\n# Taking intersection of ip's\n#unique_ip_address = list(new_data_details.ip_addr.unique())\n\n# These are the filterd IP's on which we have to find Infomation.\nprint(\"No. Of unique ip's {}\".format(len(unique_ip_address)))\n\n# Examples of unique ip address\nunique_ip_address[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I create a function that will classify all different variants of each os as the same os for example MICROSOFT_WINDOWS8.1 MICROSOFT_WINXP are to be renamed to MICROSOFT PC\nI do the same for the other types of os including mobile phones, I classify the ones not falling into these main types as others"},{"metadata":{"trusted":true},"cell_type":"code","source":"def shortenos(x):\n    #print(x)\n    if \"microsoft\" in x.lower().split(\"_\")[0]:\n        x=\"MICROSOFT PC\"\n        return x\n    elif \"windowsphone\" in x.lower().split(\"_\")[0]:\n        x=\"WINDOWS MOBILE\"\n        return x\n    elif \"windowsmobile\" in x.lower().split(\"_\")[0]:\n        x=\"WINDOWS MOBILE\"\n        return x\n    elif \"macintosh\" in x.lower().split(\"_\")[0]:\n        x=\"MACOS PC\"\n        return x\n    elif \"ios\" in x.lower().split(\"_\")[0]:\n        x=\"IOS PHONE\"\n        return x\n    elif \"android\" in x.lower().split(\"_\")[0]:\n        x=\"ANDROID\"\n        return x\n    elif \"linux\" in x.lower().split(\"_\")[0]:\n        x=\"LINUX\"\n        return x\n    elif x.lower()==\"notgiven\":\n        x=\"NotGiven\"\n        return x\n    else:\n        x=\"OTHER\"\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets groupby the new os column we created and sum the values for VIEWS and VISIT\n### This will help us in analysing which of these users are belonging to which OS"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"os\"]=df.operating_sys.apply(shortenos)\nos_df=df.groupby([\"os\"]).sum().reset_index()\nos_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Show in Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"import altair as alt\n\nalt.data_transformers.disable_max_rows()\nbase=alt.Chart(os_df).mark_bar().encode(\nx=\"os\",\ny=\"VISIT\",\ntooltip=[\"VISIT\"]\n)\n\nbase2=alt.Chart(os_df).mark_bar().encode(\nx=\"os\",\ny=\"VIEWS\",tooltip=[\"VIEWS\"]\n)\nalt.hconcat(base,base2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.user_agent.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Installing device_detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install device_detector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from device_detector import SoftwareDetector\ndef parse_family(x):\n    \n    return SoftwareDetector(x).parse().client_name()\ndef parse_os(x):\n  \n    return SoftwareDetector(x).parse().os_name()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here as I stated ill be taking the 400000 as my sample dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df=df[:400000]\nsample_df.user_agent.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=sample_df[\"user_agent\"].apply(parse_family)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df[\"user_browser\"]=x\nsample_df.user_agent.dropna(inplace=True)\nsample_df[\"user_os\"]=sample_df.user_agent.apply(parse_os)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}