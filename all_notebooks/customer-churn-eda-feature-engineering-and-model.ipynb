{"cells":[{"metadata":{},"cell_type":"markdown","source":"Context\n\n\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n\nContent\n\nEach row represents a customer, each column contains customer’s attributes described on the column Metadata.\n\nThe data set includes information about:\n\n - Customers who left within the last month – the column is called Churn\n - Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n - Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n - Demographic info about customers – gender, age range, and if they have partners and dependents"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:46.794657Z","start_time":"2019-08-24T21:34:44.54907Z"},"trusted":true},"cell_type":"code","source":"#Importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the \"../input/\" directory.\nimport os\nimport matplotlib.pyplot as plt#visualization\n%matplotlib inline\nimport pandas as pd\nfrom scipy import stats\nimport seaborn as sns#visualization\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport io\nsns.set_style(style='whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:46.860992Z","start_time":"2019-08-24T21:34:46.805112Z"},"trusted":true},"cell_type":"code","source":"#open the dataset\ndf = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n#first few rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:46.872958Z","start_time":"2019-08-24T21:34:46.864457Z"},"trusted":true},"cell_type":"code","source":"def resumetable(df):\n    '''\n    Returns few key metrics of a dataframe.\n    '''\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.342715Z","start_time":"2019-08-24T21:34:46.875912Z"},"trusted":true},"cell_type":"code","source":"resumetable(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" - customerID Customer ID\n - gender Whether the customer is a male or a female\n - SeniorCitizen Whether the customer is a senior citizen or not (1, 0)\n - Partner Whether the customer has a partner or not (Yes, No)\n - Dependents Whether the customer has dependents or not (Yes, No)\n - tenure Number of months the customer has stayed with the company\n - PhoneService Whether the customer has a phone service or not (Yes, No)\n - MultipleLines Whether the customer has multiple lines or not (Yes, No, No phone service)\n - InternetService Customer’s internet service provider (DSL, Fiber optic, No)\n - OnlineSecurity Whether the customer has online security or not (Yes, No, No internet service)\n - OnlineBackup Whether the customer has online backup or not (Yes, No, No internet service)\n - DeviceProtection Whether the customer has device protection or not (Yes, No, No internet service)\n - TechSupport Whether the customer has tech support or not (Yes, No, No internet service)\n - StreamingTV Whether the customer has streaming TV or not (Yes, No, No internet service)\n - StreamingMovies Whether the customer has streaming movies or not (Yes, No, No internet service)\n - Contract The contract term of the customer (Month-to-month, One year, Two year)\n - PaperlessBilling Whether the customer has paperless billing or not (Yes, No)\n - PaymentMethod The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n - MonthlyCharges The amount charged to the customer monthly\n - TotalCharges The total amount charged to the customer\n - Churn Whether the customer churned or not (Yes or No)"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.364427Z","start_time":"2019-08-24T21:34:47.345606Z"},"trusted":true},"cell_type":"code","source":"#Replacing spaces with null values in total charges column\ndf['TotalCharges'] = df[\"TotalCharges\"].replace(\" \",np.nan)\n#convert to float type\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.371183Z","start_time":"2019-08-24T21:34:47.365912Z"},"trusted":true},"cell_type":"code","source":"#Relable 1 and 0 with yes and no, repectively for consistency\ndf['SeniorCitizen'] = df.SeniorCitizen.replace({1:\"Yes\", 0:\"No\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"## Customer Churn by Category"},{"metadata":{},"cell_type":"markdown","source":"Let's extract the category columns to perform EDA on all items at once. Some categories also have 3 unique values. We'll see why."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.378431Z","start_time":"2019-08-24T21:34:47.372703Z"},"trusted":true},"cell_type":"code","source":"df.columns[1:-3]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.383709Z","start_time":"2019-08-24T21:34:47.38034Z"},"trusted":true},"cell_type":"code","source":"categories = list(df.columns[1:-3])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.391219Z","start_time":"2019-08-24T21:34:47.385614Z"},"trusted":true},"cell_type":"code","source":"categories.pop(4)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.398844Z","start_time":"2019-08-24T21:34:47.393125Z"},"trusted":true},"cell_type":"code","source":"#categorical features are:\ncategories","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.404735Z","start_time":"2019-08-24T21:34:47.400656Z"},"trusted":true},"cell_type":"code","source":"non_cats = []\nfor item in enumerate(list(~df.columns.isin(categories))):\n    if item[1] == True:\n        non_cats.append(df.columns[item[0]])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.412413Z","start_time":"2019-08-24T21:34:47.40673Z"},"trusted":true},"cell_type":"code","source":"non_cats.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.420526Z","start_time":"2019-08-24T21:34:47.414967Z"},"trusted":true},"cell_type":"code","source":"non_cats.pop(-1)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:47.427119Z","start_time":"2019-08-24T21:34:47.42257Z"},"trusted":true},"cell_type":"code","source":"#Non-categorical features\nnon_cats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting each categorical feature split by Churn: No/Yes and percentage of customers in each group."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:50.114194Z","start_time":"2019-08-24T21:34:47.428965Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"for cat in categories:\n    fig, ax = plt.subplots(figsize = (10,10))\n    churn_no = []\n    churn_yes = []\n    x = []\n    for i in df[cat].unique():\n        #each category has a sub-category: e.g. Gender category has male and female\n        #looping through each subcategory and adding churn and no churn data to list\n        churn_no.append(df.groupby([cat, 'Churn']).size()[i][0])\n        churn_yes.append(df.groupby([cat, 'Churn']).size()[i][1])\n        x.append(i)\n    #print(churn_no, churn_yes)\n    \n    p1 = plt.bar(x, churn_no)\n    p2 = plt.bar(x, churn_yes, bottom=churn_no)\n\n    #Plotting the bar labels inside the bars, as percentage\n    for r1, r2, in zip(p1, p2):\n        height1 = r1.get_height()\n        height2 = r2.get_height()\n        plt.text(r1.get_x() + r1.get_width() / 2., #x\n                 height1 / 2., #y\n                 f'{round(height1 / (height1 + height2)*100,1)} %', #s\n                 ha=\"center\", va=\"center\", color=\"white\", fontsize=12)\n        plt.text(r2.get_x() + r2.get_width() / 2., #x\n                 height1 + height2 / 2., #y\n                 f'{round(height2 / (height1 + height2)*100,1)} %', #s\n                 ha=\"center\", va=\"center\", color=\"white\", fontsize=12)\n\n\n    \n    plt.xlabel('Category', fontsize=12)\n    plt.ylabel('Number of Customers in Category', fontsize=12)\n    plt.legend(['No Churn','Churn'])\n    plt.title(cat, fontsize=16)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" - Gender: Gender has almost a 50/50 split and negligible difference in churn percentages.\n -\tSenior Citizens: Senior citizens have close to double the rate of churn; however, they make up only 1/6th of the total customer population\n -\tPartner: The split between population is almost equal with ~3,500 customers in each group. The percentage of customers that churn, however, is 30% higher if the customer is without a partner.\n -\tDependents: Customers are more likely to churn if they have no dependents, however, the split in customers based on dependents is imbalanced. \n -\tPhone Service: Rate of churn is similar regardless whether a customer has phone service or not.\n -\tMultiple Lines: of the customers that have phone service, the ones that have multiple lines have similar churn rates of those who only have one line.\n -\tInternet Service: Out of the customers that have internet service, customers with Fiber Optic service have double the rate of churn than those with DSL.\n -\tOnline Security: Of the customers that have internet service, ones without online security have a triple the churn rate than those who opted in for online security. May be worth investigating this feature further. \n -\tOnline Backup / Device Protection: Of the customers that have internet service, customers with these features have half the rate of churn than those that don’t\n -\tTech Support: Of the customers that have internet service, those that use tech support have a significantly lower rate of churn. Note, the number of customers that use tech support is significantly less than those who don’t.\n -\tStreaming TV / Streaming Movies: Of the customers that have internet service, no significant change in churn rate can be seen whether a customer uses the streaming service.\n -\tContract: Customers on contract have significantly lower churn rates than those that are month to month. This is expected.\n -\tPaperless Billing: Customers on paperless billing have higher rates of churn. \n -\tPayment Method: Electronic Check customers have double the rate of churn than those using other payment methods.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Customer Churn by non-categorical items"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:50.121549Z","start_time":"2019-08-24T21:34:50.116174Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"non_cats","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:50.141127Z","start_time":"2019-08-24T21:34:50.128159Z"},"trusted":true},"cell_type":"code","source":"len(df.tenure.unique())","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:50.506541Z","start_time":"2019-08-24T21:34:50.147202Z"},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ndf.tenure[df.Churn == 'Yes'].hist(bins=20)\ndf.tenure[df.Churn == 'No'].hist(bins=20, alpha=0.5)\nplt.legend(['Churn Customers', 'Non-Churn Customers'])\nplt.title('Customer Tenure')\nplt.xlabel('Tenure')\nplt.ylabel('Count of Customers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The longer a customer stays, the less likely they are to churn (tenure by month)"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:50.845389Z","start_time":"2019-08-24T21:34:50.508167Z"},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ndf.MonthlyCharges[df.Churn == 'Yes'].hist(bins=20)\ndf.MonthlyCharges[df.Churn == 'No'].hist(bins=20, alpha=0.5)\nplt.legend(['Churn Customers', 'Non-Churn Customers'])\nplt.title('Customer Monthly Charges')\nplt.xlabel('Monthly Charge Amount')\nplt.ylabel('Count of Customers')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:51.176403Z","start_time":"2019-08-24T21:34:50.847855Z"},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ndf.TotalCharges[df.Churn == 'Yes'].hist(bins=20)\ndf.TotalCharges[df.Churn == 'No'].hist(bins=20, alpha=0.5)\nplt.legend(['Churn Customers', 'Non-Churn Customers'])\nplt.title('Customer Total Charges')\nplt.xlabel('Total Charge Amount')\nplt.ylabel('Count of Customers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Churn Imbalance"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:51.186523Z","start_time":"2019-08-24T21:34:51.17902Z"},"trusted":true},"cell_type":"code","source":"df.groupby('Churn').size().values","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:51.196327Z","start_time":"2019-08-24T21:34:51.188667Z"},"trusted":true},"cell_type":"code","source":"df.groupby('Churn').size()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:51.326597Z","start_time":"2019-08-24T21:34:51.198358Z"},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\nlabels = 'No Churn', 'Churn'\nx = df.groupby('Churn').size().values\nax.pie(x, autopct='%1.1f%%', labels=labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation"},{"metadata":{},"cell_type":"markdown","source":"Correlation will indicate which variables are related to one another and to the target"},{"metadata":{},"cell_type":"markdown","source":"### Encode the dataframe"},{"metadata":{},"cell_type":"markdown","source":"The dataframe needs to be encoded into numerical values in order to make the comparison. e.g. Yes/No will need to be converted to 1 / 0. Scikit-Learn's LabelEncoder will be utilized"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:52.946055Z","start_time":"2019-08-24T21:34:51.329243Z"},"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:52.954651Z","start_time":"2019-08-24T21:34:52.948217Z"},"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:52.963376Z","start_time":"2019-08-24T21:34:52.956918Z"},"trusted":true},"cell_type":"code","source":"categories","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:52.973171Z","start_time":"2019-08-24T21:34:52.9667Z"},"trusted":true},"cell_type":"code","source":"non_cats","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:52.980702Z","start_time":"2019-08-24T21:34:52.976854Z"},"trusted":true},"cell_type":"code","source":"other = ['customerID', 'Churn']","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:52.992598Z","start_time":"2019-08-24T21:34:52.983995Z"},"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll have to encode all categorical values in the dataframe. We already defined the lists 'categories' and 'other'."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:53.003514Z","start_time":"2019-08-24T21:34:52.998522Z"},"trusted":true},"cell_type":"code","source":"encoded_df = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:53.040792Z","start_time":"2019-08-24T21:34:53.005952Z"},"trusted":true},"cell_type":"code","source":"for item in categories:\n    encoded_df[item] = le.fit_transform(df[item].values)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:53.050451Z","start_time":"2019-08-24T21:34:53.04284Z"},"trusted":true},"cell_type":"code","source":"for item in non_cats:\n    encoded_df[item] = df[item]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:53.066267Z","start_time":"2019-08-24T21:34:53.052291Z"},"trusted":true},"cell_type":"code","source":"for item in other:\n    encoded_df[item] = le.fit_transform(df[item].values)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:53.086884Z","start_time":"2019-08-24T21:34:53.068302Z"},"trusted":true},"cell_type":"code","source":"encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:53.095454Z","start_time":"2019-08-24T21:34:53.0894Z"},"trusted":true},"cell_type":"code","source":"def heatMap(df):\n    #Create Correlation df\n    corr = df.corr()\n    #Plot figsize\n    fig, ax = plt.subplots(figsize=(15, 15))\n    #Generate Heat Map, allow annotations and place floats in map\n    sns.heatmap(corr, cmap=\"Blues\", annot=True, fmt=\".2f\", linewidths=.2)\n    #Apply xticks\n    plt.xticks(range(len(corr.columns)), corr.columns);\n    #Apply yticks\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    #show plot\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:54.411238Z","start_time":"2019-08-24T21:34:53.097629Z"},"trusted":true},"cell_type":"code","source":"heatMap(encoded_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation to Churn"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:54.419098Z","start_time":"2019-08-24T21:34:54.413153Z"},"trusted":true},"cell_type":"code","source":"encoded_df.columns[0:]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:54.435422Z","start_time":"2019-08-24T21:34:54.421317Z"},"trusted":true},"cell_type":"code","source":"corr_df = encoded_df[encoded_df.columns[0:]].corr()['Churn'][:]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:54.448354Z","start_time":"2019-08-24T21:34:54.437421Z"},"trusted":true},"cell_type":"code","source":"np.abs(corr_df).sort_values(ascending=False)[1:6]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the heatmap we can see a number of negatively and positively correlated features. We can focus on these during the feature engineering stage. Contract, tenure, OnlineSecurity, TechSupport, TotalCharges."},{"metadata":{},"cell_type":"markdown","source":"## Scatterplot"},{"metadata":{},"cell_type":"markdown","source":"Next we can see if there is any indication of churn in the amount a customer spends. Since TotalCharges is correlated with Churn, it's a good idea to look at this variable to see if there is any signal."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:56.803838Z","start_time":"2019-08-24T21:34:54.450812Z"},"trusted":true},"cell_type":"code","source":"sns.set(font_scale=2)\nsns.set_style(style='whitegrid')\nsns.pairplot(df, hue=\"Churn\", height=9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Binning the data"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:56.812228Z","start_time":"2019-08-24T21:34:56.805468Z"},"trusted":true},"cell_type":"code","source":"df.tenure.describe()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:56.823647Z","start_time":"2019-08-24T21:34:56.81367Z"},"trusted":true},"cell_type":"code","source":"df['tenure_bin'] = pd.cut(df.tenure, bins=[0,10,20,30,40,50,60,70,80], labels=[0,10,20,30,40,50,60,70])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.075132Z","start_time":"2019-08-24T21:34:56.825244Z"},"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1)\nfig, ax = plt.subplots(figsize = (15,10))\nsns.countplot('tenure_bin', hue='Churn', data=df)\nplt.xlabel('Tenure bin, months')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.0809Z","start_time":"2019-08-24T21:34:57.077316Z"},"trusted":true},"cell_type":"code","source":"#adding the tenure_bins to the encoded dataframe\nencoded_df['tenure_bin'] = df.tenure_bin","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.102813Z","start_time":"2019-08-24T21:34:57.083545Z"},"trusted":true},"cell_type":"code","source":"encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.114339Z","start_time":"2019-08-24T21:34:57.10488Z"},"trusted":true},"cell_type":"code","source":"encoded_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.121581Z","start_time":"2019-08-24T21:34:57.116659Z"},"trusted":true},"cell_type":"code","source":"encoded_df = encoded_df.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.143145Z","start_time":"2019-08-24T21:34:57.123514Z"},"trusted":true},"cell_type":"code","source":"encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define features and target"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.149987Z","start_time":"2019-08-24T21:34:57.144913Z"},"trusted":true},"cell_type":"code","source":"features = encoded_df.drop(columns=['Churn', 'tenure_bin', 'customerID', 'gender','SeniorCitizen','PhoneService']).columns","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.157364Z","start_time":"2019-08-24T21:34:57.151775Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.162276Z","start_time":"2019-08-24T21:34:57.158965Z"},"trusted":true},"cell_type":"code","source":"target = ['Churn']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dealing with imbalance by downsampling"},{"metadata":{},"cell_type":"markdown","source":"Imbalance in the data can bias the model to favor the majority class. Since we have more customers (~75%) that do not churn, our model will fit to the non-churn customers more favorably. In order to control for this, we can down-sample the majority class (non-churn) to match the minority class (churn)."},{"metadata":{},"cell_type":"markdown","source":" - 1 = Churn\n - 0 = non-Churn"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.188995Z","start_time":"2019-08-24T21:34:57.164024Z"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.199089Z","start_time":"2019-08-24T21:34:57.190551Z"},"trusted":true},"cell_type":"code","source":"down = encoded_df[encoded_df.Churn == 1]\nup = encoded_df[encoded_df.Churn == 0]\ndown = down.Churn.count()\nup = up.Churn.count()\nprint(f'Churn Fraction: {down/(up+down)}')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.21507Z","start_time":"2019-08-24T21:34:57.200851Z"},"trusted":true},"cell_type":"code","source":"#let's first separate majority class and minority class and resample\n\ndf_majority = encoded_df[encoded_df.Churn == 0]\ndf_minority = encoded_df[encoded_df.Churn == 1]\n\n\n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=False,    # sample without replacement\n                                 n_samples=down,     # to match minority class\n                                 random_state=42) # reproducible results\n# combine the new dataframes\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n\ndf_downsampled.Churn.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define X and y"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.2244Z","start_time":"2019-08-24T21:34:57.217208Z"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ny = df_downsampled[target]\nX = df_downsampled[features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we don't a significant amount of data to train on, we'll use a 90/10 train/test split."},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.246926Z","start_time":"2019-08-24T21:34:57.226023Z"},"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initial Modeling"},{"metadata":{},"cell_type":"markdown","source":"Our goal is to not only predict whether a customer will churn but also get insight into why so we can intervene and change the trajectory of a customer. "},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.253161Z","start_time":"2019-08-24T21:34:57.248912Z"},"trusted":true},"cell_type":"code","source":"#import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve,\\\nprecision_score, recall_score, precision_recall_curve, classification_report, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Baseline"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.287858Z","start_time":"2019-08-24T21:34:57.255002Z"},"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogr = LogisticRegression(random_state=42, max_iter=1000, )","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.391215Z","start_time":"2019-08-24T21:34:57.289407Z"},"trusted":true},"cell_type":"code","source":"logr.fit(X_train, y_train)\ny_pred_logr = logr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.40889Z","start_time":"2019-08-24T21:34:57.394438Z"},"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_logr))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred_logr)}')\nprint(f'Precision: {precision_score(y_test, y_pred_logr)}')\nprint(f'Recall: {recall_score(y_test, y_pred_logr)}')\nprint(f'Confusion Matrix: {confusion_matrix(y_test, y_pred_logr)}')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.584662Z","start_time":"2019-08-24T21:34:57.410919Z"},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ny_prob = logr.predict_proba(X_test)[::,1]\ny_pred_proba = y_prob\nfpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\nauc_rand = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr_rand,tpr_rand,label=f\"Logistic Regression, AUC=\"+str(auc_rand))\nplt.legend(loc=4)\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification model interpretation"},{"metadata":{},"cell_type":"markdown","source":"Our initial logistic regression model did relatively well. For our test dataset we had 187 non-churn customers and 187 churn customers. Looking at the confusion matrix output, our model was able to predict non-churn and churn with a 75% (140 out of 187) and 79% (147 out of 187) accuracy, respectively. "},{"metadata":{},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.60629Z","start_time":"2019-08-24T21:34:57.587199Z"},"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:57.613429Z","start_time":"2019-08-24T21:34:57.608037Z"},"trusted":true},"cell_type":"code","source":"clf = lgb.LGBMClassifier(drop_rate=0.9, min_data_in_leaf=800, max_bin=500,\n                         n_estimators=5000, min_sum_hessian_in_leaf=1, importance_type='gain',\n                         learning_rate=0.4, bagging_fraction=0.9, colsample_bytree=1.0,\n                         feature_fraction=0.1, lambda_l1=5.0, lambda_l2=3.0, max_depth=9,\n                         min_child_samples=55, min_child_weight=5.0, min_split_gain=0.1,\n                         num_leaves=4000, subsample = 0.75)  ","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:58.262486Z","start_time":"2019-08-24T21:34:57.615181Z"},"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:58.27478Z","start_time":"2019-08-24T21:34:58.263969Z"},"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:58.288634Z","start_time":"2019-08-24T21:34:58.2778Z"},"trusted":true},"cell_type":"code","source":"print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\nprint(f'Precision: {precision_score(y_test, y_pred)}')\nprint(f'Recall: {recall_score(y_test, y_pred)}')\nprint(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:58.469056Z","start_time":"2019-08-24T21:34:58.29067Z"},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\nsns.set_style(style='whitegrid')\ny_prob = clf.predict_proba(X_test)[::,1]\ny_pred_proba = y_prob\nfpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\nauc_rand = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr_rand,tpr_rand,label=\"LightGBM, AUC=\"+str(auc_rand))\nplt.legend(loc=4)\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:58.754683Z","start_time":"2019-08-24T21:34:58.4719Z"},"trusted":true},"cell_type":"code","source":"feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns)), columns=['Value','Feature'])\nplt.figure(figsize=(20, 10))\nsns.set(font_scale=1.5)\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"From our correlation analysis, we can see the feature importance associated with the LightGBM model resembles our initial intuition for features to consider for feature engineering.\n - Contract          0.396713\n - tenure            0.352229\n - OnlineSecurity    0.289309\n - TechSupport       0.282492\n - TotalCharges      0.199484"},{"metadata":{},"cell_type":"markdown","source":"LightGBM"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:58.769841Z","start_time":"2019-08-24T21:34:58.758962Z"},"trusted":true},"cell_type":"code","source":"feature_imp.sort_values(by=\"Value\", ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total number of services enrolled in"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:58.778728Z","start_time":"2019-08-24T21:34:58.772123Z"},"trusted":true},"cell_type":"code","source":"services = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n            'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling']","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:59.213441Z","start_time":"2019-08-24T21:34:58.784011Z"},"trusted":true},"cell_type":"code","source":"encoded_df['services'] = encoded_df[services].apply(lambda x: x.sum(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:34:59.234606Z","start_time":"2019-08-24T21:34:59.215237Z"},"trusted":true},"cell_type":"code","source":"encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model test"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:00.425141Z","start_time":"2019-08-24T21:34:59.237534Z"},"trusted":true},"cell_type":"code","source":"features = encoded_df.drop(columns=['Churn','tenure_bin','customerID','gender',\n                                    'SeniorCitizen','PhoneService']).columns\ntarget = ['Churn']\ndf_majority = encoded_df[encoded_df.Churn == 0]\ndf_minority = encoded_df[encoded_df.Churn == 1]\n\n\n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=False,    # sample without replacement\n                                 n_samples=down,     # to match minority class\n                                 random_state=42) # reproducible results\n# combine the new dataframes\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n\ndf_downsampled.Churn.value_counts()\ny = df_downsampled[target]\nX = df_downsampled[features]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state=42, stratify=y)\n\n#LightGBM\nclf = lgb.LGBMClassifier(drop_rate=0.9, min_data_in_leaf=800, max_bin=500,\n                         n_estimators=5000, min_sum_hessian_in_leaf=1, importance_type='gain',\n                         learning_rate=0.4, bagging_fraction=0.9, colsample_bytree=1.0,\n                         feature_fraction=0.1, lambda_l1=5.0, lambda_l2=3.0, max_depth=9,\n                         min_child_samples=55, min_child_weight=5.0, min_split_gain=0.1,\n                         num_leaves=4000, subsample = 0.75)  \n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\nprint(f'Precision: {precision_score(y_test, y_pred)}')\nprint(f'Recall: {recall_score(y_test, y_pred)}')\nprint(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')\n\nfig, ax = plt.subplots(figsize = (10,10))\nsns.set_style(style='whitegrid')\ny_prob = clf.predict_proba(X_test)[::,1]\ny_pred_proba = y_prob\nfpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\nauc_rand = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr_rand,tpr_rand,label=\"LightGBM, AUC=\"+str(auc_rand))\nplt.legend(loc=4)\nplt.title('ROC Curve')\nplt.show()\n\nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns)), columns=['Value','Feature'])\nplt.figure(figsize=(20, 10))\nsns.set(font_scale=1.5)\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Average monthly price per service"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:00.434419Z","start_time":"2019-08-24T21:35:00.428739Z"},"trusted":true},"cell_type":"code","source":"encoded_df['avg_price'] = encoded_df.MonthlyCharges / encoded_df.services","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:00.458533Z","start_time":"2019-08-24T21:35:00.436528Z"},"trusted":true},"cell_type":"code","source":"encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model test"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:01.67268Z","start_time":"2019-08-24T21:35:00.462236Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"features = encoded_df.drop(columns=['Churn','tenure_bin','customerID','gender','services',\n                                    'SeniorCitizen','PhoneService']).columns\ntarget = ['Churn']\ndf_majority = encoded_df[encoded_df.Churn == 0]\ndf_minority = encoded_df[encoded_df.Churn == 1]\n\n\n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=False,    # sample without replacement\n                                 n_samples=down,     # to match minority class\n                                 random_state=42) # reproducible results\n# combine the new dataframes\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n\ndf_downsampled.Churn.value_counts()\ny = df_downsampled[target]\nX = df_downsampled[features]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state=42, stratify=y)\n\n#LightGBM\nclf = lgb.LGBMClassifier(drop_rate=0.9, min_data_in_leaf=800, max_bin=500,\n                         n_estimators=5000, min_sum_hessian_in_leaf=1, importance_type='gain',\n                         learning_rate=0.4, bagging_fraction=0.9, colsample_bytree=1.0,\n                         feature_fraction=0.1, lambda_l1=5.0, lambda_l2=3.0, max_depth=9,\n                         min_child_samples=55, min_child_weight=5.0, min_split_gain=0.1,\n                         num_leaves=4000, subsample = 0.75)  \n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\nprint(f'Precision: {precision_score(y_test, y_pred)}')\nprint(f'Recall: {recall_score(y_test, y_pred)}')\nprint(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')\n\nfig, ax = plt.subplots(figsize = (10,10))\nsns.set_style(style='whitegrid')\ny_prob = clf.predict_proba(X_test)[::,1]\ny_pred_proba = y_prob\nfpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\nauc_rand = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr_rand,tpr_rand,label=\"LightGBM, AUC=\"+str(auc_rand))\nplt.legend(loc=4)\nplt.title('ROC Curve')\nplt.show()\n\nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns)), columns=['Value','Feature'])\nplt.figure(figsize=(20, 10))\nsns.set(font_scale=1.5)\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extra Charges"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:01.681924Z","start_time":"2019-08-24T21:35:01.675901Z"},"trusted":true},"cell_type":"code","source":"encoded_df['extra_charges'] = (encoded_df.MonthlyCharges * encoded_df.tenure) - encoded_df.TotalCharges","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:01.704345Z","start_time":"2019-08-24T21:35:01.683501Z"},"trusted":true},"cell_type":"code","source":"encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model test"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:02.894552Z","start_time":"2019-08-24T21:35:01.706166Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"features = encoded_df.drop(columns=['Churn','tenure_bin','customerID','gender','services','avg_price',\n                                    'SeniorCitizen','PhoneService']).columns\ntarget = ['Churn']\ndf_majority = encoded_df[encoded_df.Churn == 0]\ndf_minority = encoded_df[encoded_df.Churn == 1]\n\n\n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=False,    # sample without replacement\n                                 n_samples=down,     # to match minority class\n                                 random_state=42) # reproducible results\n# combine the new dataframes\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n\ndf_downsampled.Churn.value_counts()\ny = df_downsampled[target]\nX = df_downsampled[features]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state=42, stratify=y)\n\n#LightGBM\nclf = lgb.LGBMClassifier(drop_rate=0.9, min_data_in_leaf=800, max_bin=500,\n                         n_estimators=5000, min_sum_hessian_in_leaf=1, importance_type='gain',\n                         learning_rate=0.4, bagging_fraction=0.9, colsample_bytree=1.0,\n                         feature_fraction=0.1, lambda_l1=5.0, lambda_l2=3.0, max_depth=9,\n                         min_child_samples=55, min_child_weight=5.0, min_split_gain=0.1,\n                         num_leaves=4000, subsample = 0.75)  \n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\nprint(f'Precision: {precision_score(y_test, y_pred)}')\nprint(f'Recall: {recall_score(y_test, y_pred)}')\nprint(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')\n\nfig, ax = plt.subplots(figsize = (10,10))\nsns.set_style(style='whitegrid')\ny_prob = clf.predict_proba(X_test)[::,1]\ny_pred_proba = y_prob\nfpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\nauc_rand = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr_rand,tpr_rand,label=\"LightGBM, AUC=\"+str(auc_rand))\nplt.legend(loc=4)\nplt.title('ROC Curve')\nplt.show()\n\nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns)), columns=['Value','Feature'])\nplt.figure(figsize=(20, 10))\nsns.set(font_scale=1.5)\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll keep extra_charges and avg_price as new features"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:02.936941Z","start_time":"2019-08-24T21:35:02.898126Z"},"trusted":true},"cell_type":"code","source":"features = encoded_df.drop(columns=['Churn','tenure_bin','customerID','gender','services',\n                                    'SeniorCitizen','PhoneService']).columns\ntarget = ['Churn']\ndf_majority = encoded_df[encoded_df.Churn == 0]\ndf_minority = encoded_df[encoded_df.Churn == 1]\n\n\n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=False,    # sample without replacement\n                                 n_samples=down,     # to match minority class\n                                 random_state=42) # reproducible results\n# combine the new dataframes\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n\ndf_downsampled.Churn.value_counts()\ny = df_downsampled[target]\nX = df_downsampled[features]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"## Scikit-Learn and XGBoost Classifiers"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:03.29364Z","start_time":"2019-08-24T21:35:02.9386Z"},"trusted":true},"cell_type":"code","source":"#Import classifiers\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:03.303866Z","start_time":"2019-08-24T21:35:03.295807Z"},"trusted":true},"cell_type":"code","source":"#instantiate models\nseed = 42\nclf = RandomForestClassifier(random_state=seed)\nxgb = XGBClassifier(random_state=seed)\nxtr = ExtraTreesClassifier(random_state=seed)\nlgbm = lgb.LGBMClassifier(drop_rate=0.9, min_data_in_leaf=800, max_bin=500,\n                         n_estimators=5000, min_sum_hessian_in_leaf=1, importance_type='gain',\n                         learning_rate=0.4, bagging_fraction=0.9, colsample_bytree=1.0,\n                         feature_fraction=0.1, lambda_l1=5.0, lambda_l2=3.0, max_depth=9,\n                         min_child_samples=55, min_child_weight=5.0, min_split_gain=0.1,\n                         num_leaves=4000, subsample = 0.75)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:03.31257Z","start_time":"2019-08-24T21:35:03.306618Z"},"trusted":true},"cell_type":"code","source":"classifiers = [('Random Forest', clf), ('XGBoost', xgb), ('ExtraTrees', xtr),\n              ('Logistic Regression', logr), ('LightGBM', lgbm)]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:05.060312Z","start_time":"2019-08-24T21:35:03.314917Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"# Iterate over the pre-defined list of classifiers\nfor clf_name, clf_algo in classifiers:    \n \n    # Fit clf to the training set\n    clf_algo.fit(X_train, y_train)    \n   \n    # Predict y_pred\n    y_pred = clf_algo.predict(X_test)\n    \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    cm = confusion_matrix(y_test, y_pred)\n   \n    # Evaluate clf's accuracy on the test set\n    print(f'name: {clf_name}')\n    print(classification_report(y_test, y_pred))\n    # Evaluate clf's accuracy on the test set \n    print(f'accuracy: {accuracy}')\n    print(f'precision: {precision}')\n    print(f'recall: {recall}')\n    print(f'confusion matrix: {cm}')\n    print('------------------------------')\n    \n    fig, ax = plt.subplots(figsize = (10,10))\n    y_prob = clf_algo.predict_proba(X_test)[::,1]\n    y_pred_proba = y_prob\n    fpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\n    auc_rand = roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr_rand,tpr_rand,label=f\"{clf_name}, AUC=\"+str(auc_rand))\n    plt.legend(loc=4)\n    plt.title('ROC Curve')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:06.15818Z","start_time":"2019-08-24T21:35:05.063481Z"},"trusted":true},"cell_type":"code","source":"# Import VotingClassifier from sklearn.ensemble\nfrom sklearn.ensemble import VotingClassifier\n\n# Instantiate a VotingClassifier vc\nvc = VotingClassifier(estimators=classifiers)     \n\n# Fit vc to the training set\nvc.fit(X_train, y_train)   \n\n# Evaluate the test set predictions\ny_pred = vc.predict(X_test)\n\n# Calculate accuracy score\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)\n\n\n# Evaluate clf's accuracy on the test set\nprint(f'name: Voting Classifier')\nprint(classification_report(y_test, y_pred))\n# Evaluate clf's accuracy on the test set \nprint(f'accuracy: {accuracy}')\nprint(f'precision: {precision}')\nprint(f'recall: {recall}')\nprint(f'confusion matrix: {cm}')\nprint('------------------------------')\n\nfig, ax = plt.subplots(figsize = (10,10))\ny_prob = clf_algo.predict_proba(X_test)[::,1]\ny_pred_proba = y_prob\nfpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\nauc_rand = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr_rand,tpr_rand,label=f\"{clf_name}, AUC=\"+str(auc_rand))\nplt.legend(loc=4)\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tuning"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:06.164671Z","start_time":"2019-08-24T21:35:06.160428Z"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom pprint import pprint","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:06.211593Z","start_time":"2019-08-24T21:35:06.203324Z"},"trusted":true},"cell_type":"code","source":"# Number of trees for tree ensambles\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 3)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(100, 200, num = 5)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [10, 20, 30]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [6, 8, 12]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:06.255817Z","start_time":"2019-08-24T21:35:06.236533Z"},"trusted":true},"cell_type":"code","source":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:59.164823Z","start_time":"2019-08-24T21:35:06.257786Z"},"trusted":true},"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\n# Random search of parameters, using 3 fold cross validation, \nrf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 20, \\\n                               cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:59.17344Z","start_time":"2019-08-24T21:35:59.167564Z"},"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:35:59.183183Z","start_time":"2019-08-24T21:35:59.176636Z"},"trusted":true},"cell_type":"code","source":"rf_params = rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBoost"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:36:18.028644Z","start_time":"2019-08-24T21:35:59.18535Z"},"trusted":true},"cell_type":"code","source":"parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              #'objective':['reg:linear'],\n              'learning_rate': [0.01, 0.1],\n              'max_depth': [6, 12], \n              'min_child_weight': [2, 6],\n              #'verbosity': [1],\n              'subsample': [1.0],\n              'colsample_bytree': [0.3, 0.5],\n              'gamma': [0],\n              'n_estimators': [100, 500, 1000]}\n\nxgb_rand = RandomizedSearchCV(xgb,\n                              parameters,\n                              cv = 3,\n                              n_jobs = -1,\n                              verbose=True)\n\nxgb_rand.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:36:18.036587Z","start_time":"2019-08-24T21:36:18.03082Z"},"trusted":true},"cell_type":"code","source":"xgb_rand.best_params_","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:36:18.045208Z","start_time":"2019-08-24T21:36:18.038501Z"},"trusted":true},"cell_type":"code","source":"xgb_params = xgb_rand.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Extra Randomized Trees"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:36:18.052279Z","start_time":"2019-08-24T21:36:18.047756Z"},"trusted":true},"cell_type":"code","source":"param_dist = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap\n             }","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:37:17.456265Z","start_time":"2019-08-24T21:36:18.058786Z"},"trusted":true},"cell_type":"code","source":"xtr_tune = RandomizedSearchCV(estimator = xtr, param_distributions = param_dist, n_iter = 50, \\\n                               cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nxtr_tune.fit(X_train, y_train)\nxtr_tune.best_params_","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:37:17.461374Z","start_time":"2019-08-24T21:37:17.458277Z"},"trusted":true},"cell_type":"code","source":"xtr_params = xtr_tune.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tuned Model"},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:37:17.470639Z","start_time":"2019-08-24T21:37:17.464088Z"},"trusted":true},"cell_type":"code","source":"#instantiate models\nseed = 42\nnew_clf = RandomForestClassifier(**rf_random.best_params_, random_state=seed)\nnew_xgb = XGBClassifier(**xgb_rand.best_params_, random_state=seed)\nnew_xtr = ExtraTreesClassifier(**xtr_tune.best_params_, random_state=seed)\nnew_lgbm = lgb.LGBMClassifier(drop_rate=0.9, min_data_in_leaf=800, max_bin=500,\n                         n_estimators=5000, min_sum_hessian_in_leaf=1, importance_type='gain',\n                         learning_rate=0.4, bagging_fraction=0.9, colsample_bytree=1.0,\n                         feature_fraction=0.1, lambda_l1=5.0, lambda_l2=3.0, max_depth=9,\n                         min_child_samples=55, min_child_weight=5.0, min_split_gain=0.1,\n                         num_leaves=4000, subsample = 0.75)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:37:17.479691Z","start_time":"2019-08-24T21:37:17.474246Z"},"trusted":true},"cell_type":"code","source":"classifiers = [('Random Forest', new_clf), ('XGBoost', new_xgb), ('ExtraTrees', new_xtr), ('LightGBM', new_lgbm)]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T21:37:22.545916Z","start_time":"2019-08-24T21:37:17.48854Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"# Iterate over the pre-defined list of classifiers\nfor clf_name, clf_algo in classifiers:    \n\n    # Fit clf to the training set\n    clf_algo.fit(X_train, y_train)    \n    \n    # Predict y_pred\n    y_pred = clf_algo.predict(X_test)\n          \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    cm = confusion_matrix(y_test, y_pred)\n    print(f'name: {clf_name}')\n    print(classification_report(y_test, y_pred))\n    # Evaluate clf's accuracy on the test set \n    print(f'accuracy: {accuracy}')\n    print(f'precision: {precision}')\n    print(f'recall: {recall}')\n    print(f'confusion matrix: {cm}')\n    fig, ax = plt.subplots(figsize = (10,10))\n    y_prob = clf_algo.predict_proba(X_test)[::,1]\n    y_pred_proba = y_prob\n    fpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\n    auc_rand = roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr_rand,tpr_rand,label=f\"{clf_name}, AUC=\"+str(auc_rand))\n    plt.legend(loc=4)\n    plt.title('ROC Curve')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-08-24T20:59:16.180466Z","start_time":"2019-08-24T20:59:10.095882Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"# Instantiate a VotingClassifier vc\nvc = VotingClassifier(estimators=classifiers, \n                      voting='soft', \n                      weights=[9,1,1,5]\n                     )\n\n# Fit vc to the training set\nvc.fit(X_train, y_train)   \n\n# Evaluate the test set predictions\ny_pred = vc.predict(X_test)\n\n# Calculate accuracy score\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)\nprint(f'Voting Classifier: ')\nprint(classification_report(y_test, y_pred))\n    # Evaluate clf's accuracy on the test set \nprint(f'accuracy: {accuracy}')\nprint(f'precision: {precision}')\nprint(f'recall: {recall}')\nprint(f'confusion matrix: {cm}')\nfig, ax = plt.subplots(figsize = (10,10))\ny_prob = vc.predict_proba(X_test)[::,1]\ny_pred_proba = y_prob\nfpr_rand, tpr_rand, _ = roc_curve(y_test,  y_pred_proba)\nauc_rand = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr_rand,tpr_rand,label=f\"Voting Classifier, AUC=\"+str(auc_rand))\nplt.legend(loc=4)\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"243px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}