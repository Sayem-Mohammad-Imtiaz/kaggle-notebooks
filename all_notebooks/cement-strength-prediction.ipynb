{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Cement Strength Prediction","metadata":{}},{"cell_type":"markdown","source":"### Data Description\n\nGiven is the variable name, variable type, the measurement unit and a brief description. \nThe concrete compressive strength is the regression problem. The order of this listing \ncorresponds to the order of numerals along the rows of the database. \n\n- Name -- Data Type -- Measurement -- Description\n\n- Cement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Blast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Fly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Water (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Superplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Coarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Fine Aggregate (component 7) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Age -- quantitative -- Day (1~365) -- Input Variable\n- Concrete compressive strength -- quantitative -- MPa -- Output Variable ","metadata":{}},{"cell_type":"code","source":"# necessary imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('ggplot')\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/concrete-compressive-strength/Concrete Compressive Strength.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Looks like there are no missing values in the data, let's check missing values**","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing missing values\n\nmsno.bar(df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (25, 20))\nplotnumber = 1\n\nfor col in df.columns:\n    if plotnumber <= 9: \n        ax = plt.subplot(3, 3, plotnumber)\n        sns.distplot(df[col])\n        plt.xlabel(col, fontsize = 15)\n        \n    plotnumber += 1\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating feature and label\n\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.var()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalizing features\n# let's add 1 to each value in everycolumn so that we don't get exception while calculating the log value of 0\n\nfor column in X.columns:\n    X[column] += 1\n    X[column] = np.log(X[column])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.var()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (25, 20))\nplotnumber = 1\n\nfor col in X.columns:\n    if plotnumber <= 8:\n        ax = plt.subplot(3, 3, plotnumber)\n        sns.distplot(X[col])\n        plt.xlabel(col, fontsize = 15)\n        \n    plotnumber += 1\n    \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now data is normalized and looks good, let's check for outliers.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 15))\nplotnumber = 1\n\nfor col in X.columns:\n    if plotnumber <= 8:\n        ax = plt.subplot(3, 3, plotnumber)\n        sns.boxplot(X[col])\n        plt.xlabel(col, fontsize = 15)\n    \n    plotnumber += 1\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's check how our features are related to the target column\n\nplt.figure(figsize = (20, 20))\nplotnumber = 1\n\nfor col in X.columns:\n    if plotnumber <= 8:\n        ax = plt.subplot(3, 3, plotnumber)\n        sns.scatterplot(df[col], y)\n        plt.xlabel(col, fontsize = 15)\n        \n    plotnumber += 1\n    \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking for correlation using heatmap\n\nplt.figure(figsize = (18, 10))\n\ncorr = X.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nsns.heatmap(data = corr, mask = mask, annot = True, fmt = '.2g', linewidths = 1, cbar = False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! None of column seem to be correlated.","metadata":{}},{"cell_type":"code","source":"# splitting data into training and test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scaling data\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lasso Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso, LassoCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lassocv = LassoCV(alphas = None, cv = 10, max_iter = 10000, normalize = True)\nlassocv.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso = Lasso(alpha = lassocv.alpha_)\nlasso.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndtr = DecisionTreeRegressor()\ndtr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtr.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtr.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyper Parameter Tuning Decision Tree Regressor\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_params = {\n    'criterion' : ['mse', 'friedman_mse', 'mae'],\n    'splitter' : ['best', 'random'],\n    'max_depth' : [3, 5, 7, 9, 10],\n    'min_samples_split' : [1, 2, 3, 4, 5],\n    'min_samples_leaf' : [1, 2, 3, 4, 5]\n}\n\ngrid_search = GridSearchCV(dtr, grid_params, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best parameters and best score\n\nprint(grid_search.best_params_)\nprint(grid_search.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtr = DecisionTreeRegressor(criterion = 'friedman_mse', max_depth = 10, min_samples_leaf = 1, min_samples_split = 2, splitter = 'random')\ndtr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtr.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtr.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ada Boost ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\n\nada = AdaBoostRegressor(base_estimator = dtr)\nada.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyper parameter tuning \n\ngrid_params = {\n    'n_estimators' : [40, 50, 80, 100],\n    'learning_rate' : [0.01, 0.1, 0.05, 0.5, 1, 10],\n    'loss' : ['linear','square', 'exponential']\n}\n\ngrid_search = GridSearchCV(ada, grid_params, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best parameters and best score\n\nprint(grid_search.best_params_)\nprint(grid_search.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada = AdaBoostRegressor(base_estimator = dtr, learning_rate = 1, loss = 'exponential', n_estimators = 100)\nada.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boost Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbr = GradientBoostingRegressor()\ngbr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbr.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbr.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyper parameter tuning of gradient boost regressor\n\ngrid_params = {\n    'n_estimators': [90, 100, 120, 180, 200],\n    'learning_rate' : [0.01, 0.1, 0.05, 0.5, 1],\n    'loss' : ['ls', 'lad', 'huber', 'quantile']\n}\n\ngrid_search = GridSearchCV(gbr, grid_params, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best parameters and best score\n\nprint(grid_search.best_params_)\nprint(grid_search.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbr = GradientBoostingRegressor(learning_rate = 0.5, loss = 'ls', n_estimators = 200)\ngbr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbr.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbr.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XgBoost Regressor","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(booster = 'gbtree', learning_rate = 0.1, max_depth = 7, n_estimators = 200)\nxgb.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Voting Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\n\nregressors = [('Linear Regression', lr), ('Lasso Regression', lasso), ('Decision Tree', dtr), ('Random Forest', rfr), ('Ada Boost', ada), ('Gradient Boost', gbr),\n              ('XgBoost', xgb)]\n\nvr = VotingRegressor(estimators = regressors, n_jobs = -1, verbose = 1, weights = (0.1, 0.1, 0.1, 0.2, 0.2, 0.7, 0.8))\nvr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vr.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vr.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = pd.DataFrame({\n    'Model' : ['Linear Regression', 'Lasso Regression', 'Decision Tree', 'Random Forest', 'Ada Boost', 'Gradient Boost', 'XgBoost', \"Voting Regressor\"],\n    'Score' : [lr.score(X_test, y_test), lasso.score(X_test, y_test), dtr.score(X_test, y_test), rfr.score(X_test, y_test), ada.score(X_test, y_test),\n               gbr.score(X_test, y_test), xgb.score(X_test, y_test), vr.score(X_test, y_test)]\n})\n\n\nmodels.sort_values(by = 'Score', ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 8))\n\nsns.barplot(x = 'Model', y = 'Score', data = models)\nplt.ylim(0.70, 1)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Great we get accuracy above 90% which is quite good.","metadata":{}},{"cell_type":"markdown","source":"#### If you like this kernel, Please do upvote","metadata":{}}]}