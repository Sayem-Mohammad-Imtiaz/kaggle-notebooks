{"cells":[{"metadata":{},"cell_type":"markdown","source":"I have implemented some newly gained data analysis and visualization skills on 'Data Analyst Jobs'\n\nYou can also check my similar work on:\n1. [Analysis of Data Engineer Jobs](https://www.kaggle.com/samruddhim/analysis-of-data-engineer-jobs)\n2. [Analysis of Data Scientist Jobs](https://www.kaggle.com/samruddhim/analysis-of-data-scientist-jobs)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Data Ananlysis on 'Data Analyst Jobs' Data Set.\n\n1. Data Cleaning\n2. Statistics\n3. Data Visulization\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the dataset\n\ndata_analyst_jobs = pd.read_csv('../input/data-analyst-jobs/DataAnalyst.csv')\ndata_analyst_jobs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_analyst_jobs.isnull().sum()) #checking for null values in the dataset\nprint(data_analyst_jobs.info()) #checking the general information of the dataset: non-null count, d-type, etc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Easy Apply'] = data_analyst_jobs['Easy Apply'].fillna(False).astype(bool) #As seen in dataset, Easy Apply column has -1 values, replacing them with boolean value False\ndata_analyst_jobs['Easy Apply'].value_counts() # Checking for value count of Easy Apply column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **1. Data Cleaning**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing unwanted columns\ndata_analyst_jobs.drop(['Unnamed: 0', 'Competitors', 'Easy Apply'], axis = 1, inplace = True) #Removing unwanted columns as they are not important for my further analysis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Replacing -1 with nan**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs.replace(['-1'], [np.nan], inplace=True)\ndata_analyst_jobs.replace(['-1.0'], [np.nan], inplace=True)\ndata_analyst_jobs.replace([-1], [np.nan], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs.isnull().sum()  #After replacing -1 with nan, we can see that there are null values in the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating separate columns of Salary Estimate as minimum and maximum salary**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_salary = data_analyst_jobs['Salary Estimate'].str.split(\"-\",expand=True,)\n\nminimum_salary = data_analyst_salary[0]\nminimum_salary = minimum_salary.str.replace('K',' ')\n\n\nmaximum_salary = data_analyst_salary[1].str.replace('(Glassdoor est.)', ' ')\nmaximum_salary = maximum_salary.str.replace('(', ' ')\nmaximum_salary = maximum_salary.str.replace(')', ' ')\nmaximum_salary = maximum_salary.str.replace('K', ' ')\n\nmaximum_salary = maximum_salary.str.replace('$', ' ').fillna(0).astype('int')\nminimum_salary = minimum_salary.str.replace('$', ' ').fillna(0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Minimum Salary'] = minimum_salary\ndata_analyst_jobs['Maximum Salary'] = maximum_salary\n\ndata_analyst_jobs.drop('Salary Estimate',axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Company Name'] = data_analyst_jobs['Company Name'].str.replace('\\n.*', ' ')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Making city and state columns for both Location and Headquaters**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Location = data_analyst_jobs['Location'].str.split(\",\",expand=True,)\nLocation_City = Location[0]\nLocation_State = Location[1]\ndata_analyst_jobs['Location City'] = Location_City\ndata_analyst_jobs['Location State'] = Location_State\ndata_analyst_jobs.drop('Location',axis = 1, inplace = True)\n\nHQ = data_analyst_jobs['Headquarters'].str.split(\",\",expand=True)\nHeadquarters_City = HQ[0]\nHeadquarters_State = HQ[1]\ndata_analyst_jobs['Headquarters City'] = Headquarters_City\ndata_analyst_jobs['Headquarters State'] = Headquarters_State\ndata_analyst_jobs.drop('Headquarters',axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Separating department and from job title column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"department = data_analyst_jobs['Job Title'].str.split(',', expand = True)\n#data_analyst_jobs['Job Title'], data_analysu_jobs['Department']\ndata_analyst_jobs['Job Title'], data_analyst_jobs['Department'] = department[0],department[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since, department has too many missing values (2023/2253), it can be dropped.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs.drop('Department',1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Job Title'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Job Title'] = data_analyst_jobs['Job Title'].str.replace('Sr.', 'Senior')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking values from the columns for cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Type of ownership'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Industry'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Sector'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the Revenue column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].replace('Unknown / Non-Applicable', None)\n# data['Revenue']=data['Revenue'].replace('Unknown / Non-Applicable', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('$', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('(USD)', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('(', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace(')', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace(' ', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('2to5billion', '2billionto5billion')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('5to10billion ', '5billionto10billion ')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].replace('million', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].replace('10+billion', '10billionto11billion')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('Lessthan1million', '0millionto1million')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('million', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('billion', '000 ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Revenue = data_analyst_jobs['Revenue'].str.split(\"to\",expand=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Revenue[0].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Revenue[1].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Revenue'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating two separate columns of Revenue as Minimum and Maximum Revenue**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Minimum Revenue'] = Revenue[0]\ndata_analyst_jobs['Maximum Revenue'] = Revenue[1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Maximum Revenue'] = pd.to_numeric(data_analyst_jobs['Maximum Revenue'])\ndata_analyst_jobs['Minimum Revenue'] = pd.to_numeric(data_analyst_jobs['Minimum Revenue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs.drop('Revenue',1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the Size column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Size'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Size'] = data_analyst_jobs['Size'].str.replace('employees', '')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Size'] = data_analyst_jobs['Size'].str.replace('+', 'plus')\ndata_analyst_jobs['Size'] = data_analyst_jobs['Size'].replace('Unknown', None)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Size'] = data_analyst_jobs['Size'].str.replace('10000plus', '10000 to 10001')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size = data_analyst_jobs['Size'].str.split(\"to\",expand=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating separate columns of Size as minimum and maximum size**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Minimum Size'] = size[0]\ndata_analyst_jobs['Maximum Size'] = size[1]\ndata_analyst_jobs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs.drop('Size',1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def contains_word(s, w):\n#     return f' {w} ' in f' {s} '\n\n# # def rev(text):\n# #     #if contains_word(text,'billion') is True:\n# #     text.str.replace('billion','')\n         \n# #     return text\n\n# def revenue(text):\n#     if contains_word(text,'billion') is True:\n#         max_rev = float(data_analyst_jobs['Maximum Revenue'].replace(\"billion\", \" \").strip())*1000\n#         #revenue = float(maxRev[0].replace('+','').strip())*100\n#     return max_rev\n\n# data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].apply(lambda text: clean_revenue(text))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Statistics","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Distribution of minimum and maximum salary of all Data Analyst job titles","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\nsns.despine(left=True)\nsns.distplot(data_analyst_jobs['Minimum Salary'],color = 'r',ax = axes[0])\nsns.distplot(data_analyst_jobs['Maximum Salary'],ax = axes[1])\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for outliers in Company Ratings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = data_analyst_jobs['Rating']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Minimum Size'] = data_analyst_jobs['Minimum Size'].astype('float')\ndata_analyst_jobs['Maximum Size'] = data_analyst_jobs['Maximum Size'].astype('float')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for outliers in company size","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2, figsize=(20, 5), sharex=True)\nsns.boxplot(x = data_analyst_jobs['Minimum Size'], ax = axes[0],palette='Set1');\nsns.boxplot(x = data_analyst_jobs['Maximum Size'], ax = axes[1],palette='Set2');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Visualization# ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,10))\nsplot = sns.barplot(x=data_analyst_jobs['Job Title'].value_counts()[0:20].index,y=data_analyst_jobs['Job Title'].value_counts()[0:20], palette = 'winter_r')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Job Title',fontsize=15)\nplt.ylabel('Job Count',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=15)\nplt.title('Top 20 Job Title Counts',fontsize=25);\n\n# for index, row in data_analyst_jobs.iterrows():\n#     splot.text(row.name,row.tip, round('Job Title',2), color='black', ha=\"center\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,15))\nsplot = sns.barplot(x = data_analyst_jobs['Company Name'][0:20], y = data_analyst_jobs['Maximum Revenue'][0:20], data = data_analyst_jobs, palette = 'spring')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\n\nplt.xlabel('Company Name',fontsize=15)\nplt.ylabel('Maximum revenue in million dollars',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Maximum Revenue of top 20 Companies',fontsize=25);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating 'Average Revenue' column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Average Revenue'] = data_analyst_jobs[['Minimum Revenue','Maximum Revenue']].mean(axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_rev = data_analyst_jobs['Average Revenue'][0:20]\navg_rev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(20,15))\nsplot = sns.barplot(x = data_analyst_jobs['Company Name'][0:20], y = data_analyst_jobs['Average Revenue'][0:20], data = data_analyst_jobs, palette = 'summer')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Company Name')\nplt.ylabel('Average revenue in million dollars')\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Average Revenue of top 20 Companies',fontsize=25);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data_analyst_jobs.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 cities', barmode = 'group')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data_analyst_jobs.groupby('Job Title')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 job titles', barmode = 'stack')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_analyst_jobs['Average Salary'] = data_analyst_jobs[['Minimum Salary', 'Maximum Salary']].mean(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(data_analyst_jobs, x=data_analyst_jobs['Rating'], y= data_analyst_jobs['Average Salary'])\nfig.update_layout(title = 'Relation between average salary and rating of companies')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data_analyst_jobs.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).head(25)\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(x=data2['Average Revenue'], y=data2.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3 = data_analyst_jobs.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).tail(25)\ndata3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(x=data3['Average Revenue'], y=data3.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data4 = pd.DataFrame(data_analyst_jobs['Sector'].value_counts())\ndata4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.pie(data4, values=data4['Sector'], names=data4.index)\nfig.update_layout(title = 'Percentage of Different Sectors with requirement of Data Analyst Roles')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data5 = pd.DataFrame(data_analyst_jobs['Industry'].value_counts().head(25))\ndata5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.pie(data5, values=data5['Industry'], names=data5.index)\nfig.update_layout(title = 'Percentage of top 25 Industries with requirement of Data Analyst Roles')\nfig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data6 = pd.DataFrame(data_analyst_jobs['Type of ownership'].value_counts())\ndata6\n\nimport plotly.express as px\nfig = px.pie(data6, values=data6['Type of ownership'], names=data6.index)\nfig.update_layout(title = 'Type of ownership')\nfig.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data7 = pd.DataFrame(data_analyst_jobs['Headquarters City'].value_counts().head(25))\ndata7\n\nimport plotly.express as px\nfig = px.pie(data7, values=data7['Headquarters City'], names=data7.index)\nfig.update_layout(title = 'Top 25 Headquarter City')\nfig.show()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data8 = pd.DataFrame(data_analyst_jobs['Location City'].value_counts().head(25))\ndata8\n\nimport plotly.express as px\nfig = px.pie(data8, values=data8['Location City'], names=data8.index)\nfig.update_layout(title = 'Top 25 Job Locations')\nfig.show()\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Word Cloud of Job Titles**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,15))\nwc = WordCloud()\ntext = data_analyst_jobs['Job Title']\nwc.generate(str(' '.join(text)))\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import nltk\n# from nltk.corpus import stopwords\n# import re\n# from nltk.stem.porter import PorterStemmer\n# print(stopwords.words('english'))\n\n# stop_words = set(stopwords.words('english'))\n# jobdes = data_analyst_jobs['Job Description'].to_csv()\n# jobdes = jobdes.split(' ')\n# jobdes = jobdes.lower()\n# jobdes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# skills = ['python', 'java','c', 'r','c++', 'hadoop', 'communication']\n\n# for word in all_words:\n#     print(word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_map = data_analyst_jobs.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_map = usa_map.reset_index()\nusa_map.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = usa_map['Location City']\ncities.head(20)\n\n['Daly City','Marin City', 'Los Gatos', 'Berkeley', 'San Jose', 'Cupertino','Santa Clara', 'Pico Rivera', 'Whittier','Far Rockaway', 'Secaucus', 'Sunnyvale', 'Menlo Park', 'Elk Grove Village', 'Glenview', 'Maywood', 'Northfield', 'Stanford', 'San Francisco', 'El Cajon']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a new DataFrame 'use_maps' consisting of 'Location State', 'Minimum Salary' and 'Maximum Salary' columns for ploting choropleth map for top 20 states with maximum salary.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_maps = data_analyst_jobs.groupby('Location State')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_maps = usa_maps.reset_index()\n\nusa_maps = usa_maps.drop([3, 0])\nusa_maps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.choropleth(locations= ['AZ','NJ','NY','CO','IL','NC','VA','SC','WA','PA','DE','TX','KS','FL','IN','OH','GA','UT'], \n                    locationmode=\"USA-states\", \n                    color=[94.494845, 90.232558, 89.026087, 89.022727, 88.829268,85.233333, 85.125000, 83.000000, 82.759259, 77.824561, 75.909091, 74.116751, 67.000000, 66.666667, 61.000000, 58.800000, 56.000000, 48.454545],\n                    labels={'color':'Maximum Salary', 'locations':'State'},\n                    scope=\"usa\") \n\n\nfig.update_layout(\n    \n    title_text = 'Top 20 States with Maximum Salary',\n    geo_scope='usa'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**If you like my notebook, give it an upvote! Suggestions for improvements are welcomed!**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}