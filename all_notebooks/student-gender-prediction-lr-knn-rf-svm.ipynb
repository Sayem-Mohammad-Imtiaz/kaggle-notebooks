{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nIn this notebook, we will try to predict the gender of a student based on their socio economic status, family background, as well as their scores in math, writing and reading. Below are the steps that we will be performing:\n\n1. Exploratory Data Analytics\n    * Checking for missing values\n    * Visualization of variables & correlations\n2. Data Engineering\n    * Converting qualitative variables to dummy variables\n    * Standardizing quantitative variables\n3. Data Modelling with:\n    * Logistic Regression\n    * K Nearest Neighbours\n    * Random Forest\n    * SVM\n4. Additional Findings\n5. Comparison and Conclusion\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport statsmodels.formula.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"students = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analytics\n\nWe first take a look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"students.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataframe columns are renamed for easier accessibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"students.columns = \"gender\",\"race\",\"parental_edu\",\"lunch\",\"test_prep\",\"math\",\"reading\",\"writing\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also check if there are any missing data in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"students.isna().sum()\n# No missing data in this dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We then plot bar plots and histograms to visualize the distribution of the data for each variable"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, axs = plt.subplots(3,3,figsize=(15,15))\nstudents['gender'].value_counts().plot(kind='bar', ax=axs[0,0])\naxs[0,0].title.set_text('Gender')\nstudents['race'].value_counts().plot(kind='bar', ax=axs[0,1])\naxs[0,1].title.set_text('Race')\nstudents['parental_edu'].value_counts().plot(kind='bar', ax=axs[0,2])\naxs[0,2].title.set_text('Parental Education')\nstudents['lunch'].value_counts().plot(kind='bar', ax=axs[1,0])\naxs[1,0].title.set_text('Lunch')\nstudents['test_prep'].value_counts().plot(kind='bar', ax=axs[1,1])\naxs[1,1].title.set_text('Test Prep')\naxs[1,2].hist(students['math'])\naxs[1,2].title.set_text('Math')\naxs[2,0].hist(students['reading'])\naxs[2,0].title.set_text('Readiing')\naxs[2,1].hist(students['writing'])\naxs[2,1].title.set_text('Writing')\n\nf.delaxes(axs[2][2])\nf.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, we observe the following regarding the data:\n* Qualitative variables are distributed rather evenly between the classes, with no sparse classes. \n* Quantitative variables 'Math', 'Reading', and 'Writing' have a relatively normal distribution. Besides that, they have also taken on acceptable values within the range of 0 to 100\n* However, it is worth noting that in the variable \"Parental Education\", the variable has the values \"some college\" and \"some high school\" which may be a repetition of other values in the variable. We will keep them for now, but depending on the model outcome, we may merge some values to see if we get better results"},{"metadata":{},"cell_type":"markdown","source":"Besides that, we also study the relationship between the quantitative variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(students.iloc[:,:])\nstudents.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, it can be observed that the 3 score variables are quite highly correlated, with highest correlation between reading & writing. As this may affect the model output, we may remove certain variables during modelling or combine them during the data modelling stage"},{"metadata":{},"cell_type":"markdown","source":"# Data & Feature Engineering\nAs the columns \"gender\", \"race\", \"parental_edu\", \"lunch\" and \"test_prep\" are qualitative variables, we will create dummy variables for them, removing 1 dummy variable for each variable to prevent dummy trap (multi-collinearity problems)\n\nWe then concatenate the dummy variables with the original dataset, and remove the original variable, we will store this as a new dataframe students_d"},{"metadata":{"trusted":true},"cell_type":"code","source":"dum_gender = pd.get_dummies(students.gender, prefix='gender', prefix_sep='_')\ndum_gender.drop('gender_female', inplace=True, axis=1)\n\ndum_race = pd.get_dummies(students.race, prefix='race', prefix_sep='_')\ndum_race.columns = \"race_A\", \"race_B\", \"race_C\", \"race_D\", \"race_E\"\ndum_race.drop('race_E', inplace=True, axis=1)\n\ndum_parental_edu = pd.get_dummies(students.parental_edu, prefix='parental_edu', prefix_sep='_')\ndum_parental_edu.columns = \"parental_edu_associate\", \"parental_edu_bachelor\", \"parental_edu_hs\", \"parental_edu_masters\", \"parental_edu_somecollege\", \"parental_edu_somehs\"\ndum_parental_edu.drop('parental_edu_somehs', inplace=True, axis=1)\n\ndum_lunch = pd.get_dummies(students.lunch, prefix='lunch', prefix_sep='_')\ndum_lunch.drop('lunch_free/reduced', inplace=True, axis=1)\n\ndum_test_prep = pd.get_dummies(students.test_prep, prefix='test_prep', prefix_sep='_')\ndum_test_prep.drop('test_prep_none', inplace=True, axis=1)\n\nstudents_d = pd.concat([students, dum_gender, dum_race, dum_parental_edu, dum_lunch, dum_test_prep], axis=1)\nstudents_d.drop(['gender', 'race', 'parental_edu', 'lunch', 'test_prep'], inplace=True, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we will be using distance based algorithms to model this problem (i.e. K nearest neighbours), we will perform feature scaling to scale the quantitative variables to be between the ranges 0 and 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"def norm_func(i):\n    x = (i-i.min())\t/ (i.max()-i.min())\n    return (x)\n\nstudents_d = norm_func(students_d.iloc[:,:]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gender Prediction\n\nFor gender prediction, we will try and compare several models, namely:\n1. Logistic Regression\n2. K-Nearest Neighbours\n3. Random Forest\n4. SVM"},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Model\n\nFor model validation, we will use validation set approach. For this, we first perform a train-test split on the data in the ratio of 70:30"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data,test_data = train_test_split(students_d, test_size = 0.3) # 30% test data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We then perform logistic regression using all the initial variables from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_model = sm.logit('gender_male ~ math+reading+writing+race_A+race_B+race_C+race_D+parental_edu_associate+parental_edu_bachelor+parental_edu_hs+parental_edu_masters+parental_edu_somecollege+lunch_standard+test_prep_completed', data = train_data).fit()\n\nlogit_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, we can see that some of the P-Values are rather high, meaning they are not statistically significant. Besides that, the R-squared value of the model is also not too great, below 0.85.\n\nEither way, we will use the model for validation on the train & test set to have an idea of the model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_train = logit_model.predict(pd.DataFrame(train_data))\npredict_test = logit_model.predict(pd.DataFrame(test_data))\n\ncnf_test_matrix = confusion_matrix(test_data['gender_male'], predict_test > 0.5 )\nprint(\"test set confusion matrix: \\n\", cnf_test_matrix)\n\nprint(\"test set accuracy: \", accuracy_score(test_data.gender_male, predict_test > 0.5), \"\\n\")\n\n# Error on train data\ncnf_train_matrix = confusion_matrix(train_data['gender_male'], predict_train > 0.5 )\nprint(\"train set confusion matrix: \\n\", cnf_train_matrix)\n\nprint(\"train set accuracy: \", accuracy_score(train_data.gender_male, predict_train > 0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the output, it can be seen that the model performs well on the test data, with accuracy of ~0.9. \n\nAdditionally, based on the confusion matrix, we also observe that the predictions of the model is also quite balanced, with approximately equal predictions of both classes\n\nWe will try to further improve the logistic regression model. We do this by first performing VIF on the data to determine any multi-collinearity within the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\n\nX = students_d.drop('gender_male', axis=1)\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\n\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected from the pairplot earlier, reading and writing are highly correlated. Thus, we will remove reading and calculate the VIF scores again"},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\n\nX = students_d.drop(['gender_male','reading'], axis=1)\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\n\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even after removing the variable 'reading', the VIF scores of math and writing are still high. Thus, rather than removing writing and relying only on math scores, it may be a better approach to average the 3 scores for model building.\n\nWe will attempt to build a model with this approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_model = sm.logit('gender_male ~ I(math+reading+writing/3)+race_A+race_B+race_C+race_D+parental_edu_associate+parental_edu_bachelor+parental_edu_hs+parental_edu_masters+parental_edu_somecollege+lunch_standard+test_prep_completed', data = train_data).fit()\n\nlogit_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_train = logit_model.predict(pd.DataFrame(train_data))\npredict_test = logit_model.predict(pd.DataFrame(test_data))\n\ncnf_test_matrix = confusion_matrix(test_data['gender_male'], predict_test > 0.5 )\nprint(\"test set confusion matrix: \\n\", cnf_test_matrix)\n\nprint(\"test set accuracy: \", accuracy_score(test_data.gender_male, predict_test > 0.5), \"\\n\")\n\n# Error on train data\ncnf_train_matrix = confusion_matrix(train_data['gender_male'], predict_train > 0.5 )\nprint(\"train set confusion matrix: \\n\", cnf_train_matrix)\n\nprint(\"train set accuracy: \", accuracy_score(train_data.gender_male, predict_train > 0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the extremely low R-squared score and test & train accuracies, it is evident that we may have removed some key predictors of gender and oversimplified the relationship between the 3 score variables.\n\nThus, we hypothesize that there may be interaction terms between the score variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_model = sm.logit('gender_male ~ I(reading*writing)+math+reading+writing+race_A+race_B+race_C+race_D+parental_edu_associate+parental_edu_bachelor+parental_edu_hs+parental_edu_masters+parental_edu_somecollege+lunch_standard+test_prep_completed', data = train_data).fit()\n\nlogit_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_train = logit_model.predict(pd.DataFrame(train_data))\npredict_test = logit_model.predict(pd.DataFrame(test_data))\n\ncnf_test_matrix = confusion_matrix(test_data['gender_male'], predict_test > 0.5 )\nprint(\"test set confusion matrix: \\n\", cnf_test_matrix)\n\nprint(\"test set accuracy: \", accuracy_score(test_data.gender_male, predict_test > 0.5), \"\\n\")\n\n# Error on train data\ncnf_train_matrix = confusion_matrix(train_data['gender_male'], predict_train > 0.5 )\nprint(\"train set confusion matrix: \\n\", cnf_train_matrix)\n\nprint(\"train set accuracy: \", accuracy_score(train_data.gender_male, predict_train > 0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the model summary, we can see that the newly added interaction term has a low P-value, meaning that it is statistically significant. Besides that, the R-squared of the model has also increased slightly from before.\n\nBased on the confusion matrix & accuracies, it is clear that this model is more accurate than the previous ones\n\nNote that the variable 'reading' is retained even though it has a high P-value. This is due to the hierarchical principle, stating that if we include interaction terms in the model, we should also include main effects even if their P-value is not significant\n\nWe will try to further improve the model by removing some variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_model = sm.logit('gender_male ~ I(reading*writing)+math+reading+writing+race_A+race_B+race_C+race_D+lunch_standard+test_prep_completed', data = train_data).fit()\n\nlogit_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_train = logit_model.predict(pd.DataFrame(train_data))\npredict_test = logit_model.predict(pd.DataFrame(test_data))\n\ncnf_test_matrix = confusion_matrix(test_data['gender_male'], predict_test > 0.5 )\nprint(\"test set confusion matrix: \\n\", cnf_test_matrix)\n\nprint(\"test set accuracy: \", accuracy_score(test_data.gender_male, predict_test > 0.5), \"\\n\")\n\n# Error on train data\ncnf_train_matrix = confusion_matrix(train_data['gender_male'], predict_train > 0.5 )\nprint(\"train set confusion matrix: \\n\", cnf_train_matrix)\n\nprint(\"train set accuracy: \", accuracy_score(train_data.gender_male, predict_train > 0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After trying out removal of various variables, it is found that removing the variable 'parental education' results in a slight increase in accuracy, with a decrease in complexity. Thus, we will remove this variable.\n\nSeveral transformations were also tried, with no further increase in accuracy. Thus, this will be the final logistic regression model.\n\nWe will store the final accuracy values for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_test_acc = accuracy_score(test_data.gender_male, predict_test > 0.5)\nlog_train_acc = accuracy_score(train_data.gender_male, predict_train > 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K Nearest Neighbours\n\nWe will utilize the same train & test split data to model for K nearest neighbours. Since all the variables have already been scaled to be between 0 & 1, we can begin modelling immediately\n\nNote that hyperparameter tuning for the value of k has already been done, and only the best value of k is displayed"},{"metadata":{},"cell_type":"markdown","source":"Splitting traing & test dataset into predictor and target"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_data.drop(['gender_male'], axis=1)\ntrain_Y = train_data.loc[:,'gender_male']\ntest_X = test_data.drop(['gender_male'], axis=1)\ntest_Y = test_data.loc[:,'gender_male']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=25)\nknn.fit(train_X,train_Y)\n\nprint(\"For test data: \\n\")\npred = knn.predict(test_X)\nprint(pd.crosstab(test_Y, pred, rownames=['Actual'],colnames= ['Predictions']))\nprint(\"Test accuracy:\", accuracy_score(test_Y, pred))\n\nprint(\"\\nFor training data: \\n\")\npred_train = knn.predict(train_X)\nprint(pd.crosstab(train_Y, pred_train, rownames=['Actual'],colnames= ['Predictions']))\nprint(\"Training accuracy:\", accuracy_score(train_Y, pred_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this first run, the accuracies of the KNN model is quite low. We will try to remove some variables to try to improve the accuracy of the model. We start by removing parental education, as it was deemed statistically insignificant in the logistic regression model as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(train_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1), train_Y)\n\nprint(\"For test data: \\n\")\npred = knn.predict(test_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1))\nprint(pd.crosstab(test_Y, pred, rownames=['Actual'],colnames= ['Predictions']))\nprint(\"Test accuracy:\", accuracy_score(test_Y, pred))\n\nprint(\"\\nFor training data: \\n\")\npred_train = knn.predict(train_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1))\nprint(pd.crosstab(train_Y, pred_train, rownames=['Actual'],colnames= ['Predictions']))\nprint(\"Training accuracy:\", accuracy_score(train_Y, pred_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy has increased quite significantly. In fact, we find that using only the scores for the variables 'math', 'reading', and 'writing', we are able to obtain the best prediction accuracies, as shown below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=20)\nknn.fit(train_X.drop(['race_A', 'race_B', 'race_C', 'race_D','test_prep_completed','lunch_standard','parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1), train_Y)\n\nprint(\"For test data: \\n\")\npred = knn.predict(test_X.drop(['race_A', 'race_B', 'race_C', 'race_D', 'test_prep_completed','lunch_standard','parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1))\nprint(pd.crosstab(test_Y, pred, rownames=['Actual'],colnames= ['Predictions']))\nprint(\"Test accuracy:\", accuracy_score(test_Y, pred))\n\nprint(\"\\nFor training data: \\n\")\npred_train = knn.predict(train_X.drop(['race_A', 'race_B', 'race_C', 'race_D','test_prep_completed','lunch_standard','parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1))\nprint(pd.crosstab(train_Y, pred_train, rownames=['Actual'],colnames= ['Predictions']))\nprint(\"Training accuracy:\", accuracy_score(train_Y, pred_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will store the final accuracy values for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_test_acc = accuracy_score(test_Y, pred)\nknn_train_acc = accuracy_score(train_Y,pred_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest\nWe will utilize the same train & test split data to model for random forest\n\nNote that hyperparameter tuning for the number of trees in forest has already been done, and only the best value is displayed"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=2, n_estimators=35, criterion=\"entropy\")\n\nrf.fit(train_X, train_Y)\n\nprint(\"For test data: \\n\")\npred = rf.predict(test_X)\nprint(pd.crosstab(test_Y, pred, rownames = ['Actual'], colnames = ['Predictions']))\nprint(\"Test accuracy:\", accuracy_score(test_Y,pred))\n\nprint(\"\\nFor training data: \\n\")\npred_train = rf.predict(train_X)\nprint(pd.crosstab(train_Y, pred_train, rownames = ['Actual'], colnames = ['Predictions']))\nprint(\"Training accuracy:\", accuracy_score(train_Y,pred_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will try removing variables to improve model accuracy. We will start by removing the variables 'parental education'"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=2, n_estimators=200, criterion=\"entropy\")\n\nrf.fit(train_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1), train_Y)\n\nprint(\"For test data: \\n\")\npred = rf.predict(test_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1))\nprint(pd.crosstab(test_Y, pred, rownames = ['Actual'], colnames = ['Predictions']))\nprint(\"Test accuracy:\", accuracy_score(test_Y,pred))\n\nprint(\"\\nFor training data: \\n\")\npred_train = rf.predict(train_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'], axis=1))\nprint(pd.crosstab(train_Y, pred_train, rownames = ['Actual'], colnames = ['Predictions']))\nprint(\"Training accuracy:\", accuracy_score(train_Y,pred_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the accuracy does not differ much from removal of the variable. I have also tried performing pruning on the decision trees to further improve the performance, with not much difference in accuracy.\n\nWe will store the final accuracy values for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_test_acc = accuracy_score(test_Y, pred)\nrf_train_acc = accuracy_score(train_Y,pred_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM\n\nWe will utilize the same train & test split data to model for SVM\n\nWe will model the data for the following kernels to select the best one: \n* Linear\n* Polynomial\n* Sigmoid\n* Gaussian (rbf)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# kernel = linear\nmodel_linear = SVC(kernel=\"linear\")\nmodel_linear.fit(train_X, train_Y)\npred_test_linear = model_linear.predict(test_X)\npred_train_linear = model_linear.predict(train_X)\n\n# kernel = poly\nmodel_poly = SVC(kernel=\"poly\")\nmodel_poly.fit(train_X, train_Y)\npred_test_poly = model_poly.predict(test_X)\npred_train_poly = model_poly.predict(train_X)\n\n# kernel = sigmoid\nmodel_sigmoid = SVC(kernel=\"sigmoid\")\nmodel_sigmoid.fit(train_X, train_Y)\npred_test_sigmoid = model_sigmoid.predict(test_X)\npred_train_sigmoid = model_sigmoid.predict(train_X)\n\n# kernel = rbf\nmodel_rbf = SVC(kernel=\"rbf\")\nmodel_rbf.fit(train_X, train_Y)\npred_test_rbf = model_rbf.predict(test_X)\npred_train_rbf = model_rbf.predict(train_X)\n\ndata = {\"kernel\":pd.Series([\"linear\",\"polynomial\",\"sigmoid\",\"rbf\"]),\"Test Accuracy\":pd.Series([accuracy_score(test_Y, pred_test_linear),accuracy_score(test_Y, pred_test_poly),accuracy_score(test_Y, pred_test_sigmoid),accuracy_score(test_Y, pred_test_rbf)])}\ntable_acc=pd.DataFrame(data)\ntable_acc\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, it can be seen that the linear kernel gives the best test accuracy.\n\nNext, we will try removing variables to further improve model accuracy. We will start by removing the variables 'parental education'"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'],axis=1)\ntest_X = test_X.drop(['parental_edu_associate', 'parental_edu_bachelor', 'parental_edu_hs', 'parental_edu_masters', 'parental_edu_somecollege'],axis=1)\n\n# kernel = linear\nmodel_linear = SVC(kernel=\"linear\")\nmodel_linear.fit(train_X, train_Y)\npred_test_linear_dropped = model_linear.predict(test_X)\npred_train_linear_dropped = model_linear.predict(train_X)\n\n# kernel = poly\nmodel_poly = SVC(kernel=\"poly\")\nmodel_poly.fit(train_X, train_Y)\npred_test_poly_dropped = model_poly.predict(test_X)\npred_train_poly_dropped = model_poly.predict(train_X)\n\n# kernel = sigmoid\nmodel_sigmoid = SVC(kernel=\"sigmoid\")\nmodel_sigmoid.fit(train_X, train_Y)\npred_test_sigmoid_dropped = model_sigmoid.predict(test_X)\npred_train_sigmoid_dropped = model_sigmoid.predict(train_X)\n\n# kernel = rbf\nmodel_rbf = SVC(kernel=\"rbf\")\nmodel_rbf.fit(train_X, train_Y)\npred_test_rbf_dropped = model_rbf.predict(test_X)\npred_train_rbf_dropped = model_rbf.predict(train_X)\n\ndata = {\"kernel\":pd.Series([\"linear\",\"polynomial\",\"sigmoid\",\"rbf\"]),\"Test Accuracy\":pd.Series([accuracy_score(test_Y, pred_test_linear_dropped),accuracy_score(test_Y, pred_test_poly_dropped),accuracy_score(test_Y, pred_test_sigmoid_dropped),accuracy_score(test_Y, pred_test_rbf_dropped)]),\"Train Accuracy\":pd.Series([accuracy_score(train_Y, pred_train_linear_dropped),accuracy_score(train_Y, pred_train_poly_dropped),accuracy_score(train_Y, pred_train_sigmoid_dropped),accuracy_score(train_Y, pred_train_rbf_dropped)])}\ntable_acc=pd.DataFrame(data)\ntable_acc\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be observed that removing variables does not result in an increase in accuracies. Removal of other variables have also been tested, similarly with no increase in accuracy\n\nWe will try tuning the hyperparameters for the SVM. We will use a randomized search to find the best estimator\n\nNote that a randomized search is used to have a good estimate of the hyperparameters, while reducing computation time"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import reciprocal, uniform\n\nsvm_clf=SVC()\nparam_distributions = {\"kernel\":('linear','poly','rbf'), \"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\nrnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2, cv=3)\nrnd_search_cv.fit(train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best estimator: \",rnd_search_cv.best_estimator_)\n\npredicted = rnd_search_cv.predict(test_X)\nrnd_test_acc = accuracy_score(test_Y,predicted)\nprint(\"test accuracy: \", rnd_test_acc)\n\npredicted_train = rnd_search_cv.predict(train_X)\nrnd_train_acc = accuracy_score(train_Y,predicted_train)\nprint(\"train accuracy: \", rnd_train_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, we see that there is not much difference from the initial SVM predictions.\n\nWe will store the highest final test accuracy value for final tabulation and comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"if (table_acc.iloc[:,1].idxmax() > rnd_test_acc):\n    svm_best = table_acc.iloc[:,1].idxmax()\n    svm_test_acc = table_acc.iloc[svm_best,1]\n    svm_train_acc = table_acc.iloc[svm_best,2]\nelse: \n    svm_test_acc = rnd_test_acc\n    svm_train_acc = rnd_train_acc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Additional Findings\n\nBased on the models built, it is observed that student scores in math, writing and reading are a significant predictor of their gender. Thus, we are also interested to verify this by directly comparing their scores.\n\nWe will compare male and female students average scores in math, reading, writing and overall score."},{"metadata":{"trusted":true},"cell_type":"code","source":"students[\"average_score\"] = students.loc[:,['math','reading','writing']].mean(axis=1).round(1)\nstudents\n\nstudents.loc[:,['gender','math','writing','reading','average_score']].groupby(['gender']).mean().transpose().plot.bar()\nplt.title('Comparison of Student Scores Between Genders')\nplt.xlabel('Subject')\nplt.ylabel('Score')\nplt.legend(loc='lower right')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be observed from the plot that on average male students score higher in math, whereas female students score higher in writing, reading, and have higher overall scores"},{"metadata":{},"cell_type":"markdown","source":"# Comparison and Conclusion\n\nWe will tabulate the test & train accuracies for the 4 algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\"Model\":pd.Series([\"Logistic Regression\",\"K Nearest Neighbour\",\"Random Forest\",\"SVM\"]),\"Test Accuracy\":pd.Series([log_test_acc,knn_test_acc,rf_test_acc,svm_test_acc]),\"Train Accuracy\":pd.Series([log_train_acc,knn_train_acc,rf_train_acc,svm_train_acc])}\ntable_final=pd.DataFrame(data)\ntable_final\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this, it can be seen that logistic regression and SVM have the highest accuracies. \n\nIt is proposed that logistic regression be used as the final model, due to advantages in terms of:\n* Interpretability as logistic regression provides a formula, with relative weightage of variables. The probability of each class is also provided\n* Simplicity as the logistic regression model built uses less number of variables"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}