{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Prepare Workspace"},{"metadata":{},"cell_type":"markdown","source":"#### Reference: \"Approaching (almost) Any Machine Learning Problem\", by Abhishek Thakur"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n# for statistics\nimport statistics as st \nimport scipy.stats as stats\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/mobile-price-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Have a look of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check missing values both to numeric features and categorical features \nmissing = train.isnull().sum()/train.shape[0]*100\nmissing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data set between target variable and features\nX_full = train.copy()\ny = X_full.price_range\nX_full.drop(['price_range'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Variable Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarize the class distribution \ncount = pd.crosstab(index = y, columns=\"count\")\npercentage = pd.crosstab(index = y, columns=\"frequency\")/pd.crosstab(index = y, columns=\"frequency\").sum()\npd.concat([count, percentage], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the target variable\nax = sns.countplot(x=y, data=X_full).set_title(\"Target Variable Distribution\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Zero/Close Zero Variance Predictors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find features with variance equal zero or lower than 0.05\nto_drop = [col for col in X_full.columns if np.var(X_full[col]) < 0.05]\nto_drop","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlated Predictors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation heatmap\ncorr_matrix = X_full.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set( rc = {'figure.figsize': (15, 15)})\nsns.heatmap(corr_matrix, square = True, annot=True, fmt='.2f')\nplt.title('Correlation Heatmap on data set',size=15)\nplt.yticks(fontsize=\"13\")\nplt.xticks(fontsize=\"13\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select correlated features and removed it\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n# Find index of feature columns with correlation greater than 0.75\nto_drop = [column for column in upper.columns if any(upper[column].abs() > 0.75)]\nto_drop","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization of data\nscaling = MinMaxScaler()\nX_full_sc = scaling.fit_transform(X_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data set into train and test\nX_train, X_test, y_train, y_test = train_test_split(X_full_sc, y, train_size=0.8, \n                                                                random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model\nrf_model = RandomForestClassifier(random_state=0)\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\nparam_grid = {\n    'n_estimators': range(100,501,100),\n    'max_depth' : range(1,5,1)\n}\nmy_model = GridSearchCV(rf_model,param_grid,cv=kf,verbose=10, n_jobs=-1)\nmy_model.fit(X_train,y_train)\nprint(f\"Best score: {my_model.best_score_}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best parameters:\")\nbest_parameters = my_model.best_estimator_.get_params()\nfor param_name in sorted(param_grid.keys()):\n    print(f\"\\t {param_name}: {best_parameters[param_name]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_tr = my_model.best_estimator_.predict(X_train) \npredictions_te = my_model.best_estimator_.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_train = accuracy_score(y_train, predictions_tr) \naccuracy_test = accuracy_score(y_test, predictions_te) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = X_full.columns\nimportances = my_model.best_estimator_.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}