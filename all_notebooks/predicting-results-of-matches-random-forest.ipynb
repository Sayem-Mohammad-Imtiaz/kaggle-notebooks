{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The problem","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Based on this dataset with 20,000 chess matches collected from Lichess (games taken of users from the top ~100 teams on _lichess.org_ from 2013 to 2017) the objective is to create a model that predicts the result of a match, given the parameters of the game, before it starts (available at https://www.kaggle.com/datasnaek/chess).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\n%pylab inline\n\npd.set_option('display.max_columns', 200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the dataset:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games = pd.read_csv('../input/chess/games.csv', delimiter=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Duration of the match","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_delay_in_sec = (chess_games['last_move_at'] - chess_games['created_at']) / 1000\nchess_games['duration_in_seconds'] = games_delay_in_sec.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One-Hot-Encoding of victory status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from category_encoders import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_victory_status = OneHotEncoder(cols=['victory_status'], use_cat_names=True, drop_invariant=True)\nchess_games = ohe_victory_status.fit_transform(chess_games)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Time control: Minutes and Seconds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"minutes = chess_games['increment_code'].str.split('+').map(lambda time_control: time_control[0], na_action=None).astype(int)\nincr_seconds = chess_games['increment_code'].str.split('+').map(lambda time_control: time_control[1], na_action=None).astype(int)\n\nchess_games['minutes'] = minutes.copy()\nchess_games['incr_seconds'] = incr_seconds.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games = chess_games.drop(columns=['increment_code'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date of Creation and Last Move At (as dates)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games['created_at'] = pd.to_datetime(chess_games['created_at'], unit='ms')\nchess_games['last_move_at'] = pd.to_datetime(chess_games['last_move_at'], unit='ms')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rating difference","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"One other variable that seems to be predictive is the rating difference between the players.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games['rating_difference'] = chess_games['white_rating'] - chess_games['black_rating']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games['rating_difference'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Castle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_white_moves(moves):\n    return moves[::2]\n\ndef get_black_moves(moves):\n    return moves[1::2]\n\ndef castled(moves):\n    return ('O-O' in moves) | ('O-O-O' in moves)\n\nall_moves = chess_games['moves'].str.split()\nwhite_moves = all_moves.apply(get_white_moves)\nblack_moves = all_moves.apply(get_black_moves)\nchess_games['white_castled'] = white_moves.apply(castled).astype(int)\nchess_games['black_castled'] = black_moves.apply(castled).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Number of takes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_takes(moves):\n    moves = pd.Series(moves)\n    return moves.map(lambda mv: 1 if 'x' in mv else 0).sum()\n\nchess_games['white_takes_count'] = white_moves.apply(count_takes)\nchess_games['black_takes_count'] = black_moves.apply(count_takes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clean Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We calculate a threshold in hours for a match:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_minutes = chess_games['minutes'].max()\nmax_incr_seconds = chess_games['incr_seconds'].max()\nmean_moves = chess_games['turns'].mean()\n\nduration_threshold_in_hours = (max_minutes + max_incr_seconds / 60 * mean_moves) / 60\nduration_threshold_in_hours","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we remove the matches which have until 3 turns (not possible to checkmate in 3 turns), and the ones with duration until 6 hours.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games = chess_games[chess_games['turns'] > 3]\nchess_games = chess_games[chess_games['duration_in_seconds'] < duration_threshold_in_hours * 3600]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see we have also matches which have 0 seconds.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"duration0 = chess_games[chess_games['duration_in_seconds'] == 0]\nduration0['winner'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the distribution of the matches' duration:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pyplot.hist(x=chess_games['duration_in_seconds'], bins=100)\npyplot.xlabel('Duration (in seconds)')\npyplot.ylabel('Frequency')\npyplot.title('Matches\\' Durations')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's filter the matches with duration_in_seconds > 0.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games = chess_games[chess_games['duration_in_seconds'] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_games.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reploting the durations, without the zeroes:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pyplot.hist(x=chess_games['duration_in_seconds'], bins=100)\npyplot.xlabel('Duration (in seconds)')\npyplot.ylabel('Frequency')\npyplot.title('Matches\\' Durations')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The peak at ~10000 s = ~2.7 hours is a plausible match duration.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Baseline","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's take as **baseline case** the result as a function of the rating difference points (diff):\n\nIf\n* \\- (mean difference)  < diff < (mean difference)  => draw;\n* else, diff is negative => black wins\n* else => white wins","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline = pd.DataFrame(index=chess_games.index)\nbaseline['rating_difference'] = chess_games['rating_difference']\nbaseline.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline['rating_difference'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_base_winner(rating_diff):\n    average = baseline['rating_difference'].mean()\n    if rating_diff < average and rating_diff > -average:\n        return 'draw'\n    elif rating_diff < 0:\n        return 'black'\n    else:\n        return 'white'\n\nbaseline['winner'] = baseline['rating_difference'].apply(get_base_winner)\nbaseline['winner'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use the **weighted avg precison** and **weighted avg recall** as our modeling metrics, so we balance the different quantities of examples for each result.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(chess_games['winner'], baseline['winner'], digits=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"p 0.5933, recall 0.5924 - Baseline","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Looking how to capture the **weighted avg precison**, we use its definition: _weighted_avg_precision = weighted_avg(precision, support)_","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results = precision_recall_fscore_support(chess_games['winner'], baseline['winner'])\nnp.average(results[0], weights=results[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Constructing the model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We import the Random Forest Classifier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use the following variables to make the model:\n\n(we include castled, takes quantity, rating difference)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = ['victory_status_outoftime', 'victory_status_resign', 'victory_status_mate', 'victory_status_draw', \n             'white_rating', 'black_rating', 'minutes', 'incr_seconds', 'rating_difference',\n             'white_castled', 'black_castled', 'white_takes_count', 'black_takes_count']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the dataset is small, let's divide 50% train / 50% validation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = chess_games[variables]\ny = chess_games['winner']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_valid.shape, y_train.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We train the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0)\nmodel.fit(X_train, y_train)\n\npredicted = model.predict(X_valid)\n\nresults = precision_recall_fscore_support(y_valid, predicted)\nsupport = results[3]\nprec = np.average(results[0], weights=support)\nrecall = np.average(results[1], weights=support)\nprint(\"Precision: {}\".format(prec))\nprint(\"Recall: {}\".format(recall))\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a great increase of both the metrics using the variables **white_takes_count, black_takes_count.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Cross-validation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In order to have a better estimate of the metrics, let's use KFold to do cross-validation of the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_weighted_precisions = []\navg_weighted_recalls = []\nkf = RepeatedKFold(n_splits=2, n_repeats=10, random_state=0)\n\nX = chess_games[variables]\ny = chess_games['winner']\ni = 0\n\nfor lines_train, lines_valid in kf.split(chess_games):\n    X_train, y_train = X.iloc[lines_train], y.iloc[lines_train]\n    X_valid, y_valid = X.iloc[lines_valid], y.iloc[lines_valid]\n    i = i + 1\n    \n    model = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0)\n    model.fit(X_train, y_train)\n    \n    predicted = model.predict(X_valid)\n\n    results = precision_recall_fscore_support(y_valid, predicted)\n    support = results[3]\n    prec = np.average(results[0], weights=support)\n    recall = np.average(results[1], weights=support)\n    print(\"Iteration  #{}\".format(i))\n    print(\"=====================\")\n    print(\"Precision: {}\".format(prec))\n    print(\"Recall: {}\".format(recall))\n    print()\n    \n    avg_weighted_precisions.append(prec)\n    avg_weighted_recalls.append(recall)\n\nprint(\"Average Precision: {}\".format(np.mean(avg_weighted_precisions)))\nprint(\"Average Recall: {}\".format(np.mean(avg_weighted_recalls)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And we see that both the average of precision and the average of recall are near to 80%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's plot the precision and recall distribution to detect possible outliers:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pylab.subplot(121)\npylab.xlabel('Precision')\npylab.ylabel('Value')\npylab.hist(avg_weighted_precisions, bins=20)\n\npylab.subplot(122)\npylab.xlabel('Recall')\npylab.hist(avg_weighted_recalls, bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The values for both the metrics lie in the interval [0.80, 0.82], which is not a big range of values. We haven't detected outliers.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here are some other configurations tested in order to achieve this first model with metrics around 80%:\n\n* p 0.5933, recall 0.5924 - Baseline\n\n* p 0.6477, recall 0.6473 - Random Forest (n=100)\n\n* p 0.6512, recall 0.6508 - Random Forest (n=200) with 'castled' variables\n\n* p 0.8081, recall 0.8077 - Random Forest (n=200) with 'castled' and 'takes_count' variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As we can see, we have a great improvement of the performance when we add 'takes_count' variables.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}