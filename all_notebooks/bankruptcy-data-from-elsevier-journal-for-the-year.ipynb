{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import chi2 , f_classif\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv(r\"/kaggle/input/company-bankruptcy-prediction/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create X and Y data for further analysis\nX = df.drop([\"Bankrupt?\"], axis=1)\ny = df[\"Bankrupt?\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    train_size=0.7,\n                                                    test_size = 0.3, random_state=100)\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\npca = PCA(n_components=15)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce dimentionality \nX_train.shape,X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [LogisticRegression(),RandomForestClassifier(),\n          DecisionTreeClassifier(), KNeighborsClassifier(),\n         GaussianNB(),SVC(),GradientBoostingClassifier()]\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg= LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l1',\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models comparison with ROC curves\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, \n                             classification_report, f1_score, average_precision_score, precision_recall_fscore_support)\n\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Logistic regression\nmodelLR = LogisticRegression()\nmodelLR.fit(X_train,y_train)\ny_pred_prob_lr = modelLR.predict_proba(X_test)[:,1]\nfpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_prob_lr,pos_label=1)\nroc_auc_lr = auc(fpr_lr, tpr_lr)\nprecision_lr, recall_lr, th_lr = precision_recall_curve(y_test, y_pred_prob_lr,pos_label=1)\n\n# SVM with rbf\nmodelSVMrbf=svm.SVC(kernel='rbf', probability=True)\nmodelSVMrbf.fit(X_train,y_train)\ny_pred_prob_SVMrbf = modelSVMrbf.predict_proba(X_test)[:,1]\nfpr_SVMrbf, tpr_SVMrbf, thresholds_SVMrbf = roc_curve(y_test, y_pred_prob_SVMrbf,pos_label=1)\nroc_auc_SVMrbf = auc(fpr_SVMrbf, tpr_SVMrbf)\nprecision_SVMrbf, recall_SVMrbf, th_SVMrbf = precision_recall_curve(y_test, y_pred_prob_SVMrbf,pos_label=1)\n\n# SVM with linear\nmodelSVMlinear=svm.SVC(kernel='linear', probability=True)\nmodelSVMlinear.fit(X_train,y_train)\ny_pred_prob_SVMlinear = modelSVMlinear.predict_proba(X_test)[:,1]\nfpr_SVMlinear, tpr_SVMlinear, thresholds_SVMlinear = roc_curve(y_test, y_pred_prob_SVMlinear,pos_label=1)\nroc_auc_SVMlinear = auc(fpr_SVMlinear, tpr_SVMlinear)\nprecision_SVMlinear, recall_SVMlinear, th_SVMlinear = precision_recall_curve(y_test, y_pred_prob_SVMlinear,pos_label=1)\n\n# KNN\nmodelKNN = KNeighborsClassifier(n_neighbors=3)\nmodelKNN.fit(X_train,y_train)\ny_pred_prob_KNN = modelKNN.predict_proba(X_test)[:,1]\nfpr_KNN, tpr_KNN, thresholds_KNN = roc_curve(y_test, y_pred_prob_KNN,pos_label=1)\nroc_auc_KNN = auc(fpr_KNN, tpr_KNN)\nprecision_KNN, recall_KNN, th_KNN = precision_recall_curve(y_test, y_pred_prob_KNN,pos_label=1)\n\n\n# Decision Tree\nmodelTree=DecisionTreeClassifier()\nmodelTree.fit(X_train,y_train)\ny_pred_prob_Tree = modelTree.predict_proba(X_test)[:,1]\nfpr_Tree, tpr_Tree, thresholds_Tree = roc_curve(y_test, y_pred_prob_Tree,pos_label=1)\nroc_auc_Tree = auc(fpr_Tree, tpr_Tree)\nprecision_Tree, recall_Tree, th_Tree = precision_recall_curve(y_test, y_pred_prob_Tree,pos_label=1)\n\n# Random forest\nmodelRF= RandomForestClassifier(n_estimators=100,random_state=0)\nmodelRF.fit(X_train,y_train)\ny_pred_prob_rf = modelRF.predict_proba(X_test)[:,1]\nfpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_prob_rf,pos_label=1)\nroc_auc_rf = auc(fpr_rf, tpr_rf)\nprecision_rf, recall_rf, th_rf = precision_recall_curve(y_test, y_pred_prob_rf,pos_label=1)\n\n\n# Naive Bayes\nmodelNB= GaussianNB()\nmodelNB.fit(X_train,y_train)\ny_pred_prob_nb = modelNB.predict_proba(X_test)[:,1]\nfpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, y_pred_prob_nb,pos_label=1)\nroc_auc_nb = auc(fpr_nb, tpr_nb)\nprecision_nb, recall_nb, th_nb = precision_recall_curve(y_test, y_pred_prob_nb,pos_label=1)\n\n# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_lr, tpr_lr, label='Log Reg (area = %0.3f)' % roc_auc_lr)\nplt.plot(fpr_SVMrbf, tpr_SVMrbf, label='SVM rbf (area = %0.3f)' % roc_auc_SVMrbf)\nplt.plot(fpr_SVMlinear, tpr_SVMlinear, label='SVM linear (area = %0.3f)' % roc_auc_SVMlinear)\nplt.plot(fpr_KNN, tpr_KNN, label='KNN (area = %0.3f)' % roc_auc_KNN)\nplt.plot(fpr_Tree, tpr_Tree, label='Tree (area = %0.3f)' % roc_auc_Tree)\nplt.plot(fpr_rf, tpr_rf, label='RF (area = %0.3f)' % roc_auc_rf)\nplt.plot(fpr_nb, tpr_nb, label='NB (area = %0.3f)' % roc_auc_nb)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curves from the investigated models')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}