{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"cd /kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd input/faces-npz-file/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# cd input/celeba-dataset/img_align_celeba/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(\"img_align_celeba/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = mpimg.imread(\"img_align_celeba/\"+os.listdir(\"img_align_celeba/\")[0])\nplt.imshow(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 15))\nfor i in range(5*5):\n    plt.subplot(5,5,i+1)\n    plt.axis(\"off\")\n    plt.imshow(mpimg.imread(\"img_align_celeba/\" + os.listdir(\"img_align_celeba/\")[i+10]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def load_faces():\n#     data = []\n#     dir = \"img_align_celeba/\"\n#     for i in os.listdir(dir)[:50000]:\n#         pixels = mpimg.imread(dir + i)\n#         data.append(pixels)\n#     return data\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = load_faces()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install mtcnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import mtcnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import savez_compressed\nfrom numpy import asarray","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mtcnn.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = mtcnn.MTCNN()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"face = model.detect_faces(sample)\nx1, y1, width, height = face[0][\"box\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def extract_face(model, pixels, dsize = (80,80)):\n#     face = model.detect_faces(pixels)\n#     x1, y1, width, height = face[0][\"box\"]\n#     x1, y1 = abs(x1), abs(y1)\n    \n#     x2,y2 = x1+width, y1+height\n#     face_pixels = face[y1:y2, x1:x2]\n#     image = Image.fromarray(face_pixels)\n#     image = image.resize(dsize)\n#     face_array = asarray(image)\n#     return face_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_face(model, pixels, required_size=(80, 80)):\n\t# detect face in the image\n\tfaces = model.detect_faces(pixels)\n\t# skip cases where we could not detect a face\n\tif len(faces) == 0:\n\t\treturn None\n\t# extract details of the face\n\tx1, y1, width, height = faces[0]['box']\n\t# force detected pixel values to be positive (bug fix)\n\tx1, y1 = abs(x1), abs(y1)\n\t# convert into coordinates\n\tx2, y2 = x1 + width, y1 + height\n\t# retrieve face pixels\n\tface_pixels = pixels[y1:y2, x1:x2]\n\t# resize pixels to the model size\n\timage = Image.fromarray(face_pixels)\n\timage = image.resize(required_size)\n\tface_array = asarray(image)\n\treturn face_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(filename):\n\t# load image from file\n\timage = Image.open(filename)\n\t# convert to RGB, if needed\n\timage = image.convert('RGB')\n\t# convert to array\n\tpixels = asarray(image)\n\treturn pixels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def load_faces():\n#     model = mtcnn.MTCNN()\n#     faces = []\n#     dir = \"img_align_celeba/\"\n#     for i in os.listdir(dir)[:50000]:\n#         pixels = mpimg.imread(dir + i)\n#         face = extract_face(model, pixels)\n#         faces.append(face)`a\n#         print(len(faces), face.shape)\n#     return faces","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_faces(directory, n_faces):\n\t# prepare model\n\tmodel = mtcnn.MTCNN()\n\tfaces = list()\n\t# enumerate files\n\tfor filename in os.listdir(directory):\n\t\t# load the image\n\t\tpixels = load_image(directory + filename)\n\t\t# get face\n\t\tface = extract_face(model, pixels)\n\t\tif face is None:\n\t\t\tcontinue\n\t\t# store\n\t\tfaces.append(face)\n\t\tprint(len(faces), face.shape)\n\t\t# stop once we have enough\n\t\tif len(faces) >= n_faces:\n\t\t\tbreak\n\treturn asarray(faces)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = load_faces('img_align_celeba/', 50000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd /kaggle/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd working/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"savez_compressed('img_align.npz', dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import load\ndata = load(\"img_align.npz\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"faces = data['arr_0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"faces.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator(input_shape = (80,80,3)):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(128,3, strides = (2,2), padding=\"same\", input_shape = input_shape),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(128, 3 , strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Conv2D(128, 3 , strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Conv2D(256, 3 , strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.3),\n        \n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64),\n        tf.keras.layers.Dense(1, \"sigmoid\")\n        \n    ])\n    model.compile(optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5), loss = \"binary_crossentropy\", metrics = ['acc'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator(latent_dim):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Dense(128 * 5 * 5, input_dim = latent_dim ),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Reshape((5, 5, 128)),\n        \n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(3, (3,3), activation = \"tanh\", padding = \"same\")\n    ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_model = discriminator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_model = generator(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gan(g_model, d_model):\n    d_model.trainable = False\n    model = tf.keras.models.Sequential([\n        g_model,\n        d_model\n    ])\n    model.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(0.0002, beta_1 = 0.5))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan_model = gan(g_model, d_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_real_samples(dataset, n_size):\n    ind = np.random.randint(0, dataset.shape[0], n_size)\n    data = dataset[ind]\n    data = (data - 127.5)/127.5\n    y = np.ones((n_size, 1))\n    return data, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_latent_space(n_size, latent_dim):\n    points= np.random.randn(n_size * latent_dim)\n    points = points.reshape(n_size, latent_dim)\n    return points","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_fake_examples(g_model, n_size = 64, latent_dim = 100):\n    latent_points = generate_latent_space(n_size, latent_dim)\n    preds = g_model.predict(latent_points)\n    y = np.zeros((n_size, 1))\n    return preds, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_figure(dataset):\n    plt.figure(figsize = (15,15))\n    for i in range(7*7):\n        plt.subplot(7,7,i+1)\n        plt.axis(\"off\")\n        plt.imshow(dataset[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summarize_performance(d_model, g_model, dataset, n_size = 64):\n    \n    X_real, y_real = generate_real_samples(dataset, n_size)\n    _, acc_r = d_model.evaluate(X_real, y_real)\n    \n    X_fake, y_fake = generate_fake_examples(g_model)\n    _, acc_f = d_model.evaluate(X_fake, y_fake)\n    \n    print(\"Real Acc: {} >> Fake Acc: {}\".format(acc_r, acc_f))\n    \n    plot_figure(X_fake)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(g_model, d_model, gan_model, dataset, epochs = 50, batch_size = 64, latent_dim = 100):\n    half_batch = int(batch_size/2)\n    batches_per_epoch = int(len(dataset)/batch_size)\n    for i in range(epochs):\n        for j in range(batches_per_epoch):\n            X_real, y_real = generate_real_samples(dataset, half_batch)\n            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n            \n            X_fake, y_fake = generate_fake_examples(g_model, batch_size, latent_dim)\n            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n            \n            X_gan = generate_latent_space(batch_size, latent_dim)\n            y_gan = np.ones((batch_size, 1))\n            \n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            \n            if(j%50 == 0):\n                print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n                    (i+1, j+1, batches_per_epoch, d_loss1, d_loss2, g_loss))\n        if ((i+1) %10 == 0):\n            summarize_performance(d_model, g_model, dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(g_model, d_model,gan_model, faces)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summarize_performance(d_model, g_model, faces)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd working/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_model.save(\"generator.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}