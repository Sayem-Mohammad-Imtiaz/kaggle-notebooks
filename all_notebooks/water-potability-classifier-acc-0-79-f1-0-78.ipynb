{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Name:** Water Potability Classifier\n\n**Author:** Sharome Burton\n\n**Date:** 07/21/2021\n\n**Description:** Machine learning model used to determine whether water is safe to drink.\n\n**Kaggle:** https://www.kaggle.com/sharomeethan/water-potability-classifier/\n\n## 1. Problem definition\n> How accurately can we classify whether a sample from a body of water is potable, given its chemical and physical characteristics?\n\n## 2. Context\n\nAccess to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. This is important as a health and development issue at a national, regional and local level. In some regions, it has been shown that investments in water supply and sanitation can yield a net economic benefit, since the reductions in adverse health effects and health care costs outweigh the costs of undertaking the interventions.\n\n## 3. Data\n`water_potability.csv` - contains water quality metrics for 3276 different water bodies. \n\nsource: https://www.kaggle.com/adityakadiwal/water-potability\n\n\n\n## 4. Features\n\n**1. `pH value`:**\n\nPH is an important parameter in evaluating the acid–base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52–6.83 which are in the range of WHO standards.\n\n**2. `Hardness`:**\n\nHardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.\n\n**3. `Solids` (Total dissolved solids - TDS):**\n\nWater has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg/l and maximum limit is 1000 mg/l which prescribed for drinking purpose.\n\n**4. `Chloramines`:**\n\nChlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg/L or 4 parts per million (ppm)) are considered safe in drinking water.\n\n**5. `Sulfate`:**\n\nSulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg/L). It ranges from 3 to 30 mg/L in most freshwater supplies, although much higher concentrations (1000 mg/L) are found in some geographic locations.\n\n**6. `Conductivity`:**\n\nPure water is not a good conductor of electric current rather’s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 μS/cm.\n\n**7. `Organic_carbon`:**\n\nTotal Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA < 2 mg/L as TOC in treated / drinking water, and < 4 mg/Lit in source water which is use for treatment.\n\n**8. `Trihalomethanes`:**\n\nTHMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.\n\n**9. `Turbidity`:**\n\nThe turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.\n\n**10. `Potability` (Target) :**\n\nIndicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.\n   \n## 4. Evaluation \n\n> **Goal:** Determine whether a sample of water is potable at >75% precision.\n\n","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-24T16:40:36.374758Z","iopub.execute_input":"2021-07-24T16:40:36.376693Z","iopub.status.idle":"2021-07-24T16:40:36.390786Z","shell.execute_reply.started":"2021-07-24T16:40:36.37663Z","shell.execute_reply":"2021-07-24T16:40:36.389704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Libraries","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:18:01.845585Z","iopub.execute_input":"2021-07-22T00:18:01.846032Z","iopub.status.idle":"2021-07-22T00:18:01.851158Z","shell.execute_reply.started":"2021-07-22T00:18:01.845936Z","shell.execute_reply":"2021-07-22T00:18:01.850027Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom xgboost.sklearn import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n%matplotlib inline\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-24T16:40:36.393171Z","iopub.execute_input":"2021-07-24T16:40:36.393958Z","iopub.status.idle":"2021-07-24T16:40:36.408948Z","shell.execute_reply.started":"2021-07-24T16:40:36.393926Z","shell.execute_reply":"2021-07-24T16:40:36.408232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import data","metadata":{"execution":{"iopub.status.busy":"2021-07-22T00:19:50.467758Z","iopub.execute_input":"2021-07-22T00:19:50.468111Z","iopub.status.idle":"2021-07-22T00:19:50.472305Z","shell.execute_reply.started":"2021-07-22T00:19:50.468081Z","shell.execute_reply":"2021-07-22T00:19:50.47134Z"}}},{"cell_type":"code","source":"df_raw = pd.read_csv(\"../input/water-potability/water_potability.csv\")\ndf_raw","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:36.410647Z","iopub.execute_input":"2021-07-24T16:40:36.411106Z","iopub.status.idle":"2021-07-24T16:40:36.469209Z","shell.execute_reply.started":"2021-07-24T16:40:36.411061Z","shell.execute_reply":"2021-07-24T16:40:36.468438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory data analysis (EDA)","metadata":{}},{"cell_type":"code","source":"# Checking data types\ndf_raw.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:36.470752Z","iopub.execute_input":"2021-07-24T16:40:36.471239Z","iopub.status.idle":"2021-07-24T16:40:36.487798Z","shell.execute_reply.started":"2021-07-24T16:40:36.471206Z","shell.execute_reply":"2021-07-24T16:40:36.486729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing data\ndf_raw.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:36.49014Z","iopub.execute_input":"2021-07-24T16:40:36.490693Z","iopub.status.idle":"2021-07-24T16:40:36.49879Z","shell.execute_reply.started":"2021-07-24T16:40:36.490647Z","shell.execute_reply":"2021-07-24T16:40:36.498027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have incomplete data for pH, sulfate, and trihalomethanes, so we must do some further analysis to figure out what we must replace that data with.","metadata":{}},{"cell_type":"code","source":"# Count distribution of target variable\nsns.countplot(x=df_raw[\"Potability\"])\n\n\nprint(f'{df_raw.Potability[df_raw.Potability==1].count()/df_raw.Potability.count()*100:.2f} % of samples are potable (1)')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:36.500078Z","iopub.execute_input":"2021-07-24T16:40:36.500592Z","iopub.status.idle":"2021-07-24T16:40:36.66435Z","shell.execute_reply.started":"2021-07-24T16:40:36.50056Z","shell.execute_reply":"2021-07-24T16:40:36.663528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix for dataset\nplt.figure(figsize=(15,10))\nsns.heatmap(df_raw.corr(), annot=True, cmap=\"inferno\")","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:36.665476Z","iopub.execute_input":"2021-07-24T16:40:36.665884Z","iopub.status.idle":"2021-07-24T16:40:37.570873Z","shell.execute_reply.started":"2021-07-24T16:40:36.665855Z","shell.execute_reply":"2021-07-24T16:40:37.569849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation matrix shows weak correlation between features suggesting that they are reasonably independent of eachother. There is no multicollinearity.","metadata":{}},{"cell_type":"code","source":"# Distribution of features\npotable = df_raw.query('Potability == 0')\nnot_potable = df_raw.query('Potability == 1')\n\nfig = plt.figure(figsize=(20,15))\n\nfor ax,column in enumerate(df_raw.columns[:9]):\n    plt.subplot(3,3,ax+1)\n    plt.title(f'Distribution of {column} values')\n    sns.kdeplot(x=not_potable[column],label='Not Potable(0)')\n    sns.kdeplot(x=potable[column],label='Potable(1)')\n    plt.legend(prop=dict(size=10))\n\n    \nplt.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:37.573787Z","iopub.execute_input":"2021-07-24T16:40:37.574312Z","iopub.status.idle":"2021-07-24T16:40:40.326426Z","shell.execute_reply.started":"2021-07-24T16:40:37.574279Z","shell.execute_reply":"2021-07-24T16:40:40.32547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,15))\n\nfor ax,column in enumerate(df_raw.columns[:9]):\n    plt.subplot(3,3,ax+1)\n    plt.title(f'Distribution of {column} values')\n    sns.distplot(not_potable[column], label='Not Potable(0)', hist_kws=dict(edgecolor='k', linewidth=1), bins=25)\n    sns.distplot(potable[column], label='Potable(1)', hist_kws=dict(edgecolor='k', linewidth=1), bins=25)\n    plt.legend(prop=dict(size=10))\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:40.328016Z","iopub.execute_input":"2021-07-24T16:40:40.32832Z","iopub.status.idle":"2021-07-24T16:40:44.98293Z","shell.execute_reply.started":"2021-07-24T16:40:40.328292Z","shell.execute_reply":"2021-07-24T16:40:44.981713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data shows reasonably normal distribution for all features.","metadata":{}},{"cell_type":"markdown","source":"## Imputing missing data","metadata":{}},{"cell_type":"code","source":"def fill_nan(df):\n    for index, column in enumerate(df.columns[:9]):\n        # print(index, column)\n        df[column] = df[column].fillna(df.groupby('Potability')[column].transform('mean'))\n    return df\n        \ndf = fill_nan(df_raw)\n\ndf.isna().sum()  \n\n        \n                                                         \n                                                      ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:44.98432Z","iopub.execute_input":"2021-07-24T16:40:44.984658Z","iopub.status.idle":"2021-07-24T16:40:45.011297Z","shell.execute_reply.started":"2021-07-24T16:40:44.984626Z","shell.execute_reply":"2021-07-24T16:40:45.010165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting, balancing and scaling data","metadata":{}},{"cell_type":"code","source":"# Splitting\nX = df.drop(['Potability'], axis = 1)\ny = df['Potability']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=18, stratify=y) #stratify=y\n\n# Balancing data - oversampling minority\nsmt = SMOTE()\nX_train, y_train = smt.fit_resample(X_train, y_train)\n\n# Scaling\nsc = StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:40:45.012491Z","iopub.execute_input":"2021-07-24T16:40:45.012799Z","iopub.status.idle":"2021-07-24T16:40:45.044864Z","shell.execute_reply.started":"2021-07-24T16:40:45.012772Z","shell.execute_reply":"2021-07-24T16:40:45.043886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training models\nWe will try:\n   * Logistic Regression\n   * K-Nearest Neighbors\n   * Random Forest Classifier\n   * Decision Tree Classifier\n   * Naive Bayes\n   * ExtraTreesClassifier\n   * XGB Classifier\n   * CatBoostClassifier\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-22T05:45:19.504996Z","iopub.execute_input":"2021-07-22T05:45:19.505459Z","iopub.status.idle":"2021-07-22T05:45:19.511286Z","shell.execute_reply.started":"2021-07-22T05:45:19.505428Z","shell.execute_reply":"2021-07-22T05:45:19.510257Z"}}},{"cell_type":"code","source":"# Put models in a dictionary\nmodels = {\"Logistic Regression\": LogisticRegression(),\n         \"KNN\": KNeighborsClassifier(),\n         \"Random Forest\": RandomForestClassifier(),\n         \"Decision Tree\": DecisionTreeClassifier(),\n         \"Naive Bayes\": GaussianNB(),\n         \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n         \"xgb Classifier\": XGBClassifier(),\n         \"CatBoostClassifier\": CatBoostClassifier()}\n\n\n# Create a function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n   \n    \"\"\"\n   Fits and evaluates given machine learning models.\n   models: a dict of different Scikit_Learn machine learning models\n   X_train: training data (no labels)\n   X_test: testing data (no labels)\n   y_train: training labels\n   y_test: test labels\n   \"\"\" \n    # Set random seed\n    np.random.seed(18)\n    # Make a dictionary to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit model to data\n        model.fit(X_train, y_train)\n        # Evaluate model and append its score to model_scores\n        model_scores[name] = cross_val_score(model,\n                                             X_test,\n                                             y_test,\n                                            scoring='accuracy',\n                                            cv=5\n                                            ).mean()\n\n    return model_scores","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-24T16:40:45.046281Z","iopub.execute_input":"2021-07-24T16:40:45.046596Z","iopub.status.idle":"2021-07-24T16:40:45.061761Z","shell.execute_reply.started":"2021-07-24T16:40:45.046565Z","shell.execute_reply":"2021-07-24T16:40:45.060481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_scores = fit_and_score(models,X_train,X_test,y_train,y_test)\n\nmodel_scores","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-24T16:40:45.06324Z","iopub.execute_input":"2021-07-24T16:40:45.063556Z","iopub.status.idle":"2021-07-24T16:41:07.518448Z","shell.execute_reply.started":"2021-07-24T16:40:45.063529Z","shell.execute_reply":"2021-07-24T16:41:07.517244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\nmodel_compare.T.plot.bar(color=\"orange\");","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:41:07.519976Z","iopub.execute_input":"2021-07-24T16:41:07.520367Z","iopub.status.idle":"2021-07-24T16:41:07.781807Z","shell.execute_reply.started":"2021-07-24T16:41:07.52033Z","shell.execute_reply":"2021-07-24T16:41:07.780492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The XGB Classifier seems to show the most promise with about 79% accuracy after 5 folds of cross-validation.","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"np.random.seed(18)\n\n# Create a hyperparameter grid for XGB Classifier\nxgb_grid = {\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ]}\n\n\n# Setup random hyperparameter search for XGB Classifier\nrs_xgb = RandomizedSearchCV(XGBClassifier(),\n                                param_distributions=xgb_grid,\n                                cv=2,\n                                n_iter=100,\n                                verbose=0\n                               )\n\n# Fit random hyperparameter search model for XGB Classifier\nrs_xgb.fit(X_train, y_train)\n\n# Find best hyperparamaters\nrs_xgb.best_params_\n\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-24T16:41:07.783069Z","iopub.execute_input":"2021-07-24T16:41:07.783475Z","iopub.status.idle":"2021-07-24T16:42:11.281435Z","shell.execute_reply.started":"2021-07-24T16:41:07.783443Z","shell.execute_reply":"2021-07-24T16:42:11.280486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_xgb.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:42:11.28281Z","iopub.execute_input":"2021-07-24T16:42:11.283098Z","iopub.status.idle":"2021-07-24T16:42:11.296086Z","shell.execute_reply.started":"2021-07-24T16:42:11.283068Z","shell.execute_reply":"2021-07-24T16:42:11.295034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rough hyperparameter tuning showed no improvement on baseline XGB Classifier model","metadata":{}},{"cell_type":"code","source":"# Final model - XGBClassifier\n\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:42:11.297328Z","iopub.execute_input":"2021-07-24T16:42:11.297695Z","iopub.status.idle":"2021-07-24T16:42:11.815884Z","shell.execute_reply.started":"2021-07-24T16:42:11.297652Z","shell.execute_reply":"2021-07-24T16:42:11.814968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=\"inferno\")","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:42:11.817106Z","iopub.execute_input":"2021-07-24T16:42:11.817617Z","iopub.status.idle":"2021-07-24T16:42:12.082968Z","shell.execute_reply.started":"2021-07-24T16:42:11.817573Z","shell.execute_reply":"2021-07-24T16:42:12.081735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:42:12.084358Z","iopub.execute_input":"2021-07-24T16:42:12.084784Z","iopub.status.idle":"2021-07-24T16:42:12.098976Z","shell.execute_reply.started":"2021-07-24T16:42:12.084751Z","shell.execute_reply":"2021-07-24T16:42:12.097579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n\nFinal model shows a reasonable **accuracy** of **79%** with an **f1-score** of **0.78**, passing the evaluation metric.\n","metadata":{}},{"cell_type":"markdown","source":"## Feature importance","metadata":{"execution":{"iopub.status.busy":"2021-07-22T07:35:01.728446Z","iopub.execute_input":"2021-07-22T07:35:01.728813Z","iopub.status.idle":"2021-07-22T07:35:01.788243Z","shell.execute_reply.started":"2021-07-22T07:35:01.728777Z","shell.execute_reply":"2021-07-22T07:35:01.787222Z"}}},{"cell_type":"code","source":"# Helper function for plotting feature importance\ndef plot_features(columns, importances,n=20):\n    df = (pd.DataFrame({\"features\": columns,\n                       \"feature_importances\": importances})\n         .sort_values(\"feature_importances\", ascending=False)\n         .reset_index(drop=True))\n    # Plot dataframe\n    fix, ax = plt.subplots()\n    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature Importance\")\n    ax.invert_yaxis()\n    \nplot_features(df.drop(['Potability'],axis=1).columns, model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T16:42:12.100788Z","iopub.execute_input":"2021-07-24T16:42:12.101122Z","iopub.status.idle":"2021-07-24T16:42:12.351059Z","shell.execute_reply.started":"2021-07-24T16:42:12.10109Z","shell.execute_reply":"2021-07-24T16:42:12.349731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Sulfate` and `pH` levels seem to be the biggest indicator of the potability of the water samples.","metadata":{}}]}