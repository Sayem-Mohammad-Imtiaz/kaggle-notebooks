{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cricket Players Image Classification","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras \nimport pandas as pd\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"code","source":"ds = pd.read_csv(\"../input/indian-cricketers-images/players.csv\")\nds = ds.sample(frac=1).reset_index(drop=True)\n\nle = preprocessing.LabelEncoder()\nle.fit(ds['player'])\nds['player_trans'] = le.transform(ds['player'])\n\nn = int(len(ds))\nplayers = ds.player.nunique()\nprint(\"Number Of Players    : \",players)\nprint(\"Number Of Images     : \",n)\nprint(\"\\n\\nDistribution Per Player\")\nds['player'].value_counts().plot.bar()\n\nds = ds[:-6]\ntest = ds[-6:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now let's make the distribution equal.","metadata":{}},{"cell_type":"code","source":"for index,row in ds.iterrows():\n    if len(ds[ds['player']==row['player']])>20:\n        ds.drop(ds[ds['image']==row['image']].index , inplace=True)\n\nprint(\"Distribution Per Player\")\nds['player'].value_counts().plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:image = tf.image.transpose(image)\n    if p_rotate > .75:image = tf.image.rot90(image, k=3) \n    elif p_rotate > .5:image = tf.image.rot90(image, k=2) \n    elif p_rotate > .25:image = tf.image.rot90(image, k=1) \n\n    if p_pixel_1 >= .4:image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:image = tf.image.random_brightness(image, max_delta=.1)\n\n    if p_crop > .7:\n        if p_crop > .9:image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:image = tf.image.central_crop(image, central_fraction=.8)\n        else:image = tf.image.central_crop(image, central_fraction=.9)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(224*.8),224, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\n    \n    image = tf.image.resize(image, [224,224])\n    return image,label\n\ndef load_img(image,player,player_transf):\n    path = \"../input/indian-cricketers-images/images/\"+player+\"/\"+image\n    img = tf.io.decode_jpeg(tf.io.read_file(path),channels=3)\n    img = tf.cast(img, tf.float32)\n    img = tf.image.resize(img, [224,224])\n    img = keras.applications.mobilenet_v2.preprocess_input(img)\n    return img,player_transf\ndataset = tf.data.Dataset.from_tensor_slices((ds.image.values,ds.player.values,ds.player_trans.values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = dataset.take(int(0.8*n))\nval_ds = dataset.skip(int(0.8*n))\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.map(load_img,num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.repeat(40).map(data_augment,num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.batch(32).prefetch(buffer_size=AUTOTUNE)\n\nval_ds = val_ds.map(load_img,num_parallel_calls=AUTOTUNE).batch(32).prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"base_model = keras.applications.MobileNetV2(weights=\"imagenet\",include_top=False)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(players, activation=\"softmax\")(avg)\nmodel = keras.Model(inputs=base_model.input, outputs=output)\n\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"./checkpoints/cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\nhistory = model.fit(train_ds, epochs=20, validation_data=val_ds,verbose=1,callbacks=[cp_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\npd.DataFrame(history.history)[['accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Cases","metadata":{}},{"cell_type":"code","source":"i=0\ndef load_test_img(image,player,player_transf):\n    path = \"../input/indian-cricketers-images/images/\"+player+\"/\"+image\n    img = tf.io.decode_jpeg(tf.io.read_file(path),channels=3)\n    img = tf.cast(img, tf.float32)\n    img = tf.image.resize(img, [224,224])\n    img = keras.applications.mobilenet_v2.preprocess_input(img)\n    return img\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test.image.values,test.player.values,test.player_trans.values))\ntest_ds = test_ds.map(load_test_img).batch(6)\nprediction = model.predict(test_ds)\n\nfor index,row in test.iterrows():\n    img = tf.io.decode_jpeg(tf.io.read_file(\"../input/indian-cricketers-images/images/\"+row['player']+\"/\"+row['image']),channels=3)\n    imgplot = plt.imshow(img.numpy().astype(\"uint8\"),aspect='auto')\n    real = str(list(le.classes_)[row['player_trans']])\n    top_k_values, top_k_indices = tf.nn.top_k(prediction[i], k=3)\n    top_k_names = []\n    for k in range(3):\n        top_k_names+=[str(list(le.classes_)[top_k_indices[k]])]\n    plt.title(\"Real Value: \"+str(real)+\"\\nTop 3 Predicted Values: \"+str(top_k_names))\n    plt.show()\n    i+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}