{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ndata=pd.read_csv('/kaggle/input/heart-disease/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nf, ax = plt.subplots(figsize=(15, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=missing_data.index, y=missing_data['Percent'])\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n    Age: Age\n    Sex: Sex (1 = male; 0 = female)\n    ChestPain: Chest pain (typical, asymptotic, nonanginal, nontypical)\n    RestBP: Resting blood pressure\n    Chol: Serum cholestoral in mg/dl\n    Fbs: Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n    RestECG: Resting electrocardiographic results\n    MaxHR: Maximum heart rate achieved\n    ExAng: Exercise induced angina (1 = yes; 0 = no)\n    Oldpeak: ST depression induced by exercise relative to rest\n    Slope: Slope of the peak exercise ST segment\n    Ca: Number of major vessels colored by flourosopy (0 - 3)\n    Thal: (3 = normal; 6 = fixed defect; 7 = reversable defect)\n    target: AHD - Diagnosis of heart disease (1 = yes; 0 = no)\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    If the skewness is between -0.5 to +0.5 then we can say data is fairly symmetrical.\n    If the skewness is between -1 to -0.5 or 0.5 to 1 then data is moderately skewed.\n    And if the skewness is less than -1 and greater than +1 then our data is heavily skewed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=['trestbps','chol','thalach','oldpeak']\nfor i in data[cols]:\n    print(\"column\",i,\"skewvalue\",data[i].skew(axis=0))\n    plt.figure()\n    sns.distplot(data[i])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/heart-disease/heart.csv')\ndf['chol_transformed']=np.log(df['chol']+1)\ndf['chol_transformed']=df['chol_transformed']/df['chol_transformed'].max()\ncols=['chol','chol_transformed']\nfor i in df[cols]:\n    print(\"column\",i,\"skewvalue\",df[i].skew(axis=0))\n    plt.figure()\n    sns.distplot(df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df=pd.read_csv('/kaggle/input/heart-disease/heart.csv')\ndf['oldpeak_transformed']=np.reciprocal(df['oldpeak']+1)\ndf['oldpeak_transformed']=df['oldpeak_transformed']/df['oldpeak_transformed'].max()\ncols=['oldpeak','oldpeak_transformed']\nfor i in df[cols]:\n    print(\"column\",i,\"skewvalue\",df[i].skew(axis=0))\n    plt.figure()\n    sns.distplot(df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df=pd.read_csv('/kaggle/input/heart-disease/heart.csv')\ndf['thalach_transformed']=np.power(df['thalach'],3)\ndf['thalach_transformed']=df['thalach_transformed']/df['thalach_transformed'].max()\ncols=['thalach_transformed','thalach']\nfor i in df[cols]:\n    print(\"column\",i,\"skewvalue\",df[i].skew(axis=0))\n    plt.figure()\n    sns.distplot(df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df=pd.read_csv('/kaggle/input/heart-disease/heart.csv')\ndf['trestbps_transformed']=np.log(df['trestbps']+1)\ndf['trestbps_transformed']=df['trestbps_transformed']/df['trestbps_transformed'].max()\ncols=['trestbps_transformed','trestbps']\nfor i in df[cols]:\n    print(\"column\",i,\"skewvalue\",df[i].skew(axis=0))\n    plt.figure()\n    sns.distplot(df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=['age','sex','cp','exang','ca','slope','thal','restecg','chol_transformed','oldpeak_transformed','thalach_transformed','trestbps_transformed','target']\ndataset=df[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values=dataset.values\nX, y = values[:, :-1], values[:, -1]\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.4, random_state = 2, stratify = y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\n\nrfc = LogisticRegression(random_state = 42 )\n# accuracies = cross_val_score(rfc, X_train, y_train, cv=3)\nrfc.fit(X_train,y_train)\n# pred = rfc.predict(X_test)\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",rfc.score(X_test,y_test))\nprint(\"The Accuracy Score is:\", metrics.accuracy_score(y_test,pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}