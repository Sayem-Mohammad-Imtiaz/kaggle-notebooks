{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 60% of images are used for training, and 20% are used for validation and rest of them are used for test. I added the kind.csv under /kaggle/input/fortest, which contained the bondary of these. For example, for 'airplane' label, first 0 to 436 images which are read are for training and 437-582 images are for validation, and 583-726 images are for test.\n\nIn this script, I used simple model, but if I modified a little, I could use IncetionV3, which could achive almost 99% accuracy in only several epochs. in this script which used simple model, I could reach 90% accurecy. \n\nHere are brief explanation of function\n1. read_image_fn\n   read file names of each label\n2. read_img\n   read actual images and labels accoring to filenames which read in read_image_fn and file counts of each label. Image size (139,139) are minimum size of InceptionV3 in case of using it.\n3. read_size\n   read kind.csv\n4. model_create\n   model creation. \n5. display_result\n   display graphs for accuracy and loss.\n6. main\n   main routine, in this function, ImageDataGenerator is included to increase images. Also, only several lines are commented out/in and little changed, I can use InceptionV3 as base model.\n\n","metadata":{}},{"cell_type":"code","source":"#coding:cp932\n# 2021.04.05 14.17 Created\n# 2021.04.08 10:36 Use own model insted of InceptionV3\n\nimport numpy as np\nimport pandas as pd\nimport os\nfrom keras.preprocessing.image import load_img\nfrom keras.utils.np_utils import to_categorical\n\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Input, BatchNormalization\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras import layers, optimizers\nfrom keras.preprocessing.image import img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nIMAGE_DIR=\"/kaggle/input/natural-images/data/natural_images/\"\nBASE_DIR=\".\\/\"\nkind_data = {'airplane':0 ,'car':1,'cat':2,'dog':3,'flower':4,'fruit':5,'motorbike':6,'person':7}\nCATEGORY_SIZE=8\n\ntrain_data = []\ntrain_label = []\nvalid_data = []\nvalid_label = []\n\ndef read_image_fn():\n    mydict = {}\n    \n    for i, animal in enumerate(kind_data.keys()):\n        #print(\"animal.key=\",animal)\n        direc = IMAGE_DIR + animal\n        files = os.listdir(direc)\n        data = []\n        for file in files:\n            data.append(file)\n       \n        mydict[animal] = data\n        \n    return mydict\n\ndef read_img(mydict, size_data):\n    global train_data, valid_data, train_label, valid_label\n    \n    kind_count = {'airplane':0 ,'car':0,'cat':0,'dog':0,'flower':0,'fruit':0,'motorbike':0,'person':0}\n    \n    for kind in mydict.keys():\n        #print(\"kind=\",kind)\n        for fn in mydict[kind]:\n            if kind_count[kind] <= int(size_data.loc[kind]['train']):\n                kind_count[kind] += 1\n                img = load_img(IMAGE_DIR + kind + \"/\" + fn, grayscale=False, target_size=(139,139))\n                img_array = img_to_array(img)\n                train_data.append(img_array)\n                train_label.append(kind_data[kind])\n            elif kind_count[kind] <= int(size_data.loc[kind]['valid']):\n                kind_count[kind] += 1\n                img = load_img(IMAGE_DIR + kind + \"/\" + fn, grayscale=False, target_size=(139,139))\n                img_array = img_to_array(img)\n                valid_data.append(img_array)\n                valid_label.append(kind_data[kind])\n            else:\n                continue\n\n    train_label = np.asarray(train_label)\n    valid_label = np.asarray(valid_label)                \n    train_label = to_categorical(train_label,CATEGORY_SIZE)\n    valid_label = to_categorical(valid_label,CATEGORY_SIZE)\n    train_data = np.asarray(train_data)\n    train_data = train_data.astype('float32')/255.0    \n    valid_data = np.asarray(valid_data)\n    valid_data = valid_data.astype('float32')/255.0\n    \ndef read_size():\n    size_data = pd.read_csv(\"/kaggle/input/fortest/kind.csv\", index_col=0)\n    \n    return size_data\n\ndef model_create():\n\n    #base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_tensor=layers.Input(shape=(139,139,3)), input_shape=(139,139,3))\n    #x = base_model.output\n    \n    visible = Input(shape=(139,139,3))\n    x = Conv2D(64,kernel_size=3,activation='relu')(visible)\n    #x = Conv2D(64,kernel_size=3,activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(32,kernel_size=3,activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D()(x)\n    x = Conv2D(16,kernel_size=3,activation='relu')(x) \n    x = BatchNormalization()(x) \n    x = GlobalAveragePooling2D()(x) \n    x = Flatten()(x)\n    x = Dense(1024,activation='relu')(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(CATEGORY_SIZE, activation='softmax')(x)\n    model = Model(inputs=visible, outputs=predictions)\n\n    #for layer in model.layers[:310]:\n    #    layer.trainable = False\n        \n    model.summary()\n    return model\n    \ndef display_result(graph_viz):\n    plt.figure(figsize=(10,10))\n    plt.plot(graph_viz.history['accuracy'])\n    plt.plot(graph_viz.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    plt.figure(figsize=(10,10))\n    plt.plot(graph_viz.history['loss'])\n    plt.plot(graph_viz.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'],loc='upper left')\n    plt.show()\n    \ndef main():\n    global train_data, valid_data, train_label, valid_label\n    \n    size_data = read_size()\n    mydict = read_image_fn()\n    read_img(mydict, size_data)\n    model = model_create()\n    \n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),metrics=['accuracy'])\n    \n    datagen = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization=True,\n        rotation_range=20,\n        #width_shift_range=0.2,\n        #height_shift_range=0.2,\n        horizontal_flip=True,\n        #vertical_flip=True,\n        #zoom_range=[0.2,0.2],\n        #brightness_range=[0.2,0.2]\n        )\n        \n    datagen.fit(train_data)\n    \n    graph_viz = model.fit(x = train_data,y = train_label, batch_size=32, epochs=400, verbose=2,\n                          validation_data = (valid_data, valid_label),shuffle=True)\n\n    print(\"Save model\")\n    model.save(\"./my_model.h5\")\n    print(\"Finish save model\")\n    display_result(graph_viz)\n    \nif __name__ == \"__main__\":\n    main()\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is code for prediction, modified the above traing code. So the useless code are included. This read my_model.h5 which is produced in above code and usig the image files of 20% of total images.  Also this produces the prediction label and actual label in result.csv","metadata":{}},{"cell_type":"code","source":"#coding:cp932\n# 2021.04.05 14.17 Created\n\nimport numpy as np\nimport pandas as pd\n#import glob\nimport os\nfrom keras.preprocessing.image import load_img\nfrom keras.utils.np_utils import to_categorical\n\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras import layers, optimizers\nfrom keras.preprocessing.image import img_to_array, load_img\n\nIMAGE_DIR=\"/kaggle/input/natural-images/data/natural_images/\"\nBASE_DIR=\"./\"\nkind_data = {'airplane':0 ,'car':1,'cat':2,'dog':3,'flower':4,'fruit':5,'motorbike':6,'person':7}\nCATEGORY_SIZE=8\n\ntest_data = []\ntest_label = []\n\n\ndef read_image_fn():\n    mydict = {}\n    \n    for i, animal in enumerate(kind_data.keys()):\n        #print(\"animal.key=\",animal)\n        direc = IMAGE_DIR + animal\n        files = os.listdir(direc)\n        data = []\n        for file in files:\n            data.append(file)\n       \n        mydict[animal] = data\n        \n    #print(mydict)\n    return mydict\n\ndef read_img(mydict, size_data):\n    global test_data, test_label\n    \n    #print(\"saize=\",str(len(mydict)))\n    kind_count = {'airplane':0 ,'car':0,'cat':0,'dog':0,'flower':0,'fruit':0,'motorbike':0,'person':0}\n    \n    for kind in mydict.keys():\n        #print(\"kind=\",kind)\n        for fn in mydict[kind]:\n            #print(\"limit=\", size_data.loc[kind][\"test\"])\n            #print(\"fn=\",fn)\n            kind_count[kind] += 1\n            if kind_count[kind] > int(size_data.loc[kind]['valid']) and kind_count[kind] <= int(size_data.loc[kind]['test']):\n                img = load_img(IMAGE_DIR + kind + \"/\" + fn, grayscale=False, target_size=(139,139))\n                img_array = img_to_array(img)\n                test_data.append(img_array)\n                test_label.append(kind_data[kind])\n            else:\n                continue\n\n    test_label = np.asarray(test_label)               \n    test_label = to_categorical(test_label,CATEGORY_SIZE)\n    test_data = np.asarray(test_data)\n    test_data = test_data.astype('float32')/255.0    \n    \ndef read_size():\n    size_data = pd.read_csv(\"/kaggle/input/fortest/kind.csv\", index_col=0)\n    #size_data.set_index('kind')\n    #print(size_data)\n    return size_data\n\ndef model_create():\n\n    model = keras.models.load_model(\"./my_model.h5\")\n    return model\n        \ndef main():\n    global test_data, test_label\n    \n    size_data = read_size()\n    mydict = read_image_fn()\n    read_img(mydict, size_data)\n    model = model_create()\n    \n    predictions = model.predict(test_data)\n    \n    for i in range(len(predictions)): \n        print(\"[\",i,\"]=\", np.argmax(predictions[i]), \"test_label=\", np.argmax(test_label[i]))\n        with open('result.csv', 'a') as f:\n            f.writelines(str(np.argmax(predictions[i]))+\",\"+str(np.argmax(test_label[i]))+\"\\n\")\n                          \nif __name__ == \"__main__\":\n    main()\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is modified from above code. So useless code are included. This produved table for unmatched count between prediction and actual label. and from this result, \"cat\" and \"dog\" are difficult to recognized correctly for this simple model.","metadata":{}},{"cell_type":"code","source":"#coding:cp932\n# 2021.04.05 14.17 Created\n\nimport numpy as np\nimport pandas as pd\n#import glob\nimport os\nfrom keras.preprocessing.image import load_img\nfrom keras.utils.np_utils import to_categorical\n\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras import layers, optimizers\nfrom keras.preprocessing.image import img_to_array, load_img\n\nkind_data = {'airplane':0 ,'car':1,'cat':2,'dog':3,'flower':4,'fruit':5,'motorbike':6,'person':7}\nCATEGORY_SIZE=8\n    \ndef read_size():\n    size_data = pd.read_csv(\"result.csv\", names=('pre','tst'))\n    print(size_data)\n    return size_data\n        \ndef main():\n   \n    size_data = read_size()\n    \n    data_frame = pd.DataFrame()\n    \n    for my_key_i,my_value_i in kind_data.items():\n        for my_key_j, my_value_j in kind_data.items():\n            data_frame.loc[my_key_i, my_key_j] = 0\n    \n    print(data_frame)\n    j = 0\n\n    for i in range(len(size_data)):\n        pre = int(size_data.iloc[i]['pre'])\n        tst = int(size_data.iloc[i]['tst'])\n        pre_key = [k for k, v in kind_data.items() if v == pre]\n        tst_key = [k for k, v in kind_data.items() if v == tst]\n        if size_data.iloc[i]['pre'] != size_data.iloc[i]['tst']:\n            j += 1\n            print(j, \" \", \"pre=\",pre_key, \"tst=\", tst_key)\n            data_frame.loc[pre_key,tst_key] += 1\n\n    print(data_frame)\n                          \nif __name__ == \"__main__\":\n    main()\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}