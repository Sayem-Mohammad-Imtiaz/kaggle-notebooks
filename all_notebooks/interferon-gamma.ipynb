{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('../input/cusersmarildownloadsinterferoncsv/interferon.csv', delimiter=';', encoding = \"ISO-8859-1\", nrows = nRowsRead)\ndf.dataframeName = 'cusersmarildownloadsinterferoncsv/interferon.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_percent = (df.isnull().sum()/len(df))[(df.isnull().sum()/len(df))>0].sort_values(ascending=False)\n\nmissing_data = pd.DataFrame({'Missing Percentage':na_percent*100})\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a Visualization of every feature with missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"na = (df.isnull().sum() / len(df)) * 100\nna = na.drop(na[na == 0].index).sort_values(ascending=False)\n\nf, ax = plt.subplots(figsize=(12,8))\nsns.barplot(x=na.index, y=na)\nplt.xticks(rotation='90')\nplt.xlabel('Features', fontsize=15)\nplt.title('Percentage Missing', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing Features which are numerical with 0 and 'None' for categorical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#for col in ('Age'):\n #   df[col] = df[col].fillna(0)\n    \nfor col in ['Group', 'IFNG+874', 'IGRA result', 'TST result', 'Sex', 'Ethnic background']:\n    df[col] = df[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('Ag normalized', 'PHA normalized', 'CD3+ number', 'Ag IFN-y pg/ml', 'PHA IFN-y pg/ml', 'unstimulated IFN-y pg/ml', 'Registry' ):\n    df[col] = df[col].fillna(df[col].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I tried to fill Age column, however I got error: A. Therefore I didn't make imputation with that feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = [cname for cname in df.columns if\n                    df[cname].nunique() < 10 and \n                    df[cname].dtype == \"object\"]\n\n\n# Select numerical columns\nnumerical_cols = [cname for cname in df.columns if \n                df[cname].dtype in ['int64', 'float64']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(categorical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nsns.countplot(df['IFNG+874'],linewidth=3,palette=\"Set2\",edgecolor='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Label Encoding. Our dataset cannot run with categorical columns so we must Label Encode these columns in order to make them numerical.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncategorical_col = ('Group', 'IFNG+874', 'IGRA result', 'TST result', 'Sex', 'Ethnic background')\n        \n        \nfor col in categorical_col:\n    label = LabelEncoder() \n    label.fit(list(df[col].values)) \n    df[col] = label.transform(list(df[col].values))\n\nprint('Shape all_data: {}'.format(df.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes from Vinod R https://www.kaggle.com/vinodsunny1/let-s-think-like-a-heart-surgeon","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (14,5)\nplt.subplot(1,2,1)\nsns.kdeplot(df['IFNG+874'][df.Group == 1],shade = True,color = \"red\")\nplt.title('IFNG+874')\nplt.xlabel('IFNG+874 Distribution ')\nplt.subplot(1,2,2)\nsns.kdeplot(df['IGRA result'][df.Group == 0],shade = True,color = \"green\")\nplt.title('IGRA result')\nplt.xlabel('IGRA Result Distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's See The Correlation Among The Features .\n\n# Below chart is used to visualize how one feature is correlated with every other Features Present in the dataset .\n# if we have two highly correlated features then we will consider only one of them to avoid overfitting .\n\n# since in our Dataset There is now two  features which are highly correlated ,\n# hence we have consider all the features for training our Model .\n\n\nplt.rcParams['figure.figsize'] = (10, 6)\nsns.heatmap(df.corr(),annot = True ,cmap = 'rainbow_r',annot_kws = {\"Size\":14})\nplt.title( \"Chart Shows Correlation Among Features   : \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm, skew\nnum_features = df.dtypes[df.dtypes != 'object'].index\nskewed_features = df[num_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_features})\nskewness.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_df = df.select_dtypes(exclude='object')\n\nfor i in range(len(numerical_df.columns)):\n    f, ax = plt.subplots(figsize=(7, 4))\n    fig = sns.distplot(numerical_df.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n    plt.xlabel(numerical_df.columns[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes from Mario Filho https://www.kaggle.com/mariofilho/live26-https-youtu-be-zseefujo0zq","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from category_encoders import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n\ncols_selected = ['IFNG+874']\nohe = OneHotEncoder(cols=cols_selected, use_cat_names=True)\ndf_t = ohe.fit_transform(df[cols_selected+['Age']])\n\n#scaler = MaxAbsScaler()\nX = df_t.iloc[:,:-1]\ny = df_t.iloc[:, -1].fillna(df_t.iloc[:, -1].mean()) / df_t.iloc[:, -1].max()\n\nmdl = Ridge(alpha=0.1)\nmdl.fit(X,y)\n\npd.Series(mdl.coef_, index=X.columns).sort_values().head(10).plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['IFNG+874'].hist(figsize=(10,4), bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df['IFNG+874'].value_counts().plot.barh(figsize=(10, 4))\nax.set_title('IFNG+874 Distribution', size=18)\nax.set_ylabel('IFNG+874', size=10)\nax.set_xlabel('Group', size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.ticker as ticker\nax = sns.distplot(df['IFNG+874'])\nplt.xticks(rotation=45)\nax.xaxis.set_major_locator(ticker.MultipleLocator(2))\nfigsize=(10, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm, skew #for some statistics\nimport seaborn as sb\nfrom scipy import stats #qqplot\n#Lets check the ditribution of the target variable (Placement?)\nfrom matplotlib import rcParams\n# figure size in inches\nrcParams['figure.figsize'] = 4,2\n\nsb.distplot(df['IFNG+874'], fit=norm)\n\n#Get the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df['IFNG+874'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n#The data is highly skewed, but since we'll be applying ARIMA, it's fine.\ndf['IFNG+874'].skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Das War's Kaggle Notebook Runner: MarÃ­lia Prata   @mpwolke","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}