{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle                         \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport sklearn\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We are dropping the first column, So we start it from 1 2 3 4. Because it was not important to us. \n\n\ndf=pd.read_csv(\"../input/advertising-dataset/advertising.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()  #viewing the first five rows of the Data.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()   #Viewing the Last 5 rows of the Data. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape  #Shapes and Dimensions of the Data. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datatype \n","metadata":{}},{"cell_type":"code","source":"df.info()  # Datatype of the Columns. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking Null Values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Observations\n\nOur observations are as follows\n\nNaN values do not present in the data set. Because of the Non-Null Count and number of rows in the dataset match.\n\nThere are 3 Input Variables and 1 Output Variable (Sales)\n\nThe data type of all the input variables is float64. The data type of out variable (Sales) is float64.\n\nShows that all the input as well as output variables are continuous (quantitative) data types.\n\nNone of the columns contain the Null Values","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"  ","metadata":{}},{"cell_type":"code","source":"pd.set_option('precision', 2)         # 2 values after precision. \ndf.describe()                 # Statistical Summary of the Data.   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T        # Transpose of the Describe function.   ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We can see that the min value of Radio is zero. We need to confirm how many zero values existing in the dataset.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Analysis of Zero Values in Predictors\n","metadata":{}},{"cell_type":"code","source":"(df == 0).sum(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, There is only one value which is zero. So, we do not required to handle it. So, Data Cleansing is not required. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Response Variable Analysis","metadata":{}},{"cell_type":"code","source":"df.Sales.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 121 Unique values. So our response variable is continuous. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relationship - Predictor and Response\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ncorrmat = df.corr()                        #pariwise correlation of all the columns \ntop_corr_features = corrmat.index                     #  Index(['TV', 'Radio', 'Newspaper', 'Sales'], dtype='object')\nplt.figure(figsize = (10,10))\n\n#heatmap of the data\n\ng = sns.heatmap(df[top_corr_features].corr(),annot = True, cmap=\"RdYlGn\") # annot present values in the blocks. cmap = colormap ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('precision', 2)         # 2 values after precision. \n\ndf.corr()   #Correlation between Variables.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('precision', 2)         # 2 values after precision. \n\ndf.corr().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pair plot of correlation\n\nimport seaborn as sns\nsns.pairplot(df)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relationship between Sales and TV\n","metadata":{}},{"cell_type":"code","source":"sns.regplot(df.TV, df.Sales, order=1, ci=None, scatter_kws={'color':'g', 's':9})   # 's':9 denote the size of dots. \nplt.xlim(-10,310)                                                                 \nplt.ylim(0,30)                                                                # y axis values are start from 0 \n#plt.ylim(bottom=0)\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relationship between Sales and Radio\n","metadata":{}},{"cell_type":"code","source":"sns.regplot(df.Radio, df.Sales, order=1, ci=None, scatter_kws={'color':'g', 's':9})    \nplt.xlim(-2,55)\nplt.ylim(bottom=0)   \n#plt.ylim(0,30)      \nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relationship between Sales and Newspaper\n","metadata":{}},{"cell_type":"code","source":"sns.regplot(df.Newspaper, df.Sales, order=1, ci=None, scatter_kws={'color':'g', 's':9}) \nplt.xlim(-10,115)  \n#plt.ylim(0,30)      \nplt.ylim(bottom=0)\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We need the Scaling the Data because the values of the TV are more greater than the Radio and Newspaper.  ","metadata":{}},{"cell_type":"markdown","source":"# Data Normalization\n","metadata":{}},{"cell_type":"markdown","source":"# Scaling the TV Data.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import scale                # we can also use StandardScalar. \nX = scale(df.TV, with_mean=True, with_std=False).reshape(-1,1)\ny = df.Sales     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T        # Transpose of the Describe function.   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[0:5]      #printing first five rows. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.mean()   #very near to zero. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.std()        # we give false value. So it is same as it is. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Regression for Scaled Data using Sklearn","metadata":{}},{"cell_type":"code","source":"import sklearn\nimport sklearn.linear_model as skl_lm\nfrom sklearn.linear_model import LinearRegression\n\nregr = skl_lm.LinearRegression()\nregr.fit(X,y)\nLinearRegression()\n\nregr.intercept_ ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr.coef_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_rss = np.sum((regr.intercept_+regr.coef_*X - y.values.reshape(-1,1))**2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_rss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\nSales_pred = regr.predict(X)                       # Value of Target variable when we predict it with the Independent variable. \nr2_score(y, Sales_pred) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(y, Sales_pred)                        # Know about the error between actual and predicted. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linaer Regression for Unscaled Data using Sklearn","metadata":{}},{"cell_type":"code","source":"regr = skl_lm.LinearRegression()\nX = df.TV.values.reshape(-1,1)\ny = df.Sales\nregr.fit(X,y)\nregr.score(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr.intercept_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr.coef_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Residual Sum of Squares","metadata":{}},{"cell_type":"code","source":"min_rss = np.sum((regr.intercept_+regr.coef_*X - y.values.reshape(-1,1))**2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_rss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MSE\n","metadata":{}},{"cell_type":"code","source":"mse = min_rss/len(y)                                   #  min_rss / degree of freedom   \nmse                                     #value should be 0 to infinite but not negative. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# R-Sq using Sklearn\n","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.metrics import mean_squared_error, r2_score\nSales_pred = regr.predict(X)                       # Value of Target variable when we predict it with the Independent variable. \nr2_score(y, Sales_pred) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MSE using SKLearn\n\n","metadata":{}},{"cell_type":"code","source":"mean_squared_error(y, Sales_pred)                        # Know about the error between actual and predicted. ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" \n   \n     \n     \n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Regression Summary using Statsmodel","metadata":{}},{"cell_type":"code","source":"#  OLS = ordinary least square method. \n\n\n\n\nimport statsmodels.api as sm\nX2 = sm.add_constant(X)\nest = sm.OLS(y,X2) \nest2=est.fit()\nest2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.formula.api as smf\nest = smf.ols('Sales ~ TV', df).fit()\nest.summary()   # est.summary().tables[0/1/2]   \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Regression RSS and MSE\nest.params                         \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RSS\n((df.Sales - (est.params[0] + est.params[1] * df.TV))** 2).sum()          # **2 means squaring. \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MSE\n((df.Sales - (est.params[0] + est.params[1]*df.TV))** 2).sum()/len(df.Sales)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression Sales and Radio\n\nest = smf.ols('Sales ~ Radio', df).fit()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(est.summary().tables[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The value of Beta_1  is less than 0.05 then we can say there is a relationship. If we spend 1000 dollers in Newspaper then we got 202.5+9.3116 in Sales. ","metadata":{}},{"cell_type":"code","source":"# Linear Regression Sales and Newspaper\n\nest = smf.ols('Sales ~ Newspaper', df).fit()\nprint(est.summary().tables[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multiple Linear Regression\n","metadata":{}},{"cell_type":"code","source":"est = smf.ols('Sales ~ TV + Radio + Newspaper', df).fit()\nest.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quantify the extent to which model fits the data or measure of lack of fit using 4 Methods\n\nMultiple R   <br>\n R Statistics<br>\nAdjusted  Statistics<br>\nResidual Standard Error<br>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multiple Linear Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['Sales'],axis=1)\ny = df['Sales']\nX_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.5, random_state=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.linear_model as skl_lm\nregr = skl_lm.LinearRegression()\nregr.fit(X_train,y_train)\n\nround( (regr.score(X_test,y_test)*100) , 2   )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nround( (regr.score(X_train,y_train)*100) , 2   ) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr.score(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = regr.predict(X_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr.predict([[20,334.34,34.3443]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr.predict([[20,30,230]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(3,3) ) \nplt.scatter(y_test, y_pred) \nplt.xlabel('Actual')\nplt.ylabel('Predicted')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Difference': y_test-y_pred})\ndf1.head(10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\njoblib.dump(regr, \"marketing_model.pkl\")    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas_profiling as pp\nprofile = pp.ProfileReport(df)\nprofile.to_file(\"output.html\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}