{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/sites-information-data-from-alexacom-dataset/alexa.com_site_info.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols3 = ['all_topics_easy_to_rank_keywords_search_pop_parameter_1',\n       'all_topics_easy_to_rank_keywords_search_pop_parameter_2',\n       'all_topics_easy_to_rank_keywords_search_pop_parameter_3',\n       'all_topics_easy_to_rank_keywords_search_pop_parameter_4']\n\ncols2 = ['all_topics_easy_to_rank_keywords_relevance_to_site_parameter_1',\n       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_2',\n       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_3',\n       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_4',]\n\ncols4 = ['all_topics_keyword_gaps_Avg_traffic_parameter_1',\n       'all_topics_keyword_gaps_Avg_traffic_parameter_2',\n       'all_topics_keyword_gaps_Avg_traffic_parameter_3',\n       'all_topics_keyword_gaps_Avg_traffic_parameter_4']\n\n##########################################################################################\n\ncols5 = ['all_topics_keyword_gaps_search_popularity_parameter_1',\n       'all_topics_keyword_gaps_search_popularity_parameter_2',\n       'all_topics_keyword_gaps_search_popularity_parameter_3',\n       'all_topics_keyword_gaps_search_popularity_parameter_4']\n\ncols6 = ['all_topics_buyer_keywords_Avg_traffic_parameter_1',\n        'all_topics_buyer_keywords_Avg_traffic_parameter_2',\n        'all_topics_buyer_keywords_Avg_traffic_parameter_3',\n        'all_topics_buyer_keywords_Avg_traffic_parameter_4']\n\ncols7 = ['all_topics_buyer_keywords_organic_competition_parameter_1',\n        'all_topics_buyer_keywords_organic_competition_parameter_2',\n        'all_topics_buyer_keywords_organic_competition_parameter_3',\n        'all_topics_buyer_keywords_organic_competition_parameter_4']\n\ncols8 = ['all_topics_optimization_opportunities_search_pop_parameter_1',\n        'all_topics_optimization_opportunities_search_pop_parameter_2',\n        'all_topics_optimization_opportunities_search_pop_parameter_3',\n        'all_topics_optimization_opportunities_search_pop_parameter_4']\n\ncols9 = ['all_topics_optimization_opportunities_organic_share_of_voice_parameter_1',\n        'all_topics_optimization_opportunities_organic_share_of_voice_parameter_2',\n        'all_topics_optimization_opportunities_organic_share_of_voice_parameter_3',\n        'all_topics_optimization_opportunities_organic_share_of_voice_parameter_4']\n\ncols10 = ['all_topics_top_keywords_search_traffic_parameter_1',\n         'all_topics_top_keywords_search_traffic_parameter_2',\n         'all_topics_top_keywords_search_traffic_parameter_3',\n         'all_topics_top_keywords_search_traffic_parameter_4']\n\ncols11 = ['all_topics_top_keywords_share_of_voice_parameter_1_percentage',\n         'all_topics_top_keywords_share_of_voice_parameter_2_percentage',\n         'all_topics_top_keywords_share_of_voice_parameter_3_percentage',\n         'all_topics_top_keywords_share_of_voice_parameter_4_percentage']\n\ncols12 = ['audience_overlap_sites_overlap_scores_parameter_1',\n         'audience_overlap_sites_overlap_scores_parameter_2',\n         'audience_overlap_sites_overlap_scores_parameter_3',\n         'audience_overlap_sites_overlap_scores_parameter_4',\n         'audience_overlap_sites_overlap_scores_parameter_5']\n\ncols13 = ['audience_overlap_similar_sites_to_this_site_parameter_1',\n         'audience_overlap_similar_sites_to_this_site_parameter_2',\n         'audience_overlap_similar_sites_to_this_site_parameter_3',\n         'audience_overlap_similar_sites_to_this_site_parameter_4',\n         'audience_overlap_similar_sites_to_this_site_parameter_5']\n\ndf.loc[:,'all_topics_easy_to_rank_relevance_to_site_average'] = df.loc[:, cols2].mean(axis=1)\ndf.loc[:,'all_topics_easy_to_rank_keywords_search_pop_average'] = df.loc[:, cols3].mean(axis=1)\ndf.loc[:,'all_topics_keyword_gaps_Avg_traffic_average'] = df.loc[:, cols4].mean(axis=1)\ndf.loc[:,'all_topics_keyword_gaps_search_popularity_average'] = df.loc[:, cols5].mean(axis=1)\n\ndf.loc[:,'all_topics_buyer_keywords_Avg_traffic_average'] = df.loc[:, cols6].mean(axis=1)\ndf.loc[:,'all_topics_buyer_keywords_organic_competition_average'] = df.loc[:, cols7].mean(axis=1)\ndf.loc[:,'all_topics_optimization_opportunities_search_pop_average'] = df.loc[:, cols8].mean(axis=1)\ndf.loc[:,'all_topics_optimization_opportunities_organic_share_of_voice_average'] = df.loc[:, cols9].mean(axis=1)\ndf.loc[:,'all_topics_top_keywords_search_traffic_average'] = df.loc[:, cols10].mean(axis=1)\ndf.loc[:,'all_topics_top_keywords_share_of_voice_average'] = df.loc[:, cols11].mean(axis=1)\ndf.loc[:,'audience_overlap_sites_overlap_scores_average'] = df.loc[:, cols12].mean(axis=1)\ndf.loc[:,'audience_overlap_similar_sites_to_this_site_average'] = df.loc[:, cols13].mean(axis=1)\n\n# Ali ! sotoon haye zir ro ham too clustring et estefade kon ina taki an o dige parameter i nadaran o average barashoon maani nadare\n# 'comparison_metrics_search_traffic_this_site_percentage'\n# 'comparison_metrics_search_traffic_Comp Avg_percentage'\n# 'comparison_metrics_data_bounce_rate_this_site_percentage'\n# 'comparison_metrics_data_bounce_rate_comp_avg_percentage'\n# 'comparison_metrics_data_sites_linking_in_this_site_percentage'\n# 'comparison_metrics_data_sites_linking_in_comp_avg_percentage'\n# 'This_site_rank_in_global_internet_engagement'\n# 'Daily_time_on_site'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(df['all_topics_keyword_gaps_Avg_traffic_average'].to_numpy(),\n           df['all_topics_keyword_gaps_search_popularity_average'].to_numpy())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.cluster import OPTICS\nmodel = OPTICS(max_eps=3, min_samples=60)\nyhat = model.fit_predict(df[['all_topics_keyword_gaps_Avg_traffic_average', \n                              'all_topics_keyword_gaps_search_popularity_average']].to_numpy())\nclusters = np.unique(yhat)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = df[['all_topics_keyword_gaps_Avg_traffic_average', \n                              'all_topics_keyword_gaps_search_popularity_average']].to_numpy()\nfor cluster in clusters:\n\t# get row indexes for samples with this cluster\n\trow_ix = np.where(yhat == cluster)\n\t# create scatter of these samples\n\tplt.scatter(X[row_ix, 0], X[row_ix, 1])\n# show the plot\nplt.show()\nlen(clusters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df[['all_topics_easy_to_rank_keywords_search_pop_average', \n                              'all_topics_easy_to_rank_relevance_to_site_average']].to_numpy()[[1,2,3]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\nfrom keras.engine.topology import Layer, InputSpec\nfrom keras.layers import Dense, Input\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom keras import callbacks\nfrom keras.initializers import VarianceScaling\nfrom sklearn.cluster import KMeans\n\n\ndef autoencoder(dims, act='relu', init='glorot_uniform'):\n    \"\"\"\n    Fully connected auto-encoder model, symmetric.\n    Arguments:\n        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n        act: activation, not applied to Input, Hidden and Output layers\n    return:\n        (ae_model, encoder_model), Model of autoencoder and model of encoder\n    \"\"\"\n    n_stacks = len(dims) - 1\n    # input\n    input_img = Input(shape=(dims[0],), name='input')\n    x = input_img\n    # internal layers in encoder\n    for i in range(n_stacks-1):\n        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n\n    # hidden layer\n    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n\n    x = encoded\n    # internal layers in decoder\n    for i in range(n_stacks-1, 0, -1):\n        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n\n    # output\n    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n    decoded = x\n    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx = np.concatenate((x_train, x_test))\ny = np.concatenate((y_train, y_test))\nx = x.reshape((x.shape[0], -1))\nx = np.divide(x, 255.)\n\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = len(np.unique(y))\nkmeans = KMeans(n_clusters=n_clusters, n_init=20, n_jobs=4)\ny_pred_kmeans = kmeans.fit_predict(x)\nUnsupervised Clustering with Autoencoder\n 3 minute read\nK-Means cluster sklearn tutorial\nThe \nK\n-means algorithm divides a set of \nN\n samples \nX\n into \nK\n disjoint clusters \nC\n, each described by the mean \nÎ¼\nj\n of the samples in the cluster\nkmeans = KMeans(n_clusters=2,verbose=0,tol=1e-3,max_iter=300,n_init=20)\n# Private includes Yes,No classification => n_clusters now is 2\nkmeans.fit(df.drop('Private',axis=1))\n\nclus_cent=kmeans.cluster_centers_\nclus_cent\n\nkmeans.labels_ => [0 or 1] labeled \nfrom sklearn.metrics import confusion_matrix,classification_report\nprint(confusion_matrix(df1['Cluster'],kmeans.labels_))\nprint(classification_report(df1['Cluster'],kmeans.labels_))\n\nDeep Clustering\nBuild autoencoder model, encoder and decoder\nimport keras.backend as K\nfrom keras.engine.topology import Layer, InputSpec\nfrom keras.layers import Dense, Input\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom keras import callbacks\nfrom keras.initializers import VarianceScaling\nfrom sklearn.cluster import KMeans\n\n\ndef autoencoder(dims, act='relu', init='glorot_uniform'):\n    \"\"\"\n    Fully connected auto-encoder model, symmetric.\n    Arguments:\n        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n        act: activation, not applied to Input, Hidden and Output layers\n    return:\n        (ae_model, encoder_model), Model of autoencoder and model of encoder\n    \"\"\"\n    n_stacks = len(dims) - 1\n    # input\n    input_img = Input(shape=(dims[0],), name='input')\n    x = input_img\n    # internal layers in encoder\n    for i in range(n_stacks-1):\n        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n\n    # hidden layer\n    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n\n    x = encoded\n    # internal layers in decoder\n    for i in range(n_stacks-1, 0, -1):\n        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n\n    # output\n    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n    decoded = x\n    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')\nMNIST batch data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx = np.concatenate((x_train, x_test))\ny = np.concatenate((y_train, y_test))\nx = x.reshape((x.shape[0], -1))\nx = np.divide(x, 255.)\n\nx_train.shape\n(60000, 28, 28)\nx.shape\n(7000,784)\nCluster number is MNIST Classification number\nn_clusters = len(np.unique(y))\n10\nKmeans Training\nkmeans = KMeans(n_clusters=n_clusters, n_init=20, n_jobs=4)\ny_pred_kmeans = kmeans.fit_predict(x)\ny_pred_kmeans[:10]\n>>array([0, 6, 2, 4, 3, 8, 7, 0, 7, 3], dtype=int32)\nx.shape[-1] => 784(28*28)\n# 10 means the 10 MINST classification\ndims = [x.shape[-1], 500, 500, 2000, 10]\ninit = VarianceScaling(scale=1. / 3., mode='fan_in',\n                           distribution='uniform')\npretrain_optimizer = SGD(lr=1, momentum=0.9)\n\n# dims represents the dense layer units number : 5 layers have each unit cell number\nautoencoder, encoder = autoencoder(dims, init=init)\n\nautoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\nautoencoder.fit(x, x, batch_size=batch_size, epochs=pretrain_epochs) #, callbacks=cb)\nautoencoder.save_weights(save_dir + '/ae_weights.h5')\nclass ClusteringLayer(Layer):\n    \n\n    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n        super(ClusteringLayer, self).__init__(**kwargs)\n        self.n_clusters = n_clusters\n        self.alpha = alpha\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 2\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True\n\n    def call(self, inputs, **kwargs):\n    \n        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n        q **= (self.alpha + 1.0) / 2.0\n        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n        return q\n\n    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) == 2\n        return input_shape[0], self.n_clusters\n\n    def get_config(self):\n        config = {'n_clusters': self.n_clusters}\n        base_config = super(ClusteringLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\nclustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\nmodel = Model(inputs=encoder.input, outputs=clustering_layer)\nmodel.compile(optimizer=SGD(0.01, 0.9), loss='kld')\nmodel.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n\nencoder.output","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}