{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom spacy.lang.en import STOP_WORDS\nfrom sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS, TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom collections import Counter\nfrom sklearn.metrics import classification_report\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    train = pd.read_csv(\"../input/janatahack-independence-day-2020-ml-hackathon/train.csv\")\n    test = pd.read_csv(\"../input/janatahack-independence-day-2020-ml-hackathon/test.csv\")\n    sample = pd.read_csv(\"../input/janatahack-independence-day-2020-ml-hackathon/sample_submission_UVKGLZE.csv\")\n    train.drop(\"ID\", axis=1, inplace=True)\n    test.drop(\"ID\", axis=1, inplace=True)\n    print(f\"Train data shape : {train.shape}\")\n    print(f\"Test data shape : {test.shape}\")\n    return (train, test, sample)\ntrain, test, sample = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = ['Computer Science','Physics','Mathematics','Statistics','Quantitative Biology','Quantitative Finance']\ntrain[target].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef url(text):\n    url_check = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n    clean = re.sub(url_check, \"\", text)\n    return clean\n\ndef num_repl(text):\n    num_check = \"([0-9,]*)\"\n    clean = re.sub(num_check, \"\", text).strip()\n    return clean\n\ndef remove_stop(text):\n    word_list = text.lower().split()\n    stopword_dict = Counter(STOP_WORDS)\n    newlist = [word.strip() for word in word_list if word not in stopword_dict]\n    sentence = \" \".join(newlist)\n    \n    sentence = url(sentence)\n    sentence = num_repl(sentence)\n    from string import punctuation\n    #punctuations = '''@#!?+&*[]%.:/-();$=><|{}^'`\\\\'''\n    punctuations = set(punctuation)\n    for p in punctuations:\n        sentence = sentence.replace(p, \" \")\n    sentence.strip()\n    \n    return sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"text\"] = train.TITLE + \" \" + train.ABSTRACT\ntest[\"text\"] = test.TITLE + \" \" + test.ABSTRACT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_repl = [(\"- -\",\" \"),(\"--\",\" \"),(\"-\",\" \"),(\"_\",\" \")]\nfor old, new in text_repl:\n    train.text = train.text.str.replace(old, new)\n    test.text = test.text.str.replace(old, new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"clean_text\"] = train.text.apply(remove_stop)\ntest[\"clean_text\"] = test.text.apply(remove_stop)\n\ntrain[\"clean_text\"] = train.clean_text.apply(lambda x: \" \".join([w for w in x.split() if (len(w)>2)]))\ntest[\"clean_text\"] = test.clean_text.apply(lambda x: \" \".join([w for w in x.split() if (len(w)>2)]))\n\ntrain[\"clean_text\"] = train.clean_text.apply(lambda x: \" \".join([w for w in x.split() if (len(set(w))>2)]))\ntest[\"clean_text\"] = test.clean_text.apply(lambda x: \" \".join([w for w in x.split() if (len(set(w))>2)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nfrom nltk.stem.snowball import EnglishStemmer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wnl = WordNetLemmatizer()\nstemmer = EnglishStemmer()\ndef word_lem_stem(text, lemm = True):\n    if lemm:\n        normalized = \" \".join([wnl.lemmatize(word) for word in text.split()])\n        return normalized\n    else:\n        normalized = \" \".join([stemmer.stem(word) for word in text.split()])\n        return normalized\n    \ntrain[\"final_text\"] = train.clean_text.apply(lambda x: word_lem_stem(x,True))\ntest[\"final_text\"] = test.clean_text.apply(lambda x: word_lem_stem(x,True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"count_unique\"] = train.clean_text.apply(lambda x: len(set(x.split())))\ntest[\"count_unique\"] = test.clean_text.apply(lambda x: len(set(x.split())))\n\n# add feature len of the text for each record","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_sub(file):\n    sample.to_csv(\"/kaggle/working/model_\"+file+\".csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pred_model(model, x, y, train_size=0.7, seed=1):\n    xtrain, xtest, ytrain, ytest = train_test_split(x, y, train_size=train_size, random_state = 1)\n    #xtrain = vectorizer.fit_transform(xtrain)\n    #cols = vectorizer.get_feature_names()\n    #xtest = vectorizer.transform(xtest)\n    model.fit(xtrain, ytrain)\n\n    trainpred = model.predict(xtrain)\n    testpred = model.predict(xtest)\n    \n    print(\"Train...\")\n    print(classification_report(ytrain, trainpred))\n    print(\"Test...\")\n    print(classification_report(ytest, testpred))\n\ndef total_model(model, x, y, test, seed=1):\n    #x = vectorizer.fit_transform(x)\n    #cols = vectorizer.get_feature_names()\n    #test = vectorizer.transform(test)\n    model.fit(x, y)\n\n    trainpred = model.predict(x)\n    pred = model.predict(test)\n    \n    print(\"Train...\")\n    print(classification_report(y, trainpred))\n    return(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train[\"final_text\"]\nY = train[target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nb = MultinomialNB()\nmodel_rf = RandomForestClassifier(random_state=1, n_jobs=8)\nmodel_logr = LogisticRegression(random_state=1, n_jobs=8)\nmodel_lgbm = LGBMClassifier(random_state=1, n_jobs=8)\nmodel_svc = SVC()\ncv = CountVectorizer()\ntfidf = TfidfVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\nfrom sklearn.pipeline import make_pipeline, Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb = XGBClassifier(random_state=1, n_jobs=8)#, n_estimators=100, max_depth=6, reg_alpha=0.1)\nmodel_multi = MultiOutputClassifier(model_xgb, n_jobs=8)\n\npipe = Pipeline([('countvector',cv),('multi',model_multi)])\npipe.named_steps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train[\"final_text\"]\nY = train[target]\npred_model(pipe, X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = total_model(pipe, X, Y, test.final_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.iloc[:,1:] = pred\nsample.iloc[:,1:].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_sub('xgb')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}