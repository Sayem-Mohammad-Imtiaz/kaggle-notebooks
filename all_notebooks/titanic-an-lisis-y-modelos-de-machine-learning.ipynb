{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importa bibliotecas\nimport numpy as np\nimport pandas as pd\nimport random as rnd\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Modelling Algorithms\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n\n# Modelling Helpers\nfrom sklearn.preprocessing import Normalizer , scale\nfrom sklearn.model_selection import train_test_split , StratifiedKFold\nfrom sklearn.feature_selection import RFECV\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nsns.set_style( 'white' )\npylab.rcParams[ 'figure.figsize' ] = 8 , 6\n\n#MODELOS Y METRICAS\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:36:55.506108Z","iopub.execute_input":"2021-05-28T02:36:55.506565Z","iopub.status.idle":"2021-05-28T02:36:55.527794Z","shell.execute_reply.started":"2021-05-28T02:36:55.506517Z","shell.execute_reply":"2021-05-28T02:36:55.52606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define funciones de estadistica descriptiva\ndef plot_histograms( df , variables , n_rows , n_cols ):\n    fig = plt.figure( figsize = ( 16 , 12 ) )\n    for i, var_name in enumerate( variables ):\n        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n        df[ var_name ].hist( bins=10 , ax=ax )\n        ax.set_title( 'Skew: ' + str( round( float( df[ var_name ].skew() ) , ) ) ) # + ' ' + var_name ) #var_name+\" Distribution\")\n        ax.set_xticklabels( [] , visible=False )\n        ax.set_yticklabels( [] , visible=False )\n    fig.tight_layout()  # Improves appearance a bit.\n    plt.show()\n\ndef plot_distribution( df , var , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n    facet.map( sns.kdeplot , var , shade= True )\n    facet.set( xlim=( 0 , df[ var ].max() ) )\n    facet.add_legend()\n    \ndef plot_categories( df , cat , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , row = row , col = col )\n    facet.map( sns.barplot , cat , target )\n    facet.add_legend()\n\ndef plot_correlation_map( df ):\n    corr = train_df.corr()\n    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(\n        corr, \n        cmap = cmap,\n        square=True, \n        cbar_kws={ 'shrink' : .9 }, \n        ax=ax, \n        annot = True, \n        annot_kws = { 'fontsize' : 12 }\n    )\n    \ndef describe_more( df ):\n    var = [] ; l = [] ; t = []\n    for x in df:\n        var.append( x )\n        l.append( len( pd.value_counts( df[ x ] ) ) )\n        t.append( df[ x ].dtypes )\n    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n    levels.sort_values( by = 'Levels' , inplace = True )\n    return levels\n\ndef plot_variable_importance( X , y ):\n    tree = DecisionTreeClassifier( random_state = 99 )\n    tree.fit( X , y )\n    plot_model_var_imp( tree , X , y )\n    \ndef plot_model_var_imp( model , X , y ):\n    imp = pd.DataFrame( \n        model.feature_importances_  , \n        columns = [ 'Importance' ] , \n        index = X.columns \n    )\n    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n    imp[ : 10 ].plot( kind = 'barh' )\n    print (model.score( X , y ))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:14:13.167029Z","iopub.execute_input":"2021-05-28T02:14:13.167406Z","iopub.status.idle":"2021-05-28T02:14:13.185722Z","shell.execute_reply.started":"2021-05-28T02:14:13.167375Z","shell.execute_reply":"2021-05-28T02:14:13.184626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importa los datos\ntrain_df = pd.read_csv('../input/titanic-machine-learning-from-disaster/train.csv')\ntest_df = pd.read_csv('../input/titanic-machine-learning-from-disaster/test.csv')\n\ncombine = [train_df, test_df]\n\ndataSet_df = pd.concat(combine, sort = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:29.31874Z","iopub.execute_input":"2021-05-28T02:27:29.319232Z","iopub.status.idle":"2021-05-28T02:27:29.342347Z","shell.execute_reply.started":"2021-05-28T02:27:29.319202Z","shell.execute_reply":"2021-05-28T02:27:29.341592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataSet_df.columns.values)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:32.272544Z","iopub.execute_input":"2021-05-28T02:27:32.273122Z","iopub.status.idle":"2021-05-28T02:27:32.279118Z","shell.execute_reply.started":"2021-05-28T02:27:32.273076Z","shell.execute_reply":"2021-05-28T02:27:32.277954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tabla con los primeros registros\ndataSet_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:34.82624Z","iopub.execute_input":"2021-05-28T02:27:34.826973Z","iopub.status.idle":"2021-05-28T02:27:34.845046Z","shell.execute_reply.started":"2021-05-28T02:27:34.826933Z","shell.execute_reply":"2021-05-28T02:27:34.844051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#resumen del dataset del número y tipo de variables\ndataSet_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:38.793369Z","iopub.execute_input":"2021-05-28T02:27:38.793877Z","iopub.status.idle":"2021-05-28T02:27:38.812655Z","shell.execute_reply.started":"2021-05-28T02:27:38.793844Z","shell.execute_reply":"2021-05-28T02:27:38.811609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#descripcion del dataset de variables numéricas\ndataSet_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:43.005118Z","iopub.execute_input":"2021-05-28T02:27:43.005473Z","iopub.status.idle":"2021-05-28T02:27:43.040164Z","shell.execute_reply.started":"2021-05-28T02:27:43.005443Z","shell.execute_reply":"2021-05-28T02:27:43.039059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#descripcion del dataset de variables categoricas\ndataSet_df.describe(include=['O'])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:46.454888Z","iopub.execute_input":"2021-05-28T02:27:46.455316Z","iopub.status.idle":"2021-05-28T02:27:46.485303Z","shell.execute_reply.started":"2021-05-28T02:27:46.455281Z","shell.execute_reply":"2021-05-28T02:27:46.484289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafico de correlaciones entre variables\nplot_correlation_map( train_df )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:49.379593Z","iopub.execute_input":"2021-05-28T02:27:49.380093Z","iopub.status.idle":"2021-05-28T02:27:49.951163Z","shell.execute_reply.started":"2021-05-28T02:27:49.38005Z","shell.execute_reply":"2021-05-28T02:27:49.950149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafico de distribucion de la tarifa pagada vs sobrevivencia separado por sexo\nplot_distribution( dataSet_df , var = 'Fare' , target = 'Survived' , row = 'Sex' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:53.368144Z","iopub.execute_input":"2021-05-28T02:27:53.368884Z","iopub.status.idle":"2021-05-28T02:27:54.081404Z","shell.execute_reply.started":"2021-05-28T02:27:53.368821Z","shell.execute_reply":"2021-05-28T02:27:54.080371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafico de distribucion de edad vs sobrevivencia separado por sexo\nplot_distribution( dataSet_df , var = 'Age' , target = 'Survived' , row = 'Sex' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:27:56.971233Z","iopub.execute_input":"2021-05-28T02:27:56.971839Z","iopub.status.idle":"2021-05-28T02:27:57.731778Z","shell.execute_reply.started":"2021-05-28T02:27:56.971785Z","shell.execute_reply":"2021-05-28T02:27:57.730797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafico de lugar de embarque vs sobrevivencia\nplot_categories( dataSet_df , cat = 'Embarked' , target = 'Survived' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:28:02.380444Z","iopub.execute_input":"2021-05-28T02:28:02.380849Z","iopub.status.idle":"2021-05-28T02:28:02.798459Z","shell.execute_reply.started":"2021-05-28T02:28:02.380814Z","shell.execute_reply":"2021-05-28T02:28:02.797066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafico de sexo vs sobrevivencia\nplot_categories( dataSet_df , cat = 'Sex' , target = 'Survived' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:28:07.459155Z","iopub.execute_input":"2021-05-28T02:28:07.459578Z","iopub.status.idle":"2021-05-28T02:28:07.817737Z","shell.execute_reply.started":"2021-05-28T02:28:07.459535Z","shell.execute_reply":"2021-05-28T02:28:07.816973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafico de clase vs sobrevivencia\nplot_categories( dataSet_df , cat = 'Pclass' , target = 'Survived' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:28:10.548171Z","iopub.execute_input":"2021-05-28T02:28:10.548607Z","iopub.status.idle":"2021-05-28T02:28:10.988125Z","shell.execute_reply.started":"2021-05-28T02:28:10.548572Z","shell.execute_reply":"2021-05-28T02:28:10.987149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafico de numero de hermanos/esposo vs sobrevivencia\nplot_categories( dataSet_df , cat = 'SibSp' , target = 'Survived' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:28:13.659664Z","iopub.execute_input":"2021-05-28T02:28:13.660026Z","iopub.status.idle":"2021-05-28T02:28:14.27079Z","shell.execute_reply.started":"2021-05-28T02:28:13.659997Z","shell.execute_reply":"2021-05-28T02:28:14.268984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grafica del numero de hermanos/padres vs sobrevivencia\nplot_categories( dataSet_df , cat = 'Parch' , target = 'Survived' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:04.503689Z","iopub.execute_input":"2021-05-28T02:29:04.504073Z","iopub.status.idle":"2021-05-28T02:29:05.097309Z","shell.execute_reply.started":"2021-05-28T02:29:04.504043Z","shell.execute_reply":"2021-05-28T02:29:05.096114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Crea variables dummies\npclass     = pd.get_dummies( dataSet_df.Pclass , prefix='Pclass' )\n\nsex        = pd.DataFrame(dataSet_df.Sex.map( {'male':0, 'female':1} ).astype(int),columns=['Sex'])\n\nSibSp_size = dataSet_df.SibSp.map( {0:'small', 1:'small', 2:'small', 3:'mid', 4:'mid', 5:'mid', 6:'big', 7:'big', 8:'big'} ).astype(str)\nParch_size = dataSet_df.Parch.map( {0:'small', 1:'small', 2:'small', 3:'mid', 4:'mid', 5:'mid', 6:'big', 7:'big', 8:'big', 9:'big'} ).astype(str)\nsibsp      = pd.get_dummies( SibSp_size , prefix='SibSp' )\nparch      = pd.get_dummies( Parch_size , prefix='Parch' )\n\nembarked   = pd.get_dummies( dataSet_df.Embarked , prefix='Embarked' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:07.956571Z","iopub.execute_input":"2021-05-28T02:29:07.95698Z","iopub.status.idle":"2021-05-28T02:29:07.975541Z","shell.execute_reply.started":"2021-05-28T02:29:07.956947Z","shell.execute_reply":"2021-05-28T02:29:07.974532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Crea la variable title parseando titulos del nombre\ntitle = pd.DataFrame()\n\ntitle[ 'Title' ] = dataSet_df[ 'Name' ].map( lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n\n\nTitle_Dictionary = {\n                    \"Capt\":       \"Officer\",\n                    \"Col\":        \"Officer\",\n                    \"Major\":      \"Officer\",\n                    \"Jonkheer\":   \"Royalty\",\n                    \"Don\":        \"Royalty\",\n                    \"Sir\" :       \"Royalty\",\n                    \"Dr\":         \"Officer\",\n                    \"Rev\":        \"Officer\",\n                    \"the Countess\":\"Royalty\",\n                    \"Dona\":       \"Royalty\",\n                    \"Mme\":        \"Mrs\",\n                    \"Mlle\":       \"Miss\",\n                    \"Ms\":         \"Mrs\",\n                    \"Mr\" :        \"Mr\",\n                    \"Mrs\" :       \"Mrs\",\n                    \"Miss\" :      \"Miss\",\n                    \"Master\" :    \"Master\",\n                    \"Lady\" :      \"Royalty\"\n\n                    }\n\ntitle[ 'Title' ] = title.Title.map( Title_Dictionary )\ntitle = pd.get_dummies( title.Title )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:10.852904Z","iopub.execute_input":"2021-05-28T02:29:10.853253Z","iopub.status.idle":"2021-05-28T02:29:10.867042Z","shell.execute_reply.started":"2021-05-28T02:29:10.853225Z","shell.execute_reply":"2021-05-28T02:29:10.865925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#limpia los registros de la variable ticket\ndef cleanTicket( ticket ):\n    ticket = ticket.replace( '.' , '' )\n    ticket = ticket.replace( '/' , '' )\n    ticket = ticket.split()\n    ticket = map( lambda t : t.strip() , ticket )\n    ticket = list(filter( lambda t : not t.isdigit() , ticket ))\n    if len( ticket ) > 0:\n        return ticket[0]\n    else: \n        return 'XXX'\n\nticket = pd.DataFrame()\n\nticket[ 'Ticket' ] = dataSet_df[ 'Ticket' ].map( cleanTicket )\nticket = pd.get_dummies( ticket[ 'Ticket' ] , prefix = 'Ticket' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:14.174085Z","iopub.execute_input":"2021-05-28T02:29:14.174435Z","iopub.status.idle":"2021-05-28T02:29:14.188261Z","shell.execute_reply.started":"2021-05-28T02:29:14.174406Z","shell.execute_reply":"2021-05-28T02:29:14.18674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#crea una variable dummy para el tipo de cabina\ncabin = pd.DataFrame()\n\ncabin[ 'Cabin' ] = dataSet_df.Cabin.fillna( 'U' )\ncabin[ 'Cabin' ] = cabin[ 'Cabin' ].map( lambda c : c[0] )\ncabin = pd.get_dummies( cabin['Cabin'] , prefix = 'Cabin' )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:16.826542Z","iopub.execute_input":"2021-05-28T02:29:16.826899Z","iopub.status.idle":"2021-05-28T02:29:16.837358Z","shell.execute_reply.started":"2021-05-28T02:29:16.826868Z","shell.execute_reply":"2021-05-28T02:29:16.836413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Crea la variable tamaño de familia\nfamily_size = dataSet_df.SibSp + dataSet_df.Parch\nfamily_size = family_size.map( {0:'single', 1:'small', 2:'small', 3:'small', 4:'mid', 5:'mid', 6:'mid', 7:'mid', 8:'big', 9:'big', 10:'big'} ).astype(str)\n\nfamily = pd.get_dummies(family_size, prefix = 'Family')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:19.296654Z","iopub.execute_input":"2021-05-28T02:29:19.2972Z","iopub.status.idle":"2021-05-28T02:29:19.305811Z","shell.execute_reply.started":"2021-05-28T02:29:19.297167Z","shell.execute_reply":"2021-05-28T02:29:19.304631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Crea variables ordinales para las variables edad y tarifa\nage  = pd.DataFrame(dataSet_df.Age.where(dataSet_df.Age >= 0, dataSet_df.Age.mean() + (rnd.random()*1.2 - 0.6)*dataSet_df.Age.std()),columns =['Age'])\nfare = pd.DataFrame(dataSet_df.Fare.where(dataSet_df.Fare >= 0, dataSet_df.Fare.mean() + (rnd.random()*1.2 - 0.6)*dataSet_df.Fare.std()),columns=['Fare'])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:21.674418Z","iopub.execute_input":"2021-05-28T02:29:21.674937Z","iopub.status.idle":"2021-05-28T02:29:21.839656Z","shell.execute_reply.started":"2021-05-28T02:29:21.674901Z","shell.execute_reply":"2021-05-28T02:29:21.838661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age = pd.DataFrame()\n\nage[ 'Age_child' ] = dataSet_df.Age.map( lambda s : 1 if       s < 15  else 0 )\nage[ 'Age_young' ] = dataSet_df.Age.map( lambda s : 1 if 15 <= s < 25  else 0 )\nage[ 'Age_grown' ] = dataSet_df.Age.map( lambda s : 1 if 25 <= s < 35  else 0 )\nage[ 'Age_mature'] = dataSet_df.Age.map( lambda s : 1 if 35 <= s       else 0 )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:23.477239Z","iopub.execute_input":"2021-05-28T02:29:23.477617Z","iopub.status.idle":"2021-05-28T02:29:23.494411Z","shell.execute_reply.started":"2021-05-28T02:29:23.477587Z","shell.execute_reply":"2021-05-28T02:29:23.493052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fare = pd.DataFrame()\n\n# introducing other features based on the family size\nfare[ 'Fare_low'      ] = dataSet_df.Fare.map( lambda s : 1 if         s < 8     else 0 )\nfare[ 'Fare_moderate' ] = dataSet_df.Fare.map( lambda s : 1 if 8    <= s < 14.5  else 0 )\nfare[ 'Fare_high'     ] = dataSet_df.Fare.map( lambda s : 1 if 14.5 <= s < 31.3  else 0 )\nfare[ 'Fare_veryhigh']  = dataSet_df.Fare.map( lambda s : 1 if 31.3 <= s         else 0 )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:25.888097Z","iopub.execute_input":"2021-05-28T02:29:25.88873Z","iopub.status.idle":"2021-05-28T02:29:25.90725Z","shell.execute_reply.started":"2021-05-28T02:29:25.888694Z","shell.execute_reply":"2021-05-28T02:29:25.90633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#crea una tabla con todas las variables incluyendo las que acabamos de crear\nfull_X = pd.concat( [ title, sex, age, pclass, fare, cabin, embarked, ticket, sibsp, parch, family] , axis=1 )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:28.706598Z","iopub.execute_input":"2021-05-28T02:29:28.707159Z","iopub.status.idle":"2021-05-28T02:29:28.715403Z","shell.execute_reply.started":"2021-05-28T02:29:28.707111Z","shell.execute_reply":"2021-05-28T02:29:28.714481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normaliza las variables para que los modelos las puedan representar mas facilmente\nnormalized = pd.DataFrame()\nfor col in full_X.columns:\n    normalized[col] = (full_X[col] - full_X[col].mean())/full_X[col].std()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:31.0864Z","iopub.execute_input":"2021-05-28T02:29:31.086791Z","iopub.status.idle":"2021-05-28T02:29:31.189903Z","shell.execute_reply.started":"2021-05-28T02:29:31.086759Z","shell.execute_reply":"2021-05-28T02:29:31.188543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#crea dos tablas mas consolidando las nuevas variables y las variables normalizadas\ntrainSet_X = full_X[:891]\ntrainSet_y = pd.DataFrame(train_df.Survived,columns=['Survived'])\ntestSet_X  = full_X[891:]\n\nnormtrainSet_X = normalized[:891]\nnormtestSet_X  = normalized[891:]","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:34:51.924463Z","iopub.execute_input":"2021-05-28T02:34:51.924916Z","iopub.status.idle":"2021-05-28T02:34:51.937316Z","shell.execute_reply.started":"2021-05-28T02:34:51.924879Z","shell.execute_reply":"2021-05-28T02:34:51.935874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = pd.concat([trainSet_X,trainSet_y], axis=1, sort=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:34:55.387564Z","iopub.execute_input":"2021-05-28T02:34:55.387919Z","iopub.status.idle":"2021-05-28T02:34:55.396876Z","shell.execute_reply.started":"2021-05-28T02:34:55.38789Z","shell.execute_reply":"2021-05-28T02:34:55.395352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graficos de edades separados por sexo para sobrevivientes y no sobrevientes\nc_m = train_set.Survived.where(train_set.Age_child == 1).where(train_set.Sex == 0).value_counts()\nc_f = train_set.Survived.where(train_set.Age_child == 1).where(train_set.Sex == 1).value_counts()\ny_m = train_set.Survived.where(train_set.Age_young == 1).where(train_set.Sex == 0).value_counts()\ny_f = train_set.Survived.where(train_set.Age_young == 1).where(train_set.Sex == 1).value_counts()\ng_m = train_set.Survived.where(train_set.Age_grown == 1).where(train_set.Sex == 0).value_counts()\ng_f = train_set.Survived.where(train_set.Age_grown == 1).where(train_set.Sex == 1).value_counts()\nm_m = train_set.Survived.where(train_set.Age_mature == 1).where(train_set.Sex == 0).value_counts()\nm_f = train_set.Survived.where(train_set.Age_mature == 1).where(train_set.Sex == 1).value_counts()\n\nmale_av    = [c_m.iat[0], y_m.iat[1], g_m.iat[1], m_m.iat[1]]\nfemale_av  = [c_f.iat[0], y_f.iat[0], g_f.iat[0], m_f.iat[0]]\nmale_am    = [c_m.iat[1], y_m.iat[0], g_m.iat[0], m_m.iat[0]]\nfemale_am  = [c_f.iat[1], y_f.iat[1], g_f.iat[1], m_f.iat[1]]\n\nageStage = ['child','young','grown','mature']\nage_vive_df = pd.DataFrame({'male': male_av,'female ': female_av }, index=ageStage)\nage_vive_df.plot.bar(rot=0, stacked=False, subplots=False,layout=[1,2], title='Sobrevivientes',colormap='Paired')\n\nage_muere_df = pd.DataFrame({'male': male_am,'female ': female_am }, index=ageStage)\nage_muere_df.plot.bar(rot=0, stacked=False, subplots=False,layout=[1,2], title='No Sobrevivientes',colormap='Paired')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:29:50.621141Z","iopub.execute_input":"2021-05-28T02:29:50.621584Z","iopub.status.idle":"2021-05-28T02:29:51.049111Z","shell.execute_reply.started":"2021-05-28T02:29:50.621545Z","shell.execute_reply":"2021-05-28T02:29:51.047946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Grafico de clases separados por sexo para sobrevivientes y no sobrevientes\nfirst_m  = train_set.Survived.where(train_set.Pclass_1 == 1).where(train_set.Sex == 0).value_counts()\nfirst_f  = train_set.Survived.where(train_set.Pclass_1 == 1).where(train_set.Sex == 1).value_counts()\nsecond_m = train_set.Survived.where(train_set.Pclass_2 == 1).where(train_set.Sex == 0).value_counts()\nsecond_f = train_set.Survived.where(train_set.Pclass_2 == 1).where(train_set.Sex == 1).value_counts()\nthird_m  = train_set.Survived.where(train_set.Pclass_3 == 1).where(train_set.Sex == 0).value_counts()\nthird_f  = train_set.Survived.where(train_set.Pclass_3 == 1).where(train_set.Sex == 1).value_counts()\n\nmale_cv    = [first_m.iat[1], second_m.iat[1], third_m.iat[1]]\nfemale_cv  = [first_f.iat[0], second_f.iat[0], third_f.iat[1]]\nmale_cm    = [first_m.iat[0], second_m.iat[0], third_m.iat[0]]\nfemale_cm  = [first_f.iat[1], second_f.iat[1], third_f.iat[0]]\n\nP_class = ['first','second','third']\nclass_vive_df = pd.DataFrame({'male': male_cv,'female ': female_cv }, index=P_class)\nclass_vive_df.plot.bar(rot=0, stacked=False, title='Sobrevivientes',colormap='Paired')\n\nclass_muere_df = pd.DataFrame({'male': male_cm,'female ': female_cm }, index=P_class)\nclass_muere_df.plot.bar(rot=0, stacked=False, title='No Sobrevivientes',colormap='Paired')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:30:01.877067Z","iopub.execute_input":"2021-05-28T02:30:01.877423Z","iopub.status.idle":"2021-05-28T02:30:02.241843Z","shell.execute_reply.started":"2021-05-28T02:30:01.877395Z","shell.execute_reply":"2021-05-28T02:30:02.24062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Grafico del tamaño de familia separados por sex para sobrevievientes y no sobrevivientes\nsingle_m = train_set.Survived.where(train_set.Family_single == 1).where(train_set.Sex == 0).value_counts()\nsingle_f = train_set.Survived.where(train_set.Family_single == 1).where(train_set.Sex == 1).value_counts()\nsmall_m  = train_set.Survived.where(train_set.Family_small == 1).where(train_set.Sex == 0).value_counts()\nsmall_f  = train_set.Survived.where(train_set.Family_small == 1).where(train_set.Sex == 1).value_counts()\nmid_m    = train_set.Survived.where(train_set.Family_mid == 1).where(train_set.Sex == 0).value_counts()\nmid_f    = train_set.Survived.where(train_set.Family_mid == 1).where(train_set.Sex == 1).value_counts()\nbig_m    = train_set.Survived.where(train_set.Family_big == 1).where(train_set.Sex == 0).value_counts()\nbig_f    = train_set.Survived.where(train_set.Family_big == 1).where(train_set.Sex == 1).value_counts()\n\n\nmale_fv    = [single_m.iat[1], small_m.iat[1], mid_m.iat[1], 0]\nfemale_fv  = [single_f.iat[0], small_f.iat[0], mid_f.iat[1], 0]\nmale_fm    = [single_m.iat[0], small_m.iat[0], mid_m.iat[0], big_m.iat[0]]\nfemale_fm  = [single_f.iat[1], small_f.iat[1], mid_f.iat[0], big_f.iat[0]]\n\nfam = ['single','small','mid','big']\nfam_vive_df = pd.DataFrame({'male': male_fv,'female ': female_fv }, index=fam)\nfam_vive_df.plot.bar(rot=0, stacked=False, title='Sobrevivientes',colormap='Paired')\n\nfam_muere_df = pd.DataFrame({'male': male_fm,'female ': female_fm }, index=fam)\nfam_muere_df.plot.bar(rot=0, stacked=False, title='No Sobrevivientes',colormap='Paired')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:30:07.083932Z","iopub.execute_input":"2021-05-28T02:30:07.084311Z","iopub.status.idle":"2021-05-28T02:30:07.489734Z","shell.execute_reply.started":"2021-05-28T02:30:07.084279Z","shell.execute_reply":"2021-05-28T02:30:07.488854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Separa los datos en el conjunto de entrenamiento validacion y prueba\nStrain_X , Svalid_X , Strain_y , Svalid_y = train_test_split( trainSet_X , trainSet_y , train_size = .8, test_size = .2   )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:35:01.042943Z","iopub.execute_input":"2021-05-28T02:35:01.043327Z","iopub.status.idle":"2021-05-28T02:35:01.050997Z","shell.execute_reply.started":"2021-05-28T02:35:01.043295Z","shell.execute_reply":"2021-05-28T02:35:01.049842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Strain_y = np.ravel(Strain_y)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:35:12.542214Z","iopub.execute_input":"2021-05-28T02:35:12.54277Z","iopub.status.idle":"2021-05-28T02:35:12.546722Z","shell.execute_reply.started":"2021-05-28T02:35:12.54273Z","shell.execute_reply":"2021-05-28T02:35:12.545855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hace listas para guardar datos de los modelos\nmodels     = list()\nconfusion  = list()\ntrain_eval = list()\nvalid_eval = list()\nvariance   = list()\nerror      = list()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:35:17.418053Z","iopub.execute_input":"2021-05-28T02:35:17.418769Z","iopub.status.idle":"2021-05-28T02:35:17.425574Z","shell.execute_reply.started":"2021-05-28T02:35:17.418723Z","shell.execute_reply":"2021-05-28T02:35:17.423685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#incluye los modelos en la lista de modelos\nmodel = LogisticRegression()\nmodels.append(model)\n\nmodel = SVC()\nmodels.append(model)\n\nmodel= DecisionTreeClassifier(criterion='gini', \n                             min_samples_split=10,min_samples_leaf=1,\n                             max_features='auto')\nmodels.append(model)\n\nmodel= GradientBoostingClassifier()\n\nmodels.append(model)\n\nmodel = RandomForestClassifier(criterion='gini', n_estimators=700,\n                             min_samples_split=10,min_samples_leaf=1,\n                             max_features='auto',oob_score=True,\n                             random_state=1,n_jobs=-1)\n\nmodels.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:35:23.689091Z","iopub.execute_input":"2021-05-28T02:35:23.68949Z","iopub.status.idle":"2021-05-28T02:35:23.696538Z","shell.execute_reply.started":"2021-05-28T02:35:23.689455Z","shell.execute_reply":"2021-05-28T02:35:23.695251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#entrena los modelos\nfor i in range(len(models)):\n    models[i].fit(Strain_X, Strain_y)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:35:29.658705Z","iopub.execute_input":"2021-05-28T02:35:29.659103Z","iopub.status.idle":"2021-05-28T02:35:32.652611Z","shell.execute_reply.started":"2021-05-28T02:35:29.659067Z","shell.execute_reply":"2021-05-28T02:35:32.650715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hace prediccion con los modelos\nfor i in range(len(models)):\n    predicted_train = pd.DataFrame(models[i].predict(Strain_X),columns=['Prediction'],index=Strain_X.index)\n    predicted_valid = pd.DataFrame(models[i].predict(Svalid_X),columns=['Prediction'],index=Svalid_X.index)\n\n    train_score = accuracy_score(predicted_train,Strain_y)\n    valid_score = accuracy_score(predicted_valid,Svalid_y)\n\n    accuracy       = round(train_score*100,2)\n    valid_accuracy = round(valid_score*100,2)\n    mean_error     = round(mean_absolute_error(Svalid_y, predicted_valid), 2)\n\n    mat = confusion_matrix(Svalid_y, predicted_valid)\n    confusion.append(mat)\n    \n    train_eval.append(accuracy)\n    valid_eval.append(valid_accuracy)\n    variance.append(accuracy - valid_accuracy)\n    error.append(mean_error)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:37:03.305084Z","iopub.execute_input":"2021-05-28T02:37:03.305447Z","iopub.status.idle":"2021-05-28T02:37:04.078587Z","shell.execute_reply.started":"2021-05-28T02:37:03.305416Z","shell.execute_reply":"2021-05-28T02:37:04.076595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hace dataframes de evaluacion y metricas de rendimiento\nevaluacion_train  = pd.DataFrame(train_eval,columns=['Train Score'],index=['Logistic', 'SVM', 'Tree', 'Gradient', 'Forest'])\nevaluacion_valid  = pd.DataFrame(valid_eval,columns=['Validation Score'],index=['Logistic', 'SVM', 'Tree', 'Gradient', 'Forest'])\nvariacion         = pd.DataFrame(variance,columns=['Variance'],index=['Logistic', 'SVM', 'Tree', 'Gradient', 'Forest'])\nerr               = pd.DataFrame(error,columns=['Error'],index=['Logistic', 'SVM', 'Tree', 'Gradient', 'Forest'])\nperformance       = pd.concat([evaluacion_train,evaluacion_valid,variacion,err],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:37:06.740083Z","iopub.execute_input":"2021-05-28T02:37:06.740467Z","iopub.status.idle":"2021-05-28T02:37:06.753291Z","shell.execute_reply.started":"2021-05-28T02:37:06.740435Z","shell.execute_reply":"2021-05-28T02:37:06.75197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:37:09.642475Z","iopub.execute_input":"2021-05-28T02:37:09.642983Z","iopub.status.idle":"2021-05-28T02:37:09.658784Z","shell.execute_reply.started":"2021-05-28T02:37:09.642938Z","shell.execute_reply":"2021-05-28T02:37:09.657698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#matriz de confusion de predicciones\nsns.heatmap(confusion[1].T, square=True, annot=True, fmt='3.0f', cbar=False,\n                        xticklabels=['no survive', 'survive'],\n                        yticklabels=['no survive', 'survive'],cmap=\"cool\")\nplt.xlabel('observed label')\nplt.ylabel('predicted label')\nplt.title('Confusion matrix', y=1.05, size=15)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:37:12.812298Z","iopub.execute_input":"2021-05-28T02:37:12.813037Z","iopub.status.idle":"2021-05-28T02:37:12.937588Z","shell.execute_reply.started":"2021-05-28T02:37:12.812994Z","shell.execute_reply":"2021-05-28T02:37:12.936635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelo de regresion logistica","metadata":{}},{"cell_type":"code","source":"\nmodel               = LogisticRegression()\nconfusion_logistic  = list()\ntrain_eval_logistic = list()\nvalid_eval_logistic = list()\nvariance_logistic   = list()\nerror_logistic      = list()\n\nfor i in range(1000):\n    Strain_X , Svalid_X , Strain_y , Svalid_y = train_test_split( trainSet_X , trainSet_y , train_size = .8, test_size = .2   )\n    Strain_y = np.ravel(Strain_y)\n    model.fit(Strain_X, Strain_y)\n    \n    predicted_train = pd.DataFrame(model.predict(Strain_X),columns=['Prediction'],index=Strain_X.index)\n    predicted_valid = pd.DataFrame(model.predict(Svalid_X),columns=['Prediction'],index=Svalid_X.index)\n\n    train_score = accuracy_score(predicted_train,Strain_y)\n    valid_score = accuracy_score(predicted_valid,Svalid_y)\n\n    accuracy       = round(train_score*100,2)\n    valid_accuracy = round(valid_score*100,2)\n    mean_error     = round(mean_absolute_error(Svalid_y, predicted_valid), 2)\n\n    mat = confusion_matrix(Svalid_y, predicted_valid)\n    confusion_logistic.append(mat)\n    \n    train_eval_logistic.append(accuracy)\n    valid_eval_logistic.append(valid_accuracy)\n    variance_logistic.append(accuracy - valid_accuracy)\n    error_logistic.append(mean_error)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:39:28.277597Z","iopub.execute_input":"2021-05-28T02:39:28.278186Z","iopub.status.idle":"2021-05-28T02:40:38.310306Z","shell.execute_reply.started":"2021-05-28T02:39:28.278139Z","shell.execute_reply":"2021-05-28T02:40:38.308884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluacion_train_logistic  = pd.DataFrame(train_eval_logistic,columns=['Train Score'])\nevaluacion_valid_logistic  = pd.DataFrame(valid_eval_logistic,columns=['Validation Score'])\nvariacion_logistic         = pd.DataFrame(variance_logistic,columns=['Variance'])\nerr_logistic               = pd.DataFrame(error_logistic,columns=['Error'])\nperformance_logistic       = pd.concat([evaluacion_train_logistic,evaluacion_valid_logistic,variacion_logistic,err_logistic],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:41:44.665407Z","iopub.execute_input":"2021-05-28T02:41:44.665846Z","iopub.status.idle":"2021-05-28T02:41:44.676775Z","shell.execute_reply.started":"2021-05-28T02:41:44.66581Z","shell.execute_reply":"2021-05-28T02:41:44.675516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#descrpcion de performance\nperformance_logistic.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:41:47.294558Z","iopub.execute_input":"2021-05-28T02:41:47.295013Z","iopub.status.idle":"2021-05-28T02:41:47.324885Z","shell.execute_reply.started":"2021-05-28T02:41:47.294974Z","shell.execute_reply":"2021-05-28T02:41:47.323367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelo de support vector machine","metadata":{}},{"cell_type":"code","source":"model = SVC()\nconfusion_SVC  = list()\ntrain_eval_SVC = list()\nvalid_eval_SVC = list()\nvariance_SVC   = list()\nerror_SVC      = list()\n\nfor i in range(1000):\n    Strain_X , Svalid_X , Strain_y , Svalid_y = train_test_split( trainSet_X , trainSet_y , train_size = .8, test_size = .2   )\n    Strain_y = np.ravel(Strain_y)\n    model.fit(Strain_X, Strain_y)\n    \n    \n    predicted_train = pd.DataFrame(model.predict(Strain_X),columns=['Prediction'],index=Strain_X.index)\n    predicted_valid = pd.DataFrame(model.predict(Svalid_X),columns=['Prediction'],index=Svalid_X.index)\n\n    train_score = accuracy_score(predicted_train,Strain_y)\n    valid_score = accuracy_score(predicted_valid,Svalid_y)\n\n    accuracy       = round(train_score*100,2)\n    valid_accuracy = round(valid_score*100,2)\n    mean_error     = round(mean_absolute_error(Svalid_y, predicted_valid), 2)\n\n    mat = confusion_matrix(Svalid_y, predicted_valid)\n    confusion_SVC.append(mat)\n    \n    train_eval_SVC.append(accuracy)\n    valid_eval_SVC.append(valid_accuracy)\n    variance_SVC.append(accuracy - valid_accuracy)\n    error_SVC.append(mean_error)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:42:53.567128Z","iopub.execute_input":"2021-05-28T02:42:53.567691Z","iopub.status.idle":"2021-05-28T02:44:22.956055Z","shell.execute_reply.started":"2021-05-28T02:42:53.567657Z","shell.execute_reply":"2021-05-28T02:44:22.95462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluacion_train_SVC  = pd.DataFrame(train_eval_SVC,columns=['Train Score'])\nevaluacion_valid_SVC  = pd.DataFrame(valid_eval_SVC,columns=['Validation Score'])\nvariacion_SVC         = pd.DataFrame(variance_SVC,columns=['Variance'])\nerr_SVC               = pd.DataFrame(error_SVC,columns=['Error'])\nperformance_SVC       = pd.concat([evaluacion_train_SVC,evaluacion_valid_SVC,variacion_SVC,err_SVC],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:45:33.200914Z","iopub.execute_input":"2021-05-28T02:45:33.201367Z","iopub.status.idle":"2021-05-28T02:45:33.214999Z","shell.execute_reply.started":"2021-05-28T02:45:33.201329Z","shell.execute_reply":"2021-05-28T02:45:33.213471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_SVC.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:45:36.241681Z","iopub.execute_input":"2021-05-28T02:45:36.242106Z","iopub.status.idle":"2021-05-28T02:45:36.274538Z","shell.execute_reply.started":"2021-05-28T02:45:36.242067Z","shell.execute_reply":"2021-05-28T02:45:36.273361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelo de árbol de decisión","metadata":{}},{"cell_type":"code","source":"model = DecisionTreeClassifier(criterion='gini', \n                             min_samples_split=10,min_samples_leaf=1,\n                             max_features='auto')\nconfusion_DT  = list()\ntrain_eval_DT = list()\nvalid_eval_DT = list()\nvariance_DT   = list()\nerror_DT     = list()\n\nfor i in range(1000):\n    Strain_X , Svalid_X , Strain_y , Svalid_y = train_test_split( trainSet_X , trainSet_y , train_size = .8, test_size = .2   )\n    Strain_y = np.ravel(Strain_y)\n    model.fit(Strain_X, Strain_y)\n    \n    predicted_train = pd.DataFrame(model.predict(Strain_X),columns=['Prediction'],index=Strain_X.index)\n    predicted_valid = pd.DataFrame(model.predict(Svalid_X),columns=['Prediction'],index=Svalid_X.index)\n\n    train_score = accuracy_score(predicted_train,Strain_y)\n    valid_score = accuracy_score(predicted_valid,Svalid_y)\n\n    accuracy       = round(train_score*100,2)\n    valid_accuracy = round(valid_score*100,2)\n    mean_error     = round(mean_absolute_error(Svalid_y, predicted_valid), 2)\n\n    mat = confusion_matrix(Svalid_y, predicted_valid)\n    confusion_DT.append(mat)\n    \n    train_eval_DT.append(accuracy)\n    valid_eval_DT.append(valid_accuracy)\n    variance_DT.append(accuracy - valid_accuracy)\n    error_DT.append(mean_error)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:46:14.222695Z","iopub.execute_input":"2021-05-28T02:46:14.223291Z","iopub.status.idle":"2021-05-28T02:46:31.672546Z","shell.execute_reply.started":"2021-05-28T02:46:14.223236Z","shell.execute_reply":"2021-05-28T02:46:31.67075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluacion_train_DT  = pd.DataFrame(train_eval_DT,columns=['Train Score'])\nevaluacion_valid_DT  = pd.DataFrame(valid_eval_DT,columns=['Validation Score'])\nvariacion_DT         = pd.DataFrame(variance_DT,columns=['Variance'])\nerr_DT               = pd.DataFrame(error_DT,columns=['Error'])\nperformance_DT       = pd.concat([evaluacion_train_DT,evaluacion_valid_DT,variacion_DT,err_DT],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:46:36.555936Z","iopub.execute_input":"2021-05-28T02:46:36.556349Z","iopub.status.idle":"2021-05-28T02:46:36.567718Z","shell.execute_reply.started":"2021-05-28T02:46:36.556318Z","shell.execute_reply":"2021-05-28T02:46:36.566185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:46:40.339167Z","iopub.execute_input":"2021-05-28T02:46:40.339581Z","iopub.status.idle":"2021-05-28T02:46:40.368559Z","shell.execute_reply.started":"2021-05-28T02:46:40.339549Z","shell.execute_reply":"2021-05-28T02:46:40.367589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelo gradient boost classifier","metadata":{}},{"cell_type":"code","source":"model = GradientBoostingClassifier()\nconfusion_Gd  = list()\ntrain_eval_Gd = list()\nvalid_eval_Gd = list()\nvariance_Gd   = list()\nerror_Gd      = list()\n\nfor i in range(1000):\n    Strain_X , Svalid_X , Strain_y , Svalid_y = train_test_split( trainSet_X , trainSet_y , train_size = .8, test_size = .2   )\n    Strain_y = np.ravel(Strain_y)\n    model.fit(Strain_X, Strain_y)\n    \n    predicted_train = pd.DataFrame(model.predict(Strain_X),columns=['Prediction'],index=Strain_X.index)\n    predicted_valid = pd.DataFrame(model.predict(Svalid_X),columns=['Prediction'],index=Svalid_X.index)\n\n    train_score = accuracy_score(predicted_train,Strain_y)\n    valid_score = accuracy_score(predicted_valid,Svalid_y)\n\n    accuracy       = round(train_score*100,2)\n    valid_accuracy = round(valid_score*100,2)\n    mean_error     = round(mean_absolute_error(Svalid_y, predicted_valid), 2)\n\n    mat = confusion_matrix(Svalid_y, predicted_valid)\n    confusion_Gd.append(mat)\n    \n    train_eval_Gd.append(accuracy)\n    valid_eval_Gd.append(valid_accuracy)\n    variance_Gd.append(accuracy - valid_accuracy)\n    error_Gd.append(mean_error)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:47:09.811175Z","iopub.execute_input":"2021-05-28T02:47:09.811629Z","iopub.status.idle":"2021-05-28T02:49:50.216124Z","shell.execute_reply.started":"2021-05-28T02:47:09.811592Z","shell.execute_reply":"2021-05-28T02:49:50.214874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluacion_train_Gd  = pd.DataFrame(train_eval_Gd,columns=['Train Score'])\nevaluacion_valid_Gd  = pd.DataFrame(valid_eval_Gd,columns=['Validation Score'])\nvariacion_Gd         = pd.DataFrame(variance_Gd,columns=['Variance'])\nerr_Gd               = pd.DataFrame(error_Gd,columns=['Error'])\nperformance_Gd       = pd.concat([evaluacion_train_Gd,evaluacion_valid_Gd,variacion_Gd,err_Gd],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:49:56.591001Z","iopub.execute_input":"2021-05-28T02:49:56.591357Z","iopub.status.idle":"2021-05-28T02:49:56.600383Z","shell.execute_reply.started":"2021-05-28T02:49:56.591328Z","shell.execute_reply":"2021-05-28T02:49:56.599535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_Gd.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:07:54.052686Z","iopub.status.idle":"2021-05-28T04:07:54.053327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelo de bosque aleatorio","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier(criterion='gini', n_estimators=50,\n                             min_samples_split=10,min_samples_leaf=1,\n                             max_features='auto',oob_score=True,\n                             random_state=1,n_jobs=-1)\nconfusion_Rf  = list()\ntrain_eval_Rf = list()\nvalid_eval_Rf = list()\nvariance_Rf   = list()\nerror_Rf      = list()\n\nfor i in range(1000):\n    Strain_X , Svalid_X , Strain_y , Svalid_y = train_test_split( trainSet_X , trainSet_y , train_size = .8, test_size = .2   )\n    Strain_y = np.ravel(Strain_y)\n    model.fit(Strain_X, Strain_y)\n    \n    predicted_train = pd.DataFrame(model.predict(Strain_X),columns=['Prediction'],index=Strain_X.index)\n    predicted_valid = pd.DataFrame(model.predict(Svalid_X),columns=['Prediction'],index=Svalid_X.index)\n\n    train_score = accuracy_score(predicted_train,Strain_y)\n    valid_score = accuracy_score(predicted_valid,Svalid_y)\n\n    accuracy       = round(train_score*100,2)\n    valid_accuracy = round(valid_score*100,2)\n    mean_error     = round(mean_absolute_error(Svalid_y, predicted_valid), 2)\n\n    mat = confusion_matrix(Svalid_y, predicted_valid)\n    confusion_Rf.append(mat)\n    \n    train_eval_Rf.append(accuracy)\n    valid_eval_Rf.append(valid_accuracy)\n    variance_Rf.append(accuracy - valid_accuracy)\n    error_Rf.append(mean_error)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluacion_train_Rf  = pd.DataFrame(train_eval_Rf,columns=['Train Score'])\nevaluacion_valid_Rf  = pd.DataFrame(valid_eval_Rf,columns=['Validation Score'])\nvariacion_Rf         = pd.DataFrame(variance_Rf,columns=['Variance'])\nerr_Rf               = pd.DataFrame(error_Rf,columns=['Error'])\nperformance_Rf       = pd.concat([evaluacion_train_Rf,evaluacion_valid_Rf,variacion_Rf,err_Rf],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_Rf.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier(criterion='gini', n_estimators=700,\n                             min_samples_split=10,min_samples_leaf=1,\n                             max_features='auto',oob_score=True,\n                             random_state=1,n_jobs=-1)\nconfusion_Rf  = list()\ntrain_eval_Rf = list()\nvalid_eval_Rf = list()\nvariance_Rf   = list()\nerror_Rf      = list()\n\nfor i in range(1000):\n    Strain_X , Svalid_X , Strain_y , Svalid_y = train_test_split( trainSet_X , trainSet_y , train_size = .8, test_size = .2   )\n    Strain_y = np.ravel(Strain_y)\n    model.fit(Strain_X, Strain_y)\n    \n    predicted_train = pd.DataFrame(model.predict(Strain_X),columns=['Prediction'],index=Strain_X.index)\n    predicted_valid = pd.DataFrame(model.predict(Svalid_X),columns=['Prediction'],index=Svalid_X.index)\n\n    train_score = accuracy_score(predicted_train,Strain_y)\n    valid_score = accuracy_score(predicted_valid,Svalid_y)\n\n    accuracy       = round(train_score*100,2)\n    valid_accuracy = round(valid_score*100,2)\n    mean_error     = round(mean_absolute_error(Svalid_y, predicted_valid), 2)\n\n    mat = confusion_matrix(Svalid_y, predicted_valid)\n    confusion_Rf.append(mat)\n    \n    train_eval_Rf.append(accuracy)\n    valid_eval_Rf.append(valid_accuracy)\n    variance_Rf.append(accuracy - valid_accuracy)\n    error_Rf.append(mean_error)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analisis de rendimiento de los modelos","metadata":{}},{"cell_type":"code","source":"evaluacion1 = np.hstack((evaluacion_train_logistic.values,evaluacion_train_SVC.values,evaluacion_train_DT.values,evaluacion_train_Gd.values,evaluacion_train_Rf.values))\nevaluacion2 = np.hstack((evaluacion_valid_logistic.values,evaluacion_valid_SVC.values,evaluacion_valid_DT.values,evaluacion_valid_Gd.values,evaluacion_valid_Rf.values))\nevaluacion3 = np.hstack((variacion_logistic.values,variacion_SVC.values,variacion_DT.values,variacion_Gd.values,variacion_Rf.values))\nevaluacion4 = np.hstack((err_logistic.values,err_SVC.values,err_DT.values,err_Gd.values,err_Rf.values))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_eval = pd.DataFrame(evaluacion1,columns=['Logistic','SVM','Tree','Gradient','Forest'])\nValid_eval = pd.DataFrame(evaluacion2,columns=['Logistic','SVM','Tree','Gradient','Forest'])\nVar_eval   = pd.DataFrame(evaluacion3,columns=['Logistic','SVM','Tree','Gradient','Forest'])\nerr_eval   = pd.DataFrame(evaluacion4,columns=['Logistic','SVM','Tree','Gradient','Forest'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluacion para el conjunto de entrenamiento\nTrain_eval.head(100).plot.line()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluacion para el conjunto de validacion\nValid_eval.tail(10).plot.line()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluacion de variacion\nVar_eval.head(20).plot.line()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluacion del error\nerr_eval.head(20).plot.line()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_array = pd.DataFrame(np.array([Train_eval.describe().loc['mean'][0],Train_eval.describe().loc['mean'][1],Train_eval.describe().loc['mean'][2],Train_eval.describe().loc['mean'][3],Train_eval.describe().loc['mean'][4]]).transpose(),columns=['Train_score'],index=['Logistic','SVM','Tree','Gradient','Forest'])\nvalid_array = pd.DataFrame(np.array([Valid_eval.describe().loc['mean'][0],Valid_eval.describe().loc['mean'][1],Valid_eval.describe().loc['mean'][2],Valid_eval.describe().loc['mean'][3],Valid_eval.describe().loc['mean'][4]]).transpose(),columns=['Valid_score'],index=['Logistic','SVM','Tree','Gradient','Forest'])\nvar_array   = pd.DataFrame(np.array([Var_eval.describe().loc['mean'][0],Var_eval.describe().loc['mean'][1],Var_eval.describe().loc['mean'][2],Var_eval.describe().loc['mean'][3],Var_eval.describe().loc['mean'][4]]).transpose(),columns=['Generalization'],index=['Logistic','SVM','Tree','Gradient','Forest'])\nerr_array   = pd.DataFrame(np.array([err_eval.describe().loc['mean'][0],err_eval.describe().loc['mean'][1],err_eval.describe().loc['mean'][2],err_eval.describe().loc['mean'][3],err_eval.describe().loc['mean'][4]]).transpose(),columns=['Error'],index=['Logistic','SVM','Tree','Gradient','Forest'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"promedios = pd.concat([train_array,valid_array,var_array,err_array],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resumen de rendimiento de cada modelo","metadata":{}},{"cell_type":"code","source":"promedios","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}