{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HR Analytics"},{"metadata":{},"cell_type":"markdown","source":"## Import library and dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom collections import Counter\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,roc_auc_score\nfrom sklearn.feature_selection import RFECV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain=pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ntest=pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_test.csv')\nsample_submission=pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"14 columns with target is our y variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The target column which is the predictor variable seems to be imbalanced .We have 75% of rows as 0 whereas 25% is 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Category columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_cols=train.select_dtypes('object').columns\nnumeric_cols=[c for c in train.columns if c not in obj_cols if c not in ('target')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check if there are any new categories available in test which are not present in train,"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in obj_cols:\n    if list(set(test[c])-set(train[c])):\n        print(f\"For column {c} Available only in test are {list(set(test['city'])-set(train['city']))}\")\n    print(\"No instances found\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no new categories available in testset.Lets combine both train and test for the next section of our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[:,'target']=-1\ndata=pd.concat([train,test],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/artgor/is-this-malware-eda-fe-and-lgb-updated\nstat_cols=[]\nfor c in obj_cols:\n    stat_cols.append((c,data[c].nunique(),data[c].isnull().sum()*100/data[c].shape[0],data[c].value_counts(normalize=True,dropna=False).values[0]*100))\n    stat_df=pd.DataFrame(stat_cols,columns=['column_name','unique_values','null_value_perc','perc_of_max_value'])\n    stat_df.sort_values('unique_values',ascending=False,inplace=True)\nstat_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above table provides a summary of the categorical columns.City and relevent experience have no null values whereas company_type has 32 % null values.The cardinality of city and experience is higher.75 % of the columns in major discipline are of the same category  followed similarly in enrolled_university,relevent_experience columns.Lets first handle null columns."},{"metadata":{},"cell_type":"markdown","source":"## Handling null values"},{"metadata":{},"cell_type":"markdown","source":"Lets consider both training and test sets for our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['company_type'].value_counts(normalize=True,dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use a technique described in Abhishek Thakur's book for imputing missing values.NaN's will be considered a separate category and imputed."},{"metadata":{"trusted":true},"cell_type":"code","source":"null_cols=[c for c in obj_cols if c not in ['city','relevent_experience']]\nfor n in null_cols:\n    print(f'Imputing null values in column {n}')\n    data.loc[:,n]=data[n].fillna(f'NONE_{n}').astype('str')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check company type column again,"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['company_type'].value_counts(normalize=True,dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_cols=[]\nfor c in obj_cols:\n    stat_cols.append((c,data[c].nunique(),data[c].isnull().sum()*100/data[c].shape[0],data[c].value_counts(normalize=True,dropna=False).values[0]*100))\n    stat_df=pd.DataFrame(stat_cols,columns=['column_name','unique_values','null_value_perc','perc_of_max_value'])\n    stat_df.sort_values('unique_values',ascending=False,inplace=True)\nstat_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing categorical data for Model Input"},{"metadata":{},"cell_type":"markdown","source":"For categorical data with cardinality less than 5 , we use one hot encoding while for cardinality greater than 5 we use frequency encoding.Inorder to avoid data leak,we do the frequency encoding in our cross validation setup."},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in ['relevent_experience','enrolled_university','gender']:\n    temp=pd.get_dummies(data[c],prefix='OHE')\n    data=pd.concat([data,temp],axis=1)\n    print(f'OHE {c}.Now removing original column {c} from df')\n    data.drop(c,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus all null values in the column is taken care of.Lets now check the numerical columns."},{"metadata":{},"cell_type":"markdown","source":"## Numeric columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[numeric_cols].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Null values in numeric columns.From the column name it is seen that enrolee_id is more nominal rather than a continuous column.Lets change the dtype."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[:,'enrollee_id']=data.loc[:,'enrollee_id'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now,we split the data again into train and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"train=data.loc[data['target']!=-1,:].reset_index(drop=True)\ntest=data.loc[data['target']==-1,:].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop('target',axis=1)\ny=train.target.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of numeric columns:\nfig,ax=plt.subplots(figsize=(12,10))\nplt.subplot(2,2,1)\nsns.distplot(train['city_development_index'],color='darkblue')\nplt.title(\"Distribution of city development index-Train\",fontsize=15)\nplt.xlabel('City development index',fontsize=10)\nplt.ylabel('frequency')\nplt.subplot(2,2,2)\nsns.distplot(test['city_development_index'],color='violet')\nplt.title(\"Distribution of city development index-Test\",fontsize=15)\nplt.xlabel('City development index',fontsize=10)\nplt.ylabel('frequency')\nplt.subplot(2,2,3)\nsns.distplot(train['training_hours'],color='darkblue')\nplt.title(\"Distribution of training hours-Train\",fontsize=15)\nplt.xlabel('Training Hours',fontsize=10)\nplt.ylabel('frequency')\nplt.subplot(2,2,4)\nsns.distplot(test['training_hours'],color='violet')\nplt.title(\"Distribution of training hours-Test\",fontsize=15)\nplt.xlabel('Training Hours',fontsize=10)\nplt.ylabel('frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['training_hours'].describe(),test['training_hours'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The distribution of city development index looks similar in both training and test set.The development index is having a peak at values 0.9 and 0.6.The range is also between 0.4 to 1.0\n* Training hours is right skewed with peak between 0-50.The range is also similar."},{"metadata":{},"cell_type":"markdown","source":"## Building a baseline model"},{"metadata":{},"cell_type":"markdown","source":"Since there is an imbalance in target,we use stratifiedKfold for cross validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_cols=['city','experience','company_size','major_discipline','company_type','last_new_job','education_level']\nnum_cols=['city_development_index','training_hours']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"required_cols=[c for c in X.columns if c not in ('enrollee_id')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def freq_encode(trn_df,val_df,cols):\n    for c in cols:\n        df=pd.concat([trn_df[[c]],val_df[[c]]])\n        foo=df[c].value_counts().to_dict()\n        trn_df[c]=trn_df[c].map(foo)\n        val_df[c]=val_df[c].map(foo)\n    return trn_df[cols],val_df[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df=np.zeros(len(test))\nscores=[]\nroc=[]\nfor i,(trn_idx,val_idx) in enumerate(folds.split(X,y)):\n    print(f'***Starting fold {i+1}***')\n    trn_x,trn_y=X[required_cols].iloc[trn_idx],y[trn_idx]\n    val_x,val_y=X[required_cols].iloc[val_idx],y[val_idx]\n    trn_x[freq_cols],val_x[freq_cols]=freq_encode(trn_x,val_x,freq_cols)\n    #val_x[freq_cols]=freq_encode(val_x,freq_cols)\n    clf=RandomForestClassifier(n_estimators=1000,oob_score=True,n_jobs=-1,random_state=40,max_features='sqrt')\n    clf.fit(trn_x,trn_y)\n    preds=clf.predict(val_x)\n    score=f1_score(val_y,preds)\n    roc_score=roc_auc_score(val_y,preds)\n    scores.append(score)\n    roc.append(roc_score)\n    print(f'F1 score for fold {i+1} is {score} ROC score {roc_score}')\n    \n    test[freq_cols],_=freq_encode(train[required_cols],test[required_cols],freq_cols)\n    test_preds=clf.predict(test[required_cols])\n    pred_df+=test_preds\nprint(f'Average f1 score for 5 folds {np.mean(scores)} .Avg roc score for 5 folds {np.mean(roc)}')\npred_df/=5\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model with Random forest classifier is not the best.Lets try to improve this baseline score."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=X[required_cols].copy()\ntrain_df[freq_cols],_=freq_encode(train,test,freq_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##recursive feature elimination with cross validation:\nmodel=RandomForestClassifier(n_estimators=1000,oob_score=True,n_jobs=-1,random_state=40,max_features='sqrt')\nrfecv=RFECV(estimator=model,\n           cv=StratifiedKFold(n_splits=5,shuffle=True,random_state=42).split(train_df[required_cols],y),\n           step=5,\n           scoring='roc_auc',\n           verbose=2)\nrfecv.fit(train_df[required_cols],y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Optimal number of features {rfecv.n_features_}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.plot(range(1,len(rfecv.grid_scores_)+1),rfecv.grid_scores_)\nplt.xlabel('Number of features selected')\nplt.ylabel('Cross validation score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ranking=pd.DataFrame({'features':required_cols})\nranking['Rank']=np.asarray(rfecv.ranking_)\nranking.sort_values('Rank',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score=np.max(rfecv.grid_scores_)\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target']=rfecv.predict(test[required_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reference"},{"metadata":{},"cell_type":"markdown","source":"1.Artgor's [Malware prediction kernel](https://www.kaggle.com/artgor/is-this-malware-eda-fe-and-lgb-updated)\n\n2.Abhishek Thakur's [Approaching Almost any Machine Learning Problem](https://www.amazon.in/Approaching-Almost-Machine-Learning-Problem-ebook/dp/B089P13QHT/ref=sr_1_1?crid=3VJFCEROX0U8&dchild=1&keywords=approaching+almost+any+machine+learning+problem&qid=1609395728&sprefix=approachin%2Caps%2C317&sr=8-1)\n\n3.[Recursive feature elimination with CV](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py)\n\n4.[eliminate features recursively](https://www.kaggle.com/tilii7/eliminate-features-recursively-cv)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}