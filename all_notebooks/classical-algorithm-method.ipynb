{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np #导入NumPy数学工具箱\nimport pandas as pd #导入Pandas数据处理工具箱\ndf = pd.read_csv(\"../input/bank-customer/BankCustomer.csv\") # 读取文件\ndf.head() # 显示文件前5行","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:29:01.807895Z","iopub.execute_input":"2021-06-18T12:29:01.80853Z","iopub.status.idle":"2021-06-18T12:29:01.881132Z","shell.execute_reply.started":"2021-06-18T12:29:01.808442Z","shell.execute_reply":"2021-06-18T12:29:01.880016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Exited.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:29:41.739109Z","iopub.execute_input":"2021-06-18T12:29:41.739477Z","iopub.status.idle":"2021-06-18T12:29:41.750101Z","shell.execute_reply.started":"2021-06-18T12:29:41.739446Z","shell.execute_reply":"2021-06-18T12:29:41.749035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns #导入seaborn画图工具箱\nsns.countplot(x=\"Exited\", data=df, palette=\"bwr\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:30:52.750413Z","iopub.execute_input":"2021-06-18T12:30:52.750959Z","iopub.status.idle":"2021-06-18T12:30:53.886735Z","shell.execute_reply.started":"2021-06-18T12:30:52.750911Z","shell.execute_reply":"2021-06-18T12:30:53.885963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 将某些特征转换为数值类型的哑变量\na = pd.get_dummies(df['ProductsNo'], prefix = \"PN\")\nb = pd.get_dummies(df['City'], prefix = \"City\")\nc = pd.get_dummies(df['Gender'], prefix = \"Gender\")\nframes = [df, a, b, c]\ndf = pd.concat(frames, axis = 1)\ndf.head()\ndf = df.drop(columns = ['ProductsNo', 'City',\"Gender\", \"Name\"])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:31:03.143987Z","iopub.execute_input":"2021-06-18T12:31:03.144484Z","iopub.status.idle":"2021-06-18T12:31:03.178487Z","shell.execute_reply.started":"2021-06-18T12:31:03.144439Z","shell.execute_reply":"2021-06-18T12:31:03.177713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 构建特征和标签集\ny = df.Exited.values\nX = df.drop(['Exited'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:31:27.813268Z","iopub.execute_input":"2021-06-18T12:31:27.813794Z","iopub.status.idle":"2021-06-18T12:31:27.820056Z","shell.execute_reply.started":"2021-06-18T12:31:27.813761Z","shell.execute_reply":"2021-06-18T12:31:27.818968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split  # 拆分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:31:38.092055Z","iopub.execute_input":"2021-06-18T12:31:38.092414Z","iopub.status.idle":"2021-06-18T12:31:38.397129Z","shell.execute_reply.started":"2021-06-18T12:31:38.092385Z","shell.execute_reply":"2021-06-18T12:31:38.395767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 进行特征缩放\nfrom sklearn import preprocessing\nscaler = preprocessing.MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:31:48.87129Z","iopub.execute_input":"2021-06-18T12:31:48.871888Z","iopub.status.idle":"2021-06-18T12:31:48.886335Z","shell.execute_reply.started":"2021-06-18T12:31:48.871839Z","shell.execute_reply":"2021-06-18T12:31:48.885472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import (f1_score, confusion_matrix) # 导入评估指标","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:31:58.993401Z","iopub.execute_input":"2021-06-18T12:31:58.993915Z","iopub.status.idle":"2021-06-18T12:31:58.998581Z","shell.execute_reply.started":"2021-06-18T12:31:58.993876Z","shell.execute_reply":"2021-06-18T12:31:58.997248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression # 导入逻辑回归模型\nfrom sklearn.metrics import f1_score, confusion_matrix # 导入评估标准\nlr = LogisticRegression() # 逻辑回归\nlr.fit(X_train,y_train) # 训练模型\ny_pred = lr.predict(X_test) # 预测结果\nlr_acc = lr.score(X_test,y_test)*100 # 准确率\nlr_f1 = f1_score(y_test, y_pred)*100 # F1分数\nprint(\"逻辑回归测试集准确率： {:.2f}%\".format(lr_acc))\nprint(\"逻辑回归测试集F1分数: {:.2f}%\".format(lr_f1))\nprint('逻辑回归测试集混淆矩阵:\\n', confusion_matrix(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:32:07.610125Z","iopub.execute_input":"2021-06-18T12:32:07.610499Z","iopub.status.idle":"2021-06-18T12:32:07.857392Z","shell.execute_reply.started":"2021-06-18T12:32:07.610467Z","shell.execute_reply":"2021-06-18T12:32:07.856197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier # 导入KNN算法\nk = 5 # 设定初始K值为5\nknn = KNeighborsClassifier(n_neighbors = k)  # KNN模型\nknn.fit(X_train, y_train) # 拟合KNN模型\ny_pred = knn.predict(X_test) # 预测结果\nknn_acc = knn.score(X_test,y_test)*100 # 准确率\nknn_f1 = f1_score(y_test, y_pred)*100 # F1分数\nprint(\"{}NN 预测准确率: {:.2f}%\".format(k, knn_acc))\nprint(\"{}NN 预测F1分数: {:.2f}%\".format(k, knn_f1))\nprint('KNN 混淆矩阵:\\n', confusion_matrix(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:32:18.938055Z","iopub.execute_input":"2021-06-18T12:32:18.938422Z","iopub.status.idle":"2021-06-18T12:32:19.961047Z","shell.execute_reply.started":"2021-06-18T12:32:18.938391Z","shell.execute_reply":"2021-06-18T12:32:19.959974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 寻找最佳K值\nf1_score_list = []\nacc_score_list = []\nfor i in range(1,15): # 从1到15，尝试每一个K值\n    kNN = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    kNN.fit(X_train, y_train)\n    acc_score_list.append(kNN.score(X_test, y_test))\n    y_pred = kNN.predict(X_test) # 预测结果\n    f1_score_list.append(f1_score(y_test, y_pred))\nindex = np.arange(1,15,1)\n# 绘制不同K值时，kNN的准确率和F1分数\nplt.plot(index,acc_score_list,c='blue',linestyle='solid')\nplt.plot(index,f1_score_list,c='red',linestyle='dashed')\nplt.legend([\"Accuracy\", \"F1 Score\"])\nplt.xlabel(\"K value\")\nplt.ylabel(\"Score\")\nplt.grid('false')\nplt.show()\nkNN_acc = max(f1_score_list)*100\nprint(\"Maximum kNN Score is {:.2f}%\".format(kNN_acc))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:32:30.948593Z","iopub.execute_input":"2021-06-18T12:32:30.949099Z","iopub.status.idle":"2021-06-18T12:32:43.189667Z","shell.execute_reply.started":"2021-06-18T12:32:30.949068Z","shell.execute_reply":"2021-06-18T12:32:43.188829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC # 导入SVM分类器\nsvm = SVC(random_state = 1) # SVM模型\nsvm.fit(X_train, y_train) #拟合SVM模型\ny_pred = svm.predict(X_test) # 预测心脏病结果\nsvm_acc = svm.score(X_test,y_test)*100 # 准确率\nsvm_f1 = f1_score(y_test, y_pred)*100 # F1分数\nprint(\"SVM 预测准确率:: {:.2f}%\".format(svm_acc))\nprint(\"SVM 预测F1分数: {:.2f}%\".format(svm_f1))\nprint('SVM 混淆矩阵:\\n', confusion_matrix(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:33:16.867591Z","iopub.execute_input":"2021-06-18T12:33:16.868Z","iopub.status.idle":"2021-06-18T12:33:19.580928Z","shell.execute_reply.started":"2021-06-18T12:33:16.867967Z","shell.execute_reply":"2021-06-18T12:33:19.579662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB # 导入模型\nnb = GaussianNB() # 朴素贝叶斯模型\nnb.fit(X_train, y_train) # 拟合模型\ny_pred = nb.predict(X_test) # 预测心脏病结果\nnb_acc = nb.score(X_test,y_test)*100 # 准确率\nnb_f1 = f1_score(y_test, y_pred)*100 # F1分数\nprint(\"朴素贝叶斯测试集准确率:: {:.2f}%\".format(nb_acc))\nprint(\"朴素贝叶斯测试集F1分数: {:.2f}%\".format(nb_f1))\nprint('朴素贝叶斯混淆矩阵:\\n', confusion_matrix(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:33:38.424652Z","iopub.execute_input":"2021-06-18T12:33:38.425048Z","iopub.status.idle":"2021-06-18T12:33:38.446044Z","shell.execute_reply.started":"2021-06-18T12:33:38.425015Z","shell.execute_reply":"2021-06-18T12:33:38.445127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier # 导入模型\ndt = DecisionTreeClassifier() # 分类决策树\ndt.fit(X_train, y_train) # 拟合模型\ny_pred = dt.predict(X_test) # 预测心脏病结果\ndt_acc = dt.score(X_test,y_test)*100 # 准确率\ndt_f1 = f1_score(y_test, y_pred)*100 # F1分数\nprint(\"决策树测试集准确率:: {:.2f}%\".format(dt_acc))\nprint(\"决策树测试集F1分数: {:.2f}%\".format(dt_f1))\nprint('决策树混淆矩阵:\\n', confusion_matrix(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:34:13.889568Z","iopub.execute_input":"2021-06-18T12:34:13.889936Z","iopub.status.idle":"2021-06-18T12:34:13.996276Z","shell.execute_reply.started":"2021-06-18T12:34:13.889905Z","shell.execute_reply":"2021-06-18T12:34:13.995152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier # 导入模型\nrf = RandomForestClassifier(n_estimators = 1000, random_state = 1) # 随机森林\nrf.fit(X_train, y_train) # 拟合模型\ny_pred = rf.predict(X_test) # 预测心脏病结果\nrf_acc = rf.score(X_test,y_test)*100 # 准确率\nrf_f1 = f1_score(y_test, y_pred)*100 # F1分数\nprint(\"随机森林 预测准确率:: {:.2f}%\".format(rf_acc))\nprint(\"随机森林 预测F1分数: {:.2f}%\".format(rf_f1))\nprint('随机森林 混淆矩阵:\\n', confusion_matrix( y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:34:29.00106Z","iopub.execute_input":"2021-06-18T12:34:29.001467Z","iopub.status.idle":"2021-06-18T12:34:40.240059Z","shell.execute_reply.started":"2021-06-18T12:34:29.001432Z","shell.execute_reply":"2021-06-18T12:34:40.238961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 用直方图显示出各个算法的F1分数\nimport seaborn as sns\nmethods = [\"Logistic Regression\", \"KNN\", \"SVM\", \n           \"Naive Bayes\", \"Decision Tree\", \"Random Forest\"]\nf1 = [lr_f1, knn_f1, svm_f1, nb_f1, dt_f1, rf_f1]\ncolors = [\"orange\",\"red\",\"purple\", \"magenta\", \"green\",\"blue\"]\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,10))\nplt.ylim((0,80))\nplt.ylabel(\"F1 Score\")\nplt.xlabel(\"Algorithms\")\nsns.barplot(x=methods, y=f1, palette=colors)\n# plt.grid(b=None)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:35:23.439084Z","iopub.execute_input":"2021-06-18T12:35:23.439454Z","iopub.status.idle":"2021-06-18T12:35:23.663342Z","shell.execute_reply.started":"2021-06-18T12:35:23.439426Z","shell.execute_reply":"2021-06-18T12:35:23.662358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 用直方图显示出各个算法的预测准确率\nimport seaborn as sns\nmethods = [\"Logistic Regression\", \"KNN\", \"SVM\", \n           \"Naive Bayes\", \"Decision Tree\", \"Random Forest\"]\nf1 = [lr_acc, knn_acc, svm_acc, nb_acc, dt_acc, rf_acc]\ncolors = [\"orange\",\"red\",\"purple\", \"magenta\", \"green\",\"blue\"]\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,10))\nplt.ylim((60,100))\nplt.ylabel(\"Accurancy %\")\nplt.xlabel(\"Algorithms\")\nsns.barplot(x=methods, y=f1, palette=colors)\n# plt.grid(b=None)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:35:33.405445Z","iopub.execute_input":"2021-06-18T12:35:33.405811Z","iopub.status.idle":"2021-06-18T12:35:33.64063Z","shell.execute_reply.started":"2021-06-18T12:35:33.405779Z","shell.execute_reply":"2021-06-18T12:35:33.639409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}