{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stroke Prediction\n\nYou can see the data and other details [here](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)\n\nI'm trying to predict stroke with some common classifier algorithms, and also doing some preprocessing, please give me suggestions to improve my notebook :)\n\n# **EDA**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fill null values with mean","metadata":{}},{"cell_type":"code","source":"df.bmi = df.bmi.fillna(df.bmi.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical = df[[\"age\", \"avg_glucose_level\", \"bmi\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical = df[[\"gender\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\", \"smoking_status\", \"stroke\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since our goal is to predict people with stroke, let's check the distribution of stroke","metadata":{}},{"cell_type":"code","source":"sns.countplot(df[\"stroke\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Very unbalanced, we can't directly put this dataset into models, we have to do some preprocessing first,\n\nlet's check other categorical values distribution compared to stroke column first","metadata":{}},{"cell_type":"code","source":"\nfig, axes = plt.subplots(3,3, figsize=(15,15))\na = 0\nb = 0\nfor col in categorical.columns:\n    sns.countplot(ax=axes[a][b], x=col, hue=\"stroke\", data=categorical)\n    fig.tight_layout() \n    axes[a][b].set_xticklabels(axes[a][b].get_xticklabels(), rotation=10)\n    axes\n    a+=1\n    if a==3:\n        a = 0\n        b+=1\n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's an anomaly on gender data, I'm just gonna drop it since it only one data\n\nafter that, let's check the gender with other features, we might get something","metadata":{}},{"cell_type":"code","source":"df = df[df.gender != \"Other\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(3,3, figsize=(15,15))\na = 0\nb = 0\nfor col in categorical.columns:\n    sns.countplot(ax=axes[a][b], x=col, hue=\"gender\", data= categorical[categorical.gender != \"Other\"])\n    fig.tight_layout() \n    axes[a][b].set_xticklabels(axes[a][b].get_xticklabels(), rotation=10)\n    axes\n    a+=1\n    if a==3:\n        a = 0\n        b+=1\n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the visualization we understand that:\n* There are more female population in this data\n* Most of women are not smoking\n* Can't tell the rest","metadata":{}},{"cell_type":"markdown","source":"How about numerical values?","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1,3, figsize=(15,4))\na = 0\nfor x in numerical.columns:\n    sns.distplot(df[x], ax=axes[a])\n    a+=1\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=\"age\", y=\"avg_glucose_level\", hue=\"stroke\", data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's pretty hard to tell, let's jump to the correlation between each columns","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf_prep = df.apply(le.fit_transform)\ncorrs = df_prep.corr()\nplt.figure(figsize=(12,8))\nsns.heatmap(corrs, annot=True, cmap=\"Blues\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrs[\"stroke\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we all know that stroke usually attack older people, and they tend to have higher blood pressure which brings some heart diseases.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Since the stroke data is imbalanced, we have to make them balance. And one way to do that is using SMOTE,\n\nSmote is an oversampling method by augmenting the minority classes, you can read more explanation [here](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n\nSince the augmentation will involve all features, we have to make sure that every features is numerical, let's encode the all of the categorical features first","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nLE = LabelEncoder()\n\nencode_cols = [\"gender\", \"hypertension\", \"ever_married\", \"work_type\", \"Residence_type\", \"smoking_status\"]\n\nfor col in encode_cols:\n    LE.fit(df[col])\n    df[col] = LE.transform(df[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.stroke.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apply SMOTE","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampler = SMOTE(random_state = 42)\nX = df.drop(['stroke'],axis=1)\ny = df[['stroke']]\nX,y= sampler.fit_resample(X,y['stroke'].values.ravel())\ny = pd.DataFrame({'stroke':y})\nsns.countplot(data = y, x = 'stroke', y= None)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have balanced data!","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are ready for modelling","metadata":{}},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"Splitting data into train and test","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building pipelines that will be automatically preprocessing the dataset when used by the model","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline, Pipeline\n\ncol_trans = make_column_transformer(\n            (OneHotEncoder(),['hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']),\n            (StandardScaler(),['age','avg_glucose_level', 'bmi']), \n            remainder = 'passthrough') \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.gender","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression**","metadata":{}},{"cell_type":"code","source":"logR = LogisticRegression()\n\npipe = make_pipeline(col_trans, logR)\npipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest**","metadata":{}},{"cell_type":"code","source":"RF = RandomForestClassifier(n_estimators = 50, max_depth = 3, random_state = 2 )\n\npipe = make_pipeline(col_trans, RF)\npipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gradient Boosting**","metadata":{}},{"cell_type":"code","source":"GB = GradientBoostingClassifier(n_estimators = 50, max_depth = 3, random_state = 2)\n\npipe =  make_pipeline(col_trans, GB)\npipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Naive Bayes**","metadata":{}},{"cell_type":"code","source":"NB = GaussianNB()\n\npipe =  make_pipeline(col_trans, NB)\npipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's it, Gradient Boosting results the highest accuracy (86%)\n\nI will find out something to improve these models, please give me feedback or suggestion since I'm still a beginner :)","metadata":{}}]}