{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!git clone https://gitlab.com/pw_neural_nets/numpy_gan.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir('numpy_gan')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls . #../../input/cropped-faces-celeba","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SEED = 420\n# import random\n# import numpy as np\n# import torch\n# import torchvision.utils as vutils\n# import matplotlib.pyplot as plt\n# import torchvision.transforms as transforms\n# from torchvision import datasets\n\n# from gan_utils import data_loading\n# import hparams\n# from DCGAN import models\n# from DCGAN import pipeline\n# from DCGAN import losses\n\n# np.random.seed(SEED)\n# random.seed(SEED)\n# torch.manual_seed(SEED)\n\n# if __name__ == \"__main__\":\n#     device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n    \n#     hparams.loader_type = 'load_CELEB'\n#     hparams.data_path = '../../input/cropped-faces-celeba'#'../../input/celeba-dataset'#/img_align_celeba' #\n#     hparams.epochs = 40\n#     #hparams.grad_penalty = 5.0\n#     #hparams.disc_bn = [False, True, True, True, False]\n#     #hparams.weight_clipping = 0.01\n#     hparams.disc_steps = 5\n#     hparams.gen_lr = 0.00005\n#     hparams.disc_lr = 0.00005\n    \n    \n#     data_loader = data_loading.get_data_loader(\n#         loader_type=hparams.loader_type,\n#         data_path=hparams.data_path,\n#         bs=hparams.bs,\n#         image_size=hparams.image_size\n#     )\n\n#     generator = models.Generator(channels_shapes=hparams.gen_channels_shapes).to(device)\n#     discriminator = models.Discriminator(channels_shapes=hparams.disc_channels_shapes).to(device)\n    \n#     generator.apply(models.weights_init)\n#     discriminator.apply(models.weights_init)\n\n#     gen_optimizer = torch.optim.RMSprop(generator.parameters(), lr=hparams.gen_lr)\n#     disc_optimizer = torch.optim.RMSprop(discriminator.parameters(), lr=hparams.disc_lr)\n\n# #     gen_optimizer = torch.optim.Adam(generator.parameters(), lr=hparams.gen_lr, betas=hparams.betas)\n# #     disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=hparams.disc_lr, betas=hparams.betas)\n    \n#     gen_loss_fn = losses.WassersteinGeneratorLoss()#torch.nn.BCELoss()#\n#     disc_loss_fn = losses.WassersteinDiscriminatorLoss()#torch.nn.BCELoss()#\n    \n# #     disc_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(gen_optimizer, gamma=0.99)\n# #     gen_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(disc_optimizer, gamma=0.99)\n    \n#     wgan = pipeline.WGANGP(\n#         generator=generator,\n#         discriminator=discriminator,\n#         gen_loss_fn=gen_loss_fn,\n#         disc_loss_fn=disc_loss_fn,\n#         gen_optimizer=gen_optimizer,\n#         disc_optimizer=disc_optimizer,\n#         data_loader=data_loader,\n# #         disc_lr_scheduler=disc_lr_scheduler,\n# #         gen_lr_scheduler=gen_lr_scheduler,\n#         device=device,\n#     )\n    \n#     print(wgan.__dict__.items())\n\n#     wgan.train_model()\n\n#     plt.figure(figsize=(10, 5))\n#     plt.title(\"Generator and Discriminator Loss During Training\")\n#     plt.plot(wgan.gen_losses, label=\"G\")\n#     plt.plot(wgan.disc_losses, label=\"D\")\n#     plt.xlabel(\"iterations\")\n#     plt.ylabel(\"Loss\")\n#     plt.legend()\n#     plt.show()\n\n#     # Grab a batch of real images from the dataloader\n#     real_batch = next(iter(data_loader))\n\n#     # Plot the real images\n#     plt.figure(figsize=(15, 15))\n#     plt.subplot(1, 2, 1)\n#     plt.axis(\"off\")\n#     plt.title(\"Real Images\")\n#     plt.imshow(\n#         np.transpose(vutils.make_grid(\n#             real_batch[0].to(device)[:128],\n#             padding=5,\n#             normalize=True\n#         ).cpu(), (1, 2, 0)))\n\n#     # Plot the fake images from the last epoch\n#     plt.subplot(1, 2, 2)\n#     plt.axis(\"off\")\n#     plt.title(\"Fake Images\")\n#     plt.imshow(np.transpose(wgan.img_list[-5], (1, 2, 0)))\n#     plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#     plt.figure(figsize=(10, 5))\n#     plt.title(\"Generator and Discriminator Loss During Training\")\n#     plt.plot(wgan.gen_losses, label=\"G\")\n#     plt.plot(wgan.disc_losses, label=\"D\")\n#     plt.xlabel(\"iterations\")\n#     plt.ylabel(\"Loss\")\n#     plt.legend()\n#     plt.show()\n\n#     # Grab a batch of real images from the dataloader\n#     real_batch = next(iter(data_loader))\n\n#     # Plot the real images\n#     plt.figure(figsize=(15, 15))\n#     plt.subplot(1, 2, 1)\n#     plt.axis(\"off\")\n#     plt.title(\"Real Images\")\n#     plt.imshow(\n#         np.transpose(vutils.make_grid(\n#             real_batch[0].to(device)[:128],\n#             padding=5,\n#             normalize=True\n#         ).cpu(), (1, 2, 0)))\n\n#     # Plot the fake images from the last epoch\n#     plt.subplot(1, 2, 2)\n#     plt.axis(\"off\")\n#     plt.title(\"Fake Images\")\n#     plt.imshow(np.transpose(wgan.img_list[-1], (1, 2, 0)))\n#     plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.save(wgan.img_list, './img_list.pytorch')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fake = generator(wgan.fixed_noise[0:1]).detach().cpu()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}