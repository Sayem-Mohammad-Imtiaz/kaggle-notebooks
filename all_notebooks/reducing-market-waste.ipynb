{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/hackerearths-reduce-marketing-waste/train.csv')\ntest=pd.read_csv('/kaggle/input/hackerearths-reduce-marketing-waste/test.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Analysis of Training Data****","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Probability cannot be more than 100.So, we will be dropping rows having values greater than 100\ntrain.drop(train.loc[train['Success_probability']>100].index, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train.columns:\n    print(i,\"-->\",train[i].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in test.columns:\n    print(i,\"-->\",test[i].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****EDA(Exploratory Data Analysis)****","metadata":{}},{"cell_type":"markdown","source":"### Converting Deal_value and Weighted_amount columns to float type by deleting '$' character","metadata":{}},{"cell_type":"code","source":"train['Deal_value']=train['Deal_value'].astype('str')\ntrain['Weighted_amount']=train['Weighted_amount'].astype('str')\n\ntrain['Deal_value']=train['Deal_value'].map(lambda x:str(x).split('$')[0])\ntrain['Weighted_amount']=train['Weighted_amount'].map(lambda x:str(x).split('$')[0])\n    \n    \ntrain['Deal_value']=train['Deal_value'].astype('float64')\ntrain['Weighted_amount']=train['Weighted_amount'].astype('float64')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Deal_value']=test['Deal_value'].astype('str')\ntest['Weighted_amount']=test['Weighted_amount'].astype('str')\n\ntest['Deal_value']=test['Deal_value'].map(lambda x:str(x).split('$')[0])\ntest['Weighted_amount']=test['Weighted_amount'].map(lambda x:str(x).split('$')[0])\n    \ntest['Deal_value']=test['Deal_value'].astype('float64')\ntest['Weighted_amount']=test['Weighted_amount'].astype('float64')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting year from Date_of_creation column","metadata":{}},{"cell_type":"code","source":"train['Date_of_creation']=train['Date_of_creation'].astype('str')\n\ntrain['Date_of_creation']=train['Date_of_creation'].map(lambda x:x.split('-')[0])\n\ntrain['Date_of_creation']=train['Date_of_creation'].astype('object')\ntrain.rename({'Date_of_creation':'Year'},axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Date_of_creation']=test['Date_of_creation'].astype('str')\n\ntest['Date_of_creation']=test['Date_of_creation'].map(lambda x:x.split('-')[0])\n\ntest['Date_of_creation']=test['Date_of_creation'].astype('object')\ntest.rename({'Date_of_creation':'Year'},axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting Country code from location","metadata":{}},{"cell_type":"code","source":"train['Location']=train['Location'].fillna('IND').map(lambda x:str(x).split(',')[1].rstrip() if len(str(x).split(','))>1 else 'IND')\ntest['Location']=test['Location'].fillna('IND').map(lambda x:str(x).split(',')[1].rstrip() if len(str(x).split(','))>1 else 'IND')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ****Handling Missing Values****","metadata":{}},{"cell_type":"code","source":"train.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Deal_value'].fillna(train['Deal_value'].median(),inplace=True)\ntrain['Weighted_amount'].fillna(train['Weighted_amount'].median(),inplace=True)\n\ntest['Deal_value'].fillna(test['Deal_value'].median(),inplace=True)\ntest['Weighted_amount'].fillna(test['Weighted_amount'].median(),inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Industry column has only 1 Nan value so filling it with most appeared category\ntrain['Industry'].fillna('Banks',inplace=True)\ntest['Industry'].fillna('Banks',inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Geography'].fillna(train['Geography'].mode()[0],inplace=True)\ntest['Geography'].fillna(test['Geography'].mode()[0],inplace=True)\ntrain['Geography'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Last_lead_update'].fillna(train['Last_lead_update'].mode()[0],inplace=True)\ntest['Last_lead_update'].fillna(test['Last_lead_update'].mode()[0],inplace=True)\ntrain['Last_lead_update'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Resource'].fillna(train['Resource'].mode()[0],inplace=True)\ntrain.loc[0,'Resource']='No'\ntest['Resource'].fillna(test['Resource'].mode()[0],inplace=True)\ntrain['Resource'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ****Handling Categorical Variables****","metadata":{}},{"cell_type":"code","source":"train.drop(['Deal_title','Lead_name','Contact_no','POC_name','Lead_POC_email'],axis=1,inplace=True)\ntest.drop(['Deal_title','Lead_name','Contact_no','POC_name','Lead_POC_email'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=(train.dtypes=='object')\ncategorical_features=list(s[s].index)\nprint(\"Categorical Features in the Dataset are:\")\nprint(\"\")\nprint(categorical_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in categorical_features:\n    train[i]=train[i].astype('category')\n    test[i]=test[i].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\nfor i in categorical_features:\n    train[i]=lb.fit_transform(train[i])\n    test[i]=lb.fit_transform(test[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Visualising our Data using Histograms and Scatter Plots****","metadata":{}},{"cell_type":"code","source":"for feature in train.columns:\n    data=train.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.title(feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in train.columns:\n    data=train.copy()\n    \n    data[feature]=np.log(data[feature])\n    data['Success_probability']=np.log(data['Success_probability'])\n    plt.scatter(data[feature],data['Success_probability'])\n    plt.xlabel(feature)\n    plt.ylabel('Success_probability')\n    plt.title(feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ****Looking for Outliers using Box Plots****","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfor feature in train.columns:\n    data=train.copy()\n    data[feature]=np.log(data[feature])\n    data.boxplot(column=feature)\n    plt.ylabel(feature)\n    plt.title(feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train--> Internal rating\")\nprint(train['Internal_rating'].value_counts())\n\nprint(\"Test--> Internal rating\")\nprint(test['Internal_rating'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask1=(test['Internal_rating']==-1.00)|(test['Internal_rating']==82.34)\ntest.loc[mask1,'Internal_rating']=4.00\ntest['Internal_rating']=test['Internal_rating'].astype('int64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train--> Location\")\nprint(train['Location'].value_counts())\n\nprint(\"Test--> Location\")\nprint(test['Location'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train--> Industry\")\nprint(train['Industry'].value_counts())\n\nprint(\"Test--> Industry\")\nprint(test['Industry'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train--> Hiring_candidate_role\")\nprint(train['Hiring_candidate_role'].value_counts())\n\nprint(\"Test--> Hiring_candidate_role\")\nprint(test['Hiring_candidate_role'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ****The columns Hiring_candidate_role,Industry and Location have so many outlier so remove them from training set****","metadata":{}},{"cell_type":"code","source":"Y=train['Success_probability']\nX=train.drop(['Success_probability','Hiring_candidate_role','Industry','Location'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Training Model****","metadata":{}},{"cell_type":"markdown","source":"## ****Hyperparameter Tuning****","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics\nparam_test = {\n 'max_depth':[3,4,5],\n'n_estimators':[9,10,11]\n}\n\ngsearch1 = GridSearchCV(estimator = XGBRegressor(objective= \"reg:linear\",learning_rate=0.11), \nparam_grid = param_test, scoring=metrics.mean_squared_error,n_jobs=-1,cv=3)\ngsearch1.fit(X,Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch1.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=XGBRegressor( learning_rate = 0.11,\n                max_depth =4,objective=\"reg:linear\",alpha =1,n_estimators=9)\nmodel.fit(X,Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(['Hiring_candidate_role','Industry','Location'],axis=1,inplace=True)\ny_pred=model.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t=pd.read_csv('../input/hackerearths-reduce-marketing-waste/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.DataFrame(t['Deal_title'])\nsubmission['Success_probability']=y_pred\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('Submission17.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}