{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1 Les données"},{"metadata":{},"cell_type":"markdown","source":"Un arbre de décision est utilisé dans des contextes d'apprentissage supervisés. En effet, pour le définir il est nécessaire de disposer de données étiquetées. On utilise ces données afin de construire l'arbre, puis on extrapole les résultats à l'ensemble des données de test."},{"metadata":{},"cell_type":"markdown","source":"## 2 Import des données et visualisation"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\n\niris_dataframe = pd.read_csv('../input/iris-flower-dataset/IRIS.csv')\n\niris_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.pairplot(iris_dataframe, hue='species')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3 Construction d'un arbre de décision"},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Mesure de l'entropie d'un groupe"},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import log\n\ndef entropy (dataframe):\n    rows = dataframe.shape[0]\n    series = dataframe['species'].value_counts()\n    occurences = [series.get('Iris-setosa'),series.get('Iris-versicolor'),series.get('Iris-virginica')]\n    e = 0\n    k = 3 # nombre de classes dans le dataset\n    for i in range(0,k):\n        if occurences[i] is not None:\n            e += occurences[i]/rows*log(occurences[i]/rows,2)\n    return -e","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"entropy(iris_dataframe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Déterminer quel attribut est le plus discriminant"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def decision_tree(dataframe):\n    dataframeEntropy = entropy(dataframe)\n    N = dataframe.shape[0]\n    G = 3 # nombre de groupes\n    discBest = 0 # meilleur discriminant\n    \n    for i in dataframe.keys()[:-1]: # on omet le dernier element\n        dfCopy = dataframe.sort_values(by=i)\n        subG = []\n        hGroupes = []\n        for j in range(G):\n            start = int(j*(N/G))\n            end = int((j+1)*(N/G)-1)\n            hGroupes.append(dfCopy[start:end])\n            subG.append(entropy(dfCopy[start:end]))\n        \n        # calcul du pouvoir discriminant\n        sum = 0\n        for k in subG:\n            sum += ((int(N/G)-1)/N)*k\n        disc = dataframeEntropy-sum\n        \n        if disc > discBest:\n            discBest = disc\n            meilleurAttribut = i\n            meilleursGroupes = hGroupes\n    \n    return (meilleurAttribut, meilleursGroupes)\n\ndecision_tree(iris_dataframe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":4}