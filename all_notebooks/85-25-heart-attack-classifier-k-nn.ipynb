{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\n### Aim of the Model\n- The aim of the model (kNN) is to be able to succesfully identify patients that show signs of suffering a heart attack.\n\n### Approach\n- In order to apprach this problem I'll run two versions of the kNN model:\n- Version 1: Test multiple hyperparamters and select the optimal one manually (based on a performance visualization)\n- Version 2: Test multiple hyperparameters with GridSearchCV (2-fold) and select the optimal one.\n    *My reasoning for only performing 2-fold CV is to avoid overfitting the model, given the small size of the dataset*\n\n### Definitions of the Variables\n\n- **Age** *(age)* is the age of candidate\n- **Sex** *(sex)* has numeric values. 1 denotes male and 0 denotes female\n- **Chest Pain** *(cp)* pain has values between 0-3. The types of angina that are described in the research paper. The higher the number, the lesser are the odds of heart attack\n- **Resting Blood Pressure** *(trtbps)* is normal pressure with no exercise\n- **Cholesterol** *(chol)* means the blockage for blood supply in the blood vessels\n- **Fasting Blood Pressure** *(fbs)* is blood sugar taken after a long gap between a meal and the test. Typically, it's taken before any meal in the morning\n- **Rest ECG** *(restecg)* results means ECG values taken while person is on rest which means no exercise and normal functioning of heart is happening\n- **Maximum Heart Rate** *(thalachh)* achieved\n- **Exercise Induced Angina** *(exng)* is chest pain while exercising or doing any physical activity\n- **ST Depression** *(oldpeak)* is the difference between value of ECG at rest and after exercise\n- **ST Slope** *(slp)* is the tangent to the depression value \n- **Number of Major Blood Vessels** *(caa)* supplying blood to heart blocked\n- **Types of Thalassemia** *(thall)*\n- **Heart Attack** *(target)* where 1 denotes Heart Attack suffered and 0 where it did not take place","metadata":{}},{"cell_type":"markdown","source":"## Package & Data Imports","metadata":{}},{"cell_type":"code","source":"# Importing required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:08:41.342113Z","iopub.execute_input":"2021-06-14T13:08:41.342863Z","iopub.status.idle":"2021-06-14T13:08:42.673541Z","shell.execute_reply.started":"2021-06-14T13:08:41.342734Z","shell.execute_reply":"2021-06-14T13:08:42.672585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Dataset\ndata = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\nprint(data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:08:42.674944Z","iopub.execute_input":"2021-06-14T13:08:42.675375Z","iopub.status.idle":"2021-06-14T13:08:42.727827Z","shell.execute_reply.started":"2021-06-14T13:08:42.675342Z","shell.execute_reply":"2021-06-14T13:08:42.726638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA\n\n### Observations\n***Population Distribution***\n- *Gender (sex):* Population presents ~x2 times more Males (1) than Females (0)\n- *Age (age):* Despite Male population presenting a slighly younger mean distibutions are similar, both presenting more observation below the mean (skewed to the left)\n\n***Gender Comparisons***\n- *Types of Thalassemia (thall):* Females have significant bigger probability of suffering type 2 Thalassemia. whilst males present a bigger probability of suffering type 3 Thalassemia\n- *Heart Attack (target):* Females have higher probability than males to suffer a heart attack\n- *Other Variables:* For all other variables there are differences in scales, but probability distribitions are very similar\n\n***Correlations***\n- We can observe from the heatmap that there are no major correlations","metadata":{}},{"cell_type":"code","source":"graph_df = data.copy()\nsns.set()\nsns.set(rc={'figure.figsize':(15,10)})\n\n# Population\nsns.catplot(x='sex', kind='count', data=graph_df)\nplt.show()\nplt.close()\n\n# Age\nsns.histplot(x='age', hue='sex', kde=True, data=graph_df)\nplt.show()\nplt.close()\n\n# Pairplot\nsns.pairplot(graph_df, hue='sex')\nplt.show()\nplt.close()\n\n# Plotting Correlations\nsns.heatmap(graph_df.corr(), vmin=-1, vmax=1, cmap=\"Spectral\", annot=True)\nplt.show()\nplt.close()\n\ndel graph_df","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:08:42.730049Z","iopub.execute_input":"2021-06-14T13:08:42.730456Z","iopub.status.idle":"2021-06-14T13:09:33.713264Z","shell.execute_reply.started":"2021-06-14T13:08:42.730402Z","shell.execute_reply":"2021-06-14T13:09:33.711923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n\n#### Observations\n- There is no missing data. This means preprocessing will be limited to scaling the data (no imputing or any other process for handling missing data)\n\n#### Model/Hold-Out and Training/Test Splits\n- Step 1: Arrange all features and labels as numpy arrays\n- Step 2: Create *Model* and *Hold-Out* sets. Having a *Hold-Out* set (data never seen by the model) will ensure the best test on model performance on unseen data\n- Step 3: Create *Training* and *Test* sets for model creation","metadata":{}},{"cell_type":"code","source":"# Check for Missing Data\nprint(data.info())\n# Centering and Scaling Model Features\n    # Separating Features and Labels\ndata_features = data.drop('target', axis=1)\ndata_labels = data.target\n    # Scaling Features\ndata_features_scaled = scale(data_features)\n\n# Features/Label in numpy arrays\nfeatures = data_features_scaled\nlabel = data_labels.to_numpy()\n# Model/Hold-out sets\nmodel_features, holdout_features, model_label, holdout_label = \\\n    train_test_split(features, label, test_size=0.2, random_state=57, stratify=label)\n# Test/Train sets from Model set\ntrain_features, test_features, train_label, test_label = \\\n    train_test_split(model_features, model_label, test_size=0.2, random_state=14, stratify=model_label)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:09:33.715782Z","iopub.execute_input":"2021-06-14T13:09:33.716229Z","iopub.status.idle":"2021-06-14T13:09:33.747068Z","shell.execute_reply.started":"2021-06-14T13:09:33.716181Z","shell.execute_reply":"2021-06-14T13:09:33.745878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## kNN Model Version 1\n\n***Model Creation***\n- Step 1: Open the necessary numpy arrays\n- Step 2: Iterate over the hyparparameter candidates and visualize performance\n- Steo 3: Run the model with the optimal hyperparameter","metadata":{}},{"cell_type":"code","source":"# NumPy Arrays\nneighbors = np.arange(1, 25, step=1)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n# Iterating Hyperparamater Candidates and Recording Performance\nfor i, k in enumerate(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(train_features, train_label)\n    train_accuracy[i] = knn.score(train_features, train_label)\n    test_accuracy[i] = knn.score(test_features, test_label)\n# Visualize Performance of Hyperparamaters\nplt.title('k,NN: Varying Number of Neighbors')\nplt.plot(neighbors, test_accuracy, label='Testing Accuracy', color='red', marker='o')\nplt.plot(neighbors, train_accuracy, label='Training Accuracy', linestyle='--', color='grey')\nplt.xticks(neighbors)\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:09:33.748931Z","iopub.execute_input":"2021-06-14T13:09:33.749283Z","iopub.status.idle":"2021-06-14T13:09:34.466696Z","shell.execute_reply.started":"2021-06-14T13:09:33.749248Z","shell.execute_reply":"2021-06-14T13:09:34.46556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting and Scoring the model\nknn = KNeighborsClassifier(n_neighbors=9)\nknn.fit(model_features, model_label)\nknn_model_score = knn.score(model_features, model_label)\nknn_holdout_score = knn.score(holdout_features, holdout_label)\nknn_holdout_predict = knn.predict(holdout_features)\nprint('INITIAL MODEL PERFORMANCE')\nprint('kNN Score on Training Data: {}%'.format((knn_model_score*100).round(2)))\nprint('kNN Score on Hold-Out Data: {}%'.format((knn_holdout_score*100).round(2)))\nprint('kNN Classification Report:')\nprint(classification_report(holdout_label, knn_holdout_predict))\nprint('')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:09:34.468338Z","iopub.execute_input":"2021-06-14T13:09:34.468719Z","iopub.status.idle":"2021-06-14T13:09:34.507026Z","shell.execute_reply.started":"2021-06-14T13:09:34.468683Z","shell.execute_reply":"2021-06-14T13:09:34.505768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## kNN Model Version 2\n\n***Model Creation***\n- Step 1: Open 2-fold GridSearchCv\n- Step 2: Automate kNN with optimal hyperparamters from step 1\n- Steo 3: Run the model with the optimal hyperparameter","metadata":{}},{"cell_type":"code","source":"# Tuning for optimal hyperparameter 'k' (number of neighbors) with GridSearchCV\nparam_grid = {'n_neighbors': np.arange(1, 100, step=1)}\nknn = KNeighborsClassifier()\nknn_grid_cv = GridSearchCV(knn, param_grid, cv=2)\nknn_grid_cv.fit(model_features, model_label)\noptimal_k = knn_grid_cv.best_params_['n_neighbors']\noptimal_score = knn_grid_cv.best_score_\n# Testing the model on unseen data\nknn_tuned = KNeighborsClassifier(n_neighbors=optimal_k)\nknn_tuned.fit(model_features, model_label)\naccuracy = knn_tuned.score(holdout_features, holdout_label)\nknn_tuned_predict = knn_tuned.predict(holdout_features)\nprint('TUNING PERFORMANCE')\nprint('Optimal Value of Hyperparameter: {}'.format(optimal_k))\nprint('kNN Score on Training Data: {}%'.format((optimal_score * 100).round(2)))\nprint('kNN Score on Hold-Out Data: {}%'.format((accuracy * 100).round(2)))\nprint('kNN Classifciation Report:')\nprint(classification_report(holdout_label, knn_tuned_predict))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:09:34.508498Z","iopub.execute_input":"2021-06-14T13:09:34.508806Z","iopub.status.idle":"2021-06-14T13:09:36.023989Z","shell.execute_reply.started":"2021-06-14T13:09:34.508773Z","shell.execute_reply":"2021-06-14T13:09:36.023213Z"},"trusted":true},"execution_count":null,"outputs":[]}]}