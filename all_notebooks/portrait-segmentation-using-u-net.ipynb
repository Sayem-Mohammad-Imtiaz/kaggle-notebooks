{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\n\nimport shutil\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\n# Don't Show Warning Messages\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set up the canvas for the subplots\nplt.figure(figsize=(7,7))\nplt.tight_layout()\nplt.axis('Off')\n\n\n# Our subplot will contain 4 rows and 4 columns\n# plt.subplot(nrows, ncols, plot_number)\n\n# image\nplt.subplot(1,2,1)\npath = '../input/aisegmentcom-matting-human-datasets/clip_img/1803151818/clip_00000000/1803151818-00000003.jpg'\nimage = plt.imread(path)\nplt.title('RGB Image')\nplt.imshow(image)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,2,2)\npath = '../input/aisegmentcom-matting-human-datasets/matting/1803151818/matting_00000000/1803151818-00000003.png'\nmask = plt.imread(path)\nplt.title('RGBA Image')\nplt.imshow(mask)\nplt.axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = np.zeros((800,600,4))\nf[:,:,:3] = image\nf[:,:,3] = mask[:,:,3]\nplt.imshow(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(mask[:,:,3].flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(mask[:,:,3]).dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask[:,:,3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ana = list(mask[:,:,3].flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(ana)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ana.count(0)+ana.count(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(mask[:,:,3],cmap = \"gray\") # 0 opaque 1 transparent","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#                                        # * 1. 1. * MAIN PROGRAM STARTS****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfio = pd.read_csv(\"../input/maincsv/dfio.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfio = pd.read_csv(\"../input/maincsv/dfio.csv\")\n\nfor x in range(2) :\n    \n    path = dfio[\"input_path\"][x]\n    image = plt.imread(path)\n    print(path)\n    plt.title('RGB Image')\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n\n    \n    path = dfio[\"output_path\"][x]\n    \n    print(path)\n    mask = plt.imread(path)\n    plt.title('RGBA Image')\n    plt.imshow(mask)\n    plt.axis('off')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_v = dfio.iloc[:1280,:]\ndf_t = dfio.iloc[1280:23104,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df_v),len(df_t),len(dfio))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"23148/64\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"361*64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_t[\"output_path\"][1280]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#                                                                           # TRAIN GENERATOR","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_generator( df,batch_size=64):\n    IMG_HEIGHT = 128\n    IMG_WIDTH = 128\n    IMG_CHANNELS = 3\n\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for  i in range(1280,18560,64):\n           \n            \n            # Create empty X matrix - 3 channels\n            # Note: We use len(df) because the last batch will be smaller than the other batches.\n            X_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\n            \n            \n            # Create X_train\n            #================\n            \n            for x in range(64):\n                \n                # select the folder_id from the list\n                \n\n                # set the path to the image\n                path = df[\"input_path\"][x+i]\n                # read the image\n                image = cv2.imread(path)\n                \n                # resize the image\n                image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n                p = image/255\n                # insert the image into X_train\n                X_train[x] = p\n            \n            \n            # Create Y_train\n            # ===============\n                \n           \n                \n                # select the folder_id from the list\n               \n\n                # set the path to the mask\n                path = df[\"output_path\"][x+i]\n\n                # read the image\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n\n                # select the alpha channel\n                k = mask[:, :, 3]\n                \n                \n                # expand dims from (800,600) to (800,600,1)\n                k = np.expand_dims(k, axis=-1)\n                \n                # resize the mask\n                k = resize(k, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n                k = k>0.5\n                # insert the image into Y_train\n                Y_train[x] = k\n\n            yield X_train, Y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# #VALIDTION GENERATOR","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_generator( df1,batch_size=64):\n    IMG_HEIGHT = 128\n    IMG_WIDTH = 128\n    IMG_CHANNELS = 3\n\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for  i in range(0,len(df1),64):\n           \n            \n            # Create empty X matrix - 3 channels\n            # Note: We use len(df) because the last batch will be smaller than the other batches.\n            X_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\n            \n            \n            # Create X_train\n            #================\n            \n            for x in range(64):\n                \n                # select the folder_id from the list\n                \n\n                # set the path to the image\n                path = df1[\"input_path\"][i+x]\n                # read the image\n                image = cv2.imread(path)\n                \n                # resize the image\n                image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n                p = image/255\n               \n                # insert the image into X_train\n                X_train[x] = p\n            \n            \n            # Create Y_train\n            # ===============\n                \n           \n                \n                # select the folder_id from the list\n               \n\n                # set the path to the mask\n                path = df1[\"output_path\"][x+i]\n\n                # read the image\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n\n                # select the alpha channel\n                k = mask[:, :, 3]\n                \n                \n                # expand dims from (800,600) to (800,600,1)\n                k = np.expand_dims(k, axis=-1)\n                \n                # resize the mask\n                k = resize(k, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n                k = k>0.5\n                # insert the image into Y_train\n                Y_train[x] = k\n\n            yield X_train, Y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_HEIGHT = 128\nIMG_WIDTH = 128\nIMG_CHANNELS = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, load_model\nfrom keras.layers import Input, UpSampling2D\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL CODE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n\n\n\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nnum_train_samples = 17280\nnum_val_samples = len(df_v)\ntrain_batch_size = BATCH_SIZE\nval_batch_size = BATCH_SIZE\n\n# determine numtrain steps\ntrain_steps = 270\n# determine num val steps\nval_steps = np.ceil(num_val_samples / val_batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = train_generator(df_t,batch_size=BATCH_SIZE)\nval_gen = val_generator(df_v,batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAINING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"model.h5\"\n\nearlystopper = EarlyStopping(patience=5, verbose=1,monitor=\"val_acc\")\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,  save_best_only=True, mode=\"auto\")\n\n                            \ncallbacks_list = [earlystopper, checkpoint]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=10,validation_data=val_gen, validation_steps=val_steps,verbose=1,callbacks=callbacks_list)\n                             \n                            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}