{"cells":[{"metadata":{},"cell_type":"markdown","source":"I'm just interested in visualizing the frequency of some words over time in news titles. No machine learning involved."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom textblob import TextBlob\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/abcnews-date-text.csv\",parse_dates=[0], infer_datetime_format=True)\ndata.columns = ['date','text']\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert publish_date into datetime64 format. Sort by date"},{"metadata":{"trusted":true},"cell_type":"code","source":"reindexed_data = data['text']\nreindexed_data.index = data['date']\nreindexed_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some keywords I thought might be interesting...."},{"metadata":{"trusted":true},"cell_type":"code","source":"Xi = [0]*reindexed_data.shape[0]\nTrump = [0]*reindexed_data.shape[0]\nTrade = [0]*reindexed_data.shape[0]\nWar = [0]*reindexed_data.shape[0]\n\nfor i in range(reindexed_data.shape[0]):\n    words = TextBlob(reindexed_data[i]).words\n    for word in words:\n        if word == \"xi\" or word == \"jinping\": Xi[i]=1\n        if word == \"trump\": Trump[i]=1\n        if word == \"trade\": Trade[i]=1\n        if word == \"war\": War[i]=1   # as all headlines are in lowercase\nkeywords = pd.DataFrame({'text':reindexed_data,\n                        'Xi':Xi,\n                        'Trump':Trump,\n                        'Trade':Trade,\n                        'War':War},\n                        index=reindexed_data.index)\nkeywords.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aggregate monthly frequency for keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly = keywords.resample('M').sum()\n#yearly = keywords.resample('A').sum()\nprint(monthly)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the frequency over time"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18,8))\n\nax.plot(monthly['Xi'], label='Xi');\nax.plot(monthly['Trump'], label='Trump');\nax.plot(monthly['Trade'], label='Trade');\nax.plot(monthly['War'], label='War');\nax.set_title('Keywords Frequency over Time');\nax.legend(loc='upper left');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First of all, the frequency of \"War\" in headlines was through the roof in mid 2003. I think that is when US invaded Iraq. The war lasted for a little over a month, which explains the spike.\n\nClearly Trump didn't start to get headlines until early 2016"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}