{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Productivity Prediction of Garment Employees\n\n# Predicción de  productividad de los empleados de  confección","metadata":{}},{"cell_type":"markdown","source":"### Context\nThe Garment Industry is one of the key examples of the industrial globalization of this modern era. It is a highly labour-intensive industry with lots of manual processes. Satisfying the huge global demand for garment products is mostly dependent on the production and delivery performance of the employees in the garment manufacturing companies. So, it is highly desirable among the decision makers in the garments industry to track, analyse and predict the productivity performance of the working teams in their factories\n\n### Content\nThis dataset includes important attributes of the garment manufacturing process and the productivity of the employees which had been collected manually and also been validated by the industry experts.\n\n-------------------------------------------------------------------------------------------------------------------\n### Contexto\nLa industria de la confección es uno de los ejemplos clave de la globalización industrial de esta era moderna. Es una industria que requiere mucha mano de obra y muchos procesos manuales. Satisfacer la enorme demanda mundial de productos de confección depende principalmente del rendimiento de producción y entrega de los empleados en las empresas de fabricación de prendas de vestir. Por lo tanto, es muy deseable entre los tomadores de decisiones en la industria de la confección rastrear, analizar y predecir el desempeño productivo de los equipos de trabajo en sus fábricas.\n\n### Contenido\nEste conjunto de datos incluye atributos importantes del proceso de fabricación de prendas de vestir y la productividad de los empleados que se recopilaron manualmente y también fueron validados por los expertos de la industria.","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/ishadss/productivity-prediction-of-garment-employees","metadata":{}},{"cell_type":"markdown","source":"##  Predict the productivity range\n\n### Task Details\nIt is highly desirable among the decision makers in the garments industry to track, analyse and predict the productivity performance of the working teams in their factories.\n\n### Expected Submission\nThis dataset can be used for regression purpose by predicting the productivity range (0-1) or for classification purpose by transforming the productivity range (0-1) into different classes.\n\n\n\n## Sumary\n\n1. Explanation of variables\n2. Data analysis\n3. Pre-processing of data\n4. Correlation in our variables\n5. Data visualization\n6. Application of models\n7. Model comparison\n8. Decision tree regressor\n9. Randon forest regressor\n10. Conclusion and results\n\n\n\n\n-------------------------------------------------------------------------------------------------------------------\n\n## Predecir el rango de productividad\n\n### Detalles de la tarea\nEs muy deseable entre los tomadores de decisiones en la industria de la confección rastrear, analizar y predecir el desempeño productivo de los equipos de trabajo en sus fábricas.\n\n### Envío esperado\nEste conjunto de datos se puede utilizar con fines de regresión al predecir el rango de productividad (0-1) o con fines de clasificación al transformar el rango de productividad (0-1) en diferentes clases.\n\n\n\n## Resumen\n\n1. Explicación de variables\n2. Análisis de datos\n3. Tratamiento previo de datos\n4. Visualización de datos\n5. Correlación en nuestras variables\n6. Aplicación de modelos\n7. Comparación de modelos\n8. Regresor del árbol de decisión\n9. Regresor del bosque de Randon\n10. Conclusión y resultados\n\n\n\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Explanation of variables\n\n1.date : Date in MM-DD-YYYY\n\n2.day : Day of the Week\n\n3.quarter : A portion of the month. A month was divided into four quarters\n\n4.department : Associated department with the instance\n5.teamNumber : Associated team number with the instance\n6.noofworkers : Number of workers in each team\n7.noofstylechange : Number of changes in the style of a particular product\n\n8.targetedproductivity : Targeted productivity set by the Authority for each team for each day.\n\n9.smv : Standard Minute Value, it is the allocated time for a task\n\n10.wip : Work in progress. Includes the number of unfinished items for products\n\n11.overtime : Represents the amount of overtime by each team in minutes\n\n12.incentive : Represents the amount of financial incentive (in BDT) that enables or motivates a particular course of action.\n\n13.idletime : The amount of time when the production was interrupted due to several reasons\n\n14.idlemen : The number of workers who were idle due to production interruption\n\n15.actual_productivity : The actual % of productivity that was delivered by the workers. It ranges from 0-1.\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# 1. Explicación de variables\n\n1.Fecha: fecha en MM-DD-AAAA\n\n2.Día: día de la semana\n\n3.Trimestre: una parte del mes. Un mes se dividió en cuatro trimestres.\n\n4.Departamento: Departamento asociado a la instancia\n\n5.TeamNumber: número de equipo asociado a la instancia\n\n6.No_of_workers: Número de trabajadores en cada equipo\n\n7.No_of_stylechange: número de cambios en el estilo de un producto en particular\n\n8.Productividad objetivo: Productividad objetivo establecida por la Autoridad para cada equipo para cada día.\n\n9.smv: Valor minuto estándar, es el tiempo asignado para una tarea\n\n10.wip: trabajo en curso. Incluye el número de elementos sin terminar de los productos.\n\n11.Tiempo extra: representa la cantidad de tiempo extra de cada equipo en minutos\n\n12.Incentivo: Representa la cantidad de incentivo financiero (en BDT) que habilita o motiva un curso de acción en particular.\n\n13.Idletime: la cantidad de tiempo en que se interrumpió la producción debido a varias razones\n\n14.Idlemen: el número de trabajadores que estuvieron inactivos debido a la interrupción de la producción\n\n15.Productividad_real: El% real de productividad que entregaron los trabajadores. Va de 0 a 1.","metadata":{}},{"cell_type":"markdown","source":"#### We include the necessary libraries in the project\n#### Incluimos las librerias necesarias en el proyecto","metadata":{}},{"cell_type":"code","source":"# Machine Learning Libraries#\nimport pandas as pd\nimport numpy as np\nimport warnings\n\nfrom sklearn import tree\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics, linear_model\nfrom sklearn.metrics import accuracy_score, confusion_matrix,r2_score, mean_squared_error\n\n\n\nfrom sklearn.decomposition import PCA\n\nfrom scipy.spatial.distance import pdist, squareform\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix \n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import tree\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.impute import SimpleImputer  #Remplazar valores null\n\n\nimport warnings","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:04:03.83177Z","iopub.execute_input":"2021-07-09T10:04:03.83213Z","iopub.status.idle":"2021-07-09T10:04:05.298553Z","shell.execute_reply.started":"2021-07-09T10:04:03.832099Z","shell.execute_reply":"2021-07-09T10:04:05.297527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data analysis","metadata":{}},{"cell_type":"code","source":"#Importamos el dataset\n\ndf = pd.read_csv('/kaggle/input/productivity-prediction-of-garment-employees/garments_worker_productivity.csv')\ndf.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:05:58.223533Z","iopub.execute_input":"2021-07-09T10:05:58.223887Z","iopub.status.idle":"2021-07-09T10:05:58.284015Z","shell.execute_reply.started":"2021-07-09T10:05:58.223857Z","shell.execute_reply":"2021-07-09T10:05:58.283057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:01.674245Z","iopub.execute_input":"2021-07-09T10:06:01.674996Z","iopub.status.idle":"2021-07-09T10:06:01.701245Z","shell.execute_reply.started":"2021-07-09T10:06:01.674951Z","shell.execute_reply":"2021-07-09T10:06:01.69962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:08.273218Z","iopub.execute_input":"2021-07-09T10:06:08.273938Z","iopub.status.idle":"2021-07-09T10:06:08.326279Z","shell.execute_reply.started":"2021-07-09T10:06:08.273873Z","shell.execute_reply":"2021-07-09T10:06:08.325351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Pre-processing of data","metadata":{}},{"cell_type":"markdown","source":"### Valores nulos\n\n\nMCAR (Missing Completely At Random): los valores faltantes realmente \n    son aleatorios. No sabemos la causa de su ausencia y no hay otras \n    variables que la expliquen. No podemos estimar su valor. Si no son\n    muchos valores faltantes, los podemos eliminar. Aunque a medida \n    que vayamos eliminando más datos, perderemos precisión en nuestros \n    modelos, por eso sería más interesante estimar los valores.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()\n#Encontramos 506 valores nulos en la columna wip","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:12.89596Z","iopub.execute_input":"2021-07-09T10:06:12.896437Z","iopub.status.idle":"2021-07-09T10:06:12.908591Z","shell.execute_reply.started":"2021-07-09T10:06:12.896385Z","shell.execute_reply":"2021-07-09T10:06:12.907427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pasamos a eliminar los datos nulos\ndf.sample(10)\n#Observamos que en la estructura de los datos si tienen Header","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:16.476773Z","iopub.execute_input":"2021-07-09T10:06:16.477249Z","iopub.status.idle":"2021-07-09T10:06:16.505668Z","shell.execute_reply.started":"2021-07-09T10:06:16.477208Z","shell.execute_reply":"2021-07-09T10:06:16.504688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pregunta: Por que mi variable team aparece como false?","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:23.067679Z","iopub.execute_input":"2021-07-09T10:06:23.068174Z","iopub.status.idle":"2021-07-09T10:06:23.075226Z","shell.execute_reply.started":"2021-07-09T10:06:23.068142Z","shell.execute_reply":"2021-07-09T10:06:23.074236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp = SimpleImputer(missing_values = np.nan, strategy = 'wip')\n\ndf","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:29.621888Z","iopub.execute_input":"2021-07-09T10:06:29.622515Z","iopub.status.idle":"2021-07-09T10:06:29.654151Z","shell.execute_reply.started":"2021-07-09T10:06:29.622481Z","shell.execute_reply":"2021-07-09T10:06:29.65292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['team'].unique()  #Sacamos un listado de los items contenidos en esta columna, con el fin de evaluar su posible distribución\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:38.104219Z","iopub.execute_input":"2021-07-09T10:06:38.10457Z","iopub.status.idle":"2021-07-09T10:06:38.112604Z","shell.execute_reply.started":"2021-07-09T10:06:38.104541Z","shell.execute_reply":"2021-07-09T10:06:38.111534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:49:27.954244Z","iopub.execute_input":"2021-07-09T08:49:27.954777Z","iopub.status.idle":"2021-07-09T08:49:27.9634Z","shell.execute_reply.started":"2021-07-09T08:49:27.954742Z","shell.execute_reply":"2021-07-09T08:49:27.962629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos que los datos que se contienen en la columna 'team' deben ser clasificados y distribuidos, para lo cual es necesario aplicar el metodo apply(lambda) --> esto aplicado como string.\n\nDe igual manera, a continuación procederemos a dropear la columna quarter y day, para luego utilizar la columna 'date' y tomar el primer y segundo elemento, con el fin de que posteriormente con un get_dummies ingresarlos junto con las nuevas columnas de team a nuestro nuevo dataset.","metadata":{}},{"cell_type":"code","source":"\n#dropear quarter y day para \ndf2 = df.drop(['quarter','day'], axis = 1)\n#\ndf2['team'] = df2['team'].apply(lambda x:str(x))\n\n#Department\n#df2['department'] = df['department'].apply(lambda x: 'finishing' if x == ('finishing ' or 'finishing' ) else 'sewing' )\n\n#Tomar date extraigo el dia y el mes, despues lo dropeo\ndf2['day'] = df2['date'].apply(lambda x:int(x.split(\"/\")[0]))\ndf2['month'] = df2['date'].apply(lambda x:int(x.split(\"/\")[1]))\n\n\ndf2 = df2.drop(['date'], axis = 1)\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:50.415886Z","iopub.execute_input":"2021-07-09T10:06:50.416262Z","iopub.status.idle":"2021-07-09T10:06:50.448345Z","shell.execute_reply.started":"2021-07-09T10:06:50.41623Z","shell.execute_reply":"2021-07-09T10:06:50.447227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos que el head() que invocamos ya no tiene las columnas dropeadas y por lo contrario tenemos dos nuevas que son 'day' y 'month', extraidas de la columna 'date', que también ya no se encuentra.","metadata":{}},{"cell_type":"code","source":"df2 = pd.get_dummies(df2)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:06:59.787117Z","iopub.execute_input":"2021-07-09T10:06:59.787497Z","iopub.status.idle":"2021-07-09T10:06:59.802166Z","shell.execute_reply.started":"2021-07-09T10:06:59.787466Z","shell.execute_reply":"2021-07-09T10:06:59.801218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The get_dummies () function is used to convert categorical variable into dummy / indicator variables. Fecha of which to get dummy indicators. String to append DataFrame column names. ","metadata":{}},{"cell_type":"code","source":"df2.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:07:03.881118Z","iopub.execute_input":"2021-07-09T10:07:03.881461Z","iopub.status.idle":"2021-07-09T10:07:03.905206Z","shell.execute_reply.started":"2021-07-09T10:07:03.881432Z","shell.execute_reply":"2021-07-09T10:07:03.904372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente observamos las nuevas columnas de 'team', las cuales son 12 que son la cantidad de equipos en nuestro dataset.\n\nA continuación utilizamos el algoritmo Knn que es denominado como el mas proximo, para remplazar los valores null que tengamos en nuestro dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import KNNImputer  # Con esto imputamos los valores null utilizando el algoritmo de knn \"El mas proximo\"\n\nkimp = KNNImputer(n_neighbors = 3)   #\ndf2_clean = kimp.fit_transform(df2)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:07:11.524684Z","iopub.execute_input":"2021-07-09T10:07:11.525421Z","iopub.status.idle":"2021-07-09T10:07:11.635484Z","shell.execute_reply.started":"2021-07-09T10:07:11.52536Z","shell.execute_reply":"2021-07-09T10:07:11.634384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2_clean = pd.DataFrame(df2_clean, columns = df2.columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:07:19.702802Z","iopub.execute_input":"2021-07-09T10:07:19.703131Z","iopub.status.idle":"2021-07-09T10:07:19.70771Z","shell.execute_reply.started":"2021-07-09T10:07:19.703103Z","shell.execute_reply":"2021-07-09T10:07:19.706556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente ya remplazamos los valores null que teniamos y procedemos a guardarlos en un nuevo dataset que llamaremos df2_clean. Para comprobarlo, realizamos un \".isnull().sum()\" para sumar todos nuestro valores nulos,con lo cual observaremos que no tenemos ninguno.\n\nEn teoria, ya terminamos de limpiar nuestro dataset y podemos proceder con esto.","metadata":{}},{"cell_type":"code","source":"df2_clean.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:07:28.17563Z","iopub.execute_input":"2021-07-09T10:07:28.176149Z","iopub.status.idle":"2021-07-09T10:07:28.183997Z","shell.execute_reply.started":"2021-07-09T10:07:28.176105Z","shell.execute_reply":"2021-07-09T10:07:28.183253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Correlation in our variables","metadata":{}},{"cell_type":"code","source":"correlation_matrix = df2_clean.corr().round(2)\n\nfig, ax = plt.subplots(figsize = (15,10))\nsns.heatmap(data = correlation_matrix, annot = True, ax = ax, cmap = 'coolwarm')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:19:47.101309Z","iopub.execute_input":"2021-07-09T10:19:47.101711Z","iopub.status.idle":"2021-07-09T10:19:51.097932Z","shell.execute_reply.started":"2021-07-09T10:19:47.101677Z","shell.execute_reply":"2021-07-09T10:19:51.097007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notamos una correlación del 94% en las variables 'department_sweing' y 'no_of_workers', asi mismo otra correlación que podemos destacar es la que existe entre 'no_of_workers' y 'smv' con un 91%.\n\nOtras encontradas:\n\n-'department_sweing' AND 'smv' -->87%\n\n-'no_of_workers' AND 'over_time' -->73%\n\n-'department_sweing' AND 'over_time' -->68%\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# 5. Data visualization","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df2_clean,diag_kind='kde');","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:50:30.267624Z","iopub.execute_input":"2021-07-09T08:50:30.268043Z","iopub.status.idle":"2021-07-09T08:54:37.012463Z","shell.execute_reply.started":"2021-07-09T08:50:30.268007Z","shell.execute_reply":"2021-07-09T08:54:37.011059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df2_clean['no_of_workers'], df2_clean['smv'], label = 'Cluster 1');\nplt.scatter(df2_clean['no_of_workers'], df['team'], label = 'Cluster 2', marker = 'x');\nplt.scatter(df2_clean['no_of_workers'], df2_clean['over_time'], label = 'Cluster 3');\nplt.legend()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:03.163385Z","iopub.execute_input":"2021-07-09T10:20:03.163731Z","iopub.status.idle":"2021-07-09T10:20:03.433951Z","shell.execute_reply.started":"2021-07-09T10:20:03.163704Z","shell.execute_reply":"2021-07-09T10:20:03.43273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df2_clean['no_of_workers'], df2_clean['over_time'], label = 'Cluster 3');\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:06.417362Z","iopub.execute_input":"2021-07-09T10:20:06.417918Z","iopub.status.idle":"2021-07-09T10:20:06.602019Z","shell.execute_reply.started":"2021-07-09T10:20:06.417874Z","shell.execute_reply":"2021-07-09T10:20:06.601009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.displot(df2_clean['actual_productivity'])","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:11.770509Z","iopub.execute_input":"2021-07-09T10:20:11.770874Z","iopub.status.idle":"2021-07-09T10:20:12.185864Z","shell.execute_reply.started":"2021-07-09T10:20:11.770845Z","shell.execute_reply":"2021-07-09T10:20:12.184864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2_clean.actual_productivity.hist()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:17.514226Z","iopub.execute_input":"2021-07-09T10:20:17.514609Z","iopub.status.idle":"2021-07-09T10:20:17.756104Z","shell.execute_reply.started":"2021-07-09T10:20:17.514574Z","shell.execute_reply":"2021-07-09T10:20:17.755099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2_clean.skew().sort_values(ascending=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:23.687624Z","iopub.execute_input":"2021-07-09T10:20:23.687953Z","iopub.status.idle":"2021-07-09T10:20:23.699056Z","shell.execute_reply.started":"2021-07-09T10:20:23.687925Z","shell.execute_reply":"2021-07-09T10:20:23.69772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats.mstats import normaltest\nnormaltest(df.actual_productivity.values)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:28.416922Z","iopub.execute_input":"2021-07-09T10:20:28.417309Z","iopub.status.idle":"2021-07-09T10:20:28.428642Z","shell.execute_reply.started":"2021-07-09T10:20:28.417276Z","shell.execute_reply":"2021-07-09T10:20:28.427562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_price = np.log(df.actual_productivity)\nlog_price.hist()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:32.344791Z","iopub.execute_input":"2021-07-09T10:20:32.345124Z","iopub.status.idle":"2021-07-09T10:20:32.573019Z","shell.execute_reply.started":"2021-07-09T10:20:32.345096Z","shell.execute_reply":"2021-07-09T10:20:32.571803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.boxplot(data=df2_clean,y='actual_productivity')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:37.585502Z","iopub.execute_input":"2021-07-09T10:20:37.585994Z","iopub.status.idle":"2021-07-09T10:20:37.709672Z","shell.execute_reply.started":"2021-07-09T10:20:37.585947Z","shell.execute_reply":"2021-07-09T10:20:37.708925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfig, ax = plt.subplots(1,1,figsize = (10,3))\nsns.distplot(df2_clean['no_of_workers'], bins = 40, ax = ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:20:47.931557Z","iopub.execute_input":"2021-07-09T10:20:47.931893Z","iopub.status.idle":"2021-07-09T10:20:48.338257Z","shell.execute_reply.started":"2021-07-09T10:20:47.931861Z","shell.execute_reply":"2021-07-09T10:20:48.337296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nfig, ax = plt.subplots(1,1,figsize = (10,3))\nsns.distplot(df2_clean['over_time'], bins = 40, ax = ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:55:36.329421Z","iopub.execute_input":"2021-07-09T08:55:36.329836Z","iopub.status.idle":"2021-07-09T08:55:36.714147Z","shell.execute_reply.started":"2021-07-09T08:55:36.3298Z","shell.execute_reply":"2021-07-09T08:55:36.712938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Application of models","metadata":{}},{"cell_type":"markdown","source":"#### We set our variables to train and plot in our models\n\n#### Planteamos nuestras variables a entrenar y plotear en nuestros modelos","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 5))\n\nX = ['no_of_workers','smv']\nY = df2_clean['actual_productivity']\n\nfor i, col in enumerate(X):\n    plt.subplot(1, len(X) , i + 1)\n    x = df2_clean[col]\n    y = Y\n    plt.scatter(x, y, marker = 'o')\n    plt.title(\"actual_productivity en función de \" + col)\n    plt.xlabel(col)\n    plt.ylabel('actual_productivity')\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:09.453608Z","iopub.execute_input":"2021-07-09T10:21:09.453937Z","iopub.status.idle":"2021-07-09T10:21:09.894923Z","shell.execute_reply.started":"2021-07-09T10:21:09.45391Z","shell.execute_reply":"2021-07-09T10:21:09.89387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Definimos las variables a ingresar en nuestros modelos  'X' y 'Y' para el Train y el Test","metadata":{}},{"cell_type":"code","source":"X = df2_clean.drop(['actual_productivity'], axis = 1)\nY = df2_clean['actual_productivity']","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:18.996453Z","iopub.execute_input":"2021-07-09T10:21:18.996813Z","iopub.status.idle":"2021-07-09T10:21:19.002128Z","shell.execute_reply.started":"2021-07-09T10:21:18.996783Z","shell.execute_reply":"2021-07-09T10:21:19.000884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 123)\n\nprint(X_train.shape), print(X_test.shape), print(Y_train.shape), print(Y_test.shape);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:21.815875Z","iopub.execute_input":"2021-07-09T10:21:21.816229Z","iopub.status.idle":"2021-07-09T10:21:21.826449Z","shell.execute_reply.started":"2021-07-09T10:21:21.816198Z","shell.execute_reply":"2021-07-09T10:21:21.825197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sacamos los PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n\nX = df2_clean.drop(['actual_productivity'], axis = 1)\npca = PCA()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:33.360265Z","iopub.execute_input":"2021-07-09T10:21:33.360622Z","iopub.status.idle":"2021-07-09T10:21:33.367505Z","shell.execute_reply.started":"2021-07-09T10:21:33.360593Z","shell.execute_reply":"2021-07-09T10:21:33.365899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PCs = preprocessing.StandardScaler().fit_transform(pca.fit_transform(X))\n\n['PC' + str(i) for i in range(1, X.shape[1] + 1)]","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:35.872583Z","iopub.execute_input":"2021-07-09T10:21:35.872929Z","iopub.status.idle":"2021-07-09T10:21:35.935979Z","shell.execute_reply.started":"2021-07-09T10:21:35.8729Z","shell.execute_reply":"2021-07-09T10:21:35.934914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.cumsum(pca.explained_variance_ratio_))\nfig, ax = plt.subplots(figsize = (20, 5))\nax.bar(x = range(1, X.shape[1] + 1), \n        height = np.round(pca.explained_variance_ratio_ * 100, decimals = 1), \n        tick_label = ['PC' + str(i) for i in range(1, X.shape[1] + 1)]);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:42.492579Z","iopub.execute_input":"2021-07-09T10:21:42.492949Z","iopub.status.idle":"2021-07-09T10:21:42.899508Z","shell.execute_reply.started":"2021-07-09T10:21:42.49291Z","shell.execute_reply":"2021-07-09T10:21:42.898346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nuestro PC1 y PC2 son los que representan la mayor parte de todos.","metadata":{}},{"cell_type":"code","source":"X_pca = pd.DataFrame(PCs, \n                     columns = ['PC' + str(i) for i in range(1, X.shape[1] + 1)])\nX_pca.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:48.246838Z","iopub.execute_input":"2021-07-09T10:21:48.247187Z","iopub.status.idle":"2021-07-09T10:21:48.279557Z","shell.execute_reply.started":"2021-07-09T10:21:48.247157Z","shell.execute_reply":"2021-07-09T10:21:48.278035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:21:53.97898Z","iopub.execute_input":"2021-07-09T10:21:53.980211Z","iopub.status.idle":"2021-07-09T10:21:53.988882Z","shell.execute_reply.started":"2021-07-09T10:21:53.980153Z","shell.execute_reply":"2021-07-09T10:21:53.987717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize = (15,7))\n\nim1 = ax[0,0].scatter(X_pca['PC1'], X_pca['PC2'], c = df['no_of_workers']) \nfig.colorbar(im1, ax = ax[0,0])\nim2 = ax[0,1].scatter(X_pca['PC1'], X_pca['PC2'], c = df['actual_productivity'])\nfig.colorbar(im2, ax = ax[0,1])\nim3 = ax[1,0].scatter(X_pca['PC1'], X_pca['PC2'], c = df['over_time'])\nfig.colorbar(im3, ax = ax[1,0])\nim4 = ax[1,1].scatter(X_pca['PC1'], X_pca['PC2'], c = df['smv'])\nfig.colorbar(im4, ax = ax[1,1])\n\nfig.colorbar(im4, ax = ax[1,1])\n \nax[0,0].set_ylabel(\"PC2\") \nax[0,1].set_ylabel(\"PC2\")\nax[1,0].set_xlabel(\"PC1\"), ax[1,0].set_ylabel(\"PC2\")\nax[1,1].set_xlabel(\"PC1\"), ax[1,1].set_ylabel(\"PC2\")\n\nax[0,0].set_title(\"Profiling Number of workers\")\nax[0,1].set_title(\"Profiling Actual Productivity\")\nax[1,0].set_title(\"Profiling Over Time\")\nax[1,1].set_title(\"Profiling index of Standard Minute Value\");","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:22:32.848022Z","iopub.execute_input":"2021-07-09T10:22:32.848581Z","iopub.status.idle":"2021-07-09T10:22:34.114755Z","shell.execute_reply.started":"2021-07-09T10:22:32.848545Z","shell.execute_reply":"2021-07-09T10:22:34.114053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (7,4))\n\nim1 = ax.scatter(X_pca['PC1'], X_pca['PC2'], c = df['targeted_productivity'], marker = 'o') \nfig.colorbar(im1, ax = ax)\n\nax.set_xlabel(\"PC1\"), ax.set_ylabel(\"PC2\")\nax.set_title(\"Profiling target productivity\");","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:22:39.008532Z","iopub.execute_input":"2021-07-09T10:22:39.009037Z","iopub.status.idle":"2021-07-09T10:22:39.538023Z","shell.execute_reply.started":"2021-07-09T10:22:39.00899Z","shell.execute_reply":"2021-07-09T10:22:39.536714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix = X_pca.corr().round(2)\n\nfig, ax = plt.subplots(figsize = (15,10))\nsns.heatmap(data = correlation_matrix, annot = True, ax = ax, cmap = 'coolwarm');","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:22:44.210089Z","iopub.execute_input":"2021-07-09T10:22:44.21063Z","iopub.status.idle":"2021-07-09T10:22:47.371677Z","shell.execute_reply.started":"2021-07-09T10:22:44.210587Z","shell.execute_reply":"2021-07-09T10:22:47.370305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comenzamos con el estudio de nuestros modelos","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nmodelo_lineal = LinearRegression()\nmodelo_lineal.fit(X_train, Y_train);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:22:51.684249Z","iopub.execute_input":"2021-07-09T10:22:51.684752Z","iopub.status.idle":"2021-07-09T10:22:51.703059Z","shell.execute_reply.started":"2021-07-09T10:22:51.684707Z","shell.execute_reply":"2021-07-09T10:22:51.702171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelo_lineal.coef_","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:22:55.808147Z","iopub.execute_input":"2021-07-09T10:22:55.808689Z","iopub.status.idle":"2021-07-09T10:22:55.817091Z","shell.execute_reply.started":"2021-07-09T10:22:55.808642Z","shell.execute_reply":"2021-07-09T10:22:55.815665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluamos el modelo simple\n\nRealizamos los planteamientos para nuestros modelo, para ello describiremos uno a uno los modelos simples y luego implementaremos probar todos para establecer cual es el mejor modelo.","metadata":{}},{"cell_type":"code","source":"prediccion_train_lineal_simple = modelo_lineal.predict(X_train)\nmean_squared_error(Y_train, prediccion_train_lineal_simple) ","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:22:59.754388Z","iopub.execute_input":"2021-07-09T10:22:59.754732Z","iopub.status.idle":"2021-07-09T10:22:59.77479Z","shell.execute_reply.started":"2021-07-09T10:22:59.754702Z","shell.execute_reply":"2021-07-09T10:22:59.772838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediccion_test_lineal_simple = modelo_lineal.predict(X_test)\nmean_squared_error(Y_test, prediccion_test_lineal_simple) ","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:23:19.571772Z","iopub.execute_input":"2021-07-09T10:23:19.572103Z","iopub.status.idle":"2021-07-09T10:23:19.584254Z","shell.execute_reply.started":"2021-07-09T10:23:19.572064Z","shell.execute_reply":"2021-07-09T10:23:19.583086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nresultados = []\nnombres = []\n\nscores = -cross_val_score(modelo_lineal, X_train, Y_train, cv = 5, scoring = 'neg_mean_squared_error')\nprint(scores.mean())\n\nresultados.append(scores)\nnombres.append(\"Lineal simple\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:23:25.960902Z","iopub.execute_input":"2021-07-09T10:23:25.961311Z","iopub.status.idle":"2021-07-09T10:23:26.00004Z","shell.execute_reply.started":"2021-07-09T10:23:25.96128Z","shell.execute_reply":"2021-07-09T10:23:25.999062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import learning_curve\n\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\ntrain_sizes, train_scores, test_scores = learning_curve(\n                                                estimator = LinearRegression(),\n                                                X = X_train,\n                                                y = Y_train, \n                                                train_sizes = np.linspace(0.1, 1.0, 100), \n                                                cv = 3,\n                                                scoring = 'neg_mean_squared_error')\ntrain_scores *= -1 \ntest_scores *= -1\n\ntrain_mean = np.mean(train_scores, axis = 1)\ntrain_std = np.std(train_scores, axis = 1)\n\ntest_mean = np.mean(test_scores, axis = 1)\ntest_std = np.std(test_scores, axis = 1)\n\nax.plot(train_sizes, np.mean(train_scores, 1), color = 'blue', label = 'training score')\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color = \"#DDDDDD\", alpha = 0.2)\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color = \"#DDDD00\", alpha = 0.2)\n\nax.plot(train_sizes, np.mean(test_scores, 1), color = 'red', label = 'validation score')\nax.hlines(np.mean([train_scores[-1], test_scores[-1]]), train_sizes[0], train_sizes[-1],\n                 color = 'gray', linestyle = 'dashed')\n\n#ax.set_ylim(0, 1)\nax.set_xlim(train_sizes[0], train_sizes[-1])\nax.set_xlabel('training size')\nax.set_ylabel('score')\nax.set_title('Learning curves', size = 14)\nax.legend(loc = 'best')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:23:33.70848Z","iopub.execute_input":"2021-07-09T10:23:33.708807Z","iopub.status.idle":"2021-07-09T10:23:36.984877Z","shell.execute_reply.started":"2021-07-09T10:23:33.70878Z","shell.execute_reply":"2021-07-09T10:23:36.98415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nmodelo_ridge = Ridge(alpha = 1.0)\nmodelo_ridge.fit(X_train, Y_train)\n\nprediccion_train = modelo_ridge.predict(X_train)\nprint(mean_squared_error(Y_train, prediccion_train)) \n\nprediccion_test = modelo_ridge.predict(X_test)\nprint(mean_squared_error(Y_test, prediccion_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:23:47.244298Z","iopub.execute_input":"2021-07-09T10:23:47.244649Z","iopub.status.idle":"2021-07-09T10:23:47.276361Z","shell.execute_reply.started":"2021-07-09T10:23:47.244621Z","shell.execute_reply":"2021-07-09T10:23:47.275373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = -cross_val_score(modelo_ridge, X_train, Y_train, cv = 5, scoring = 'neg_mean_squared_error')\nprint(scores.mean())\n\nresultados.append(scores)\nnombres.append(\"Lineal ridge\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:24:09.156573Z","iopub.execute_input":"2021-07-09T10:24:09.156883Z","iopub.status.idle":"2021-07-09T10:24:09.212381Z","shell.execute_reply.started":"2021-07-09T10:24:09.156856Z","shell.execute_reply":"2021-07-09T10:24:09.211388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nscaler = preprocessing.StandardScaler()\nX_train_s = scaler.fit(X_train).transform(X_train)\nX_test_s = scaler.fit(X_test).transform(X_test)\n\nmodelo_ridge = Ridge(alpha = 1.0)\nmodelo_ridge.fit(X_train_s, Y_train)\n\n\nprediccion_train = modelo_ridge.predict(X_train_s)\nprint(mean_squared_error(Y_train, prediccion_train)) # root mean squared error\n\nprediccion_test = modelo_ridge.predict(X_test_s)\nprint(mean_squared_error(Y_test, prediccion_test))\n\nscores = -cross_val_score(modelo_ridge, X_train_s, Y_train, cv = 5, scoring = 'neg_mean_squared_error')\nprint(scores.mean())\n\nresultados.append(scores)\nnombres.append(\"Lineal ridge std.\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:24:37.228739Z","iopub.execute_input":"2021-07-09T10:24:37.229051Z","iopub.status.idle":"2021-07-09T10:24:37.268733Z","shell.execute_reply.started":"2021-07-09T10:24:37.229024Z","shell.execute_reply":"2021-07-09T10:24:37.266316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.logspace(-6, 6, 13)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:24:44.173209Z","iopub.execute_input":"2021-07-09T10:24:44.173544Z","iopub.status.idle":"2021-07-09T10:24:44.179817Z","shell.execute_reply.started":"2021-07-09T10:24:44.173517Z","shell.execute_reply":"2021-07-09T10:24:44.178902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelo_ridge = linear_model.RidgeCV(alphas = np.logspace(-6, 6, 13), cv = 5)\nmodelo_ridge.fit(X_train_s, Y_train)\n\nmodelo_ridge.alpha_\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:24:47.143503Z","iopub.execute_input":"2021-07-09T10:24:47.143871Z","iopub.status.idle":"2021-07-09T10:24:47.37232Z","shell.execute_reply.started":"2021-07-09T10:24:47.143837Z","shell.execute_reply":"2021-07-09T10:24:47.371333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediccion_train = modelo_ridge.predict(X_train_s)\nprint(mean_squared_error(Y_train, prediccion_train))\n\nprediccion_test = modelo_ridge.predict(X_test_s)\nprint(mean_squared_error(Y_test, prediccion_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:24:51.636068Z","iopub.execute_input":"2021-07-09T10:24:51.636359Z","iopub.status.idle":"2021-07-09T10:24:51.646305Z","shell.execute_reply.started":"2021-07-09T10:24:51.636334Z","shell.execute_reply":"2021-07-09T10:24:51.645278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelo_lasso = linear_model.Lasso(alpha = 0.1)\nmodelo_lasso.fit(X_train_s, Y_train)\n\nprediccion_train = modelo_lasso.predict(X_train_s)\nprint(mean_squared_error(Y_train, prediccion_train))\n\nprediccion_test = modelo_lasso.predict(X_test_s)\nprint(mean_squared_error(Y_test, prediccion_test))\n\nscores = -cross_val_score(modelo_lasso, X_train_s, Y_train, cv = 5, scoring = 'neg_mean_squared_error')\nprint(scores.mean())\n\nresultados.append(scores)\nnombres.append(\"Lineal lasso std.\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:24:56.459537Z","iopub.execute_input":"2021-07-09T10:24:56.459846Z","iopub.status.idle":"2021-07-09T10:24:56.49757Z","shell.execute_reply.started":"2021-07-09T10:24:56.459818Z","shell.execute_reply":"2021-07-09T10:24:56.496541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelo_lasso = linear_model.LassoCV(alphas = np.logspace(-6, 6, 13), cv = 5)\nmodelo_lasso.fit(X_train_s, Y_train)\n\nmodelo_lasso.alpha_","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:57:30.951442Z","iopub.execute_input":"2021-07-09T08:57:30.951842Z","iopub.status.idle":"2021-07-09T08:57:31.111013Z","shell.execute_reply.started":"2021-07-09T08:57:30.951809Z","shell.execute_reply":"2021-07-09T08:57:31.109936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediccion_train = modelo_ridge.predict(X_train_s)\nprint(mean_squared_error(Y_train, prediccion_train))\n\nprediccion_test = modelo_ridge.predict(X_test_s)\nprint(mean_squared_error(Y_test, prediccion_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:57:33.834065Z","iopub.execute_input":"2021-07-09T08:57:33.834477Z","iopub.status.idle":"2021-07-09T08:57:33.852651Z","shell.execute_reply.started":"2021-07-09T08:57:33.834438Z","shell.execute_reply":"2021-07-09T08:57:33.851346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\n\npoly = Pipeline([('poly', PolynomialFeatures(degree = 2)),\n                 ('linear', LinearRegression(fit_intercept = True))])\npoly.fit(X_train, Y_train)\n\nprediccion_train = poly.predict(X_train)\nprint(mean_squared_error(Y_train, prediccion_train))\n\nprediccion_test = poly.predict(X_test)\nprint(mean_squared_error(Y_test, prediccion_test))\n\nscores = -cross_val_score(poly, X_train_s, Y_train, cv = 5, scoring = 'neg_mean_squared_error')\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:57:37.835452Z","iopub.execute_input":"2021-07-09T08:57:37.835897Z","iopub.status.idle":"2021-07-09T08:57:38.300981Z","shell.execute_reply.started":"2021-07-09T08:57:37.835863Z","shell.execute_reply":"2021-07-09T08:57:38.299746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Por Lasso","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\nfrom sklearn.pipeline import Pipeline\n\npoly = Pipeline([('poly', PolynomialFeatures(degree = 2)),\n                 ('linear', Lasso(fit_intercept = True ,alpha = 10))])\npoly.fit(X_train, Y_train)\n\nprediccion_train = poly.predict(X_train)\nprint(mean_squared_error(Y_train, prediccion_train))\n\nprediccion_test = poly.predict(X_test)\nprint(mean_squared_error(Y_test, prediccion_test))\n\nscores = -cross_val_score(poly, X_train_s, Y_train, cv = 5, scoring = 'neg_mean_squared_error')\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:57:41.531669Z","iopub.execute_input":"2021-07-09T08:57:41.532384Z","iopub.status.idle":"2021-07-09T08:57:41.742441Z","shell.execute_reply.started":"2021-07-09T08:57:41.532342Z","shell.execute_reply":"2021-07-09T08:57:41.741253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"k-fold CV con varias repeticiones (así la variancia de los resultados es más acurada). Escogemos unos cuantos pipelines y hacemos nk-fold CV para escoger el mejor modelo.","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.model_selection import RepeatedKFold\n\nrkf = RepeatedKFold(n_splits = 5, n_repeats = 20, random_state = 123)\nX = df2_clean.drop(['actual_productivity'], axis = 1)\n\nlist(rkf.split(X))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:57:44.496973Z","iopub.execute_input":"2021-07-09T08:57:44.497381Z","iopub.status.idle":"2021-07-09T08:57:44.947384Z","shell.execute_reply.started":"2021-07-09T08:57:44.497348Z","shell.execute_reply":"2021-07-09T08:57:44.946431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  Buscamos el alpha ideal para cada uno de los modelos","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\n\nerr = []\nerr2 = []\nini = 1\nend = 20\nfor deg in range(ini, end):\n    poly = Pipeline([('poly', PolynomialFeatures()),\n                 ('linear', Lasso(fit_intercept = False, alpha = deg))])\n    poly.fit(X_train, Y_train)\n\n    prediccion_train = poly.predict(X_train)\n    err.append(mean_squared_error(Y_train, prediccion_train))\n    prediccion_test = poly.predict(X_test)\n    err2.append(mean_squared_error(Y_test, prediccion_test))\n\nplt.plot(np.arange(ini, end, 1.0), err, label = 'train')\nplt.plot(np.arange(ini, end, 1.0), err2, label = 'test')\nplt.xticks(np.arange(ini, end, 1.0))\nplt.vlines(np.argmin(err2) + ini, 0, max(err2),  color = 'gray', linestyle = 'dashed')\nplt.yscale('log')\nplt.ylabel('error')\nplt.xlabel('degree');","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:25:24.722535Z","iopub.execute_input":"2021-07-09T10:25:24.723206Z","iopub.status.idle":"2021-07-09T10:25:24.747178Z","shell.execute_reply.started":"2021-07-09T10:25:24.723167Z","shell.execute_reply":"2021-07-09T10:25:24.74569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Este paso anterior se puede realizar para todos los modelos y asi encontrar su alpha ideal","metadata":{"execution":{"iopub.status.busy":"2021-07-09T08:58:30.302744Z","iopub.execute_input":"2021-07-09T08:58:30.303315Z","iopub.status.idle":"2021-07-09T08:58:30.313496Z","shell.execute_reply.started":"2021-07-09T08:58:30.303262Z","shell.execute_reply":"2021-07-09T08:58:30.311575Z"}}},{"cell_type":"markdown","source":"# 7. Model comparison","metadata":{}},{"cell_type":"markdown","source":"Realizaremos el calculo de todos los modelos para compararlos, adicionamos una pequeña red neuronal para incluirla en nuestro estudio.\n\n\nMulti-layer Perceptron regressor=>This model optimizes the squared-loss using LBFGS or stochastic gradient descent.\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.model_selection import RepeatedKFold\n\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\n\n\nresultados=[]\n\npipelines = []\n\nnombres = []\n\n\npipelines.append(('scaled_linear', Pipeline([('scaler', StandardScaler()),\n                                        ('linear', LinearRegression())\n                                       ])))\npipelines.append(('scaled_linear_ridge', Pipeline([('scaler', StandardScaler()),\n                                        ('ridge', Ridge(alpha = 15))\n                                       ])))\npipelines.append(('scaled_linear_Lasso', Pipeline([('scaler', StandardScaler()),\n                                        ('lasso', Lasso(alpha = 1))\n                                       ])))\n\npipelines.append(('scaled_poly_ridge', Pipeline([('scaler', StandardScaler()),\n                                        ('poly', PolynomialFeatures(degree = 2)),\n                                        ('ridge', Ridge(alpha = 15))\n                                       ])))\npipelines.append(('scaled_poly_lasso', Pipeline([('scaler', StandardScaler()),\n                                        ('poly', PolynomialFeatures(degree = 2)),\n                                        ('lasso', Lasso(alpha = 0.05))\n                                       ])))\npipelines.append(('poly_ridge', Pipeline([('poly', PolynomialFeatures(degree = 2)),\n                                        ('ridge', Ridge(alpha = 15))\n                                       ])))\n\npipelines.append(('poly_lasso', Pipeline([('poly', PolynomialFeatures(degree = 2)),\n                                        ('lasso', Lasso(alpha = 0.05))\n                                       ])))\n\npipelines.append(('SVR_Linear', Pipeline([( \"SVR\",SVR(kernel = 'linear', C = 1, max_iter=100))\n                        \n                                       ])))\npipelines.append(('SVR_Poly', Pipeline([( \"SVR\",SVR(kernel = 'poly', C = 1,degree = 2))\n                        \n                                       ])))\n\npipelines.append(('MLPRegresor', Pipeline([( \"MLPRegressor\",MLPRegressor(max_iter=10, hidden_layer_sizes=(25,)))\n                        \n                                       ])))\n\nfor nombre, modelo in pipelines:\n    \n    \n    #prediccion_train = modelo.predict(X_train)\n    #prediccion_test = modelo.predict(X_test)\n    \n    rkf = RepeatedKFold(n_splits = 5, n_repeats = 20, random_state = 123)\n    resultados_nk = []\n    \n    \n    for train_index, test_index in rkf.split(X):\n        X_train_nk, X_test_nk = X.values[train_index], X.values[test_index]\n        Y_train_nk, Y_test_nk = Y.values[train_index], Y.values[test_index]\n        scores = -cross_val_score(modelo, X_train_nk, Y_train_nk, cv = 5, scoring = 'neg_mean_squared_error')\n        resultados_nk.append(scores.mean())\n        \n    resultados.append(resultados_nk)\n    nombres.append(nombre)\n    print(\"%s: %f (%f)\" % (nombre, np.mean(resultados_nk), np.std(resultados_nk)))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:25:37.739904Z","iopub.execute_input":"2021-07-09T10:25:37.740257Z","iopub.status.idle":"2021-07-09T10:28:22.026668Z","shell.execute_reply.started":"2021-07-09T10:25:37.740226Z","shell.execute_reply":"2021-07-09T10:28:22.025617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obtenemos todos los resultados de los modelos planteados y procedemos a plotearlos, se destaca que en el paso anterior conseguimos establecer cual es el mejor y peor modelo para nuestro Dataset.","metadata":{}},{"cell_type":"markdown","source":"## Plot de comparación de algoritmos","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (20,15)) \nax.set_title('Comparación de algoritmos')\nax.boxplot(resultados)\nax.set_xticklabels(nombres)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:29:17.842717Z","iopub.execute_input":"2021-07-09T10:29:17.843057Z","iopub.status.idle":"2021-07-09T10:29:18.173851Z","shell.execute_reply.started":"2021-07-09T10:29:17.843026Z","shell.execute_reply":"2021-07-09T10:29:18.172878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nfig, ax = plt.subplots(1, 1, figsize = (20,15)) \nax.set_title('Comparación de algoritmos')\nsns.boxplot(data = resultados, palette = \"Set2\", ax = ax);\nax.set_xticklabels(nombres);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:29:24.441931Z","iopub.execute_input":"2021-07-09T10:29:24.442258Z","iopub.status.idle":"2021-07-09T10:29:24.818597Z","shell.execute_reply.started":"2021-07-09T10:29:24.442231Z","shell.execute_reply":"2021-07-09T10:29:24.817477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (20,15)) \nax.set_title('Comparación de algoritmos')\nsns.swarmplot(data = resultados, color = \"black\", ax = ax)\nsns.boxplot(data = resultados, palette = \"Set2\", ax = ax)\nax.set_xticklabels(nombres);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:29:30.369659Z","iopub.execute_input":"2021-07-09T10:29:30.36998Z","iopub.status.idle":"2021-07-09T10:29:32.597673Z","shell.execute_reply.started":"2021-07-09T10:29:30.369954Z","shell.execute_reply":"2021-07-09T10:29:32.596145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Recordando los resultados obtenidos previamente:\n\n\n###### scaled_linear: 0.376954 (0.151149)\n\n###### scaled_linear_ridge: 0.288120 (0.071774)\n\n###### scaled_linear_Lasso: 0.031084 (0.000715)\n\nscaled_poly_ridge: 2164.370534 (2193.214479)\n\nscaled_poly_lasso: 88.653517 (44.022341)\n\npoly_ridge: 54.857675 (31.694947)\n\npoly_lasso: 3.983882 (2.867972)\n\nSVR_Linear: 2641.121353 (9649.024103)\n\n###### SVR_Poly: 0.035161 (0.005364)\n\nMLPRegresor: 221262.839704 (300972.414711)-->En este utilizamos 25 neuronas para encontrar el mejor valor para este\n","metadata":{}},{"cell_type":"markdown","source":"Con todo lo anterior establecemos que, los mejores resultados son:\n\n\n1.scaled_linear_Lasso: 0.031084 (0.000715)\n\n2.SVR_Poly: 0.035161 (0.005364)\n\n3.scaled_linear_ridge: 0.288120 (0.071774)\n\n4.scaled_linear: 0.376954 (0.151149)\n\n\n\n","metadata":{}},{"cell_type":"code","source":"resultados=[]\n\npipelines = []\n\nnombres = []\n\n\npipelines.append(('scaled_linear', Pipeline([('scaler', StandardScaler()),\n                                        ('linear', LinearRegression())\n                                       ])))\npipelines.append(('scaled_linear_ridge', Pipeline([('scaler', StandardScaler()),\n                                        ('ridge', Ridge(alpha = 15))\n                                       ])))\npipelines.append(('scaled_linear_Lasso', Pipeline([('scaler', StandardScaler()),\n                                        ('lasso', Lasso(alpha = 1))\n                                       ])))\n\npipelines.append(('SVR_Poly', Pipeline([( \"SVR\",SVR(kernel = 'poly', C = 1,degree = 2))\n                        \n                                       ])))\n\n\n\nfor nombre, modelo in pipelines:\n    \n    \n    #prediccion_train = modelo.predict(X_train)\n    #prediccion_test = modelo.predict(X_test)\n    \n    rkf = RepeatedKFold(n_splits = 5, n_repeats = 20, random_state = 123)\n    resultados_nk = []\n    \n    \n    for train_index, test_index in rkf.split(X):\n        X_train_nk, X_test_nk = X.values[train_index], X.values[test_index]\n        Y_train_nk, Y_test_nk = Y.values[train_index], Y.values[test_index]\n        scores = -cross_val_score(modelo, X_train_nk, Y_train_nk, cv = 5, scoring = 'neg_mean_squared_error')\n        resultados_nk.append(scores.mean())\n        \n    resultados.append(resultados_nk)\n    nombres.append(nombre)\n    print(\"%s: %f (%f)\" % (nombre, np.mean(resultados_nk), np.std(resultados_nk)))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:29:40.931542Z","iopub.execute_input":"2021-07-09T10:29:40.931871Z","iopub.status.idle":"2021-07-09T10:30:22.632579Z","shell.execute_reply.started":"2021-07-09T10:29:40.931843Z","shell.execute_reply":"2021-07-09T10:30:22.631522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (20,15)) \nax.set_title('Comparación de algoritmos')\nax.boxplot(resultados)\nax.set_xticklabels(nombres)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:30:32.525732Z","iopub.execute_input":"2021-07-09T10:30:32.52625Z","iopub.status.idle":"2021-07-09T10:30:32.774125Z","shell.execute_reply.started":"2021-07-09T10:30:32.526206Z","shell.execute_reply":"2021-07-09T10:30:32.772738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nfig, ax = plt.subplots(1, 1, figsize = (15,5)) \nax.set_title('Comparación de algoritmos')\nsns.boxplot(data = resultados, palette = \"Set2\", ax = ax);\nax.set_xticklabels(nombres);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:30:54.937125Z","iopub.execute_input":"2021-07-09T10:30:54.937494Z","iopub.status.idle":"2021-07-09T10:30:55.418535Z","shell.execute_reply.started":"2021-07-09T10:30:54.937462Z","shell.execute_reply":"2021-07-09T10:30:55.417412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (15,5)) \nax.set_title('Comparación de algoritmos')\nsns.swarmplot(data = resultados, color = \"black\", ax = ax)\nsns.boxplot(data = resultados, palette = \"Set2\", ax = ax)\nax.set_xticklabels(nombres);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:31:21.028225Z","iopub.execute_input":"2021-07-09T10:31:21.028574Z","iopub.status.idle":"2021-07-09T10:31:21.747739Z","shell.execute_reply.started":"2021-07-09T10:31:21.028542Z","shell.execute_reply":"2021-07-09T10:31:21.746712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resultados=[]\n\npipelines = []\n\nnombres = []\n\n\n\npipelines.append(('scaled_linear_Lasso', Pipeline([('scaler', StandardScaler()),\n                                        ('lasso', Lasso(alpha = 1))\n                                       ])))\n\npipelines.append(('SVR_Poly', Pipeline([( \"SVR\",SVR(kernel = 'poly', C = 1,degree = 2))\n                        \n                                       ])))\n\nfor nombre, modelo in pipelines:\n    \n    \n    #prediccion_train = modelo.predict(X_train)\n    #prediccion_test = modelo.predict(X_test)\n    \n    rkf = RepeatedKFold(n_splits = 5, n_repeats = 20, random_state = 123)\n    resultados_nk = []\n    \n    \n    for train_index, test_index in rkf.split(X):\n        X_train_nk, X_test_nk = X.values[train_index], X.values[test_index]\n        Y_train_nk, Y_test_nk = Y.values[train_index], Y.values[test_index]\n        scores = -cross_val_score(modelo, X_train_nk, Y_train_nk, cv = 5, scoring = 'neg_mean_squared_error')\n        resultados_nk.append(scores.mean())\n        \n    resultados.append(resultados_nk)\n    nombres.append(nombre)\n    print(\"%s: %f (%f)\" % (nombre, np.mean(resultados_nk), np.std(resultados_nk)))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:31:30.490443Z","iopub.execute_input":"2021-07-09T10:31:30.490833Z","iopub.status.idle":"2021-07-09T10:32:06.154624Z","shell.execute_reply.started":"2021-07-09T10:31:30.490801Z","shell.execute_reply":"2021-07-09T10:32:06.153918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (20,10)) \nax.set_title('Comparación de los mejores algoritmos')\nsns.swarmplot(data = resultados, color = \"black\", ax = ax)\nsns.boxplot(data = resultados, palette = \"Set3\", ax = ax)\nax.set_xticklabels(nombres);","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:32:32.074578Z","iopub.execute_input":"2021-07-09T10:32:32.07516Z","iopub.status.idle":"2021-07-09T10:32:32.359998Z","shell.execute_reply.started":"2021-07-09T10:32:32.075114Z","shell.execute_reply":"2021-07-09T10:32:32.35885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaled linear Lasso: \n0.031084 (0.000715)\n### Support Vector Regression (SVR): \n0.035161 (0.005364)","metadata":{}},{"cell_type":"markdown","source":"Después de intentar con multiples modelos, se establece que el mas idoneo es el Scaled linear Lasso","metadata":{}},{"cell_type":"markdown","source":"# 8. Decision tree regressor","metadata":{}},{"cell_type":"markdown","source":"Se implementa este metodo para encontrar las variables optimas para obtener un error inferior ","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.tree import DecisionTreeRegressor\n\nregressor = DecisionTreeRegressor(random_state = 123, max_depth = 3)\n\nscores = -cross_val_score(regressor, X, Y, cv = 5, scoring = 'neg_mean_squared_error')\n\nprint(scores.mean() * 100)\nprint(scores.std())\n\n\nregressor.fit(X_train, Y_train)\nfig, ax = plt.subplots(1, 1, figsize = (20, 15))\ntree.plot_tree(regressor, \n               impurity = True,\n               class_names = Y.unique(),\n               feature_names = X.columns\n              );\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:32:45.454225Z","iopub.execute_input":"2021-07-09T10:32:45.45458Z","iopub.status.idle":"2021-07-09T10:32:46.482015Z","shell.execute_reply.started":"2021-07-09T10:32:45.45455Z","shell.execute_reply":"2021-07-09T10:32:46.480303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Randon forest regressor","metadata":{}},{"cell_type":"markdown","source":"Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression. Ensemble learning method is a technique that combines predictions from multiple machine learning algorithms to make a more accurate prediction than a single model.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nbosque = RandomForestRegressor(n_estimators = 100,\n                                criterion = 'mse',\n                                max_depth = None,\n                                max_features = 'sqrt',\n                                oob_score = True,\n                                random_state = 123)\n\nbosque.fit(X_train, Y_train)\nprint(bosque.feature_importances_)\nprint('OOB error: {}'.format(1 - bosque.oob_score_))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T10:33:07.769619Z","iopub.execute_input":"2021-07-09T10:33:07.770122Z","iopub.status.idle":"2021-07-09T10:33:08.046214Z","shell.execute_reply.started":"2021-07-09T10:33:07.770057Z","shell.execute_reply":"2021-07-09T10:33:08.045567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nuevo modelo a entrenar","metadata":{}},{"cell_type":"markdown","source":"# 10. Conclusion and results","metadata":{}},{"cell_type":"markdown","source":"#### General","metadata":{}},{"cell_type":"markdown","source":"Notamos una correlación del 94% en las variables 'department_sweing' y 'no_of_workers', asi mismo otra correlación que podemos destacar es la que existe entre 'no_of_workers' y 'smv' con un 91%.\n\nOtras encontradas:\n\n-'department_sweing' AND 'smv' -->87%\n\n-'no_of_workers' AND 'over_time' -->73%\n\n-'department_sweing' AND 'over_time' -->68%\n\n## Modelos implementados en nuestro dataset y sus resultados\n\n\n\nscaled_linear: 0.376954 (0.151149)\n\nscaled_linear_ridge: 0.288120 (0.071774)\n\nscaled_linear_Lasso: 0.031084 (0.000715)\n\nscaled_poly_ridge: 2164.370534 (2193.214479)\n\nscaled_poly_lasso: 88.653517 (44.022341)\n\npoly_ridge: 54.857675 (31.694947)\n\npoly_lasso: 3.983882 (2.867972)\n\nSVR_Linear: 2641.121353 (9649.024103)\n\nSVR_Poly: 0.035161 (0.005364)\n\nMLPRegresor: 221262.839704 (300972.414711)-->En este utilizamos 25 neuronas para encontrar el mejor valor para este\n\n\n## Los mejores resultados de nuestros modelos son:\n\n### Scaled linear Lasso: \n0.031084 (0.000715)\n### Support Vector Regression (SVR): \n0.035161 (0.005364)\n\n\n### Decision Tree Regressor\n\n\n","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (20, 15))\ntree.plot_tree(regressor, \n               impurity = True,\n               class_names = Y.unique(),\n               feature_names = X.columns\n              );","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-09T10:33:13.53442Z","iopub.execute_input":"2021-07-09T10:33:13.534898Z","iopub.status.idle":"2021-07-09T10:33:14.600509Z","shell.execute_reply.started":"2021-07-09T10:33:13.534866Z","shell.execute_reply":"2021-07-09T10:33:14.59929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Randon forest regressor\n\n\n\n0.003976886617684627\n\n\nOOB error: 0.4639779970632426","metadata":{}},{"cell_type":"markdown","source":"# Edison Jair Bejarano Sepulveda","metadata":{}}]}