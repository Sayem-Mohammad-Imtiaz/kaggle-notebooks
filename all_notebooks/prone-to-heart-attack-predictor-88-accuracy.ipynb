{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # Seaborn visualization library\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import RobustScaler\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hi there, to get started lets import and visualize the data","metadata":{}},{"cell_type":"markdown","source":"**Import the data**","metadata":{}},{"cell_type":"code","source":"heart_df = pd.read_csv(\"/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets see how much data we workin with**","metadata":{}},{"cell_type":"code","source":"heart_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Small dataset but nothing to worry about**","metadata":{}},{"cell_type":"markdown","source":"**Lets look at the features**","metadata":{}},{"cell_type":"code","source":"heart_df.sample(6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Any values missing?**","metadata":{}},{"cell_type":"code","source":"heart_df.isnull().sum().sort_values(ascending=False)[:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart_df.isna().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hm complete dataset, right on**","metadata":{}},{"cell_type":"code","source":"heart_df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Couple features that I want to label as categories since some are disretized (sex, cp, fbs, restecg, exng, slp, caa, thall)**","metadata":{}},{"cell_type":"code","source":"heart_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation time**","metadata":{}},{"cell_type":"code","source":"# Compute the correlation matrix\ncorr = heart_df.corr(method ='pearson')\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart_df.corr(method ='pearson')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Some features are displaying some correlation - gives us hope we may have good data to train the model on**","metadata":{}},{"cell_type":"markdown","source":"**Specifically features cp, thalachh, excng, old peak and caa may have signifigance. Plotting the categories will diplay if the counts are balanced**","metadata":{}},{"cell_type":"code","source":"# Plot counts vs. cat features\nsig_cat_feats = [\"cp\", \"exng\", \"caa\"]\nfor i in sig_cat_feats:\n    sns.set_theme(style=\"darkgrid\")\n    ax = sns.countplot(data=heart_df, x=i)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets check out how balanced the labels are (labels = prone to a heart attack or not)**","metadata":{}},{"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\nax = sns.countplot(data=heart_df, x=\"output\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pretty balanced, way better than the stroke dataset I worked on previously**","metadata":{}},{"cell_type":"markdown","source":"# Okay enough data drooling, lets split the data and preprocess","metadata":{}},{"cell_type":"markdown","source":"**Lets split up the data:\ntrain = 75%  |  test = 25%**","metadata":{}},{"cell_type":"code","source":"# Breakdown the data frame into attributes and label\nX = heart_df.drop('output', axis=1)\ny = heart_df['output']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Set up pipelines:\nScale the integer features,\nCategorize the discrete features with OneHot** ","metadata":{}},{"cell_type":"code","source":"numeric_transformer = Pipeline(steps=[\n    ('scaler', RobustScaler())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"heart_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Breakdown heart dataframe into categories and numeric sections - this will prep the data for the pipeline**","metadata":{}},{"cell_type":"code","source":"numerical_feats = [\"age\", \"trtbps\", \"chol\", \"thalachh\", \"oldpeak\"]\ncategorical_feats = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exng\", \"slp\", \"caa\", \"thall\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Combine the category and numerical transformers as a preprocessor**","metadata":{}},{"cell_type":"code","source":"# Data cleaning and transforming\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numerical_feats),\n        ('cat', categorical_transformer, categorical_feats)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model and Run","metadata":{}},{"cell_type":"markdown","source":"**List the classifiers as a list (will be easy to go back and add classifiers)**","metadata":{}},{"cell_type":"code","source":"# Run multiple models and compare\nclassifiers = [\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    KNeighborsClassifier(),\n    LogisticRegression(),\n    ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loop through the classifiers and run Pipeline and fit functions on the trainig set then predict test set based on the model**","metadata":{}},{"cell_type":"code","source":"print(\"** Following results reflect classifier models **\")\nclassif_list = []\nacc_list = []\nfor classifier in classifiers:\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', classifier)])\n    pipe.fit(X_train, y_train)   \n    \n    # Predict the test labels\n    preds = pipe.predict(X_test)\n    \n    # Calculate the accuracy and cofussion matrix\n    acc_score = accuracy_score(y_test, preds)\n    conf_matrix = confusion_matrix(y_test, preds)\n    \n    # Calculate how many preidctions were right and wrong\n    n_labels_right = accuracy_score(y_test, preds, normalize=False)\n    n_labels_total = y_test.size\n      \n    # Print details of classifiers, accuracy and cofussion matrix\n    print(\"-------------------------------------------\")\n    print(classifier)\n    print(\"Accuracy: \", acc_score*100)\n    print(\"Predictions correct = \", n_labels_right)\n    print(\"Predictions wrong   = \", n_labels_total - n_labels_right)\n    print(\"Confussion matrix = \\n\", conf_matrix)\n    \n    # Put classifier and accuracy in list to extract the best at the end\n    classif_list.append(classifier)\n    acc_list.append(acc_score*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**See which model predicted the best**","metadata":{}},{"cell_type":"code","source":"# Output the best model by accuracy\nprint(\"-------------------------------------------\")\nprint(\"** The Best Model Goes to ... **\")\nbest_acc = max(acc_list)\nindex = acc_list.index(max(acc_list))\nbest_classif = classif_list[index]\nprint(\"The best accuracy model = \", best_classif)\nprint(\"With an accuracy = \", best_acc)\nprint(\"Complete.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}