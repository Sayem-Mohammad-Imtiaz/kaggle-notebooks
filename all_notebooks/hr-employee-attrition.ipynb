{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.14.0/css/all.css\">\n\n<div style=\"background-color:#4bcfad; color:ghostwhite; text-align:center\">\n    <div style=\"margin: 0px !important; color:ghostwhite; padding:15px; background-color:#37bc98\"> \n        <i style=\"font-size:10em; padding:30px\" class=\"fas fa-user-slash\"></i>\n        <h1 style=\"font-weight:700; padding:0px; margin:0px;color:ghostwhite\"> Employee Attrition </h1> \n    </div>    \n    <div style=\"text-align:center; color:ghostwhite; padding: 50px;\">\n        <i>  \n         The objective is to identify and improve factors to prevent loss of good people.  \n        <br>\n        <a style=\"color:ghostwhite\" href=\"https://www.kaggle.com/colearninglounge/employee-attrition\"><u>TAST LINK</u></a>\n        </i>\n    </div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"**Attrition**\n> *A company’s success is rooted in its employees’ talents as well as on its capacity to optimize a group’s strengths to push it to continuously surpass itself. Therefore one of the key tasks is to determine which factors keep employees at a company and which prompt others to leave. The objective is to identify which factors we can change to prevent the loss of good people.*","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nTable of Contents\n<a class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/hr-employee-attrition/notebook#heading\">¶</a>\n</h2>\n\n[0. Import & Setup](#import_libraries)  \n  * Libraries  \n  * Print Styles\n  * Table Style\n  * Global Variables\n  \n[1. Load Data](#import_data)  \n\n[2. Exploratory Data Analysis](#rename_features)  \n  * Determine Data Structures\n    * Understand the Dataframe \n    * Understanding the Features \n      * Dataframe Information\n      * Dataframe Head/Tail\n  * Distinguish Attributes \n    * Split Features (Categorical vs Numerical) \n    * Split Categorical Features (Ordinal vs Nominal) \n    * Split Numerical Features (Discrete vs Continuous) \n\n\n[3. Feature Descriptions](#feature_descriptions)  \n[4. Pre-split Inspect Data](#pre-split_inspect_data)  ","metadata":{}},{"cell_type":"markdown","source":"<div>\n<h1 id=\"heading\" style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">\n0. Import Libraries\n<a id=\"import_libraries\" class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/avocado-price-prediction-linear-regression/notebook#heading\">¶</a>\n</h1>\n<h1 style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">0. Import Libraries</h1>\n<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nImport & Setup\n</h2>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Libraries\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-07-02T08:48:26.162273Z","iopub.execute_input":"2021-07-02T08:48:26.162602Z","iopub.status.idle":"2021-07-02T08:48:26.169146Z","shell.execute_reply.started":"2021-07-02T08:48:26.162575Z","shell.execute_reply":"2021-07-02T08:48:26.167672Z"}}},{"cell_type":"code","source":"#-------------------------------------\n# General\n#-------------------------------------\n\nimport math\nfrom statistics import mode\n\n#-------------------------------------\n# Data Analysis\n#-------------------------------------\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport pandas_profiling\n\n#-------------------------------------\n# Visualisation\n#-------------------------------------\n\n# matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport warnings\nimport matplotlib.cbook\nwarnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\nimport matplotlib.dates as mdates\n\n# seaborn\nimport seaborn as sns\nsns.set_theme(style='dark')\n\n# html\nfrom IPython.core.display import display, HTML\n\n#-------------------------------------\n# Feature Extraction\n#-------------------------------------\n\n# Numeric\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\n\n# Categorical\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Transformer\nfrom sklearn.compose import ColumnTransformer\n\n# Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_transformer","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:32:31.43378Z","iopub.execute_input":"2021-07-08T20:32:31.434157Z","iopub.status.idle":"2021-07-08T20:32:31.444129Z","shell.execute_reply.started":"2021-07-08T20:32:31.434125Z","shell.execute_reply":"2021-07-08T20:32:31.443216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Functions\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-07-02T12:42:40.348101Z","iopub.execute_input":"2021-07-02T12:42:40.348709Z","iopub.status.idle":"2021-07-02T12:42:40.353997Z","shell.execute_reply.started":"2021-07-02T12:42:40.348675Z","shell.execute_reply":"2021-07-02T12:42:40.352969Z"}}},{"cell_type":"code","source":"def heading_3(title, description):\n    display(HTML('<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> ' + title + '</h3><div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>' + description + '<br><br><br>'))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:32:31.445474Z","iopub.execute_input":"2021-07-08T20:32:31.445921Z","iopub.status.idle":"2021-07-08T20:32:31.459991Z","shell.execute_reply.started":"2021-07-08T20:32:31.445869Z","shell.execute_reply":"2021-07-08T20:32:31.459126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plt_font():\n    small_size = 10\n    title_size = 16\n    plt.rc('font', size=small_size)          # controls default text sizes\n    plt.rc('axes', titlesize=small_size)     # fontsize of the axes title\n    plt.rc('axes', labelsize=small_size)    # fontsize of the x and y labels\n    plt.rc('xtick', labelsize=small_size)    # fontsize of the tick labels\n    plt.rc('ytick', labelsize=small_size)    # fontsize of the tick labels\n    plt.rc('legend', fontsize=small_size)    # legend fontsize\n    plt.rc('figure', titlesize=small_size)  # fontsize of the figure title   \n    plt.rc('xtick.major', size=small_size)  # fontsize of the figure title   \n    plt.rc('ytick.major', size=small_size)  # fontsize of the figure title   \n    plt.rc('xtick.minor', size=small_size)  # fontsize of the figure title   \n    plt.rc('ytick.minor', size=small_size)  # fontsize of the figure title   \n    plt.xticks(fontsize=small_size)\n    plt.yticks(fontsize=small_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:32:31.462134Z","iopub.execute_input":"2021-07-08T20:32:31.462833Z","iopub.status.idle":"2021-07-08T20:32:31.477762Z","shell.execute_reply.started":"2021-07-08T20:32:31.462783Z","shell.execute_reply":"2021-07-08T20:32:31.476894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Print Styles\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{}},{"cell_type":"code","source":"purple = '\\033[95m'\ncyan = '\\033[96m'\ndarkcyan = '\\033[36m'\nblue = '\\033[94m'\ngreen = '\\033[92m'\nyellow = '\\033[93m'\nred = '\\033[91m'\nbold = '\\033[1m'\nunderline = '\\033[4m'\nend = '\\033[0m'","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-08T20:32:31.479459Z","iopub.execute_input":"2021-07-08T20:32:31.48021Z","iopub.status.idle":"2021-07-08T20:32:31.490104Z","shell.execute_reply.started":"2021-07-08T20:32:31.480158Z","shell.execute_reply":"2021-07-08T20:32:31.489055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Table Style\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{}},{"cell_type":"code","source":"%%html\n<style type=\"text/css\" >\n    table\n    {\n        display: inline-block;\n        text-align: left !important;\n    }\n\n    th\n    {\n        background-color: rgb(75, 207, 173) !important;\n        color: white;\n    }\n    \n    th:first-of-type\n    {\n        background-color: rgb(245, 245, 245) !important;\n        color: grey;\n        font-weight: normal;\n    }\n    \n    th:empty\n    {\n        background-color: rgb(75, 207, 173) !important;        \n    }\n        \n    tr:nth-child(even)\n    {\n        background-color: rgb(245, 245, 245) !important;\n    }\n    \n    td, th, tr\n    {\n        text-align: left !important;\n        \n    }\n</style>","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-08T20:32:31.491651Z","iopub.execute_input":"2021-07-08T20:32:31.492389Z","iopub.status.idle":"2021-07-08T20:32:31.504237Z","shell.execute_reply.started":"2021-07-08T20:32:31.492337Z","shell.execute_reply":"2021-07-08T20:32:31.503224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Global Variables\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"target_feature = \"Attrition\"\n\n# feature extraction\npairwise_correlation_features = []\nlow_variation_features = []\nsingle_value_features = []\ndrop_features = []\ndrop_rows_missing = []\nimpute_missing = []\nduplicate_rows = []\nhigh_outliers = []\ncorrelation_ranking = []\n\n# categorical\ncategorical_features = []\nnominal_features = []\nordinal_features = []\n\n# numerical\nnumerical_features = []\ncontinuous_features = []\ndiscrete_features = []","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:32:31.505806Z","iopub.execute_input":"2021-07-08T20:32:31.506513Z","iopub.status.idle":"2021-07-08T20:32:31.520429Z","shell.execute_reply.started":"2021-07-08T20:32:31.506463Z","shell.execute_reply":"2021-07-08T20:32:31.519457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div>\n<h1 id=\"heading\" style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">\n0. Load Data\n<a id=\"import_libraries\" class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/avocado-price-prediction-linear-regression/notebook#heading\">¶</a>\n</h1>\n<h1 style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">0. Import Libraries</h1>\n<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nLoad Data\n</h2>\n</div>","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:46:45.588833Z","iopub.execute_input":"2021-06-18T09:46:45.589308Z","iopub.status.idle":"2021-06-18T09:46:45.597291Z","shell.execute_reply.started":"2021-06-18T09:46:45.58926Z","shell.execute_reply":"2021-06-18T09:46:45.595965Z"}}},{"cell_type":"code","source":"# load data\n_train = pd.read_csv(\"../input/employee-attrition/employee_attrition_train.csv\")\n_test = pd.read_csv(\"../input/employee-attrition/employee_attrition_test.csv\")\n_train.name = \"hr_train\"\n_test.name = \"hr_test\"\n\n# create a seperate train variable to use for EDA\ntrain = _train.copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:32:31.521867Z","iopub.execute_input":"2021-07-08T20:32:31.522229Z","iopub.status.idle":"2021-07-08T20:32:31.562293Z","shell.execute_reply.started":"2021-07-08T20:32:31.522185Z","shell.execute_reply":"2021-07-08T20:32:31.561359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div>\n<h1 id=\"heading\" style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">\n0. Load Data\n<a id=\"import_libraries\" class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/avocado-price-prediction-linear-regression/notebook#heading\">¶</a>\n</h1>\n<h1 style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">0. Import Libraries</h1>\n<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nExploratory Data Analysis\n</h2>\n</div>","metadata":{"execution":{"iopub.status.busy":"2021-06-21T20:20:13.560564Z","iopub.execute_input":"2021-06-21T20:20:13.560905Z","iopub.status.idle":"2021-06-21T20:20:13.568597Z","shell.execute_reply.started":"2021-06-21T20:20:13.560875Z","shell.execute_reply":"2021-06-21T20:20:13.56703Z"}}},{"cell_type":"markdown","source":"<h2 style=\"line-height:40px; border-radius: 5px; margin-right:10px; padding: 0px 10px; background-color:#68CAEC; font-weight:400; color:ghostwhite; min-height:40px; display: inline-block;text-align: center\"> \n    Determine Data Structures\n</h2>","metadata":{"execution":{"iopub.status.busy":"2021-07-01T09:17:57.387037Z","iopub.execute_input":"2021-07-01T09:17:57.387561Z","iopub.status.idle":"2021-07-01T09:17:57.391965Z","shell.execute_reply.started":"2021-07-01T09:17:57.387529Z","shell.execute_reply":"2021-07-01T09:17:57.390975Z"}}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\n\nThe following is required for a basic understanding of the data:\n* High level understanding of the dataframe\n* High level understanding of the columns/features\n* Split features into categorical and numerical\n* Split categorical features into ordinal and nominal","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:36:12.280693Z","iopub.execute_input":"2021-06-24T21:36:12.281067Z","iopub.status.idle":"2021-06-24T21:36:12.286871Z","shell.execute_reply.started":"2021-06-24T21:36:12.281034Z","shell.execute_reply":"2021-06-24T21:36:12.285566Z"}}},{"cell_type":"code","source":"# !pip install pandas-profiling==3.0.0","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:32:31.687426Z","iopub.execute_input":"2021-07-08T20:32:31.688175Z","iopub.status.idle":"2021-07-08T20:32:31.692131Z","shell.execute_reply.started":"2021-07-08T20:32:31.688127Z","shell.execute_reply":"2021-07-08T20:32:31.691092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pandas_profiling.ProfileReport(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:32:31.693797Z","iopub.execute_input":"2021-07-08T20:32:31.694129Z","iopub.status.idle":"2021-07-08T20:33:49.703133Z","shell.execute_reply.started":"2021-07-08T20:32:31.694097Z","shell.execute_reply":"2021-07-08T20:33:49.701857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Understand the Dataframe\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-06-21T20:50:30.356828Z","iopub.execute_input":"2021-06-21T20:50:30.357194Z","iopub.status.idle":"2021-06-21T20:50:30.363222Z","shell.execute_reply.started":"2021-06-21T20:50:30.357161Z","shell.execute_reply":"2021-06-21T20:50:30.361855Z"}}},{"cell_type":"code","source":"def get_table_info(df):\n    \n    \"\"\"\n    High level information that can be picked up without looking at what is in the columns, rows or cells yet\n    \"\"\"\n    \n    df_shape = df.shape\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    \n    data = {\n    'Columns (Shape)':df_shape[1], \n    'Rows (Shape)':df_shape[0], \n    'Duplicate Rows':df.duplicated().sum(),\n    'Columns with NaN':df.isnull().any(axis=0).sum(),\n    'Rows with NaN':df.isnull().any(axis=1).sum(),\n    'Cells with NaN': df.isnull().sum().sum(),\n    }\n    \n    # add value counts to the end of the series\n    data.update(df.dtypes.value_counts())\n    \n    # convert series to dataframe in order to view as a table\n    df_ret = pd.DataFrame(data, index=[\"Amount\"]).transpose().reset_index()\n    \n    display(df_ret)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-08T20:33:49.705384Z","iopub.execute_input":"2021-07-08T20:33:49.705714Z","iopub.status.idle":"2021-07-08T20:33:49.714907Z","shell.execute_reply.started":"2021-07-08T20:33:49.705683Z","shell.execute_reply":"2021-07-08T20:33:49.713829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get high level information of the data\nget_table_info(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:49.717381Z","iopub.execute_input":"2021-07-08T20:33:49.718371Z","iopub.status.idle":"2021-07-08T20:33:49.765203Z","shell.execute_reply.started":"2021-07-08T20:33:49.718312Z","shell.execute_reply":"2021-07-08T20:33:49.764384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#FFFCDF; padding:15px 15px 7px; color:#332906; font-style:italic; border-radius: 5px\">\n\n* Based on the fact that 'Rows with NaN' and 'Cells with NaN' have very similar amounts we can assume the NaN's are spread out and not generally shared in rows.","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Understanding the Features\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-06-21T20:51:15.705738Z","iopub.execute_input":"2021-06-21T20:51:15.706083Z","iopub.status.idle":"2021-06-21T20:51:15.711406Z","shell.execute_reply.started":"2021-06-21T20:51:15.706053Z","shell.execute_reply":"2021-06-21T20:51:15.710387Z"}}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\n\nTips\n* 1 Unique Value  \nColumns with only 1 unique value add no value and must be dropped\n\n* Unique Amount & Data Type  \nThese columns assist in understanding what type of data we are looking at\n    \n* Amount Missing  \nMissing Values below 10% can be dropped. But if they are important columns, they must be imputed. Also, we have to make sure that overall, there should not be major loss of information due to dropping of missing values","metadata":{}},{"cell_type":"code","source":"def get_column_info(df):\n    \n    # ------------------------------------------------------\n    # gives the following information:\n    #\n    # - column names\n    # \n    # ------------------------------------------------------\n    \n    global single_value_features\n    \n    col_single_unique = []\n    col_unique_sum = []\n    percentage_missing = []\n    amount_missing = []\n    data_type = []\n    skewness = []\n    \n    # get data types\n    for i in df.dtypes:\n        data_type.append(i)\n    \n    for i in df.columns:\n        \n        # get skewness\n        try:\n            skewness.append(train[i].skew())\n        except:\n            skewness.append(0)\n        \n        # get percentage missing\n        perc_mis = round(df[i].isna().sum() * 100 / len(df[i]), 2)\n        if perc_mis == 0:\n            perc_mis = \"\"\n        percentage_missing.append(perc_mis)\n        \n        # get amount missing\n        amount_mis = df[i].isna().sum()\n        if amount_mis == 0:\n            amount_mis = \"\"\n        amount_missing.append(amount_mis)\n        \n        col_unique_sum.append(df[i].nunique())\n        if df[i].nunique() <= 1:\n            col_single_unique.append(True)\n            single_value_features.extend([i])\n        else:\n            col_single_unique.append(\"\")\n            \n    data = {\n    'Column Name':df.columns, \n    '1 Unique Value (Drop Col)':col_single_unique, \n    'Unique Amount of ' + str(df.shape[0]):col_unique_sum, \n    '% Missing':percentage_missing,\n    'Amount Missing of ' + str(df.shape[0]): amount_missing,\n    '% Data Type':data_type,\n    'Skew':skewness\n    }\n    \n    df_table = pd.DataFrame(data)\n    df_describe = pd.DataFrame(df.describe(include = 'all').transpose()).reset_index().drop(['index'], axis = 1)\n    \n    df_table = pd.concat([df_table, df_describe], axis=1)\n    \n    display(HTML('<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> ' + 'Dataframe Information' + '</h3><div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>' + 'Couple of common functions shown in one view.' + '<br><br>'))\n    display(df_table)\n    display(HTML('<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> ' + 'Dataframe Head/Tail' + '</h3><div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>' + '' + '<br>'))\n    display(df)\n    \n    # histogram to view the distribution of the data\n    _hist = df.hist(bins=10, figsize=(20,20))\n    plt_font()\n    heading_3(\"Histogram (all features)\", '')\n    plt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-08T20:33:49.766448Z","iopub.execute_input":"2021-07-08T20:33:49.766934Z","iopub.status.idle":"2021-07-08T20:33:49.780955Z","shell.execute_reply.started":"2021-07-08T20:33:49.766902Z","shell.execute_reply":"2021-07-08T20:33:49.780101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get information about the data's columns\nget_column_info(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:49.782544Z","iopub.execute_input":"2021-07-08T20:33:49.78302Z","iopub.status.idle":"2021-07-08T20:33:54.566606Z","shell.execute_reply.started":"2021-07-08T20:33:49.782974Z","shell.execute_reply":"2021-07-08T20:33:54.565227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#FFFCDF; padding:15px 15px 7px; color:#332906; font-style:italic; border-radius: 5px\">\n\n**Observation:**\n* Attrition (the target) constist of only 2 values (Yes, No)\n* 2 columns with semi-high amount of missing values (StandardHours, Age)...first need some investigation to see what to do with them\n* 5 columns with some missing values...not a lot considering there are 35 columns\n* Age is between 18 - 60 (working - retiring age?)  \n* 3 columns containing only one variable, so they are of no use and must be dropped. \n    * EmployeeCount\n    * Over18\n    * StandardHours\n* EmployeeNumber serves an ID, which brings no value...drop.","metadata":{}},{"cell_type":"code","source":"# adding actions to global variables\n\ndrop_rows_missing.extend(['Age'])\nimpute_missing.extend(['BusinessTravel', 'MaritalStatus', 'DailyRate', 'DistanceFromHome'])\ndrop_features.extend(['EmployeeNumber'])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.568422Z","iopub.execute_input":"2021-07-08T20:33:54.568754Z","iopub.status.idle":"2021-07-08T20:33:54.57362Z","shell.execute_reply.started":"2021-07-08T20:33:54.568723Z","shell.execute_reply":"2021-07-08T20:33:54.57249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"line-height:40px; border-radius: 5px; margin-right:10px; padding: 0px 10px; background-color:#68CAEC; font-weight:400; color:ghostwhite; min-height:40px; display: inline-block;text-align: center\"> \n    Distinguish Data Types\n</h2>","metadata":{"execution":{"iopub.status.busy":"2021-07-01T10:09:18.583181Z","iopub.execute_input":"2021-07-01T10:09:18.583581Z","iopub.status.idle":"2021-07-01T10:09:18.589974Z","shell.execute_reply.started":"2021-07-01T10:09:18.583544Z","shell.execute_reply":"2021-07-01T10:09:18.589043Z"}}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\nBefore working with the data it's important to split the distinguish the data by types. This is required later when filtering by type.","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:06:02.340557Z","iopub.execute_input":"2021-07-02T10:06:02.341062Z","iopub.status.idle":"2021-07-02T10:06:02.346214Z","shell.execute_reply.started":"2021-07-02T10:06:02.341017Z","shell.execute_reply":"2021-07-02T10:06:02.344903Z"}}},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Split Features (Categorical vs Numerical)\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\nFrom what we've explored so far, we can determine which of the features are categorical vs numerical.","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:18:34.842762Z","iopub.execute_input":"2021-06-24T21:18:34.843241Z","iopub.status.idle":"2021-06-24T21:18:34.847958Z","shell.execute_reply.started":"2021-06-24T21:18:34.84321Z","shell.execute_reply":"2021-06-24T21:18:34.846655Z"}}},{"cell_type":"code","source":"categorical_features = ['Attrition', 'BusinessTravel', 'Department', 'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance']\nnumerical_features = list(set(train.columns.tolist()) - set(categorical_features) -set(single_value_features))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.575327Z","iopub.execute_input":"2021-07-08T20:33:54.575653Z","iopub.status.idle":"2021-07-08T20:33:54.590754Z","shell.execute_reply.started":"2021-07-08T20:33:54.57562Z","shell.execute_reply":"2021-07-08T20:33:54.589533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Split Categorical Features (Ordinal vs Nominal)\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:48:13.848026Z","iopub.execute_input":"2021-06-24T21:48:13.84839Z","iopub.status.idle":"2021-06-24T21:48:13.85408Z","shell.execute_reply.started":"2021-06-24T21:48:13.848358Z","shell.execute_reply":"2021-06-24T21:48:13.852917Z"}}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\nNow that we've seperated the features, we can seperate the categorical features further into nominal vs ordinal. Let's first see what each categorical feature consists of (unique values).","metadata":{}},{"cell_type":"code","source":"# prints the unique values of each feature marked as categorical\ndef unique_cat_features(df, _categorical_features):\n    \n    print(bold + \"The following are the unique values of each categorical feature:\" + end + \"\\n\")\n    \n    for i in _categorical_features:\n        print(bold + underline + i + end)\n        print(list(df[i].unique()))\n        print('---------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.593792Z","iopub.execute_input":"2021-07-08T20:33:54.594164Z","iopub.status.idle":"2021-07-08T20:33:54.612146Z","shell.execute_reply.started":"2021-07-08T20:33:54.59413Z","shell.execute_reply":"2021-07-08T20:33:54.610771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_cat_features(train, categorical_features)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.614315Z","iopub.execute_input":"2021-07-08T20:33:54.614681Z","iopub.status.idle":"2021-07-08T20:33:54.637125Z","shell.execute_reply.started":"2021-07-08T20:33:54.614648Z","shell.execute_reply":"2021-07-08T20:33:54.635815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define nominal vs ordinal\n# define the nominal and then subtract the nominal from the categorical to get the left over ordinal\nnominal_features = ['Attrition', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']\nordinal_features = list(set(categorical_features) - (set(nominal_features)))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.638554Z","iopub.execute_input":"2021-07-08T20:33:54.638854Z","iopub.status.idle":"2021-07-08T20:33:54.644051Z","shell.execute_reply.started":"2021-07-08T20:33:54.638824Z","shell.execute_reply":"2021-07-08T20:33:54.642698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Split Numerical Features (Discrete vs Continuous)\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:03:49.834007Z","iopub.execute_input":"2021-07-01T11:03:49.834351Z","iopub.status.idle":"2021-07-01T11:03:49.84056Z","shell.execute_reply.started":"2021-07-01T11:03:49.834323Z","shell.execute_reply":"2021-07-01T11:03:49.839079Z"}}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\nNow that we've seperated the features into categorical and numerical, we can seperate the numerical features further into discrete vs continuous.","metadata":{}},{"cell_type":"code","source":"def view_numerical_features(df, _numerical_features):\n    display(df[_numerical_features])\n    display(df[_numerical_features].dtypes)\n    \n    print(\"============================\")\n    print(\"The following columns should actually be int types\")\n    \n    _float = ['float16', 'float32', 'float64']\n    \n    for i in df[_numerical_features]:\n        \n        if df[i].dtypes in _float:\n            \n            col_check = df[i].dropna()\n            if np.array_equal(col_check, col_check.astype(int)) == True:\n                print(' - ' + i)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.645405Z","iopub.execute_input":"2021-07-08T20:33:54.645729Z","iopub.status.idle":"2021-07-08T20:33:54.659392Z","shell.execute_reply.started":"2021-07-08T20:33:54.645698Z","shell.execute_reply":"2021-07-08T20:33:54.658114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"view_numerical_features(train, numerical_features)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.66078Z","iopub.execute_input":"2021-07-08T20:33:54.661251Z","iopub.status.idle":"2021-07-08T20:33:54.707917Z","shell.execute_reply.started":"2021-07-08T20:33:54.661081Z","shell.execute_reply":"2021-07-08T20:33:54.70679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#FFFCDF; padding:15px 15px 7px; color:#332906; font-style:italic; border-radius: 5px\">\n\n* Even though the dtypes are float64 for 3 of the features, they are actually integers\n* All values appear to be rounded so there are no continuous features.","metadata":{}},{"cell_type":"code","source":"discrete_features = ['YearsInCurrentRole', 'TotalWorkingYears', 'MonthlyRate', 'DistanceFromHome', 'YearsWithCurrManager', 'HourlyRate', 'TrainingTimesLastYear', 'DailyRate', 'PercentSalaryHike', 'EmployeeNumber', 'NumCompaniesWorked', 'YearsAtCompany', 'YearsSinceLastPromotion', 'Age', 'MonthlyIncome']\ncontinuous_features = list(set(numerical_features) - set(discrete_features))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.709372Z","iopub.execute_input":"2021-07-08T20:33:54.709653Z","iopub.status.idle":"2021-07-08T20:33:54.716121Z","shell.execute_reply.started":"2021-07-08T20:33:54.709626Z","shell.execute_reply":"2021-07-08T20:33:54.714179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"line-height:40px; border-radius: 5px; margin-right:10px; padding: 0px 10px; background-color:#68CAEC; font-weight:400; color:ghostwhite; min-height:40px; display: inline-block;text-align: center\"> \n    Univariate Numerical\n</h2>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\nLet's explore each numerical feature in isolation.","metadata":{}},{"cell_type":"code","source":"def uni_numerical_boxplots(df, numerical_features):\n    \n    '''\n    Creates a boxplot of all the numerical values\n    '''\n    \n    # normalize columns\n    x_scaled = preprocessing.MinMaxScaler().fit_transform(df[numerical_features].values)\n    new_df = pd.DataFrame(x_scaled)\n    new_df.columns = numerical_features\n    new_df = new_df.melt()\n    \n    # boxplot\n    plt.figure(figsize=(15,10))\n    bp=sns.boxplot(x='variable',y='value', data = new_df)\n    bp.set_xticklabels(bp.get_xticklabels(),rotation=90)\n    plt_font()\n    heading_3(\"Boxplot (normalized numerical features)\", '')\n    plt.show()\n    \n    # non-normalize columns\n    non_norm_df = pd.DataFrame(df[numerical_features].values)\n    non_norm_df.columns = numerical_features\n    non_norm_df = non_norm_df.melt()\n    \n    fig = plt.figure(figsize=(15,10))\n    \n    cols_count = 5\n    rows_count = math.ceil(len(numerical_features)/cols_count)\n    \n    counter = 1\n    for i in numerical_features:\n        \n        plt.subplot(rows_count,cols_count,counter) # 1 row, 2 columns, Plot 1\n        sns.boxplot(x='variable',y='value', data = non_norm_df[non_norm_df['variable'] == i])\n\n        counter += 1\n        \n    fig.tight_layout()\n    plt_font()\n    heading_3(\"Boxplot (non-normalized numerical features)\", '')\n    plt.show()\n        \n    # min/max\n    heading_3('Min/Max Range', 'Check amount of variation to see if columns should be dropped')\n    minmax_df = pd.DataFrame()\n    minmax_df['min'] = df[numerical_features].min()\n    minmax_df['max'] = df[numerical_features].max()\n    minmax_df['range'] = df[numerical_features].max() - df[numerical_features].min()\n    display(minmax_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.717454Z","iopub.execute_input":"2021-07-08T20:33:54.71779Z","iopub.status.idle":"2021-07-08T20:33:54.735698Z","shell.execute_reply.started":"2021-07-08T20:33:54.717759Z","shell.execute_reply":"2021-07-08T20:33:54.734443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uni_numerical_boxplots(train, numerical_features)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:54.737038Z","iopub.execute_input":"2021-07-08T20:33:54.737579Z","iopub.status.idle":"2021-07-08T20:33:57.472163Z","shell.execute_reply.started":"2021-07-08T20:33:54.73753Z","shell.execute_reply":"2021-07-08T20:33:57.471106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"line-height:40px; border-radius: 5px; margin-right:10px; padding: 0px 10px; background-color:#68CAEC; font-weight:400; color:ghostwhite; min-height:40px; display: inline-block;text-align: center\"> \n    Bivariate Numerical (Target vs Features)\n</h2>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#E6F6FC; padding:15px 15px 15px;margin:0px\">\nView the numerical features when filtered by the target values.","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:14:07.30954Z","iopub.execute_input":"2021-07-02T10:14:07.30995Z","iopub.status.idle":"2021-07-02T10:14:07.315593Z","shell.execute_reply.started":"2021-07-02T10:14:07.309915Z","shell.execute_reply":"2021-07-02T10:14:07.314282Z"}}},{"cell_type":"code","source":"def bi_numerical_boxplots(df, numerical_features, _target):\n    \n    '''\n    Creates a boxplot of all the numerical values\n    '''\n    \n    # normalize columns\n    numeric_data = df[numerical_features].melt()\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(df[numerical_features].values)\n    new_df = pd.DataFrame(x_scaled)\n    new_df.columns = numerical_features\n    new_df[_target] = df[_target]\n    new_df = new_df.melt(id_vars=['Attrition'])\n    \n    # boxplot\n    plt.figure(figsize=(15,10))\n    bp=sns.boxplot(x='variable',y='value',hue = _target, data = new_df)\n    bp.set_xticklabels(bp.get_xticklabels(),rotation=90)\n    plt_font()\n    heading_3(\"Boxplot (normalized numerical features)\", '')\n    plt.show()\n    \n    # non-normalize columns\n    numeric_data = df[numerical_features].melt()\n    x_scaled = df[numerical_features].values\n    non_norm_df = pd.DataFrame(x_scaled)\n    non_norm_df.columns = numerical_features\n    non_norm_df[_target] = df[_target]\n    non_norm_df = non_norm_df.melt(id_vars=['Attrition'])\n    \n    # boxplot\n#     plt.figure(figsize=(15,10))\n#     bp=sns.boxplot(x='variable',y='value',hue = _target, data = new_df)\n#     bp.set_xticklabels(bp.get_xticklabels(),rotation=90)\n#     plt_font()\n#     heading_3(\"Boxplot (normalized numerical features)\", '')\n#     plt.show()\n    \n    fig = plt.figure(figsize=(15,10))\n    \n    cols_count = 5\n    rows_count = math.ceil(len(numerical_features)/cols_count)\n    \n    counter = 1\n    for i in numerical_features:\n        \n        plt.subplot(rows_count,cols_count,counter) # 1 row, 2 columns, Plot 1\n        sns.boxplot(x='variable',y='value', hue = _target, data = non_norm_df[non_norm_df['variable'] == i])\n\n        counter += 1\n        \n    fig.tight_layout()\n    plt_font()\n    heading_3(\"Boxplot (non-normalized numerical features)\", '')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:57.473862Z","iopub.execute_input":"2021-07-08T20:33:57.474235Z","iopub.status.idle":"2021-07-08T20:33:57.486466Z","shell.execute_reply.started":"2021-07-08T20:33:57.474202Z","shell.execute_reply":"2021-07-08T20:33:57.485526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bi_numerical_boxplots(train, numerical_features, target_feature)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:33:57.487583Z","iopub.execute_input":"2021-07-08T20:33:57.488034Z","iopub.status.idle":"2021-07-08T20:34:02.472192Z","shell.execute_reply.started":"2021-07-08T20:33:57.48799Z","shell.execute_reply":"2021-07-08T20:34:02.471125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"line-height:40px; border-radius: 5px; margin-right:10px; padding: 0px 10px; background-color:#68CAEC; font-weight:400; color:ghostwhite; min-height:40px; display: inline-block;text-align: center\"> \n    Univariate Categorical\n</h2>","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:02:11.1609Z","iopub.execute_input":"2021-07-02T10:02:11.161255Z","iopub.status.idle":"2021-07-02T10:02:11.16751Z","shell.execute_reply.started":"2021-07-02T10:02:11.161221Z","shell.execute_reply":"2021-07-02T10:02:11.166168Z"}}},{"cell_type":"code","source":"def uni_categorical_countplot(df, _categorical_features, _target):\n    \n    uni_cat = df[_categorical_features].melt(id_vars=[_target])\n    \n    uni_cat_fg = sns.FacetGrid(uni_cat, col='variable', sharex=False, sharey=False, dropna=True, height=4, col_wrap=3)\n    histPlot=uni_cat_fg.map(sns.countplot,'value')\n    uni_cat_fg.add_legend()\n    [plt.setp(ax.get_xticklabels(), rotation=45) for ax in uni_cat_fg.axes.flat]\n    uni_cat_fg.fig.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:02.474173Z","iopub.execute_input":"2021-07-08T20:34:02.474598Z","iopub.status.idle":"2021-07-08T20:34:02.483349Z","shell.execute_reply.started":"2021-07-08T20:34:02.474555Z","shell.execute_reply":"2021-07-08T20:34:02.482156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global target_feature\nglobal categorical_features\nuni_categorical_countplot(train, categorical_features, target_feature)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:02.484897Z","iopub.execute_input":"2021-07-08T20:34:02.485286Z","iopub.status.idle":"2021-07-08T20:34:07.326377Z","shell.execute_reply.started":"2021-07-08T20:34:02.485253Z","shell.execute_reply":"2021-07-08T20:34:07.324982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#FFFCDF; padding:15px 15px 7px; color:#332906; font-style:italic; border-radius: 5px\">\n\n* Attrition feature is highly imbalanced","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"line-height:40px; border-radius: 5px; margin-right:10px; padding: 0px 10px; background-color:#68CAEC; font-weight:400; color:ghostwhite; min-height:40px; display: inline-block;text-align: center\"> \n    Bivariate Categorical\n</h2>","metadata":{}},{"cell_type":"code","source":"def countplot(x, hue, **kwargs):\n    data=kwargs.pop(\"data\")\n    sns.countplot(x=x, hue=hue, data=data,**kwargs)\n\n\ndef categorical_countplot(df, _categorical_features, _target):\n    #Bivariate Analysis for actual categorical Variables with Attrition\n    NumericBVData = df[_categorical_features].melt(id_vars=[_target])\n    \n    g = sns.FacetGrid(NumericBVData, col='variable', dropna=True, height=4, col_wrap=4, sharex=False, sharey=False)\n    g.map_dataframe(countplot, 'value',hue=_target, alpha=.6, palette=sns.color_palette())\n\n    [plt.setp(ax.get_xticklabels(), rotation=45) for ax in g.axes.flat]\n    g.fig.tight_layout()\n    plt.show()\n    \n    \nglobal target_feature\nglobal categorical_features\ncategorical_countplot(train, categorical_features, target_feature)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:07.327785Z","iopub.execute_input":"2021-07-08T20:34:07.32812Z","iopub.status.idle":"2021-07-08T20:34:13.380475Z","shell.execute_reply.started":"2021-07-08T20:34:07.328058Z","shell.execute_reply":"2021-07-08T20:34:13.379515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"from scipy import stats\n# display(train[(np.abs(stats.zscore(train[numerical_features])) < 3)])\ndisplay(train[(np.abs(stats.zscore(train[numerical_features])) < 3)])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:13.381996Z","iopub.execute_input":"2021-07-08T20:34:13.382319Z","iopub.status.idle":"2021-07-08T20:34:13.436346Z","shell.execute_reply.started":"2021-07-08T20:34:13.38229Z","shell.execute_reply":"2021-07-08T20:34:13.435591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def view_outliers(df, numerical_features):\n\n    Q1 = df.quantile(0.25)\n    Q3 = df.quantile(0.75)\n    IQR = Q3 - Q1\n\n    df_outliers = (df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))\n    \n    # heatmap\n    plt.figure(figsize=(15, 15))\n    plt_font()\n    heading_3('Heatmap: Visualise Outlier Data', '')\n    missing_hm = sns.heatmap(df_outliers ==True, yticklabels=False, cbar=False, cmap=cm.Blues)#'viridis')\n    plt.show()\n    \n    total = 0\n    outlier_list = []\n    \n    for i in df_outliers.columns:\n        total += len(df_outliers[df_outliers[i]==True])\n    \n        non_outlier_count = len(df_outliers[df_outliers[i]==False])\n        df_rows_count = df_outliers.shape[0]\n        outlier_count = len(df_outliers[df_outliers[i]==True])\n        outlier_percentage = round((100/df_rows_count)*outlier_count, 2)\n        \n        from pandas.api.types import is_string_dtype\n        from pandas.api.types import is_numeric_dtype\n\n        if is_numeric_dtype(df[i]):\n            IQR_value = IQR[i]\n        else:\n            IQR_value = np.nan\n\n        outlier_list.append([IQR_value , non_outlier_count, outlier_count, outlier_percentage])\n            \n    outlier_df = pd.DataFrame(outlier_list, columns=['IQR', 'Non Outliers Count', 'Outlier Count', 'Outlier %'], index=df_outliers.columns)\n    \n    heading_3('Table: Understand Outlier Data', '')\n    display(outlier_df)\n    \nview_outliers(train, numerical_features)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:13.437598Z","iopub.execute_input":"2021-07-08T20:34:13.43802Z","iopub.status.idle":"2021-07-08T20:34:14.166094Z","shell.execute_reply.started":"2021-07-08T20:34:13.437976Z","shell.execute_reply":"2021-07-08T20:34:14.165159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#FFFCDF; padding:15px 15px 7px; color:#332906; font-style:italic; border-radius: 5px\">\n\nThe following 3 columns have a hight amount of outliers:  \n* PerformanceRating  \n* TrainingTimesLastYear  \n* YearsSinceLastPromotion  ","metadata":{"execution":{"iopub.status.busy":"2021-07-07T18:09:16.972821Z","iopub.execute_input":"2021-07-07T18:09:16.973245Z","iopub.status.idle":"2021-07-07T18:09:16.980008Z","shell.execute_reply.started":"2021-07-07T18:09:16.973211Z","shell.execute_reply":"2021-07-07T18:09:16.978702Z"}}},{"cell_type":"code","source":"high_outliers.extend(['PerformanceRating', 'TrainingTimesLastYear', 'YearsSinceLastPromotion'])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:14.167448Z","iopub.execute_input":"2021-07-08T20:34:14.167748Z","iopub.status.idle":"2021-07-08T20:34:14.171788Z","shell.execute_reply.started":"2021-07-08T20:34:14.167717Z","shell.execute_reply":"2021-07-08T20:34:14.170914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div>\n<h1 id=\"heading\" style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">\n0. Load Data\n<a id=\"import_libraries\" class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/avocado-price-prediction-linear-regression/notebook#heading\">¶</a>\n</h1>\n<h1 style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">0. Import Libraries</h1>\n<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nCorrelation\n</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"def data_correlation(df, _target):\n    \n    global correlation_ranking\n    \n    new_df = df.copy()\n    new_df[_target] = new_df[_target].astype('category').cat.codes\n\n    # heatmap\n    plt.figure(figsize=(18,15))\n    sns.heatmap(new_df.corr(),annot=True, cmap=cm.Blues)\n    plt.show()\n\n    # sorted matrix\n    corr_matrix = new_df.corr()\n    correlation_ranking = corr_matrix[_target].abs().sort_values(ascending=False)\n    display(correlation_ranking)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:14.173054Z","iopub.execute_input":"2021-07-08T20:34:14.173365Z","iopub.status.idle":"2021-07-08T20:34:14.185426Z","shell.execute_reply.started":"2021-07-08T20:34:14.173334Z","shell.execute_reply":"2021-07-08T20:34:14.184581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_correlation(train, target_feature)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:14.186913Z","iopub.execute_input":"2021-07-08T20:34:14.187423Z","iopub.status.idle":"2021-07-08T20:34:17.566614Z","shell.execute_reply.started":"2021-07-08T20:34:14.18738Z","shell.execute_reply":"2021-07-08T20:34:17.565709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div>\n<h1 id=\"heading\" style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">\n0. Load Data\n<a id=\"import_libraries\" class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/avocado-price-prediction-linear-regression/notebook#heading\">¶</a>\n</h1>\n<h1 style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">0. Import Libraries</h1>\n<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nMissing Data\n</h2>\n</div>","metadata":{"execution":{"iopub.status.busy":"2021-06-21T20:53:13.960831Z","iopub.execute_input":"2021-06-21T20:53:13.961198Z","iopub.status.idle":"2021-06-21T20:53:13.967205Z","shell.execute_reply.started":"2021-06-21T20:53:13.961165Z","shell.execute_reply":"2021-06-21T20:53:13.966179Z"}}},{"cell_type":"code","source":"import missingno as msno\n\ndef visualize_missing_data(df):\n    \n    cols_list = df.columns.tolist()\n    \n    # heatmap\n    # missing data heat map to visualise how many of the collumns share missing data\n    plt.figure(figsize=(5, 5))\n    plt_font()\n    heading_3('Heatmap: Visualise Missing Data', 'Missing data heat map to visualise how many of the collumns/features share missing data. Look for where cells/lines group together or where multiple cells in rows are highlighted together.')\n    missing_hm = sns.heatmap(df[cols_list].isnull(), yticklabels=False, cbar=False, cmap=cm.Blues)#'viridis')\n    plt.show()\n    \n    # heatmap    \n    msno.heatmap(df[cols_list], figsize=(5, 5), cmap=cm.Blues)\n    plt_font()\n    heading_3(\"Heatmap: Missing Data Correlation\", '')\n    plt.show()\n    \n    # dendrogram\n    msno.dendrogram(df[df.columns], figsize=(10, 2.5), fontsize = 10)\n    plt_font()\n    heading_3(\"Dendrogram\", 'Visualise hierarchical relationship between features.')\n    plt.show()\n    \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-08T20:34:17.570149Z","iopub.execute_input":"2021-07-08T20:34:17.570452Z","iopub.status.idle":"2021-07-08T20:34:17.579427Z","shell.execute_reply.started":"2021-07-08T20:34:17.570422Z","shell.execute_reply":"2021-07-08T20:34:17.578393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_missing_data(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:17.581567Z","iopub.execute_input":"2021-07-08T20:34:17.582036Z","iopub.status.idle":"2021-07-08T20:34:18.815971Z","shell.execute_reply.started":"2021-07-08T20:34:17.581989Z","shell.execute_reply":"2021-07-08T20:34:18.815152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div>\n<h1 id=\"heading\" style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">\n0. Load Data\n<a id=\"import_libraries\" class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/avocado-price-prediction-linear-regression/notebook#heading\">¶</a>\n</h1>\n<h1 style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">0. Import Libraries</h1>\n<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nFeature Selection\n</h2>\n</div>","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:12:36.274821Z","iopub.execute_input":"2021-07-03T08:12:36.275693Z","iopub.status.idle":"2021-07-03T08:12:36.289705Z","shell.execute_reply.started":"2021-07-03T08:12:36.275538Z","shell.execute_reply":"2021-07-03T08:12:36.287735Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_column_info(train[numerical_features])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:18.817406Z","iopub.execute_input":"2021-07-08T20:34:18.818021Z","iopub.status.idle":"2021-07-08T20:34:22.03492Z","shell.execute_reply.started":"2021-07-08T20:34:18.817973Z","shell.execute_reply":"2021-07-08T20:34:22.033813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"line-height:40px; border-radius: 5px; margin-right:10px; padding: 0px 10px; background-color:#68CAEC; font-weight:400; color:ghostwhite; min-height:40px; display: inline-block;text-align: center\"> \n    Pipeline\n</h2>","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:29:56.51128Z","iopub.execute_input":"2021-07-03T09:29:56.511783Z","iopub.status.idle":"2021-07-03T09:29:56.517799Z","shell.execute_reply.started":"2021-07-03T09:29:56.511748Z","shell.execute_reply":"2021-07-03T09:29:56.516459Z"}}},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Define feature variables\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:30:30.774249Z","iopub.execute_input":"2021-07-03T09:30:30.774806Z","iopub.status.idle":"2021-07-03T09:30:30.781459Z","shell.execute_reply.started":"2021-07-03T09:30:30.774769Z","shell.execute_reply":"2021-07-03T09:30:30.779886Z"}}},{"cell_type":"markdown","source":"# feature extraction\nhigh_correlation_features  \nsingle_value  \ndrop_features  \ndrop_missing  \nimpute_missing  \n\n# categorical\ncategorical_features  \nnominal_features  \nordinal_features  \n\n# numerical\nnumerical_features  \ncontinuous_features  \ndiscrete_features  ","metadata":{}},{"cell_type":"code","source":"def feature_attributes_series(feature_list, attribute_list):\n    \n    feature_has_attribute = []\n    for i in feature_list:\n        feature_has_attribute.append(i in attribute_list)\n        \n    pd.Series(feature_has_attribute, index = feature_list)\n        \n    return(pd.Series(feature_has_attribute, index = feature_list).T)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.036503Z","iopub.execute_input":"2021-07-08T20:34:22.036801Z","iopub.status.idle":"2021-07-08T20:34:22.042307Z","shell.execute_reply.started":"2021-07-08T20:34:22.036773Z","shell.execute_reply":"2021-07-08T20:34:22.04106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"att_list = [numerical_features, continuous_features, discrete_features]\n\natt_dict = {\n    'numerical' : feature_attributes_series(train.columns, numerical_features),\n    'continuous' : feature_attributes_series(train.columns, continuous_features),\n    'discrete' : feature_attributes_series(train.columns, discrete_features),\n    'categorical' : feature_attributes_series(train.columns, categorical_features),\n    'nominal' : feature_attributes_series(train.columns, nominal_features),\n    'ordinal' : feature_attributes_series(train.columns, ordinal_features),\n    'high correlation' : feature_attributes_series(train.columns, pairwise_correlation_features),\n    'single value' : feature_attributes_series(train.columns, single_value_features),\n    'low variance' : feature_attributes_series(train.columns, low_variation_features),\n    'duplicat rows' : feature_attributes_series(train.columns, duplicate_rows),\n    'drop features' : feature_attributes_series(train.columns, drop_features),\n    'drop rows missing' : feature_attributes_series(train.columns, drop_rows_missing),\n    'impute missing' : feature_attributes_series(train.columns, impute_missing),\n    'high outliers' : feature_attributes_series(train.columns, high_outliers),\n    'correlation ranking' : correlation_ranking,\n}\n\natt_df = pd.DataFrame(att_dict)\ndisplay(att_df.style.applymap(lambda x: 'background-color : #fd7e14; color: white' if x==True else ''))\n\n\ndrop_combined_list = []\nfor i in [single_value_features, drop_features]:\n    drop_combined_list.extend(i)\n    \nprint(drop_combined_list)    ","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.04393Z","iopub.execute_input":"2021-07-08T20:34:22.044396Z","iopub.status.idle":"2021-07-08T20:34:22.124702Z","shell.execute_reply.started":"2021-07-08T20:34:22.044352Z","shell.execute_reply":"2021-07-08T20:34:22.123662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Revert to original data\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{}},{"cell_type":"code","source":"train = _train.copy()\ntest = _test.copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.126188Z","iopub.execute_input":"2021-07-08T20:34:22.126778Z","iopub.status.idle":"2021-07-08T20:34:22.131798Z","shell.execute_reply.started":"2021-07-08T20:34:22.126729Z","shell.execute_reply":"2021-07-08T20:34:22.130788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Drop unwanted features\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{}},{"cell_type":"code","source":"train.drop(drop_combined_list, axis=1, inplace=True)\n\nfor i in numerical_features:\n    if i in drop_combined_list or i == target_feature:\n        numerical_features.remove(i)\n\nfor i in categorical_features:\n    if i in drop_combined_list or i == target_feature:\n        categorical_features.remove(i)\n        \n# if target_feature in categorical_features: \n#     categorical_features.remove(target_feature)\n# if target_feature in numerical_features: \n#     numerical_features.remove(target_feature)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.133167Z","iopub.execute_input":"2021-07-08T20:34:22.133686Z","iopub.status.idle":"2021-07-08T20:34:22.149611Z","shell.execute_reply.started":"2021-07-08T20:34:22.13364Z","shell.execute_reply":"2021-07-08T20:34:22.148577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* drop unwanted columns\n* drop unwanted rows\n* impute rows\n* convert cat\n* convert num","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Split X & y\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# split X & y\nX, y = train.drop(target_feature, axis=1), train[target_feature]\n\n# get train & test\nX_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.25,random_state=23)\n\n# convert target to numerical\ny_train = y_train.map(dict(Yes=1, No=0))\ny_test = y_test.map(dict(Yes=1, No=0))#pd.get_dummies(y_test)\n\n\n# print(y_train)\n# print(y_test)\nprint(len(X_train))\nprint(len(y_train))\n# X_test, y_test = test.drop(target_feature, axis=1), test[target_feature]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:53:02.147931Z","iopub.execute_input":"2021-07-08T20:53:02.148303Z","iopub.status.idle":"2021-07-08T20:53:02.165469Z","shell.execute_reply.started":"2021-07-08T20:53:02.148272Z","shell.execute_reply":"2021-07-08T20:53:02.164423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-weight:400; color:#81D3EF; max-height:5px; display: inline-block;text-align: center\"> \n    Preprocessor\n</h3>\n<div style=\"background-color:#81D3EF; max-height:1px; margin-bottom: 10px\"> <br></div>","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:32:05.314233Z","iopub.execute_input":"2021-07-03T09:32:05.314754Z","iopub.status.idle":"2021-07-03T09:32:05.319959Z","shell.execute_reply.started":"2021-07-03T09:32:05.31472Z","shell.execute_reply":"2021-07-03T09:32:05.318916Z"}}},{"cell_type":"code","source":"# p = make_pipeline(preprocessor, LinearRegression())","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.182711Z","iopub.execute_input":"2021-07-08T20:34:22.183024Z","iopub.status.idle":"2021-07-08T20:34:22.187734Z","shell.execute_reply.started":"2021-07-08T20:34:22.182997Z","shell.execute_reply":"2021-07-08T20:34:22.186198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numeric_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='median')),\n#     ('scaler', StandardScaler())])\n\n# categorical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n#     ('one_hot', OneHotEncoder())])\n\n# preprocessor = ColumnTransformer(\n#     transformers=[\n#         ('num', numeric_transformer, numeric_features),\n#         ('cat', categorical_transformer, categorical_features)\n#     ])\n\n# pipe = Pipeline(steps=[('preprocessor', preprocessor),\n#                       ('classifier',  LogisticRegression(class_weight='balanced', random_state=0))])\n    \n# model = pipe.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.189576Z","iopub.execute_input":"2021-07-08T20:34:22.190385Z","iopub.status.idle":"2021-07-08T20:34:22.19931Z","shell.execute_reply.started":"2021-07-08T20:34:22.190252Z","shell.execute_reply":"2021-07-08T20:34:22.198494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create preprocessor\npreprocessor = make_column_transformer(\n    \n    # categorical\n    (\n        make_pipeline\n        (\n        SimpleImputer(strategy='constant', fill_value='missing'),\n        OneHotEncoder(handle_unknown='ignore')\n        )\n        ,categorical_features\n    ),\n    \n    # numerical\n    (\n        make_pipeline\n        (\n            SimpleImputer(strategy='median'),\n            StandardScaler()\n        )\n        ,numerical_features\n    )\n    \n    ,remainder = 'passthrough'\n)\n\npreprocessor.fit(X_train)\nX_train = (make_pipeline(preprocessor).transform(X_train))\nprint(len(X_train))\nprint(len(y_train))\n\n# print(preprocessor.fit_transform(X_train)[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:53:07.267689Z","iopub.execute_input":"2021-07-08T20:53:07.268124Z","iopub.status.idle":"2021-07-08T20:53:07.324162Z","shell.execute_reply.started":"2021-07-08T20:53:07.268091Z","shell.execute_reply":"2021-07-08T20:53:07.323086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.linear_model import LinearRegression\n# from sklearn.metrics import r2_score\n\n# # create pipeline\n# p = make_pipeline(preprocessor, LinearRegression())\n\n# # fit\n# # p.fit(X_train, y_train)\n\n# # make_pipeline(preprocessor).fit_transform(X_train, y_train)\n\n# # # predict\n# # y_pred = p.predict(X_test)\n\n# # # score\n# # r2_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.213287Z","iopub.execute_input":"2021-07-08T20:34:22.214015Z","iopub.status.idle":"2021-07-08T20:34:22.229405Z","shell.execute_reply.started":"2021-07-08T20:34:22.213962Z","shell.execute_reply":"2021-07-08T20:34:22.228381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_train = (make_pipeline(preprocessor).transform(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:38:49.804659Z","iopub.execute_input":"2021-07-08T20:38:49.805012Z","iopub.status.idle":"2021-07-08T20:38:49.809114Z","shell.execute_reply.started":"2021-07-08T20:38:49.804982Z","shell.execute_reply":"2021-07-08T20:38:49.808032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(X_train[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-08T20:34:22.269181Z","iopub.status.idle":"2021-07-08T20:34:22.269599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div>\n<h1 id=\"heading\" style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">\n0. Load Data\n<a id=\"import_libraries\" class=\"anchor-link\" href=\"https://www.kaggle.com/nealliddle/avocado-price-prediction-linear-regression/notebook#heading\">¶</a>\n</h1>\n<h1 style=\"padding:0px; margin:0px; font-size:0px; max-height:0px; line-height:0px\">0. Import Libraries</h1>\n<h2 style=\"margin-top:0px; background-color:#4fc1e9; color:ghostwhite; font-weight:300; min-height:50px; line-height:50px\"><span style=\"background-color:#3bafda; min-width:50px;min-height:50px; display: inline-block;text-align: center\">\n0.\n</span>\nModels\n</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"import sklearn\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(max_iter=1000),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n#     svm.LinearSVC(max_iter=10000),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n#     discriminant_analysis.LinearDiscriminantAnalysis(),\n#     discriminant_analysis.QuadraticDiscriminantAnalysis(tol=0.0001),\n\n    \n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')    \n    ]\n\n#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n#note: this is an alternative to train_test_split\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n\n#create table to compare MLA metrics\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n#create table to compare MLA predictions\nMLA_predict = []\n\n#index through MLA and save performance to table\nrow_index = 0\nfor alg in MLA:\n    \n    print(alg)\n\n    #set name and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n#     print(len(X_train))\n#     print(len(y_train))\n    \n    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n    cv_results = model_selection.cross_validate(alg, X_train, y_train, return_train_score =True, cv  = cv_split)\n    \n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n    \n    \n\n#     #save MLA predictions - see section 6 for usage\n#     alg.fit(X_train, y_train)\n#     MLA_predict[MLA_name] = alg.predict(X_train)\n    \n    row_index+=1\n\n    \n#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare\n#MLA_predict","metadata":{"execution":{"iopub.status.busy":"2021-07-08T21:56:21.147564Z","iopub.execute_input":"2021-07-08T21:56:21.147986Z","iopub.status.idle":"2021-07-08T21:57:04.69202Z","shell.execute_reply.started":"2021-07-08T21:56:21.147953Z","shell.execute_reply":"2021-07-08T21:57:04.690836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T21:18:42.426133Z","iopub.execute_input":"2021-07-08T21:18:42.426555Z","iopub.status.idle":"2021-07-08T21:18:42.814179Z","shell.execute_reply.started":"2021-07-08T21:18:42.426522Z","shell.execute_reply":"2021-07-08T21:18:42.813077Z"},"trusted":true},"execution_count":null,"outputs":[]}]}