{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/test-file/tested.csv\"\ndf = pd.read_csv(path)\n%config Completer.use_jedi = False\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Write the logic and code to handle missing values.","metadata":{}},{"cell_type":"code","source":"#Since from above we see missing values is Cabin column are 327 out of 417 so it would be better to drop it..\ndft = df.drop([\"Cabin\"],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we may replace missing 87 age values with average age\ndft2 = dft.replace(np.nan,df.Age.mean() )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft2.isna().sum()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Write a code to delete a column.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"dft3 = dft2.drop([\"SibSp\"],axis=1)\ndft3.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.write a code to delete a row.","metadata":{}},{"cell_type":"code","source":"# Removing row at index 1\ndft3[dft3.PassengerId != 893].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. write a code to find duplicate rows.\n","metadata":{}},{"cell_type":"markdown","source":"#### 1.  finding perfectly duplicated columns i.e. entire row values are same","metadata":{}},{"cell_type":"code","source":"dft3.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. duplicates on specific column(s), use subset.","metadata":{}},{"cell_type":"code","source":"dft3.duplicated(subset=['Ticket']).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. write a code to delete duplicate rows.\n\n","metadata":{}},{"cell_type":"markdown","source":"#### drop duplicates on specific column(s)-","metadata":{}},{"cell_type":"code","source":"len(dft3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dft3.drop_duplicates(subset=['Ticket']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Write a code to group rows by values.\n","metadata":{}},{"cell_type":"code","source":"dft3.groupby('Pclass').count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft3.groupby(['Sex','Survived'])['Age'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Write a code to apply functions over all elements in a column.","metadata":{}},{"cell_type":"code","source":"def uppercase(x):\n    return x.upper()\n# Apply function, show two rows\ndft3['Sex'].apply(uppercase)[0:4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. group rows by time","metadata":{}},{"cell_type":"code","source":"# Load libraries\nimport pandas as pd\nimport numpy as np\n# Create date range\ntime_index = pd.date_range('06/06/2017', periods=100000, freq='30S')\n# Create DataFrame\ndataframe = pd.DataFrame(index=time_index)\n# Create column of random values\ndataframe['Sale_Amount'] = np.random.randint(1, 10, 100000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group rows by week, calculate sum per week\ndataframe.resample('W').sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. write a code to apply function to groups.\n","metadata":{}},{"cell_type":"code","source":"dft3.groupby('Sex').apply(lambda x: x.count())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10. write a code to create 2 data frames which contain first ten and last 10 values. Now merge both data frames into one.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n# Create DataFrame\ndf1 = {'employee_id': [k for k in range(1,11)],\n                  'name': ['Amy Jones', 'Allen Keys', 'Alice Bees', 'Tim Horton','Amy Jones', \n                           'Allen Keys', 'Alice Bees', 'Tim Horton','Alice Bees', 'Tim Horton']\n                }\ndf1 = pd.DataFrame(df1, columns = ['employee_id','name'])\n# Create DataFrame\ndf2 = {'employee_id': [k for k in range(11,21)],\n       'name': ['Amy Jones', 'Allen Keys','Amy Jones', 'Allen Keys','Amy Jones', 'Allen Keys',\n                'Amy Jones', 'Allen Keys','Amy Jones', 'Allen Keys']\n      }\ndf2 = pd.DataFrame(df2, columns = ['employee_id','name'])\nframes = [df1, df2]\npd.concat(frames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}