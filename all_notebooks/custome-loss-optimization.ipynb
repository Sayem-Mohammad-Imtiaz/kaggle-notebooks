{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Custome Loss optimization \nin this notebook we will look at using custom loss in keras to optimize mean revenue for discount offer for leaving customers\n## introduction\nour goal is to offer the highest price that the user will accsept without exeding his/hers spend limit\nits like playing \"The price is right\" if we go over the spend limit or revune is zero\n\nalso to be cost efective we canot offer less then 55 dolar for our service\nin this notebook we will\n* load and fix the data to our use case (Anima streming service)\n* preprocessing \n* create an evalution metric\n* define our metric of revune and evaluate baseline model (mean spend limit$ sale offer for all)\n* create a base NN to predict spend limit\n* creat a NN with custome loss and output\n"},{"metadata":{},"cell_type":"markdown","source":"# load and fix the data to our use case"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport os\nimport seaborn\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\ndata = pd.read_csv(\"/kaggle/input/churn-modeling-dataset/Churn_Modelling.csv\").drop(\n    [\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1\n)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets make the data more anima like\ndata.columns = [\n    \"SpendLimit\",\n    \"Geography\",\n    \"Gender\",\n    \"Age\",\n    \"Tenure\",\n    \"TotalWatchTime\",\n    \"VODRental\",\n    \"HasCrCard\",\n    \"IsActiveMember\",\n    \"LastMonthWatchTime\",\n    \"PreferDub\",\n]\ndata[\"SpendLimit\"] = data[\"SpendLimit\"] / 10\ndata.head(3).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# create an evalution metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#lets visulize our profit from a user with a spending limit of 62$\nx = np.asarray(range(100) )\ny =np.asarray(range(100) )\ny[y<5]=0\ny[y>62]=0\npd.DataFrame([x,y]).T.set_index(0).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true_sample = np.asarray([30,40,50])\ny_pred_sample = np.asarray([20,50,40])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_profit(y_true,y_pred):\n    return ((y_pred<y_true).astype(int) *y_pred).mean()\nmean_profit(y_true_sample,y_pred_sample)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n\nenc = OneHotEncoder(handle_unknown=\"ignore\")\nstander_scaler = StandardScaler()\nlabel_encoder = LabelEncoder()\n\nX = np.concatenate(\n    (\n        ## OneHotEncoder\n        enc.fit_transform(data[[\"Geography\"]]).toarray(),\n        ## Stander Scaler\n        stander_scaler.fit_transform(\n            data[\n                [\n                    \"Age\",\n                    \"Tenure\",\n                    \"TotalWatchTime\",\n                    \"VODRental\",\n                    \"LastMonthWatchTime\",\n                ]\n            ]\n        ),\n        ## LabelEncoder\n        label_encoder.fit_transform(data[[\"Gender\"]]).reshape(-1, 1),\n        ## No formatation\n        data[[\"HasCrCard\", \"IsActiveMember\"]].values,\n    ),\n    axis=1,\n)\n\ny = data[\"SpendLimit\"].values\nX.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D\nimport keras\n\n\ndef get_model():\n    return Sequential(\n        [\n            Dense(units=200, input_dim=11, activation=\"relu\"),\n            Dense(150, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(1, activation=\"relu\"),\n        ]\n    )\n\n\ndef train_ann(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n\n    model = get_model()\n\n    model.compile(\n        optimizer=\"adam\", loss=\"mae\", metrics=[\"mse\"],\n    )\n\n    # Trainig and returning back the results.\n    history = model.fit(\n        X_train,\n        y_train,\n        batch_size=100,\n        epochs=5,\n        verbose=1,\n        validation_data=(X_test, y_test),\n    )\n    y_pred = model.predict(X_test)\n    score = mean_profit(y_test,y_pred)\n    print (f\"your score is :{score} with min pred of {y_pred.min()} \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimize\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D,Lambda,BatchNormalization\nimport keras\nimport keras.backend as K\n\n\ndef get_model2():\n    return Sequential(\n        [\n            Dense(units=200, input_dim=11, activation=\"relu\"),\n            Dense(150, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(1, activation=\"relu\"),\n            #Lambda(lambda x: K.clip(x,55,1000))\n        ]\n    )\ndef customLoss(y_true,y_pred):\n    return -K.mean(K.cast(y_pred<y_true,\"float32\") *y_pred - K.cast(y_pred>y_true,\"float32\") *(y_pred- y_true))\ndef customLoss_naive(y_true,y_pred):\n    return -K.mean((K.cast(y_pred<y_true,\"float32\") *y_pred))\n\ndef train_ann_custom(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n\n    model = get_model2()\n\n    model.compile(\n        optimizer=\"adam\", loss=customLoss, metrics=[\"mse\"],\n    )\n\n    # Trainig and returning back the results.\n    history = model.fit(\n        X_train,\n        y_train,\n        batch_size=50,\n        epochs=50,\n        verbose=1,\n        validation_data=(X_test, y_test),\n    )\n    y_pred = model.predict(X_test)\n    score = mean_profit(y_test,y_pred)\n    print (f\"your score is :{score} with min pred of {y_pred.min()} \")\ntrain_ann_custom(X, y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}