{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![friends-tv-show-1542126105](https://user-images.githubusercontent.com/66208179/120125041-aa98ff80-c1bf-11eb-9e56-6b1990a1f720.jpeg)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T00:24:17.937765Z","iopub.execute_input":"2021-05-31T00:24:17.938101Z","iopub.status.idle":"2021-05-31T00:24:18.674169Z","shell.execute_reply.started":"2021-05-31T00:24:17.938074Z","shell.execute_reply":"2021-05-31T00:24:18.673161Z"}}},{"cell_type":"markdown","source":"Friends is one my favorite tv shows ‚ù§Ô∏è. I remember crying about the final for two days üòÖ (it was so touching to see every character grow throughout the show ‚ú®).\n\nIn this project, I will be getting a bit nostalgic and will try to understand given data through Exploratory Data Analysis. I will also see if we can predict something (at this point, anything). It can be sentiment analysis based on summaries and titles, or classification for the number of episode contributers.\n\n# Data\n\nWe have the following columns:\n    \n- `Date`: the date of release for the episode\n\n- `Episode`: episode number (season - episode)\n\n- `Title`: episode title\n\n- `Directed by`\n\n- `Written by`\n\n- `Duration` \n- `Summary`\n\n- `Rating/Share`\n\n- `U.S. viewers`: how many people viewed the episode in the US\n\n- `Prod. code`: unique values\n\n\n# Process:\n\n1. ‚úÖTweak the data a bit to understand the data in detail.\n2. ‚úÖTry to understand any type of correlation.\n3. ‚úÖIf there is - model!","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:43.4632Z","iopub.execute_input":"2021-06-02T15:34:43.463807Z","iopub.status.idle":"2021-06-02T15:34:43.468948Z","shell.execute_reply.started":"2021-06-02T15:34:43.463754Z","shell.execute_reply":"2021-06-02T15:34:43.468163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understanding Data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/friends-tv-show-all-seasons-and-episodes-data/friends_info.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:43.562719Z","iopub.execute_input":"2021-06-02T15:34:43.563142Z","iopub.status.idle":"2021-06-02T15:34:43.593018Z","shell.execute_reply.started":"2021-06-02T15:34:43.563103Z","shell.execute_reply":"2021-06-02T15:34:43.592176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:43.660636Z","iopub.execute_input":"2021-06-02T15:34:43.661252Z","iopub.status.idle":"2021-06-02T15:34:43.676228Z","shell.execute_reply.started":"2021-06-02T15:34:43.661205Z","shell.execute_reply":"2021-06-02T15:34:43.675047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:43.750275Z","iopub.execute_input":"2021-06-02T15:34:43.750626Z","iopub.status.idle":"2021-06-02T15:34:43.766596Z","shell.execute_reply.started":"2021-06-02T15:34:43.750595Z","shell.execute_reply":"2021-06-02T15:34:43.765326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will apply the following transformations:\n    \n- `Date`: get the date as year, day and month solely and add them as new columns\n\n- `Episode`: keep the episode column, but also create two other columns for episode and season separetely\n\n- `Title`: keep it like it is for EDA, but since this a categorical column we will need to transform it before modeling\n\n- `Directed by`: keep it like it is for EDA, but since this a categorical column we will need to transform it before modeling\n\n- `Written by`: add a column `written_by_numbers` to keep track of how many people have written the episode\n\n- `Duration`: keep it like it is\n\n- `Summary`:  keep it like it is for EDA, but since this a categorical column we will need to transform it before modeling\n\n- `Rating/Share`: make the division and keep that value\n\n- `U.S. viewers`: change to float\n- `Prod. code`: can be removed","metadata":{}},{"cell_type":"code","source":"data.Episode","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:43.803272Z","iopub.execute_input":"2021-06-02T15:34:43.803629Z","iopub.status.idle":"2021-06-02T15:34:43.811864Z","shell.execute_reply.started":"2021-06-02T15:34:43.803598Z","shell.execute_reply":"2021-06-02T15:34:43.810813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Date column\n\ndata[\"release_year\"] = pd.DatetimeIndex(data['Date']).year\ndata[\"release_month\"] = pd.DatetimeIndex(data['Date']).month\ndata[\"release_day\"] = pd.DatetimeIndex(data['Date']).day\ndata.drop(\"Date\", axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:43.856129Z","iopub.execute_input":"2021-06-02T15:34:43.856676Z","iopub.status.idle":"2021-06-02T15:34:43.923381Z","shell.execute_reply.started":"2021-06-02T15:34:43.856616Z","shell.execute_reply":"2021-06-02T15:34:43.92248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Episode","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:43.947477Z","iopub.execute_input":"2021-06-02T15:34:43.948009Z","iopub.status.idle":"2021-06-02T15:34:43.957054Z","shell.execute_reply.started":"2021-06-02T15:34:43.947968Z","shell.execute_reply":"2021-06-02T15:34:43.956049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üßê As we can see, there are some special columns that do not follow the **episode-season** format. So I will create an exception to make sure we are keeping track of different formats and classify them as missing.","metadata":{}},{"cell_type":"code","source":"seasons = []\nepisodes = []\n\nfor i in data.Episode:\n    try:\n        seasons.append(i.split(\"-\")[0])\n    except:\n        seasons.append(\"Special\") \n    try:\n        episodes.append(i.split(\"-\")[1])\n    except:\n        episodes.append(\"Special\")\n\ndata[\"episode_number\"] = episodes\ndata[\"season_number\"] = seasons\ndata[\"episode-season\"] = data[\"Episode\"]\ndata.drop(\"Episode\", axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.022443Z","iopub.execute_input":"2021-06-02T15:34:44.022809Z","iopub.status.idle":"2021-06-02T15:34:44.033817Z","shell.execute_reply.started":"2021-06-02T15:34:44.022775Z","shell.execute_reply":"2021-06-02T15:34:44.032908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üå± `Written by` column will **depend on the number of `&` characters** since it is the format the dataframe follows. If there is no `&`, we have one writer; if there is one `&`, there are 2 writers and so on.","metadata":{}},{"cell_type":"code","source":"# written by column\n\nwritten_number = [] \nfor i in data[\"Written by\"]:\n    written_number.append(str(i).count('&') + 1)\n    \ndata[\"writtenby_number\"] = written_number\ndata[\"writtenby_number\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.07631Z","iopub.execute_input":"2021-06-02T15:34:44.07682Z","iopub.status.idle":"2021-06-02T15:34:44.085634Z","shell.execute_reply.started":"2021-06-02T15:34:44.076787Z","shell.execute_reply":"2021-06-02T15:34:44.084882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rating/ share column\nrating_score = []\nfor i in data[\"Rating/Share\"]:\n    rating_score.append(float(i.split(\"/\")[0]) / float(i.split(\"/\")[1]))\n\ndata[\"rating\"] = rating_score\ndata.drop(\"Rating/Share\", axis = 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.127397Z","iopub.execute_input":"2021-06-02T15:34:44.12793Z","iopub.status.idle":"2021-06-02T15:34:44.136005Z","shell.execute_reply.started":"2021-06-02T15:34:44.127893Z","shell.execute_reply":"2021-06-02T15:34:44.134973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove the prod column\ndata.drop(\"Prod.\\ncode\", axis = 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.217523Z","iopub.execute_input":"2021-06-02T15:34:44.217934Z","iopub.status.idle":"2021-06-02T15:34:44.223888Z","shell.execute_reply.started":"2021-06-02T15:34:44.217901Z","shell.execute_reply":"2021-06-02T15:34:44.222775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# US viewers change to float\nfor i in range(len(data[\"U.S. viewers\"])):\n    data[\"U.S. viewers\"].iloc[i] = float(data[\"U.S. viewers\"].iloc[i].replace(' million', ''))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.300115Z","iopub.execute_input":"2021-06-02T15:34:44.300786Z","iopub.status.idle":"2021-06-02T15:34:44.437191Z","shell.execute_reply.started":"2021-06-02T15:34:44.300745Z","shell.execute_reply":"2021-06-02T15:34:44.436147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"U.S. viewers\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.438637Z","iopub.execute_input":"2021-06-02T15:34:44.438995Z","iopub.status.idle":"2021-06-02T15:34:44.447151Z","shell.execute_reply.started":"2021-06-02T15:34:44.43896Z","shell.execute_reply":"2021-06-02T15:34:44.446095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename some column with spaces\n\ndata.columns = data.columns.str.replace(' ', '_')\ndata.columns = data.columns.str.replace('.', '')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.449224Z","iopub.execute_input":"2021-06-02T15:34:44.449551Z","iopub.status.idle":"2021-06-02T15:34:44.460093Z","shell.execute_reply.started":"2021-06-02T15:34:44.449518Z","shell.execute_reply":"2021-06-02T15:34:44.458785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.498878Z","iopub.execute_input":"2021-06-02T15:34:44.499268Z","iopub.status.idle":"2021-06-02T15:34:44.521696Z","shell.execute_reply.started":"2021-06-02T15:34:44.499229Z","shell.execute_reply":"2021-06-02T15:34:44.520297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"markdown","source":"ü§Ø At this point, we are done with tweaking the features (of course, we can always go back and iterate through different methods again). I will know **visualize** some of the columns to better understand the relation.\n\nI am currently reading **[The Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)**, so I will try to apply what I've learned in here. It is important to apply what you've recently learnt and it is one of things I really love about Kaggle: you can apply what you've learned in books or courses here ‚≠êÔ∏è\n\n**Things that Caught My Eye During `Understanding Data` part:**\n1. views vs. number of writers\n2. views vs. date (month, day, year)\n3. views and writers (who wrote it)\n4. views and directors\n5. us viewers and ratings\n\n\nand whatever catches my attention during visualization :)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T00:33:46.515469Z","iopub.execute_input":"2021-05-31T00:33:46.515836Z","iopub.status.idle":"2021-05-31T00:33:46.522215Z","shell.execute_reply.started":"2021-05-31T00:33:46.515803Z","shell.execute_reply":"2021-05-31T00:33:46.521067Z"}}},{"cell_type":"markdown","source":"On eof my favourite libraries is **Pandas Profiling**. You can check [this notebook](https://www.kaggle.com/dtomruk/commonlit-eda-modeling) to learn more about it.","metadata":{}},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\nProfileReport(data)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:34:44.55813Z","iopub.execute_input":"2021-06-02T15:34:44.558523Z","iopub.status.idle":"2021-06-02T15:35:01.616612Z","shell.execute_reply.started":"2021-06-02T15:34:44.558483Z","shell.execute_reply":"2021-06-02T15:35:01.615523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feel free to discover what Pandas Profiling showed us. \n\nHere are some of my takes:\n\nüåé**Correlation Matrix**: There isn't any correlation between numerical values.\n\n<img width=\"663\" alt=\"Screen Shot 2021-05-31 at 3 03 21 PM\" src=\"https://user-images.githubusercontent.com/66208179/120232412-3496a600-c25c-11eb-9a81-4f086cf12f38.png\">\n\nüåà**The directors** that appaeared the most:\n\n<img width=\"410\" alt=\"Screen Shot 2021-05-31 at 3 01 30 PM\" src=\"https://user-images.githubusercontent.com/66208179/120232414-35c7d300-c25c-11eb-90f2-cf52ab800652.png\">\n\nüëÅThe **views** in the US:\n\n<img width=\"556\" alt=\"Screen Shot 2021-05-31 at 3 02 08 PM\" src=\"https://user-images.githubusercontent.com/66208179/120232415-36606980-c25c-11eb-97e5-4df4e05ca2e4.png\">","metadata":{}},{"cell_type":"code","source":"# views vs ratings\n\nsns.relplot(x=\"US_viewers\", y=\"rating\", data=data);","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:01.618363Z","iopub.execute_input":"2021-06-02T15:35:01.618718Z","iopub.status.idle":"2021-06-02T15:35:01.933332Z","shell.execute_reply.started":"2021-06-02T15:35:01.618679Z","shell.execute_reply":"2021-06-02T15:35:01.932139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.corr());","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:01.935318Z","iopub.execute_input":"2021-06-02T15:35:01.935633Z","iopub.status.idle":"2021-06-02T15:35:02.254427Z","shell.execute_reply.started":"2021-06-02T15:35:01.935596Z","shell.execute_reply":"2021-06-02T15:35:02.253242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(data.US_viewers);","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.256083Z","iopub.execute_input":"2021-06-02T15:35:02.256391Z","iopub.status.idle":"2021-06-02T15:35:02.410605Z","shell.execute_reply.started":"2021-06-02T15:35:02.256358Z","shell.execute_reply":"2021-06-02T15:35:02.409516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will also check if a character that is mentioned in the summary (such as Rachel or Monica) is somehow related to ratings or views.","metadata":{}},{"cell_type":"code","source":"rachel = []\nmonica = []\nross = []\nchandler = []\njoey = []\nphoebe = []\n\nfor i in range(len(data)):\n    # there are still nan values (possibly i could've filled them with \"missing\" value, too)\n    try:\n        if \"Rachel\" in data.Summary.iloc[i]:\n            rachel.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Monica\" in data.Summary.iloc[i]:\n            monica.append((data.US_viewers.iloc[i],data.rating.iloc[i]))\n        if \"Ross\" in data.Summary.iloc[i]:\n            ross.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Chandler\" in data.Summary.iloc[i]:\n            chandler.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Joey\" in data.Summary.iloc[i]:\n            joey.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Phoebe\" in data.Summary.iloc[i]:\n            phoebe.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n    except:\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.411929Z","iopub.execute_input":"2021-06-02T15:35:02.412219Z","iopub.status.idle":"2021-06-02T15:35:02.479849Z","shell.execute_reply.started":"2021-06-02T15:35:02.412189Z","shell.execute_reply":"2021-06-02T15:35:02.478763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check [*this tutorial*](https://www.tutorialspoint.com/matplotlib/matplotlib_pie_chart.htm#:~:text=Matplotlib%20API%20has%20a%20pie,array%20will%20not%20be%20normalized.) for pie charts.","metadata":{}},{"cell_type":"code","source":"# viewers\nrachel_sum = sum([r[0] for r in rachel])\nmonica_sum = sum([r[0] for r in monica])\nross_sum = sum([r[0] for r in ross])\nphoebe_sum = sum([r[0] for r in phoebe])\nchandler_sum = sum([r[0] for r in chandler])\njoey_sum = sum([r[0] for r in joey])\n\n\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\nnames = ['Rachel', 'Monica', 'Ross', 'Phoebe', 'Chandler', 'Joey']\nlist_sum = [rachel_sum, monica_sum, ross_sum, phoebe_sum, chandler_sum, joey_sum]\nax.pie(list_sum, labels = names,autopct='%1.2f%%')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.481189Z","iopub.execute_input":"2021-06-02T15:35:02.481484Z","iopub.status.idle":"2021-06-02T15:35:02.60406Z","shell.execute_reply.started":"2021-06-02T15:35:02.481456Z","shell.execute_reply":"2021-06-02T15:35:02.603228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There doesn't seem to be a huge difference when it comes to viewers.","metadata":{}},{"cell_type":"code","source":"# ratings\n\nrachel_sum = sum([r[1] for r in rachel])\nmonica_sum = sum([r[1] for r in monica])\nross_sum = sum([r[1] for r in ross])\nphoebe_sum = sum([r[1] for r in phoebe])\nchandler_sum = sum([r[1] for r in chandler])\njoey_sum = sum([r[1] for r in joey])\n\n\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\nnames = ['Rachel', 'Monica', 'Ross', 'Phoebe', 'Chandler', 'Joey']\nlist_sum = [rachel_sum, monica_sum, ross_sum, phoebe_sum, chandler_sum, joey_sum]\nax.pie(list_sum, labels = names,autopct='%1.2f%%')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.60519Z","iopub.execute_input":"2021-06-02T15:35:02.605615Z","iopub.status.idle":"2021-06-02T15:35:02.725846Z","shell.execute_reply.started":"2021-06-02T15:35:02.605583Z","shell.execute_reply":"2021-06-02T15:35:02.724966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not a huge difference on ratings either. Rachel seems to attract more viewers and ratings though! üßö\n\nThe üëëqueenüëë  deserves her own column then :)","metadata":{}},{"cell_type":"code","source":"x = []\n\nfor i in data.Summary:\n    try:\n        x.append(i.count(\"Rachel\"))\n    except:\n        x.append(0)\n        \ndata[\"rachel_count\"] = x","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.727693Z","iopub.execute_input":"2021-06-02T15:35:02.728119Z","iopub.status.idle":"2021-06-02T15:35:02.734055Z","shell.execute_reply.started":"2021-06-02T15:35:02.728086Z","shell.execute_reply":"2021-06-02T15:35:02.733027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define the Problem","metadata":{}},{"cell_type":"markdown","source":"## Can we predict the ratings of episodes based on other columns?\n\nThe approach will be based on time-series. Our model can learn from previous episodes and predict the rating of future episodes. This is a regression problem since the target is ratings, a continous value.\n\nBefore getting into modeling, we need to do several things:\n- categorical to numerical transformations\n- train test split \n- fill missing values\n- scaling if needed","metadata":{"execution":{"iopub.status.busy":"2021-06-02T14:33:42.346051Z","iopub.execute_input":"2021-06-02T14:33:42.346407Z","iopub.status.idle":"2021-06-02T14:33:42.350296Z","shell.execute_reply.started":"2021-06-02T14:33:42.346367Z","shell.execute_reply":"2021-06-02T14:33:42.34916Z"}}},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.735472Z","iopub.execute_input":"2021-06-02T15:35:02.735951Z","iopub.status.idle":"2021-06-02T15:35:02.748667Z","shell.execute_reply.started":"2021-06-02T15:35:02.735905Z","shell.execute_reply":"2021-06-02T15:35:02.747512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Categorical Data","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.750064Z","iopub.execute_input":"2021-06-02T15:35:02.75039Z","iopub.status.idle":"2021-06-02T15:35:02.773445Z","shell.execute_reply.started":"2021-06-02T15:35:02.750359Z","shell.execute_reply":"2021-06-02T15:35:02.772054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Few things first:\n- `episode_number`, `season_number` and`US viewers` can be expressed as a float. Let's fix that.\n- we can drop `episode-season` since we already have those in separate columns.","metadata":{}},{"cell_type":"code","source":"data.drop(\"episode-season\", axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.775537Z","iopub.execute_input":"2021-06-02T15:35:02.776108Z","iopub.status.idle":"2021-06-02T15:35:02.787272Z","shell.execute_reply.started":"2021-06-02T15:35:02.776056Z","shell.execute_reply":"2021-06-02T15:35:02.786029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(data.episode_number)):\n    try:\n        if data.episode_number.iloc[i] == \"Special\":\n            data.episode_number.iloc[i] = 0\n        else:\n            data.episode_number.iloc[i] = int(i)\n    except:\n        data.episode_number.iloc[i] = int(i.str.replace('\\n', ''))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.789337Z","iopub.execute_input":"2021-06-02T15:35:02.790036Z","iopub.status.idle":"2021-06-02T15:35:02.959724Z","shell.execute_reply.started":"2021-06-02T15:35:02.789983Z","shell.execute_reply":"2021-06-02T15:35:02.95755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(data.season_number)):\n    try:\n        if data.season_number.iloc[i] == \"Special\":\n            data.season_number.iloc[i] = 0\n        data.season_number.iloc[i] = int(data.season_number.iloc[i])\n    except:\n        data.season_number.iloc[i] = int(data.season_number.iloc[i].str.replace('\\n', ''))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:02.961226Z","iopub.execute_input":"2021-06-02T15:35:02.961615Z","iopub.status.idle":"2021-06-02T15:35:03.132939Z","shell.execute_reply.started":"2021-06-02T15:35:02.96158Z","shell.execute_reply":"2021-06-02T15:35:03.131909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(\"Summary\", axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:15.814353Z","iopub.execute_input":"2021-06-02T15:35:15.814788Z","iopub.status.idle":"2021-06-02T15:35:15.822366Z","shell.execute_reply.started":"2021-06-02T15:35:15.814746Z","shell.execute_reply":"2021-06-02T15:35:15.820863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.season_number = pd.to_numeric(data.season_number)\ndata.episode_number = pd.to_numeric(data.episode_number)\ndata.US_viewers = pd.to_numeric(data.US_viewers)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:16.775165Z","iopub.execute_input":"2021-06-02T15:35:16.775532Z","iopub.status.idle":"2021-06-02T15:35:16.78345Z","shell.execute_reply.started":"2021-06-02T15:35:16.7755Z","shell.execute_reply":"2021-06-02T15:35:16.781943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = list(set(data.columns) - set(data._get_numeric_data().columns))\ncat_cols","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:17.460181Z","iopub.execute_input":"2021-06-02T15:35:17.460552Z","iopub.status.idle":"2021-06-02T15:35:17.468728Z","shell.execute_reply.started":"2021-06-02T15:35:17.460518Z","shell.execute_reply":"2021-06-02T15:35:17.467468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummies = pd.get_dummies(data[cat_cols])\ndata = data.drop(cat_cols, axis = 1)\ndata = pd.concat([data, dummies], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:20.429661Z","iopub.execute_input":"2021-06-02T15:35:20.430047Z","iopub.status.idle":"2021-06-02T15:35:20.446533Z","shell.execute_reply.started":"2021-06-02T15:35:20.430011Z","shell.execute_reply":"2021-06-02T15:35:20.445447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:20.736504Z","iopub.execute_input":"2021-06-02T15:35:20.736909Z","iopub.status.idle":"2021-06-02T15:35:20.766413Z","shell.execute_reply.started":"2021-06-02T15:35:20.736873Z","shell.execute_reply":"2021-06-02T15:35:20.765293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split\n\nIt is important to split our data before filling the missing values to prevent data snooping.\n\ni will keep the test size as 0.2.","metadata":{}},{"cell_type":"code","source":"len(data) * 0.8","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:38.26208Z","iopub.execute_input":"2021-06-02T15:35:38.262499Z","iopub.status.idle":"2021-06-02T15:35:38.268382Z","shell.execute_reply.started":"2021-06-02T15:35:38.262461Z","shell.execute_reply":"2021-06-02T15:35:38.267199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# note that the data is already in ascending order in terms of release date\ntrain = data[:183]\ntest = data[183:]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:35:45.451728Z","iopub.execute_input":"2021-06-02T15:35:45.452093Z","iopub.status.idle":"2021-06-02T15:35:45.457107Z","shell.execute_reply.started":"2021-06-02T15:35:45.452062Z","shell.execute_reply":"2021-06-02T15:35:45.456262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill Missing Values","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:26:22.027327Z","iopub.execute_input":"2021-06-02T15:26:22.027865Z","iopub.status.idle":"2021-06-02T15:26:22.032101Z","shell.execute_reply.started":"2021-06-02T15:26:22.027814Z","shell.execute_reply":"2021-06-02T15:26:22.031211Z"}}},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:36:17.201724Z","iopub.execute_input":"2021-06-02T15:36:17.202096Z","iopub.status.idle":"2021-06-02T15:36:17.215042Z","shell.execute_reply.started":"2021-06-02T15:36:17.202064Z","shell.execute_reply":"2021-06-02T15:36:17.214117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Duration\"].fillna(train.Duration.mean(), inplace = True) ","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:37:20.324287Z","iopub.execute_input":"2021-06-02T15:37:20.324719Z","iopub.status.idle":"2021-06-02T15:37:20.331834Z","shell.execute_reply.started":"2021-06-02T15:37:20.324687Z","shell.execute_reply":"2021-06-02T15:37:20.330542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test","metadata":{}},{"cell_type":"code","source":"test.isna().sum().sum()\ntest[\"Duration\"].fillna(test.Duration.mean(), inplace = True) ","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:38:31.962373Z","iopub.execute_input":"2021-06-02T15:38:31.962802Z","iopub.status.idle":"2021-06-02T15:38:31.972931Z","shell.execute_reply.started":"2021-06-02T15:38:31.962765Z","shell.execute_reply":"2021-06-02T15:38:31.971593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = train.drop(\"rating\", axis = 1), train[\"rating\"]\nX_test, y_test = test.drop(\"rating\", axis = 1), test[\"rating\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T15:38:32.680509Z","iopub.execute_input":"2021-06-02T15:38:32.680894Z","iopub.status.idle":"2021-06-02T15:38:32.69027Z","shell.execute_reply.started":"2021-06-02T15:38:32.680862Z","shell.execute_reply":"2021-06-02T15:38:32.689054Z"},"trusted":true},"execution_count":null,"outputs":[]}]}