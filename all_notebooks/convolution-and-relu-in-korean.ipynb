{"cells":[{"metadata":{},"cell_type":"markdown","source":"---\n이 글은 kaggle의 Computer Vision 강의를 번역한 것입니다.\n\n(오역 및 잘못된 부분이 많으니 참고 바랍니다.)\n\n---"},{"metadata":{"lines_to_next_cell":0},"cell_type":"markdown","source":"<!--TITLE: Convolution and ReLU-->"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom itertools import product\n\ndef show_kernel(kernel, label=True, digits=None, text_size=28):\n    # Format kernel\n    kernel = np.array(kernel)\n    if digits is not None:\n        kernel = kernel.round(digits)\n\n    # Plot kernel\n    cmap = plt.get_cmap('Blues_r')\n    plt.imshow(kernel, cmap=cmap)\n    rows, cols = kernel.shape\n    thresh = (kernel.max()+kernel.min())/2\n    # Optionally, add value labels\n    if label:\n        for i, j in product(range(rows), range(cols)):\n            val = kernel[i, j]\n            color = cmap(0) if val > thresh else cmap(255)\n            plt.text(j, i, val, \n                     color=color, size=text_size,\n                     horizontalalignment='center', verticalalignment='center')\n    plt.xticks([])\n    plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction #\n\n지난 강의에서 합성곱(Convolutional) 분류기는 Convolution **base**와 dense 레이어의 **head** 두 부분으로 구성되어 있음을 확인했습니다. 우리는 base의 역할이 이미지에서 시각적 특징을 추출(Extract visual features)하는 것임을 배웠습니다. 그러면 Head가 이미지를 분류하는 데 사용합니다.\n\n다음 몇 가지 강의를 통해 합성곱(Convolutional) 이미지 분류기 base에서 일반적으로 찾을 수있는 가장 중요한 두 가지 유형의 레이어에 대해 알아볼 것입니다.\n1. **ReLU 활성화(Activiation)**가 있는 **Convolutional 레이어**\n2. **Maximum pooling 레이어**입니다. \n\n5강에서는 이러한 레이어를 특성 추출(Feature Extraction)을 수행하는 블록으로 구성하여 자신만의 Convnet을 설계하는 방법을 배웁니다.\n\n이 강의는 ReLU 활성화 기능이 있는 합성곱 레이어(Convolutional layer)에 대한 것입니다.\n\n\n# Feature Extraction #\n\n합성곱(Convolution)에 대해 자세히 알아보기 전에, 신경망에서 이런 레이어의 *목적*에 대해 토의하겠습니다. 세 가지 operation들을(Convolution, ReLU, 그리고 Maximum pooling) 사용하여 Feature Extraction 과정을 구현하는 방법을 살펴 보겠습니다.\n\nBase가 수행하는 **Feature Extraction**은 세 가지 기본 operation으로 구성됩니다.\n1. **Filter** : 하나의 특정 feature에 대한 이미지를 필터링합니다. (Convolution)\n2. **Detect** : 필터링된 이미지 내의 Feature를 탐지합니다. (ReLU)\n3. **Condense** : Feature 강화를 위해 이미지를 압축합니다. (Maximum pooling)\n\n다음 그림은 이 과정을 시각적으로 보여줍니다. 이 세 가지 작업이 원본 이미지의 특별한 특징(이 경우에는 수평선)을 분리하는 방법을 확인할 수 있습니다.\n\n<figure>\n<!-- <img src=\"./images/2-show-extraction.png\" width=\"1200\" alt=\"An example of the feature extraction process.\"> -->\n<img src=\"https://i.imgur.com/IYO9lqp.png\" width=\"600\" alt=\"An example of the feature extraction process.\">\n<figcaption style=\"textalign: center; font-style: italic\"><center>The three steps of feature extraction.</center></figcaption>\n</figure>\n\n일반적으로 네트워크는 단일 이미지에서 여러 추출을 병렬로 수행합니다. 현대의 Convnet에서 base의 최종 레이어가 1,000개 이상의 고유한 시각적 Feature들을 생성하는 것은 드문 일이 아닙니다.\n\n\n# Filter with Convolution #\n\n합성곱 레이어(Convolutional layer)는 필터링 단계를 수행합니다. Keras 모델에서 다음과 같이 합성곱 레이어를 정의할 수 있습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n    # More layers follow\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"레이어의 *가중치(Weights)*와 *활성화(Activiations)*의 관계를 살펴보면 이러한 파라미터들을 이해할 수 있습니다. 이제 살펴봅시다.\n\n## Weights ##\n\nConvnet이 학습(Training)하는 동안 사용하는 **가중치**는 주로 합성곱 레이어에 포함됩니다. 이러한 가중치를 우리는 **커널(Kernels)**이라고 부릅니다. 우리는 이것들을 작은 배열(Arrays)로 표현할 수 있습니다.\n\n<figure>\n<!-- <img src=\"./images/3-kernel.png\" width=\"150\" alt=\"A 3x3 kernel.\"> -->\n<img src=\"https://i.imgur.com/uJfD9r9.png\" width=\"150\" alt=\"A 3x3 kernel.\">\n</figure>\n\n커널은 이미지를 스캔하고 픽셀(pixel) 값의 *가중 합계(Weighted sum)*를 생성하여 작동합니다. 이런 식으로, 커널은 특정 패턴의 정보를 강조하거나 강조하지 않는 일종의 편광 렌즈처럼 작동합니다.\n\n<figure>\n<!-- <img src=\"./images/3-kernel-lens.png\" width=\"400\" alt=\"A kernel acts as a kind of lens.\"> -->\n<img src=\"https://i.imgur.com/j3lk26U.png\" width=\"250\" alt=\"A kernel acts as a kind of lens.\">\n<figcaption style=\"textalign: center; font-style: italic\"><center>A kernel acts as a kind of lens.</center></figcaption>\n</figure>\n\n커널은 합성곱 레이어가 다음 레이어에 연결되는 방식을 정의합니다. 위의 커널은 출력단에 있는 각 뉴런(neuron)을 9개의 입력 뉴런에 연결합니다. 커널 크기를 `kernel_size`로 설정하면 Convnet에 이러한 연결을 형성하는 방법을 알려줍니다. 대부분의 경우 커널은 -- `kernel_size = (3, 3)`또는`(5, 5)`와 같은 -- 홀수 차원을 가지므로 단일 픽셀이 중앙에 배치되는데 이는 필수 사항은 아닙니다.\n\n합성곱 레이어의 커널은 생성되는 feature의 종류를 결정합니다. 학습 동안에 Convnet은 분류 문제를 해결하는데 필요한 feature들을 배우려고 시도합니다. 이것은 커널에 가장 적합한 값을 찾는 것을 의미합니다.\n\n<!--TODO: Learning a kernel-->\n\n## Activations ##\n\n신경망의 활성화(Activations)는 **Feature Maps**으로 부릅니다. 이는 이미지에 필터를 적용한 결과입니다. \n\n여기에는 커널이 추출하는 시각적 Feature들이 포함되어 있습니다. 다음은 그들이 생성 한 Feature Map으로 묘사 된 몇 가지 커널입니다.\n\n<figure>\n<img src=\"https://i.imgur.com/JxBwchH.png\" width=\"800\" alt=\"Three kernels and the feature maps they produce.\"><figcaption style=\"textalign: center; font-style: italic\"><center>Kernels and features.</center></figcaption>\n</figure>\n\n커널의 패턴의 수를 통해, 당신은 커널이 생성하는 Feature maps의 종류를 말할 수 있습니다. 일반적으로 합성곱(Convolution)이 입력에서 강조하는 것은 커널의 *pisitive* 숫자들의 모양과 일치합니다. 위의 왼쪽 및 중간 커널은 모두 수평 모양을 필터링 합니다.\n\n`filters` 파라미터를 사용해서 출력으로 생성할 Feature map이 얼마나 있는지 합성곱 레이어에 알려줄 수 있습니다.\n\n\n# Detect with ReLU #\n\n필터링 과정 이후 Feature map들은 활성화 함수(Activiation Function)을 통과합니다. **Rectifier Function**은 아래와 같은 그래프입니다:\n\n<figure>\n<!-- <img src=\"./images/relu.png\" width=\"300\" alt=\"\"> -->\n<img src=\"https://i.imgur.com/DxGJuTH.png\" width=\"300\" alt=\"Graph of the ReLU activation function.\">\n<figcaption style=\"textalign: center; font-style: italic\"><center>The graph of the rectifier function looks like a line with the negative part \"rectified\" to 0.</center></figcaption>\n</figure>\n\nRectifier가 부착된 뉴런을 *Rectified Linear Unit*이라고 부릅니다. 이러한 배경때문에 Rectifier Function을 **ReLU activation** 혹은 아예 ReLU function으로 부르기도 합니다.\n\nReLU 활성화(Activation)는 자체 `Activation` 레이어로 정의될 수 있지만 대부분의 경우 `Conv2D`의 활성화 기능으로 포함합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu')\n    # More layers follow\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"활성화 함수(Activation Function)는 중요도에 따라 픽셀 값을 채점하는 것으로 생각할 수 있습니다. ReLU 활성화는 음수 값이 중요하지 않다는 것을 나타내므로 이를 0으로 설정합니다 ( \"중요하지 않은 모든 것은 똑같이 중요하지 않습니다.\").\n\n위의 Feature map을 적용한 ReLU는 다음과 같습니다. ReLU가 Feature들을 분리하는데 어떻게 성공하는지 확인하십시오.\n\n\n<figure>\n<!-- <img src=\"./images/3-relu-and-maps.png\" width=\"800\" alt=\"ReLU applied to feature maps.\"> -->\n<img src=\"https://i.imgur.com/dKtwzPY.png\" width=\"800\" alt=\"ReLU applied to feature maps.\">\n</figure>\n\n다른 활성화 함수와 마찬가지로 ReLU 함수는 **비선형(Non-linear)**입니다. 본질적으로 이것은 신경망에 모든 레이어의 전체 효과(Total Effect)가 그냥 모든 효과를 더하여 얻을 수 있는 것과 달라진다는 것을 의미합니다. -- 이것은 단일 레이어(single layer)로만 달성 할 수있는 것과 동일합니다. 비선형성은 Feature가 신경망 깊숙이 이동할 때 흥미로운 방식으로 결합되도록 합니다. (5강에서 이 \"Feature 합성(Feature Compounding)\"에 대해 자세히 살펴 보겠습니다.)\n\n\n# Example - Apply Convolution and ReLU #\n\n합성곱(Convolutional) 레이어가 \"뒤에서\" 수행하는 작업을 더 잘 이해하기 위해 아래 예제에서 직접 Extraction을 수행합니다.\n\n이 예제에 사용할 이미지는 다음과 같습니다:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\n\nimage_path = '../input/computer-vision-resources/car_feature.jpg'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(tf.squeeze(image), cmap='gray')\nplt.axis('off')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"필터링 단계에서는 커널을 정의한 다음 이것을 합성곱(Convolution)과 함께 적용합니다. 이 경우 커널은 \"Edge Detection\"커널입니다. Numpy에서 `np.array`로 배열을 정의하는 것처럼`tf.constant`로 정의 할 수 있습니다. 이것은 TensorFlow가 사용하는 종류의 *tensor*를 생성합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nkernel = tf.constant([\n    [-1, -1, -1],\n    [-1,  8, -1],\n    [-1, -1, -1],\n])\n\nplt.figure(figsize=(3, 3))\nshow_kernel(kernel)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TensorFlow는 `tf.nn` [module](https://www.tensorflow.org/api_docs/python/tf/nn)에 신경망이 수행하는 많은 기본 operation들을 포함하고 있습니다. 우리가 사용할 두 가지는 `conv2d`와 `relu`입니다. 이들은 단순히 Keras 레이어의 function 버전(역주: 함수로 제공한다는 뜻)입니다.\n\n다음 hidden cell은 TensorFlow와 호환되도록 형식을 다시 지정합니다. 이 예에서는 세부 정보가 중요하지 않습니다."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Reformat for batch compatibility.\nimage = tf.image.convert_image_dtype(image, dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nkernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\nkernel = tf.cast(kernel, dtype=tf.float32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"이제 커널을 적용하고 무슨 일이 일어나는지 봅시다."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_filter = tf.nn.conv2d(\n    input=image,\n    filters=kernel,\n    # we'll talk about these two in lesson 4!\n    strides=1,\n    padding='SAME',\n)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(tf.squeeze(image_filter))\nplt.axis('off')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"다음은 ReLU 기능을 사용한 Detection 단계입니다. 이 함수는 설정할 파라미터가 없기 때문에 합성곱(Convolution)보다 훨씬 간단합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_detect = tf.nn.relu(image_filter)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(tf.squeeze(image_detect))\nplt.axis('off')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature map을 만들었습니다! 이와 같은 이미지는 Head가 분류 문제(Classification problem)를 해결하는 데 사용하는 것입니다. 특정 Feature는 *차(Cars)*의 특징이고 다른 Feature는 *트럭(Trucks)*의 특징 일 수 있습니다. 학습 중 Convnet의 임무는 이러한 기능을 찾을 수있는 커널을 만드는 것입니다.\n\n\n# Conclusion #\n\n이 강의에서 Convnet이 Feature Extraction을 수행하는 데 사용하는 처음 두 단계를 배웠습니다.\n- `Conv2D` 레이어로 **filter**\n- `relu` 활성화로 **detect**\n\n\n# Your Turn #\n\n[**2강 실전 문제**](https://www.kaggle.com/kernels/fork/11989557)에서 1강에서 사용한 사전 훈련된 VGG16 모델의 커널을 실험해볼 기회가 있습니다."},{"metadata":{},"cell_type":"markdown","source":"---\n\n*질문이나 코멘트가 있다면, 저에게 문의 주시거나 댓글을 남겨주세요. 혹은 한국 [Vision & AI Study(VAIS) 그룹](https://v-ais.github.io)에서 자유롭게 토론해주세요.\n\n*원문에 대해서는 [Learn Discussion forum](https://www.kaggle.com/learn-forum)을 방문하여 다른 학습자들과 토론해주세요.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}