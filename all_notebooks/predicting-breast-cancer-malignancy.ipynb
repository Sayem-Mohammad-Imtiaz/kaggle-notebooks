{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","file_extension":".py","name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python"},"_is_fork":false,"_change_revision":0,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"cells":[{"metadata":{"_uuid":"69c15131971484dcc6732e263280bd24e30f9d8b","_cell_guid":"10baa3ff-22cf-265c-9057-c20a6732efe9"},"cell_type":"markdown","source":"This project attempts to predict if a breast cancer mass is Malignant or Benign based on 30 features of the cell nuclei as gathered using a fine needle aspirate method. We have a 569 record dataset that is used for the training, test, and cross validation steps. \n\nWe include all available predictor versions in our model <b>(<i>Mean, Standard Error, and Worst</i>)</b> for the 10 core predictors (<b>Radius, Texture, Perimeter, Area, Smoothness, Compactness, Concavity, Concave Points, Symmetry, and Fractal Dimension</b>).\n\n<b>Findings</b>: Including all available predictor versions in our model (Mean, Standard Error, and Worst) for the 10 core predictors (Radius, Texture, Perimeter, Area, Smoothness, Compactness, Concavity, Concave Points, Symmetry, and Fractal Dimension) we achieve a <b>~99.42% accuracy with Multilayer Perceptron Classification with a cross-validation score of ~95%</b> (the same cv score as our Random Forest, but a much higher testing accuracy).  Our Random Forest Classifier <b>accuracy of ~98%</b> and a <b>cross-validation score of ~95%</b>.   SVM achieves the lowest accuracy of ~96%. \n\nacknowledgments: Thanks to Buddhini W. for a well-articulated treatment of this dataset-  [1st Place Kaggle Submission - author: Buddhini W.](https://www.kaggle.com/buddhiniw/d/uciml/breast-cancer-wisconsin-data/breast-cancer-prediction)"},{"metadata":{"_uuid":"93c24a407286ac8245a4b73119210fd2b3b85798","_cell_guid":"4c7099f5-9d74-358b-8ba5-bc2aac2d2d3a"},"cell_type":"markdown","source":"<h6> Dataset Description </h6>\n<p> source: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29<br>\nsource: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data<br>\n1st place submission: https://www.kaggle.com/buddhiniw/d/uciml/breast-cancer-wisconsin-data/breast-cancer-prediction<br>\n\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) \nof a breast mass. They describe characteristics of the cell nuclei present \nin the image. n the 3-dimensional space is that described in: \n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of \nTwo Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server: \n    ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n\nAlso can be found on UCI Machine Learning Repository: \n    https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\nAttribute Information:\n\n1) ID number 2) Diagnosis (M = malignant, B = benign) \n\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)<br> \nb) texture (standard deviation of gray-scale values)<br> \nc) perimeter<br> \nd) area<br> \ne) smoothness (local variation in radius lengths)<br> \nf) compactness (perimeter^2 / area - 1.0)<br> \ng) concavity (severity of concave portions of the contour)<br> \nh) concave points (number of concave portions of the contour)<br> \ni) symmetry<br> \nj) fractal dimension (\"coastline approximation\" - 1)<br>\n\nThe mean, standard error and \"worst\" or largest (mean of the three largest values)\nof these features were computed for each image, resulting in 30 features.\nFor instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n"},{"metadata":{"_uuid":"dadc587121036a50a5c7eab9d404c3220d7f08e7","_cell_guid":"6bbdb8cb-c699-32fa-0f67-cda3d278c732","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as s\nfrom sklearn import cross_validation\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.cross_validation import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\nimport matplotlib.pyplot as plt"},{"metadata":{"_uuid":"3b523a36a203ebec9f8a2066c15c2121cabbef7e","_cell_guid":"f5c7bb60-e1aa-6530-3eb5-2795a998a4fa","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#%% Get and Clean Data\n\n#Read data as pandas dataframe\nd = pd.read_csv('../input/data.csv')\n\ndf = d.drop('Unnamed: 32', axis=1)\n\n#if using diagnosis as categorical\ndf.diagnosis = df.diagnosis.astype('category')\n\n#Create references to subset predictor and outcome variables\nx = list(df.drop('diagnosis',axis=1).drop('id',axis=1))\ny ='diagnosis'\n\n# -- Feature Normalization / Scaling -----------------------------------------\n#  Normalize features for SVM and MLPClassifier\n#-----------------------------------------------------------------------------\ndf2 = df[x]\ndf_norm = (df2 - df2.mean()) / (df2.max() - df2.min())\ndf_norm = pd.concat([df_norm, df[y]], axis=1)\n#-----------------------------------------------------------------------------\n\n#show first 10 rows\ndf.head(10)"},{"metadata":{"_uuid":"51585d606c04938a0acb6e08968e27d1180b1af8","_cell_guid":"a7252265-42cc-1096-ed06-0d1cad8def9c","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#Explore correlations\nplt.rcParams['figure.figsize']=(12,8)\ns.set(font_scale=1.4)\ns.heatmap(df.drop('diagnosis', axis=1).drop('id',axis=1).corr(), cmap='coolwarm')"},{"metadata":{"_uuid":"2d92bd3be2fe79f6a9cfc2ed08c57112d020625a","_cell_guid":"ff3e30b5-bcc5-1109-41a3-56ccc13106a3"},"cell_type":"markdown","source":"**<h4> Mean versions of the 10 Core Predictors </h4><br>**\nThe below boxplots are of the \"mean\" value for the 10 core features in the dataset.  These are ranked as the most important features in the model we fit (see Feature Importances below) in terms of classifying the breast cancer mass as Malignant (M) or Benign (B). \n\nThe charts reveal a tendency for the average value of a feature to be generally higher for malignant diagnoses vs. the benign class. This is true for every feature except for <b> Fractal Dimension Mean</b> which shows a flat difference between M and B diagnoses for the mean value of the feature.  <b>Radius Mean</b> on the other hand shows a more distinct distribution for M vs. B diagnoses, as is subsequently found to be the most important feature according to our fitted Random Forest model further below (see cell [18]: below).  "},{"metadata":{"_uuid":"40173f920809de6a06beb200197ba2413e93ec27","_cell_guid":"4422914c-fc33-833d-5e68-0e3df569db9a","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"plt.rcParams['figure.figsize']=(10,5)\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='radius_mean',data=df, ax=ax1)\ns.boxplot('diagnosis',y='texture_mean',data=df, ax=ax2)\ns.boxplot('diagnosis',y='perimeter_mean',data=df, ax=ax3)\ns.boxplot('diagnosis',y='area_mean',data=df, ax=ax4)\ns.boxplot('diagnosis',y='smoothness_mean',data=df, ax=ax5)\nf.tight_layout()\n\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='compactness_mean',data=df, ax=ax2)\ns.boxplot('diagnosis',y='concavity_mean',data=df, ax=ax1)\ns.boxplot('diagnosis',y='concave points_mean',data=df, ax=ax3)\ns.boxplot('diagnosis',y='symmetry_mean',data=df, ax=ax4)\ns.boxplot('diagnosis',y='fractal_dimension_mean',data=df, ax=ax5)    \nf.tight_layout()"},{"metadata":{"_uuid":"edbad839e87127ed3073681e75d0c261634bc35c","_cell_guid":"8d5a4b26-e27a-7646-bb41-45649742949c"},"cell_type":"markdown","source":"**<h4> Standard Error versions of the 10 Core Predictors </h4><br>**\nVisualizing the <i>Standard Error</i> feature columns below, we see much larger spreads between the max values and the average values of the vectors than observed in the <i> Mean </i> above.  \n\nWe also see some similarity in average values for M vs. B in some of these standard error derived features that we did not observe in the mean derived features. For example, below <b>Texture SE</b> shows a similar flatness across the mean value for M vs. B. \n\n<b>Smoothness SE</b> also has a much smaller difference in mean value for M vs. B.  In the case of <b>Symmetry SE</b> the average for M is actually smaller than that for B, which is the opposite dynamic of the <b>Symmetry Mean</b> feature as seen above.  "},{"metadata":{"_uuid":"c6ef83cea86e1c9ff8bb36e6a7cd6b66ff9c2734","_cell_guid":"355c65e8-f2fe-35c0-8f93-4692ee83da93","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#%%\nplt.rcParams['figure.figsize']=(10,5)\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='radius_se',data=df, ax=ax1, palette='cubehelix')\ns.boxplot('diagnosis',y='texture_se',data=df, ax=ax2, palette='cubehelix')\ns.boxplot('diagnosis',y='perimeter_se',data=df, ax=ax3, palette='cubehelix')\ns.boxplot('diagnosis',y='area_se',data=df, ax=ax4, palette='cubehelix')\ns.boxplot('diagnosis',y='smoothness_se',data=df, ax=ax5, palette='cubehelix')\nf.tight_layout()\n\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='compactness_se',data=df, ax=ax2, palette='cubehelix')\ns.boxplot('diagnosis',y='concavity_se',data=df, ax=ax1, palette='cubehelix')\ns.boxplot('diagnosis',y='concave points_se',data=df, ax=ax3, palette='cubehelix')\ns.boxplot('diagnosis',y='symmetry_se',data=df, ax=ax4, palette='cubehelix')\ns.boxplot('diagnosis',y='fractal_dimension_se',data=df, ax=ax5, palette='cubehelix')    \nf.tight_layout()"},{"metadata":{"_uuid":"b0a88a927c9087421891b74a07a75a7be4a4d75a","_cell_guid":"965e861c-3653-c7b2-8a0f-b3f412feafe1"},"cell_type":"markdown","source":"**<h4> Worst versions of the 10 Core Predictors </h4><br>**\nFinally we look at the <i> Worst</i> set of features for the 10 core metrics.  Interestingly, these features show more similar vector distribution to the <i>Mean</i> columns than do the <i>Standard Error</i> columns; however, they are ranked lower in feature importance than the <i>Standard Error</i> predictors.  \n\nA visual inspection shows that the average values of the vectors shows a similar tendency for higher average values for diagnosis == M vs. diagnosis == B.  Given this similarity in distribution to the most important <i>Mean</i> features, and taking into account the low importance ranking even compared to <i>SE</i> features, we decide to include all available predictors to achieve an improved accuracy that may capture dynamics previously unaccounted for by the classifier's ranking of the predictors' importances (see Feature Importances below).\n\n<i><b>Of note:</b></i> Note that the <b>Fractal Dimension</b> core metric only shows a similar dynamic of higher avg. value for M vs. B when looking at the <b>Fractal Dimension Worst </b> feature values.  "},{"metadata":{"_uuid":"7eedfe271cf26dd2278dc062c302dba76fba6eda","_cell_guid":"426cea5c-54ea-e201-b72f-faa77d526069","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"plt.rcParams['figure.figsize']=(10,5)\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='radius_worst',data=df, ax=ax1, palette='coolwarm')\ns.boxplot('diagnosis',y='texture_worst',data=df, ax=ax2, palette='coolwarm')\ns.boxplot('diagnosis',y='perimeter_worst',data=df, ax=ax3, palette='coolwarm')\ns.boxplot('diagnosis',y='area_worst',data=df, ax=ax4, palette='coolwarm')\ns.boxplot('diagnosis',y='smoothness_worst',data=df, ax=ax5, palette='coolwarm')\nf.tight_layout()\n\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='compactness_worst',data=df, ax=ax2, palette='coolwarm')\ns.boxplot('diagnosis',y='concavity_worst',data=df, ax=ax1, palette='coolwarm')\ns.boxplot('diagnosis',y='concave points_worst',data=df, ax=ax3, palette='coolwarm')\ns.boxplot('diagnosis',y='symmetry_worst',data=df, ax=ax4, palette='coolwarm')\ns.boxplot('diagnosis',y='fractal_dimension_worst',data=df, ax=ax5, palette='coolwarm')    \nf.tight_layout()"},{"metadata":{"_uuid":"c490a06db3b6fa9629fb8ee579bc294e11760443","_cell_guid":"fd39c603-f1de-4c6c-40ec-10f812852c2d"},"cell_type":"markdown","source":"<hr>\n<center><h3><i> Fitting a Random Forest Classifier </i></h3></center>\n\nBelow, we fit a RandomForestClassifier() with 1000 trees (n_estimators=1000) and then cross-validate using sklearn's native `cross_val_score()` function.\n\nHere we are looking at all predictors, that is 3 versions of the 10 core predictors totaling 30 features. "},{"metadata":{"_uuid":"ff2e5a09e272b703c2329f06322c029b6febda5d","_cell_guid":"a0792332-ba1b-5be9-2473-487271ec6b3e","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#--------------------------------------------------------------------------------------#\n# Train Random Forest\nnp.random.seed(10)\n\ntraindf, testdf = train_test_split(df, test_size = 0.3)\n\nx_train = traindf[x]\ny_train = traindf[y]\n\nx_test = testdf[x]\ny_test = testdf[y]\n\nforest = RandomForestClassifier(n_estimators=1000)\nfit = forest.fit(x_train, y_train)\naccuracy = fit.score(x_test, y_test)\npredict = fit.predict(x_test)\ncmatrix = confusion_matrix(y_test, predict)\n\n#--------------------------------------------------------------------------------------#\n# Perform k fold cross-validation\n\n\nprint ('Accuracy of Random Forest: %s' % \"{0:.2%}\".format(accuracy))\n\n# Cross_Validation\nv = cross_val_score(fit, x_train, y_train, cv=10)\nfor i in range(10):\n    print('Cross Validation Score: %s'%'{0:.2%}'.format(v[i,]))"},{"metadata":{"_uuid":"77a70875edc3ddb9c5e80eb16a6a2a41f0deee9f","_cell_guid":"9ef9d70d-30c2-118b-b179-5b92092c7804"},"cell_type":"markdown","source":"A visualization of the confusion matrix below reveals the <b>1.75% error</b> is the result of our model misclassifying 3 cases as Malignant when they were actually Benign.  \n\nWe see; however, that our classification accuracy for a mass being Benign when it is actually Benign is a perfect 100%.  However, the cross-validation performed above reveals a higher expected out-of-sample error (~4.2%) so we expect that further tests of this model on fresh data will likely be accompanied by either some misclassifications of Benign cases as well as Malignant, or greater increase in false positives where Benign cases are classified as Malignant.  "},{"metadata":{"_uuid":"db23a3b53754309970237d11a276a1e55aad5f5c","_cell_guid":"236c67b6-5e46-4ca4-db6f-77306fbd3070","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"plt.rcParams['figure.figsize']=(14,8)\nax = plt.axes()\ns.heatmap(cmatrix, annot=True, fmt='d', ax=ax, cmap='BrBG', annot_kws={\"size\": 30})\nax.set_title('Random Forest Confusion Matrix')"},{"metadata":{"_uuid":"5406f2bbdc808f2da2822ad6ca0b7e4bb8f1d7f0","_cell_guid":"bb3c584c-ffa0-7e2a-4585-e81c25e81474","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#%%Feature importances\nimportances = forest.feature_importances_\nindices = np.argsort(importances)[::-1]\n\nprint(\"Feature ranking:\")\nfor f in range(traindf[x].shape[1]):\n    print(\"feature %s (%f)\" % (list(traindf[x])[f], importances[indices[f]]))"},{"metadata":{"_uuid":"fe531382d7c9ebf948be3d944214d2c3be4e0b8a","_cell_guid":"bef3ed20-1e59-f2a0-e28c-ba2b8c2e1356"},"cell_type":"markdown","source":"Gini Importances of our predictors sorted descending as derived from our Random Forest model.  \n\nDespite the high importance of ‘Mean’ features, we forego eliminating features based on low importance (according to RF classifier) and/or potential multi-collinearity.  Feature optimization is covered in prior research, and our goal is to test accuracy using all features."},{"metadata":{"_uuid":"ecbfec73d97fb608ab07a2a599d818103b2d3f54","_cell_guid":"735fa19c-4840-886b-118c-fb1a65432288","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"feat_imp = pd.DataFrame({'Feature':list(traindf[x]),\n                        'Gini importance':importances[indices]})\nplt.rcParams['figure.figsize']=(8,12)\ns.set_style('whitegrid')\nax = s.barplot(x='Gini importance', y='Feature', data=feat_imp)\nax.set(xlabel='Gini Importance')\nplt.show()"},{"metadata":{"_uuid":"2acb50d57dba915b8e0ba4af3944ab13a01031dc","_cell_guid":"a8085f16-9dfe-351d-30ad-a1d3fcdedb99"},"cell_type":"markdown","source":"**<hr>\n<center><h3><i> Fitting a Support Vector Machine </i></h3></center>**"},{"metadata":{"_uuid":"7eba128509fce0d8c184fd69705d95ab0f6afc20","_cell_guid":"2458d8e0-bd9d-20d0-fdc7-55aad812c8ff","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#---------------------------------------------------------------------------------------#\n# Train Support Vector Machine ---------------------------------------------------------#\n#---------------------------------------------------------------------------------------#\n\nnp.random.seed(10)\n\ntraindf, testdf = train_test_split(df_norm, test_size = 0.3)\n\nx_train = traindf[x]\ny_train = traindf[y]\n\nx_test = testdf[x]\ny_test = testdf[y]\n\nsvmf = svm.SVC()\nsvm_fit = svmf.fit(x_train, y_train)\naccuracy = svm_fit.score(x_test, y_test)\npredict = svm_fit.predict(x_test)\nsvm_cm = confusion_matrix(y_test, predict)\n\n#--------------------------------------------------------------------------------------#\n# Perform k fold cross-validation\nprint ('Accuracy of Support Vector Machine: %s' % \"{0:.2%}\".format(accuracy))\n\n# Cross_Validation\nv = cross_val_score(svm_fit, x_train, y_train, cv=10)\nfor i in range(10):\n    print('Cross Validation Score: %s'%'{0:.2%}'.format(v[i,]))"},{"metadata":{"_uuid":"91d83d1f9c5e87c8114d4d02484a25d9d62772e8","_cell_guid":"efda6223-8333-52f3-e9a0-4fdce34f1ee4","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#   Visualize SVM Confusion Matrix\nplt.rcParams['figure.figsize']=(14,8)\nax = plt.axes()\ns.heatmap(svm_cm, annot=True, fmt='d', ax=ax, cmap=\"YlGnBu\", annot_kws={\"size\": 30})\nax.set_title('Support Vector Machine Confusion Matrix')"},{"metadata":{"_uuid":"fee9fc1a35782204aff4f85a38d717ca56e4d2a0","_cell_guid":"79306430-7e95-9cde-9f74-ae32a6b8da80"},"cell_type":"markdown","source":"**<hr>\n<center><h3><i> Fitting an MLP Classifier </i></h3></center>**"},{"metadata":{"_uuid":"58a7738858892af298358fdad1d44c5ab129463a","_cell_guid":"da048ceb-c15e-09bf-9361-01e7f3b5b8a5","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"\n#---------------------------------------------------------------------------------------#\n# Train MLPClassifier ------------------------------------------------------------------#\n#---------------------------------------------------------------------------------------#\nnp.random.seed(10)\n\ntraindf, testdf = train_test_split(df_norm, test_size = 0.3)\n\nx_train = traindf[x]\ny_train = traindf[y]\n\nx_test = testdf[x]\ny_test = testdf[y]\n\nclf = MLPClassifier(solver='lbfgs', alpha=5, hidden_layer_sizes=(500,), random_state=10)\nmlp_fit = clf.fit(x_train, y_train)\naccuracy = mlp_fit.score(x_test, y_test)\npredict = mlp_fit.predict(x_test)\nmlp_cm = confusion_matrix(y_test, predict)\n\n#--------------------------------------------------------------------------------------#\n# Perform k fold cross-validation\nprint ('Accuracy of Multilayer Perceptron: %s' % \"{0:.2%}\".format(accuracy))\n\n# Cross_Validation\nv = cross_val_score(mlp_fit, x_train, y_train, cv=10)\nfor i in range(10):\n    print('Cross Validation Score: %s'%'{0:.2%}'.format(v[i,]))"},{"metadata":{"_uuid":"84caadbcfdac2423dd666078afc929c4da75a6f9","_cell_guid":"928cb467-f0a2-988f-4a21-bb1c3a4a4588","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#   Visualize MLP Confusion Matrix\nplt.rcParams['figure.figsize']=(14,8)\nax = plt.axes()\ns.heatmap(mlp_cm, annot=True, fmt='d', ax=ax, annot_kws={\"size\": 30})\nax.set_title('Multilayer Perceptron Confusion Matrix')"},{"metadata":{"_uuid":"88da226192387038d52be202b044cbf67f945aa7","_cell_guid":"1e7ccba7-75a8-55d2-828d-743c89c1cb79"},"cell_type":"markdown","source":"**<h4><i>Conclusions and Remarks for Future Research:</i></h4>**\n\nIn spite of the higher importance of <i>Mean</i> category features, we find a high accuracy and cross-validation score by including all available predictor versions in our model <b>(<i>Mean, Standard Error, and Worst</i>)</b> for the 10 core predictors (<b>Radius, Texture, Perimeter, Area, Smoothness, Compactness, Concavity, Concave Points, Symmetry, and Fractal Dimension</b>).  \n\nWhile our <b>Multilayer Perceptron Classifier</b> has the highest accuracy of <b>99.42%</b>, our study, uses a very small dataset of only 569 observations that need to be used for both the training and test dataframes. Further adjustments may likely be necessary with increased data size. In addition, we may be able to improve accuracy incrementally by further paramater optimization (i.e. testing many different levels of Alpha penalty in the MLPClassifier).\n\nIt would also be of use to understand how our SVM classifier achieves 100% accuracy for predicting Malignant data records while having a higher error for Benign classifications alone than our Random Forest and Multilayer Perceptron classifiers which have a 100% accuracy on predicting Benign records, but show error in predicting Malignant.\n\nFurthermore, detail on the additional measurements that can be acquired by the FNA (Fine Needle Aspirate) technique on breast cancer mass nuclei should be explored."},{"metadata":{"_uuid":"cf7897461fcd3aebc6fc0dd057f40ae2798fa85d","_cell_guid":"d98b843e-5381-2837-741f-da95e281d55d"},"cell_type":"markdown","source":"----------\n**Appendix**"},{"metadata":{"_uuid":"f6a559556b6d35ab6e4026d917ff79a7d5549ac0","_cell_guid":"ae6b1183-3ac0-0fe5-dc2c-545670becf7a","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"diagnosis = df['diagnosis']\nmean_cols = [col for col in df.columns if 'mean' in col]\nmeandf = pd.concat([diagnosis,df[mean_cols]], axis=1)\n\nplt.rcParams['figure.figsize']=(12,12)\ng = s.PairGrid(meandf, hue=\"diagnosis\")\ng.map_diag(plt.hist)\ng.map_offdiag(plt.scatter)\ng.add_legend();\n\nplt.tight_layout()"},{"metadata":{"_uuid":"50d5ec4991e867c9044ad672c4dfe4f71723fd6c","_cell_guid":"77173118-6a7f-0ffc-4819-230f5ff7451c","collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""}],"nbformat_minor":1}