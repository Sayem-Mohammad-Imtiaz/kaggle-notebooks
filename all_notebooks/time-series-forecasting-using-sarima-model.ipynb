{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Time Series Forecasting Using SARIMA Model\n\n**Problem Statement** - Forecast airlines Passangers for next 36 months.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        full_filepath = os.path.join(dirname, filename)\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read AirPassangers data\nts = pd.read_csv(os.path.join(full_filepath),parse_dates=[\"Month\"], index_col=\"Month\")\ndisplay(ts.shape)\nprint(ts.head())\nprint('Timeseries Range => ', ts.index.min(), ' - ' , ts.index.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Initial Plot ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_ts_plot(timeseries, xlabel ='Date', ylabel ='Value', title =\"\", dpi=120):\n    plt.figure(figsize=(16,5),dpi=dpi)\n    plt.plot(timeseries, color='red')\n    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n    plt.show()\n\ndraw_ts_plot(ts, xlabel=\"Dates in Month\", ylabel = \"Passanger Counts\", title=\"Monthly Airlines passange Counts\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot clearly shows that there is upward trend and seasonal data. Lets see year wise trend.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"years = ts.index.year.unique()\nplt.figure(figsize=(16,5),dpi=120)\nfor year in years:\n    plt.plot(ts.index[ts.index.year == year].month,\n    ts[ts.index.year == year]['#Passengers'], label = year )\n\nplt.gca().set(title = \"Yearly Trend\")\nplt.legend(loc='right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot clearly shows there is seasonal data avaiable in airline passanger data.May to September are showing spike in passanger counts. Let decompose timeseries data and display","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\n# additive decomposition\nresult_additive = seasonal_decompose(ts,model='additive', extrapolate_trend='freq')\n\n# multiplicative\nresult_multiplicative = seasonal_decompose(ts,model='multiplicative', extrapolate_trend='freq')\n\n# plot\nplt.rcParams.update({'figure.figsize':(20,8)})\nresult_additive.plot()\nplt.suptitle('Additive Seasonal Decompose', fontsize=12)\nplt.show()\n\nresult_multiplicative.plot()\nplt.suptitle('Multiplicative Seasonal Decompose', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residual of additive decomposition still shwoing some trend, hence considering multiplicative residual data. lets extract component to data frame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_multiplicative = pd.concat([\n    result_multiplicative.observed, \n    result_multiplicative.trend, \n    result_multiplicative.seasonal, \n    result_multiplicative.resid], axis= 1)\ndf_multiplicative.columns  = ['actual', 'trend','seasonal','resid']\ndf_multiplicative.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split Train and Test Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = ts[0:-36]\ntest = ts[-36:]\nprint('Train Timeseries Range => ', train.index.min(), ' - ' , train.index.max())\nprint('Train Timeseries Range => ', test.index.min(), ' - ' , test.index.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dickey-Fuller test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# regression{“c”,”ct”,”ctt”,”nc”}\n# Constant and trend order to include in regression.\n\n# “c” : constant only (default).\n# “ct” : constant and trend.\n# “ctt” : constant, and linear and quadratic trend.\n# “nc” : no constant, no trend.\n\nfor reg in [\"c\",\"ct\",\"ctt\",\"nc\"]:\n    res = sm.tsa.adfuller(train.dropna(),regression=reg)\n    print('Reg - {}\\t adf :{} - lag used : {}, Critical value : {}'.format(reg, res[0],res[2],res[4]))\n    res = sm.tsa.adfuller(train.diff().dropna(),regression=reg)\n    print('Reg diff - {}\\t adf :{} - lagused : {}, Critical value : {}'.format(reg, res[0],res[2],res[4]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since seasional data is available, SARIMA Model will best suit. Autocorrelogram & Partail Autocorrelogram will helpful to estimate parameters for the models \n\nAutocorrelogram - Plots lags on the horizontal and the correlations on vertical axis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1, figsize =(18, 10))\nfig = sm.graphics.tsa.plot_acf(train.diff().dropna(), lags=15, ax=ax[0])\nfig = sm.graphics.tsa.plot_pacf(train.diff().dropna(), lags=15, ax=ax[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nres = sm.tsa.arma_order_select_ic(train, max_ar=7, max_ma=7, ic=['aic'], trend='nc')\nprint(res['aic_min_order'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arima = sm.tsa.statespace.SARIMAX(train,order=(6,1,7), seasonal_order=(2,1,0,12),\n                                 enforce_stationarity=False, enforce_invertibility=False,).fit()\n#arima.summary()\nfrom sklearn.metrics import mean_squared_error\npred_train = arima.predict(train.index.min(), train.index.max())\npred_test = arima.predict(test.index.min(), test.index.max())\nplt.title('ARIMA model MSE:{}'.format(mean_squared_error(test,pred_test)))\nplt.plot(train, label='train')\nplt.plot(pred_train, color='orange', linestyle='--', label= 'train prediction')\nplt.plot(pred_test, color='red', linestyle='--', label= 'prediction')\nplt.plot(test, color='green', label='actual')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}