{"cells":[{"metadata":{"tags":[]},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/adult-dataset/adult.csv\", header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Rename Column Names"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', \\\n           'occupation', 'relationship', 'race', 'gender', 'gain', 'loss', 'hpw', 'country', \\\n           'income']\n# gain    ==> capital gain\n# loss    ==> capital loss\n# hpw     ==> hours per week\n# country ==> native country\ndf.columns = columns","execution_count":null,"outputs":[]},{"metadata":{"tags":[]},"cell_type":"markdown","source":"# Column Values Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_count(X):\n    L = len(X)\n    ms = X.isnull().sum()    \n    df = {\"Name\":X.columns, \"Total\":[L]*X.shape[1], \"Missing\":ms, \"Missing(%)\":round(ms/L*100, 2), \"Dtypes\":X.dtypes}\n    df = pd.DataFrame(df)\n    return df\nmissing_count(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Well it's look like there are no missing values in dataset, but there are some, we will look it further"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [col for col in df.columns if df[col].dtype == \"O\"]\nprint(categorical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = [col for col in df.columns if df[col].dtype != \"O\"]\nprint(numerical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Unique Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical:\n    print(\"=====\", col, \"=====\")\n    print(df[col].unique(), end=\"\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Let's remove first space from every value in all categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical:\n    def mapper(val):\n        return val[1:]\n    df[col] = df[col].apply(mapper)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There are \"?\" value in [\"workclass\", \"occupation\", \"country\"] features\nThese are missing values"},{"metadata":{},"cell_type":"markdown","source":"## \"workclass\", \"occupation\", \"country\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"workclass\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Means there are 1836 missing values in \"workclass\" column"},{"metadata":{"trusted":true},"cell_type":"code","source":"1836 / len(df) * 100  #  % values missing\n# We will take care about it later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"occupation\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Means there are 1843 missing values in occupation column"},{"metadata":{"trusted":true},"cell_type":"code","source":"1843 / len(df) * 100  #  % values missing\n# We will take care about it later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"country\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Means there are 583 missing values in country column"},{"metadata":{"trusted":true},"cell_type":"code","source":"583 / len(df) * 100  #  % values missing\n# We will take care about it later","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Replace all \"?\" with np.NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in [\"workclass\", \"occupation\", \"country\"]:\n    df[col].replace(\"?\", np.NaN, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in [\"workclass\", \"occupation\", \"country\"]:\n    print(df[col].unique(), end=\"\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## \"income\" Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"income\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mapper(val):\n    if(val == \"<=50K\"):\n        return 0\n    else:\n        return 1\ndf[\"income\"] = df[\"income\"].apply(mapper)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Null values Filling using mode"},{"metadata":{},"cell_type":"raw","source":"Let's first see how many rows(with atleast 1 null value) in dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"null_rows = []\nfor i in range(len(df)):\n    if(df.loc[i].isnull().sum()):\n        null_rows.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(null_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(null_rows) / len(df) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"means there are 7.36% rows have atleast one feature missing"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_count(df)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"for i in [\"workclass\", \"occupation\", \"country\"]:\n    df[i].fillna(df[i].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_count(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Buliding"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop([\"income\"], axis=1)\ny = df[\"income\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\nencoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship', \n                                 'race', 'gender', 'country'])\nX = encoder.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 77)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\nrobust = RobustScaler()\nX_train = robust.fit_transform(X_train)\nX_test = robust.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.DataFrame(X_train, columns=[cols])\nX_test = pd.DataFrame(X_test, columns=[cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gnb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"train score\", gnb.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"test score\", gnb.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxi = y_train.value_counts().idxmax()\nnull_acc = y_test.value_counts()[maxi] / y_test.shape[0]\nprint(\"Null Accuracy: \", null_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ndef confusion_heatmap(y_test, y_pred, label_mapping=None, normalize=None):\n    labels = np.unique(np.concatenate((np.unique(y_test), np.unique(y_pred)), axis=0))\n    cm = confusion_matrix(y_test, y_pred, labels=labels, normalize=normalize)\n    \n    mapping = labels\n    if(label_mapping):\n        mapping = [name_mapping[l] for l in labels]\n\n    d = pd.DataFrame(cm)\n    d.columns = mapping\n    d.index = mapping\n\n    sns.heatmap(d, annot=True, fmt=\".4g\", cmap=\"Blues\", )\n    plt.ylabel('True label',fontsize=12)\n    plt.xlabel('Predicted label',fontsize=12)\n    plt.show();\nconfusion_heatmap(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nround(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\nTP = cm[0,0]\nTN = cm[1,1]\nFP = cm[0,1]\nFN = cm[1,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\nclassification_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_error = (FP + FN) / float(TP + TN + FP + FN)\nclassification_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = TP / float(TP + FP)\nprecision","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recall = TP / float(TP + FN)\nrecall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_positive_rate = TP / float(TP + FN)\ntrue_positive_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate = FP / float(FP + TN)\nfalse_positive_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specificity = TN / (TN + FP)\nspecificity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gnb.predict_proba(X_test)[:, 1]\n\nplt.rcParams['font.size'] = 12\nplt.hist(y_pred, bins =10)\nplt.title('Histogram of predicted probabilities of 1')\nplt.xlim(0,1)\nplt.xlabel('Predicted probabilities of 1')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n\nplt.figure(figsize=(6,4))\nplt.plot(fpr, tpr, linewidth=2)\nplt.plot([0,1], [0,1], 'k--' )\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Gaussian Naive Bayes Classifier for Predicting Salaries')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nROC_AUC = roc_auc_score(y_test, y_pred)\nROC_AUC","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}