{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install simpletransformers==0.40.0\n!pip install transformers\n!pip install tensorflow==2.1.0\n!pip install tokenizers==0.7.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!export CUDA_HOME=/usr/local/cuda-10.1\n!git clone https://github.com/NVIDIA/apex\n%cd apex\n!pip install -v --no-cache-dir ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import logging\n\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Я смог найти дополнительные данные здесь же на каггле https://www.kaggle.com/shivamb/real-or-fake-fake-jobposting-prediction, которые прекрасно коррелировали с задачей этого соревнования. Плюс найденный датасет был больше того, что выдавался организаторами. В итоге было принято решение обучаться на нем"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/test-data-for-fake-jobs/train_data.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим сколько у нас отсутствующих значений"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на отношение реальных объявлений к фейковым"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nprint(df[\"Фейк\"].value_counts())\nsns.barplot(df[\"Фейк\"].unique(), df[\"Фейк\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что датасет несбалансированый (та же картина была и с оригинальным датасетом)"},{"metadata":{},"cell_type":"markdown","source":"В итоге из-за того, что в датасете было много пропусков, а многие из фичей не выглядели убедительно было принято решение сконкатенировать все текстовые признаки в один текст и скормить тяжелой модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(' ',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text\"] = df['Название'] + ' ' + df['Место'] + ' ' + df['Отдел'] + ' ' + df['Описание компании'] + ' ' + df['Описание вакансии'] + ' ' + df['Требования'] + ' ' + df['Соцпакет'] + ' ' + df['Тип занятости'] + ' ' + df['Образование'] + ' ' + df['Индустрия'] + ' ' + df['Позиция']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь удалим все ненужные фичи и оставим только текст и таргет"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['Название']\ndel df['Место']\ndel df['Отдел']\ndel df['Описание компании']\ndel df['Описание вакансии']\ndel df['Требования']\ndel df['Соцпакет']\ndel df['Тип занятости']\ndel df['Опыт']\ndel df['Образование']\ndel df['Индустрия']\ndel df['Позиция']\ndel df['Дистанционно']\ndel df['Зарплата']\ndel df['Вопросы']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Перед тем, как засовывать текст в модель, я решил его обработать  "},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy, re\n#Data Cleanup\n\ndf['text']=df['text'].str.replace('\\n','')\ndf['text']=df['text'].str.replace('\\r','')\ndf['text']=df['text'].str.replace('\\t','')\n  \n#This removes unwanted texts\ndf['text'] = df['text'].apply(lambda x: re.sub(r'[0-9]','',x))\ndf['text'] = df['text'].apply(lambda x: re.sub(r'[/(){}\\[\\]\\|@,;.:-]',' ',x))\n  \n#Converting all upper case to lower case\ndf['text']= df['text'].apply(lambda s:s.lower() if type(s) == str else s)\n  \n\n#Remove un necessary white space\ndf['text']=df['text'].str.replace('  ',' ')\n\n#Remove Stop words\nnlp=spacy.load(\"en_core_web_sm\")\ndf['text'] =df['text'].apply(lambda x: ' '.join([word for word in x.split() if nlp.vocab[word].is_stop==False ]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from nltk.corpus import stopwords\n# import string\n# c = set(stopwords.words('english'))\n# punctuation = list(string.punctuation)\n# stop.update(punctuation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_simple_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet\nfrom tqdm import tqdm\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    final_text = []\n    for i in tqdm(text.split()):\n        if i.strip().lower() not in stop:\n            pos = pos_tag([i.strip()])\n            word = lemmatizer.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n            final_text.append(word.lower())\n    return \" \".join(final_text)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.text = df.text.apply(lemmatize_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Далее должен был быть трейн-тест сплит, но для сабмита я обучался на всем датасете, используя как валидацию кагловский тест датасет"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df[\"Фейк\"], test_size = 0.20, stratify=df[\"Фейк\"], random_state=777)\n\ntrain_df = pd.DataFrame({0: df['text'], 1: df[\"Фейк\"]})\ntest_df = pd.DataFrame({0: X_test, 1: y_test})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В качестве модели было решено использовать bert, в конце которого будет два аутпута для бинарной классификации"},{"metadata":{"trusted":true},"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel, ClassificationArgs\nmodel_args = ClassificationArgs()\nmodel_args.use_early_stopping = True\nmodel_args.early_stopping_delta = 0.01\nmodel_args.early_stopping_metric = \"mcc\"\nmodel_args.early_stopping_metric_minimize = False\nmodel_args.early_stopping_patience = 1\nmodel_args.evaluate_during_training_steps = 1000\nmodel_args.overwrite_output_dir = True\nmodel_args.train_batch_size = 64\nmodel_args.save_steps = 10000\nmodel_args.save_model_every_epoch = False\nmodel_args.num_train_epochs = 10\n\n# model = ClassificationModel('albert', 'albert-base-v2', num_labels=2, args={'overwrite_output_dir': True, \"train_batch_size\": 64, \"save_steps\": 10000, \"save_model_every_epoch\":False,\n#                                                                           'num_train_epochs': 5}, use_cuda=True)\n# model = ClassificationModel('bert', 'bert-base-uncased', num_labels=2, args=model_args, use_cuda=True)\n\nmodel = ClassificationModel('bert', 'bert-base-uncased', num_labels=2, args={'overwrite_output_dir': True, \"train_batch_size\": 64, \"save_steps\": 10000, \"save_model_every_epoch\":False,\n                                                                           'num_train_epochs': 5}, use_cuda=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.train_model(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model\nresult, model_outputs, wrong_predictions = model.eval_model(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\npreds = [np.argmax(tuple(m)) for m in model_outputs]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nprint(f1_score(test_df[1], preds, average='micro'))\nprint(f1_score(test_df[1], preds, average='macro'))\nprint(f1_score(test_df[1], preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(test_df[1], preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Готовимся предиктить тест"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/test-data-for-fake-jobs/test_data.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Делаем те же препарации с фичами, что и на трейне"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.fillna(\" \",inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission[\"text\"] = submission['Название'] + ' ' + submission['Место'] + ' ' + submission['Отдел'] + ' ' + submission['Описание компании'] + ' ' + submission['Описание вакансии'] + ' ' + submission['Требования'] + ' ' + submission['Соцпакет'] + ' ' + submission['Тип занятости'] + ' ' + submission['Образование'] + ' ' + submission['Индустрия'] + ' ' + submission['Позиция']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del submission['Название']\ndel submission['Место']\ndel submission['Отдел']\ndel submission['Описание компании']\ndel submission['Описание вакансии']\ndel submission['Требования']\ndel submission['Соцпакет']\ndel submission['Тип занятости']\ndel submission['Опыт']\ndel submission['Образование']\ndel submission['Индустрия']\ndel submission['Позиция']\ndel submission['Дистанционно']\ndel submission['Зарплата']\ndel submission['Вопросы']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = submission[\"Id\"].copy()\nsubmission = submission.drop(columns='Id')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['text']=submission['text'].str.replace('\\n','')\nsubmission['text']=submission['text'].str.replace('\\r','')\nsubmission['text']=submission['text'].str.replace('\\t','')\n\n#This removes unwanted texts\nsubmission['text'] = submission['text'].apply(lambda x: re.sub(r'[0-9]','',x))\nsubmission['text'] = submission['text'].apply(lambda x: re.sub(r'[/(){}\\[\\]\\|@,;.:-]',' ',x))\n\n#Converting all upper case to lower case\nsubmission['text']= submission['text'].apply(lambda s:s.lower() if type(s) == str else s)\n\n\n#Remove un necessary white space\nsubmission['text']=submission['text'].str.replace('  ',' ')\n\n#Remove Stop words\nnlp=spacy.load(\"en_core_web_sm\")\nsubmission['text'] =submission['text'].apply(lambda x: ' '.join([word for word in x.split() if nlp.vocab[word].is_stop==False ]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.text = submission.text.apply(lemmatize_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Предиктим тест"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions, raw_outputs = model.predict(submission.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Формируем сабмит"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame()\nresult['Id'] = ids.values\nresult['Фейк'] = predictions\nresult = result.set_index('Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сохраняем сабмит в виде csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\n\nresult.to_csv(r'lim_bert_submission_best5.csv', )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Формируем ссылку для скачивания нашего сабмита для дальнейшей отправки его на каггл"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'lim_bert_submission_best5.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}