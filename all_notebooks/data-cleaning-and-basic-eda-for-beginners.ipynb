{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://verstaresearch.com/wp-content/uploads/2014/08/VB2014-08-27-01-900x450.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Intro\n**Data cleaning** is such an integral part of data analysis.Unlike here in Kaggle,almost all data you see in the real world would be dirty and messy. Some even say data cleaning would take 80% of data analysis time.\n   \n### What we will do in this notebook\n- Data cleaning\n- Basic EDA\n- Visualization\n\n### This notebook is stil under construction.\n### Feel free to <font color=deepskyblue> FORK  </font> this notebook, Please  <font color=deepskyblue> UPVOTE !! </font> if it's helpful to you  <font color=deepskyblue> : ) </font>\n\n\n>    By the way,english is not my native language, so dont freak out if you run into any language error. ","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Know your data\nThe second step or I would say the very fisrt step of any given data analysis project would be getting to know your data especially when you are dealing a messy one.\n\nTake a look at our data as below, the data is quite obscure,it's hard to understand for a human,not mentioned for a computer.in this kind of situation,you have ways to get acquaintance with your data as follows:\n\n1. Go to the data source page [WHO OBESITY DATA](https://apps.who.int/gho/data/node.main.A900A?lang=en) \n2. Read the description in this kaggle data page [Obesity among adults by country, 1975-2016](https://www.kaggle.com/amanarora/notebook)\n3. If solution 1 or 2 doesnnot work or hard to do, you can always go to ask data curator directly.","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/obesity-among-adults-by-country-19752016/data.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Why and how data is messy?\nIn most cases, data is collected by human or machines,a tiny glich would cause a long strip of bad data.if the data is collected by human, then it is a big chance that it would be messy. data can be dirty in many different ways,but mostly fall into those categories :\n\n1. **Missing data**<br>like NAN\n2. **Validity of data**<br>like 2016.1 / 2016.2 in the column\n3. **Outliers**<br>like if a BMI entry is greater than 100\n4. **Consistency of data**<br>the unit of every entry is not the same\n5. **Correctness of data**<br>\n    we are not gonna go through this ,but it is an important part of doing analysis in bussiness world,\n    basically you need external data source or database to cross check the data in your hand because as we always say:\n>  You dont know what you dont know \n\n6. Data is in **wide form** not in long form <br>\n    we are gonna go deeper about this one.\n\nAre you ready, it's time to get our hands dirty!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4.1 long form VS wide form\n   The original data we have here is in wide form which means the form is very wide literally.\n   \n   After read the description in WHO webpage we know that the year value 2016 or 2017 are actually values but were put in column which made the form wide.\n   \n   the .1 .2 in year number stand for gender, we gonna fix that later. \n   \n   Wide data is not easy to analyze or stored effectively in computer, so we want to change it as soon as we can.\n   go to read this [tidy-data](https://vita.had.co.nz/papers/tidy-data.pdf) if you want to know more.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data.copy()\ndf.rename(columns={'Unnamed: 0':'country'},inplace=True)\ndf=df.melt(id_vars=['country'],var_name='year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.2 correct the format\n\n1. we will dorp the first 3 row since its actually headers in the original forms.\n2. correct year value\n3. correct the gender value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([0,1,2]).reset_index()\ndf[['year','gender']]=df['year'].str.split('.',expand=True)\ndf=df.drop(columns=['index'])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['gender']=df['gender'].map({None:'both sex','1':'male','2':'female'})\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. correct the BMI value columns\n\n   from the webpage of WHO we can know that the values in [] are actually estimation intervel，so we need to seperate them into 3 columns\n   \n   you can use **str.matach()** or **str.findall()** with **regular expression** to extract float number in this field,but I am gonna use **str.split()**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'value':'BMI'},inplace=True)\ndf1=df.copy()\ndf['BMI']=df1['BMI'].str.split('[',expand=True)[0]\ndf['BMI_lower_esti']=df1['BMI'].str.split('[',expand=True)[1].str.split('-',expand=True)[0]\ndf['BMI_upper_esti']=df1['BMI'].str.split('[',expand=True)[1].str.split('-',expand=True)[1].str.split(']',expand=True)[0]\ndf=df[['country','year','gender','BMI','BMI_upper_esti','BMI_lower_esti']] #reset the column sequence\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.3 check validity of all columns or fields\n\nWe now have a pretty clean data compared to the one we just got.\nbut our job is still not done yet.\nwe need to go through every columns or fields to make sure the data is reletively correct.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.3.1 Country columns\n\n**What we know：**\n\n1. There is a country named **country** which need to be fixed \n2. There are **Nones** in country column which need to be fixed \n3. We have \n\n**What we do：**\n\nWe gonna drop those entries.","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#locate Na\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#delet country == 'Country' and country == None entries\n\ndf1=df.dropna(subset=['country'])\ndf1=df1.drop(df[df.country=='Country'].index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3.2 BMI \\ BMI_upper_esti and BMI_lower_esti columns\n\n**What we know：**\n\n1. 4 contries have no BMI data which are Monaca,Sudan,South Sudan and San Marino,hence they dont have estimations.\n2. We have 191 countries that do have BMI data and each of them has 126 entries. \n3. The descriptive statistics of BMI data seems OK, no outliers.\n\n**What we do：**\n\n1. We gonna create a new dataframe without those 4 countries to analyze.\n2. We gonna change the data type of BMI and estimations to float. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df1.isna().sum())\nprint('\\n')\nprint(df1[df1.BMI_upper_esti.isna()|df1.BMI_lower_esti.isna()].BMI.value_counts())\nprint('\\n')\nprint(df1[df1.BMI=='No data'].country.value_counts())\ncon=df1[df1.BMI=='No data'].country.value_counts().index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from above we can find that thare are 4 countries have no data, so exclude them, we have df2 to investigare ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=df1[~df1.country.isin(con)]\n# df2 dataframe is the one excluded no data countries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df2.country.value_counts().index)\nval=df2.country.value_counts().values\nnp.unique(val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[['BMI','BMI_upper_esti','BMI_lower_esti']]=df2.loc[:,['BMI','BMI_upper_esti','BMI_lower_esti']].astype('float')\n#change datatype to float\ndf2.loc[:,['BMI','BMI_upper_esti','BMI_lower_esti']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3.3 Year and gender columns\n\n**What we know：**\n\n1. We have year across from 1975 to 2016","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df2.year.value_counts().sort_index()\n# year column seems ok","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df2.gender.value_counts()\n#gender columns seems ok","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean process finished\n\nWe now have a pretty clean data, it's time to do some EDA and visualization\n\n<img src='https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/237/clapping-hands-sign_1f44f.png' align='left'/>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5 visualization and EDA\n\nBefore you doing any EDA, come up with some questions first. Question orientated is always a good way to explore a set of data, you could easily fall into rabbit holes you enconter along the process otherwise.You dont have to write those question down, I'm just gonna do it.\n\nBy the way, EDA means **Exploratory Data Analysis**\n\n**What question we could possibly answer through this data?**\n\n1. which countries have the highest/lowest BMI ?\n2. How do those country change over the past few years ?\n3. How does the BMI change globally ?\n4. If there is any diffrence in obesity between male and female ?","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mean_BMI=df2.groupby(by=['year','gender']).BMI.mean().reset_index().set_index('year')\ndf_median_BMI=df2.groupby(by=['year','gender']).BMI.median().reset_index().set_index('year')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mean/Median BMI Changes over the years \n\n**What we can know from the graph:**\n\n1. The mean/median BMI value across the globe is steadily increase over the last 41 years for both male and female","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,10))\nax = fig.add_subplot(211)\ng=sns.lineplot(data=df_mean_BMI,x=df_mean_BMI.index,y='BMI',hue='gender',ax=ax)\nax.tick_params(axis='x', rotation=45)\nplt.title('BMI Changes over the years',size=20)\nax1 = fig.add_subplot(212)\ng1=sns.lineplot(data=df_median_BMI,x=df_median_BMI.index,y='BMI',hue='gender',ax=ax1)\nax1.tick_params(axis='x', rotation=45)\nax.set_ylabel('BMI-mean',size=20)\nax1.set_ylabel('BMI-median',size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BMI distribution in 1975 1995 and 2016\n\n**What we can know from the graph:**\n\n1. In year 1975,the distribution is unimodal, left-skrewed clearly.\n2. In year 1995 and 2016,the center of distribution is moving towards right over time and become multimodal(two peaks on the curve)","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,6))\nsns.distplot(df2[df2.year=='1975'].BMI,hist=False,label='1975')\nsns.distplot(df2[df2.year=='1995'].BMI,hist=False,label='1995')  # 1995 is roughly the middle point between 1975 and 2016\nsns.distplot(df2[df2.year=='2016'].BMI,hist=False,label='2016')\nplt.title('BMI Distribution Across the Globe',size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How top 10 BMI countries changes\n\nThey didn't change much","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df3=df2[df2.gender=='both sex'].sort_values('BMI',ascending=False).groupby('year').head(10).sort_values('year')\ndf3 #Top contries from 1975 to 2016","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"years=df3.year.unique().astype('int')\nyear=[x for x in years if x%2==0 ] #sampling years using systematic sampling\ndf4=df3[df3.year.astype('int').isin(year)].sort_values(by=['year','BMI'])\ndf4.country=df4.country.str.replace('Federated States of','FSo')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(df4, col=\"year\",col_wrap=4,sharey=False)\ngrid.map(plt.barh,\"country\", \"BMI\")\nplt.suptitle('Top 10 countries over 41 years',x=0.5,y=1.02,size=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Diffrence between male and famale","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_temp=df2[(df2.gender!='both sex')&df2.year.isin(['1975','1985','1995','2005','2015'])]\nplt.figure(figsize=(10,8))\nsns.violinplot(data=data_temp,x='year',y='BMI',hue='gender',palette='Accent',split=True)\nplt.title('Obesity Distribution between male and female',size=20)\nplt.legend(loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" I'm still trying to find better ways to explore and visualize the difference between male and female across countries in long term.\nif you have better ideas, let me know in the comment,plz.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## A basic Racing Charts","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.ticker as ticker\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\ndf3.year=df3.year.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_barchart(year):\n    dff = df3[df3['year'].eq(year)].sort_values(by='BMI', ascending=True).tail(10)\n    ax.clear()\n    ax.barh(dff['country'], dff['BMI'],color='lightblue')\n    dx = dff['BMI'].max() / 200\n    for i, (value, name) in enumerate(zip(dff['BMI'], dff['country'])):\n        ax.text(value-dx, i,     name,           size=14, weight=600, ha='right', va='center')\n        #ax.text(value-dx, i-.25, group_lk[name], size=10, color='#444444', ha='right', va='baseline')\n        ax.text(value+dx, i,     f'{value:,.0f}',  size=14, ha='left',  va='center')\n    # ... polished styles\n    ax.text(1, 0.4, year, transform=ax.transAxes, color='#777777', size=46, ha='right', weight=800)\n    ax.text(0, 1.06, 'Obesity %', transform=ax.transAxes, size=12, color='#777777')\n    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n    ax.xaxis.set_ticks_position('top')\n    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n    ax.set_yticks([])\n    ax.margins(0, 0.01)\n    ax.grid(which='major', axis='x', linestyle='-')\n    ax.set_axisbelow(True)\n    ax.text(0, 1.12, 'The most Obesity% countries in the world from 1975 to 2016',\n            transform=ax.transAxes, size=24, weight=600, ha='left')\n    #ax.text(1, 0, 'by @pratapvardhan; credit @jburnmurdoch', transform=ax.transAxes, ha='right',color='#777777', bbox=dict(facecolor='white', alpha=0.8, edgecolor='white'))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%%capture\nfig, ax = plt.subplots(figsize=(18, 10))\nanimator = animation.FuncAnimation(fig, draw_barchart, frames=range(1975, 2016))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HTML(animator.to_jshtml())\n# or use animator.to_html5_video() or animator.save()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To be continued...\n\nThis notebook is still under construction, so if you want to know anything about data cleaning or EDA process,just leave your commet below,and upvote it if you think it's helpful.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}