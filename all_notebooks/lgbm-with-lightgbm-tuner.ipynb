{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Fetal Health Classification"},{"metadata":{},"cell_type":"markdown","source":"## Motivation\n\nCardiotocograms (CTGs) are a simple and cost accessible option to assess fetal health. This allows healthcare professionals to take action in order to prevent child and maternal mortality. \n\nDeaths during and following pregnancy and childbirth is 295,000 (as of 2017). The vast majority of these deaths (94%) occurred in low-resource settings, and most could have been prevented.\n\nWe'll predict fetal_health from CTGs data. The goal is to be able to respond to the risk of death in advance."},{"metadata":{},"cell_type":"markdown","source":"## Target\n\nWe aim for good predictions of \"fetal_health\" class.\n\nThis class is cardiotocogram exams' result classified by three expert obstetritians. The labels are coresponding to the following three:\n\n- Normal\n- Suspect\n- Pathological"},{"metadata":{},"cell_type":"markdown","source":"## Evaluetaion\n\nI'll evaluate my model by F1 score.\n\n$$\n  F_1 = \\frac{2}{\\frac{1}{recall} + \\frac{1}{precision}} = \\frac{2TP}{2TP + FP + FN}\n$$\n\nHere, TP is True Positive, TN is True Negative, FP is False Positive and FN is False Negative.\n\nThe highest possible value is 1. This indicates perfect precision and recall. The lowest possible value is 0. This indicates either the precision or the recall is zero.\n\nI also check auc and Roc curves.\n\nI use 66% of dataset for training, and 33% for test. "},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"alert alert-block alert-info\">Load data and library</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nfrom itertools import cycle\nimport random\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import interp\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\nfrom optuna.integration import lightgbm as lgb\n#import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_seed(seed):\n    # random\n    random.seed(seed)\n    # Numpy\n    np.random.seed(seed)\n\nSEED = 42\nfix_seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/fetal-health-classification","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fetal_health = pd.read_csv(\"../input/fetal-health-classification/fetal_health.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"alert alert-block alert-info\">Checking data overview</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null data. all data are float64 type."},{"metadata":{"trusted":true},"cell_type":"code","source":"fetal_health.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scales are different by each data column. In this notebbok, I'll use LightBGM, so I won't normalize scales. (This is because I don't think LightBGM will be affected much by scales.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_with_seaborn(fetal_health):\n    fig, axes = plt.subplots(11, 2, figsize=(10,40))\n    fig.suptitle(f\"Distributions of values of dataset\")\n    g1 = sns.distplot(fetal_health[\"baseline value\"],  color='orange', ax=axes[0, 0])\n    g2 = sns.distplot(fetal_health[\"accelerations\"], color='darkgoldenrod', ax=axes[0, 1])\n    g3 = sns.distplot(fetal_health[\"fetal_movement\"], color='darkkhaki', ax=axes[1, 0])\n    g4 = sns.distplot(fetal_health[\"uterine_contractions\"], color='olive', ax=axes[1, 1])\n    g5 = sns.distplot(fetal_health[\"light_decelerations\"], color='lime', ax=axes[2, 0])\n    g6 = sns.countplot(fetal_health[\"severe_decelerations\"], ax=axes[2, 1])\n    g7 = sns.countplot(fetal_health[\"prolongued_decelerations\"], ax=axes[3, 0])\n    g8 = sns.distplot(fetal_health[\"abnormal_short_term_variability\"], color='blue', ax=axes[3, 1])\n    g9 = sns.distplot(fetal_health[\"mean_value_of_short_term_variability\"], color='violet', ax=axes[4, 0])\n    g10 = sns.distplot(fetal_health[\"percentage_of_time_with_abnormal_long_term_variability\"], color='darkmagenta', ax=axes[4, 1])\n    g11 = sns.distplot(fetal_health[\"mean_value_of_long_term_variability\"], color='orange', ax=axes[5, 0])\n    g12 = sns.distplot(fetal_health[\"histogram_width\"], color='darkgoldenrod', ax=axes[5, 1])\n    g13 = sns.distplot(fetal_health[\"histogram_min\"], color='darkkhaki', ax=axes[6, 0])\n    g14 = sns.distplot(fetal_health[\"histogram_max\"], color='olive', ax=axes[6, 1])\n    g15 = sns.distplot(fetal_health[\"histogram_number_of_peaks\"], color='lime', ax=axes[7, 0])\n    g16 = sns.countplot(fetal_health[\"histogram_number_of_zeroes\"], ax=axes[7, 1])\n    g17 = sns.distplot(fetal_health[\"histogram_mode\"], color='darkturquoise', ax=axes[8, 0])\n    g18 = sns.distplot(fetal_health[\"histogram_mean\"], color='blue', ax=axes[8, 1])\n    g19 = sns.distplot(fetal_health[\"histogram_median\"], color='violet', ax=axes[9, 0])\n    g20 = sns.distplot(fetal_health[\"histogram_variance\"], color='darkmagenta', ax=axes[9, 1])\n    g21 = sns.distplot(fetal_health[\"histogram_tendency\"], color='orange', ax=axes[10, 0])\n    g22 = sns.countplot(fetal_health[\"fetal_health\"], ax=axes[10, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_with_seaborn(fetal_health)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some columns have skewed distribution. I'm worried about it, but I'll adopt it all as input for now.\n\nCorrelation matrix is here."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\ncorr = fetal_health.corr()\nsns.heatmap(corr, square=True, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"prolongued_decelerations, abnormal_short_term_variability and percentage_of_time_with_abnormal_long_term_variability have high relation to fetal_health.\n\nPair plot is folowing. Too big, so I divide tmen two groups, high relation with fetal_health or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\nsns.pairplot(fetal_health[corr[abs(corr[\"fetal_health\"]) > 0.30].index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\nsns.pairplot(fetal_health[corr[abs(corr[\"fetal_health\"]) <= 0.30].index])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"alert alert-block alert-info\">Training</div>\n\nIn this notebook, I choose LightGBM as model, and tune hyper parameter by LightGBM Tuner.\n\nWe can use LightGBM Tuner very easily but it strongly tune our model.\n\nFor LightGBM Tuner, you can read following contents.\n\n- https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258\n\n- https://optuna.readthedocs.io/en/stable/_modules/optuna/integration/lightgbm.html"},{"metadata":{},"cell_type":"markdown","source":"First, I devide dataset to train and target, and devide them train and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = fetal_health[[col for col in fetal_health.columns if col not in [\"fetal_health\"]]]\ny = fetal_health[\"fetal_health\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, X_test, y, y_test = train_test_split(X, y, test_size=0.33, random_state=SEED)\nX = X.reset_index(drop=True)\ny = y.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True) \ny_test = y_test.reset_index(drop=True)\n\n#To use LightGBM's multiclass objective, I adjust labels.\ny = y - 1\ny_test = y_test - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    \"objective\": \"multiclass\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 40,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"multi_logloss\",\n    \"num_class\" : 3,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_multiclass_auc(y_test, y_pred):\n    y_test = label_binarize(y_test, classes=[0, 1, 2])\n    y_pred = label_binarize(y_pred, classes=[0, 1, 2])\n    \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(3):\n        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    \n    return roc_auc, tpr, fpr\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"kf = KFold(n_splits=3)\nmodels = []\nf1 = 0\nauc_vals = []\ntpr_vals = []\nfpr_vals = []\n\nfor train_index,val_index in kf.split(X):\n    train_features = X.loc[train_index]\n    train_target = y.loc[train_index]\n    \n    val_features = X.loc[val_index]\n    val_target = y.loc[val_index]\n    \n    d_training = lgb.Dataset(train_features, label=train_target, free_raw_data=False)\n    d_val = lgb.Dataset(val_features, label=val_target, free_raw_data=False)\n    \n    cls = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_val], verbose_eval=25, early_stopping_rounds=50)\n\n    models.append(cls)\n    f1 += f1_score(val_target, np.argmax(cls.predict(val_features),axis=1), average='macro')\n    \n    roc_auc, tpr, fpr = calc_multiclass_auc(val_target, np.argmax(cls.predict(val_features),axis=1))\n    auc_vals.append(roc_auc)\n    tpr_vals.append(tpr)\n    fpr_vals.append(fpr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_tuned_params(cls, fold):\n    print(\"---------------------\")\n    print(f\"Tune result of the {fold}th fold.\")\n    print(\"params:\", cls.params)\n    print(\"best_iteration:\", cls.best_iteration)\n    print(\"best_score:\", cls.best_score)    \n    print(\"---------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold = 1\nfor cls in models:\n    print_tuned_params(cls, fold)\n    fold += 1\n\nprint(\"F1 score:\", f1 / 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_cal_micro = 0\nauc_val_0 = 0\nauc_val_1 = 0\nauc_val_2 = 0\n\nfor auc_val in auc_vals:\n    auc_cal_micro += auc_val['micro']\n    auc_val_0 += auc_val[0]\n    auc_val_1 += auc_val[1]\n    auc_val_2 += auc_val[2]\n    \nprint(\"auc micro\", auc_cal_micro / 3)\nprint(\"auc for label 0:\", auc_val_0 / 3)\nprint(\"auc for label 1:\", auc_val_1 / 3)\nprint(\"auc for label 2:\", auc_val_2 / 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK, we got good f1 score. The learning seems to be going well.\n\nI also check auc and roc curves."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(tprs, fprs, fold,  n_classes, lw):\n    \"\"\"Plots ROC curves for the multilabel problem\n    Refer https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n    \"\"\"\n    if fold != \"test\":\n        tpr = tprs[fold]\n        fpr = fprs[fold]\n    else:\n        tpr = tprs\n        fpr = fprs\n        \n    n_classes = 3\n    lw = 2\n    \n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(n_classes):\n        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n    # Finally average it and compute AUC\n    mean_tpr /= n_classes\n\n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n    # Plot all ROC curves\n    plt.figure()\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\n    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\n    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n    for i, color in zip(range(n_classes), colors):\n        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Roc Curve of fold {fold}')\n    plt.legend(loc=\"lower right\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(tpr_vals, fpr_vals, 0,  3, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(tpr_vals, fpr_vals, 1,  3, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(tpr_vals, fpr_vals, 2,  3, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"alert alert-block alert-info\">Predict</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.zeros((X_test.shape[0], 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    result += model.predict(X_test)\nf1_test = f1_score(y_test, np.argmax(result,axis=1), average='macro')\nauc_test, tpr_test, fpr_test = calc_multiclass_auc(y_test, np.argmax(result,axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(tpr_test, fpr_test, \"test\",  3, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK, we got good f1 score in test, too."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Predicted fetal_health labels are:\")\nnp.argmax(result,axis=1) + 1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}