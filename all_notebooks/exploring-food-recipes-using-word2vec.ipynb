{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is my first attempt in building Word2Vec model, with inspiration from \"What's Cooking\" challenge on Kaggle.\nIf you like it please upvote. Expert reviews/comments or suggestions are welcomed.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport collections\nimport gensim \nfrom gensim.models import word2vec, phrases\nfrom gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, strip_numeric,\\\n                    strip_non_alphanum, strip_multiple_whitespaces, strip_short\nfrom textblob import TextBlob, Word\n\nimport re\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the recipes dataset\nfilepath = \"/kaggle/input/foodrecipes/recipes.csv\"\ndf_recipes = pd.read_csv(filepath, encoding=\"ISO-8859-1\")\n\n#drop rows where cuisine, ingregients are NA\ndf_recipes.dropna(subset=['cuisine', 'ingredients'],inplace=True)\ndf_recipes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert to lower case\ndf_recipes['ingredients'] = df_recipes['ingredients'].apply(lambda x: x.lower())\n\ntotal_ingredients = []\nall_receipes_ingredients =  []\n\nfor i in range(len(df_recipes)):\n    all_ingredients = list()\n    \n    #split each recipe into different ingredients\n    ingred = df_recipes.loc[i, \"ingredients\"][1:-1]\n    \n    for ing in (ingred.split(',')):\n        ing = remove_stopwords(ing)\n        ing = strip_numeric(ing)\n        ing = re.sub(r'\\(.*oz.\\)|(Â®)|(.*ed)|(.*ly)|boneless|skinless|chunks|fresh|large|cook drain|green|frozen|ground','',ing).strip()\n        ing = strip_short(ing,2)\n        ing = strip_multiple_whitespaces(ing)\n        ing = strip_punctuation(ing)\n        ing = strip_non_alphanum(ing)\n        \n        #convert plurals to singular e.g. tomatoes --> tomato\n        ing = (\" \".join(TextBlob(ing).words.singularize()))\n        \n        all_ingredients.append(ing)\n        total_ingredients.append(ing)\n        \n    all_receipes_ingredients.append(all_ingredients)\n    \ncounts_ingr = collections.Counter(total_ingredients)\n\nprint('Total Ingredients (with repetition):  \\t{}'.format((len(total_ingredients))))\nprint('Unique Ingredients : \\t\\t\\t{}'.format((len(counts_ingr.values()))))\nprint('Total Receipes:  \\t\\t\\t{}'.format((len(all_receipes_ingredients))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add cleaned ingredients back to original dataframe\ndf_recipes['clean_ingredients'] = pd.Series(all_receipes_ingredients)\n\n#record the number of ingredients for each recipe\ndf_recipes['ingredient_count'] =  df_recipes.apply(lambda row: len(row['clean_ingredients']), axis = 1)\n\n#convert time in seconds to minutes\ndf_recipes['timeMins'] = df_recipes.totalTimeInSeconds.apply(lambda x: x/60) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.mean(list(counts_ingr.values())))\nprint(np.std(list(counts_ingr.values())))\nprint(np.median(list(counts_ingr.values())))\nprint(np.percentile(list(counts_ingr.values()), [25., 50., 75., 99.]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the most common ingredients used across all recipes\nprint (\"---- Most Common Ingredients ----\")\nprint (counts_ingr.most_common(10))\n\nprint (\"\\n\")\n\n#find the most common ingredients used across all recipes\nprint (\"---- Least Common Ingredients ----\")\nprint (counts_ingr.most_common()[-10:])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the ingredients in WordCloud \n\nfrom wordcloud import WordCloud\n\ndef plot_wordcloud(text, title=None, max = 1000, size=(12,8), title_size=16):\n    \"\"\"plots wordcloud\"\"\"\n    wordcloud = WordCloud(max_words=max).generate(text)\n    plt.figure(figsize=size)\n    plt.title(title, size=title_size)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n\nplot_wordcloud(' '.join(total_ingredients), title='Ingredients')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train the Word2Vec model\n\nnum_features = 300    # Word vector dimensionality                      \nmin_word_count = 4                        \nnum_workers = 4       # Number of CPUs\ncontext = 10          # Context window size; \n\ndownsampling = 1e-2   # threshold for configuring which \n                      # higher-frequency words are randomly downsampled\n            \n# Initialize and train the model \nmodel = word2vec.Word2Vec(all_receipes_ingredients, workers=num_workers, \\\n            size=num_features, min_count = min_word_count, \\\n            window = context,sample = downsampling, iter=20)\n\n# If you don't plan to train the model any further, calling \n# init_sims will make the model much more memory-efficient.\nmodel.init_sims(replace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the similar ingredients returned by the model for search_terms\n\nsimilar_words = {search_term: [item[0] for item in model.wv.most_similar([search_term], topn=5)]\n                  for search_term in ['paneer','egg','mango','bread', 'rice']}\nsimilar_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualization with Tsne\nfrom sklearn.manifold import TSNE\n\nwords = sum([[k] + v for k, v in similar_words.items()], [])\nwvs = model.wv[words]\ntsne = TSNE(n_components=2, random_state=0, n_iter=1000, perplexity=2)\nnp.set_printoptions(suppress=True)\nT = tsne.fit_transform(wvs)\nlabels = words\n\nplt.figure(figsize=(14, 8))\nplt.scatter(T[:, 0], T[:, 1], c='orange', edgecolors='r')\nfor label, x, y in zip(labels, T[:, 0], T[:, 1]):\n    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar_cosmul(positive=['paneer', u'chicken'], negative=['tomato sauce'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('chocolate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('mayonnaise')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('chicken')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.similarity('paneer', 'chicken')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.doesnt_match(\"chicken paneer lentils meat\".split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.similarity('chocolate', 'cream')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = 'bread'\nb= 'cheese'\na = 'bread'\npredicted = model.wv.most_similar([x, b], [a])[0][0]\nprint(\" {} is to  {} as {} is to {} \".format(a, b, x, predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.available\nplt.style.use('ggplot')\n\nplt.xlabel('Cooking Time (minutes)')\nplt.ylabel('Recipe Count')\n\nlabels = ['4', '3', '5', '0', '2', '1']\nplt.pie(df_recipes.rating.value_counts(), labels=labels, autopct='%1.1f%%', colors=['gold', 'green', 'lightcoral', 'lightskyblue', 'red'], startangle=50, pctdistance=0.6)\nplt.axis('equal')\nplt.title('Recipes by Rating')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ingredient/rating relationship?\n\nfeature_cols = ['ingredient_count']\nX= df_recipes[feature_cols]\ny= df_recipes.rating\nplt.scatter(X, y)\nplt.xlabel('Ingredients')\nplt.ylabel('Yummly Rating')\nplt.title('Ingredient Counts vs Ratings')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['timeMins']\nX= df_recipes.dropna()[feature_cols]\ny= df_recipes.dropna().rating\nplt.scatter(X, y)\nplt.xlabel('Time in Minutes')\nplt.ylabel('Yummly Rating')\nplt.title('Cooking Time vs Ratings')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ingredients/cooking time relationship?\nfeature_cols = ['ingredient_count']\nX= df_recipes.dropna()[feature_cols]\ny= df_recipes.dropna()['timeMins']\nplt.scatter(X, y)\nplt.xlabel('Ingredient Count')\nplt.ylabel('Time in Minute')\nplt.title('Ingredients vs. Cooking Times')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_indian = df_recipes[df_recipes.cuisine.str.contains(\"indian\", case=False)].copy()\n\ningredients =df_indian[\"clean_ingredients\"].sum()\n\ncounts = collections.Counter(ingredients)\n\ncounts.most_common(30)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}