{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T04:22:10.5641Z","iopub.execute_input":"2021-08-01T04:22:10.564594Z","iopub.status.idle":"2021-08-01T04:22:10.575271Z","shell.execute_reply.started":"2021-08-01T04:22:10.564544Z","shell.execute_reply":"2021-08-01T04:22:10.574072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"float_data = pd.read_csv('../input/jena-climate-2009-2016/jena_climate_2009_2016.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:10.576901Z","iopub.execute_input":"2021-08-01T04:22:10.577268Z","iopub.status.idle":"2021-08-01T04:22:11.640517Z","shell.execute_reply.started":"2021-08-01T04:22:10.577237Z","shell.execute_reply":"2021-08-01T04:22:11.639452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"float_data = float_data.iloc[:4000,1:].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:11.642343Z","iopub.execute_input":"2021-08-01T04:22:11.642644Z","iopub.status.idle":"2021-08-01T04:22:11.66437Z","shell.execute_reply.started":"2021-08-01T04:22:11.642615Z","shell.execute_reply":"2021-08-01T04:22:11.662674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = float_data[:, 1]\nplt.plot(range(len(temp)), temp)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:11.666434Z","iopub.execute_input":"2021-08-01T04:22:11.666832Z","iopub.status.idle":"2021-08-01T04:22:11.863504Z","shell.execute_reply.started":"2021-08-01T04:22:11.666797Z","shell.execute_reply":"2021-08-01T04:22:11.862404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1440), temp[:1440])","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:11.86483Z","iopub.execute_input":"2021-08-01T04:22:11.865179Z","iopub.status.idle":"2021-08-01T04:22:12.067825Z","shell.execute_reply.started":"2021-08-01T04:22:11.865136Z","shell.execute_reply":"2021-08-01T04:22:12.066556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = float_data[:2000].mean(axis=0)\nfloat_data -= mean\nstd = float_data[:2000].std(axis=0)\nfloat_data /= std","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:12.069452Z","iopub.execute_input":"2021-08-01T04:22:12.069833Z","iopub.status.idle":"2021-08-01T04:22:12.076828Z","shell.execute_reply.started":"2021-08-01T04:22:12.069792Z","shell.execute_reply":"2021-08-01T04:22:12.075449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generator yielding temporal samples","metadata":{}},{"cell_type":"code","source":"def generator(data, lookback, delay, min_index, max_index,\n        shuffle=False, batch_size=128, step=6):\n    if max_index is None:\n        max_index = len(data) - delay - 1\n    i = min_index + lookback\n    while 1:\n        if shuffle:\n            rows = np.random.randint(\n                min_index + lookback, max_index, size=batch_size)\n        else:\n            if i + batch_size >= max_index:\n                i = min_index + lookback\n            rows = np.arange(i, min(i + batch_size, max_index))\n            i += len(rows)\n        samples = np.zeros((len(rows),\n            lookback // step,\n            data.shape[-1]))\n        targets = np.zeros((len(rows),))\n        for j, row in enumerate(rows):\n            indices = range(rows[j] - lookback, rows[j], step)\n            samples[j] = data[indices]\n            targets[j] = data[rows[j] + delay][1]\n        yield samples, targets","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:12.078291Z","iopub.execute_input":"2021-08-01T04:22:12.078574Z","iopub.status.idle":"2021-08-01T04:22:12.264868Z","shell.execute_reply.started":"2021-08-01T04:22:12.078545Z","shell.execute_reply":"2021-08-01T04:22:12.263753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lookback = 144\nstep = 6\ndelay = 144\nbatch_size = 128\n\ntrain_gen = generator(float_data,\n    lookback=lookback,\n    delay=delay,\n    min_index=0,\n    max_index=2000,\n    shuffle=True,\n    step=step,\n    batch_size=batch_size)\nval_gen = generator(float_data,\n    lookback=lookback,\n    delay=delay,\n    min_index=2001,\n    max_index=3000,\n    step=step,\n    batch_size=batch_size)\ntest_gen = generator(float_data,\n    lookback=lookback,\n    delay=delay,\n    min_index=3001,\n    max_index=None,\n    step=step,\n    batch_size=batch_size)\nval_steps = (3000 - 2001 - lookback)\ntest_steps = (len(float_data) - 3001 - lookback)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:12.268201Z","iopub.execute_input":"2021-08-01T04:22:12.268574Z","iopub.status.idle":"2021-08-01T04:22:12.288691Z","shell.execute_reply.started":"2021-08-01T04:22:12.268541Z","shell.execute_reply":"2021-08-01T04:22:12.287424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline model","metadata":{}},{"cell_type":"code","source":"def evaluate_naive_method():\n    batch_maes = []\n    for step in range(val_steps):\n        samples, targets = next(val_gen)\n        preds = samples[:, -1, 1]\n        mae = np.mean(np.abs(preds - targets))\n        batch_maes.append(mae)\n    print(np.mean(batch_maes))\nevaluate_naive_method()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:12.290284Z","iopub.execute_input":"2021-08-01T04:22:12.290561Z","iopub.status.idle":"2021-08-01T04:22:15.794833Z","shell.execute_reply.started":"2021-08-01T04:22:12.290534Z","shell.execute_reply":"2021-08-01T04:22:15.794082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"celsius_mae = 0.29 * std[1]","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:15.795849Z","iopub.execute_input":"2021-08-01T04:22:15.796318Z","iopub.status.idle":"2021-08-01T04:22:15.800833Z","shell.execute_reply.started":"2021-08-01T04:22:15.796286Z","shell.execute_reply":"2021-08-01T04:22:15.799656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic ML model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nhistory = model.fit_generator(train_gen,\n    steps_per_epoch=50,\n    epochs=10,\n    validation_data=val_gen,\n    validation_steps=val_steps)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:22:15.802306Z","iopub.execute_input":"2021-08-01T04:22:15.80279Z","iopub.status.idle":"2021-08-01T04:23:09.474945Z","shell.execute_reply.started":"2021-08-01T04:22:15.80274Z","shell.execute_reply":"2021-08-01T04:23:09.473795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:23:09.477715Z","iopub.execute_input":"2021-08-01T04:23:09.478112Z","iopub.status.idle":"2021-08-01T04:23:09.663129Z","shell.execute_reply.started":"2021-08-01T04:23:09.47807Z","shell.execute_reply":"2021-08-01T04:23:09.661784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GRU model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nhistory = model.fit_generator(train_gen,\n    steps_per_epoch=50,\n    epochs=10,\n    validation_data=val_gen,\n    validation_steps=val_steps)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:23:09.664675Z","iopub.execute_input":"2021-08-01T04:23:09.665354Z","iopub.status.idle":"2021-08-01T04:24:22.290535Z","shell.execute_reply.started":"2021-08-01T04:23:09.66531Z","shell.execute_reply":"2021-08-01T04:24:22.289444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:24:22.292334Z","iopub.execute_input":"2021-08-01T04:24:22.292678Z","iopub.status.idle":"2021-08-01T04:24:22.479305Z","shell.execute_reply.started":"2021-08-01T04:24:22.292642Z","shell.execute_reply":"2021-08-01T04:24:22.477998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GRU with dropout","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.GRU(32,\n    dropout=0.2,\n    recurrent_dropout=0.2,\n    input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nhistory = model.fit_generator(train_gen,\n    steps_per_epoch=50,\n    epochs=10,\n    validation_data=val_gen,\n    validation_steps=val_steps)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T04:24:22.480813Z","iopub.execute_input":"2021-08-01T04:24:22.481208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.GRU(32,\n    dropout=0.1,\n    recurrent_dropout=0.5,\n    return_sequences=True,\n    input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.GRU(64, activation='relu',\n    dropout=0.1,\n    recurrent_dropout=0.5))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nhistory = model.fit_generator(train_gen,\n    steps_per_epoch=50,\n    epochs=10,\n    validation_data=val_gen,\n    validation_steps=val_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bidirectional GRU","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Bidirectional(\n    layers.GRU(32), input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nhistory = model.fit_generator(train_gen,\n    steps_per_epoch=50,\n    epochs=10,\n    validation_data=val_gen,\n    validation_steps=val_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1D Convnet","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Conv1D(32, 5, activation='relu',\n    input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.MaxPooling1D(3))\n#model.add(layers.Conv1D(32, 5, activation='relu'))\n#model.add(layers.MaxPooling1D(3))\nmodel.add(layers.Conv1D(32, 5, activation='relu'))\nmodel.add(layers.GlobalMaxPooling1D())\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nhistory = model.fit_generator(train_gen,\n    steps_per_epoch=50,\n    epochs=10,\n    validation_data=val_gen,\n    validation_steps=val_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Higher-resolution generator","metadata":{}},{"cell_type":"code","source":"step = 3\nlookback = 72\ndelay = 144\ntrain_gen = generator(float_data,\n    lookback=lookback,\n    delay=delay,\n    min_index=0,\n    max_index=2000,\n    shuffle=True,\n    step=step)\nval_gen = generator(float_data,\n    lookback=lookback,\n    delay=delay,\n    min_index=2001,\n    max_index=3000,\n    step=step)\ntest_gen = generator(float_data,\n    lookback=lookback,\n    delay=delay,\n    min_index=3001,\n    max_index=None,\n    step=step)\nval_steps = (3000 - 2001 - lookback) // 128\ntest_steps = (len(float_data) - 3001 - lookback) // 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1D convolution + GRU","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Conv1D(32, 5, activation='relu',\n    input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.MaxPooling1D(3))\nmodel.add(layers.Conv1D(32, 5, activation='relu'))\nmodel.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\nmodel.add(layers.Dense(1))\nmodel.summary()\nmodel.compile(optimizer=RMSprop(), loss='mae')\n\nhistory = model.fit_generator(train_gen,\n    steps_per_epoch=50,\n    epochs=10,\n    validation_data=val_gen,\n    validation_steps=val_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}