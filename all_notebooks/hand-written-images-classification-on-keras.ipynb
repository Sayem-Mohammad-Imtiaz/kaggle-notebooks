{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Follow Kaggle's way to load datasets\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load dataset and change it into Pandas Dataframe \nimport pandas as pd\ndataset=pd.read_csv(\"/kaggle/input/mnistlike-dataset-squarecircletriangle/train_data.csv\")\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Change dataset into float 32 data.\ndataset.astype('float32')\n# Now X is \"Explanatory variable\", y is \"Taget\".\nX = dataset.drop('label',axis = 1)\ny = dataset['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import two libraries, matplot, seaborn.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(15,5))\nsns.distplot(y,kde=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There are so many triangles.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import numpy and give a seed. \nimport numpy as np\nnp.random.seed(182)\n#Show 3 images at random and convert them into gray scale. \nfor i in range(3):\n    plt.imshow(X.iloc[np.random.randint(0,200)].values.reshape(28,28),cmap='Greys')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load some libraries that I frequently use. \nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom tensorflow import keras as kr\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now, reload the dataset and change it into \"numpy array\".\ndataset=pd.read_csv(\"/kaggle/input/mnistlike-dataset-squarecircletriangle/train_data.csv\").to_numpy()\n#Divide dataset into two parts, one is \"Explanatory variable\", the other is \"Taget\".\nX = dataset[1:,1:]\nY = dataset[1:,0]\n#Split the \"X,Y\" data into the ratio of 7:3, 3 is the test size. \n(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.3, random_state=2)\n#Reshape the data and change it into float 32 as usual.\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n#The pixcel of the data is comprised from 0 to 255. 0 is white,255 is black.\n#Now normalize the data from 0 to 1 without some libraries, in a simple way.\nX_train = X_train / 255\nX_test = X_test / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-Hot-Encoding of the target.\nY_train = np_utils.to_categorical(Y_train)\nY_test = np_utils.to_categorical(Y_test)\n#Check how many target classes exist in this dataset. 3\nnum_classes = Y_train.shape[1]\nnum_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build a CNN model.\nmodel = Sequential()\nmodel.add(Conv2D(64, (5, 5), input_shape=(28, 28, 1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nprint(model.summary())\nmodel.compile(optimizer = \"rmsprop\", loss = 'categorical_crossentropy', metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the train data.\nTrain1=model.fit(X_test, Y_test,batch_size=10, epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate this models by using two metrics, loss and accuracy.\nmetrics = ['loss', 'accuracy']\n#show the evaluation result by using matoplot.\nplt.figure(figsize=(10, 5))\n#Use \"For Loop\".\nfor i in range(len(metrics)):\n    metric = metrics[i]\n    #set subplots to show the result\n    plt.subplot(1, 2, i+1)\n    #Titles of subplots are \"loss\" and \"accuracy\"\n    plt.title(metric) \n    plt_train1 = Train1.history[metric] \n\n    #plot them all\n    plt.plot(plt_train1, label='train1') \n    plt.legend() \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=27\n#Here is the prediction sample.\nplt.imshow(X_test[[i]].reshape(28,28),cmap='Greys')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's predict.\nprediction=model.predict(X_test[[i]]) \nprediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preparation for this predction. \nlist1=[0,1,2]\nlist2=[\"circle\",\"triangle\",\"square\"]\ndic = dict(zip(list1, list2))\n#Let's check the result.\nprint(\"The answer is\",dic[np.argmax(prediction)],\". :-)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's enjoy quiz_for_competition_r.csv\".\ndataset=pd.read_csv(\"/kaggle/input/mnistlike-dataset-squarecircletriangle/quiz_for_competition_r.csv\").to_numpy()\n#Divide dataset into two parts, one is \"Explanatory variable\", the other is \"Taget\".\nQX = dataset[1:,1:]\nQX = QX.reshape(QX.shape[0], 28, 28, 1).astype('float32')\nQX = QX / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make a dictionary\ndic2 = dict(zip([0,1,2], [0,1,2]))\n\n#Set definition\ndef answer(i):\n    for i in range(i):\n        pred2=model.predict(QX[[i]])\n        ans=dic2[np.argmax(pred2)]\n        ans_list.append(ans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's do it!\nans_list=[]\nanswer(199)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check the prediction\nprint(np.array([ans_list]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1st step: Let's make the final prediction data!\nans_array=np.array([ans_list]).T\n\n#2nd step: Let's change the prediction into a CSV file.\nnp.savetxt(\"final_prediction.csv\", ans_array, delimiter=',',fmt='%d' )\nprint(\"File Saved\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}