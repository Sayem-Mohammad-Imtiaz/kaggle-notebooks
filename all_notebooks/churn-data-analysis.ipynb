{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U imbalanced-learn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns; sns.set()\n%matplotlib inline\n\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nfrom imblearn.pipeline import make_pipeline, Pipeline\nfrom imblearn.over_sampling import SMOTE\n\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import KBinsDiscretizer, FunctionTransformer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom category_encoders import WOEEncoder\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import MinMaxScaler, KBinsDiscretizer, FunctionTransformer\nfrom category_encoders import OneHotEncoder\n\nfrom mlxtend.evaluate import feature_importance_permutation\nfrom sklearn.model_selection import train_test_split\n\nfrom mlxtend.feature_extraction import PrincipalComponentAnalysis\nfrom mlxtend.preprocessing import standardize\n\nfrom mlxtend.plotting import plot_pca_correlation_graph\n\n\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import KBinsDiscretizer, FunctionTransformer\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.pipeline import make_pipeline, Pipeline\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read the Data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/churn-in-telecoms-dataset/bigml_59c28831336c6604c800002a.csv')\ndf_orig = pd.read_csv('../input/churn-in-telecoms-dataset/bigml_59c28831336c6604c800002a.csv')\ntarget = 'churn'\ny = df[target]\nlabels = df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Look at the Data**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['phone number'], axis = 1)\ndf = df.drop(['area code'], axis = 1)\ndf = df.drop(['state'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['international plan'] = df['international plan'].map({'yes': 1, 'no': 0})\ndf['voice mail plan'] = df['voice mail plan'].map({'yes': 1, 'no': 0})\ndf['churn'] = df['churn'].map({True: 1, False: 0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create Train Test split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop([target],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Log Reg**"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nlr = LogisticRegression()\npipe = make_pipeline(scaler, lr)\n\npipe.fit(X_train, y_train)\n\ntrain_preds = pipe.predict(X_train)\ntest_preds = pipe.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stringify(data):\n    df = pd.DataFrame(data)\n    for c in df.columns.tolist():\n        df[c] = df[c].astype(str)\n    return df\n\nbinner = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\nobjectify = FunctionTransformer(func=stringify, \n                                validate=False)\nclf = LogisticRegression(class_weight='balanced')\nencoder = WOEEncoder()\nscorecard = make_pipeline(binner, objectify, encoder, lr)\n\n\nscores = cross_val_score(scorecard, X, y, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = Pipeline(scorecard.steps[:-1]).fit_transform(X, y).values\nused_cols = [c for c in df.columns.tolist() if c not in [target]]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1, stratify=y)\n\nclf.fit(X_train, y_train)\nimp_vals, imp_all = feature_importance_permutation(\n    predict_method=clf.predict, \n    X=X_test,\n    y=y_test,\n    metric='accuracy',\n    num_rounds=10,\n    seed=1)\n\nstd = np.std(imp_all, axis=1)\nindices = np.argsort(imp_vals)[::-1]\n\nplt.figure()\nplt.title(\"Scorecard Feature Importance via Permutation Importance\")\nplt.bar(range(X.shape[1]), imp_vals[indices],\n        yerr=std[indices])\n# plt.xticks(range(X.shape[1]), indices)\nplt.xticks(range(X.shape[1]), np.array(used_cols)[indices], rotation = 90)\nplt.xlim([-1, X.shape[1]])\nplt.ylim([0, 0.05])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_feat = ['customer service calls', 'total day minutes','total intl calls']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import TransformerMixin\n\nclass ForestEncoder(TransformerMixin):\n    \n    def __init__(self, forest):\n        self.forest = forest\n        self.n_trees = 1\n        try:\n            self.n_trees = self.forest.n_estimators\n        except:\n            pass\n        self.ohe = OneHotEncoder(cols=range(self.n_trees), use_cat_names=True)\n        \n    def fit(self, X, y=None):\n        self.forest.fit(X, y)\n        self.ohe.fit(self.forest.apply(X))\n        return self\n    \n    def transform(self, X, y=None):\n        return self.ohe.transform(self.forest.apply(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#entropy criterion\nused_cols = [c for c in df.columns.tolist() if c not in [target]]\nX, y = df[used_cols].values, df[target].values\n\nN = 5\n\nrf = RandomForestClassifier(max_depth = N, n_estimators=100, n_jobs=-1, random_state=42,criterion = 'entropy', max_leaf_nodes = 2**N-1)\nencoder = ForestEncoder(rf)\nclf = LogisticRegression(class_weight='balanced')\npipe = make_pipeline(encoder, clf)\npipe.fit(X, y)\n\nscores = cross_val_score(rf, X, y, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gini criterion\n\nrf = RandomForestClassifier(max_depth = N, n_estimators=100, n_jobs=-1, random_state=42,criterion = 'gini', max_leaf_nodes = 2**N-1)\nencoder = ForestEncoder(rf)\nclf = LogisticRegression(class_weight='balanced')\npipe = make_pipeline(encoder, clf)\npipe.fit(X, y)\n\nscores = cross_val_score(rf, X, y, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = ForestEncoder(rf)\nclf = LogisticRegression(class_weight='balanced')\npipe = make_pipeline(encoder, clf)\n\nscores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(X.shape[1]):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n# Plot the feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(X.shape[1]), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(X.shape[1]), np.array(used_cols)[indices], rotation = 90)\nplt.xlim([-1, X.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_imp_feat = ['total day charge','total day minutes','total eve charge']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dealing with Imbalances **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#smote to affect imbalances\n\nsmote = SMOTE()\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\nN = 5\n\nrf = RandomForestClassifier(max_depth = N, n_estimators=100, n_jobs=-1, \n                            random_state=42,criterion = 'entropy', \n                            max_leaf_nodes = 2**N-1)\nencoder = ForestEncoder(rf)\nclf = LogisticRegression(class_weight='balanced')\npipe = make_pipeline(encoder, clf)\npipe.fit(X_resampled, y_resampled)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(rf, X_resampled, y_resampled, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hyper Parameter Tuning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create train test split for resampled data\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_resampled, y_resampled, test_size=0.2, random_state=1, stratify=y_resampled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_p = {\"n_estimators\": [20, 50, 100],\n          \"criterion\": [\"gini\", \"entropy\"],\n          \"max_features\": ['sqrt', 'log2', 0.2],\n          \"max_depth\": [4, 6, 10],\n          \"min_samples_split\": [2, 5, 10],\n          \"min_samples_leaf\": [1, 5, 10]}\n\ngrid_search = GridSearchCV(rf, grid_p, n_jobs=-1, cv=5, scoring='roc_auc')\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(criterion='entropy',\n max_depth=10,\n max_features='sqrt',\n min_samples_leaf=1,\n min_samples_split=5,\n n_estimators=20)\nencoder = ForestEncoder(rf)\nclf = LogisticRegression(class_weight='balanced')\npipe = make_pipeline(encoder, clf)\npipe.fit(X_resampled, y_resampled)\n\nscores = cross_val_score(rf, X_resampled, y_resampled, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(criterion='entropy',\n max_depth=10,\n max_features='sqrt',\n min_samples_leaf=5,\n min_samples_split=2,\n n_estimators=100)\nencoder = ForestEncoder(rf)\nclf = LogisticRegression(class_weight='balanced')\npipe = make_pipeline(encoder, clf)\npipe.fit(X_resampled, y_resampled)\n\nscores = cross_val_score(rf, X_resampled, y_resampled, cv=5, scoring='roc_auc')\nprint(scores.mean(), \"+/-\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}