{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://github.com/rasbt/deeplearning-models)\n\n## Code Modules","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch,tensorflow as tf\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class tdata(tds):\n    def __init__(self,X,y):   \n        self.X=torch.tensor(X,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        image,label=self.X[index],self.y[index]\n        return image,label\n    def __len__(self):\n        return self.y.shape[0]\ndef tloaders(x_train,y_train,x_test,y_test,batch_size):\n    train=tdata(x_train,y_train)\n    test=tdata(x_test,y_test)\n    train_loader=tdl(dataset=train,\n                     batch_size=batch_size,shuffle=True)\n    test_loader=tdl(dataset=test,\n                    batch_size=batch_size,shuffle=False)\n    return train_loader,test_loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train,y_train),(x_test,y_test)=\\\ntf.keras.datasets.mnist.load_data()\nx_train=np.array(x_train,dtype='float32')/255\nx_train=x_train.reshape(-1,28,28,1)\nx_test=x_test.reshape(-1,28,28,1)\nx_test=np.array(x_test,dtype='float32')/255\ny_train=np.array(y_train,dtype='int32')\ny_test=np.array(y_test,dtype='int32')\nx_train.shape,y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader,test_loader=\\\ntloaders(x_train,y_train,x_test,y_test,64)\nfor images,labels in train_loader:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')/255\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.2*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_train=x[:n],x[n:]\ny_test,y_train=y[:n],y[n:]\nx_train.shape,y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader2,test_loader2=\\\ntloaders(x_train,y_train,x_test,y_test,64)\nfor images,labels in train_loader2:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MLP with Sigmoid Activation & MSE Loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class MLPS():\n    def __init__(self,num_features,hidden,num_classes):\n        super(MLPS,self).__init__()\n        self.num_features=num_features\n        self.num_classes=num_classes\n        self.weight1=torch.zeros(hidden,num_features, \n                                 dtype=torch.float).normal_(0.,.1)\n        self.bias1=torch.zeros(hidden,dtype=torch.float)\n        self.weightout=torch.zeros(self.num_classes,hidden, \n                                   dtype=torch.float).normal_(0.,.1)\n        self.biasout=torch.zeros(self.num_classes,dtype=torch.float)        \n    def forward(self,x):\n        z1=torch.mm(x,self.weight1.t())+self.bias1\n        a1=torch.sigmoid(z1)\n        z2=torch.mm(a1,self.weightout.t())+self.biasout\n        a2=torch.sigmoid(z2)\n        return a1,a2\n    def backward(self,x,a1,a2,y):  \n        y_ohe=torch.FloatTensor(y.size(0),self.num_classes)\n        y_ohe.zero_()\n        y_ohe.scatter_(1,y.view(-1,1).long(),1)\n        dloss_da2=2.*(a2-y_ohe)/y.size(0)\n        da2_dz2=a2*(1.-a2)\n        delta_out=dloss_da2*da2_dz2\n        dz2__dw_out=a1\n        dloss__dw_out=torch.mm(delta_out.t(),dz2__dw_out)\n        dloss__db_out=torch.sum(delta_out,dim=0)\n        dz2__a1=self.weightout\n        dloss_a1=torch.mm(delta_out,dz2__a1)\n        da1__dz1=a1*(1.-a1)\n        dz1__dw1=x\n        dloss_dw1=torch.mm((dloss_a1*da1__dz1).t(),dz1__dw1)\n        dloss_db1=torch.sum((dloss_a1*da1__dz1),dim=0)\n        return dloss__dw_out,dloss__db_out,dloss_dw1,dloss_db1","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def ohe(y,num_classes):\n    y_ohe=torch.FloatTensor(y.size(0),num_classes)\n    y_ohe.zero_()\n    y_ohe.scatter_(1,y.view(-1,1).long(),1).float()\n    return y_ohe\ndef tloss(targets_ohe,probs_ohe):\n    return torch.mean(torch.mean((targets_ohe-probs_ohe)**2,dim=0))\ndef tmse(model,data_loader):\n    curr_mse=torch.zeros(model.num_classes).float()\n    num_examples=0\n    with torch.no_grad():\n        for features,targets in data_loader:\n            features=features.view(-1,model.num_features)\n            logits,probs=model.forward(features)\n            y_ohe=ohe(targets,model.num_classes)\n            loss=torch.sum((y_ohe-probs)**2,dim=0)\n            num_examples+=targets.size(0)\n            curr_mse+=loss\n        curr_mse=torch.mean(curr_mse/num_examples,dim=0)\n        return curr_mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_train(model,data_loader,num_epochs,learning_rate=.1):\n    minibatch_cost=[]; epoch_cost=[]  \n    for e in range(num_epochs):\n        for batch_idx,(features,targets) in enumerate(data_loader):            \n            features=features.view(-1,model.num_features)\n            a1,a2=model.forward(features)\n            dloss__dw_out,dloss__db_out,dloss_dw1,dloss_db1=\\\n            model.backward(features,a1,a2,targets)\n            model.weight1-=learning_rate*dloss_dw1\n            model.bias1-=learning_rate*dloss_db1\n            model.weightout-=learning_rate*dloss__dw_out\n            model.biasout-=learning_rate*dloss__db_out\n            curr_cost=tloss(ohe(targets,model.num_classes),a2)\n            minibatch_cost.append(curr_cost)\n            if not batch_idx%300:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(e+1,num_epochs,batch_idx,\n                         len(data_loader),curr_cost))        \n        curr_cost=tmse(model,data_loader)\n        epoch_cost.append(curr_cost)\n        print('Epoch: %03d/%03d |'%(e+1,num_epochs),end=\" \")\n        print('Train MSE: %.5f'%curr_cost)\n    return minibatch_cost,epoch_cost\ndef model_acc(model,data_loader):\n    correct_pred,num_examples=0,0\n    with torch.no_grad():\n        for features,targets in data_loader:\n            features=features.view(-1,model.num_features)\n            _,outputs=model.forward(features)\n            predicted_labels=torch.argmax(outputs,1)\n            num_examples+=targets.size(0)\n            correct_pred+=(predicted_labels==targets).sum()\n        return correct_pred.float()/num_examples*100 ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 1","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"torch.manual_seed(23)\nmodel=MLPS(num_features=28*28*1,\n           hidden=128,num_classes=10)\nminibatch_cost,epoch_cost=\\\nmodel_train(model,train_loader,\n            num_epochs=50,learning_rate=.07)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy: %.2f'%model_acc(model,train_loader))\nprint('Test Accuracy: %.2f'%model_acc(model,test_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for features,targets in test_loader:\n    break\nfig,ax=pl.subplots(1,5)\nfor i in range(5):\n    ax[i].imshow(features[5+i].view(28,28),\n                 cmap=pl.cm.bone)\n_,predictions=\\\nmodel.forward(features[5:10].view(-1,model.num_features))\npred_labels=torch.argmax(predictions,dim=1)\nprint('Predicted labels: ',pred_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"torch.manual_seed(23)\nmodel=MLPS(num_features=32*32*3,\n           hidden=512,num_classes=33)\nminibatch_cost2,epoch_cost2=\\\nmodel_train(model,train_loader2,\n            num_epochs=200,learning_rate=.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy: %.2f'%model_acc(model,train_loader2))\nprint('Test Accuracy: %.2f'%model_acc(model,test_loader2))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}