{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pneumothorax binary classification with Pytorch \n\n### Tasks\n##### 1. With small sub sample of Pneumothorax dataset use pre trained Pytorch models to get Pneumothorax sufficient level of accuracy\n##### 2. Explore Pytorch API","metadata":{}},{"cell_type":"markdown","source":"##### Insipred by https://www.kaggle.com/abhishek and his book *Approaching (Almost) Any Machine Learning Problem* https://www.amazon.com/Approaching-Almost-Machine-Learning-Problem-ebook/dp/B089P13QHT","metadata":{}},{"cell_type":"code","source":"pip install pretrainedmodels","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:50:22.240874Z","iopub.execute_input":"2021-07-25T15:50:22.241392Z","iopub.status.idle":"2021-07-25T15:50:32.635375Z","shell.execute_reply.started":"2021-07-25T15:50:22.241283Z","shell.execute_reply":"2021-07-25T15:50:32.634402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations\nimport torch\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pretrainedmodels\nimport torch.nn as nn\nfrom PIL import Image\nfrom PIL import ImageFile\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:50:32.63716Z","iopub.execute_input":"2021-07-25T15:50:32.637561Z","iopub.status.idle":"2021-07-25T15:50:37.066377Z","shell.execute_reply.started":"2021-07-25T15:50:32.637515Z","shell.execute_reply":"2021-07-25T15:50:37.065589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class that read data in map-stype way \n# To read more https://pytorch.org/docs/stable/data.html\n\nclass ClassificationDataset:\n    \"\"\"\n    A general classification dataset class\n    \"\"\"\n    def __init__(self, image_paths, targets, resize=None, augmentations=None):\n        \"\"\"\n         image_paths: list of path to images\n         targets: numpy array\n         resize: tuple. Will resizes image if not None\n         augmentations: albumentation augmentations of images\n        \"\"\"\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        \"\"\"\n        Return the total number of samples in the dataset\n        \"\"\"\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        \"\"\"\n        Given an index will get image from dataset\n        \"\"\"\n        # PIL to open the image\n        image = Image.open(self.image_paths[item])\n        # convert image to RGB\n        image = image.convert(\"RGB\")\n        # get the from data targets\n        targets = self.targets[item]\n        # resize if Not None\n        if self.resize is not None:\n            image = image.resize((self.resize[1], self.resize[0]), resample=Image.BILINEAR)\n        # convert to numpy array\n        image = np.array(image)\n        # if albumentation not None\n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        # pytorch expects CHW instead of HWC\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        # Return tensor of images and targets \n        return {\"image\": torch.tensor(image, dtype=torch.float), \"targets\": torch.tensor(targets, dtype=torch.long)}","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:50:37.068317Z","iopub.execute_input":"2021-07-25T15:50:37.068781Z","iopub.status.idle":"2021-07-25T15:50:37.080964Z","shell.execute_reply.started":"2021-07-25T15:50:37.068714Z","shell.execute_reply":"2021-07-25T15:50:37.080103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to get an model\n# more about pretrained models  https://pytorch.org/vision/stable/models.html\n\ndef load_model_from():\n    # pretrained models from Pytorch with pretrainedmodels libs\n    model = pretrainedmodels.__dict__[\"resnet18\"](pretrained='imagenet')\n    # add final layers \n    model.last_linear = nn.Sequential(\n        nn.BatchNorm1d(512), # more here https://pytorch.org/docs/master/generated/torch.nn.BatchNorm1d.html#batchnorm1d\n        nn.Dropout(p=0.25), # \n        nn.Linear(in_features=512, out_features=2048),\n        nn.ReLU(),\n        nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=2048, out_features=1))\n\n    return model\n\n# You could play with BatchNorm1d, Dropout","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:50:37.082371Z","iopub.execute_input":"2021-07-25T15:50:37.082783Z","iopub.status.idle":"2021-07-25T15:50:37.092364Z","shell.execute_reply.started":"2021-07-25T15:50:37.082743Z","shell.execute_reply":"2021-07-25T15:50:37.091618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare device, set the paths, initialize the data loaders of Dataset class\n\nEPOCHS = 10 # set number of epoch to run \nNUM_WORKERS = 12 # could increase the time to calculate the results \nRANDOM_STATE = 11 # to repproduce results\n\n# path to images\ndata_path = \"../input/pneumothorax-binary-classification-task/small_train_data_set/small_train_data_set\"\n\n# cuda/cpu device (depends on your settings)\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\nprint(device)\n\n# load the dataframe of images path and targets \ndf = pd.read_csv(\"../input/pneumothorax-binary-classification-task/train_data.csv\")\n# add new column with full path\ndf['full_path_to_images'] = data_path + \"/\" + df.file_name.values\n\n# image ids and targets values \nimages = df.full_path_to_images.values.tolist()\ntargets = df.target.values\n\n# get the pretrained model\nmodel = load_model_from()\nprint(model)\n\n# move model to device https://pytorch.org/docs/stable/notes/cuda.html\nmodel.to(device)\n# mean and std values of RGB channels for imagenet dataset\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n# albumentations is an image augmentation library\naug = albumentations.Compose([albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)])\n\n# train_test_split date \ntrain_images, valid_images, train_targets, valid_targets = train_test_split(images, targets, stratify=targets, random_state=RANDOM_STATE)\n\n# set train dataset with batch_size\ntrain_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets, resize=(227, 227), augmentations=aug)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n\n# set test dataset with batch_size\nvalid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets, resize=(227, 227), augmentations=aug)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=NUM_WORKERS)\n\n# simple Adam optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:50:37.093917Z","iopub.execute_input":"2021-07-25T15:50:37.094362Z","iopub.status.idle":"2021-07-25T15:50:44.965357Z","shell.execute_reply.started":"2021-07-25T15:50:37.094328Z","shell.execute_reply":"2021-07-25T15:50:44.964389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate functions \n\ndef train(data_loader, model, optimizer, device):\n    \"\"\"\n    training for one epoch with selected model and params\n     data_loader:  pytorch dataloader\n     model: pytorch model\n     optimizer: optimizer \n     device: cuda/cpu\n    \"\"\"\n    # set training mode \n    model.train()\n    # go over every batch of data in data loader\n    for data in data_loader:\n        inputs = data[\"image\"]\n        targets = data[\"targets\"]\n        # move inputs/targets to cuda/cpu device\n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        # zero grad the optimizer\n        optimizer.zero_grad()\n        # do the forward step of model\n        outputs = model(inputs)\n        # calculate loss\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        # backward step the loss\n        loss.backward()\n        # step optimizer\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    \"\"\"\n    Evaluation for one epoch\n    data_loader: this is the pytorch dataloader\n    model: pytorch model\n    device: cuda/cpu\n    \"\"\"\n    # put model in evaluation mode\n    model.eval()\n    # init lists to store targets and outputs\n    final_targets = []\n    final_outputs = []\n    # no_grad context\n    with torch.no_grad():\n        for data in data_loader:\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            # generate prediction\n            output = model(inputs)\n            # convert targets and outputs to lists\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            # extend the original list\n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:50:44.966756Z","iopub.execute_input":"2021-07-25T15:50:44.967109Z","iopub.status.idle":"2021-07-25T15:50:44.980845Z","shell.execute_reply.started":"2021-07-25T15:50:44.967073Z","shell.execute_reply":"2021-07-25T15:50:44.980049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train and print auc score for all epochs\nfor epoch in tqdm(range(EPOCHS)):\n    # train \n    train(train_loader, model, optimizer, device=device)\n    # predict \n    predictions, valid_targets = evaluate(valid_loader, model, device=device)\n    # metrics \n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:50:44.983566Z","iopub.execute_input":"2021-07-25T15:50:44.983869Z","iopub.status.idle":"2021-07-25T15:56:07.630743Z","shell.execute_reply.started":"2021-07-25T15:50:44.983837Z","shell.execute_reply":"2021-07-25T15:56:07.629896Z"},"trusted":true},"execution_count":null,"outputs":[]}]}