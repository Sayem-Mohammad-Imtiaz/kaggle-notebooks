{"cells":[{"metadata":{},"cell_type":"markdown","source":"Influenza-like illness (ILI), also known as flu-like syndrome/symptoms, is a medical diagnosis of possible influenza or other illness causing a set of common symptoms. \n\nSymptoms commonly include fever, shivering, chills, malaise, dry cough, loss of appetite, body aches, and nausea, typically in connection with a sudden onset of illness. In most cases, the symptoms are caused by cytokines released by immune system activation, and are thus relatively non-specific. \n\nCommon causes of ILI include the common cold and influenza, which tends to be less common but more severe than the common cold. Less-common causes include side effects of many drugs and manifestations of many other diseases https://en.wikipedia.org/wiki/Influenza-like_illness\n\nHowever don't think to treat Covid-19 as Flu. The best succeeded countries were those that treated the outbreak like Sars, the killer virus that hit Asia in 2003, and saved lives. By contrast, the ones which response to coronavirus was based on planning for a flu pandemic had higher rates.  ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQeyIuhXNV4WfW7V8AEQJEdI592V-PwaGQbR928Obn5z0AEVZPT&usqp=CAU',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pt-br.facebook.com","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('../input/covid19-open-datasets-for-brazil/Flu-Like Syndrome/dados-nacional_01_06.csv', delimiter=';', encoding = \"ISO-8859-1\", nrows = nRowsRead)\ndf.dataframeName = 'dados-nacional_01_06.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes from  Pratik Barua https://www.kaggle.com/pratikbarua/house-pricing-predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"na_percent = (df.isnull().sum()/len(df))[(df.isnull().sum()/len(df))>0].sort_values(ascending=False)\n\nmissing_data = pd.DataFrame({'Missing Percentage':na_percent*100})\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Creating a Visualization of every feature with missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"na = (df.isnull().sum() / len(df)) * 100\nna = na.drop(na[na == 0].index).sort_values(ascending=False)\n\nf, ax = plt.subplots(figsize=(12,8))\nsns.barplot(x=na.index, y=na)\nplt.xticks(rotation='90')\nplt.xlabel('Features', fontsize=15)\nplt.title('Percentage Missing', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing some features with 'None'. Any of the below features with a missing value likely indicates that it doesn't exist (?)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('evolucaoCaso', 'dataEncerramento', 'cbo', 'dataNotificacao'):\n    df[col] = df[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing some features with their mode\n\nThe reason we fill in these features with their mode (most common value), meaning that if these values are missing it has to be because of the data, not because of the fact they are missing the feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('condicoes', 'resultadoTeste', 'tipoTeste', 'classificacaoFinal', 'dataTeste', 'bairro', 'estadoTeste'):\n    df[col] = df[col].fillna(df[col].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = [cname for cname in df.columns if\n                    df[cname].nunique() < 10 and \n                    df[cname].dtype == \"object\"]\n\n\n# Select numerical columns\nnumerical_cols = [cname for cname in df.columns if \n                df[cname].dtype in ['int64', 'float64']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(categorical_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Label Encoding.\nOur dataset cannot run with categorical columns so we must Label Encode these columns in order to make them numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncategorical_col = ('profissionalSaude', 'estadoTeste', 'tipoTeste', 'resultadoTeste', 'paisOrigem', 'sexo', 'estado', 'origem', 'estadoNotificacao', 'excluido', 'validado', 'evolucaoCaso', 'classificacaoFinal')\n        \n        \nfor col in categorical_col:\n    label = LabelEncoder() \n    label.fit(list(df[col].values)) \n    df[col] = label.transform(list(df[col].values))\n\nprint('Shape all_data: {}'.format(df.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking Skew - Create a new variable containing the dataset of only numerical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm, skew\nnum_features = df.dtypes[df.dtypes != 'object'].index\nskewed_features = df[num_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_features})\nskewness.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Skew Visualization - Visualize each numerical feature with distplot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_df = df.select_dtypes(exclude='object')\n\nfor i in range(len(numerical_df.columns)):\n    f, ax = plt.subplots(figsize=(7, 4))\n    fig = sns.distplot(numerical_df.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n    plt.xlabel(numerical_df.columns[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Hot-Encode Categorical features\ndf = pd.get_dummies(df) \n\n# Splitting dataset back into X and test data\nX = df[:len(df)]\ntest = df[len(df):]\n\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save target value for later\ny = df.resultadoTeste.values\n\n# In order to make imputing easier, we combine train and test data\ndf.drop(['resultadoTeste'], axis=1, inplace=True)\ndf = pd.concat((df, test)).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n# Indicate number of folds for cross validation\nkfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Parameters for models\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [0.00005, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#My 1st Lasso","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LassoCV\n# Lasso Model\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas = alphas2, random_state = 42, cv=kfolds))\n\n# Printing Lasso Score with Cross-Validation\nlasso_score = cross_val_score(lasso, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlasso_rmse = np.sqrt(-lasso_score.mean())\nprint(\"LASSO RMSE: \", lasso_rmse)\nprint(\"LASSO STD: \", lasso_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nlasso.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas = alphas_alt, cv=kfolds))\nridge_score = cross_val_score(ridge, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nridge_rmse =  np.sqrt(-ridge_score.mean())\n# Printing out Ridge Score and STD\nprint(\"RIDGE RMSE: \", ridge_rmse)\nprint(\"RIDGE STD: \", ridge_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nridge.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\nelastic_score = cross_val_score(elasticnet, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nelastic_rmse =  np.sqrt(-elastic_score.mean())\n\n# Printing out ElasticNet Score and STD\nprint(\"ELASTICNET RMSE: \", elastic_rmse)\nprint(\"ELASTICNET STD: \", elastic_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nelasticnet.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\nlightgbm = make_pipeline(RobustScaler(),\n                        LGBMRegressor(objective='regression',num_leaves=5,\n                                      learning_rate=0.05, n_estimators=720,\n                                      max_bin = 55, bagging_fraction = 0.8,\n                                      bagging_freq = 5, feature_fraction = 0.2319,\n                                      feature_fraction_seed=9, bagging_seed=9,\n                                      min_data_in_leaf =6, \n                                      min_sum_hessian_in_leaf = 11))\n\n# Printing out LightGBM Score and STD\nlightgbm_score = cross_val_score(lightgbm, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlightgbm_rmse = np.sqrt(-lightgbm_score.mean())\nprint(\"LIGHTGBM RMSE: \", lightgbm_rmse)\nprint(\"LIGHTGBM STD: \", lightgbm_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nlightgbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nxgboost = make_pipeline(RobustScaler(),\n                        XGBRegressor(learning_rate =0.01, n_estimators=3460, \n                                     max_depth=3,min_child_weight=0 ,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,nthread=4,\n                                     scale_pos_weight=1,seed=27, \n                                     reg_alpha=0.00006))\n\n# Printing out XGBOOST Score and STD\nxgboost_score = cross_val_score(xgboost, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nxgboost_rmse = np.sqrt(-xgboost_score.mean())\nprint(\"XGBOOST RMSE: \", xgboost_rmse)\nprint(\"XGBOOST STD: \", xgboost_score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model for later\nxgboost.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viewing Model Performance - View Model Performance through a DataFrame and a barplot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'Model':['Lasso',\n            'Ridge',\n            'ElasticNet',\n            'LightGBM',\n            'XGBOOST',\n            ],\n    'Score':[lasso_rmse,\n             ridge_rmse,\n             elastic_rmse,\n             lightgbm_rmse,\n             xgboost_rmse,\n             \n            ]})\n\nsorted_result = results.sort_values(by='Score', ascending=True).reset_index(drop=True)\nsorted_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(14,8))\nplt.xticks(rotation='90')\nsns.barplot(x=sorted_result['Model'], y=sorted_result['Score'])\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Performance', fontsize=15)\nplt.ylim(0.10, 0.12)\nplt.title('RMSE', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have no clue why there is no bar and how to fix it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Stacking - Predict every model, then combine every prediction into a final predictions used for submission","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Predict every model\nlasso_pred = lasso.predict(test)\nridge_pred = ridge.predict(test)\nelasticnet_pred = elasticnet.predict(test)\nlightgbm_pred = lightgbm.predict(test)\nxgboost_pred = xgboost.predict(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stacking: At this point we basically trained and predicted each model so we can combine its predictions into a 'final_predictions' variable for submission","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"elasticnet_pred = elasticnet.predict(test)\n# Combine predictions into final predictions\nfinal_predictions = np.expm1((0.3*elasticnet_pred) + (0.3*lasso_pred) + (0.2*ridge_pred) + \n               (0.1*xgboost_pred) + (0.1*lightgbm_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission = pd.DataFrame()\n#submission['Id'] = test_Id\n#submission['resultadoTeste'] = final_predictions\n#submission.to_csv('house_pricing_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks for the script Pratik Barua https://www.kaggle.com/pratikbarua/house-pricing-predictions","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcR4VMlKNr5b886C0n7yTB-XHxufMF6P7jlpBgSiPhpIRYnHgEGZ&usqp=CAU',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"flu-likesymptons.com","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Kaggle Notebook Runner: Marília Prata  @mpwolke","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}