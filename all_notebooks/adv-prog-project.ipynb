{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport sys\nimport numpy as np\nimport random as rn\nimport pandas as pd\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data understanding and Overview","metadata":{}},{"cell_type":"markdown","source":"Read & view dataset :","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nreview_df=pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\").iloc[:10000, :]\n\nreview_df.head(10)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"show simple describtion of dataset number of positive and negative records:","metadata":{}},{"cell_type":"code","source":"print(review_df['sentiment'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ploting bar plot flowshart (comparing number of positive and negative records) :","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(6,5))\nsns.set(style = \"darkgrid\" , font_scale = 1.2)\nsns.countplot(review_df.sentiment)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"chose just positve reviews of our data frame ,,,to use it in wordcloud visualizing :","metadata":{}},{"cell_type":"code","source":"positive_values = review_df[(review_df.review .notnull()) & (review_df.sentiment == \"positive\")]\n\npositive_values.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ploting wordcloud for positive values :","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS \nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nwordcloud = WordCloud(width=500,height=250, max_font_size=80, max_words=150, background_color=\"white\").generate(positive_values.review[0])\nf = plt.figure() \nf.set_figwidth(15) \nf.set_figheight(10) \nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"chose just negative reviews of our data frame ,,,to use it in wordcloud visualizing :","metadata":{}},{"cell_type":"code","source":"negative_values=review_df[(review_df.review .notnull()) & (review_df.sentiment == \"negative\")]\n\nnegative_values.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ploting wordcloud for negative values :","metadata":{}},{"cell_type":"code","source":"wordcloud = WordCloud(width=500,height=250, max_font_size=80, max_words=150, background_color=\"white\").generate(negative_values.review[11])\n\n\nf = plt.figure() \nf.set_figwidth(15) \nf.set_figheight(10) \n\n \nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\n \nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing phase","metadata":{}},{"cell_type":"markdown","source":"1. Turn sentiment into categorical values :","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nreview_df['sentiment'] = labelencoder.fit_transform(review_df['sentiment'])\n\nreview_df['sentiment'].head(10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Remove none text and special character\n","metadata":{}},{"cell_type":"code","source":"%%time\n\nimport re\nimport string\npattern = re.compile(r'<br\\s*/><br\\s*/>>*|(\\-)|(\\\\)|(\\/)')\ndef preprocess_reviews(reviews):\n    reviews = [pattern.sub(\" \",item) for item in reviews]\n    return reviews\nclean = preprocess_reviews(review_df['review'])\n\nreview_df['review'] = clean\n\ndef remove_punctuation(input):\n    table = str.maketrans('','',string.punctuation)\n    return input.translate(table)\nreview_df['review'] = review_df['review'].apply(remove_punctuation)\n\nreview_df['review'].head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Convert all text to lowercase","metadata":{}},{"cell_type":"code","source":"review_df['review'] = review_df['review'].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_df.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Remove line breaks","metadata":{}},{"cell_type":"code","source":"%%time\nreview_df['review']=review_df['review'].apply(str)\ndef remove_linebreaks(input):\n    text = re.compile(r'\\n')\n    return text.sub(r' ',input)\nreview_df['review'] = review_df['review'].apply(remove_linebreaks)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Tokenization","metadata":{}},{"cell_type":"code","source":"%%time\nfrom nltk.tokenize import word_tokenize\nreview_df['review'] = review_df['review'].apply(word_tokenize)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_df.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Remove stopword","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrom nltk.corpus import stopwords\ndef remove_stopwords(input1):\n    words = []\n    for word in input1:\n            if word not in stopwords.words('english'):\n             words.append(word)\n    return words\nreview_df['review'] = review_df['review'].apply(remove_stopwords)\n\n\nreview_df['review'].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. Lemmatization","metadata":{}},{"cell_type":"code","source":"%%time\nfrom nltk.stem import WordNetLemmatizer\nlem = WordNetLemmatizer()\ndef lemma_wordnet(input):\n    return [lem.lemmatize(w) for w in input]\nreview_df['review'] = review_df['review'].apply(lemma_wordnet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_df.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"8. Combine individual words","metadata":{}},{"cell_type":"code","source":"%%time\ndef combine_text(input):\n    combined = '  '.join(input)\n    return combined\nreview_df['review'] = review_df['review'].apply(combine_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_df['review'].head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-darkgrid')\nplt.figure(figsize=(10,5))\nsns.distplot(review_df['review'].apply(len),kde=False,color='red',hist=True)\nplt.xlabel(\"Rivew Length\",size=15)\nplt.ylabel(\"Frequency\",size=15)\nplt.title(\"Length Histogram\",size=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"determine X:review , y:seniment (label and target feature of dataset)to use it later in ML models : ","metadata":{}},{"cell_type":"code","source":"X=review_df.iloc[:,0:1].values\ny=review_df.iloc[:,-1].values\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word embedding techniques (Text  features extraction) ","metadata":{}},{"cell_type":"markdown","source":"**Since we have reviews as text and we want to run a mathematical model we need a method to convert the text to numbers**","metadata":{}},{"cell_type":"markdown","source":"A. Bag of words ","metadata":{}},{"cell_type":"code","source":"# from sklearn.feature_extraction.text import CountVectorizer\n# cv=CountVectorizer(max_features=1000)\n# X=cv.fit_transform(review_df['review']).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"B. TF-IDF **","metadata":{}},{"cell_type":"code","source":"# import sklearn\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))\n# X = tfidf.fit_transform(review_df.review).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"C. Hashing ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import HashingVectorizer\nhv = HashingVectorizer(n_features=1000)\nX=hv.fit_transform(review_df['review']).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"spliting data into train and test set by using sklearn’s train_test_split :","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing machine learningModels( classification models )","metadata":{}},{"cell_type":"markdown","source":"build and prepare models :","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier as RFC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\n\n#Gaussian Naive Bayes model\nclf1=GaussianNB()\n\n#Bernoulli model\nclf2=BernoulliNB()\n\n#Ridge Classifier model\nclf3=RidgeClassifier()\n\n#Random Forest Classifier model \nclf4 = RFC(n_jobs = 2, random_state = 0)\n\n#Support Vector Machine Classifier model\nclf5 = SVC(kernel='linear')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train models on our dataset :","metadata":{}},{"cell_type":"code","source":"clf1.fit(X_train,y_train)\nclf2.fit(X_train,y_train)\nclf3.fit(X_train,y_train)\nclf4.fit(X_train,y_train)\nclf5.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluating our trined machine learning models :","metadata":{}},{"cell_type":"code","source":"y_pred1=clf1.predict(X_test)\ny_pred2=clf2.predict(X_test)\ny_pred3=clf3.predict(X_test)\ny_pred4=clf4.predict(X_test)\ny_pred5=clf5.predict(X_test)\n\nacc1=accuracy_score(y_test,y_pred1)\nacc2=accuracy_score(y_test,y_pred2)\nacc3=accuracy_score(y_test,y_pred3)\nacc4=accuracy_score(y_test,y_pred4)\nacc5=accuracy_score(y_test,y_pred5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get acuracy score results for trained models :\nprint(\"Gaussian\",acc1,\"%\")\nprint(\"Bernaulli\",acc2,\"%\")\nprint(\"RidgeClassifier\",acc3,\"%\")\nprint(\"Random Forest\",acc4,\"%\")\nprint(\"Support Vector Machine\",acc5,\"%\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting Models Accuaracy scores :**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(7,5))\nax = fig.add_axes([0,0,1,1])\nmodels = ['Gaussian ', 'Bernaulli ', 'Ridge ', 'Random Forest ', 'SVM']\naccurisy = [acc1*100 ,acc2*100,acc3*100,acc4*100,acc5*100]\nax.bar(models,accurisy,color = 'bgmrc',width = 0.8)\nplt.xlabel(\"ML model\",size=15)\nplt.ylabel(\"Accuracy\",size=15)\n \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get evaluation metrics of ML models (confusion_matrix ,accuracy , precision,recall,f1-score ,support ) :","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nfrom yellowbrick.datasets import load_occupancy\nfrom yellowbrick.classifier import classification_report\nclas = ['Bad Reviews','Good Reviews']\nvisualizer = classification_report(\n    clf1, X_train, y_train, X_test, y_test, classes=clas, support=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Co_Mat = confusion_matrix(y_test,y_pred1)\nprint(Co_Mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(y_test,y_pred1)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"YlOrRd\", \n            linecolor = 'black', \n            linewidth = 1, \n            annot = True, \n            fmt='', \n            xticklabels = ['Bad Reviews','Good Reviews'], \n            yticklabels = ['Bad Reviews','Good Reviews'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nfrom yellowbrick.datasets import load_occupancy\nfrom yellowbrick.classifier import classification_report\nclas = ['Bad Reviews','Good Reviews']\nvisualizer = classification_report(\n    clf2, X_train, y_train, X_test, y_test, classes=clas, support=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Co_Mat = confusion_matrix(y_test,y_pred2)\nprint(Co_Mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(y_test,y_pred2)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"YlOrRd\", \n            linecolor = 'black', \n            linewidth = 1, \n            annot = True, \n            fmt='', \n            xticklabels = ['Bad Reviews','Good Reviews'], \n            yticklabels = ['Bad Reviews','Good Reviews'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see RidgeClassifier  model gave the highest accuricy , so lits show it‘s classification report:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nfrom yellowbrick.datasets import load_occupancy\nfrom yellowbrick.classifier import classification_report\nclas = ['Bad Reviews','Good Reviews']\nvisualizer = classification_report(\n    clf3, X_train, y_train, X_test, y_test, classes=clas, support=True\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Co_Mat = confusion_matrix(y_test,y_pred3)\nprint(Co_Mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(y_test,y_pred3)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"YlOrRd\", \n            linecolor = 'black', \n            linewidth = 1, \n            annot = True, \n            fmt='', \n            xticklabels = ['Bad Reviews','Good Reviews'], \n            yticklabels = ['Bad Reviews','Good Reviews'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Rabdom Forest  classification report is :\\n\")\n# print(classification_report(y_test,y_pred4, target_names = ['Bad Reviews','Good Reviews']))\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom yellowbrick.datasets import load_occupancy\nfrom yellowbrick.classifier import classification_report\nclas = ['Bad Reviews','Good Reviews']\nvisualizer = classification_report(\n    clf4, X_train, y_train, X_test, y_test, classes=clas, support=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Co_Mat = confusion_matrix(y_test,y_pred4)\nprint(Co_Mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(y_test,y_pred4)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"YlOrRd\", \n            linecolor = 'black', \n            linewidth = 1, \n            annot = True, \n            fmt='', \n            xticklabels = ['Bad Reviews','Good Reviews'], \n            yticklabels = ['Bad Reviews','Good Reviews'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"SVM  classification report is :\\n\")\n# print(classification_report(y_test,y_pred5, target_names = ['Bad Reviews','Good Reviews']))\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom yellowbrick.datasets import load_occupancy\nfrom yellowbrick.classifier import classification_report\nclas = ['Bad Reviews','Good Reviews']\nvisualizer = classification_report(\n    clf5, X_train, y_train, X_test, y_test, classes=clas, support=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Co_Mat = confusion_matrix(y_test,y_pred5)\nprint(Co_Mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(y_test,y_pred5)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"YlOrRd\", \n            linecolor = 'black', \n            linewidth = 1, \n            annot = True, \n            fmt='', \n            xticklabels = ['Bad Reviews','Good Reviews'], \n            yticklabels = ['Bad Reviews','Good Reviews'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pytorch_pretrained_bert","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom pytorch_pretrained_bert import BertModel\nfrom torch import nn\n# from torchnlp.datasets import imdb_dataset      # --> We are using our own uploaded dataset.\nfrom pytorch_pretrained_bert import BertTokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom torch.optim import Adam\nfrom torch.nn.utils import clip_grad_norm_\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rn.seed(321)\nnp.random.seed(321)\ntorch.manual_seed(321)\ntorch.cuda.manual_seed(321)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/imdb-50k-movie-reviews-test-your-bert/'\n\n# experimenting here with a sample of dataset, to avoid memory overflow.\n\ntrain_data = pd.read_csv(path + 'train.csv')\ntest_data = pd.read_csv(path + 'test.csv')\n\n\n\n\n# experimenting here with a sample of dataset, to avoid memory overflow.\ntrain_data = train_data[:7500]\ntest_data = test_data[:2500]\n\n\n# Convert the DataFrame to a dictionary , like [{'col1': 1.0, 'col2': 0.5}, {'col1': 2.0, 'col2': 0.75}]\ntrain_data = train_data.to_dict(orient='records')\ntest_data = test_data.to_dict(orient='records')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\ntest_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n\nlen(train_texts), len(train_labels), len(test_texts), len(test_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"visualizing one of the sentences from train set","metadata":{}},{"cell_type":"code","source":"train_texts[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STEP 1: Preprocess Data and Build a Transformer Model","metadata":{}},{"cell_type":"code","source":"# pytorch_pretained_bert already available in kaggle conda env.\n!pip install pytorch-nlp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preparing Token embeddings","metadata":{}},{"cell_type":"code","source":"from pytorch_pretrained_bert import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.tokenize('Here is nashaat jouda welcome ')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\ntest_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n\nlen(train_tokens), len(test_tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preparing Token Ids..","metadata":{}},{"cell_type":"code","source":"train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\ntest_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n\ntrain_tokens_ids.shape, test_tokens_ids.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y = np.array(train_labels) == 'pos'\ntest_y = np.array(test_labels) == 'pos'\ntrain_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\ntest_masks =  [[float(i > 0) for i in ii] for ii in test_tokens_ids]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# baseline_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# baseline_predicted = baseline_model.predict(test_texts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(classification_report(test_labels, baseline_predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT Model","metadata":{}},{"cell_type":"code","source":"class BertBinaryClassifier(nn.Module):\n    def __init__(self, dropout=0.1):\n        super(BertBinaryClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, 1)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, tokens, masks=None):\n        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n        dropout_output = self.dropout(pooled_output)\n        linear_output = self.linear(dropout_output)\n        proba = self.sigmoid(linear_output)\n        return proba","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_clf = BertBinaryClassifier()\nbert_clf = bert_clf.cuda()     # running BERT on CUDA_GPU","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor(train_tokens_ids[:3]).to(device)\ny, pooled = bert_clf.bert(x, output_all_encoded_layers=False)\nx.shape, y.shape, pooled.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = bert_clf(x)\ny.cpu().detach().numpy()        # kinda Garbage Collector to free up used and cache space","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross- checking CUDA GPU Memory to ensure GPU memory is not overflowing.\nstr(torch.cuda.memory_allocated(device)/1000000 ) + 'M'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y, x, pooled = None, None, None\ntorch.cuda.empty_cache()     # Clearing Cache space for fresh Model run\nstr(torch.cuda.memory_allocated(device)/1000000 ) + 'M'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fine Tune BERT..","metadata":{}},{"cell_type":"code","source":"# Setting hyper-parameters\n\nBATCH_SIZE = 4\nEPOCHS = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokens_tensor = torch.tensor(train_tokens_ids)\ntrain_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n\ntest_tokens_tensor = torch.tensor(test_tokens_ids)\ntest_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n\ntrain_masks_tensor = torch.tensor(train_masks)\ntest_masks_tensor = torch.tensor(test_masks)\n\nstr(torch.cuda.memory_allocated(device)/1000000 ) + 'M'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n\ntest_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\ntest_sampler = SequentialSampler(test_dataset)\ntest_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_optimizer = list(bert_clf.sigmoid.named_parameters()) \noptimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(bert_clf.parameters(), lr=3e-6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()   # Clearing Cache space for a fresh Model run","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch_num in range(EPOCHS):\n    bert_clf.train()\n    train_loss = 0\n    for step_num, batch_data in enumerate(train_dataloader):\n        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n        logits = bert_clf(token_ids, masks)\n        \n        loss_func = nn.BCELoss()\n\n        batch_loss = loss_func(logits, labels)\n        train_loss += batch_loss.item()\n        \n        \n        bert_clf.zero_grad()\n        batch_loss.backward()\n        \n\n        clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        clear_output(wait=True)\n        print('Epoch: ', epoch_num + 1)\n        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_clf.eval()\nbert_predicted = []\nall_logits = []\nwith torch.no_grad():\n    for step_num, batch_data in enumerate(test_dataloader):\n\n        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n\n        logits = bert_clf(token_ids, masks)\n        loss_func = nn.BCELoss()\n        loss = loss_func(logits, labels)\n        numpy_logits = logits.cpu().detach().numpy()\n        \n        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n        all_logits += list(numpy_logits[:, 0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(bert_predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_y, bert_predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}