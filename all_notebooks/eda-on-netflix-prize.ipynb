{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport os\nimport random\nimport matplotlib\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nfrom scipy import sparse\nfrom scipy.sparse import csc_matrix\n\nfrom sklearn.decomposition import TruncatedSVD\n#from sklearn.metrics.pariwise import cosine_similarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\nif not os.path.isfile('data.csv'):\n    #read all txt file and store them in one big file\n    data = open('data.csv', mode='w')\n    \n    row = list()\n    files = ['../input/netflix-prize-data/combined_data_1.txt', '../input/netflix-prize-data/combined_data_2.txt',\n            '../input/netflix-prize-data/combined_data_3.txt', '../input/netflix-prize-data/combined_data_4.txt']\n    for file in files:\n        print('reading ratings from {}...'.format(file))\n        with open(file) as f:\n            for line in f:\n                del row[:]\n                line = line.strip()\n                if line.endswith(':'):\n                    #all are rating\n                    movid_id = line.replace(':', '')\n                else:\n                    row = [x for x in line.split(',')]\n                    row.insert(0, movid_id)\n                    data.write(','.join(row))\n                    data.write('\\n')\n        print('Done.\\n')\n    data.close()\nprint('time taken:', datetime.now() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('creating the dataframe from data.csv file..')\ndf = pd.read_csv('data.csv', sep=',', names=['movie','user','rating','date'])\n\ndf.date = pd.to_datetime(df.date)\nprint('Done.\\n')\n\n#arranging the rating according to time\nprint('sorting the dataframe by date..')\ndf.sort_values(by='date', inplace=True)\nprint('sorting done.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()['rating']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking NaN values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('number of NaN values in our dataset:', sum(df.isnull().any()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check and Remove Duplicate"},{"metadata":{"trusted":true},"cell_type":"code","source":"dup = df.duplicated(['movie','user','rating'])\ndups = sum(dup) #considering by column\nprint('there are {} duplicate rating entries in the data.....'.format(dups))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Basic Stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total Data')\nprint(\"-\"*60)\nprint('\\nTotal number of rating:', df.shape[0])\nprint('Total number of users:', len(np.unique(df.user)))\nprint('total number of movie:', len(np.unique(df.movie)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split the Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.isfile('train.csv'):\n    #create a dataframe and store it\n    df.iloc[:int(df.shape[0]*0.80)].to_csv(\"train.csv\", index=False)\nif not os.path.isfile('test.csv'):\n    #create a dataframe and store it\n    df.iloc[int(df.shape[0]*0.80)].to_csv(\"test.csv\", index=False)\n\ntrain_df = pd.read_csv('train.csv', parse_dates=['date'])\ntest_df = pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Basic Statistics on Train and Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of rating:',train_df.shape[0])\nprint('Total number of users:', len(np.unique(train_df.user)))\nprint('Total number of movies:', len(np.unique(train_df.movie)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of rating:',test_df.shape[0])\n#print('Total number of users:', len(np.unique(test_df.user)))\n#print('Total number of movies:', len(np.unique(test_df.movie)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EDA on Train Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def human(num, units='M'):\n    units = units.lower()\n    num = float(num)\n    if units == 'k':\n        return str(num/10**3) + \"K\"\n    elif units == 'm':\n        return str(num/10**6) + \"M\"\n    elif units == 'b':\n        return str(num/10**9) + \"B\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nplt.title('Distribution if rating over training dataset', fontsize=10)\nsns.countplot(train_df.rating)\nax.set_yticklabels([human(item,'M') for item in ax.get_yticks()])\nax.set_ylabel('No. of Ratings (Million)')\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above distribution we see that most people give a rating of 4 and few people gave a rating of 1 ."},{"metadata":{},"cell_type":"markdown","source":"Now add a 'week day' column for Data Analysis "},{"metadata":{"trusted":true},"cell_type":"code","source":"#It is used to skip the warnings\n#pd.options.mode.chained_assignment = None\n#train_df['day_of_week'] = train_df.date.dt.weekday_name\n\n#train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No. of Rating per Month"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = train_df.resample('m', on='date')['rating'].count().plot()\nax.set_title('No. of ratings per month (Training Data)')\nplt.xlabel('Month')\nplt.ylabel('No. of Rating per Month')\nax.set_yticklabels([human(item,'M') for item in ax.get_yticks()])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there is a massive growth of Netflix during the period 2003â€“2006. There are about 4.5 million ratings given by the users in 2005."},{"metadata":{},"cell_type":"markdown","source":"**Plot PDF(Probability Distribution Function) and CDF(Cumulative Distribution Function)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_rated_movie_per_user = train_df.groupby(by='user')['rating'].count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=plt.figaspect(.5))\n\nax1 = plt.subplot(121)\nsns.kdeplot(no_of_rated_movie_per_user, ax=ax1, shade=True)\nplt.xlabel('No of ratings by user')\nplt.ylabel('PDF')\n\n\n\nax2 = plt.subplot(122)\nsns.kdeplot(no_of_rated_movie_per_user, ax=ax2, shade=True, cumulative=True)\nplt.xlabel('No of ratings by user')\nplt.ylabel('CDF')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_rated_movie_per_user.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_ratings_per_movie = train_df.groupby(by='movie')['rating'].count().sort_values(ascending=True)\n\nfig = plt.figure(figsize=plt.figaspect(.5))\nax = plt.gca()\nplt.plot(no_of_ratings_per_movie.values)\nplt.title('Rating Per Movie')\nplt.xlabel('Movie')\nplt.ylabel('No. of Users who rated a Movie')\nax.set_xticklabels([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating sparse matrix from data frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\nif os.path.isfile('train_sparse_matrix.npz'):\n    train_sparse_matrix = sparse.load_npz('train_sparse_matrix.npz')\nelse:\n    train_sparse_matrix = sparse.csr_matrix((train_df.rating.values, (train_df.user.values, train_df.movie.values)),)\n    print('It is shape is:(user, movie):', train_sparse_matrix.shape)\n    \nprint(datetime.now() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sparsity of Train Sparse Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"us, mv = train_sparse_matrix.shape\nelem = train_sparse_matrix.count_nonzero()\n\nprint(elem)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sparsity of train matrix:{}%'.format((1-(elem/us*mv)))*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find Average of all movie ratings, average rating per user, average rating per movie"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_average_ratings(sparse_matrix, of_users):\n    #avg rating from user\n    ax = 1 if of_users else 0\n    \n    #'.A1' is for converting column_matrix to 1-D numpy array\n    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n    \n    #boolean matrix of ratings (user raed or not)\n    is_rated = sparse_matrix!=0\n    \n    #no.of ratings that each user\n    no_of_ratings = is_rated.sum(axis=ax).A1\n    \n    u,m = sparse_matrix.shape\n    \n    #create a dictionary of users and their avg \n    average_ratings = {i : sum_of_ratings[i]/no_of_ratings[i] for i in range(u if of_users else m) if no_of_ratings[i]!=0}\n    \n    return average_ratings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Global average of all movie ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_averages = dict()\n\n#get global average \ntrain_global_average = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\ntrain_averages['global'] = train_global_average\ntrain_averages","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Avg Rating per Movie"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_averages['movie'] = get_average_ratings(train_sparse_matrix, of_users=False)\nprint('\\n Average rating of movie 15:', train_averages['movie'][15])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PDF & CDF of Avg Ratings of Users and Movies**"},{"metadata":{},"cell_type":"markdown","source":"In Training Data********"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=plt.figaspect(.5))\nfig.suptitle('Avg Ratings per users and per Movie', fontsize=15)\n\nax1.set_title('users-avg-ratings')\n\n#getting a list of avg user rating from the avg dictionary\nuser_avg = [rat for rat in train_averages['user'].values()]\n\nsns.distplot(user_avg, ax=ax1, hint=False, kde_kws = dict(cumulative=True), label='Cdf')\n\nsns.distplot(user_avg, ax=ax1, hint=False,label='Pdf')\nax2.set_title('Movies-Avg-Rating')\n\n#getting a list of movie_avg user rating from the avg dictionary\n\nmovie_average = [rat for rat in train_averages['movie'].values()]\n\nsns.distplot(movie_average, ax=ax2, hint=False, kde_kws = dict(cumulative=True), label='Cdf')\n\nsns.distplot(movie_average, ax=ax2, hint=False,label='Pdf')\n\nplt.show()\nprint(datetime.now() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Computing Movie-Movie similarity Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\nif not os.path.isfile('m_m_sparse.npz'):\n    print('It seems dont have a file. computing movie_movie smimilarity...')\n    start = datetime.now()\n    m_m_sim_sparse = cosine_similarity(X=train_sparse_matrix.T, dense_output = False)\n    \n    #store this sparse matrix in disk \n    #print('saving it to disk without the need of re-computing it again')\n    #sparse.save_npz(\"m_m_sim_sparse.npz\", m_m_sim_sparse)\nelse:\n    print('it is there.')\n    m_m_sim_sparse = sparse.load_npz(\"m_m_sim_sparse\")\n    \nprint(\"it is a \", m_m_sim_sparse.shape, \"dimensional matrix\")\n\nprint(datetime.now() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We take only those top similar movie ratings and store them in a separate dictionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_ids = np.unique(m_m_sim_sparse.nonzero()[1])\n\nstart  = datetime.now()\nsimilaer_movies = dict()\nfor movie in movie_ids:\n    sim_movies = m_m_sim_sparse[movie].toarry().ravel().argsort()[::-1][1:]\n    similar_movies[movie] = sim_movie[:100]\nprint(datetime.now() - start)\n\n#testing similar movies for movie_15\nsimilar_movies[15]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding Most Similar Movie"},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_titles = pd.read_csv(\"../input/netflix-prize-data/movie_titles.csv\", sep=',', header=None, names=['movie_id', 'year_of_release', 'title'], verbose=True, index_col='movie_id', encoding='ISO-8859-1')\n\nmovie_titles.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}