{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/ccdata/CC GENERAL.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('CUST_ID', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Values","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(subset= ['CREDIT_LIMIT'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['MINIMUM_PAYMENTS'].fillna(df['MINIMUM_PAYMENTS'].median(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"i=1\nplt.figure(figsize= (20,40))\nfor col in df.columns:\n    plt.subplot(9,2,i)\n        \n    sns.distplot(df[col])\n    \n    i=i+1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.columns:\n    print(col)\n    print({df[col].skew()})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It seems that our data is skewed**\n\nTo deal with the skewness, we will transform it using square root method","metadata":{}},{"cell_type":"code","source":"i=1\nplt.figure(figsize=(20,40))\nfor col in df.columns:\n    plt.subplot(9,2,i)\n    df[col]= np.sqrt(df[col])\n    sns.distplot(df[col])\n    i=i+1\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There is still skewness, but it is better than before**","metadata":{}},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting correlation heatmap to see if there are many co=related features**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are many co-related features**","metadata":{}},{"cell_type":"markdown","source":"# Dimensionality Reduction","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nss= StandardScaler()\ndf= ss.fit_transform(df)\n\npca= PCA()\npca.fit(df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(pca.explained_variance_ratio_.cumsum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca= PCA(n_components=6)\nX= pca.fit_transform(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KMeans Clustering","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nplt.figure(figsize=(15,10))\ndistortions=[]\nsil_scores=[]\nfor i in range(2,30):\n    kmeans= KMeans(n_clusters=i, n_init=10, init= 'k-means++', algorithm='full', max_iter=300)\n    kmeans.fit(X)\n    distortions.append(kmeans.inertia_)\n    label= kmeans.labels_\n    sil_scores.append(silhouette_score(X, label))\nplt.plot(np.arange(2,30,1), distortions, alpha=0.5)\nplt.plot(np.arange(2,30,1), distortions,'o' ,alpha=0.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.plot(np.arange(2,30,1), sil_scores)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5 looks like the right number of clusters for this problem**","metadata":{}},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans= KMeans(n_clusters=5, n_init=10, init= 'k-means++', algorithm='full', max_iter=300)\nkmeans.fit(X)\nlabels= kmeans.labels_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We use PCA again so that we can reduce the data to 2 components, in order to visualize our clusters better**","metadata":{}},{"cell_type":"code","source":"pca= PCA(n_components=2)\nX2= pca.fit_transform(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_df = pd.DataFrame(data=X2, columns=['pca1','pca2'])\npca_df['labels']= labels\npca_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nax = sns.scatterplot(x='pca1', y='pca2', hue='labels', data=pca_df, palette='bright')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5 clusters look good. Let's try using 3 clusters also**","metadata":{}},{"cell_type":"code","source":"kmeans= KMeans(n_clusters=3, n_init=10, init= 'k-means++', algorithm='full', max_iter=300)\nkmeans.fit(X)\nlabels= kmeans.labels_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca= PCA(n_components=2)\nX2= pca.fit_transform(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_df = pd.DataFrame(data=X2, columns=['pca1','pca2'])\npca_df['labels']= labels\npca_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nax = sns.scatterplot(x='pca1', y='pca2', hue='labels', data=pca_df, palette='bright')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can group them using 3 or 5 clusters depending upon our use. Both can serve different purposes**","metadata":{}},{"cell_type":"markdown","source":"# Upvote and Comment if you liked my notebook :)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}