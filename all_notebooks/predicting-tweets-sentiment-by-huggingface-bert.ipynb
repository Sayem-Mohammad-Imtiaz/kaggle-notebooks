{"cells":[{"metadata":{"id":"2PoKARqOb42j","outputId":"70ddc9d1-1a11-4726-c139-903e46551ce0","trusted":true},"cell_type":"code","source":"!pip install --quiet transformers\n!pip install --quiet pytorch-lightning\n!pip install --quiet tokenizers\n!pip install --quiet sentencepiece","execution_count":null,"outputs":[]},{"metadata":{"id":"puLy5WX1b73z","trusted":true},"cell_type":"code","source":"import transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ../input/twitter-and-reddit-sentimental-analysis-dataset/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"id":"DNYxAU_Fqy4R","trusted":true},"cell_type":"code","source":"df = pd.read_csv('Twitter_Data.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"ipWtrAUPrcbb","outputId":"26a7b3e1-1074-40d1-aa15-0d092a26630c","trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"id":"zx0vwE6QwOlG","outputId":"a565c29f-7282-4fc5-ac6a-ebcf66a63b25","trusted":true},"cell_type":"code","source":"df[df['clean_text'].isnull()].index","execution_count":null,"outputs":[]},{"metadata":{"id":"VRDxBpQUwtuC","outputId":"7b368a5c-831e-43d7-ebe5-6f054b1e8633","trusted":true},"cell_type":"code","source":"df[df['category'].isnull()].index","execution_count":null,"outputs":[]},{"metadata":{"id":"ZhYG2N6zreSF","outputId":"1216ed0a-97e7-40c7-ef7d-3bfa4677e5fe","trusted":true},"cell_type":"code","source":"df = df.drop([148, 158694, 159443, 160560,130448, 155642, 155698, 155770, 158693, 159442, 160559])\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"1OBcX9YQr0RP","outputId":"2a6b2d49-5307-4bed-f76f-a95e80104ab5","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"N_Gns4klwna0","outputId":"3b29af6f-2966-43a0-e6df-9f940bd14626","trusted":true},"cell_type":"code","source":"sns.countplot(df.category)\nplt.xlabel('Twitter Category')","execution_count":null,"outputs":[]},{"metadata":{"id":"prVUXe8zJTve","trusted":true},"cell_type":"code","source":"def to_sentiment(rating):\n  rating = int(rating)\n  if rating == -1:\n    return 0\n  elif rating == 0 :\n    return 1\n  else:\n    return 2","execution_count":null,"outputs":[]},{"metadata":{"id":"ZlQVFf2yJpGu","trusted":true},"cell_type":"code","source":"df['sentiment'] = df.category.apply(to_sentiment)","execution_count":null,"outputs":[]},{"metadata":{"id":"QanBtp6kxNwl","outputId":"c9c8aaee-d79a-41bf-b518-d8dd6dbe246c","trusted":true},"cell_type":"code","source":"df.category.value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"id":"35J9JNyhHDy_","trusted":true},"cell_type":"code","source":"g = df.groupby('category')\ndf = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))","execution_count":null,"outputs":[]},{"metadata":{"id":"dmKlbmz6ZBK-","outputId":"1793f3b2-26b8-47bf-9530-318da97fdd3e","trusted":true},"cell_type":"code","source":"df.category.value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"id":"2JPqEZpbJ1zO","outputId":"38692f82-5867-4091-dfe8-21b133a6f89c","trusted":true},"cell_type":"code","source":"class_names = ['negative','neutral', 'positive']\nax = sns.countplot(df.sentiment)\nax.set_xticklabels(class_names);","execution_count":null,"outputs":[]},{"metadata":{"id":"G2rYna6QgajN","outputId":"3cc05e2a-75d1-494f-9f30-9c1df6fb6299","trusted":true},"cell_type":"code","source":"df = df.sample(frac=1)\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"ERlpTzZ-k-F7","trusted":true},"cell_type":"code","source":"PRE_TRAINED_MODEL_NAME = 'bert-base-cased'","execution_count":null,"outputs":[]},{"metadata":{"id":"4hPko88anBC3","outputId":"6b32f51b-2f59-4133-e780-b14e155a8a8e","trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","execution_count":null,"outputs":[]},{"metadata":{"id":"_fzYo4l1nDIU","trusted":true},"cell_type":"code","source":"MAX_LEN= 280\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{"id":"CLVtWEo7siwm","trusted":true},"cell_type":"code","source":"class TwitterSentimentDataset(Dataset):\n  def __init__(\n      self, tweets, targets, tokenizer, max_len\n      ):\n    self.tweets = tweets\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n\n  def __len__(self):\n    return len(self.tweets)\n  \n  def __getitem__(self, item):\n    tweets = str(self.tweets[item])\n    target = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      tweets,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      padding='max_length',\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n  \n    return {\n      'tweet_text': tweets,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }\n","execution_count":null,"outputs":[]},{"metadata":{"id":"1tfvvdajy3BR","trusted":true},"cell_type":"code","source":"df_train, df_test = train_test_split(\n  df,\n  test_size=0.06,\n  random_state=RANDOM_SEED\n)\ndf_val, df_test = train_test_split(\n  df_test,\n  test_size=0.5,\n  random_state=RANDOM_SEED\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"Vk58DB-u4BzJ","outputId":"81c18922-6a0a-4701-a5a2-112993ad4f56","trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"gmEk13Yi4Ndr","trusted":true},"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n  ds = TwitterSentimentDataset(\n    tweets=df.clean_text.to_numpy(),\n    targets=df.sentiment.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=MAX_LEN\n  )\t\n  return DataLoader(\n    ds,\n    batch_size=batch_size\n  )","execution_count":null,"outputs":[]},{"metadata":{"id":"gVbSdqn2AjFS","trusted":true},"cell_type":"code","source":"train_data_loader = create_data_loader(df_train,tokenizer,MAX_LEN,BATCH_SIZE)\nval_data_loader = create_data_loader(df_val,tokenizer,MAX_LEN,BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test,tokenizer,MAX_LEN,BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"id":"o5_mchAPAmtM","outputId":"16c7b549-35a8-4aa9-99fe-7c9528eee3b6","trusted":true},"cell_type":"code","source":"'''data = next(iter(train_data_loader))\ndata.keys()'''","execution_count":null,"outputs":[]},{"metadata":{"id":"fnfFYspVGJsV","outputId":"fd04c80d-dbb0-48df-c975-96d19283cbdb","trusted":true},"cell_type":"code","source":"bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)","execution_count":null,"outputs":[]},{"metadata":{"id":"80Hk0DpMGPDR","trusted":true},"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n  def __init__(self, n_classes):\n    super(SentimentClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n    self.softmax = nn.Softmax(dim=1)\n  def forward(self, input_ids, attention_mask):\n    output = self.bert(\n        input_ids = input_ids,\n        attention_mask = attention_mask\n    ) \n    pooled_output = output[1]\n    output = self.drop(pooled_output)\n    return self.out(output)\n    return self.softmax(output)","execution_count":null,"outputs":[]},{"metadata":{"id":"HGv3yZz7ReP6","trusted":true},"cell_type":"code","source":"model = SentimentClassifier(len(class_names))\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"a-_5YDENRr8L","trusted":true},"cell_type":"code","source":"EPOCHS = 5\noptimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\nloss_fn = nn.CrossEntropyLoss().to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"m98YkUK1TrB6","trusted":true},"cell_type":"code","source":"def train_epoch(\n  model,\n  data_loader,\n  loss_fn,\n  optimizer,\n  device,\n  scheduler,\n  n_examples\n):\n  model = model.train()\n  losses = []\n  correct_predictions = 0\n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    optimizer.zero_grad()\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    loss = loss_fn(outputs, targets)\n    _, preds = torch.max(outputs, dim=1)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n   \n  return correct_predictions.double() / n_examples, np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"id":"ounSajn7UrSh","trusted":true},"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n  losses = []\n  correct_predictions = 0\n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    with torch.no_grad():\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n  return correct_predictions.double() / n_examples, np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"id":"tqR65MBuVoOL","outputId":"00a2a56f-73b0-491e-8dcf-fcd23e58156f","trusted":true},"cell_type":"code","source":"%%time\nhistory = defaultdict(list)\nbest_accuracy = 0\nfor epoch in range(EPOCHS):\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\n  print('-' * 10)\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,\n    loss_fn,\n    optimizer,\n    device,\n    scheduler,\n    len(df_train)\n  )\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn,\n    device,\n    len(df_val)\n  )\n  print(f'Val loss {val_loss} accuracy {val_acc}')\n  print()\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n  if val_acc > best_accuracy:\n    best_accuracy = val_acc\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}