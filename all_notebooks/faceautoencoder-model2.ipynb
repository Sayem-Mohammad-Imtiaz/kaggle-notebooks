{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,InputLayer,Conv2DTranspose\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport numpy as np\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras import optimizers\nfrom keras import losses\nfrom keras import models\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/list_attr_celeba.csv\").head(10000)\nfnames=list(df.image_id.unique())\nfnames[0]\nimage = load_img(\"/kaggle/input/img_align_celeba/img_align_celeba/\"+fnames[0])\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(image).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.transform import resize\n# bottle_resized = resize(bottle, (140, 54), anti_aliasing=True)\ndef pre_process_image(image):\n#     if image.size != (28, height):  \n#     image=resize(image, (218,178, 3), anti_aliasing=True)\n    face_width = face_height = 50\n#     print(image.shape)\n    j = (image.shape[0] - face_width) // 2\n    i = (image.shape[1] - face_height) // 2\n    image = image[j: j + face_width, i:i + face_height]\n    #         image = image.resize([width, height], Image.BILINEAR)\n    return resize(image, IMAGE_SIZE+(3,), anti_aliasing=True)\n\ndef nopreprocess(x):\n    return x\n\nbatch_size = 64\nIMAGE_SIZE=(64, 64)\ntrain_datagen = ImageDataGenerator(rescale=1/255,preprocessing_function=pre_process_image)\n\ntrain_generator = train_datagen.flow_from_dataframe(df,\n        '/kaggle/input/img_align_celeba/img_align_celeba/',\n        target_size=IMAGE_SIZE, x_col='image_id',\n        batch_size=32, class_mode='input')\n\nvalidation_datagen = ImageDataGenerator(rescale=1/255,preprocessing_function=pre_process_image)\nvalidation_generator = validation_datagen.flow_from_dataframe(df.tail(20),\n        '/kaggle/input/img_align_celeba/img_align_celeba/',\n        target_size=IMAGE_SIZE, x_col='image_id',\n        batch_size=32, class_mode='input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_generator[0][0][1].astype(np.float))\nplt.show()\nplt.imshow(train_generator[0][0][1].astype(np.uint8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropout_rate = 0.5\n# DIMEN = 64\n# kernel_size = ( 4 , 4 )\n\n# NEURAL_SCHEMA = [\n\n#     Conv2D( 32 , input_shape=( DIMEN , DIMEN , 3 ) , kernel_size=kernel_size , strides=1,activation=\"relu\"),\n#     Dropout( dropout_rate ) ,\n#     Conv2D( 64, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n#     Conv2D( 128, kernel_size=kernel_size, strides=1, activation=\"relu\") ,\n#     Dropout(dropout_rate),\n#     Conv2D( 256, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n#     Flatten(),\n#     Reshape((52,52,256)),\n#     Conv2DTranspose( 128, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n#     Conv2DTranspose( 64, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n#     Conv2DTranspose( 32, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n#     Conv2DTranspose( 3, kernel_size=kernel_size, strides=1, activation=\"tanh\" ),\n\n# ]\n\n# model = Sequential( NEURAL_SCHEMA )\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#works\ndropout_rate = 0.3\nDIMEN = 64\nkernel_size = ( 4 , 4 )\n\nNEURAL_SCHEMA = [\n\n    Conv2D( 32 , input_shape=( DIMEN , DIMEN , 3 ) , kernel_size=kernel_size , strides=1,activation=\"relu\"),\n    Dropout( dropout_rate ) ,\n    BatchNormalization(),\n    Conv2D( 64, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n    Dropout(dropout_rate),\n    Conv2D( 128, kernel_size=kernel_size, strides=1, activation=\"relu\") ,\n    Dropout(dropout_rate),\n    Conv2D( 256, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n    Dropout(dropout_rate),\n    Flatten(),\n    Reshape((52,52,256)),\n    Conv2DTranspose( 128, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n    BatchNormalization(),\n    Conv2DTranspose( 64, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n    BatchNormalization(),\n    Conv2DTranspose( 32, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n    BatchNormalization(),\n    Conv2D( 32, kernel_size=(3,3), strides=1, activation=\"relu\",padding='same'),\n    Conv2DTranspose( 3, kernel_size=kernel_size, strides=1, activation=\"tanh\" ),\n\n]\n\nmodel = Sequential( NEURAL_SCHEMA )\n# \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropout_rate = 0.3\nDIMEN = 64\nkernel_size = ( 3 , 3 )\n\n# NEURAL_SCHEMA = [\n\n#     Conv2D( 32 , input_shape=( DIMEN , DIMEN , 3 ) , kernel_size=kernel_size , strides=1,activation=\"relu\"),\n#     Dropout( dropout_rate ) ,\n#     BatchNormalization(),\n#     Conv2D( 64, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n#     Conv2D( 128, kernel_size=kernel_size, strides=1, activation=\"relu\") ,\n#     Dropout(dropout_rate),\n#     Conv2D( 256, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n#     Dropout(dropout_rate),\n#     Flatten(),\n#     Reshape((52,52,256)),\n#     Conv2DTranspose( 128, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n# #     Dropout(dropout_rate),\n#     BatchNormalization(),\n#     Conv2DTranspose( 64, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n# #     Dropout(dropout_rate),\n#     BatchNormalization(),\n#     Conv2DTranspose( 32, kernel_size=kernel_size, strides=1, activation=\"relu\"),\n# #     Dropout(dropout_rate),\n#     BatchNormalization(),\n#     Conv2DTranspose( 3, kernel_size=kernel_size, strides=1, activation=\"tanh\" ),\n\n# ]\n\n# model = Sequential( NEURAL_SCHEMA )\n\n# encoder=Sequential()\n# encoder.add(Conv2D( 64 , input_shape=( DIMEN , DIMEN , 3 ) , kernel_size=(3,3) , strides=1,activation=\"relu\",padding='same'))\n# encoder.add(MaxPooling2D( (2,2) ,padding='same'))\n# encoder.add(Conv2D( 32 , kernel_size=(3,3) , strides=1,activation=\"relu\",padding='same'))\n# encoder.add(MaxPooling2D( (2,2) ,padding='same'))\n# encoder.add(Conv2D( 16 , kernel_size=(3,3) , strides=1,activation=\"relu\",padding='same'))\n# encoder.add(MaxPooling2D( (2,2) ,padding='same'))\n# encoder.add(Conv2D( 8 , kernel_size=(3,3) , strides=1,activation=\"relu\",padding='same'))\n# encoder.add(Flatten())\n# encoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# decoder=Sequential()\n# decoder.add(Dense(512,input_shape=(512,)))\n# decoder.add(Reshape((8,8,8)))\n# decoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n# decoder.add(UpSampling2D((2, 2)))\n# decoder.add(Conv2D( 16 , kernel_size=(3,3) , strides=1,activation=\"relu\",padding='same'))\n# decoder.add(UpSampling2D((2, 2)))\n# decoder.add(Conv2D( 32 , kernel_size=(3,3) , strides=1,activation=\"relu\",padding='same'))\n# decoder.add(UpSampling2D((2, 2)))\n# decoder.add(Conv2D( 3 , kernel_size=(3,3) , strides=1,activation=\"relu\",padding='same'))\n# decoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model=Sequential()\n# for layer in encoder.layers:\n#     model.add(layer)\n# for layer in decoder.layers:\n#     model.add(layer)\n# model.compile(optimizer=optimizers.Adam(0.00001),\n#     loss=losses.mean_squared_error,\n#     metrics=['mae'])\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder=Sequential()\nfor layer in model.layers[:10]:\n    encoder.add(layer)\nencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input\nencoded_input = Input(shape=(692224,))\ndeco=model.layers[10](encoded_input)\nfor layer in model.layers[11:]:\n    deco=layer(deco)\ndecoder = Model(encoded_input, deco)\ndecoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=optimizers.Adam(0.00001),\n    loss=losses.mean_squared_error,\n    metrics=['mae'],\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit_generator(generator=train_generator, steps_per_epoch=train_generator.n, epochs=10, \n                    validation_data=validation_generator, validation_steps=validation_generator.n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image=train_generator[0][0][30].astype(np.float).reshape(1,64,64,3)\nplt.imshow(test_image.reshape(64, 64,3))\nplt.show()\nencoded_img=encoder.predict(test_image)\nplt.imshow(encoded_img)\nplt.show()\ndecoded_img=decoder.predict(encoded_img)\nplt.imshow(decoded_img.reshape(64,64,3))\nplt.show()\ndecoded_img2=model.predict(test_image)\nplt.imshow(decoded_img2.reshape(64,64,3))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image=train_generator[0][0][1].astype(np.float).reshape(1,64,64,3)\nplt.imshow(test_image.reshape(64, 64,3))\nplt.show()\nencoded_img=encoder.predict(test_image)\nplt.imshow(encoded_img)\nplt.show()\ndecoded_img=decoder.predict(encoded_img)\nplt.imshow(decoded_img.reshape(64,64,3))\nplt.show()\ndecoded_img2=model.predict(test_image)\nplt.imshow(decoded_img2.reshape(64,64,3))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model.h5\")\nencoder.save(\"encoder_face.h5\")\ndecoder.save(\"decoder_face.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"./encoder_face.h5\"> Encoder </a>"},{"metadata":{},"cell_type":"markdown","source":"<a href=\"./decoder_face.h5\"> Decoder </a>"},{"metadata":{},"cell_type":"markdown","source":"<a href=\"./model.h5\"> model </a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# plt.savefig(\"fig1.png\")\nimport scipy.misc\nscipy.misc.imsave('fig1.jpg', train_generator[0][0][30].astype(np.float).reshape(64,64,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.imshow(train_generator[0][0][1].astype(np.float).reshape(64,64,3))\n# plt.savefig(\"fig2.png\")\nscipy.misc.imsave('fig2.jpg', train_generator[0][0][1].astype(np.float).reshape(64,64,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"./fig1.jpg\"> fig1 </a>"},{"metadata":{},"cell_type":"markdown","source":"<a href=\"./fig2.jpg\"> fig2 </a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ndef interpolate_points(p1, p2, n_steps=10):\n\t# interpolate ratios between the points\n\tratios = np.linspace(0, 1, num=n_steps)\n\t# linear interpolate vectors\n\tvectors = list()\n\tfor ratio in ratios:\n\t\tv = (1.0 - ratio) * p1 + ratio * p2\n\t\tvectors.append(v)\n\treturn np.asarray(vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of interpolating \nfrom numpy import asarray\nfrom numpy import vstack\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom numpy import arccos\nfrom numpy import clip\nfrom numpy import dot\nfrom numpy import sin\nfrom numpy import linspace\nfrom numpy.linalg import norm\nfrom keras.models import load_model\n# spherical linear interpolation (slerp)\ndef slerp(val, low, high):\n\tomega = arccos(clip(dot(low/norm(low), high/norm(high)), -1, 1))\n\tso = sin(omega)\n\tif so == 0:\n\t\t# L'Hopital's rule/LERP\n\t\treturn (1.0-val) * low + val * high\n\treturn sin((1.0-val)*omega) / so * low + sin(val*omega) / so * high\n\n# uniform interpolation between two points in latent space\ndef interpolate_points_slerp(p1, p2, n_steps=10):\n\t# interpolate ratios between the points\n\tratios = linspace(0, 1, num=n_steps)\n\t# linear interpolate vectors\n\tvectors = list()\n\tfor ratio in ratios:\n\t\tv = slerp(ratio, p1, p2)\n\t\tvectors.append(v)\n\treturn asarray(vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image1=train_generator[0][0][13].astype(np.float).reshape(1,64,64,3)\ntest_image2=train_generator[0][0][22].astype(np.float).reshape(1,64,64,3)\nencoded_img1=encoder.predict(test_image1)\nencoded_img2=encoder.predict(test_image2)\ninterpolated_images=interpolate_points(encoded_img1.flatten(),encoded_img2.flatten())\ninterpolated_orig_images=interpolate_points(test_image1.flatten(),test_image2.flatten())\ninterpolated_slerp_images=interpolate_points_slerp(encoded_img1.flatten(),encoded_img2.flatten())\ninterpolated_slerp_orig_images=interpolate_points_slerp(test_image1.flatten(),test_image2.flatten())\n\ninterpolated_images.shape\nnum_images = 10\nnp.random.seed(42)\nplt.figure(figsize=(20, 8))\n\nfor i, image_idx in enumerate(interpolated_images):\n    \n    ax = plt.subplot(5, num_images, i + 1)\n#     plt.imshow(interpolated_images[i].reshape(16, 8))\n#     plt.gray()\n#     ax.get_xaxis().set_visible(False)\n#     ax.get_yaxis().set_visible(False)\n    \n    ax = plt.subplot(5, num_images,num_images+ i + 1)\n    plt.imshow(decoder.predict(interpolated_images[i].reshape(1,692224)).reshape(64,64,3))\n#     plt.gray()\n    ax.get_xaxis().set_visible(False)\n    \n    ax.get_yaxis().set_visible(False)\n    ax = plt.subplot(5, num_images,2*num_images+ i + 1)\n    plt.imshow(decoder.predict(interpolated_slerp_images[i].reshape(1,692224)).reshape(64,64,3))\n#     plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    ax = plt.subplot(5, num_images,3*num_images+ i + 1)\n    plt.imshow(interpolated_orig_images[i].reshape(64,64,3))\n#     plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    ax = plt.subplot(5, num_images,4*num_images+ i + 1)\n    plt.imshow(interpolated_slerp_orig_images[i].reshape(64,64,3))\n#     plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}