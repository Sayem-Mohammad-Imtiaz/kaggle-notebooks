{"cells":[{"metadata":{},"cell_type":"markdown","source":"Vehicle Recognition"},{"metadata":{},"cell_type":"markdown","source":"#Overview\nWelcome to my kernel!\nData Description: The data contains features extracted from the silhouette of vehicles in different angles. Four \"Corgie\" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400 cars. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars."},{"metadata":{},"cell_type":"markdown","source":"#Objective:\nThe objective is to classify a given silhouette as one of three types of vehicle, using a set of features extracted from the silhouette. The vehicle may be viewed from one of many different angles."},{"metadata":{},"cell_type":"markdown","source":"#Importing the Libraries and Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom scipy.stats import zscore\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the csv file and make the data frame\nvehicle_df = pd.read_csv('/kaggle/input/vehicle/vehicle.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the first 5 rows of dataframe\nvehicle_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The dataframe has {} rows and {} columns\".format(vehicle_df.shape[0],vehicle_df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the information of dataframe\nvehicle_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that except 'class' column all columns are numeric type and there are null values in some columns.\nclass column is our target column."},{"metadata":{"trusted":true},"cell_type":"code","source":"#display in each column how many null values are there\nvehicle_df.apply(lambda x: sum(x.isnull()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that max null values is 6 which are in two columns 'radius_ratio', 'skewness_about'.\nso we have two options either we will drop those null values or we will impute those null values.\nDropping null values is not a good way because we will lose some information.but we will go with both options then we will see what's the effect on model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#display 5 point summary of dataframe\nvehicle_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(vehicle_df,diag_kind='kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above pair plots we can see that many columns are correlated and many columns have long tail so that is the indication of outliers.we will see down the line with the help of correlation matrix what's the strength of correlation and outliers are there or not."},{"metadata":{},"cell_type":"markdown","source":"From above we can see that our data has missing values in some column. so before building any model we have to handle missing values. we have two option either we will drop those missing values or we will impute missing values. we will go with both options and see what's the effect on model. so first we will drop the missing values. Before dropping missing values we will create another dataframe and copy the original dataframe data into that. It's a good practice to keep the original dataframe as it is and make all modifications to the new dataframe."},{"metadata":{},"cell_type":"markdown","source":"#Dropping Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#copy the dataframe to another dataframe and drop null/missing values from the newly created dataframe\nnew_vehicle_df = vehicle_df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so now we have new dataframe called new_vehicle_df and we will make changes in this new dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the first 5 rows of new dataframe\nnew_vehicle_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the shape of dataframe\nprint(\"Shape of newly created dataframe:\",new_vehicle_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the null vaues from the new dataframe\nnew_vehicle_df.dropna(axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we will see what is the shape of dataframe\nprint(\"After dropping missing values shape of dataframe:\",new_vehicle_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display 5 point summary of new dataframe\nnew_vehicle_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Analysis of each column with the help of plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['compactness'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['compactness'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in compactness column and it's looks like normally distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['circularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['circularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in circularity column and it's looks like normally distributed"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['distance_circularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['distance_circularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in distance_circularity column but in distribution plot we can see that there are two peaks and we can see that there is right skewness because long tail is at the right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['radius_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['radius_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in radius_ratio column and there is right skewness because long tail is at the right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in radius_ratio column\nq1 = np.quantile(new_vehicle_df['radius_ratio'],0.25)\nq2 = np.quantile(new_vehicle_df['radius_ratio'],0.50)\nq3 = np.quantile(new_vehicle_df['radius_ratio'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"radius_ratio above\",new_vehicle_df['radius_ratio'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in radius_ratio column are\",new_vehicle_df[new_vehicle_df['radius_ratio']>276]['radius_ratio'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['pr.axis_aspect_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['pr.axis_aspect_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in pr.axis_aspect_ratio column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in pr.axis_aspect_ratio column\nq1 = np.quantile(new_vehicle_df['pr.axis_aspect_ratio'],0.25)\nq2 = np.quantile(new_vehicle_df['pr.axis_aspect_ratio'],0.50)\nq3 = np.quantile(new_vehicle_df['pr.axis_aspect_ratio'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"pr.axis_aspect_ratio above\",new_vehicle_df['pr.axis_aspect_ratio'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in pr.axis_aspect_ratio column are\",new_vehicle_df[new_vehicle_df['pr.axis_aspect_ratio']>77]['pr.axis_aspect_ratio'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['max.length_aspect_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['max.length_aspect_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in max.length_aspect_ratio and there is a right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in pr.axis_aspect_ratio column\nq1 = np.quantile(new_vehicle_df['max.length_aspect_ratio'],0.25)\nq2 = np.quantile(new_vehicle_df['max.length_aspect_ratio'],0.50)\nq3 = np.quantile(new_vehicle_df['max.length_aspect_ratio'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"max.length_aspect_ratio above\",new_vehicle_df['max.length_aspect_ratio'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"max.length_aspect_ratio below\",new_vehicle_df['max.length_aspect_ratio'].quantile(0.25)-(1.5 * IQR),\"are outliers\")\nprint(\"The above Outliers in max.length_aspect_ratio column are\",new_vehicle_df[new_vehicle_df['max.length_aspect_ratio']>14.5]['max.length_aspect_ratio'].shape[0])\nprint(\"The below Outliers in max.length_aspect_ratio column are\",new_vehicle_df[new_vehicle_df['max.length_aspect_ratio']<2.5]['max.length_aspect_ratio'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['scatter_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['scatter_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in scatter_ratio column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median) "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['elongatedness'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['elongatedness'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in elongatedness column and there are two peaks in distribution plot and there is left skewness because long tail is at left side(mean<median) "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['pr.axis_rectangularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['pr.axis_rectangularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in pr.axis_rectangularity column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['max.length_rectangularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['max.length_rectangularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in max.length_rectangularity column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['scaled_variance'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['scaled_variance'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in scaled_variance column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in scaled_variance column\nq1 = np.quantile(new_vehicle_df['scaled_variance'],0.25)\nq2 = np.quantile(new_vehicle_df['scaled_variance'],0.50)\nq3 = np.quantile(new_vehicle_df['scaled_variance'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"scaled_variance above\",new_vehicle_df['scaled_variance'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in scaled_variance column are\",new_vehicle_df[new_vehicle_df['scaled_variance']>292]['scaled_variance'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['scaled_variance.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['scaled_variance.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in scaled_variance.1 column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in scaled_variance.1 column\nq1 = np.quantile(new_vehicle_df['scaled_variance.1'],0.25)\nq2 = np.quantile(new_vehicle_df['scaled_variance.1'],0.50)\nq3 = np.quantile(new_vehicle_df['scaled_variance.1'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"scaled_variance.1 above\",new_vehicle_df['scaled_variance.1'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in scaled_variance.1 column are\",new_vehicle_df[new_vehicle_df['scaled_variance.1']>988]['scaled_variance.1'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['scaled_radius_of_gyration'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['scaled_radius_of_gyration'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in scaled_radius_of_gyration column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['scaled_radius_of_gyration.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['scaled_radius_of_gyration.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in scaled_radius_of_gyration.1 column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in scaled_radius_of_gyration.1 column\nq1 = np.quantile(new_vehicle_df['scaled_radius_of_gyration.1'],0.25)\nq2 = np.quantile(new_vehicle_df['scaled_radius_of_gyration.1'],0.50)\nq3 = np.quantile(new_vehicle_df['scaled_radius_of_gyration.1'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"scaled_radius_of_gyration.1 above\",new_vehicle_df['scaled_radius_of_gyration.1'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in scaled_radius_of_gyration.1 column are\",new_vehicle_df[new_vehicle_df['scaled_radius_of_gyration.1']>87]['scaled_radius_of_gyration.1'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['skewness_about'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['skewness_about'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in skewness_about column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in skewness_about column\nq1 = np.quantile(new_vehicle_df['skewness_about'],0.25)\nq2 = np.quantile(new_vehicle_df['skewness_about'],0.50)\nq3 = np.quantile(new_vehicle_df['skewness_about'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"skewness_about above\",new_vehicle_df['skewness_about'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in skewness_about column are\",new_vehicle_df[new_vehicle_df['skewness_about']>19.5]['skewness_about'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['skewness_about.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['skewness_about.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in skewness_about.1 column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in skewness_about.1 column\nq1 = np.quantile(new_vehicle_df['skewness_about.1'],0.25)\nq2 = np.quantile(new_vehicle_df['skewness_about.1'],0.50)\nq3 = np.quantile(new_vehicle_df['skewness_about.1'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"skewness_about.1 above\",new_vehicle_df['skewness_about.1'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in skewness_about.1 column are\",new_vehicle_df[new_vehicle_df['skewness_about.1']>38.5]['skewness_about.1'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['skewness_about.2'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['skewness_about.2'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in skewness_about.2 column and there is left skewness because long tail is at left side(mean<median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(new_vehicle_df['hollows_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(new_vehicle_df['hollows_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in hollows_ratio column and there is left skewness because long tail is at left side(mean<median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#display how many are car,bus,van. \nnew_vehicle_df['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(new_vehicle_df['class'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that cars are most followed by bus and then vans."},{"metadata":{},"cell_type":"markdown","source":"so by now we analyze each column and we found that there are outliers in some column. now our next step is to know whether these outliers are natural or artificial. if natural then we have to do nothing but if these outliers are artificial then we have to handle these outliers.\nwe have 8 columns in which we found outliers:\n->radius_ratio\n->pr.axis_aspect_ratio\n->max.length_aspect_ratio\n->scaled_variance\n->scaled_variance.1\n->scaled_radius_of_gyration.1\n->skewness_about\n->skewness_about.1"},{"metadata":{},"cell_type":"markdown","source":"after seeing the max values of above outliers column. it's looks like outliers in above columns are natural not a typo mistake or artificial.\nNote: It's my assumption only. as there is no way to prove whether these outliers are natural or artificial.\nAs we know that mostly algorithms are affected by outliers and outliers may affect the model.as we will apply SVM on above data which is affected by outliers. so better to drop those outliers."},{"metadata":{},"cell_type":"markdown","source":"#Fix Outliers after dropping missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#radius_ratio column outliers\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['radius_ratio']>276].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pr.axis_aspect_ratio column outliers\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['pr.axis_aspect_ratio']>77].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#max.length_aspect_ratio column outliers\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['max.length_aspect_ratio']>14.5].index,axis=0,inplace=True)\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['max.length_aspect_ratio']<2.5].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_variance column outliers\nnew_vehicle_df[new_vehicle_df['scaled_variance']>292]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from above we can see that scaled_variance column outliers has been removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_variance.1 column outliers\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['scaled_variance.1']>988].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_radius_of_gyration.1 column outliers\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['scaled_radius_of_gyration.1']>87].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness_about column outliers\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['skewness_about']>19.5].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness_about.1 column outliers\nnew_vehicle_df.drop(new_vehicle_df[new_vehicle_df['skewness_about.1']>38.5].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now what is the shape of dataframe\nprint(\"after removing outliers shape of dataframe:\",new_vehicle_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the correlation between independent variables\nplt.figure(figsize=(20,5))\nsns.heatmap(new_vehicle_df.corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so our objective is to reocgnize whether an object is a van or bus or car based on some input features.\nso our main assumption is there is little or no multicollinearity between the features.\nif two features is highly correlated then there is no use in using both features.in that case, we can drop one feature. \nso heatmap gives us the correlation matrix there we can see which features are highly correlated.\nFrom above correlation matrix we can see that there are many features which are highly correlated. if we see carefully then scaled_variance.1 and scatter_ratio has 1 correlation and many other features also there which having more than 0.9 correlation\nso we will drop those columns whose correlation is +-0.9 or above.\nso there are 8 such columns:\n->max.length_rectangularity\n->scaled_radius_of_gyration\n->skewness_about.2\n->scatter_ratio\n->elongatedness\n->pr.axis_rectangularity\n->scaled_variance\n->scaled_variance.1"},{"metadata":{},"cell_type":"markdown","source":"now, again we have two option we will drop those above eight columns manually or we will apply pca and let pca to be decided how it will explain above data which is in high dimension with smaller number of variables.\nwe will see both approaches."},{"metadata":{},"cell_type":"markdown","source":"Principal Component Analysis is an unsupervised learning class of statistical techniques used to explain data in high dimension using small number of variables called the principal components. Principal components are the linear combinations of the original variables in the dataset. As it will explain high dimension data with small number of variables. The big disadvantage is we cannot do interpretation with the model.In other words model with pca will become blackbox.   \nIn pca first we have to find the covariance matrix after that from that covariance matrix we have to find eigen vectors and eigen values. There is mathematical way to find eigen vectors and eigen values. i will attach the link of how to find the eigen value and eigen vector. Corresponding to each eigen vector there is eigen value. after that we have to sort the eigen vector by decreasing eigen values and choose k eigen vectors with the largest eigen value. "},{"metadata":{},"cell_type":"markdown","source":"#With Principal Component Analysis(PCA) "},{"metadata":{"trusted":true},"cell_type":"code","source":"#now separate the dataframe into dependent and independent variables\nnew_vehicle_df_independent_attr = new_vehicle_df.drop('class',axis=1)\nnew_vehicle_df_dependent_attr = new_vehicle_df['class']\nprint(\"shape of new_vehicle_df_independent_attr::\",new_vehicle_df_independent_attr.shape)\nprint(\"shape of new_vehicle_df_dependent_attr::\",new_vehicle_df_dependent_attr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now sclaed the independent attribute and replace the dependent attr value with number\nnew_vehicle_df_independent_attr_scaled = new_vehicle_df_independent_attr.apply(zscore)\nnew_vehicle_df_dependent_attr.replace({'car':0,'bus':1,'van':2},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make the covariance matrix and we have 18 independent features so aur covariance matrix is 18*18 matrix\ncov_matrix = np.cov(new_vehicle_df_independent_attr_scaled,rowvar=False)\nprint(\"cov_matrix shape:\",cov_matrix.shape)\nprint(\"Covariance_matrix\",cov_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now with the help of above covariance matrix we will find eigen value and eigen vectors\npca_to_learn_variance = PCA(n_components=18)\npca_to_learn_variance.fit(new_vehicle_df_independent_attr_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display explained variance ratio\npca_to_learn_variance.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display explained variance\npca_to_learn_variance.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display principal components\npca_to_learn_variance.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(list(range(1,19)),pca_to_learn_variance.explained_variance_ratio_)\nplt.xlabel(\"eigen value/components\")\nplt.ylabel(\"variation explained\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.step(list(range(1,19)),np.cumsum(pca_to_learn_variance.explained_variance_ratio_))\nplt.xlabel(\"eigen value/components\")\nplt.ylabel(\"cummalative of variation explained\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that 8 dimension are able to explain 95%variance of data. so we will use first 8 principal components"},{"metadata":{"trusted":true},"cell_type":"code","source":"#use first 8 principal components\npca_eight_components = PCA(n_components=8)\npca_eight_components.fit(new_vehicle_df_independent_attr_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform the raw data which is in 18 dimension into 8 new dimension with pca\nnew_vehicle_df_pca_independent_attr = pca_eight_components.transform(new_vehicle_df_independent_attr_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the shape of new_vehicle_df_pca_independent_attr\nnew_vehicle_df_pca_independent_attr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now before apply pca with 8 dimension which are explaining more than 95% variantion of data we will make model on raw data after that we will make model with pca and then we will compare both models."},{"metadata":{"trusted":true},"cell_type":"code","source":"#now split the data into 80:20 ratio\nrawdata_X_train,rawdata_X_test,rawdata_y_train,rawdata_y_test = train_test_split(new_vehicle_df_independent_attr_scaled,new_vehicle_df_dependent_attr,test_size=0.20,random_state=1)\npca_X_train,pca_X_test,pca_y_train,pca_y_test = train_test_split(new_vehicle_df_pca_independent_attr,new_vehicle_df_dependent_attr,test_size=0.20,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"shape of rawdata_X_train\",rawdata_X_train.shape)\nprint(\"shape of rawdata_y_train\",rawdata_y_train.shape)\nprint(\"shape of rawdata_X_test\",rawdata_X_test.shape)\nprint(\"shape of rawdata_y_test\",rawdata_y_test.shape)\nprint(\"--------------------------------------------\")\nprint(\"shape of pca_X_train\",pca_X_train.shape)\nprint(\"shape of pca_y_train\",pca_y_train.shape)\nprint(\"shape of pca_X_test\",pca_X_test.shape)\nprint(\"shape of pca_y_test\",pca_y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we will train the model with both raw data and pca data with new dimension\nsvc = SVC() #instantiate the object","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the model on raw data\nsvc.fit(rawdata_X_train,rawdata_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the y value\nrawdata_y_predict = svc.predict(rawdata_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now fit the model on pca data with new dimension\nsvc.fit(pca_X_train,pca_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the y value\npca_y_predict = svc.predict(pca_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display accuracy score of both models\nprint(\"Accuracy score with raw data(18 dimension)\",accuracy_score(rawdata_y_test,rawdata_y_predict))\nprint(\"Accuracy score with pca data(8 dimension)\",accuracy_score(pca_y_test,pca_y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that by reducing 10 dimension we are achieving 94% accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"#display confusion matrix of both models\nprint(\"Confusion matrix with raw data(18 dimension)\\n\",confusion_matrix(rawdata_y_test,rawdata_y_predict))\nprint(\"Confusion matrix with pca data(8 dimension)\\n\",confusion_matrix(pca_y_test,pca_y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#With dropping the above mentioned columns Manually"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the columns\nnew_vehicle_df_independent_attr_scaled.drop(['max.length_rectangularity','scaled_radius_of_gyration','skewness_about.2','scatter_ratio','elongatedness','pr.axis_rectangularity','scaled_variance','scaled_variance.1'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the shape of new dataframe\nnew_vehicle_df_independent_attr_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropcolumn_X_train,dropcolumn_X_test,dropcolumn_y_train,dropcolumn_y_test = train_test_split(new_vehicle_df_independent_attr_scaled,new_vehicle_df_dependent_attr,test_size=0.20,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"shape of dropcolumn_X_train\",dropcolumn_X_train.shape)\nprint(\"shape of dropcolumn_y_train\",dropcolumn_y_train.shape)\nprint(\"shape of dropcolumn_X_test\",dropcolumn_X_test.shape)\nprint(\"shape of dropcolumn_y_test\",dropcolumn_y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the model on dropcolumn_X_train,dropcolumn_y_train\nsvc.fit(dropcolumn_X_train,dropcolumn_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the y value\ndropcolumn_y_predict = svc.predict(dropcolumn_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the accuracy score and confusion matrix\nprint(\"Accuracy score with dropcolumn data(10 dimension)\",accuracy_score(dropcolumn_y_test,dropcolumn_y_predict))\nprint(\"Confusion matrix with dropcolumn data(10 dimension)\\n\",confusion_matrix(dropcolumn_y_test,dropcolumn_y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Imputing missing values"},{"metadata":{},"cell_type":"markdown","source":"First let's create a new dataframe and then we will impute the missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a new dataframe\nimpute_vehicle_df = vehicle_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the first 5 rows of dataframe\nimpute_vehicle_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the shape of dataframe\nimpute_vehicle_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the information of dataframe\nimpute_vehicle_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are null values in some column.now we will impute those null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#display 5 point summary\nimpute_vehicle_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above 5 point summary it's looks like we can impute with median.again by imputing the missing values with median we are changing the shape of distribution and introducing bias.but it's might be better than drpping missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"impute_vehicle_df.fillna(impute_vehicle_df.median(),axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the info of dataframe\nimpute_vehicle_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no null values in each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"#display 5 point summary after imputation \nimpute_vehicle_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Analysis of each column with the help of plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['compactness'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['compactness'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in compactness column and it's looks like normally distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['circularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['circularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in circularity column and it's looks like normally distributed"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['distance_circularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['distance_circularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in distance_circularity column but in distribution plot we can see that there are two peaks and we can see that there is right skewness because long tail is at the right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['radius_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['radius_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in radius_ratio column and there is right skewness because long tail is at the right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in radius_ratio column\nq1 = np.quantile(impute_vehicle_df['radius_ratio'],0.25)\nq2 = np.quantile(impute_vehicle_df['radius_ratio'],0.50)\nq3 = np.quantile(impute_vehicle_df['radius_ratio'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"radius_ratio above\",impute_vehicle_df['radius_ratio'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in radius_ratio column are\",impute_vehicle_df[impute_vehicle_df['radius_ratio']>276]['radius_ratio'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['pr.axis_aspect_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['pr.axis_aspect_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in pr.axis_aspect_ratio column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in pr.axis_aspect_ratio column\nq1 = np.quantile(impute_vehicle_df['pr.axis_aspect_ratio'],0.25)\nq2 = np.quantile(impute_vehicle_df['pr.axis_aspect_ratio'],0.50)\nq3 = np.quantile(impute_vehicle_df['pr.axis_aspect_ratio'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"pr.axis_aspect_ratio above\",impute_vehicle_df['pr.axis_aspect_ratio'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in pr.axis_aspect_ratio column are\",impute_vehicle_df[impute_vehicle_df['pr.axis_aspect_ratio']>77]['pr.axis_aspect_ratio'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['max.length_aspect_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['max.length_aspect_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in max.length_aspect_ratio and there is a right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in max.length_aspect_ratio column\nq1 = np.quantile(impute_vehicle_df['max.length_aspect_ratio'],0.25)\nq2 = np.quantile(impute_vehicle_df['max.length_aspect_ratio'],0.50)\nq3 = np.quantile(impute_vehicle_df['max.length_aspect_ratio'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"max.length_aspect_ratio above\",impute_vehicle_df['max.length_aspect_ratio'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"max.length_aspect_ratio below\",impute_vehicle_df['max.length_aspect_ratio'].quantile(0.25)-(1.5 * IQR),\"are outliers\")\nprint(\"The above Outliers in max.length_aspect_ratio column are\",impute_vehicle_df[impute_vehicle_df['max.length_aspect_ratio']>14.5]['max.length_aspect_ratio'].shape[0])\nprint(\"The below Outliers in max.length_aspect_ratio column are\",impute_vehicle_df[impute_vehicle_df['max.length_aspect_ratio']<2.5]['max.length_aspect_ratio'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['scatter_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['scatter_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in scatter_ratio column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median) "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['elongatedness'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['elongatedness'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in elongatedness column and there are two peaks in distribution plot and there is left skewness because long tail is at left side(mean<median) "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['pr.axis_rectangularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['pr.axis_rectangularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in pr.axis_rectangularity column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['max.length_rectangularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['max.length_rectangularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in max.length_rectangularity column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['scaled_variance'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['scaled_variance'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in scaled_variance column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in scaled_variance column\nq1 = np.quantile(impute_vehicle_df['scaled_variance'],0.25)\nq2 = np.quantile(impute_vehicle_df['scaled_variance'],0.50)\nq3 = np.quantile(impute_vehicle_df['scaled_variance'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"scaled_variance above\",impute_vehicle_df['scaled_variance'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in scaled_variance column are\",impute_vehicle_df[impute_vehicle_df['scaled_variance']>292]['scaled_variance'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['scaled_variance.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['scaled_variance.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in scaled_variance.1 column and there are two peaks in distribution plot and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in scaled_variance.1 column\nq1 = np.quantile(impute_vehicle_df['scaled_variance.1'],0.25)\nq2 = np.quantile(impute_vehicle_df['scaled_variance.1'],0.50)\nq3 = np.quantile(impute_vehicle_df['scaled_variance.1'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"scaled_variance.1 above\",impute_vehicle_df['scaled_variance.1'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in scaled_variance.1 column are\",impute_vehicle_df[impute_vehicle_df['scaled_variance.1']>989.5]['scaled_variance.1'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['scaled_radius_of_gyration'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['scaled_radius_of_gyration'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in scaled_radius_of_gyration column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['scaled_radius_of_gyration.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['scaled_radius_of_gyration.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in scaled_radius_of_gyration.1 column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in scaled_radius_of_gyration.1 column\nq1 = np.quantile(impute_vehicle_df['scaled_radius_of_gyration.1'],0.25)\nq2 = np.quantile(impute_vehicle_df['scaled_radius_of_gyration.1'],0.50)\nq3 = np.quantile(impute_vehicle_df['scaled_radius_of_gyration.1'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"scaled_radius_of_gyration.1 above\",impute_vehicle_df['scaled_radius_of_gyration.1'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in scaled_radius_of_gyration.1 column are\",impute_vehicle_df[impute_vehicle_df['scaled_radius_of_gyration.1']>87]['scaled_radius_of_gyration.1'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['skewness_about'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['skewness_about'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in skewness_about column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in skewness_about column\nq1 = np.quantile(impute_vehicle_df['skewness_about'],0.25)\nq2 = np.quantile(impute_vehicle_df['skewness_about'],0.50)\nq3 = np.quantile(impute_vehicle_df['skewness_about'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"skewness_about above\",impute_vehicle_df['skewness_about'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in skewness_about column are\",impute_vehicle_df[impute_vehicle_df['skewness_about']>19.5]['skewness_about'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['skewness_about.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['skewness_about.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are outliers in skewness_about.1 column and there is right skewness because long tail is at right side(mean>median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check how many outliers are there in skewness_about.1 column\nq1 = np.quantile(impute_vehicle_df['skewness_about.1'],0.25)\nq2 = np.quantile(impute_vehicle_df['skewness_about.1'],0.50)\nq3 = np.quantile(impute_vehicle_df['skewness_about.1'],0.75)\nIQR = q3-q1\nprint(\"Quartie1::\",q1)\nprint(\"Quartie2::\",q2)\nprint(\"Quartie3::\",q3)\nprint(\"Inter Quartie Range::\",IQR)\n#outliers = q3 + 1.5*IQR, q1 - 1.5*IQR\nprint(\"skewness_about.1 above\",impute_vehicle_df['skewness_about.1'].quantile(0.75)+(1.5 * IQR),\"are outliers\")\nprint(\"The Outliers in skewness_about.1 column are\",impute_vehicle_df[impute_vehicle_df['skewness_about.1']>40]['skewness_about.1'].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['skewness_about.2'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['skewness_about.2'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in skewness_about.2 column and there is left skewness because long tail is at left side(mean<median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(impute_vehicle_df['hollows_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(impute_vehicle_df['hollows_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in hollows_ratio column and there is left skewness because long tail is at left side(mean<median)"},{"metadata":{"trusted":true},"cell_type":"code","source":"impute_vehicle_df['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(impute_vehicle_df['class'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that cars are most followed by bus and then vans."},{"metadata":{},"cell_type":"markdown","source":"so by now we analyze each column and we found that there are outliers in some column. now our next step is to know whether these outliers are natural or artificial. if natural then we have to do nothing but if these outliers are artificial then we have to handle these outliers.\nwe have 8 columns in which we found outliers:\n->radius_ratio\n->pr.axis_aspect_ratio\n->max.length_aspect_ratio\n->scaled_variance\n->scaled_variance.1\n->scaled_radius_of_gyration.1\n->skewness_about\n->skewness_about.1"},{"metadata":{},"cell_type":"markdown","source":"after seeing the max values of above outliers column. it's looks like outliers in above columns are natural not a typo mistake or artificial.\nas we will apply SVM on above data which is affected by outliers. so better to drop those outliers."},{"metadata":{},"cell_type":"markdown","source":"#Fix Outliers after imputing missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#radius_ratio column outliers\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['radius_ratio']>276].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pr.axis_aspect_ratio column outliers\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['pr.axis_aspect_ratio']>77].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#max.length_aspect_ratio column outliers\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['max.length_aspect_ratio']>14.5].index,axis=0,inplace=True)\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['max.length_aspect_ratio']<2.5].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_variance column outliers\nimpute_vehicle_df[impute_vehicle_df['scaled_variance']>292]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from above we can see that scaled_variance column outliers has been removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_variance.1 column outliers\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['scaled_variance.1']>989.5].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_radius_of_gyration.1 column outliers\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['scaled_radius_of_gyration.1']>87].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness_about column outliers\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['skewness_about']>19.5].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness_about.1 column outliers\nimpute_vehicle_df.drop(impute_vehicle_df[impute_vehicle_df['skewness_about.1']>40].index,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the shape of data frame\nprint(\"after fixing outliers shape of dataframe:\",impute_vehicle_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,4))\nsns.heatmap(impute_vehicle_df.corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so our objective is to reocgnize whether an object is a van or bus or car based on some input features.\nso our main assumption is there is little or no multicollinearity between the features.\nif two features is highly correlated then there is no use in using both features.in that case, we can drop one feature. \nso heatmap gives us the correlation matrix there we can see which features are highly correlated.\nFrom above correlation matrix we can see that there are many features which are highly correlated. if we see carefully then scaled_variance.1 and scatter_ratio has 1 correlation and many other features also there which having more than 0.9 correlation\nso we will drop those columns whose correlation is +-0.9 or above.\nso there are 8 such columns:\n->max.length_rectangularity\n->scaled_radius_of_gyration\n->skewness_about.2\n->scatter_ratio\n->elongatedness\n->pr.axis_rectangularity\n->scaled_variance\n->scaled_variance.1"},{"metadata":{},"cell_type":"markdown","source":"now, again we have two option we will drop those above eight columns manually or we will apply pca and let pca to be decided how it will explain above data which is in high dimension with smaller number of variables.\nwe will see both approaches."},{"metadata":{},"cell_type":"markdown","source":"#With Principal Component Analysis(PCA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#now separate the dataframe into dependent and independent variables\nimpute_vehicle_df_independent_attr = impute_vehicle_df.drop('class',axis=1)\nimpute_vehicle_df_dependent_attr = impute_vehicle_df['class']\nprint(\"shape of impute_vehicle_df_independent_attr::\",impute_vehicle_df_independent_attr.shape)\nprint(\"shape of impute_vehicle_df_dependent_attr::\",impute_vehicle_df_dependent_attr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now sclaed the independent attribute and replace the dependent attr value with number\nimpute_vehicle_df_independent_attr_scaled = impute_vehicle_df_independent_attr.apply(zscore)\nimpute_vehicle_df_dependent_attr.replace({'car':0,'bus':1,'van':2},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make the covariance matrix and we have 18 independent features so aur covariance matrix is 18*18 matrix\nimpute_cov_matrix = np.cov(impute_vehicle_df_independent_attr_scaled,rowvar=False)\nprint(\"Impute cov_matrix shape:\",impute_cov_matrix.shape)\nprint(\"Impute Covariance_matrix\",impute_cov_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now with the help of above covariance matrix we will find eigen value and eigen vectors\nimpute_pca_to_learn_variance = PCA(n_components=18)\nimpute_pca_to_learn_variance.fit(impute_vehicle_df_independent_attr_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display explained variance ratio\nimpute_pca_to_learn_variance.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display explained variance\nimpute_pca_to_learn_variance.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display principal components\nimpute_pca_to_learn_variance.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(list(range(1,19)),impute_pca_to_learn_variance.explained_variance_ratio_)\nplt.xlabel(\"eigen value/components\")\nplt.ylabel(\"variation explained\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.step(list(range(1,19)),np.cumsum(impute_pca_to_learn_variance.explained_variance_ratio_))\nplt.xlabel(\"eigen value/components\")\nplt.ylabel(\"cummalative of variation explained\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that 8 dimension are able to explain 95%variance of data. so we will use first 8 principal components"},{"metadata":{"trusted":true},"cell_type":"code","source":"#use first 8 principal components\nimpute_pca_eight_components = PCA(n_components=8)\nimpute_pca_eight_components.fit(impute_vehicle_df_independent_attr_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform the impute raw data which is in 18 dimension into 8 new dimension with pca\nimpute_vehicle_df_pca_independent_attr = impute_pca_eight_components.transform(impute_vehicle_df_independent_attr_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the shape of new_vehicle_df_pca_independent_attr\nimpute_vehicle_df_pca_independent_attr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now before apply pca with 8 dimension which are explaining more than 95% variantion of data we will make model on raw data after that we will make model with pca and then we will compare both models."},{"metadata":{"trusted":true},"cell_type":"code","source":"#now split the data into 80:20 ratio\nimpute_rawdata_X_train,impute_rawdata_X_test,impute_rawdata_y_train,impute_rawdata_y_test = train_test_split(impute_vehicle_df_independent_attr_scaled,impute_vehicle_df_dependent_attr,test_size=0.20,random_state=1)\nimpute_pca_X_train,impute_pca_X_test,impute_pca_y_train,impute_pca_y_test = train_test_split(impute_vehicle_df_pca_independent_attr,impute_vehicle_df_dependent_attr,test_size=0.20,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"shape of impute_rawdata_X_train\",impute_rawdata_X_train.shape)\nprint(\"shape of impute_rawdata_y_train\",impute_rawdata_y_train.shape)\nprint(\"shape of impute_rawdata_X_test\",impute_rawdata_X_test.shape)\nprint(\"shape of impute_rawdata_y_test\",impute_rawdata_y_test.shape)\nprint(\"--------------------------------------------\")\nprint(\"shape of impute_pca_X_train\",impute_pca_X_train.shape)\nprint(\"shape of impute_pca_y_train\",impute_pca_y_train.shape)\nprint(\"shape of impute_pca_X_test\",impute_pca_X_test.shape)\nprint(\"shape of impute_pca_y_test\",impute_pca_y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the model on impute raw data\nsvc.fit(impute_rawdata_X_train,impute_rawdata_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the y value\nimpute_rawdata_y_predict = svc.predict(impute_rawdata_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now fit the model on pca data with new dimension\nsvc.fit(impute_pca_X_train,impute_pca_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the y value\nimpute_pca_y_predict = svc.predict(impute_pca_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display accuracy score of both models\nprint(\"Accuracy score with impute raw data(18 dimension)\",accuracy_score(impute_rawdata_y_test,impute_rawdata_y_predict))\nprint(\"Accuracy score with impute pca data(8 dimension)\",accuracy_score(impute_pca_y_test,impute_pca_y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display confusion matrix of both models\nprint(\"Confusion matrix with impute raw data(18 dimension)\\n\",confusion_matrix(impute_rawdata_y_test,impute_rawdata_y_predict))\nprint(\"Confusion matrix with impute pca data(8 dimension)\\n\",confusion_matrix(impute_pca_y_test,impute_pca_y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#With Dropping the above mentioned columns manually"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the columns\nimpute_vehicle_df_independent_attr_scaled.drop(['max.length_rectangularity','scaled_radius_of_gyration','skewness_about.2','scatter_ratio','elongatedness','pr.axis_rectangularity','scaled_variance','scaled_variance.1'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the shape of new dataframe\nimpute_vehicle_df_independent_attr_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"impute_dropcolumn_X_train,impute_dropcolumn_X_test,impute_dropcolumn_y_train,impute_dropcolumn_y_test = train_test_split(impute_vehicle_df_independent_attr_scaled,impute_vehicle_df_dependent_attr,test_size=0.20,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"shape of impute_dropcolumn_X_train\",impute_dropcolumn_X_train.shape)\nprint(\"shape of impute_dropcolumn_y_train\",impute_dropcolumn_y_train.shape)\nprint(\"shape of impute_dropcolumn_X_test\",impute_dropcolumn_X_test.shape)\nprint(\"shape of impute_dropcolumn_y_test\",impute_dropcolumn_y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the model on dropcolumn_X_train,dropcolumn_y_train\nsvc.fit(impute_dropcolumn_X_train,impute_dropcolumn_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the y value\nimpute_dropcolumn_y_predict = svc.predict(impute_dropcolumn_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the accuracy score and confusion matrix\nprint(\"Accuracy score with impute dropcolumn data(10 dimension)\",accuracy_score(impute_dropcolumn_y_test,impute_dropcolumn_y_predict))\nprint(\"Confusion matrix with impute dropcolumn data(10 dimension)\\n\",confusion_matrix(impute_dropcolumn_y_test,impute_dropcolumn_y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Conclusion:\nFrom above we can see that pca is doing a very good job.Accuracy with pca is approx 94% and with raw data approx 96% but note that pca 94% accuracy is with only 8 dimension where as rawdata has 18 dimension.But every thing has two sides, disadvantage of pca is we cannot do interpretation with the model.it's blackbox."},{"metadata":{},"cell_type":"markdown","source":"Thanks for reading the kernel!\nHappy Learning:)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}