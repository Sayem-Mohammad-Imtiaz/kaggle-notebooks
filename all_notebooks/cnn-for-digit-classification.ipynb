{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Red neuronal convolutiva para procesamiento de imagenes en reconocimiento de digitos.\n\nCon este modelo se logró un 99.428 % top 25%","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-27T22:03:00.212293Z","iopub.execute_input":"2021-05-27T22:03:00.212791Z","iopub.status.idle":"2021-05-27T22:03:00.222998Z","shell.execute_reply.started":"2021-05-27T22:03:00.212751Z","shell.execute_reply":"2021-05-27T22:03:00.221199Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport random\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom tensorflow import keras\nfrom keras import losses\nfrom keras import metrics\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Plot Confusion matrix function\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\nimport os\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:03:13.645128Z","iopub.execute_input":"2021-05-27T22:03:13.645715Z","iopub.status.idle":"2021-05-27T22:03:13.68589Z","shell.execute_reply.started":"2021-05-27T22:03:13.645647Z","shell.execute_reply":"2021-05-27T22:03:13.684927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importa las imagenes \ntrain_df            = pd.read_csv(\"../input/mnist-digit-recognizer/train.csv\")\nunlabeled_images_df = pd.read_csv(\"../input/mnist-digit-recognizer/test.csv\")\n\n#Para el conjunto de entrenamiento separa la imagen de su etiqueta de clase\ntrain_images_df     = train_df.iloc[:,1:]\ntrain_labels_df     = train_df.iloc[:,0:1]\n\n#Convierte los datos de pandas df a numpy array\nlabeled_images      = train_images_df.values\nlabels              = train_labels_df.values\nunlabeled_images    = unlabeled_images_df.values\n\n#Convierte la etiqueta de clase en multicategorical\none_hot_labels      = keras.utils.to_categorical(labels, num_classes=10)\n\n#Normaliza las imagenes de rango (0, 255) al rango (0,1) \nlabeled_images      = labeled_images/255\nunlabeled_images    = unlabeled_images/255\n\n#Cambia la forma de las imagenes de vector size = 784 a matrix size = (28,28,1)\nlabeled_images      = np.reshape(labeled_images,(labeled_images.shape[0],28,28,1))\nunlabeled_images    = np.reshape(unlabeled_images,(unlabeled_images.shape[0],28,28,1))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:05:16.22377Z","iopub.execute_input":"2021-05-27T22:05:16.224126Z","iopub.status.idle":"2021-05-27T22:05:22.902401Z","shell.execute_reply.started":"2021-05-27T22:05:16.224093Z","shell.execute_reply":"2021-05-27T22:05:22.901412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Imagen de ejemplo\nimagen = labeled_images[250,:,:,0]\nplt.imshow(imagen)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:05:41.157236Z","iopub.execute_input":"2021-05-27T22:05:41.15782Z","iopub.status.idle":"2021-05-27T22:05:41.35598Z","shell.execute_reply.started":"2021-05-27T22:05:41.15777Z","shell.execute_reply":"2021-05-27T22:05:41.354867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#modelo\nmodel = keras.Sequential()\n\nmodel.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(keras.layers.Dropout(0.25))\n\nmodel.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(keras.layers.Dropout(0.25))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(256, activation = \"relu\"))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(10, activation = \"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:06:03.669375Z","iopub.execute_input":"2021-05-27T22:06:03.669763Z","iopub.status.idle":"2021-05-27T22:06:03.858243Z","shell.execute_reply.started":"2021-05-27T22:06:03.66973Z","shell.execute_reply":"2021-05-27T22:06:03.857412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_seed = 2\n\n#Define el tamaño del conjunto con el que se va a entrenar la red\ntest_set_percentage  = 0.25\n\n#Define si se trabaja con output size = (1,10) o output size = (1)\nsparse = False\n\nif(sparse == True):\n    train_images,test_images,train_labels,test_labels = train_test_split(labeled_images, labels, test_size = test_set_percentage, random_state=random_seed)\nelse:\n    train_images,test_images,train_labels,test_labels = train_test_split(labeled_images, one_hot_labels, test_size = test_set_percentage, random_state=random_seed)\n    \nif(sparse == True):\n    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\nelse:\n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:06:27.074162Z","iopub.execute_input":"2021-05-27T22:06:27.074695Z","iopub.status.idle":"2021-05-27T22:06:27.547263Z","shell.execute_reply.started":"2021-05-27T22:06:27.074635Z","shell.execute_reply":"2021-05-27T22:06:27.546126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen = keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, \n                                                        samplewise_center=False, \n                                                        featurewise_std_normalization=False, \n                                                        samplewise_std_normalization=False, \n                                                        zca_whitening=False, \n                                                        zca_epsilon=1e-06, \n                                                        rotation_range=30, \n                                                        width_shift_range=0.1, \n                                                        height_shift_range=0.1, \n                                                        brightness_range=None, \n                                                        shear_range=0.1, \n                                                        zoom_range=0.1, \n                                                        channel_shift_range=0.0, \n                                                        fill_mode='nearest', \n                                                        cval=0.0, \n                                                        horizontal_flip=False, \n                                                        vertical_flip=False, \n                                                        rescale=0, \n                                                        preprocessing_function=None, \n                                                        data_format=None, \n                                                        validation_split=0.0, \n                                                        dtype=None)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:06:45.689356Z","iopub.execute_input":"2021-05-27T22:06:45.689741Z","iopub.status.idle":"2021-05-27T22:06:45.697207Z","shell.execute_reply.started":"2021-05-27T22:06:45.689705Z","shell.execute_reply":"2021-05-27T22:06:45.695979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen.fit(train_images)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:07:04.903238Z","iopub.execute_input":"2021-05-27T22:07:04.903864Z","iopub.status.idle":"2021-05-27T22:07:05.016995Z","shell.execute_reply.started":"2021-05-27T22:07:04.903806Z","shell.execute_reply":"2021-05-27T22:07:05.01606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Entrena el modelo con 10 epochs, pero originalmente se corrio con 40 epochs\nfit_history = model.fit(data_gen.flow(train_images, train_labels, batch_size=32), \n                        epochs=10, \n                        validation_data=(test_images,test_labels),\n                        verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:07:42.600475Z","iopub.execute_input":"2021-05-27T22:07:42.600857Z","iopub.status.idle":"2021-05-27T22:29:07.007241Z","shell.execute_reply.started":"2021-05-27T22:07:42.600825Z","shell.execute_reply":"2021-05-27T22:29:07.00633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc      = fit_history.history['accuracy']\nval_acc  = fit_history.history['val_accuracy']\nloss     = fit_history.history['loss']\nval_loss = fit_history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:34:02.863616Z","iopub.execute_input":"2021-05-27T22:34:02.864Z","iopub.status.idle":"2021-05-27T22:34:03.177894Z","shell.execute_reply.started":"2021-05-27T22:34:02.863958Z","shell.execute_reply":"2021-05-27T22:34:03.176694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize model.\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:34:35.112066Z","iopub.execute_input":"2021-05-27T22:34:35.11244Z","iopub.status.idle":"2021-05-27T22:34:35.122032Z","shell.execute_reply.started":"2021-05-27T22:34:35.112409Z","shell.execute_reply":"2021-05-27T22:34:35.120531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen = keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, \n                                                        samplewise_center=False, \n                                                        featurewise_std_normalization=False, \n                                                        samplewise_std_normalization=False, \n                                                        zca_whitening=False, \n                                                        zca_epsilon=1e-06, \n                                                        rotation_range=25, \n                                                        width_shift_range=0.1, \n                                                        height_shift_range=0.1, \n                                                        brightness_range=None, \n                                                        shear_range=0.1, \n                                                        zoom_range=0.1, \n                                                        channel_shift_range=0.0, \n                                                        fill_mode='nearest', \n                                                        cval=0.0, \n                                                        horizontal_flip=False, \n                                                        vertical_flip=False, \n                                                        rescale=0, \n                                                        preprocessing_function=None, \n                                                        data_format=None, \n                                                        validation_split=0.0, \n                                                        dtype=None)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T22:34:51.446121Z","iopub.execute_input":"2021-05-27T22:34:51.446478Z","iopub.status.idle":"2021-05-27T22:34:51.453699Z","shell.execute_reply.started":"2021-05-27T22:34:51.446448Z","shell.execute_reply":"2021-05-27T22:34:51.452552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen.fit(labeled_images)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:05:43.561124Z","iopub.execute_input":"2021-05-27T23:05:43.561533Z","iopub.status.idle":"2021-05-27T23:05:43.725105Z","shell.execute_reply.started":"2021-05-27T23:05:43.561496Z","shell.execute_reply":"2021-05-27T23:05:43.723908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(data_gen.flow(labeled_images, one_hot_labels, batch_size=36), epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:08:06.909708Z","iopub.execute_input":"2021-05-27T23:08:06.910121Z","iopub.status.idle":"2021-05-27T23:35:00.090467Z","shell.execute_reply.started":"2021-05-27T23:08:06.910085Z","shell.execute_reply":"2021-05-27T23:35:00.08899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(labeled_images, one_hot_labels, batch_size=36)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:35:06.063266Z","iopub.execute_input":"2021-05-27T23:35:06.06363Z","iopub.status.idle":"2021-05-27T23:35:43.188947Z","shell.execute_reply.started":"2021-05-27T23:35:06.063597Z","shell.execute_reply":"2021-05-27T23:35:43.18757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict results\nresults = model.predict(unlabeled_images)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:41:55.845473Z","iopub.execute_input":"2021-05-27T23:41:55.845878Z","iopub.status.idle":"2021-05-27T23:42:19.936071Z","shell.execute_reply.started":"2021-05-27T23:41:55.845843Z","shell.execute_reply":"2021-05-27T23:42:19.935046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:42:25.207649Z","iopub.execute_input":"2021-05-27T23:42:25.208007Z","iopub.status.idle":"2021-05-27T23:42:25.214539Z","shell.execute_reply.started":"2021-05-27T23:42:25.207976Z","shell.execute_reply":"2021-05-27T23:42:25.21364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select the index with the maximum probability\nresults = np.argmax(results,axis=1)\n\nresults_serie = pd.Series(results,name=\"Label\")","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:42:29.420983Z","iopub.execute_input":"2021-05-27T23:42:29.421403Z","iopub.status.idle":"2021-05-27T23:42:29.42831Z","shell.execute_reply.started":"2021-05-27T23:42:29.421364Z","shell.execute_reply":"2021-05-27T23:42:29.4271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results_serie],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:43:05.521984Z","iopub.execute_input":"2021-05-27T23:43:05.522326Z","iopub.status.idle":"2021-05-27T23:43:05.529025Z","shell.execute_reply.started":"2021-05-27T23:43:05.522296Z","shell.execute_reply":"2021-05-27T23:43:05.528094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unlabeled data model predictions\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-05-27T23:43:08.48803Z","iopub.execute_input":"2021-05-27T23:43:08.488475Z","iopub.status.idle":"2021-05-27T23:43:08.505547Z","shell.execute_reply.started":"2021-05-27T23:43:08.488433Z","shell.execute_reply":"2021-05-27T23:43:08.503965Z"},"trusted":true},"execution_count":null,"outputs":[]}]}