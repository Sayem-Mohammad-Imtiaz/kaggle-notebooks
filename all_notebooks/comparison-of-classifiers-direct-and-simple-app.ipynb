{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport seaborn as sns\nimport plotly.express as px\nfrom mpl_toolkits import mplot3d \nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report,plot_confusion_matrix\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Viewing the data contents and its summary :-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking if any feature column has any null values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Making sure all the data is in numeric form**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visulizations of the data :-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hm = df.corr()\nsns.heatmap(hm, xticklabels=hm.columns, yticklabels=hm.columns , cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.box(df, x='sex', y='age', points=\"all\",color_discrete_sequence =['green']*len(df))\nfig.update_layout(title_text=\"Male = 1 Female =0\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.box(df, x='target', y='age', color_discrete_sequence =['red']*len(df))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize =(14, 9)) \nax = plt.axes(projection ='3d') \n\nax.scatter(df['age'], df['sex'], df['chol'], c='orange', marker='o') \nax.set_xlabel('Age')\nax.set_ylabel('Sex')\nax.set_zlabel('Cholestrol')  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.values\nx=X[:,0:13]\ny=X[:,13]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Standardizing all the feature values and spliiting the data into train and test set:-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x=preprocessing.StandardScaler().fit(x).transform(x)\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.1,random_state=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K Nearest Neighbour Classifier :-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nkmax=22\nmean_acc=np.zeros((kmax-1))\n\nfor i in range(1,kmax):\n    kn=KNeighborsClassifier(n_neighbors=i).fit(xtrain,ytrain)\n    yhat=kn.predict(xtest)\n    n1=1000\n    mean_acc[i-1]=metrics.accuracy_score(ytest,yhat)\n    \nplt.plot(range(1,kmax),mean_acc,'r')\nplt.ylabel('Accuracy')\nplt.xlabel('Number of neighbors')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the optimal number of neighbors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best accuracy of KNN was\", mean_acc.max(),\"with k=\",mean_acc.argmax()+1)\nkn=KNeighborsClassifier(n_neighbors=19).fit(xtrain,ytrain)\nyhat=kn.predict(xtest)\n\nplot_confusion_matrix(kn,xtest,ytest,cmap=plt.cm.Blues)\nplt.show()\nprint(classification_report(ytest,yhat))\na1=metrics.accuracy_score(ytest,yhat)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logisitic Regression Classifier:-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Lib Linear solver :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LR1=LogisticRegression(C=0.01,solver=\"liblinear\").fit(xtrain,ytrain)\nyhat1=LR1.predict(xtest)\n\nplot_confusion_matrix(LR1,xtest,ytest,cmap=plt.cm.Reds)\nplt.show()\n\nprint(classification_report(ytest,yhat1))\na2=metrics.accuracy_score(ytest,yhat1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Newton-cg solver :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LR2=LogisticRegression(C=0.01,solver=\"newton-cg\").fit(xtrain,ytrain)\nyhat2=LR2.predict(xtest)\n\nplot_confusion_matrix(LR2,xtest,ytest,cmap=plt.cm.Greys)\nplt.show()\n\nprint(classification_report(ytest,yhat2))\na3=metrics.accuracy_score(ytest,yhat2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using SAG solver :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LR3=LogisticRegression(C=0.01,solver=\"sag\").fit(xtrain,ytrain)\nyhat3=LR3.predict(xtest)\n\nplot_confusion_matrix(LR3,xtest,ytest,cmap=plt.cm.YlOrBr)\nplt.show()\n\nprint(classification_report(ytest,yhat3))\na4=metrics.accuracy_score(ytest,yhat3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Machine Classifier :-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the rbf kernel:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmM1=svm.SVC(C=0.2,kernel='rbf')\nsvmM1.fit(xtrain,ytrain)\nyhatsvm1=svmM1.predict(xtest)\n\nplot_confusion_matrix(svmM1,xtest,ytest,cmap=plt.cm.Greens)\nplt.show()\n\nprint(classification_report(ytest,yhatsvm1))\na5=metrics.accuracy_score(ytest,yhatsvm1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the linear kernel:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmM2=svm.SVC(C=0.1,kernel='linear')\nsvmM2.fit(xtrain,ytrain)\nyhatsvm2=svmM2.predict(xtest)\n\nplot_confusion_matrix(svmM2,xtest,ytest,cmap=plt.cm.Blues)\nplt.show()\n\nprint(classification_report(ytest,yhatsvm2))\na6=metrics.accuracy_score(ytest,yhatsvm2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the ploynomial kernel :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmM3=svm.SVC(C=1.5,kernel='poly')\nsvmM3.fit(xtrain,ytrain)\nyhatsvm3=svmM3.predict(xtest)\n\nplot_confusion_matrix(svmM3,xtest,ytest,cmap=plt.cm.Oranges)\nplt.show()\n\nprint(classification_report(ytest,yhatsvm3))\na7=metrics.accuracy_score(ytest,yhatsvm3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decison Tree Classifier :-**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt=DecisionTreeClassifier(criterion=\"entropy\")\ndt.fit(xtrain,ytrain)\nyhatdt=dt.predict(xtest)\n\nplot_confusion_matrix(dt,xtest,ytest,cmap=plt.cm.Reds)\nplt.show()\n\nprint(classification_report(ytest,yhatdt))\na8=metrics.accuracy_score(ytest,yhatdt)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest Classifier :-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=n1)\nrf = rf.fit(xtrain, ytrain)\nyhatrf=rf.predict(xtest)\n\nplot_confusion_matrix(rf,xtest,ytest,cmap=plt.cm.Greys)\nplt.show()\n\nprint(classification_report(ytest,yhatrf))\na9=metrics.accuracy_score(ytest,yhatrf)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ada Boost Classifier :-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nab = AdaBoostClassifier(n_estimators=17)\nab = ab.fit(xtrain, ytrain)\nyhatab=ab.predict(xtest)\n\nplot_confusion_matrix(ab,xtest,ytest,cmap=plt.cm.Greens)\nplt.show()\n\nprint(classification_report(ytest,yhatab))\na10=metrics.accuracy_score(ytest,yhatab)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracies of the different classifier models used :-**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"KNN Accuracy                            : %.5f\"%metrics.accuracy_score(ytest,yhat))\nprint(\"Logistic Regression(liblinear) Accuracy : %.5f\"%metrics.accuracy_score(ytest,yhat1))\nprint(\"Logistic Regression(newton-cg) Accuracy : %.5f\"%metrics.accuracy_score(ytest,yhat2))\nprint(\"Logistic Regression(sag) Accuracy       : %.5f\"%metrics.accuracy_score(ytest,yhat2))\nprint(\"SVM(rbf Kernel) Accuracy                : %.5f\"%metrics.accuracy_score(ytest,yhatsvm1))\nprint(\"SVM(linear Kernel) Accuracy             : %.5f\"%metrics.accuracy_score(ytest,yhatsvm2))\nprint(\"SVM(polynomial Kernel)                  : %.5f\"%metrics.accuracy_score(ytest,yhatsvm3))\nprint(\"Decision Tree Accuracy                  : %.5f\"%metrics.accuracy_score(ytest,yhatdt))\nprint(\"Random Forest Accuracy                  : %.5f\"%metrics.accuracy_score(ytest,yhatrf))\nprint(\"Ada Boost Accuracy                      : %.5f\"%metrics.accuracy_score(ytest,yhatab))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nclassifiers = ['KNN', 'LR1', 'LR2', 'LR3', 'SVM1','SVM2','SVM3','DT','RF','AB']\naccuracies = [a1,a2,a3,a4,a5,a6,a7,a8,a9,a10]\nax.bar(classifiers,accuracies,align='center', width=0.4)\nplt.ylim([0.7, 0.95])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that for the given data, Logisitic Regression(with Linear solver), SVM(with a Linear Kernel) and Random Forest Classifier gave the highest accuracies. Whereas SVM(with a Ploynomial Kernel) and Decision Tree Classifier gave the least accuracy.\nI hope this insight, comparions and the various models helped.\nCheers","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}