{"cells":[{"metadata":{"_uuid":"daf83ff4d120f1731d6c60e6232b0e3392c046dc","_cell_guid":"ce21c07f-71ac-4a64-8881-0535b4c830f9"},"cell_type":"markdown","source":"Notebook that explores the correlation between happiness and six factors – economic production, social support, life expectancy, freedom, absence of corruption, and generosity  – that strongly contribute to making life evaluations higher. Makes a prediction of happiness based on these six factors using gradient boosted regressor. This notebook is a variation of the data analysis used to make this [interactive visual exploration of the state of global happiness](http://www.alexanderbastidasfry.com/happy/)."},{"metadata":{"_uuid":"0f8e154bf3f60818e9ca96fe18a820c2b559768f","_cell_guid":"5abbf3e6-42d5-457f-8e7d-8be5b070e061","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor"},{"metadata":{"_uuid":"0534a4bf58de023483a7fb74ac36b84a8802321d","_cell_guid":"01c04cf3-2a92-4af5-8fd5-4cb1e174b2b7"},"execution_count":null,"cell_type":"code","outputs":[],"source":"happy_index = pd.read_csv(\"../input/2017.csv\", sep=',', header=0, names=[\"country\", \"rank\", \"score\", \"high\", \"low\", \"gdp\", \"family\", \"health\", \"free\", \"gen\", \"trust\",\"dystopia\"])\nhappy_index.head(5)"},{"metadata":{"_uuid":"a227e2f947c6d170b04920d66eea6c8cf4ab8a57","_cell_guid":"a302b03a-fc94-4708-a13d-8931988e2c38"},"execution_count":null,"cell_type":"code","outputs":[],"source":"corr_matrix = happy_index.corr()\nsns.heatmap(corr_matrix, annot=True, cbar=True, cmap=\"RdYlGn\")\nplt.show()"},{"metadata":{"_uuid":"6226f3aaf4d6ecee35ca70c1a1c2f34245011931","_cell_guid":"99487ca2-8a41-4374-ad29-33f281557bc2"},"cell_type":"markdown","source":"simplfy data to just the relevant metrics"},{"metadata":{"_uuid":"48c4c36ffce9a0cd9b56a06261cd98952aa3c1d4","_cell_guid":"d38c71da-e963-4587-87db-c350d0b631f4"},"execution_count":null,"cell_type":"code","outputs":[],"source":"cols = [\"score\",\"high\", \"low\", \"family\", \"gdp\", \"free\", \"health\", \"gen\", \"trust\"]\nhappy_index_simple = happy_index[cols]\nscaler = MinMaxScaler()\nhappy_index_simple[cols] = scaler.fit_transform(happy_index[cols])\ncorr_matrix = happy_index[[\"score\", \"family\", \"gdp\", \"free\", \"health\", \"gen\", \"trust\"]].corr()\nsns.set_context(\"poster\",font_scale=1.0) \nsns.heatmap(corr_matrix, annot=True, cbar=True, cmap=\"GnBu\")\nplt.show()"},{"metadata":{"_uuid":"67ad8ade923f71f1494a1a9ca933fa9ed0a1825a","_cell_guid":"442b7980-e240-420d-b007-e346515d0899"},"cell_type":"markdown","source":"First a simple linear regression fit for each metric"},{"metadata":{"_uuid":"565a7114c214e4221fd1a96ca7c5768c879a2ecb","_cell_guid":"35b746d9-bf41-4687-bb9f-2530ba0740c3","_kg_hide-input":false},"execution_count":null,"cell_type":"code","outputs":[],"source":"metrics = [\"family\", \"gdp\", \"free\", \"health\", \"gen\", \"trust\"]\nintercepts = {}\ncoefs = {}\nf, axes  = plt.subplots(3, 2, sharey='row')\nn = 0 \nfor metric in metrics:    \n    X = happy_index_simple[metric]\n    X = X.values.reshape(-1,1)\n    y = happy_index_simple[\"score\"]\n    y = y.values.reshape(-1,1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n    lr = LinearRegression(normalize=False, fit_intercept=True)\n    lr.fit(X_train,y_train)\n    intercepts[metric] = lr.intercept_[0]\n    coefs[metric] = lr.coef_[0][0]\n    predictions = lr.predict(X_test)\n    axes[n%3][n%2].scatter(X_train,y_train, color = \"grey\")\n    #axes[n%3][n%2].scatter(X_test,y_test, color = \"black\")\n    axes[n%3][n%2].plot(X_train, lr.coef_[0][0]*X_train+ lr.intercept_[0], color=\"black\", alpha=.7)\n    axes[n%3][n%2].set_title(metric)\n    n += 1\nf.subplots_adjust(hspace=0.4)\nplt.show()\nprint(intercepts)\nprint(coefs)"},{"metadata":{"_uuid":"9e8b318a9e57ab2dbf31d63c214288ac9ee87f62","_cell_guid":"ef70ae34-9161-4c7e-abc5-87d8b8244164","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[],"source":"def plot_errors(X_test,y_test,predictions):\n    f, axes  = plt.subplots(3, 2, sharey='row')\n    n = 0 \n    for metric in metrics:\n    #axes[n%3][n%2].scatter(X_test[metric].values, y_test, color = \"black\")\n        axes[n%3][n%2].scatter(X_test[metric].values, y_test-predictions, color = \"grey\", alpha=.7)\n        axes[n%3][n%2].set_title(metric)\n        n += 1\n        f.subplots_adjust(hspace=0.4)\n    plt.show()"},{"metadata":{"_uuid":"dae1465db478c1af0c1315832dbf44f6736126c7","_cell_guid":"4b7db7d1-ef19-4682-9ea9-ae71a0780abf","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[],"source":"X = happy_index_simple[metrics]\ny = happy_index_simple[\"score\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)"},{"metadata":{"_uuid":"4ff00eb68af79edaf333cbc22085c0f727f955b3","_cell_guid":"96be1be3-877c-4a08-8fe2-bdd944a556ef"},"execution_count":null,"cell_type":"code","outputs":[],"source":"mlr = LinearRegression(normalize=False, fit_intercept=True)\nmlr.fit(X_train, y_train)\nprint('Coeff:', mlr.coef_)\nprint('Intercept:', mlr.intercept_)\nmlr_predictions = mlr.predict(X_test)\nprint('mae:', mean_absolute_error(y_test, mlr_predictions))\nprint('mse:', mean_squared_error(y_test, mlr_predictions))\nprint('rmse:', np.sqrt(mean_squared_error(y_test, mlr_predictions)))\nprint('score:', mlr.score(X_test, y_test))\nplot_errors(X_test, y_test, mlr_predictions)"},{"metadata":{"_uuid":"63182f1c6fa8ea40f39ba38581f651f06196d14a","_cell_guid":"cc031e01-c4b5-476b-bca6-32d471a061d1"},"cell_type":"markdown","source":"Gradient Boosting Regressor approach with cross validation and grid search to get best params"},{"metadata":{"_uuid":"450f5dfe2fda1d82a8ea4736b4b3b8d23ca8ee30","_cell_guid":"9d7d8ee8-572e-4b12-960a-48a751cd754a"},"execution_count":null,"cell_type":"code","outputs":[],"source":"gbr = GradientBoostingRegressor(alpha=0.85, learning_rate=0.1, loss=\"ls\",\n                                              max_features=0.9, min_samples_leaf=5,\n                                              min_samples_split=6)\nparam_grid = [\n    {'n_estimators': [96,128,512],\n    'min_samples_leaf':[1,5],\n    'alpha': [.85,.9, .95]}\n    #'min_impurity_split': [1e-08,1e-06,1e-05],\n    #'max_features': [.5,0.9,1],\n    #'min_samples_split': [2,6]}\n    ]\ngbr_grid = GridSearchCV(gbr, cv=2, n_jobs=2, param_grid=param_grid, scoring=\"neg_mean_squared_error\")\ngbr_grid.fit(X,y)\ngbr_cv = gbr_grid.best_estimator_\n#print(gbr_cv.get_params)\ngbr_cv.fit(X_train,y_train)\ngbr_predictions = gbr_cv.predict(X_test)\nprint('mae:', mean_absolute_error(y_test, gbr_predictions))\nprint('mse:', mean_squared_error(y_test, gbr_predictions))\nprint('rmse:', np.sqrt(mean_squared_error(y_test, gbr_predictions)))\nprint('score:', gbr_cv.score(X_test, y_test))\nplot_errors(X_test, y_test, gbr_predictions)\n"},{"metadata":{"_uuid":"2c5ec4dc4ca6832aa81aa273091791a967becdbf","_cell_guid":"7e405b16-16cb-44ff-97f7-9e6753f9887f"},"cell_type":"markdown","source":"Compare all the errors."},{"metadata":{"_uuid":"dd45729d9d63e658e505c00cac50037fbf2d272a","_cell_guid":"5ac29e16-023b-4134-a58f-2e1e9393fe00"},"execution_count":null,"cell_type":"code","outputs":[],"source":"X = happy_index_simple[metrics] \ny = happy_index_simple[\"score\"]\nxrange_vals = range(len(X))\nxrange_vals = np.asarray(xrange_vals).reshape(-1,1)\n\n#multiple linear regression\nmlr_error = - y + mlr.predict(X)\nplt.plot(xrange_vals, mlr_error, color=\"blue\", alpha=.2, label='multiple linear regression')\nmlr_meta = LinearRegression(normalize=False, fit_intercept=True)\nmlr_meta.fit(xrange_vals, mlr_error)\nplt.plot(xrange_vals,mlr_meta.predict(xrange_vals), color=\"blue\")\n\n#gradient boosted regression\ngbr_error = - y + gbr_cv.predict(X)\nplt.plot(xrange_vals, gbr_error, color=\"red\", alpha=.2, label='gradient boosted regression')\ngbr_meta = LinearRegression(normalize=False, fit_intercept=True)\ngbr_meta.fit(xrange_vals, gbr_error)\nplt.plot(xrange_vals, gbr_meta.predict(xrange_vals), color=\"red\")\n\nplt.xlabel(\"country rank\")\nplt.ylabel(\"error\")\nplt.legend()\nplt.show()"},{"metadata":{"_uuid":"6ce0217dc4142eefaab0e1696476f1a9cd7da4c4","_cell_guid":"e65b6913-4b53-4a48-9d5e-876e806a8588"},"cell_type":"markdown","source":"gradient boosted regression comparison to mean errors"},{"metadata":{"_uuid":"d4023c0eaa09ce3a0ea9089835c0cf0f3d5b678b","_cell_guid":"854ed35b-bbc7-456b-b7ec-a0b8edd0f0af"},"execution_count":null,"cell_type":"code","outputs":[],"source":"gbr_error = - y + gbr_cv.predict(X)\nplt.plot(xrange_vals, gbr_error, color=\"red\", alpha=.5, label='gradient boosted regression')\ngbr_meta = LinearRegression(normalize=False, fit_intercept=True)\ngbr_meta.fit(xrange_vals, gbr_error)\nplt.plot(xrange_vals, gbr_meta.predict(xrange_vals), color=\"red\")\nplt.plot(xrange_vals, happy_index_simple[\"score\"]-happy_index_simple[\"high\"], color=\"black\", alpha=.5, label=\"error\")\nplt.plot(xrange_vals, happy_index_simple[\"score\"]-happy_index_simple[\"low\"], color=\"black\", alpha=.5)\nplt.xlabel(\"country rank\")\nplt.ylabel(\"error\")\nplt.legend()\nplt.show()\n\nhappy_index_simple[\"delta\"] = gbr_error\nhappy_index_simple[\"pred\"] = gbr_cv.predict(X)\nprint(happy_index_simple.head(5))"},{"metadata":{"_uuid":"de8751f97eae3081d921ca8fb07be82582739af2","_cell_guid":"3d1ad1a8-40da-4d0c-9a7d-91194770cf6e"},"cell_type":"markdown","source":" All these regression fits under predict the happiness of the most happy countries, while over predicting the happiness for unhappy countries! But the skew is worse for linear regression.\n"}],"metadata":{"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","nbconvert_exporter":"python","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"nbformat":4}