{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA & ML Modelling Report on Loan Approval\n\nAnalysis By: NEELESH DUGAR\n\nEmail: dugar.nilesh23@gmail.com\n\nMob: +91-7838823636","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### 1. We are importing WARNINGS class to suppress any warning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2. We are now importing all necessary packages for our report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport gc\nfrom datetime import datetime \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, SGDClassifier, LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom xgboost import XGBClassifier\nimport lightgbm as lgbm\n\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 3. We will now load the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/LoanApproval.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 4. Let us have a preview of the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop('Loan_ID', axis=1, inplace= True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 5. Let us see the no. of rows and columns in this dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dataset contains -\",data.shape[0],\"rows and\",data.shape[1],\"columns\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 6. Let us see a basic Descriptive Stats of this dataset (Before Cleaning)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 7. How many null values are there column-wise?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 8. We will now handle Missing Values and Categorical Variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"(a) Converting Categorical Variable 'Gender' to Numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Gender[data.Gender == 'Male'] = 1\ndata.Gender[data.Gender == 'Female'] = 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(b) Filling missing values in 'Gender' by random function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_gender = [1,2]\ndata.Gender.fillna(np.random.choice(dict_gender), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(c) Converting Categorical Variable 'Married' to Numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Married[data.Married == 'Yes'] = 1\ndata.Married[data.Married == 'No'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(d) Filling missing values in 'Married' by random function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_married = [0,1]\ndata.Married.fillna(np.random.choice(dict_married), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(e) Filling missing values in 'Dependents' by random function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_dependents = [0,1,2,3]\ndata.Dependents.fillna(np.random.choice(dict_dependents), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(f) Converting Categorical Variable 'Self_Employed' to Numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Self_Employed[data.Self_Employed == 'Yes'] = 1\ndata.Self_Employed[data.Self_Employed == 'No'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(g) Filling missing values in 'Self_Employed' by random function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_self_employed = [0,1]\ndata.Self_Employed.fillna(np.random.choice(dict_self_employed), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(h) Filling missing values in 'LoanAmount' by mean function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.LoanAmount.fillna(data.LoanAmount.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(i) Filling missing values in 'Loan_Amount_Term' by random function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_loan_amount_term = [120,240,360,480]\ndata.Loan_Amount_Term.fillna(np.random.choice(dict_loan_amount_term), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(j) Filling missing values in 'Credit_History' by random function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_credit_history = [0,1]\ndata.Credit_History.fillna(np.random.choice(dict_credit_history), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now that we have treated all Missing values, there should be no NULL/NaN values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 9. Let us now again see a basic Descriptive Stats of this dataset (After Cleaning)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 10. Now lets see some visualizations for possible combinations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have converted datatype of 'Gender' from 'int64'->'object', for Visualization purpose\ndata.Gender=data.Gender.astype(object)\n\n# We have converted datatype of 'Married' from 'int64'->'object', for Visualization purpose\ndata.Married=data.Married.astype(object)\n\n# We have converted datatype of 'Self_Employed' from 'int64'->'object', for Visualization purpose\ndata.Self_Employed=data.Self_Employed.astype(object)\n\n# This command below will show the datatypes of all the columns\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we are creating a new DataFrame named \"obj_cols\" from the old DataFrame 'data' which will have columns with only OBJECT as its datatype\nobj_cols = [*data.select_dtypes('object').columns]\nobj_cols1 = obj_cols\nobj_cols.remove('Loan_Status')\n\n# Setting up the height & width of the plot we will make below\nplt.figure(figsize=(24, 18))\n\n# We are using a For-loop to plot 6 graphs in one plot using \"obj_cols\" as our refernce dataset\nfor idx, cols in enumerate(obj_cols):\n    \n    plt.subplot(3, 3, idx+1)\n    \n    sns.countplot(cols, data= data, hue='Loan_Status')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we will start preparing ML models and compare their scores to select the best accurate model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"(a) Converting Categorical Variable 'Loan_Status' to Numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Loan_Status.replace({'Y': 0, 'N': 1}, inplace= True)\ndata['Loan_Status']= data.Loan_Status.astype(int)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are creating a DataFrame named 'dummies' by using '.get_dummies' function of pandas which will convert all categorical variables to dummy variables\ndummies = pd.get_dummies(data, drop_first=True)\ndummies.info()\n\n# 'SimpleImputer()' function is used to fill missing values in a DataFrame\nSimImp = SimpleImputer()\n\n# We are now creating a new DataFrame named 'train' which will be like our original dataset named 'data' but with no missing values\ntrain= pd.DataFrame(SimImp.fit_transform(dummies), columns=dummies.columns)\ntrain.info()\n\n# We are selecting all the numerical columns and making a new DataFrame with name 'num_cols'\nnum_cols = [*data.select_dtypes(['Int64', 'Float64']).columns]\nnum_cols.remove('Loan_Amount_Term')\nnum_cols.remove('Credit_History')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are creating a new DataFrame named 'obj_train' from the old Train DataFrame by removing all the numerical columns from it\n# obj_train = train.drop(num_cols, axis=1)\n# obj_train.info()\n\n# For ML modelling, we'll only use the categorical features for training \nX, y = train.drop('Loan_Status', axis=1), train.Loan_Status\n\n# We will split the data to train and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify= y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\nlog_pred = log_reg.predict(X_test)\nlog_score = round(log_reg.score(X_train, y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Ada Boost Classifier ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = AdaBoostClassifier()\nabc.fit(X_train,y_train)\nabc_pred = abc.predict(X_test)\nabc_score = round(abc.score(X_train, y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. LogisticRegressionCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lrcv = LogisticRegressionCV()\nlrcv.fit(X_train,y_train)\nlrcv_pred = lrcv.predict(X_test)\nlrcv_score = round(lrcv.score(X_train, y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Stochastic Gradient Descent (SGD) Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = SGDClassifier()\nsgd.fit(X_train,y_train)\nsgd_pred = sgd.predict(X_test)\nsgd_score = round(sgd.score(X_train, y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. XG Boost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X_train,y_train)\nxgb_pred = xgb.predict(X_test)\nxgb_score = round(xgb.score(X_train, y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We will now check scores of all the models by comparing against each other","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Ada Boost Classifier', \n              'LogisticRegressionCV', 'SGD Classifier', \n              'XG Boost'],\n    'Score': [log_score, abc_score, \n              lrcv_score, sgd_score, xgb_score]})\n\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see that the XG Boost Classifier is giving the \"Best Accuracy\" with a score of 84.93.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### I hope this report helps you in understanding a few more concepts of Data Science & Analytics. This is my second kernel posted and a lot more will be coming soon. Stay Tuned!!\nAnd you can contact me for any queries/collaboration/discussion. My contact details are available at the Top.\n\nWelcome to Data Science & Machine Learning Club! All the best for future endeavours! :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}