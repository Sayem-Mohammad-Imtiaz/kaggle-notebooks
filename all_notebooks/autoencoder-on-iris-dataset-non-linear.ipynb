{"cells":[{"metadata":{"_uuid":"433d4d6cbc0b69bc58812e3f48fc485e85dac7e9"},"cell_type":"markdown","source":"# References \n* [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n* [Matplotlib Gallery](https://matplotlib.org/gallery/index.html)"},{"metadata":{"_uuid":"335140ee2e31402a1cecd0466b7482533650ffea"},"cell_type":"markdown","source":"# Content\n* Compress the 4 features of Iris Dataset to 2 features using Autoencoder\n* Visualize training using TensorBoard\n* Plot the obtained 2 features and assign different colors to different species\n\n# Issues \n* Reconstructed data is not similar to input data.\n\n# To be Done\n* Try to use dropout in encoding layers\n    * Dropout: A Simple Way to Prevent Neural Networks from Overfitting - http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n* Try different activation functions\n\n# What's New\n* Visualized weights\n    * Initializing weights and biases in between 0 and 1 is giving better results than default initialization (which is glorot_uniform initialization)\n* Set a threshold on error\n* Tried to reduce batch_size in sgd\n    * Result is improved drastically\n* Added one more layer of length 8 on both sides of middle layer\n    * Model stopped training due to some unknown reasons"},{"metadata":{"trusted":true,"_uuid":"eed67151de83768092a5031ff028a871c048df2c"},"cell_type":"code","source":"# import shutil\n# shutil.rmtree('/tmp/autoencoder')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50e00190dfed9683e632d0d6ab8daf1dc474f49c"},"cell_type":"code","source":"import keras\nclass Histories(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.weights = []\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        nx = []\n        x = [x.reshape(-1) for x in self.model.get_weights()]\n        for xi in x :\n            nx += list(xi)\n        self.weights.append(nx)\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e454fe84a2fe6707fdf1c0ad6a1fff778b6f8332"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b279869ee8f62abf45302ee5bc70843100ecd12"},"cell_type":"markdown","source":"## Importing Data"},{"metadata":{"trusted":true,"_uuid":"3dccc906b3643ffbbd169679c9601ab673c5ba33"},"cell_type":"code","source":"data = pd.read_csv(\"../input/Iris.csv\")\nx_train, x_test, y_train, y_test = train_test_split(data[['SepalLengthCm', 'SepalWidthCm',\n                                                          'PetalLengthCm', 'PetalWidthCm']],\n                                                    data['Species'],test_size=0.1, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d158bd6a9008c93d2cf98eb9505f3a9925b19f70"},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81611a8e12dae66ddecdd76e2501a4a0fe4b0f87"},"cell_type":"markdown","source":"## Launching TensorBoard"},{"metadata":{"trusted":true,"_uuid":"164cf2d7edb504f490c0076318edab661edd2070"},"cell_type":"code","source":"# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n# !unzip ngrok-stable-linux-amd64.zip\n# LOG_DIR = '/tmp/autoencoder' # Here you have to put your log directory\n# get_ipython().system_raw(\n#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n#     .format(LOG_DIR)\n# )\n# get_ipython().system_raw('./ngrok http 6006 &')\n# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"259eb70c735aa726dc95259456eec00e53b1b189"},"cell_type":"markdown","source":"## Encoder and Decoder"},{"metadata":{"trusted":true,"_uuid":"0d3696d75b7784f4d08b32697e7c469c7818b5e6"},"cell_type":"code","source":"from keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.callbacks import TensorBoard\n\n# this is the size of our encoded representations\nencoding_dim = 2\ninput_dim = 4\n\n# this is our input placeholder\ninput_img = Input(shape=(input_dim,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(input_dim, activation='relu')(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)\n\n# this model maps an input to its encoded representation\nencoder = Model(input_img, encoded)\n\n# create a placeholder for an encoded (2-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\n\nautoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n\n\nfrom keras.utils.vis_utils import plot_model\nplot_model(autoencoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\nplt.axis(\"off\")\nplt.imshow(mpimg.imread('model_plot.png'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"x_hist = Histories()\nwhile (True):\n    x_hist = Histories()\n    # this is our input placeholder\n    input_img = Input(shape=(input_dim,))\n    # \"encoded\" is the encoded representation of the input\n    encoded = Dense(encoding_dim, activation='relu')(input_img)\n    # \"decoded\" is the lossy reconstruction of the input\n    decoded = Dense(input_dim, activation='relu')(encoded)\n    \n    # this model maps an input to its reconstruction\n    autoencoder = Model(input_img, decoded)\n\n    # this model maps an input to its encoded representation\n    encoder = Model(input_img, encoded)\n\n    # create a placeholder for an encoded (2-dimensional) input\n    encoded_input = Input(shape=(encoding_dim,))\n    # retrieve the last layer of the autoencoder model\n    decoder_layer = autoencoder.layers[-1]\n    # create the decoder model\n    decoder = Model(encoded_input, decoder_layer(encoded_input))\n\n    autoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n    \n    weight_list = []\n    \n    history = autoencoder.fit(x_train, x_train,\n                    epochs=50,\n                    batch_size=135,\n                    shuffle=True,\n                    validation_data=(x_test, x_test),\n                    verbose=0,\n                   callbacks=[TensorBoard(log_dir='/tmp/autoencoder'),x_hist])\n    \n    if (autoencoder.history.history['loss'][-1] < 1):\n        break\n\n# encode and decode some data points\n# note that we take them from the *test* set\nencoded_datapoints = encoder.predict(x_test)\ndecoded_datapoints = decoder.predict(encoded_datapoints)\n\nprint('Original Datapoints :')\nprint(x_test)\nprint('Reconstructed Datapoints :')\nprint(decoded_datapoints)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc7de62fc50a1225f87142beb03561fb47b1436a"},"cell_type":"markdown","source":"## Plotting Encoded Features"},{"metadata":{"trusted":true,"_uuid":"7398436f682db4ea45f63effb3b4a481d22cd588"},"cell_type":"code","source":"encoded_dataset = encoder.predict(data[['SepalLengthCm', 'SepalWidthCm','PetalLengthCm', 'PetalWidthCm']])\n\nplt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=data['Species'].astype('category').cat.codes)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"13085aaf036b1fd7b4d6d9e817f6bdb137948706"},"cell_type":"code","source":"autoencoder.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0ee18f1cb8e7bde31c5bded2f6ecbf7ea7829e"},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\nplt.axis(\"off\")\nplt.imshow(mpimg.imread('model_plot.png'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cad699cf7b841a2b98fb73a145c29ec3a2f4586c"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bd06d7e6110ef2340893470389b54509fc8b67a"},"cell_type":"markdown","source":"### Visualize weights"},{"metadata":{"trusted":true,"_uuid":"5052fae5addc39dcc1f281bfadd9804714dda4c1"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfor i in range(len(x_hist.weights[0])):\n    plt.plot(list(range(len(x_hist.weights))), [x[i] for x in x_hist.weights])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1465fb6dab9b153a4f38c91865221a699f25a5b3"},"cell_type":"markdown","source":"## For single iteration visualizing weights"},{"metadata":{"trusted":true,"_uuid":"a467efcf5d80cda9a90919cd2b651ce891a1a82e"},"cell_type":"code","source":"x_hist = Histories()\n# this is our input placeholder\ninput_img = Input(shape=(input_dim,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(input_dim, activation='relu')(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)\n\n# this model maps an input to its encoded representation\nencoder = Model(input_img, encoded)\n\n# create a placeholder for an encoded (2-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\n\nautoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n\nweight_list = []\n\nhistory = autoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=135,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                verbose=0,\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder'),x_hist])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5b9dcd688befef22a566df103abc3b50a0b667c"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfor i in range(len(x_hist.weights[0])):\n    plt.plot(list(range(len(x_hist.weights))), [x[i] for x in x_hist.weights])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17a072029ed7a8aba70431710b2ca2186b29c5eb","scrolled":true},"cell_type":"code","source":"# encode and decode some data points\n# note that we take them from the *test* set\nencoded_datapoints = encoder.predict(x_test)\ndecoded_datapoints = decoder.predict(encoded_datapoints)\n\nprint('Original Datapoints :')\nprint(x_test)\nprint('Reconstructed Datapoints :')\nprint(decoded_datapoints)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c0e1f14dd3b09a69eed32dec2520e373226c48b"},"cell_type":"markdown","source":"###  Effect of initializing weights and biases in between 0 and 1"},{"metadata":{"trusted":true,"_uuid":"e929c6fd90bd4e01475cda3fb7883af34c113da1"},"cell_type":"code","source":"x_hist = Histories()\n# this is our input placeholder\ninput_img = Input(shape=(input_dim,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(input_dim, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)\n\n# this model maps an input to its encoded representation\nencoder = Model(input_img, encoded)\n\n# create a placeholder for an encoded (2-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\n\nautoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n\nweight_list = []\n\nhistory = autoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=135,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                verbose=0,\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder'),x_hist])\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfor i in range(len(x_hist.weights[0])):\n    plt.plot(list(range(len(x_hist.weights))), [x[i] for x in x_hist.weights])\n\nplt.show()\n\n\n# encode and decode some data points\n# note that we take them from the *test* set\nencoded_datapoints = encoder.predict(x_test)\ndecoded_datapoints = decoder.predict(encoded_datapoints)\n\nprint('Original Datapoints :')\nprint(x_test)\nprint('Reconstructed Datapoints :')\nprint(decoded_datapoints)\nprint('Training Loss : ',history.history['loss'][-1])\nprint('Validation Loss : ',history.history['val_loss'][-1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08c12ed5210a7aaac05332522e7a1f30366ddf99"},"cell_type":"markdown","source":"### Effect of reducing batch size from 135 to 15"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4301636db4d6c121165e2bc23d9fefe143fa962a"},"cell_type":"code","source":"x_hist = Histories()\n# this is our input placeholder\ninput_img = Input(shape=(input_dim,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(input_dim, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)\n\n# this model maps an input to its encoded representation\nencoder = Model(input_img, encoded)\n\n# create a placeholder for an encoded (2-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\n\nautoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n\nweight_list = []\n\nhistory = autoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=15,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                verbose=0,\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder'),x_hist])\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfor i in range(len(x_hist.weights[0])):\n    plt.plot(list(range(len(x_hist.weights))), [x[i] for x in x_hist.weights])\n\nplt.show()\n\n# Ploting encodings\nencoded_dataset = encoder.predict(data[['SepalLengthCm', 'SepalWidthCm','PetalLengthCm', 'PetalWidthCm']])\n\nplt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=data['Species'].astype('category').cat.codes)\nplt.show()\n\n\n# encode and decode some data points\n# note that we take them from the *test* set\nencoded_datapoints = encoder.predict(x_test)\ndecoded_datapoints = decoder.predict(encoded_datapoints)\n\nprint('Original Datapoints :')\nprint(x_test)\nprint('Reconstructed Datapoints :')\nprint(decoded_datapoints)\nprint('Training Loss : ',history.history['loss'][-1])\nprint('Validation Loss : ',history.history['val_loss'][-1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12378ff4b46b26d7bfe66112b9d79f610fc7dc46"},"cell_type":"markdown","source":"### Add one more layer of size 8 on both sides of middle layer"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e63057552b9083845129e2de948bad0412096b3c"},"cell_type":"code","source":"x_hist = Histories()\n# this is our input placeholder\ninput_img = Input(shape=(input_dim,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(8, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(input_img)\n\nencoded = Dense(encoding_dim, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(encoded)\n\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(8, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(encoded)\n\ndecoded = Dense(input_dim, activation='relu',\n               kernel_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None),\n                bias_initializer=keras.initializers.RandomUniform(minval=0, maxval=1, seed=None))(decoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)\n\n# this model maps an input to its encoded representation\nencoder = Model(input_img, encoded)\n\n# create a placeholder for an encoded (2-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer1 = autoencoder.layers[-2]\ndecoder_layer2 = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer2(decoder_layer1(encoded_input)))\n\nautoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n\nfrom keras.utils.vis_utils import plot_model\nplot_model(autoencoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n\nweight_list = []\n\nhistory = autoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=135,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                verbose=0,\n               callbacks=[TensorBoard(log_dir='/tmp/autoencoder'),x_hist])\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfor i in range(len(x_hist.weights[0])):\n    plt.plot(list(range(len(x_hist.weights))), [x[i] for x in x_hist.weights])\n\nplt.show()\n\n# Ploting encodings\nencoded_dataset = encoder.predict(data[['SepalLengthCm', 'SepalWidthCm','PetalLengthCm', 'PetalWidthCm']])\n\nplt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=data['Species'].astype('category').cat.codes)\nplt.show()\n\n\n# encode and decode some data points\n# note that we take them from the *test* set\nencoded_datapoints = encoder.predict(x_test)\ndecoded_datapoints = decoder.predict(encoded_datapoints)\n\nprint('Original Datapoints :')\nprint(x_test)\nprint('Reconstructed Datapoints :')\nprint(decoded_datapoints)\nprint('Training Loss : ',history.history['loss'][-1])\nprint('Validation Loss : ',history.history['val_loss'][-1])\n\nfrom PIL import Image\nImage.open('model_plot.png')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}