{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Importing Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Additional details about the attributes:**-\n\n1)Pregnancies: Number of times pregnant\n\n2)Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\n3)BloodPressure: Diastolic blood pressure (mm Hg)\n\n4)SkinThickness: Triceps skin fold thickness (mm)\n\n5)Insulin: 2-Hour serum insulin (mu U/ml)\n\n6)BMI: Body mass index (weight in kg/(height in m)^2)\n\n7)DiabetesPedigreeFunction: Diabetes pedigree function\n\n8)Age: Age (years)\n\n9)Outcome: Class variable (0 or 1)"},{"metadata":{},"cell_type":"markdown","source":"**importing dataset**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv',encoding='utf8', engine='python')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").size()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"maximum value=\",df['Glucose'].max())\nprint(\"maximum value=\",df['BloodPressure'].max())\nprint(\"maximum value=\",df['SkinThickness'].max())\nprint(\"maximum value=\",df['Insulin'].max())\nprint(\"maximum value=\",df['BMI'].max())\nprint(\"maximum value=\",df['DiabetesPedigreeFunction'].max())\nprint(\"maximum value=\",df['Age'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"manimum value=\",df['Glucose'].min())\nprint(\"manimum value=\",df['BloodPressure'].min())\nprint(\"manimum value=\",df['SkinThickness'].min())\nprint(\"manimum value=\",df['Insulin'].min())\nprint(\"manimum value=\",df['BMI'].min())\nprint(\"manimum value=\",df['DiabetesPedigreeFunction'].min())\nprint(\"manimum value=\",df['Age'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Count plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,1,figsize=(10,4))\nsns.countplot(x=\"Outcome\",data=df,palette=\"plasma\")\n#df['Outcome'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Relation between pregnancies and diebetes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,1,figsize=(20,4))\nsns.countplot(x=\"Pregnancies\",data=df,hue=\"Outcome\",palette=\"plasma\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Histogram**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(12,12))  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Correlation matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_corr(df,size=11): \n    corr = df.corr() # calling the correlation function on the datafrmae\n    fig, ax = plt.subplots(figsize=(size,size))\n    ax.matshow(corr) # color code the rectangles by correlation value\n    plt.xticks(range(len(corr.columns)),corr.columns) # draw x tickmarks\n    plt.yticks(range(len(corr.columns)),corr.columns)\nplot_corr(df)    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Boxplot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(kind= 'box' , subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(12,12)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KDE Plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,1,figsize=(25,4))\nsns.kdeplot(df.loc[(df['Outcome']==1), 'Glucose'], color='r', shade=True, Label='1')\nsns.kdeplot(df.loc[(df['Outcome']==0), 'Glucose'], color='g', shade=True, Label='0')\nplt.xlabel('Glucose') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,1,figsize=(25,4))\nsns.kdeplot(df.loc[(df['Outcome']==1), 'BloodPressure'], color='c', shade=True, Label='1')\nsns.kdeplot(df.loc[(df['Outcome']==0), 'BloodPressure'], color='m', shade=True, Label='0')\nplt.xlabel('BloodPressure') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scatter matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nscatter_matrix(df, figsize = (20,20),color='m')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pairplot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,hue = 'Outcome', vars = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'] )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Violinplot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(20,5))\nbox1=sns.violinplot(x=\"Outcome\",y=\"Glucose\",data=df,ax=ax[0])\nbox2=sns.violinplot(x=\"Outcome\",y=\"BloodPressure\",data=df,ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train Test split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"attributes = list(df.columns[:8])  # creates a list of all paramter names\nX = df[attributes].values  # masking the parameter values\ny= df['Outcome'].values  # Just picking up values from Outcome.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nsc_X = StandardScaler() \nX = sc_X.fit_transform(X) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train Test Split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state =0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\nfrom sklearn.calibration import CalibratedClassifierCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append((\"LR\",LogisticRegression()))\nmodels.append((\"GNB\",GaussianNB()))\nmodels.append((\"KNN\",KNeighborsClassifier()))\nmodels.append((\"DecisionTree\",DecisionTreeClassifier()))\nmodels.append((\"LDA\",  LinearDiscriminantAnalysis()))\nmodels.append((\"QDA\",  QuadraticDiscriminantAnalysis()))\nmodels.append((\"AdaBoost\", AdaBoostClassifier()))\nmodels.append((\"SVM Linear\",SVC(kernel=\"linear\")))\nmodels.append((\"SVM RBF\",SVC(kernel=\"rbf\")))\nmodels.append((\"Random Forest\",  RandomForestClassifier()))\nmodels.append((\"Bagging\",BaggingClassifier()))\nmodels.append((\"Calibrated\",CalibratedClassifierCV()))\nmodels.append((\"GradientBoosting\",GradientBoostingClassifier()))\nmodels.append((\"LinearSVC\",LinearSVC()))\nmodels.append((\"Ridge\",RidgeClassifier()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfor name,model in models:\n    kfold = KFold(n_splits=10, random_state=0)\n    cv_result = cross_val_score(model,X_train,y_train, cv = kfold,scoring = \"accuracy\")\n# It gives you an unbiased estimate of the actual performance you will get at runtime\n    results.append(tuple([name,cv_result.mean(), cv_result.std()]))\n    results.sort(key=lambda x: x[1], reverse = True)    \nfor i in range(len(results)):\n    print('{:20s} {:2.2f} (+/-) {:2.2f} '.format(results[i][0] , results[i][1] * 100, results[i][2] * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nmodel = SVC()\nparamaters = [\n             {'C' : [0.01, 0.1, 1, 10, 100, 1000], 'kernel' : ['linear']}   \n             ]\ngrid_search = GridSearchCV(estimator = model, \n                           param_grid = paramaters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search = grid_search.fit(X_train, y_train)\nbest_accuracy = grid_search.best_score_ \nbest_parameters = grid_search.best_params_  \nprint('Best accuracy : ', grid_search.best_score_)\nprint('Best parameters :', grid_search.best_params_  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting output for test set. \nfinal_model = SVC(C = 0.1, kernel = 'linear')\nfinal_model.fit(X_train, y_train)\ny_pred = final_model.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncf = confusion_matrix(y_test, y_pred)\nprint(cf)\nprint(accuracy_score(y_test, y_pred) * 100) \nfrom sklearn.metrics import classification_report\nreport = classification_report(y_test, y_pred)\nprint(report)\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_pred)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nplt.figure(figsize = (10,7))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, color = 'red', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = final_model.score(X_train,y_train)\ntest_score = final_model.score(X_test,y_test)\nprint(f'Training Accuracy of our model is: {train_score}')\nprint(f'Test Accuracy of our model is: {test_score}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}