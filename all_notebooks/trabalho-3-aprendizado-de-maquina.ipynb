{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://lh3.googleusercontent.com/proxy/TT8EmtFoqnN0XU2HpT8NYFx4T9Hs0k0M8fvinBxFNwWZ7oDX3PkGtU0Fim99qji5diZcDt03gvZ7McVrv1UJoo790-ih2gM8mOIXQD7LMzDuvMZnv_Y6FCaztbhTqTi2ZitSwTz2hH9CJzRYwNXzbhw)"},{"metadata":{},"cell_type":"markdown","source":"# Bruno Dutra e Diogo Ceddia\n# Inteligência Artificial\n# Trabalho 3 - Aprendizado de Máquina"},{"metadata":{},"cell_type":"markdown","source":"Inicialmente, esse dataset fora escolhido devido ao seu tamanho (quase um milhão de linhas e 45 colunas). Dessa forma, é possível que possamos filtrar e preprocessar à vontade, sem que haja preocupação em reduzir demasiadamente o dataset. Inicialmente, o dataset foi divulgado com o intuito de realizar a predição do diâmetro do asteróide. Entretanto, foi de interesse da dupla proceder predição classificatória, e não regressiva, visto que nossa pouca experiência somente contemplou análise regressiva. Buscamos implementar algo que nunca haviamos tentado implementar.\n\nhttps://www.kaggle.com/basu369victor/prediction-of-asteroid-diameter/tasks"},{"metadata":{},"cell_type":"markdown","source":"# 1 - Inicialização do modelo"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ndata = pd.read_csv('/kaggle/input/asteroid-dataset/dataset.csv', low_memory=False)\n\npd.set_option('display.max_columns', 500)\n\nprint(f'Quantidade de linhas da matriz: {data.shape[0]} \\nQuantidade de colunas na matriz: {data.shape[1]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para reduzir o tamanho da matriz, assim como definir o escopo da predição:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data['class'].isin(['IMB', 'MCA', 'APO', 'AMO', 'TJN', 'TNO'])].reset_index(drop=True)\n\nprint(f'Quantidade de linhas da matriz: {data.shape[0]} \\nQuantidade de colunas na matriz: {data.shape[1]}')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deletando colunas de ID/strings de identificação que não são úteis para predição."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['id','spkid','full_name','name','orbit_id','equinox','pdes','prefix'],axis=1)\n\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Identificando colunas que tem muitos valores faltando, colunas com mais de 80% serão removidas pois não tem como tratar esses valores de forma razoável."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_rows = data.shape[0]\nmissing_values_columns = [];\n\nprint(\"Colunas a serem removidas: \\n\")\n\nfor column in data:\n    \n    not_na = (1 - (data[column].count() / total_rows)) * 100\n    \n    if(not_na > 80):\n        missing_values_columns.append(column)\n        print(column,': %.2f' % not_na)\n    else:\n        data = data[data[column].notna()]\n        \ndata = data.drop(missing_values_columns, axis='columns', inplace=False) \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataInfo = data.shape\n\nprint('Quantidade de Linhas: ', dataInfo[0])\nprint('Quantidade de Colunas: ', dataInfo[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 - Pré-Processamento"},{"metadata":{},"cell_type":"markdown","source":"Identificando as colunas que não estão representadas de forma númerica e vão precisar ser categorizadas para serem entendidas pelo modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorial_columns = []\nnumerical_columns = []\n\nfor column in data:\n    if(data[column].dtypes != \"float64\" and data[column].dtypes != \"int64\"):\n        categorial_columns.append(column)\n    else:\n        numerical_columns.append(column)\n\n# Removendo a coluna 'class' pois o modelo irá predizer esse valor\ncategorial_columns.remove('class')\n\nprint(\"Colunas a serem categorizadas: \", categorial_columns)\nprint(\"Colunas a serem scaladas: \", numerical_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Realização do data split, utilizando 10% para treinamento e 90% para validação. Como o dataset é desbalanceado, utilizamos o comando stratity para realizar uma amostragem estratificada proporcional."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Separando dataset de teste\n\nX=data.drop(['class'], axis=1)\ny=data['class']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.1, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definição das métricas para avaliação do desempenho dos modelos"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nfrom sklearn import metrics \n\nwarnings.filterwarnings('always')\n\ndef metricCalculation(classifier, y_test, pred, best_params):\n    \n    precision_metric = metrics.precision_score(y_test, pred, average = \"macro\")\n    recall_metric = metrics.recall_score(y_test, pred, average = \"macro\")\n    accuracy_metric = metrics.balanced_accuracy_score(y_test, pred)\n    f1_metric = metrics.f1_score(y_test, pred, labels=np.unique(pred), average = \"macro\")\n\n    return {\n        'classifier': str(classifier).split('(')[0],\n        'precision': round(precision_metric, 2),\n        'recall': round(recall_metric, 2),\n        'accuracy': round(accuracy_metric, 4),\n        'f1-score': round(f1_metric, 2)\n    }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3 - Execução Pipeline"},{"metadata":{},"cell_type":"markdown","source":"Nessa etapa, elencamos 4 modelos relevantes para comparação:\n\nDecisionTreeClassifier, que é somenteuma árvore de decisão classificatória;\n\nExtraTreeClassifier, que é similar ao RandomForest, porém possivelmente mais rápico computacionalmente e insere possivelmente mais ruído na predição;\n\nRandomForestClassifier, que consiste na utilização de várias árvores de decisão simultaneamente;\n\nXGBClassifier, que são árvores de decisão com gradiente aumentado projetadas para velocidade e desempenho.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier, DecisionTreeRegressor\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\n\nfrom xgboost import XGBClassifier\n\nfrom operator import itemgetter\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import RocCurveDisplay\n\n# Compondo os pré-processadores\n\npreprocessor = ColumnTransformer(transformers=[\n    ('scaler', MinMaxScaler(), numerical_columns),\n    ('one-hot', OneHotEncoder(sparse = False), categorial_columns)    \n])\n\n#Classifier Parameters\n\nparameters = [ \n                { \n                    'clf': [DecisionTreeClassifier()],\n                    'clf__max_depth': [None, 3, 4, 5], \n                    'clf__criterion': ['gini', 'entropy'],\n                    'clf__min_samples_split': [None, 100, 1000, 10000],\n                    'clf__max_features': [ None , \"sqrt\", \"log2\"],\n                    'clf__class_weight': [None, \"balanced\"]\n                    \n                },{ \n                    'clf': [ExtraTreeClassifier()],\n                    'clf__max_depth': [None, 3, 4, 5], \n                    'clf__criterion': ['gini', 'entropy'],\n                    'clf__min_samples_split': [None, 100, 1000, 10000],\n                    'clf__max_features': [ None , \"sqrt\", \"log2\"],\n                    'clf__class_weight': [None, \"balanced\"]\n                },{\n                    'clf': [RandomForestClassifier()],\n                    'clf__random_state': [None, 100, 100, 1000],\n                    'clf__criterion': ['gini', 'entropy']\n                }, {\n                    'clf': [XGBClassifier()]\n                }\n\n]\n\nresult=[]\nmetrics_result=[]\n\nfor params in parameters:\n\n    \n    #classifier\n    clf = params['clf'][0]\n\n    #getting arguments by\n    #popping out classifier\n    params.pop('clf')\n\n    #pipeline\n    steps = [\n                ('preprocessor', preprocessor), \n                ('clf', clf)\n    ]\n    \n    kfold = KFold(n_splits=3, shuffle=True)\n\n    grid = GridSearchCV(Pipeline(steps), param_grid=params, cv=kfold, n_jobs=-1, refit=True)\n    grid.fit(X_train, y_train)\n\n    y_pred = grid.best_estimator_.predict(X_valid)\n    \n    metrics_result.append(metricCalculation(clf, y_valid, y_pred, grid.best_params_))\n    \n    #storing result\n    result.append({\n                'grid': grid,\n                'classifier': grid.best_estimator_,\n                'best score': grid.best_score_,\n                'best params': grid.best_params_,\n                'cv': grid.cv\n    })\n\n#sorting result by best score\nbest_result = sorted(result, key=itemgetter('best score'),reverse=True)\n\n#saving best classifier\nbest_grid = best_result[0]['grid']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4 - Métricas"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_results = pd.DataFrame(metrics_result)\n\nm_results = m_results.sort_values(by=['precision',\n                                      'accuracy',\n                                      'recall',\n                                      'f1-score'\n                                     ], ascending=False)\n\nm_results[0:6]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Portanto, analisamos que os modelos convergem em acurácia, e as features são capazes de explicar com muita precisão o target."},{"metadata":{},"cell_type":"markdown","source":"# 5 - Matriz de Confusão"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix\n\nfig, axn = plt.subplots(2, 2, figsize=(30, 8))\n\nplt.subplots_adjust(top=12, bottom=10)\n\nfor i, ax in enumerate(axn.flat):\n    k = result[i]\n    \n    estimator_ = k['grid'].best_estimator_\n    \n    plot_confusion_matrix(estimator_ , X_train, y_train).plot(ax=ax)\n    ax.set_title(str(estimator_['clf']).split('(')[0] ,fontsize=12)\n    \n    plt.close()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"A matriz confusão, como esperado, apresenta praticamente exclusivamente valores na diagonal principal. Isso significa que os valores preditos foram assertivos."},{"metadata":{},"cell_type":"markdown","source":"# 6 - Curva ROC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.preprocessing import label_binarize\n\nfig, axn = plt.subplots(2, 2, figsize=(30, 8))\n\nplt.subplots_adjust(top=12, bottom=10)\n\nfor i, ax in enumerate(axn.flat):\n    k = result[i]\n    \n    estimator_ = k['grid'].best_estimator_\n    \n    y_pred_ = estimator_.predict(X_valid)\n    \n    y_pred_ = label_binarize(y_pred_, classes = estimator_.classes_)\n    y_valid_ = label_binarize(y_valid, classes = estimator_.classes_)\n    \n    fpr, tpr, _ = roc_curve(y_valid_[:,1], y_pred_[:,1])\n    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n    \n    roc_display.plot(ax = ax)\n    ax.set_title(str(estimator_['clf']).split('(')[0] ,fontsize=12)\n    \n    #plt.close()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7 - Importância das Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ = best_grid.best_estimator_\nfeature_names = pipeline_['preprocessor'].transformers_[1][1].get_feature_names(categorial_columns)\n\nfeature_names = list(feature_names)\n\nfor n in numerical_columns: \n    feature_names.append(n)\n\nfeatures_imp = []\n\n\nfor r in result:\n    \n    pipeline_ = r['grid'].best_estimator_\n     \n    if hasattr(pipeline_['clf'], 'feature_importances_'):\n        \n        \n        clf_imp = pipeline_['clf']\n        \n        f_imp = pd.DataFrame(clf_imp.feature_importances_,index=feature_names, columns = [str(clf_imp).split('(')[0]])\n        features_imp.append(f_imp)\n\ndt_features_imp = pd.concat(features_imp, axis=1).sort_values(by=['RandomForestClassifier', 'XGBClassifier'], ascending=False)\n\ndt_features_imp['DecisionTreeClassifier'] = dt_features_imp['DecisionTreeClassifier'].replace({0:np.nan})\ndt_features_imp['ExtraTreeClassifier']    = dt_features_imp['ExtraTreeClassifier'].replace({0:np.nan})\ndt_features_imp['RandomForestClassifier'] = dt_features_imp['RandomForestClassifier'].replace({0:np.nan})\ndt_features_imp['XGBClassifier']          = dt_features_imp['XGBClassifier'].replace({0:np.nan})\n\ndt_features_imp[0:30]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De acordo com a análise de feature importance, observamos que a maioria das features possui baixa relevância para o sucesso do modelo, sendo possível realizar uma redução de dimensão das features. Para isso vamos selecionar até 10 features mais importantes de cada modelo e comparar para verificarmos como o modelo funciona com um número reduzido de features."},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics_result_with_importance = []\n\nfor r in result:\n    \n    model = r['grid'].best_estimator_['clf']\n    classifier_name = str(model).split('(')[0] \n    \n    \n    tmp_features_imp = dt_features_imp[classifier_name].sort_values(ascending=False)\n    tmp_features_imp = tmp_features_imp.dropna()\n    \n    data_features_impl = []\n    \n    most_importants_features = tmp_features_imp[0:10].index\n    print('\\nFeatures', classifier_name, ':' , list(most_importants_features), end='')\n    \n    for tmp_feature in most_importants_features: \n        \n        try:\n            data_features_impl.append(data[tmp_feature])\n        except:\n            pass \n            \n    X = pd.concat(data_features_impl ,axis=1)\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0, train_size=0.1, stratify=y)\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n    y_pred = pd.DataFrame(y_pred,columns=['class'])\n\n    metrics_result_with_importance.append(metricCalculation(model, y_valid, y_pred, r['best params']))\n    \n    \nm_results = pd.DataFrame(metrics_result_with_importance)\n\nm_results = m_results.sort_values(by=['precision',\n                                      'accuracy',\n                                      'recall',\n                                      'f1-score'\n                                     ], ascending=False)\n\nm_results[0:6]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Podemos concluir, então, que 10 features explicam com precisão praticamente igual ao modelo com 34 features no caso do XGBClassifier. Essa redução de quantidade de features reduz o tempo computacional.\n\nOutro fato interessante é que utilizando comente 10% do dado para treinamento, o que dá precedente para a possibilidade de redução de linhas do dataset, com a mesma finalidade de redução de tempo computacional."},{"metadata":{},"cell_type":"markdown","source":"# 8 - Stacking"},{"metadata":{},"cell_type":"markdown","source":"Como nossos resultados anteriores obtiveram acurácia de aproximadamente 100%, vamos fazer arbitrariamente uma redução de dimensionalidade do dataset para obtermos acurácias piores. Dessa forma, poderemos comparar e avaliar o desempenho do stacking, um método ensemble que utiliza diversos modelos distintos para computar uma predição mais robusta."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ntemp = pd.concat([X,y],axis=1)\ntemp = shuffle(temp.reset_index(drop=True))\ntemp = temp[0:300]\nX = temp.drop(['class'],axis=1).reset_index(drop=True)\ny = temp['class'].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora, iremos proceder o método stacking (ensamble), a partir dos resultados dos estimadores DecisionTreeClassifier, ExtraTreeClassifier, RandomForestClassifier e XGBoostClassifier. Esses estimadores serão as features da nova predição, que será feita através do LogisticRegressor. Foi utilizado crossvalidation (5 folds) para calcular acurácia. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.classifier import StackingCVClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport warnings\nfrom sklearn import model_selection\n\nwarnings.simplefilter('ignore')\n\nclassifiers_stacking = []\nclassifiers_labels = []\n\nfor r in result:\n    clf_stck = r['grid'].best_estimator_['clf']\n    classifiers_stacking.append(clf_stck)\n    classifiers_labels.append(str(clf_stck).split('(')[0])\n\n    \nclassifiers_labels.append('Stacking Classifier')\nlr = LogisticRegression()\n\n\nsclf = StackingCVClassifier(classifiers=classifiers_stacking, meta_classifier=lr,\n                           shuffle=False, use_probas=True)\n\nprint('5-fold cross validation:\\n')\n\nfor clf, label in zip(classifiers_stacking, \n                      classifiers_labels):\n\n    scores = model_selection.cross_val_score(clf, X, y, \n                                              cv=5, scoring='balanced_accuracy')\n    \n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n          % (scores.mean(), scores.std(), label))\n                                   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De acordo com o resultado do stacking, podemos afirmar que tal ferramenta apresentou resultado igual ou maior que os modelos testados previamente. \nA utilização do stacking apresentou acurácia igual aos modelos que melhor descreveram a relação feature-target.\nStacking é um modelo que possui a desvantagem de ser mais custoso computacionalmente, mas constitui uma predição muito mais robusta para o dataset."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}