{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Welcome to this CSSA ML Workshop!**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%capture\nfrom IPython.display import Image\n\nimport os\nimport re\nimport numpy as np\nimport pandas as pd\nimport random\nimport warnings\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import collections as matcoll\nimport seaborn as sns\nimport lightgbm\n\nimport sklearn\nfrom sklearn import ensemble\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import *\nfrom sklearn.metrics import *\nfrom sklearn import model_selection\n\nfrom sklearn.metrics import roc_auc_score\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')\nmatplotlib.rcParams['figure.figsize'] = [15, 7.5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"L6_100nt = pd.read_csv('../input/L6_100nt.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Finding columns that contain data about the participant's microbiota\")\nL6_pattern = re.compile(\"k__(\\w*);p__(\\w*);c__(\\w*);o__(\\w*);f__(\\w*);g__(\\w*)$\")\nL3_pattern = re.compile(\"k__(\\w*);p__(\\w*);c__(\\w*);o__(\\w*)$\")\nL2_pattern = re.compile(\"k__(\\w*);p__(\\w*)$\")\nL6_columns = [col for col in L6_100nt.columns if L6_pattern.match(col)]\nL3_columns = [col for col in L6_100nt.columns if L3_pattern.match(col)]\nL2_columns = [col for col in L6_100nt.columns if L2_pattern.match(col)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filter_data(study):\n    \"\"\" Removes unwanted rows or modify them to limit the space of the task \"\"\"\n    study = L6_100nt[L6_100nt['STUDY'] == study]\n\n    study[\"ANTIBIOTIC_HISTORY\"] = study[\"ANTIBIOTIC_HISTORY\"].replace(\"no_data\",np.nan).replace(\"Unspecified\",np.nan).replace(\"Unknown\",np.nan)\n    study['AGE_CORRECTED'] = study['AGE_CORRECTED'].replace(\"Unspecified\",np.nan).replace(\"Unknown\",np.nan).astype(float)    \n    study = study[(study['AGE_CORRECTED'].isnull()) | (study['AGE_CORRECTED'] >= 18)]\n    \n    study['POULTRY_FREQUENCY'] = study['POULTRY_FREQUENCY'].replace(\"Occasionally (1-2 times/week)\",1).replace(\"Unspecified\",np.nan).replace(\"Unknown\",np.nan)\n    study['POULTRY_FREQUENCY'] = study['POULTRY_FREQUENCY'].replace(\"Regularly (3-5 times/week)\",1).replace(\"Rarely (less than once/week)\",0).replace(\"Never\",0).replace(\"Daily\",1)\n\n    return study","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Filtering based on the study, as many scientific studies were involved\")\nmeta_study = pd.concat([filter_data(study) for study in L6_100nt['STUDY'].unique()])\nmeta_study = meta_study[~meta_study['#SampleID'].duplicated()]\nmeta_study = meta_study.fillna(0)\n# Filtering data to only consider one source of microbiota in the participant's body \ndata = meta_study[meta_study['BODY_SITE'] == 'UBERON:feces']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data[L6_columns].var().sort_values(ascending=False).index[:600].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[\"ANTIBIOTIC_HISTORY\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(data[features].columns))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning The Data\n\nRemoving extraneous data and conforming class data to a standard pattern"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bin the survey responses as True (have taken anitbiotics) and False (have not taken anitbiotics)\nweek = data[data['ANTIBIOTIC_HISTORY'] == 'Week']\nmonth = data[data['ANTIBIOTIC_HISTORY'] == 'Month']\n\nyears = data[data['ANTIBIOTIC_HISTORY'] == 'I have not taken antibiotics in the past year.']\n\nantibiotics = pd.concat([week, month, years])\nantibiotics['ANTIBIOTIC_HISTORY'].value_counts()\n\nantibiotics['antibiotic_target'] = (antibiotics['ANTIBIOTIC_HISTORY'] == 'Month') | (antibiotics['ANTIBIOTIC_HISTORY'] == 'Week')\nantibiotics['antibiotic_target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do you see any potential issues with the number of False instances vs True instances?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n\nno_antibiotics = antibiotics[antibiotics['antibiotic_target'] == False]\nyes_antibiotics = antibiotics[antibiotics['antibiotic_target'] == True]\n\n#Implement Down Sampling:\n#https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html\n\nno_antibiotic_downsampled = resample(no_antibiotics, replace=False, n_samples = 1083)\ndata_downsampled = pd.concat([no_antibiotic_downsampled, yes_antibiotics])\n\ndata_downsampled['antibiotic_target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ndata[features].head()\ntarget = data_downsampled['antibiotic_target'].reset_index(drop=True)\ntarget.head()\n\npca_antibiotics = PCA(n_components=2)\n\nprincipalComponents_antibiotics = pca_antibiotics.fit_transform(data_downsampled[features])\n\npca_antibiotics_df = pd.DataFrame(data=principalComponents_antibiotics, columns = ['principal component 1', 'principal component 2'])\n\npca_antibiotics_df = pd.concat([pca_antibiotics_df, target], axis = 1)\n\npca_antibiotics_df.head()\n\npc1 = pca_antibiotics_df['principal component 1'].tolist()\npc2 = pca_antibiotics_df['principal component 2'].tolist()\n\ntarget = pca_antibiotics_df[\"antibiotic_target\"].tolist()\nfig = plt.figure()\nax = fig.add_subplot(111 )\nax.scatter(pc1, pc2,  c=target, cmap=\"Accent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training A Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data_downsampled[features], data_downsampled['antibiotic_target'], random_state=1, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#Train a decision tree model on the dataset:\n#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n\ntree = sklearn.tree.DecisionTreeClassifier()\ntrained = tree.fit(x_train, y_train)\npredictions = tree.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use a confusion matrix to evaluate the perfrormance\ncm = confusion_matrix(y_test, predictions)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nprint(roc_auc_score(y_test, predictions))\npd.DataFrame(data=cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt\nimport matplotlib.pyplot as plt\n\nprobs = tree.predict_proba(x_test)\n\nskplt.metrics.plot_roc_curve(y_test, probs)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Identifying People who have ate Chicken with their Microbiota"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['POULTRY_FREQUENCY'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data['SUBSET_ANTIBIOTIC_HISTORY'] | (data['ANTIBIOTIC_HISTORY'] == 'Year') | (data['ANTIBIOTIC_HISTORY'] == '6 months')]\n\ndata = data.groupby([\"HOST_SUBJECT_ID\"]).first()\ndata['POULTRY_FREQUENCY'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data[features], data[\"POULTRY_FREQUENCY\"], test_size=0.3)\ny_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a model with K Nearest Neighbors: initializing it, training it, and predicting classes\nmodel = sklearn.neighbors.KNeighborsClassifier()\n\ntrained_model = model.fit(x_train, y_train)\npredictions = model.predict(x_test)\ncm = confusion_matrix(y_test, predictions)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nprint(roc_auc_score(y_test, predictions))\npd.DataFrame(data=cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate using K Fold\n\nseed = 7\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\nresults = model_selection.cross_val_score(trained_model, x_train, y_train, cv=kfold)\nprint(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a model with Random Forest: initializing it, training it, and predicting classes\nmodel = ensemble.RandomForestClassifier(n_estimators=200)\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)\n\npredictions = model.predict(x_test)\ncm = confusion_matrix(y_test, predictions)\nqcm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nprint(roc_auc_score(y_test, predictions))\npd.DataFrame(data=cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 7\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\nresults = model_selection.cross_val_score(model, x_train, y_train, cv=kfold)\nprint(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bootstrapping the training data to get better results \nfrom sklearn.metrics import accuracy_score\nfrom matplotlib import pyplot\n\nn_iterations = 10\nnumber_rows = len(data.index)\nlist_rows = list(range(number_rows))\n\nstats = list()\nfor i in range(n_iterations):\n    train_set_indices = resample(list_rows)\n    #Getting out of bag samples\n    test_set_indices = [x for x in list_rows if x not in train_set_indices]\n    \n    x_train = data[features].iloc[train_set_indices,:]\n    y_train = data.iloc[train_set_indices,:]['POULTRY_FREQUENCY']\n    x_test = data[features].iloc[test_set_indices,:]\n    y_test = data.iloc[test_set_indices,:]['POULTRY_FREQUENCY']\n\n    model = ensemble.RandomForestClassifier(n_estimators=200)\n    model.fit(x_train, y_train)\n    # evaluate model\n    predictions = model.predict(x_test)\n    score = accuracy_score(y_test, predictions)\n    stats.append(score)\n    \n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.95\np = ((1.0-alpha)/2.0) * 100\nlower = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)/2.0)) * 100\nupper = min(1.0, np.percentile(stats, p))\nprint('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Curse of Dimensionality Example"},{"metadata":{"trusted":true},"cell_type":"code","source":"dimensions = 300\nn_points = 1000\n\ncursed_data = np.random.normal(0, 1, size=(n_points, dimensions))\ncursed_label = cursed_data[:,0] > 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(cursed_data[:,0], y=[0]*(n_points), c=cursed_label, cmap=\"Accent\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(cursed_data[:,0], cursed_data[:,1], c=cursed_label, cmap=\"Accent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\nax.scatter(cursed_data[:,0], cursed_data[:,2], cursed_data[:,1], c=cursed_label, cmap=\"Accent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cursed_features = range(0,100)\ncursed_df = pd.DataFrame(cursed_data)\ncursed_df[\"target\"] = cursed_label\nx_train, x_test, y_train, y_test = train_test_split(cursed_df[cursed_features], cursed_df[\"target\"], test_size=0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sklearn.neighbors.KNeighborsClassifier()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sklearn.tree.DecisionTreeClassifier()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}