{"cells":[{"metadata":{},"cell_type":"markdown","source":"# An analysis of the netflix dataset","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #for plotting of figures \nfrom matplotlib.dates import DateFormatter #for date fromatting on plots \nfrom datetime import datetime\n\nimport plotly.graph_objects as go\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# **EDA of the Netflix Dataset **","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, let's Look for some big picture patterns.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#first we read in the dataset\nnetflix=pd.read_csv('/kaggle/input/netflix-shows/netflix_titles.csv')\nprint(netflix.shape)\nnetflix.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First thing we shall observe is the proportion of shows to movies.   ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's first look at the proprotion of movies vs tv shows \nlabels=list(netflix['type'].unique())\nvalues=pd.DataFrame(netflix['type'].value_counts())\n\n#plot the pie chart \nfig1, ax1 = plt.subplots()\nexplode = (0, 0.1)\nax1.pie(values['type'],explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.title('Proportion of Movies to Tv-shows on Netflix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like through the years, there are in total more movies as compared to TV-Shows. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next, let's observe which countries has the most number of tv-shows and movies combined in their library.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#want to see where majority of movie and tv shows are shown \n\n#First we pre process the column and make a list for each\nfor i in range (netflix.shape[0]):\n    netflix['country'][i]=[x.strip() for x in str(netflix['country'][i]).split(\",\")]\n    \n#next create a dictionary of countries and count of countries \ncountry_data=netflix['country']\ncount_country={}\nfor i in range (len(country_data)):\n    for j in country_data[i]:\n                if j in count_country:\n                    count_country[j]+=1\n                else:\n                    count_country[j]=1\n    \n  \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we plot the top 10 countries \ncount_country_final=pd.DataFrame(list(count_country.items()),columns = ['country','count']) \ncount_country_final=count_country_final.sort_values(by='count',ascending=False)\n#remove nan\nindexNames = count_country_final[ count_country_final['country'] == 'nan' ].index\n \n# Delete these row indexes from dataFrame\ncount_country_final.drop(indexNames , inplace=True)\n\n\n#for plotting horizontal barchart\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\ncountry = count_country_final['country'][:10]\nvalue = count_country_final['count'][:10]\nax.barh(country,value)\n\nplt.title('Top 10 countries having the most number of tv-shows and movies combined')\nplt.gca().invert_yaxis()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"USA has substantially the most number of programmes, probably due to the initial interest from the early years in the US as compared to more countries that started having a growing interest in netflix later on in the years, such as India. This then opens up the question of how the number of shows and movies have increased over the years cumulatively, to understand when the demand of netflix rose in certain countries. Let's use India as an example.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will create a function for this, so that this time analysis of any country can be done. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def country_show_over_time(country):\n\n    #first we filter out the country \n    index=[country in netflix['country'][i] for i in range(netflix.shape[0])]\n    target=netflix.iloc[index]\n\n\n    # now we need to find the cumulative count of shows over time. First we sort by date\n    target['date_added']=pd.to_datetime(target['date_added'])\n    target=target.sort_values(by='date_added')\n\n    #create a column for cumulative numbers \n    target['cumsum']=1\n    target['cumsum']=target['cumsum'].cumsum()\n    \n    #and finally plot the reuslts out \n    \n    \n    fig,ax=plt.subplots()\n    \n    ax.plot(target['date_added'],target['cumsum'])\n    \n    myFmt = DateFormatter(\"%m-%y\")\n    ax.xaxis.set_major_formatter(myFmt) \n    \n    plt.ylabel('Number of shows')\n    plt.xlabel('Time')\n    plt.title('Shows Over time in '+country)\n    \n    \n    \n    \n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we plot India's number of shows and movies over time \ncountry_show_over_time(\"India\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"India's seemed to rise tremendously betwwen 2017 and 2018 shortly after being introduced in the country. Now this trend would probably be different in other countries, and it would be interesting to find more patterns. Having said that, what if we want to recommend shows to people watching some of these shows, with other shows that netflix has to offer? Next i will work on a simple recommender system for that to happen. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Recommender system of the netflix dataset using Content-based Recommender System. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will use the python built in tfidf vectorizer and a linear kernel (cosine similarity). Here, we are only using the textual description of the movies to make a reco.  \n\nThis can easily be done for just movies or just tv shows, but for the purpose of this notebook, i will incorportate both. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the necessary modules \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create the vectorizer and form the tfidf matrix \ntf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\ntfidf_matrix = tf.fit_transform(netflix['description'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#built the cosine similarity function to get the recommendations out  \ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix) \nresults = {}\nfor idx, row in netflix.iterrows():\n   similar_indices = cosine_similarities[idx].argsort()[:-100:-1] \n   similar_items = [(cosine_similarities[idx][i], netflix['show_id'][i]) for i in similar_indices] \n   results[row['show_id']] = similar_items[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we create a function which will pull out the necessary recommendations as computed from the above model \n#def item(title):  \n # return netflix.loc[netflix['title'] == title]['title'].tolist()[0].split(' - ')[0] \n\n#to recommend the top num movies or tv shows \ndef recommend(title, num):\n    print(\"Recommending \" + str(num) + \" products similar to \" + title + \"...\")   \n    print(\"-------\")\n    item_id=int(netflix.loc[netflix['title'] == title]['show_id'])\n    recs = results[item_id][:num]   \n    for rec in recs: \n       print(\"Recommended: \" + str(netflix.loc[netflix['show_id']==rec[1]]['title']) + \" (score:\" +      str(rec[0]) + \")\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recommend('Transformers Prime',5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Closing thoughts\nFor this example i did a simple EDA on the netflix dataset, but more particularly did one per ocuntry. This simple recommender system can be suited for individual countries as well, and that may yield different results too. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}