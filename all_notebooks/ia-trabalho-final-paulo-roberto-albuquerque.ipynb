{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Trabalho Final de Estágio Docente\n## Estagiário: Douglas Macedo Sgrott\n## Aluno: Paulo Roberto Albuquerque\n## Data de entrega: 23/06/2021 (quarta-feira)\n## O trabalho está organizado em partes:\n - ### **Dataset: Onde você irá limpar e pre processar o dataset. Atribua a versão final do dataset em um dataframe chamado df.**\n - Separação dos dados: Aqui os dados são normalizados e divididos em Treino/Validação. Não precisa modificar o código.\n - ### **Arquitetura da Rede Neural: Onde você vai definir a arquitetura da rede neural.**\n - ### **Parâmetros de otimização da Rede Neural: Onde você vai definir outros parâmetros da rede neural.**\n - Visualização dos resultados: Onde os resultados são obtidos\n - Exemplos: Servir como exemplo de análise, data cleaning e pré-processamento.\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# importing stuff\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# a lot of stuff\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Z-score / outliers stuff\nfrom scipy import stats\n\n# Rede Neural stuff\nfrom tensorflow.keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.utils import plot_model\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-24T01:55:45.223613Z","iopub.execute_input":"2021-06-24T01:55:45.224038Z","iopub.status.idle":"2021-06-24T01:55:45.235115Z","shell.execute_reply.started":"2021-06-24T01:55:45.224003Z","shell.execute_reply":"2021-06-24T01:55:45.234024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/aula-2-ia-dataset/CasasParaAlugar.csv', index_col=0)\n\n## Colunas Vazias Parte 1 (Antes da remoção dos Outliers):\n#   Rooms para 1\ndf['rooms'].fillna(value=1, inplace=True)\n#   Bathroom para 1\ndf['bathroom'].fillna(value=1, inplace=True)\n#   Parking Spaces para 0\ndf['parking spaces'].fillna(value=0, inplace=True)\n#   Floor para 0\ndf['floor'].fillna(value=0, inplace=True)\n#   Animal para \"acept\" discreto = 1\ndf['animal'].fillna(value=1, inplace=True)\n#   Furniture para \"not furnished\" discreto = 0\ndf['furniture'].fillna(value=0, inplace=True)\n#   City para a moda\ndf['city'].fillna(value=df['city'].mode(), inplace=True)\n\n## Substituição:\n#   Floor subst \"-\" para 0 e depois string para int\ndf['floor'].replace(to_replace='-', value=0, inplace=True)\ndf['floor'] = pd.to_numeric(df['floor'])\n#   Animal subst strings para valor discreto\ndf['animal'].replace(to_replace='acept', value=1, inplace=True)\ndf['animal'].replace(to_replace='not acept', value=0, inplace=True)\n#   Furniture subst strings para valor discreto\ndf['furniture'].replace(to_replace='furnished', value=1, inplace=True)\ndf['furniture'].replace(to_replace='not furnished', value=0, inplace=True)\n#   City para valores discretos\ndf.loc[df['city'] == 'Belo Horizonte', 'city'] = 1\ndf.loc[df['city'] == 'São Paulo', 'city'] = 2\ndf.loc[df['city'] == 'Porto Alegre', 'city'] = 3\ndf.loc[df['city'] == 'Rio de Janeiro', 'city'] = 4\ndf.loc[df['city'] == 'Campinas', 'city'] = 5\ndf.dropna(subset=['city'], inplace=True)\ndf['city'] = pd.to_numeric(df['city'])\n\n## Ouliers:\n#   Floor removemos andares maiores que 60\ndf.drop(df.loc[df['floor'] > 60].index, inplace=True)\n#   Removemos outliers das outras features usando os respectivos valores para Z\ncolumns = ['area', 'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)', 'total (R$)']\nzs =      [1.0   , 0.2       , 4                 , 0.3                , 5                    , 1           ]\n\nfig, axes = plt.subplots(nrows=len(columns), ncols=2, figsize=(15,30))\nfor i, col in enumerate(columns):\n    axes[i][0].hist(df[col], bins=50)\n    \n    mask = np.abs(stats.zscore(df[col].dropna())) < zs[i] # Usando cada z para cada coluna\n    dado_filtrado = df[col].dropna()[mask]\n    df[col] = df[col].dropna()[mask] # Aplicamos na df a remoção\n    \n    axes[i][1].hist(dado_filtrado)\n    ymax = axes[i][0].get_yticks()[-1]\n    axes[i][0].vlines(x=max(dado_filtrado), ymin=0, ymax=ymax, color=\"red\")\n    axes[i][0].set_title(\"{} - sem filtro de outliers\".format(col))\n    axes[i][1].set_title(\"{} - com filtro de outliers\".format(col))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T01:55:45.278603Z","iopub.execute_input":"2021-06-24T01:55:45.27894Z","iopub.status.idle":"2021-06-24T01:55:47.736227Z","shell.execute_reply.started":"2021-06-24T01:55:45.27891Z","shell.execute_reply":"2021-06-24T01:55:47.735241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Colunas Vazias Parte 2:\n#   Se ambos Hoa e Rent estiverem faltando, apaga a linha\ndf.dropna(subset=['hoa (R$)', 'rent amount (R$)'], how='all', inplace=True)\n#   Hoa = proporção média (hoa/rent) multiplicado pelo rent daquela linha\nmean_hoa_rent = df['hoa (R$)'].mean() / df['rent amount (R$)'].mean()\ndf['hoa (R$)'] = df.apply(\n    lambda row: row['rent amount (R$)'] * mean_hoa_rent if np.isnan(row['hoa (R$)']) else row['hoa (R$)'],\n    axis=1\n)\n#   Rent = proporção média (hoa/rent) dividido pelo hoa daquela linha\ndf['rent amount (R$)'] = df.apply(\n    lambda row: row['hoa (R$)'] / mean_hoa_rent if np.isnan(row['rent amount (R$)']) else row['rent amount (R$)'],\n    axis=1\n)\n#   Tax para média\ndf['property tax (R$)'].fillna(value=df['property tax (R$)'].mean(), inplace=True)\n#   Insurance média\ndf['fire insurance (R$)'].fillna(value=df['fire insurance (R$)'].mean(), inplace=True)\n#   Total soma dos outros valores\ndf['total (R$)'] = df.apply(\n    lambda row: row['hoa (R$)'] + row['rent amount (R$)'] + row['property tax (R$)'] + row['fire insurance (R$)'],\n    axis=1\n)\n#   Area apaga linha\ndf.dropna(subset=['area'], inplace=True)\n\n\n# df.drop(columns='area', inplace=True)\n# df.drop(columns='parking spaces', inplace=True)\n# df.drop(columns='bathroom', inplace=True)\n# df.drop(columns='rooms', inplace=True)\n# df.drop(columns='floor', inplace=True)\n# df.drop(columns='animal', inplace=True)\n# df.drop(columns='furniture', inplace=True)\n\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T01:55:47.737628Z","iopub.execute_input":"2021-06-24T01:55:47.73791Z","iopub.status.idle":"2021-06-24T01:55:48.486322Z","shell.execute_reply.started":"2021-06-24T01:55:47.737883Z","shell.execute_reply":"2021-06-24T01:55:48.485233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gráfico da distribuição dos valores","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df[['area', 'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)', 'total (R$)']])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T01:55:48.488109Z","iopub.execute_input":"2021-06-24T01:55:48.488398Z","iopub.status.idle":"2021-06-24T01:55:57.895798Z","shell.execute_reply.started":"2021-06-24T01:55:48.48837Z","shell.execute_reply":"2021-06-24T01:55:57.894753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Separação dos dados","metadata":{}},{"cell_type":"code","source":"# Normalizamos os dados de df em uma escala de [0, 1]\n# Estou fazendo isto aqui pois temos que \"desnormalizar\" na hora de gerar os gráficos de R²\ncolumn_names = df.columns\nscaler = MinMaxScaler()\nscaler.fit(df)\ndf = scaler.transform(df)\ndf = pd.DataFrame(df)\ndf.columns = column_names\n\n# Pegamos o dataset df e separamos em x (entrada) e y (saida), numa separação 70% treino e 30% validação\ninput_dim = df.shape[1] - 1\nx = df.drop(columns='total (R$)')\ny = df['total (R$)']\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T01:55:57.897261Z","iopub.execute_input":"2021-06-24T01:55:57.897695Z","iopub.status.idle":"2021-06-24T01:55:57.913348Z","shell.execute_reply.started":"2021-06-24T01:55:57.897648Z","shell.execute_reply":"2021-06-24T01:55:57.912574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Arquitetura da Rede Neural\n#### Criei um código bem simples pra permitir criar diferentes redes neurais modificando apenas algumas variáveis (EM CAPSLOCK),\n#### Mas se quiser criar sua própria arquitetura mais customizada, fique a vontade","metadata":{}},{"cell_type":"code","source":"NEURONIOS_CAMADA_INICIAL = 20\n\n# Número de camadas intermediárias e neurônios. Tamanho do array são os números de camadas, elementos do array são números de neurônios.\n# Ex: [30, 15] = 2 camadas intermediárias com 30 neurônios na primeira e 15 neurônios na segunda\n# Ex: [] = Nenhuma camada intermediária\n# Ex: [10, 10, 10, 10, 50] = 5 camadas intermediárias, com 10 neurônios nas 4 primeiras e 50 neurônios na última\nNEURONIOS_CAMADAS_INTERMEDIARIAS = [30, 30]\n\n# Usar dropout: True para usar, False para não usar\nUSAR_DROPOUT = False\n\n# Porcentagem de Dropout: valor entre 0 e 1\nDROPOUT_VALUE = 0.005\n\n# Regularizador: None = Não usar regularizador, 'l1' = Reg L1, 'l2' = Reg L2\nTIPO_REGULARIZADOR = 'l1'\n\n# Função de ativação: 'relu', 'tanh', 'sigmoid', 'softmax', 'softplus', 'elu'\nFN_ATIVACAO = 'relu'\n\n# #####################################################################################\n# Definição da ARQUITETURA da Rede Neural\nmodel = Sequential()\n\n# Primeira camada da RNA (input_dim entradas)\nmodel.add(Dense(units=NEURONIOS_CAMADA_INICIAL, input_dim=input_dim, activation=FN_ATIVACAO, kernel_regularizer=TIPO_REGULARIZADOR))\n# Camadas intermediárias\nfor UNITS in NEURONIOS_CAMADAS_INTERMEDIARIAS:\n    model.add(Dense(units=UNITS, activation=FN_ATIVACAO, kernel_regularizer=TIPO_REGULARIZADOR))\n    if USAR_DROPOUT:\n        model.add(Dropout(DROPOUT_VALUE, input_shape=(120,)))\n# Última camada da RNA (1 saída)\nmodel.add(Dense(units=1, activation=FN_ATIVACAO))\n\n\n# \"Doug, mas que código tosco!\" Também acho... Caso você queira criar sua própria arquitetura\n# sem usar os parâmetros acima, é bem simples. Segue abaixo um exemplo meio doideira:\n# model = Sequential()\n# model.add(Dense(units=30, input_dim=input_dim, activation='relu', kernel_regularizer='l1'))\n# model.add(Dropout(0.4, input_shape=(30,)))\n# model.add(Dense(units=20, activation='tanh', kernel_regularizer='l2'))\n# model.add(Dense(units=20, activation='relu', kernel_regularizer=None))\n# model.add(Dense(units=1, activation='relu'))\n\nplot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T01:55:57.914489Z","iopub.execute_input":"2021-06-24T01:55:57.91489Z","iopub.status.idle":"2021-06-24T01:55:58.091277Z","shell.execute_reply.started":"2021-06-24T01:55:57.914855Z","shell.execute_reply":"2021-06-24T01:55:58.090247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parâmetros de otimização da Rede Neural\n#### Pode alterar os valores das variáveis que estão EM CAPSLOCK","metadata":{}},{"cell_type":"code","source":"CALLBACKS = [] # Definição dos callbacks a serem utilizados. Isso aqui é opcional, mas pode ajudar: https://keras.io/api/callbacks/early_stopping/\nLOSS = 'mean_absolute_error' # 'mean_absolute_error', 'mean_squared_error'\nBATCH_SIZE = 150\nEPOCHS = 50\nOPTIMIZER = 'adam' # 'adam' é o mais utilizado. Caso prefira outro, como 'sgd', boa sorte!\n\n# Compilação do modelo + Definição da Função de Loss e do Otimizador\nmodel.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=LOSS)\n\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=CALLBACKS,\n    validation_data=(x_valid, y_valid),\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T01:55:58.092868Z","iopub.execute_input":"2021-06-24T01:55:58.093366Z","iopub.status.idle":"2021-06-24T01:56:05.146096Z","shell.execute_reply.started":"2021-06-24T01:55:58.093327Z","shell.execute_reply":"2021-06-24T01:56:05.145138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualização dos resultados","metadata":{}},{"cell_type":"code","source":"\ndf_valid_scaled = np.column_stack((x_valid, y_valid))\ndf_valid = scaler.inverse_transform(df_valid_scaled)\ny_true = y_valid\n\n\ny_pred = model.predict(x_valid)\npred_df = pd.concat([pd.DataFrame(x_valid).reset_index(drop=True), pd.DataFrame(y_pred)], axis=1)\npred_df = scaler.inverse_transform(pred_df)\npred_df = pd.DataFrame(pred_df)\npred_df.columns = df.columns\npred_df\n\nr2 = r2_score(y_true, y_pred)\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\naxes[0].plot(history.history['loss'])\naxes[0].plot(history.history['val_loss'])\naxes[0].set_title('model loss | \"Quantidade de dados e colunas usadas: {}'.format(df.shape))\naxes[0].set_ylabel('loss')\naxes[0].set_xlabel('epoch')\naxes[0].legend(['train', 'val'], loc='upper left')\n\naxes[1].scatter(x=df_valid[:, -1], y=pred_df['total (R$)'])\n# axes[0].plot(history.history['val_loss'])\naxes[1].set_title('R² = {}'.format(r2))\naxes[1].set_ylabel('y_pred')\naxes[1].set_xlabel('y_true')\n\nprint(\"Quantidade de dados e colunas usadas: {}\".format(df.shape))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T01:56:05.147708Z","iopub.execute_input":"2021-06-24T01:56:05.148003Z","iopub.status.idle":"2021-06-24T01:56:05.618898Z","shell.execute_reply.started":"2021-06-24T01:56:05.147968Z","shell.execute_reply":"2021-06-24T01:56:05.617751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ----------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# -----------------------------------------------------","metadata":{}}]}