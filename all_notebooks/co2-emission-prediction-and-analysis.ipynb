{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#importing data visualization and manipulation libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n#importing machine learning libraries\n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing dataset\n\ndf = pd.read_csv(\"/kaggle/input/co2-emission-by-vehicles/CO2 Emissions_Canada.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for null values, didn't expect any\n\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I chose to rename this column to something easier to type as it is used very frequently \n\ndf.rename(columns={'CO2 Emissions(g/km)' : 'CO2_emission'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.drop('Fuel Consumption Comb (mpg)', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.rename(columns={'Fuel Consumption Comb (L/100 km)' : 'Fuel_Cons_comb_(l/100km)'}, inplace=True)\ndf2.rename(columns={'Fuel Consumption Hwy (L/100 km)' : 'Fuel_Cons_hwy_(l/100km)'}, inplace=True)\ndf2.rename(columns={'Fuel Consumption City (L/100 km)' : 'Fuel_Cons_city_(l/100km)'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.rename(columns={'Fuel Type' : 'Fuel_type'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#updated dataset\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting to know the dataset a little more in the next few steps\n\ndf['Fuel Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Transmission'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#discovering correlation\n\ndf.corr()['CO2_emission'].sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#heatmap for a better understanding of correlated values\n\nplt.figure(figsize = (8,6))\ncorr = df.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap = 'Blues', square = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I have a habit of using pairplot function of seaborn to see how each individual graph looks like\n\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Some visualizations to show our understanding of the dataset\n\nmkI = df['Make'].value_counts().index\nmkV = df['Make'].value_counts().values\nplt.figure(figsize = (10,8))\nsns.barplot(mkI,mkV)\nplt.xticks(rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkI = df['Vehicle Class'].value_counts().index\nmkV = df['Vehicle Class'].value_counts().values\nplt.figure(figsize = (10,8))\nsns.barplot(mkV,mkI, orient = 'h', palette='Spectral')\nplt.xticks(rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this boxplot shows us that Vans typically emit more CO2 when compared to other vehicle classes\n\nplt.figure(figsize = (10,8))\nsns.boxplot(x=\"Vehicle Class\", y=\"CO2_emission\", data=df)\nplt.xticks(rotation = 'vertical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['Fuel Consumption City (L/100 km)'], color = \"red\")\nplt.show()\nsns.boxplot(df['Fuel Consumption Hwy (L/100 km)'])\nplt.show()\nsns.boxplot(df['Fuel Consumption Comb (L/100 km)'], color = 'green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,8))\nsns.boxplot(x = 'Fuel Type' , y = 'CO2_emission', data = df)\nplt.xticks([0,1,2,3,4],['Premium Gasoline','Diesel','Regular Gasoline','Ethanol','Natural Gas'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,8))\nsns.catplot(x = 'Cylinders' , y = 'CO2_emission', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ethanol typically is the most efficient fuel type \n\nplt.figure(figsize = (10,8))\nsns.boxplot(y = 'Fuel Consumption Comb (mpg)', x = 'Fuel Type', data = df, palette = 'muted')\nplt.xticks([0,1,2,3,4],['Premium Gasoline','Diesel','Regular Gasoline','Ethanol','Natural Gas'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,8))\nsns.distplot(df['Fuel Consumption Comb (mpg)'], bins = 10, color = 'purple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.drop('Make', axis = 1, inplace = True)\ndf2.drop('Model', axis = 1, inplace = True)\ndf2.drop('Vehicle Class', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nencode = LabelEncoder()\n\nencode.fit(df2.Fuel_type.drop_duplicates()) \ndf2.Fuel_type = encode.transform(df2.Fuel_type)\n\nencode.fit(df2.Transmission.drop_duplicates())\ndf2.Transmission = encode.transform(df2.Transmission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#assigning dependent and independent variables\n#can be used with any column across the dataset provided hyperparameters are adjusted accordingly\n\nx = df2.iloc[:, :-1].values\ny = df2.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting and reshaping data into testing and training sets\n\nxTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 0)\n\n# xTrain= xTrain.reshape(-1, 1)\n# yTrain= yTrain.reshape(-1, 1)\n# xTest = xTest.reshape(-1, 1)\n# yTest = yTest.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear regression model achieving 85% accuracy\n#at the end of the kernel I attempted to create and use my own linear regression model to find out coefficient and intercept without using scikit learn\n\nreg = LinearRegression()\nreg.fit(xTrain, yTrain)\nregYpred = reg.predict(xTest)\nprint(reg.score(xTest,yTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I printed the coefficient and the intercept here to compare my model built from scratch against the imported scikit learn model\n\nprint('regression coefficient', reg.coef_, 'intercept', reg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, figsize=(10, 8), sharex=True)\n\nsns.stripplot(y = yTest.flatten(), color = 'darkmagenta', alpha = 0.7, label = 'Test Data')\nsns.stripplot(y = regYpred.flatten(), color = 'lawngreen', alpha = 0.7, label = 'Train Data')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I used these histograms to show Predicted values vs. Actual values in all three models\n\nsns.distplot(regYpred, bins = 20, color = 'red')\nplt.title = 'Predicted values'\nplt.show()\nsns.distplot(yTest, bins = 20)\nplt.title = 'Actual values'\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Regression line showing best fit\n\nsns.regplot(x = 'Fuel Consumption Comb (L/100 km)', y = 'CO2_emission', data  = df, color = 'blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree model got us a higher accuracy at 88%\n\nfrom sklearn.tree import DecisionTreeRegressor\ndtr = DecisionTreeRegressor(random_state = 0)\ndtr.fit(xTrain, yTrain)\ndtrYpred = dtr.predict(xTest)\ndtrScore = r2_score(yTest,dtrYpred)\nprint('Score: %.3f' % dtrScore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, figsize=(10, 8), sharex=True)\n\nsns.stripplot(y = yTest.flatten(), color = 'darkmagenta', alpha = 0.7, label = 'Test Data')\nsns.stripplot(y = dtrYpred.flatten(), color = 'lawngreen', alpha = 0.7, label = 'Train Data')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dtrYpred, bins = 20, color = 'red')\nplt.show()\nsns.distplot(yTest, bins = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Regressor had the highest accuracy standing at 89%\n#I used a for loop for the n estimators to see which yielded the highest accuracy, it landed at 20\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(n_estimators = 20, random_state = 0)\nrfr.fit(xTrain, yTrain)\nrfrYpred = rfr.predict(xTest)\nrfrScore = r2_score(yTest,rfrYpred)\nprint('Score: %.3f' % rfrScore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, figsize=(10, 8), sharex=True)\n\nsns.stripplot(y = yTest.flatten(), color = 'darkmagenta', alpha = 0.7, label = 'Test Data')\nsns.stripplot(y = regYpred.flatten(), color = 'lawngreen', alpha = 0.7, label = 'Train Data')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(rfrYpred, bins = 20, color = 'red')\nplt.show()\nsns.distplot(yTest, bins = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is my attempt to build my own linear regression model from scratch to calculate coefficient and slope of the regression line"},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating mean of x and y values\n\nX,Y = xTrain,yTrain\nxMean = np.mean(X)\nyMean = np.mean(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating variance and covariance\n\ncovar = 0\nvar = 0\nfor i in range (len(X)):\n    covar += (X[i] - xMean) * (Y[i] - yMean)\n    var += (X[i]-xMean) ** 2      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#computing coefficient and intercepts based on previous calculations\n\ncoeff = covar/var\nintercept = yMean - (coeff * xMean)\n\nprint('intercept is',intercept, 'coefficient is', coeff)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This was my first attempt to build a linear regression model from scratch. Any and all critiques welcomed!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}