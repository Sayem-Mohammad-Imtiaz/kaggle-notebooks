{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom itertools import combinations\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/bakerybasket/bakeryBasket.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/bakerybasket/bakeryBasket.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['I1'],dataset['I2'],dataset['I3'],dataset['I4'] = np.nan,np.nan,np.nan,np.nan\nfor r in range(dataset.shape[0]):\n    l = dataset.iloc[r,0].split(',')\n    n = len(l)\n    for i in range(1,n+1):\n        dataset.iloc[r,i] = l[i-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#intializing minimum support\nmin_sup,records = 1,[]\nfor i in range(0,dataset.shape[0]):\n    records.append([str(dataset.values[i,j]) for j in range(1,len(dataset.columns)) if str(dataset.values[i,j]) != 'nan'])\nitemlist = sorted([item for sublist in records for item in sublist if item != np.nan])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Frequent itemset when(k=1)\ndef freq_itm1(itemlist,min_sup):\n    c1 = {i: itemlist.count(i) for i in itemlist}\n    k1= {}\n    for key,val in c1.items():\n        if val >= min_sup:\n            k1[key] = val\n    return c1,k1\n\nc1,k1= freq_itm1(itemlist,min_sup)\nfreq_item = pd.DataFrame(k1,index=['sup_count']).T\n\nfreq_item.sort_values(by=['sup_count'],inplace=True,ascending=False)\n\nfreq_item","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#frequent itemset rule of pairing (k=2)\ndef check_freq(current,previous,n):\n    if n > 1:\n        subsets = list(combinations(current,n))\n    else:\n        subsets = current\n    for item in subsets:\n        if not item in previous:\n            return False\n        else:\n            return True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub_list(item1,item2):\n    return set(item1) <= set(item2)\n\ndef freq_itm2(k1,records,min_sup):\n    k1 = sorted(list(k1.keys()))\n    L1 = list(combinations(k1,2))\n    c2,k2 = {},{}\n    for it1 in L1:\n        count = 0\n        for it2 in records:\n            if sub_list(it1,it2):\n                count += 1\n        c2[it1] = count\n    for key,val in c2.items():\n        if val >= min_sup:\n            if check_freq(key,k1,1):\n                k2[key] = val\n    return c2,k2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c2,k2 = freq_itm2(k1,records,min_sup)\nk2 = {key: value for key,value in k2.items() if value != 0}\nfreq_item2 = pd.DataFrame(k2,index=['sup_count']).T\nfreq_item2.sort_values(by=['sup_count'],inplace=True,ascending=False)\nfreq_item2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def freq_itm3(k2,records,min_sup):\n    k2 = list(k2.keys())\n    L2 = sorted(list(set([item for temp in k2 for item in temp])))\n    L2 = list(combinations(L2,3))\n    c3,k3 = {},{}\n    for it1 in L2:\n        count = 0\n        for it2 in records:\n            if sub_list(it1,it2):\n                count += 1\n        c3[it1] = count\n    for key,val in c3.items():\n        if val >= min_sup:\n            if check_freq(key,k2,2):\n                k3[key] = val\n    return c3,k3\nc3,k3 = freq_itm3(k2,records,min_sup)\nk3 = {key: value for key,value in k3.items() if value != 0}\nfreq_item3= pd.DataFrame(k3,index=['sup_count']).T\nfreq_item3.sort_values(by=['sup_count'],inplace=True,ascending=False)\nfreq_item3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def freq_itm4(k3,records,min_sup):\n    k3 = list(k3.keys())\n    L3 = sorted(list(set([item for temp in k3 for item in temp])))\n    L3 = list(combinations(L3,4))\n    c4,k4 = {},{}\n    for it1 in L3:\n        count = 0\n        for it2 in records:\n            if sub_list(it1,it2):\n                count += 1\n        c4[it1] = count\n        for key,val in c4.items():\n            if val >= min_sup:\n                if check_freq(key,k3,3):\n                    k4[key] = val\n    return c4,k4\n\n# Test run\nc4,k4 = freq_itm4(k3,records,min_sup)\nk4 = {key: value for key,value in k4.items() if value != 0}\nfreq_item4 = pd.DataFrame(k4,index=['sup_count']).T\nfreq_item4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items = {**k1,**k2,**k3,**k4}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assc_sets = []\nfor it1 in list(k3.keys()):\n    assc_subset = list(combinations(it1,2))\n    assc_sets.append(assc_subset)\n\nmin_conf = 60\ndef sup_calc(it,items):\n    return items[it]\n# Calculating confidence\nk3_assc = list(k3.keys())\nselected_assc = []\nfor i in range(len(k3_assc)):\n    for it1 in assc_sets[i]:\n        denom = it1\n        d = list(denom)\n        num = set(k3_assc[i]) - set(it1)\n        n = list(num)\n        confidence = ((sup_calc(k3_assc[i],items))/(sup_calc(it1,items)))*100\n        if confidence > min_conf:\n            print(\"People who purchase {} and {} also purchase: {}\".format(d[0],d[1],n[0]),\"\\n Confidence= {:.2f}%\".format(confidence),\"\\n\")\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}