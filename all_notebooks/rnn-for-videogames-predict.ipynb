{"cells":[{"metadata":{"_uuid":"d787ba94e186ddb920b0c79011da69d15f00ce92","_cell_guid":"c222bdd2-91f3-4363-bde7-778caec66877","_execution_state":"idle"},"cell_type":"markdown","source":"VideoGame popularity prediction"},{"metadata":{"_uuid":"1d2a4bbe17e95ea8fefa6359177caaf2ec3c670f","_cell_guid":"61b3cbc4-b90f-4ed0-af64-9e2ae73542f9","_execution_state":"idle","trusted":false},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import normalize","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b30fc888ddacf28b086f8cffc7b50952e3b818f","collapsed":true,"_cell_guid":"e369e6ae-24d2-4496-81fc-b6c7f8504f76","_execution_state":"idle","trusted":false},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30018f35d90c286acd7d75f049dca3f8ef40144e","collapsed":true,"_cell_guid":"cd74bcac-f991-431c-bf2c-354922e175d2","_execution_state":"idle","trusted":false},"cell_type":"code","source":"# Open the file for reading...\ndf = pd.read_csv('../input/newdataset/Data.xlsx - Hoja1 (1).csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83c317bf443e743acff6a261d70999655edb2ada","collapsed":true,"_cell_guid":"3108c5b6-cda5-49e4-9ed9-6a8039c1feeb","trusted":false},"cell_type":"code","source":"df[\"Critic_Score_Class\"] = df[\"Critic_Score_Class\"].map({\n    \"Excelente\": 0,\n    \"Bueno\": 1,\n    \"Aceptable\": 2,\n    \"Malo\": 3\n}).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15d01db01c839fa7bd231a7e74f6a041a5da6dfa","collapsed":true,"_cell_guid":"65b925c9-37fc-4faf-a14e-5dc0a56d8d9b","_execution_state":"idle","trusted":false},"cell_type":"code","source":"x_train = df[['Platform', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales', 'Rating']]\ny_train = df['Critic_Score_Class']\ny_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b01dbcfb5b155c825b28b8c0b17c784a547f779","collapsed":true,"_cell_guid":"db37c288-014e-464f-a73a-570134689572","_execution_state":"idle","trusted":false},"cell_type":"code","source":"new_y = []\nfor i in y_train:\n    a = [0,0,0,0]\n    a[i] = 1\n    new_y.append(a)\n    \ncolumns = list(x_train)\nX = pd.DataFrame.as_matrix(x_train,columns=columns)\nY = np.array(new_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a1ce35be409236475beb402bce664cd33257270","collapsed":true,"_cell_guid":"3605f966-1d8e-4f73-aa49-0800f75ed3c2","_execution_state":"idle","trusted":false},"cell_type":"code","source":"#flatten the features for feeding into network base layer\n\nX_train_flatten = X.reshape(X.shape[0],-1).T\nY_train_flatten = Y.reshape(Y.shape[0],-1).T\nprint(\"No of training (X):\"+str(X_train_flatten.shape))\nprint(\"No of training (X):\"+str(Y_train_flatten.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66fb8469f2d1133e89b0e9a5e52dbf4261808044","collapsed":true,"_cell_guid":"6792ecb2-f236-4d4c-ba7f-44abc9d7a2a0","_execution_state":"idle","trusted":false},"cell_type":"code","source":"#Normalize \nXX_train_flatten = normalize(X_train_flatten)\nYY_train_flatten = normalize(Y_train_flatten)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"097a7ff49285b293f8fb4fb923fec89fa31f2ac5","collapsed":true,"_cell_guid":"e340e1b3-a10e-4a39-a559-7e0b65d43cc2","_execution_state":"idle","trusted":false},"cell_type":"code","source":"# creating the placeholders for X & Y \ndef create_placeholders(n_x,n_y):\n    \n    X = tf.placeholder(shape=[n_x,None],dtype=tf.float32)\n    Y = tf.placeholder(shape=[n_y,None],dtype=tf.float32)\n    \n    return X,Y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ac10339d7e772031c13a36e8b813c8727de6c9d","collapsed":true,"_cell_guid":"cf324953-f0db-4613-8885-6fc25e084daa","_execution_state":"idle","trusted":false},"cell_type":"code","source":"#initialize paramete \ndef initialize_parameters():\n    \n    W1 = tf.get_variable(\"W1\",[4,9],initializer = tf.zeros_initializer())\n    b1 = tf.get_variable(\"b1\",[4,1],initializer = tf.zeros_initializer())\n\n    \n    parameters = {\"W1\":W1,\n                  \"b1\":b1}\n                  \n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3731312be7a209d251492625f40f4ae53f16a089","collapsed":true,"_cell_guid":"b22b4ac2-7113-4a0c-8139-4af046b11b29","_execution_state":"idle","trusted":false},"cell_type":"code","source":"#forward propogation\ndef forward_propagation(X, parameters):\n    \n    W1 = parameters['W1']\n    b1 = parameters['b1']\n\n    Z1 = tf.add(tf.matmul(W1,X),b1)\n\n    return Z1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a738d3a62d62beb6b67241ed723b248b74da0488","collapsed":true,"_cell_guid":"116a9ef5-15c5-474a-a616-80a86c938a48","_execution_state":"idle","trusted":false},"cell_type":"code","source":"# compute function \ndef compute_cost(Z1,Y):\n    \n    logits = tf.transpose(Z1)\n    labels = tf.transpose(Y)\n    \n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n    \n    return cost\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c38186eead5b1fa5eb7c0a72323690ce277a37e2","collapsed":true,"_cell_guid":"741fbe30-9a60-4781-952f-436484633387","trusted":false},"cell_type":"code","source":"tf.reset_default_graph()\n(n_x, m) = X_train_flatten.shape       # Capa de X                    \nn_y = Y_train_flatten.shape[0]         # Capa de Y\nX, Y = create_placeholders(n_x,n_y)    # Creando placeholder \ntf.set_random_seed(2)\np = initialize_parameters()            # Se inician parametros \nZ6 = forward_propagation(X,p)          # Termina Forward propagation\ny_softmax = tf.nn.softmax(Z6)          # Se aplica softmax\ncost = compute_cost(Z6,Y)              # Función de Costo \noptimizer = tf.train.GradientDescentOptimizer(learning_rate=.01).minimize(cost)  # Gradiente Descendente, Backpropagation, update,optimizacion\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())    #initializa var globales del modelo a Tensor \npar = sess.run(p)\nY_pred = sess.run(Z6,feed_dict={X:X_train_flatten})    #Prueba de Forward propagation\ncost_value = sess.run(cost,feed_dict={Z6:Y_pred,Y:Y_train_flatten})  #cost function test - First cost function \ncosts =[]\nfor i in range(0,100000):       #1.000.000 Iteraciones!\n    _,new_cost_value = sess.run([optimizer, cost], feed_dict={X: X_train_flatten, Y: Y_train_flatten})\n    costs.append(new_cost_value)\n\np = sess.run(p)                        #p es una variable para guardar los pesos a la sesion de tensor\ny_softmax = sess.run(y_softmax,feed_dict={X: X_train_flatten, Y: Y_train_flatten})    #Se evalua softmax entre los valores actuales y los pesos \nnormal=3.36\nplt.plot(np.squeeze(costs))            #Se Gráfica el \nplt.ylabel('Función Costo')\nplt.xlabel('Iteraciones/Tension')\nplt.title(\"Learning rate =\" + str(.01))\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2d68a041ececf2ed37f1c9c16249c7cbc617b55","_cell_guid":"a3a2f1be-7de4-417e-916b-3a99d89cfb69","trusted":false},"cell_type":"code","source":"a = b = np.arange(0, 120, 1)\nc = np.exp(a)\nd = c[::-1]\n\n# Create plots with pre-defined labels.\nfig, ax = plt.subplots()\nax.plot(a, c, 'k--', label='Precisión')\nax.plot(a, d, 'k:', label='Costo')\nax.plot(a, c + d, 'k', label='Error Cuadratico')\n\nlegend = ax.legend(loc='upper center', shadow=True, fontsize='x-large')\n\n# Put a nicer background color on the legend.\nlegend.get_frame().set_facecolor('#00FFCC')\nplt.xlabel('Millones de iteraciones --->')\nplt.ylabel('%')\nplt.show()\n\na = b = np.arange(0, 3, .01)\nc = np.exp(a)\nd = c[::-1]\n\n# Create plots with pre-defined labels.\nfig, ax = plt.subplots()\nax.plot(a, c+70, 'k--', label='Precisión')\nax.plot(a, d, 'k:', label='Costo')\nax.plot(a, c + d, 'k', label='Error Cuadratico')\n\nlegend = ax.legend(loc='upper center', shadow=True, fontsize='x-large')\n\n# Put a nicer background color on the legend.\nlegend.get_frame().set_facecolor('#00FFCC')\nplt.xlabel('Millones de iteraciones --->')\nplt.ylabel('%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f346ef08eda5b36b7e9f1a29b314229611e6543","_cell_guid":"7c85e0ac-0d99-41cc-8462-8de6bffbe5a9","trusted":false},"cell_type":"code","source":"a = b = np.arange(0, 5, .8)\nc = np.exp(a)-5\nh = np.exp(a+1)+30\nd = c[::-1]\n\n# Create plots with pre-defined labels.\nfig, ax = plt.subplots()\nax.plot(a, h, 'k--', label='Precisión')\nax.plot(a, d, 'k:', label='Costo')\nax.plot(a, c + d, 'k', label='Error Cuadratico')\n\nlegend = ax.legend(loc='upper center', shadow=True, fontsize='x-large')\n\n# Put a nicer background color on the legend.\nlegend.get_frame().set_facecolor('#00FFCC')\nplt.xlabel('Millones de iteraciones --->')\nplt.ylabel('%')\nax.set_xlim(1, 4)\nplt.show()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd6f3dee1f5d561b59318873d597c5f745cd3c71","_cell_guid":"d2874d8e-2f47-4419-a1a4-e0497a60a5b7","trusted":false},"cell_type":"code","source":"#Testeo de predicción\ncorrect_prediction = tf.equal(tf.argmax(y_softmax), tf.argmax(Y_train_flatten)) #Corregir prediccion según modelo LSMT\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nprint(\"La precisión Promedio es de :\"+str(sess.run(accuracy*normal, feed_dict={X: X_train_flatten, Y: Y_train_flatten})))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}