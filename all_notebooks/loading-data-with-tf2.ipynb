{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Load data into tensorflow \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We are going to explore the different ways to laod data into tensorflow and make the data usable, this might require a bit of pre-processing","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"try:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\n\n\n\nimport functools\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load CSV data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"curr_dir = '../input/'\ntrain_data_path= curr_dir + \"test-dataset-for-titanic-competition/titanic_test.csv\"\ntest_data_path= curr_dir + \"test-dataset-for-titanic-competition/titanic_train.csv\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets make the numnber easier to read [printOptions](https://docs.scipy.org/doc/numpy/reference/generated/numpy.set_printoptions.html)and look peek inside the training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.set_printoptions(precision=3, suppress=True)\n!head {train_data_path}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to identify the target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LABEL_COLUMN = 'Survived'\nLABELS = [0, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset(file_path, **kwargs):\n  dataset = tf.data.experimental.make_csv_dataset(\n      file_path,\n      batch_size=5, # Artificially small to make examples easier to show.\n      label_name=LABEL_COLUMN,\n      na_value=\"?\",\n      num_epochs=1,\n      ignore_errors=True, \n      **kwargs)\n  return dataset\n\n#raw_train_data = get_dataset(train_data_path)\nraw_test_data = get_dataset(test_data_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_batch(dataset):\n  for batch, label in dataset.take(1):\n    for key, value in batch.items():\n      print(\"{:20s}: {}\".format(key,value.numpy()))\n      \nshow_batch(raw_test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Load data using pandas****","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#print(os.listdir(\"../input/nyt-comments/\"))\ncurr_dir = '../input/'\ncomments = pd.read_csv(curr_dir + \"nyt-comments/CommentsApril2018.csv\")\narticles = pd.read_csv(curr_dir + 'nyt-comments/ArticlesApril2018.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**get a sample of data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"comments.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#comments.shape\ncomments.info()\n#comments.commentBody.sample()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load from csv**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(os.listdir(\"../input/nyt-comments/\"))\ndata = pd.read_csv(\"../input/nyt-comments/ArticlesMarch2018.csv\")\nprint(data.head)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load from text**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_imdb_dataset():\n    \n    imdb_path = \"../input/imdb-movie-reviews-dataset/aclimdb/aclImdb/\"\n    train_texts = []\n    train_labels = []\n    test_texts = []\n    test_labels = []\n    for dset in ['train', 'test']:\n        for cat in ['pos', 'neg']:\n            dset_path = os.path.join(imdb_path, dset, cat)\n            for fname in sorted(os.listdir(dset_path)):\n                if fname.endswith('.txt'):\n                    with open(os.path.join(dset_path, fname)) as f:\n                        if dset == 'train': train_texts.append(f.read())\n                        else: test_texts.append(f.read())\n                    label = 0 if cat == 'neg' else 1\n                    if dset == 'train': train_labels.append(label)\n                    else: test_labels.append(label)\n                        \n                        \n            # Converting to np.array\n    train_texts = np.array(train_texts)\n    train_labels = np.array(train_labels)\n    test_texts = np.array(test_texts)\n    test_labels = np.array(test_labels)\n\n    # Shuffle the dataset\n    train_texts, train_labels = shuffle(train_texts, train_labels)\n    test_texts, test_labels = shuffle(test_texts, test_labels)\n\n    # Return the dataset\n    return train_texts, train_labels, test_texts, test_labels\n\n            \n\n    \n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}