{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"version":"3.6.3","file_extension":".py","name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"}}},"nbformat_minor":1,"cells":[{"execution_count":null,"metadata":{"_cell_guid":"ce4e5b95-53f3-4df1-bb9e-e44577eaeadb","collapsed":true,"_uuid":"257ea107c13e0bcc1165fdc59638d5ab49bd3f0f"},"source":"import pandas as pd","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# Load data","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"people = pd.read_csv('../input/people_wiki.csv')","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"people.head()","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# Explore the dataset and checkout the text it contains\n\n# Exploring the entry for president Obama","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"obama = people[people['name'] == 'Barack Obama']","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"obama","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"pd.options.display.max_colwidth = 5000\nobama['text']","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"## Exploring the entry for actor George Clooney","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"clooney = people[people['name'] == 'George Clooney']","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# Getting  sorted word counts for obama","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"def sortedbow(wordstring):\n    wordlist = wordstring.split()\n    bow = {}\n    for w in wordlist:\n        bow[w] = 0\n    for w in wordlist:\n        bow[w] += 1 \n    print (sorted (bow.items(), key=lambda x: x[1], reverse=True))","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"sortedbow(str(obama['text']))","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# Note that the top words are common words from dictionary like the, in, and, of...","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# Build a nearest neighbor model for document retrieval using tfidf","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vectorizer = CountVectorizer()\nword_count = count_vectorizer.fit_transform(people['text'])\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer()\ntfidf = tfidf_transformer.fit_transform(word_count)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"from sklearn.neighbors import NearestNeighbors\nneigh = NearestNeighbors(n_neighbors=2, n_jobs=-1) \nneigh.fit(tfidf)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"obama_word_counts = count_vectorizer.transform(['obama'])\nobama_tfidf = tfidf_transformer.transform(obama_word_counts)\nres = neigh.kneighbors(obama_tfidf, return_distance=False)\nprint (res)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"people.iloc[[35811]]","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# Obviously  the nearest neighbor of obama is obama himself","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{},"source":"people.iloc[[4032]]","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# Does this make sense?","cell_type":"code","outputs":[]}],"nbformat":4}