{"cells":[{"metadata":{"id":"2SYp4MqkX0XC"},"cell_type":"markdown","source":"# DPhi - Flower Recognition Challenge\n\nThe dataset contains images of 5 types of flowers.\n\nClasses:-\n- daisy\n- dandelion\n- rose\n- sunflower\n- tulip\n\n# Reading & Understanding Data\n## Importing Libraries"},{"metadata":{"trusted":true,"id":"egm0WDv1X0XF"},"cell_type":"code","source":"# importing libraries\nimport os, time, random, sys\nos.environ['PYTHONHASHSEED']=str(1)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use('seaborn-deep')\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 8\nplt.rcParams['ytick.labelsize'] = 8\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['figure.figsize'] = (12, 8)\n\npd.options.mode.chained_assignment = None\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 400)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport sklearn.utils as sku\nfrom skimage.io import imread\nfrom skimage.transform import resize\nseed = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"xW4qQFZNX0XH","outputId":"53d1411d-018a-47da-e5ff-712dee789463"},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_addons as tfa\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"DEqffEqFX0XI","outputId":"19837b9d-4b9c-4bfd-9f2c-52f2cb26752c"},"cell_type":"code","source":"def runSeed():\n    global seed\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nrunSeed()\n\n## Checking the GPU configuration\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"id":"giyXVx4dX0XJ"},"cell_type":"markdown","source":"### Loading Dataset"},{"metadata":{"id":"F1pctQeDYM_7","outputId":"ffb6f8ec-786d-4278-efba-f0d83e7bbc5c","trusted":true},"cell_type":"code","source":"# from google_drive_downloader import GoogleDriveDownloader as gdd\n\n# gdd.download_file_from_google_drive(file_id='1H0rJmSBmYQoWM2w2tqy-jmX0Y2Wg6k2v', \n#                                     dest_path='content/flowers.zip', unzip=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"gf77ppLrX0XK","outputId":"74839744-f83e-428f-e3f4-e81db4d3d069"},"cell_type":"code","source":"basePath = '/kaggle/input/flowers-dataset/'\ntrainPath = basePath + 'train/'\nos.listdir(trainPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_test_set = pd.read_csv(basePath + 'Testing_set_flower.csv')\nsubmission_test_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Ut0bIWLAX0XL"},"cell_type":"code","source":"def showImage(img):\n    plt.figure(figsize=(3,3))\n    plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"VOHWU18KX0XM"},"cell_type":"markdown","source":"# Data Preparation\n"},{"metadata":{"id":"3SA_tDn_X0XM"},"cell_type":"markdown","source":"## Setup Image Generator"},{"metadata":{"trusted":true,"id":"_vy3hkZCX0XN","outputId":"975ed116-b277-44dc-c155-8c70ac7405fc"},"cell_type":"code","source":"# constants\nbatch_size = 128\nimg_dim = 299\ndef getImgTensor(img_d):\n    return (img_d, img_d, 3)\ngetImgTensor(img_dim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"AJAs7ZQfX0XO","outputId":"a1502114-e508-402a-9f0e-a7bf53b44ecf"},"cell_type":"code","source":"# reading training and validation separately to prevent overlapping \n\ntrain_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1./255, \n                                                         validation_split=0.2,\n                                                         shear_range=0.2, \n                                                         zoom_range=0.2, \n                                                         horizontal_flip=True, \n                                                         rotation_range=45,\n                                                         width_shift_range=0.1, \n                                                         height_shift_range=0.1,\n                                                         fill_mode='nearest'\n                                                        )\n\ntrain_generator=train_datagen.flow_from_directory(directory=trainPath,\n                                                  subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"pPallCwsX0XP","outputId":"d8fd8719-55e7-48f9-a0e0-397b6d5ad0a4"},"cell_type":"code","source":"# generate class weights as classes are imbalanced\nclass_weights = sku.class_weight.compute_class_weight('balanced',\n                                                      np.unique(train_generator.classes), \n                                                      train_generator.classes)\ntrain_class_weights = {i:x for i, x in enumerate(class_weights)}\ntrain_class_weights","execution_count":null,"outputs":[]},{"metadata":{"id":"Wq6WEJQ1Z9kC","outputId":"1170f387-f4da-44ae-840c-ba994e797371","trusted":true},"cell_type":"code","source":"batch = train_generator.next()[0]\nshowImage(batch[0])\nshowImage(batch[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"bWH3AYx7X0XP"},"cell_type":"code","source":"valid_generator=train_datagen.flow_from_directory(directory=trainPath,\n                                                  subset=\"validation\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Ni5qW65vX0XQ","outputId":"c12c34ed-2c31-4d73-bc46-c181e3bb8f45"},"cell_type":"code","source":"test_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_generator=test_datagen.flow_from_directory(basePath, \n                                                batch_size=1,\n                                                color_mode=\"rgb\",\n                                                seed=seed,\n                                                shuffle=False,\n                                                classes=['test'],\n                                                target_size=getImgTensor(img_dim)[:2])","execution_count":null,"outputs":[]},{"metadata":{"id":"-SoRFuuFX0XR"},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true,"id":"X1rbTFPuX0XS"},"cell_type":"code","source":"def plotModelHistory(h):\n    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n    ax[0].plot(h.history['loss'])   \n    ax[0].plot(h.history['val_loss'])\n    ax[0].legend(['loss','val_loss'])\n    ax[0].title.set_text(\"Train loss vs Validation loss\")\n\n    ax[1].plot(h.history['categorical_accuracy'])   \n    ax[1].plot(h.history['val_categorical_accuracy'])\n    ax[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n    ax[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n\n    print(\"Max. Training Accuracy\", max(h.history['categorical_accuracy']))\n    print(\"Max. Validaiton Accuracy\", max(h.history['val_categorical_accuracy']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"CHjLR-_rX0XT"},"cell_type":"code","source":"class myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        ACCURACY_THRESHOLD = 0.99\n        if(logs.get('categorical_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"id":"PW_7MuXgX0XT"},"cell_type":"code","source":"def trainModel(model, epochs, optimizer, vb=1, modelName='model'):\n    bestModelPath = './'+modelName+'_model.hdf5'\n    callback = myCallback()\n    callbacks_list = [\n        callback,\n        k.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 5, verbose = 1, min_lr=0.00001), \n        k.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1, restore_best_weights = True), \n        k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)\n    ]\n    model.compile(optimizer=optimizer,\n                  loss=k.losses.CategoricalCrossentropy(label_smoothing=.05),\n                  metrics=[k.metrics.CategoricalAccuracy()]\n    )\n    train_generator.reset()\n    \n    steps_per_epoch = np.ceil(train_generator.n/train_generator.batch_size)\n    validation_steps = np.ceil(valid_generator.n/valid_generator.batch_size)\n\n    return model.fit_generator(generator=train_generator, steps_per_epoch=steps_per_epoch, \n                               validation_data=valid_generator, validation_steps=validation_steps, \n                               epochs=epochs, verbose=vb,\n                              #  class_weight=train_class_weights,\n                               callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ALWIayHmX0XU"},"cell_type":"code","source":"# evaluate model with time\ndef evaluateModel(model, path=True):\n    batch_size = valid_generator.batch_size\n    num_train_sequences = valid_generator.n\n    valid_generator.reset()\n    steps_per_epoch = 0\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        steps_per_epoch = int(valid_generator.n/valid_generator.batch_size)\n    else:\n        steps_per_epoch = int(valid_generator.n//valid_generator.batch_size) + 1\n\n    t1 = time.time()\n    if path:\n        model = k.models.load_model(model)\n    eval_results = model.evaluate_generator(valid_generator, steps=steps_per_epoch)\n    t2 = time.time()\n    print(f'\\nLoss: {eval_results[0]}, Accuracy: {eval_results[1]}')\n    print(f'Prediction Time per Image: {(t2-t1)/valid_generator.n}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"KUsBHZu_X0XU"},"cell_type":"code","source":"# predict images using model\ndef predictModel(modelPath):\n    batch_size = test_generator.batch_size\n    num_train_sequences = test_generator.n\n    steps_per_epoch = 0\n    if (test_generator.n%test_generator.batch_size) == 0:\n        steps_per_epoch = int(test_generator.n/test_generator.batch_size)\n    else:\n        steps_per_epoch = int(test_generator.n//test_generator.batch_size) + 1\n\n    test_generator.reset()\n\n    t1 = time.time()\n    model = k.models.load_model(modelPath)\n    predictions = model.predict_generator(test_generator, steps=steps_per_epoch, verbose=1)\n    t2 = time.time()\n    print(f'Prediction Time per Image: {(t2-t1)/test_generator.n}')\n    \n    print(\"Generating Predictions file..\")\n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predicted_class_indices=np.argmax(predictions, axis=1)\n    predictions_label = [labels[k] for k in predicted_class_indices]\n    filenames = list(map(lambda x: x.split('/')[-1], test_generator.filenames))\n    submission=pd.DataFrame({\n        \"Filename\":filenames, \n        \"Class\":predictions_label\n    })\n    # generate series of predictions as per testing_set\n    submission_final = pd.Series([submission[submission['Filename'] == x].iloc[0,1] for x in np.ravel(submission_test_set.values)])\n    submission_file = \"submission_\"+modelPath.split('/')[-1].split('_')[0]+\".csv\"\n    submission_final.to_csv(submission_file,index=False, header=['prediction'])\n    print(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\n    submission.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Oryp23LsX0XV"},"cell_type":"markdown","source":"## Train MobileNetV2 - Light Model"},{"metadata":{"trusted":true,"id":"jEMT1OlPX0XW","outputId":"8a9320c3-b20d-4b78-d030-e103617ab2fc"},"cell_type":"code","source":"img_dim=224\nmobilenet = k.applications.mobilenet_v2.MobileNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nmobilenet.trainable = False\n\nmodel = k.models.Sequential([\n                             mobilenet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"fKJqmGjXX0XX","outputId":"1e225639-a94d-4b09-8d52-9414312224d2"},"cell_type":"code","source":"history_1 = trainModel(model, 50, 'adam', modelName='mobilenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"MEBscIoFX0XX","outputId":"12599bc5-dfb5-4f6e-ff1f-2bb6bf68698b"},"cell_type":"code","source":"plotModelHistory(history_1)","execution_count":null,"outputs":[]},{"metadata":{"id":"Rf4BVuW7X0XY"},"cell_type":"markdown","source":"## Train ResNet152 - Heavy Model"},{"metadata":{"scrolled":false,"trusted":true,"id":"jxCmUsuSX0XY","outputId":"6a0988e7-6a93-435b-c5cc-9891bb1d6585"},"cell_type":"code","source":"img_dim=224\nresnet152 = k.applications.ResNet152V2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nresnet152.trainable = False\n\nmodel_2 = k.models.Sequential([\n                             resnet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                            #  k.layers.Dense(1024, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.3),\n\n                             k.layers.Dense(512, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"L-fQJbJXX0XZ","outputId":"cba23ef1-48a2-4d81-be79-5133361ab14b"},"cell_type":"code","source":"history_2 = trainModel(model_2, 50, 'adam', modelName='resnet152')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"sEA8TrWhX0Xa","outputId":"325d21dc-f837-49a2-f5e6-9fc04ef774b9"},"cell_type":"code","source":"plotModelHistory(history_2)","execution_count":null,"outputs":[]},{"metadata":{"id":"IJKeZr2wX0Xa"},"cell_type":"markdown","source":"## Train InceptionV3 - Medium Model"},{"metadata":{"trusted":true,"id":"nIYVDMTRX0Xb","outputId":"7821618c-4a85-4419-db24-b1423a026ebb"},"cell_type":"code","source":"img_dim=224\ninceptionv3 = k.applications.InceptionV3(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionv3.trainable = False\n\nmodel_3 = k.models.Sequential([\n                             inceptionv3,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"uUTZmaYbX0Xb","outputId":"7cb27385-151e-4465-cccb-6e3fac58312d"},"cell_type":"code","source":"history_3 = trainModel(model_3, 50, 'adam', modelName='inceptionv3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"CKub9az7X0Xc","outputId":"c82473a1-6ba0-4943-88b3-f68faa6b9b70"},"cell_type":"code","source":"plotModelHistory(history_3)","execution_count":null,"outputs":[]},{"metadata":{"id":"RD4CbJSpX0Xd"},"cell_type":"markdown","source":"## Train NASNetLarge - Heavy Model"},{"metadata":{"trusted":true,"id":"om0ZmE3dX0Xd","outputId":"54236369-618c-4ba7-d878-0bb862fbc6de"},"cell_type":"code","source":"img_dim=331\nnasnet = k.applications.nasnet.NASNetLarge(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nnasnet.trainable = False\n\nmodel_4 = k.models.Sequential([\n                             nasnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_4.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"XJKsm2PkX0Xe","outputId":"75bce52b-5930-45fc-aa74-bccdbd3a3fd3"},"cell_type":"code","source":"history_4 = trainModel(model_4, 50, 'adam', modelName='nasnet_large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"c0IWf_v3X0Xf","outputId":"8be3cde2-e154-4997-c1b4-e82c11b44bb4"},"cell_type":"code","source":"plotModelHistory(history_4)","execution_count":null,"outputs":[]},{"metadata":{"id":"HZeBfdR6X0Xf"},"cell_type":"markdown","source":"## Train InceptionResNetV2 - Heavy Model"},{"metadata":{"trusted":true,"id":"tRNUs8CNX0Xg","outputId":"c69563b5-b0b9-4868-8a3e-dd05acd222a7"},"cell_type":"code","source":"img_dim=299\ninceptionresnet = k.applications.InceptionResNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionresnet.trainable = False\n\nmodel_5 = k.models.Sequential([\n                             inceptionresnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_5.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"2oVp-LsxX0Xh","outputId":"2db8031f-9d14-4e27-94a2-260f2093ff10"},"cell_type":"code","source":"history_5 = trainModel(model_5, 50, 'adam', modelName='inceptionresnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"X6kHdc4kX0Xj","outputId":"91c3be61-6d6c-44e9-d308-ec9132d1b7ac"},"cell_type":"code","source":"plotModelHistory(history_5)","execution_count":null,"outputs":[]},{"metadata":{"id":"ycoGVxaRbVoK"},"cell_type":"markdown","source":"## Train DenseNet169 - Light Model"},{"metadata":{"id":"pCwAKafrbZHG","outputId":"36ccd0a1-f674-4605-bc56-f5afc892b53c","trusted":true},"cell_type":"code","source":"img_dim=299\ndensenet152 = k.applications.DenseNet169(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ndensenet152.trainable = False\n\nmodel_6 = k.models.Sequential([\n                             densenet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_6.summary())","execution_count":null,"outputs":[]},{"metadata":{"id":"7GbTH7A1bfXo","outputId":"9d2a4484-e316-4a94-e820-78963eddfa31","trusted":true},"cell_type":"code","source":"history_6 = trainModel(model_6, 50, 'adam', modelName='densenet169')","execution_count":null,"outputs":[]},{"metadata":{"id":"mh8nGjWJqXGw","outputId":"aa14fb7f-c2f8-4a85-d8f3-20e983d4f4fa","trusted":false},"cell_type":"code","source":"plotModelHistory(history_6)","execution_count":null,"outputs":[]},{"metadata":{"id":"dTn0pEPF0laJ"},"cell_type":"markdown","source":"## CNN + XGB Model"},{"metadata":{"id":"PcGidvRe0mdQ","outputId":"e70cd8e1-2bef-4b54-f793-7bfb578d1238","trusted":true},"cell_type":"code","source":"model_7 = k.Model(model_5.input, model_5.layers[-3].output)\ntrain_generator.reset()\n# scan model feature representations\nX_train_embed = []\ny_train_embed = []\nfor x in range(int(np.ceil(train_generator.n/train_generator.batch_size))):\n    x_batch, y_batch = next(train_generator)\n    x_last = model_7.predict(x_batch)\n    X_train_embed.extend(x_last)\n    y_train_embed.extend(y_batch)\n\n# generate predictions for embeddings\ny_train_embed = np.array(np.argmax(y_train_embed, axis=1))\nX_train_embed = np.array(X_train_embed)\nprint(y_train_embed.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"RieFXnb8eGlZ","outputId":"69219477-c51a-4966-dc49-b493247e0c42","trusted":true},"cell_type":"code","source":"# create xgb classifier for classification\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(max_depth=10, objective='multi:softmax', n_estimators=1000, num_classes=5,\n                    tree_meth ='gpu_hist', gpu_id=0, n_jobs=-1)\nxgb.fit(X_train_embed,y_train_embed)","execution_count":null,"outputs":[]},{"metadata":{"id":"QhugeYBieJOx","outputId":"2f592872-f0cf-4500-d445-3cc9a84da754","trusted":false},"cell_type":"code","source":"# generate predictions for test data\nimg_dim=299\nX_test_embed = np.array(model_7.predict(test_generator))\npredictions_xgb = xgb.predict(X_test_embed)\n\n# generate submission file for predictions\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions_label = [labels[k] for k in predictions_xgb]\nfilenames = list(map(lambda x: x.split('/')[-1], test_generator.filenames))\nsubmission=pd.DataFrame({\n    \"Filename\":filenames, \n    \"Class\":predictions_label\n})\n# generate series of predictions as per testing_set\nsubmission_final = pd.Series([submission[submission['Filename'] == x].iloc[0,1] for x in np.ravel(submission_test_set.values)])\nsubmission_file = \"submission_DENSENET169_XGB.csv\"\nsubmission_final.to_csv(submission_file,index=False)\nprint(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"XKQMQfnLX0Xj"},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":true,"id":"H3BbsqRyX0Xl","outputId":"942b8e8e-2108-4c07-d340-2a82a274da39"},"cell_type":"code","source":"# mobile net\nimg_dim=224\nevaluateModel('./mobilenet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"4WHYAT7NX0Xl"},"cell_type":"code","source":"# resnet152\nimg_dim=224\nevaluateModel('./resnet152_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"qR8cyyUQX0Xm","outputId":"133676e7-fcb3-4395-c949-f74566dbb4d2"},"cell_type":"code","source":"# inceptionv3\nimg_dim=224\nevaluateModel('./inceptionv3_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"YZy4NL4HX0Xm","outputId":"4ff1e7c6-f09a-4038-b95f-e4b351043cd5"},"cell_type":"code","source":"# nasnet\nimg_dim=331\nevaluateModel('./nasnet_large_model.hdf5')\n# evaluateModel(model_4, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"F0p2zvJ1X0Xn","outputId":"d098ccce-cb76-4aff-8522-464d5918e712"},"cell_type":"code","source":"# inceptionresnet\nimg_dim=299\nevaluateModel('./inceptionresnet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"id":"nJj7tuOPbxCI","outputId":"01c14457-996e-40cc-c8b2-eb21012296d2","trusted":true},"cell_type":"code","source":"# densenet169\nimg_dim=299\nevaluateModel('./densenet169_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"id":"Qux6-CgOX0Xo"},"cell_type":"markdown","source":"# Model Prediction"},{"metadata":{"trusted":true,"id":"LKCc5JRkX0Xo","outputId":"81f335d4-46c8-4d28-d8a7-851939bfc0e5"},"cell_type":"code","source":"# mobile net\nimg_dim=224\npredictModel('./mobilenet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"nA9PpWtyX0Xp","outputId":"87c676ba-5cfc-419f-f02f-1a89cc7cd104"},"cell_type":"code","source":"# resnet152\nimg_dim=224\npredictModel('./resnet152_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"TS9PTttTX0Xp","outputId":"f1891fae-3506-4dba-9624-c9ecc871cae5"},"cell_type":"code","source":"# inceptionv3\nimg_dim=224\npredictModel('./inceptionv3_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8-VCldE1X0Xq","outputId":"a4f8ef2b-eac1-4733-8fd4-be00be435956"},"cell_type":"code","source":"# nasnet\nimg_dim=331\npredictModel('./nasnet_large_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"NkFKGLUZX0Xr","outputId":"a1ef06fc-3fe9-4ffe-9c1a-343af2374aa6"},"cell_type":"code","source":"# inceptionresnet\nimg_dim=299\npredictModel('./inceptionresnet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"id":"PrjWVHLgb77p","outputId":"bda8a039-f250-45f7-efec-977c2b940773","trusted":true},"cell_type":"code","source":"# densenet169\nimg_dim=299\npredictModel('./densenet169_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"id":"tg2Zp-fP-l64","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}