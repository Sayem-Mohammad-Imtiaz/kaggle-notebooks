{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas_profiling as pd_prof\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nsns.set()\n\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"poke_data = pd.read_csv('../input/Pokemon.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0f72309520e4d633e43d5cec4cb5a2133d00b5f"},"cell_type":"markdown","source":"## Initial EDA"},{"metadata":{"trusted":true,"_uuid":"697582e52fe64a056caf5c479e7098f619ec0c5f"},"cell_type":"code","source":"poke_data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e65eaaa3bbd7d286679ce72cce4f55b7ce5ed36"},"cell_type":"markdown","source":"#### Initially only one column seems to have null values, 'Type 2'. Going by the data description it is the second column to depict the type of pokemon so it is acceptable to be null at some places because it is not necessary that every pokemon would have more than one type."},{"metadata":{"_uuid":"046c34f71bb4e1cf0544a3adb0edda237cee9929"},"cell_type":"markdown","source":"#### Column 'Total' is the Sum of Attack, Sp. Atk, Defense, Sp. Def, Speed and HP"},{"metadata":{"trusted":true,"_uuid":"38e6ce402b9789842ac4644925cccebe3107fb2a"},"cell_type":"code","source":"poke_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9ae041148ce289bd567862325b4f6211a56f5ef"},"cell_type":"markdown","source":"#### This # column seems to be useful as the index for this dataframe, Let's load the dataframe again with # as index"},{"metadata":{"trusted":true,"_uuid":"42fb6f98e6bb9c128d640acbdc8c49cd4413569e"},"cell_type":"code","source":"poke_data = pd.read_csv('../input/Pokemon.csv',index_col='#')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5418f59d0735fbfaa9462c23c12e3907f744c6b"},"cell_type":"code","source":"poke_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53a787a08c430785feae887ba83633ddcc97370f"},"cell_type":"markdown","source":"#### Let's do a summary statistic analysis for the data"},{"metadata":{"trusted":true,"_uuid":"57ee2027b517d590b1d7521a9442e312f7a53c65"},"cell_type":"code","source":"poke_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e17300804584c897426b9a971e9a0d4256dd065"},"cell_type":"code","source":"#pd_prof.ProfileReport(poke_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4874b4e5302f03187468f4533c3a413ad011db94"},"cell_type":"markdown","source":"#### We should replace the bool values in Legendary column with binary values"},{"metadata":{"trusted":true,"_uuid":"7961bb8c729baa8d60d44133b43416668ca58b82"},"cell_type":"code","source":"poke_data.Legendary.replace({True:1,False:0},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28a111c9c4cf18016686a355d7306036a70737d7"},"cell_type":"markdown","source":"#### Let's check now"},{"metadata":{"trusted":true,"_uuid":"ac07f478cff0b60e867b7f1e25572262595be7b3"},"cell_type":"code","source":"poke_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c64f8d22d237f70ef85ae5d054396c4822e667f"},"cell_type":"markdown","source":"#### No doubt the data would require to be scaled before modelling can take place. The max values of all columns are varying widely.\n#### Apart from that none of the statistics seem to be unrealistic like negative values etc. so lets move forward."},{"metadata":{"trusted":true,"_uuid":"a1930ba48c16807b402af826f25a04f40d54f1a9"},"cell_type":"code","source":"p = poke_data.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ae7933851cdefc47230a29cd2c3bafae4df073f"},"cell_type":"markdown","source":"#### Some of the factors like Sp. Atk, Defence seem to be skewed."},{"metadata":{"_uuid":"0be4af04e7cfc31fbcc270264f64a45cceb11e5d"},"cell_type":"markdown","source":"## Skewness\n\nA ***left-skewed distribution*** has a long left tail. Left-skewed distributions are also called negatively-skewed distributions. That’s because there is a long tail in the negative direction on the number line. The mean is also to the left of the peak.\n\nA ***right-skewed distribution*** has a long right tail. Right-skewed distributions are also called positive-skew distributions. That’s because there is a long tail in the positive direction on the number line. The mean is also to the right of the peak.\n\n\n![](https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2014/02/pearson-mode-skewness.jpg)\n\n\n#### to learn more about skewness\nhttps://www.statisticshowto.datasciencecentral.com/probability-and-statistics/skewed-distribution/"},{"metadata":{"_uuid":"4a44aed1e3412d02f89c1d28920d2d698ccc5842"},"cell_type":"markdown","source":"### Unique Values in each column"},{"metadata":{"trusted":true,"_uuid":"7dfd60952b2fbb996c2965ed4acd5b6f79fadf32"},"cell_type":"code","source":"poke_data['Legendary'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"248828474440a8302f940bb62011c35ce3b349d0"},"cell_type":"markdown","source":"#### Great class imbalance!"},{"metadata":{"trusted":true,"_uuid":"cbbedb1e1c6ab475b542ef1adaabcfc534125f7b"},"cell_type":"code","source":"poke_data['Type 1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7de05be02a0a1fa0e4154d12e85dab4194cc9fa"},"cell_type":"code","source":"poke_data['Type 2'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01957016fe0035c98d97cab88cf05373df351777"},"cell_type":"markdown","source":"#### Two columns have the same categories. This may cause issues with one hot encoding. Let's try to solve for this.\n#### Beginning by checking what values the two columns contain and are they same."},{"metadata":{"trusted":true,"_uuid":"8c76af53aba2ed86790c3213943fbc6be31e3cef"},"cell_type":"code","source":"type_1_list = list(poke_data['Type 1'].value_counts().index)\ntype_2_list = list(poke_data['Type 2'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"935da8ab094d379ca8d301645d1816203244f9c0"},"cell_type":"code","source":"type_1_list.sort()==type_2_list.sort()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17f3fb5f2a964f2103a2ffc1938716e3e4bfbcc0"},"cell_type":"markdown","source":"#### This shows that the values in both the type columns are same. That means no column has a different category."},{"metadata":{"_uuid":"d6b8a9dc4980ebbadf9805eea3ae0afe02e5592e"},"cell_type":"markdown","source":"### If get_dummies is directly applied to change this categorical data to binary, the function will produce columns with the same name because of the presence of same categories in both columns and due to the nature of get_dummies function. This would cause high dimensionality and unnecessary redundancy.\n#### To deal with this problem dummies of the two columns are created separately."},{"metadata":{"trusted":true,"_uuid":"80a74def010e23912696f5dae4389ff8323290e6"},"cell_type":"code","source":"dummy_type_1 = pd.get_dummies(poke_data['Type 1'])\ndummy_type_2 = pd.get_dummies(poke_data['Type 2'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1f6590f774b458cea437b04dca81dfb8f2860d8"},"cell_type":"markdown","source":"#### Now iterating on the name of the categories present in one of the columns (any one because both columns have same categories), the values of the columns having same name would be added together and stored in a third dataframe with the same index as the initial dataframe."},{"metadata":{"trusted":true,"_uuid":"5b18af49ec31c1fc5dd8b5250878b4fa62d11d72"},"cell_type":"code","source":"dummy_final = pd.DataFrame(index=poke_data.index)\nfor column_name in type_2_list:\n    dummy_final[column_name] = dummy_type_1[column_name] + dummy_type_2[column_name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6833b860e1e21626df1ce5985715925bd7b49cb"},"cell_type":"code","source":"dummy_final.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59939c12c73d31d74713342746e83a7c5055da4e"},"cell_type":"markdown","source":"#### To check whether the steps we took are correct, summary stats are printed for the new dataframe. None of the columns contains a max value greater than one. Hence there's nothing to worry about."},{"metadata":{"trusted":true,"_uuid":"1ba825cca2e16cbebad8fd96a671e08f66ee08bc"},"cell_type":"code","source":"dummy_final.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e3d27286523718383be6ff6f2ff2e73a18d85cf"},"cell_type":"code","source":"dummy_final.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7af41337b74d3ebd67d428fb23fb6082809a2888"},"cell_type":"markdown","source":"#### By printing the info we can see that this new dataframe doesn't contain any Nan values whereas we had seen that the type 2 column had Nans. So what just happened? Where did the Nan values go?\n\n#### Let's try to understand using a very raw example that I tried to depict below. "},{"metadata":{"trusted":true,"_uuid":"45e76d1e38aade3f892ff02b1104c18731271be5"},"cell_type":"code","source":"# I have a dataframe 'df' like this \n\n# Id    v1    v2\n# 0     A     0.23\n# 1     B     0.65\n# 2     NaN   0.87\n\n# If I use this function\n\n# df1 = get_dummies(df)\n# df1\n\n# Id    v1_A    v1_B    v2\n# 0     1       0       0.23\n# 1     0       1       0.65\n# 2     0       0       0.87 .","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35fdd38210a89716d61c84b33c1230d177aaa646"},"cell_type":"markdown","source":"#### So it is visible that get_dummies function converts Nans to 0 and doesn't form a separate column for them like it does for other categories. Our problem has been solved thanks to get_dummies()"},{"metadata":{"_uuid":"cb53c0ce88d43cccbe8224c824368412c7784d7f"},"cell_type":"markdown","source":"#### Now we can concatenate this dataframe with the initial dataframe and drop the type 1 and type 2 columns"},{"metadata":{"trusted":true,"_uuid":"26c57ccc24184278ea596c7489f7a7fa9a349294"},"cell_type":"code","source":"poke_data_new = pd.concat([poke_data,dummy_final],sort=False,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3380f694b07a8004d6ff305593ee9f0cccf38f8d"},"cell_type":"markdown","source":"#### Now let's do a basic check on this!"},{"metadata":{"trusted":true,"_uuid":"be2c9e234cc8a0c2f885fa45e9fe27982fad6617"},"cell_type":"code","source":"poke_data_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eeae3e2cb58e7b33e89a602a47d6cb4da1ec72b6"},"cell_type":"code","source":"poke_data_new.drop(['Type 1','Type 2'],axis=1,inplace=True)\npoke_data_new.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"497b71bc7463ea948253b77b7a4599fa1d6d4bf0"},"cell_type":"markdown","source":"#### Perfect we'll be using this one from now. "},{"metadata":{"_uuid":"79879f6924dc5fa526b8e1fe53ca526eab68eb7b"},"cell_type":"markdown","source":"#### Finally let's see the column Generation"},{"metadata":{"trusted":true,"_uuid":"5ba9f7f32bcf886e81a899f59a474823370053e9"},"cell_type":"code","source":"poke_data_new['Generation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c40b74ee021741a468cc85a7e2d24800d9a674a9"},"cell_type":"markdown","source":"## Bivariate EDA"},{"metadata":{"trusted":true,"_uuid":"411c760121553ddd863e5aaaaeb96af2b70162b9"},"cell_type":"code","source":"plt.figure(figsize=(20,20))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(poke_data.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90dc79dd32344a1917f7b88598ddb722540ef647"},"cell_type":"markdown","source":"#### Noticable that none of the factors seem to have a correlation with the target value higher than 0.70"},{"metadata":{"trusted":true,"_uuid":"09131e22080ecbde7b8e95c1468d8b04a7f06d2b"},"cell_type":"code","source":"poke_data_new.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78887a82a8b29b9c33044ae70e5f183c8293d189"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nnumerical =  pd.DataFrame(sc_X.fit_transform(poke_data_new[['Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def',\n       'Speed']]),columns=['Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def',\n       'Speed'],index= poke_data_new.index\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"823dd232323a1175c037f39ce5d1481e04e7179f"},"cell_type":"code","source":"#numerical\npoke_clean_standard = poke_data_new.copy(deep=True)\npoke_clean_standard[['Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def',\n       'Speed']] = numerical[['Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def',\n       'Speed']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"833fbe43c58746c5eacad2534e8428ecf39a44f3"},"cell_type":"code","source":"poke_clean_standard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fc6582299bdccd367539c092e1f5120741449cc"},"cell_type":"code","source":"poke_clean_standard.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9527317fc5f84d9f013c9636e845b06523caa1a1"},"cell_type":"code","source":"x = poke_clean_standard.drop([\"Legendary\",\"Name\"],axis=1)\ny = poke_clean_standard.Legendary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90eabe97f0544c649604e4678d70d25b97ff2afa"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y,random_state = 2,test_size=0.4,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cf516128753d30debe56ed4e15c5a6b0d9c742d"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,15):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d18005601c6f99e887189e99122c3ab5aa2de663"},"cell_type":"code","source":"## score that comes from testing on the same datapoints that were used for training\nmax_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b39a693587cd98a87396bffb8b1270c66cbe5851"},"cell_type":"code","source":"## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\nmax_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee09a351a8ab1aa05b24d0ee3a9747684890e301"},"cell_type":"markdown","source":"## Result visualisation"},{"metadata":{"trusted":true,"_uuid":"b5b7e56bc802c17bd8d7fbc4615ab8d5ccd3d493"},"cell_type":"code","source":"plt.figure(figsize=(12,5))\np = sns.lineplot(range(1,15),train_scores,marker='*',label='Train Score')\np = sns.lineplot(range(1,15),test_scores,marker='o',label='Test Score')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b807d0d520a0dc976b34203b151a2bf7c7d6c28c"},"cell_type":"markdown","source":"#### The best result is captured at k = 7 hence 7 is used for the final model "},{"metadata":{"trusted":true,"_uuid":"7a88878f8d7c15c9d59788801f4a9cb04e5c5465"},"cell_type":"code","source":"#Setup a knn classifier with k neighbors\n#Setup a knn classifier with k neighbors\nknn = KNeighborsClassifier(7)\n\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b00b8f4f2fc693927c5632dbcdea8dfaf732fd87"},"cell_type":"markdown","source":"## Confusion Matrix"},{"metadata":{"trusted":true,"_uuid":"c2d1ad4f5d88cb56bcd36eab390427bff6f63119"},"cell_type":"code","source":"y_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb321fd5328216dbf951250c2b998bf2202eaf85"},"cell_type":"code","source":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# F1 Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Matthew Correlation Coefficient Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import matthews_corrcoef\nprint(matthews_corrcoef(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aada63ef33edf30113fa3d555bf278b29b0ded3f"},"cell_type":"markdown","source":"## ROC Curve"},{"metadata":{"trusted":true,"_uuid":"3f50367414d0172140b8f672728225cce019b531"},"cell_type":"code","source":"from sklearn.metrics import roc_curve\ny_pred_proba = knn.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=7) ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6aa64ac1f6727dc5b2da7a12b13c2db2292cb59"},"cell_type":"markdown","source":"# SMOTE for Class Imbalance"},{"metadata":{"trusted":true,"_uuid":"88aa682508a1df005a0e51000a63ad7de27c1771"},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poke_clean_standard.Legendary.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=2, ratio = 'minority')\nx_train_res, y_train_res = sm.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,15):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(x_train_res,y_train_res)\n    \n    train_scores.append(knn.score(x_train_res,y_train_res))\n    test_scores.append(knn.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## score that comes from testing on the same datapoints that were used for training\nmax_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\nmax_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(2)\n\nknn.fit(x_train_res,y_train_res)\nknn.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import matthews_corrcoef\nprint(matthews_corrcoef(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SMOTE Tomek Method"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek\n\nsmt = SMOTETomek(ratio='auto')\nx_train_res, y_train_res = smt.fit_sample(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,15):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(x_train_res,y_train_res)\n    \n    train_scores.append(knn.score(x_train_res,y_train_res))\n    test_scores.append(knn.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## score that comes from testing on the same datapoints that were used for training\nmax_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\nmax_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(2)\n\nknn.fit(x_train_res,y_train_res)\nknn.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import matthews_corrcoef\nprint(matthews_corrcoef(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Yet To Be Updated"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}