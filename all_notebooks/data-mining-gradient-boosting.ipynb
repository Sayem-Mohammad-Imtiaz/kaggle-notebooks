{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"churn <- read.csv(\"BankChurners.csv\", na.strings = c(\"Unknown\"))\nhead(churn)\nnames(churn)\n#target distribution\ntable(churn$Attrition_Flag)/nrow(churn)\n\n#tolgo ID\nchurn<-churn[-c(1,23,22)]\n\nstr(churn)\n\n#Rename Variables\nnames(churn)[10]<-\"Customer_Product\" \nnames(churn)[11]<-\"Inactivity_Months\"\nnames(churn)[12]<-\"Contacts\"\n```\n\n\n```{r}\n#convert to factor\nchurn$Attrition_Flag<-as.factor(churn$Attrition_Flag)\nlevels(churn$Attrition_Flag)\ntable(churn$Attrition_Flag)\n\nchurn$Gender<-as.factor(churn$Gender)\nlevels(churn$Gender)\ntable(churn$Gender)\n\nchurn$Education_Level<-as.factor(churn$Education_Level)\nlevels(churn$Education_Level)\ntable(churn$Education_Level)\n\nchurn$Marital_Status<-as.factor(churn$Marital_Status)\nlevels(churn$Marital_Status)\ntable(churn$Marital_Status)\n\nchurn$Income_Category<-as.factor(churn$Income_Category)#reddito annuale\nlevels(churn$Income_Category)\ntable(churn$Income_Category)\n\nchurn$Card_Category<-as.factor(churn$Card_Category)\nlevels(churn$Card_Category)\ntable(churn$Card_Category)\n\n#Numeric\nnumeric <- sapply(churn, function(x) is.numeric(x))\nnumeric <-churn[, numeric]\nstr(numeric)\n\nlibrary(funModeling)\nstatus=df_status(churn, print_results = F)\nstatus\n```","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"################## PREPROCESSING PREPROCESSING PREPROCESSING ###################\nsapply(churn, function(x)(sum(is.na(x))))/nrow(churn)\n```\n\nIl primo step della fase di preprocessing, ancora prima di scegliere se procedere \nun crossvalidation method o con uno split del dataset in dati di training e di validation\ne lo step riguardante l'imputazione: procederemo con il criterio \"pmm\", un sottoprocesso\ndei metodi di mice imputation.\n```{r}\nlibrary(mice)\nnames(churn)\n#Dopo aver selezionato le variabili con i dati da imputare procediamo:\npmmData<-mice(churn[-1], m=8, maxit=15, meth='pmm', seed=500)\n\ncompletedData<-complete(pmmData,1)\n\nAttrition_Flag<-churn$Attrition_Flag\nchurn<-cbind(Attrition_Flag,completedData)\nnames(churn)\n\n#controlliamo che l'imputazione sia andata a buon fine\nsapply(churn, function(x)(sum(is.na(x))))\n#Non ci sono più dati mancanti.\nchurn_sheet<-churn#dataset da usare per fare porcherie\n```\n\n## 1.b)COLLINEARITY\n\n```{r}\nlibrary(caret)\ncorFeatures <- findCorrelation(cor(numeric), cutoff = 0.90, names = TRUE)\ncorFeatures\n```\nLa variabile *\"Avg_Open_To_Buy\"* riporta un legame lineare superiore al 90%, difatti,\nnella parte introduttiva alla compresione del significato delle variabili abbiamo notato\nl'esistenza di una combinazione lineare, la quale comprendeva la variabile in questione.\n\"Avg_Open_To_Buy\" = \"Credit_Limit\" - \"Total_Revolving_Bal\" !!!!!\n\nProcediamo...\n```{r}\nlibrary(corrplot)\ncorrplot(cor(numeric),  type=\"upper\", method=\"color\")\n```\n\n```{r}\nnames(churn)\nchurn_features<-churn[-c(1,15)]#dataset con solo predittori, senza target\nchurn<-churn[-15]\nchurn_sheet<-churn#dataset da usare per fare porcherie\n```\n\n## 1.c) ZERO VARIANCE\n```{r}\nno_variance <- nearZeroVar(churn_features, saveMetrics = TRUE)\nno_variance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"######################## STEP1 STEP1 STEP1 STEP1 STEP1 #########################\n#                            MODEL TUNNING\n\n```{r}\nchurn$Attrition_Flag=ifelse(churn$Attrition_Flag==\"Attrited Customer\",\"l1\",\"l0\")\ntable(churn$Attrition_Flag)\nchurn_sheet<-churn\n```\n\n\n##              CREZIONE DELLE PARTIZIONI DI TRAIN & VALIDATION\n```{r}\nlibrary(caret)\nset.seed(1)\npartition_score<-createDataPartition(y=churn$Attrition_Flag,times=1,p=.95)\n?createDataPartition()\nchurn=churn[partition_score$Resample1,]\ntable(churn$Attrition_Flag)\nscore_churn=churn[-partition_score$Resample1,]\ntable(score_churn$Attrition_Flag)\n##########\nset.seed(1)\npartition<-createDataPartition(y=churn$Attrition_Flag,times=1,p=.7)\n?createDataPartition()\ntrain_churn=churn[partition$Resample1,]\ntest_churn=churn[-partition$Resample1,]\n\nstr(train_churn)\ntrain_churn$Attrition_Flag<-as.factor(train_churn$Attrition_Flag)\ntable(train_churn$Attrition_Flag)/nrow(train_churn)\n\nstr(test_churn)\ntest_churn$Attrition_Flag<-as.factor(test_churn$Attrition_Flag)\ntable(test_churn$Attrition_Flag)/nrow(test_churn)\n\nstr(score_churn)\nscore_churn$Attrition_Flag<-as.factor(score_churn$Attrition_Flag)\ntable(score_churn$Attrition_Flag)/nrow(score_churn)\n\n\n```\n\n\n## 2.a) RANDOM FOREST\n\nset.seed(1)\n   \n#?trainControl() - chiedere cosa cambia mettendo method=\"OOB\"\ncontrol <- trainControl(method=\"cv\",\n                        number=10,\n                        search=\"grid\",\n                        summaryFunction = twoClassSummary,\n                        classProbs = TRUE)\nrf_grid <- expand.grid(.mtry=c(1:round((length(variable.names(churn)))/3)))\nrandom_forest <- train(Attrition_Flag~., data=train_churn,\n                      method=\"rf\",\n                      tuneGrid=rf_grid,\n                      metric=\"Spec\",\n                      ntree=250,\n                      trControl=control)\n\nrandom_forest#tiene in memoria l'ultimo modello, tra l'altro risulta essere quello vincente!\nggplot(random_forest)\nconfusionMatrix(random_forest)\n\n```\n\n## 2.b) TREE BAGGING \n```{r}\nset.seed(1)\n\ncontrol <- trainControl(method=\"cv\",\n                        number=10,\n                        search=\"grid\",\n                        summaryFunction = twoClassSummary,\n                        classProbs = TRUE)\n\ntree_bagging <- train(Attrition_Flag ~ .,\n                            data = train_churn,\n                            method = \"treebag\",\n                            metric=\"Spec\",\n                            ntree=250,\n                            trControl = control)\n\ntree_bagging\nconfusionMatrix(tree_bagging)\n```\n\n\n## 2.c) GRADIENT BOOSTING\n```{r}\nset.seed(1)\ncontrol <- trainControl(method=\"cv\",\n                        number=10,\n                        search=\"grid\",\n                        summaryFunction = twoClassSummary,\n                        classProbs = TRUE)\ngbm_grid <-  expand.grid(interaction.depth = c(1,2,3,4,5,6,7,8,9),#profondità dell'albero \n                        n.trees = 50,#numero di alberi/iterazioni \n                        shrinkage = c(0.075,0.1,0.5,0.7),#learning rate/decay\n                        n.minobsinnode = 20)#numero minimo di soggetti per ogni nodo\ngradient_boost <- train(Attrition_Flag ~ ., data = train_churn, \n                 method = \"gbm\",\n                 tuneGrid=gbm_grid,\n                 metric=\"Spec\",\n                 trControl = control,\n                 verbose = FALSE)\n\ngradient_boost\ngradient_boost$bestTune#the best gbTree for Spec having shrink=0.5 and 8 int.depth\nggplot(gradient_boost)\nconfusionMatrix(gradient_boost)\n```\n\n## 3) NEURAL NETWORK\n```{r}\n#elimino variabile \"Avg_Utilization_Ratio\" \ntrain_churn_net<-train_churn[-19]\nlibrary(caret)\nset.seed(1)\n#Model Selction with classification tree\ncontrol <- trainControl(method = \"cv\", number=10, search=\"grid\", classProbs = TRUE, summaryFunction = twoClassSummary)\n\ntree_modsel_net <- train(Attrition_Flag ~ ., data =train_churn_net , method = \"rpart\",\n                      metric=\"Spec\",\n                      tuneLength = 10,\n                      trControl = control)\n\n# best accuracy using best cp\ntree_modsel_net\n\n\n\n# variables Importance\nvarImp(object=tree_modsel_net)\nplot(varImp(object=tree_modsel_net),main=\"train tuned - Variable Importance\")\n\n# select only important variables\nv_importance=as.data.frame(tree_modsel_net$finalModel$variable.importance)\nv_importance\ndim(v_importance)\n\n# select important var from dataset \nvi_name=row.names(v_importance)\nvi_name\nvi_name[11]<-\"Income_Category\"\nvi_name[14]<-\"Card_Category\"\nvi_name<-vi_name[-15]\nvi_name\n\n\n# save train and test with only selected/important covariates of the tree \ntrain_churn_net=train_churn[vi_name]\nnames(train_churn_net)\ntest_churn_net=test_churn[vi_name]\nnames(test_churn_net)\n# add target\ntrain_churn_net=cbind(train_churn[1], train_churn_net)\ntest_churn_net=cbind(test_churn[1], test_churn_net)\n\nhead(train_churn_net)\nhead(test_churn_net)\n\n#TUNNING NEURAL NET\nset.seed(1)\ncontrol = trainControl(method=\"cv\", number=10, search=\"grid\",  classProbs = T, summaryFunction=twoClassSummary)\nnnet_grid <- expand.grid(size=c(1:7), decay = c(0.05 , 0.1, 0.3, 0.5, 0.75))\nnnet_tree <- train(train_churn_net[-1], train_churn_net$Attrition_Flag,\n                         method = \"nnet\",\n                         preProcess = \"scale\", \n                         tuneLength = 10, \n                         trControl=control,\n                         metric = \"Spec\",\n                         tuneGrid=nnet_grid,\n                         trace = TRUE,\n                         maxit = 750)\n\n\n\n\nnnet_tree$results\nggplot(nnet_tree)\n```\n\n## 4) KNN\n\n```{r}\nlibrary(Boruta)\n\nset.seed(1)\ntrain_churn_knn_boruta<-train_churn[-19]#elimino variabile \"Avg_Utilization_Ratio\"\ntest_churn_knn_boruta<-test_churn[-19]\nboruta_train <- Boruta(Attrition_Flag~., data = train_churn_knn_boruta, doTrace = 1)\n\nplot(boruta_train, xlab = \"features\", xaxt = \"n\", ylab=\"MDI\")\n#' Three Blue boxplots correspond to minimal, average and maximum Z score of MDI of an attribute. \n\n#' Red un-important feature \n#' yellow tentative/at limit important feature \n#' green important feature\n\nprint(boruta_train)\n\n# boruta metrics on predictors#####\nboruta_metrics <- attStats(boruta_train)\nhead(boruta_metrics)\ntable(boruta_metrics$decision)\n\n\n# must select 49 vars...drop tantative and unimportant vars\nknn_selected=subset(boruta_metrics, decision==\"Confirmed\")\nhead(knn_selected)  \n#getSelectedAttributes(final.boruta, withTentative = F)\nsel=t(knn_selected)\n\n# select data from selected vars####\ntrain_churn_knn_boruta<-cbind(train_churn[1],train_churn_knn_boruta[,colnames(sel)])\ndim(train_churn_knn_boruta)\n\ntest_churn_knn_boruta<-cbind(test_churn[1],test_churn_knn_boruta[,colnames(sel)])\ndim(test_churn_knn_boruta)\n\n\n\nset.seed(1)\nlibrary(caret)\n\ncontrol <- trainControl(method = \"cv\", number=10, search=\"grid\", \n                       summaryFunction = twoClassSummary, \n                       classProbs = TRUE)\n\nknn <- train(Attrition_Flag ~., data=train_churn_knn_boruta,\n                 method = \"knn\", tuneLength = 10,\n                 preProcess = c(\"center\", \"scale\"),\n                 metric=\"Spec\",\n                 trControl = control)\nprint(knn)\n```\n\n\n```{r}\nset.seed(1)\nknn_boot <- train(Attrition_Flag ~., data=train_churn_knn_boruta,\n                 method = \"knn\",\n                 preProcess = c(\"center\", \"scale\"),\n                 tuneLength = 10, \n                 trControl = trainControl(method = \"boot\",\n                                          summaryFunction = twoClassSummary, \n                                          classProbs = TRUE), \n                                          metric=\"Spec\")\n\nprint(knn_boot)\n\n```\n\n\n## NAIVE BAYES\n\n```{r}\npredictors=c(\"Attrition_Flag\",\"Customer_Age\",\"Gender\",\"Dependent_count\",\"Education_Level\",\"Marital_Status\",\"Income_Category\",\"Card_Category\",\"Months_on_book\",\"Customer_Product\",\"Inactivity_Months\",\n\"Contacts\",\"Credit_Limit\",\"Total_Revolving_Bal\",\"Total_Amt_Chng_Q4_Q1\",\"Total_Trans_Amt\",\"Total_Trans_Ct\",\"Total_Ct_Chng_Q4_Q1\")\ntrain_churn_naive <- train_churn[predictors]  \ntest_churn_naive<-test_churn[predictors] \n\nnumeric_naive <- sapply(train_churn_naive, function(x) is.numeric(x))\nnumeric_naive <-train_churn_naive[, numeric_naive]\nAttrition_Flag=train_churn_naive$Attrition_Flag\nnumeric_naive <-cbind(numeric_naive, Attrition_Flag)\n\n\n\ncontrol = trainControl(method=\"cv\", number = 10, classProbs = T,\n                   summaryFunction=twoClassSummary)\n\nnaive=train(Attrition_Flag~.,\n                 data=train_churn_naive, method = \"naive_bayes\", metric=\"Spec\",\n                 trControl = control, tuneLength=10) \n\nnaive\n```\n\n## LASSO\n```{r}\nlibrary(caret)\nset.seed(1)\ncontrol=trainControl(method=\"cv\", number = 10, classProbs = T,\n                   summaryFunction=twoClassSummary)\nlasso_grid = expand.grid(.alpha=1,.lambda=c(0.1,0.25,0.5,0.75))\nlasso=train(Attrition_Flag~.,\n            data=train_churn, method = \"glmnet\",\n            trControl = control, tuneLength=5,\n            tuneGrid=lasso_grid, metric=\"Spec\")\nlasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"######################## STEP2 STEP2 STEP2 STEP2 STEP2 #########################\n\n\n#                         STEP 2 - CONFRONTO TRA MODELLI\n\n```{r}\nlibrary(caret)\nresults <- resamples(list(random_forest=random_forest, tree_bagging=tree_bagging, gradient_boost=gradient_boost,nnet_tree=nnet_tree, naive=naive, knn=knn))\nsummary(results)\nbwplot(results)\n\ntest_churn_step2<-test_churn\n\n\ntest_churn_step2$knn=predict(knn,test_churn, type=\"prob\")[,2]\ntest_churn_step2$naive=predict(naive,test_churn, \"prob\")[,2]\ntest_churn_step2$nnet_tree=predict(nnet_tree,test_churn, \"prob\")[,2]\ntest_churn_step2$gradient_boost=predict(gradient_boost,test_churn, \"prob\")[,2]\ntest_churn_step2$tree_bagging=predict(tree_bagging,test_churn, \"prob\")[,2]\ntest_churn_step2$random_forest=predict(random_forest,test_churn, \"prob\")[,2]\ntest_churn_step2$lasso=predict(lasso,test_churn, \"prob\")[,2]\n\nhead(test_churn_step2)\n\nlibrary(pROC)\n# See roc values ########\nroc_knn=roc(Attrition_Flag ~ knn, data = test_churn_step2)\nroc_naive=roc(Attrition_Flag ~ naive, data = test_churn_step2)\nroc_nnet_tree=roc(Attrition_Flag ~ nnet_tree, data = test_churn_step2)\nroc_gradient_boost=roc(Attrition_Flag ~ gradient_boost, data = test_churn_step2)\nroc_tree_bagging=roc(Attrition_Flag ~ tree_bagging, data = test_churn_step2)\nroc_random_forest=roc(Attrition_Flag ~ random_forest, data = test_churn_step2)\nroc_lasso=roc(Attrition_Flag ~ lasso, data = test_churn_step2)\n\n\nAUC<-cbind(roc_knn$auc,roc_naive$auc,roc_lasso$auc,roc_nnet_tree$auc,roc_gradient_boost$auc,roc_tree_bagging$auc,roc_random_forest$auc)\ncolnames(AUC)<-c(\"knn\",\"naive\",\"lasso\",\"nnet\",\"gboost\",\"tbagg\",\"rf\")\nrownames(AUC)<-\"AUC:\"\nAUC\n```\nPlottiamo le ROC curves dei vari classificatori per ogni soglia predetta\n```{r}\n\nplot(roc_knn,col=\"black\", xlab=\"FPR = {1-Specificity}\")\nplot(roc_naive,add=T,col=\"red\")\nplot(roc_nnet_tree,add=T,col=\"blue\")\nplot(roc_gradient_boost,add=T,col=\"brown\")\nplot(roc_tree_bagging,add=T,col=\"green\")\nplot(roc_random_forest,add=T,col=\"orange\")\nplot(roc_lasso,add=T,col=\"purple\")\nlegend( \"bottomright\", c(\"knn - AUC = 0.891087\",\n                         \"naive - AUC = 0.8738543\",\n                         \"lasso - AUC = 0.5\",\n                         \"nnet_tree - AUC = 0.9815\",\n                         \"gradient_boost - AUC = 0.992\",\n                         \"tree_bagging - AUC = 0.9875\",\n                         \"random_forest - AUC = 0.9924\"),\n                         col=c(\"black\", \"red\", \"purple\",\"blue\", \"brown\",\"green\",\"orange\"),\n                         cex=.8,box.col=\"green\",lty=1, lwd=4 )\n\n```\n\n\n```{r}\nposterior_gradient_boost = predict(gradient_boost, newdata = test_churn, type=\"prob\")\nposterior_gradient_boost=data.frame(posterior_gradient_boost)\nhead(posterior_gradient_boost)\n\n\n# find one column of interest\nposterior_l0=posterior_gradient_boost[,1]\nposterior_l1=posterior_gradient_boost[,2]\n\n# add to test data\ntest_churn$posterior_l0=posterior_l0\ntest_churn$posterior_l0=round(test_churn$posterior_l0, digits = 3)\ntest_churn$posterior_l1=posterior_l1\ntest_churn$posterior_l1=round(test_churn$posterior_l1, digits = 3)\n\nhead(test_churn)\n\n\n# extract mimimum elements for lift curves: target and predicted!!!########\ntest_minimal_elements=test_churn[,c(1,21)]\nhead(test_minimal_elements)\n\n\ntest_minimal_elements$breaks <- with(test_minimal_elements, cut(posterior_l1, \n          breaks=unique(quantile(posterior_l1, probs=seq(0,1, length= 13), type = 5, na.rm=TRUE)), include.lowest=TRUE))\n\n\n\ntest_minimal_elements$decile <- as.numeric(test_minimal_elements$breaks)  \n\ntest_minimal_elements$decile2 <- factor(11-test_minimal_elements$decile)          \n\nhead(test_minimal_elements)\ntable(test_minimal_elements$decile2)\n\n\n# find mean posterior in each decile....\nlibrary(dplyr)\ntest_minimal_elements %>%\n  group_by(decile2)%>%\n  summarise(m1  = mean(posterior_l1)) %>% arrange(-m1)\n\n```\n\n```{r}\nlibrary(funModeling)\n#gain_lift(data = test_minimal_elements, score = 'posterior_l1', target = 'Attrition_Flag')\ngain_lift(data = test_churn_step2, score = 'random_forest', target = 'Attrition_Flag')\n#stessi risultati\ngain_lift(data = test_churn_step2, score = 'tree_bagging', target = 'Attrition_Flag')\ngain_lift(data = test_churn_step2, score = 'nnet_tree', target = 'Attrition_Flag')\ngain_lift(data = test_churn_step2, score = 'gradient_boost', target = 'Attrition_Flag')\n\nprop.table(table(test_churn$Attrition_Flag))\n\n```\n\n```{r}\npred=predict(gradient_boost, test_churn)\nconfusionMatrix(pred, test_churn$Attrition_Flag)\n#1)MODELLO SURROGATO\npredProb_Attrited=predict(gradient_boost, train_churn, type=\"prob\")[,2]\nhead(predProb_Attrited)\n\nlibrary(gbm)\nlibrary(caret)\n\nImportance_gradient_boost<- varImp(gradient_boost ,numTrees=50)\nggplot(Importance_gradient_boost)\n\n\n# do a copy of df\ncopy=train_churn\ncopy$predProb_Attrited=predict(gradient_boost, train_churn, type=\"prob\")[,2]\ncopy$Attrition_Flag=NULL  \n\n# fit  a tree\nlibrary(rpart)\n\nset.seed(1) \ntree_surrogate <- rpart(predProb_Attrited ~ ., data = copy)\ntree_surrogate$cptable\n\nprun_surrogate <- prune(tree_surrogate, cp = 0.01)\n\n\npar(mfrow=c(1,1))\nlibrary(rpart.plot)\nrpart.plot(prun_surrogate, type = 4, tweak=2)\nmean(predProb_Attrited)\n\n#2)PARTIAL DEPENDENT PLOT (PDP)\nlibrary(DALEX)\n\n\n# find pred to be yes in the train data\npredProb_Attrited=predict(gradient_boost, train_churn, type=\"prob\")[,2]\nhead(predProb_Attrited)\nversion\nplot(Importance_gradient_boost)\nversion(gradient_boost)\nexplainer_rf  <- explain(gradient_boost, data = train_churn[-1], predict.function = predProb_Attrited)#is the same for all variables\n#PDP-Total_Trans_Amt\nprofile_rf_ttAMT  <- single_variable(explainer_rf, variable = \"Total_Trans_Amt\",  type = \"pdp\",\n                                 which.class = 2, prob = TRUE)\nplot(profile_rf_ttAMT)\n#PDP-Total_Trans_Ct \nprofile_rf_ttCT  <- single_variable(explainer_rf, variable = \"Total_Trans_Ct\",  type = \"pdp\",\n                                 which.class = 2, prob = TRUE)\nplot(profile_rf_ttCT)\n#PDP-Total_Revolving_Bal \nprofile_rf_trBAL  <- single_variable(explainer_rf, variable = \"Total_Revolving_Bal\",  type = \"pdp\",\n                                 which.class = 2, prob = TRUE)\nplot(profile_rf_trBAL)\n#PDP-Credit_Limit\nprofile_rf_cLIMIT  <- single_variable(explainer_rf, variable = \"Credit_Limit\",  type = \"pdp\",\n                                 which.class = 2, prob = TRUE)\nplot(profile_rf_cLIMIT)\n```\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"######################## STEP3 STEP3 STEP3 STEP3 STEP3 #########################\n```\n#                             STEP 3 - Maximize Spec\n\n```{r}\n# extract mimimum elements: target and predicted!!!########\ntarget_posterior=test_churn[,c(1,20)]\nhead(target_posterior)\n\n\n# for each threshold, find tp, tn, fp, fn and the sens=prop_true_l0, spec=prop_true_l1, precision=tp/(tp+fp)\nlibrary(dplyr)\nthresholds <- seq(from = 0, to = 1, by = 0.01)\nprop_table <- data.frame(threshold = thresholds, prop_true_l0 = NA,  prop_true_l1 = NA, true_l0 = NA,  true_l1 = NA ,fn_l0=NA)\n\nfor (threshold in thresholds) {\n  pred <- ifelse(target_posterior$posterior_l0 > threshold, \"l0\", \"l1\")  \n  pred_t <- ifelse(pred == target_posterior$Attrition_Flag, TRUE, FALSE)\n  \n  group <- data.frame(target_posterior, \"pred\" = pred_t) %>%\n    group_by(Attrition_Flag, pred) %>%\n    dplyr::summarise(n = n())\n  \n  group_l0 <- filter(group, Attrition_Flag == \"l0\")\n  \n  true_l0=sum(filter(group_l0, pred == TRUE)$n)\n  prop_l0 <- sum(filter(group_l0, pred == TRUE)$n) / sum(group_l0$n)\n  \n  prop_table[prop_table$threshold == threshold, \"prop_true_l0\"] <- prop_l0\n  prop_table[prop_table$threshold == threshold, \"true_l0\"] <- true_l0\n  \n  fn_l0=sum(filter(group_l0, pred == FALSE)$n)\n  prop_table[prop_table$threshold == threshold, \"fn_l0\"] <- fn_l0\n  \n  \n  group_l1 <- filter(group, Attrition_Flag == \"l1\")\n  \n  true_l1=sum(filter(group_l1, pred == TRUE)$n)\n  prop_l1 <- sum(filter(group_l1, pred == TRUE)$n) / sum(group_l1$n)\n  \n  prop_table[prop_table$threshold == threshold, \"prop_true_l1\"] <- prop_l1\n  prop_table[prop_table$threshold == threshold, \"true_l1\"] <- true_l1\n  \n}\n\nhead(prop_table, n=10)\n\n\n# now think to your best cell in the matrix ad decide the metric of interest##########\n##########\n#pred\t\n#true\tl0\t   l1\n#l0  \t TP\t  FN\n#l1     FP\t  TN\n##########\n\n# calculate other missing measures\n\n# n of observations of the validation set    \nprop_table$n=nrow(test_churn)\n\n# false positive (fp_l0) by difference of   n and            tn,                 tp,         fn, \nprop_table$fp_l0=nrow(test_churn)-prop_table$true_l1-prop_table$true_l0-prop_table$fn_l0\n\n# find precision\nprop_table$prec_l0=prop_table$true_l0/(prop_table$true_l0+prop_table$fp_l0)\n\n# find accuracy\nprop_table$acc=(prop_table$true_l1+prop_table$true_l0)/nrow(train_churn)\n\n# find F1 =2*(prec*sens)/(prec+sens)\nprop_table$F1=2*(prop_table$prop_true_l0*prop_table$prec_l0)/(prop_table$prop_true_l0+prop_table$prec_l0)\n\n# verify not having NA metrics at start or end of data \ntail(prop_table)\n# we have typically some NA in the precision and F1 at the boundary..put,impute 1,0 respectively \n\nlibrary(Hmisc)\n#impute NA as 0, this occurs typically for precision\nprop_table$prec_l0=impute(prop_table$prec_l0, 1)\nprop_table$F1=impute(prop_table$F1, 0)\ntail(prop_table)\n\ncolnames(prop_table)\n\n# drop counts, PLOT only metrics\nprop_table2 = prop_table[,-c(4:8)] \nhead(prop_table2)\n\n# plot measures vs soglia##########\n# before we must impile data vertically: one block for each measure\nlibrary(dplyr)\nlibrary(tidyr)\n\ngathered=prop_table2 %>%\n  gather(x, y, prop_true_l0:F1)\n\nhead(gathered)\n\n# plot measures \nlibrary(ggplot2)\ngathered %>%\n  ggplot(aes(x = threshold, y = y, color = x)) +\n  geom_point() +\n  geom_line() +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(y = \"measures\",\n       color = \"l0: event\\nl1: nonevent\")\n\n\n# zoom\ngathered %>%\n  ggplot(aes(x = threshold, y = y, color = x)) +\n  geom_point() +\n  geom_line() +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(y = \"measures\",\n       color = \"l0: event\\n l1: nonevent\") +\n  coord_cartesian(xlim = c(0.4, 0.7))\n\n\n# now you can choose the best threshold (using validated/test prob).##########\n# decide the decision rule.\ny=test_churn$Attrition_Flag\ny=ifelse(y==\"l0\",1,0)\n\n\npred_probrO=predict(gradient_boost,newdata=test_churn,type=c(\"prob\"))[,1]\n\nlibrary(ROCR)\npredR <- prediction(pred_probrO,y)\n\nz<-performance(predR,measure=\"spec\")\n#z@x.values ------ Valore della soglia\n#z@y.values ------ Valore della Specificity in corrispondenza della soglia\nspec<-cbind(z@x.values[[1]],z@y.values[[1]])\ncolnames(spec)<-c(\"Treshold\",\"Specificity\")\nspec<-as.data.frame(spec)#dataframe where for each row corresponding the estimate Treshold with relativity Specificity\n\n# maximize spec: threshold 0.75\nhead(target_posterior)\n\ntarget_posterior$decision=ifelse(target_posterior$posterior_l0>0.75,\"l0\",\"l1\")\n\n\ntable(target_posterior$Attrition_Flag,target_posterior$decision)\nspec_metric<- 434/(29+434)#Our specificity with threshold of 0.75\n################\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"######################## STEP4 STEP4 STEP4 STEP4 STEP4 #########################\n\n```\n\n#                               STEP 4 - SCORING\n\n```{r}\nscore_churn$prob = predict(gradient_boost, score_churn, \"prob\")\nhead(score_churn$prob)\nprobExist<-score_churn$prob[,1]\nscore_churn$pred_y=ifelse(probExist>0.75, \"Exist\",\"Attrited\")\nhead(score_churn[c(\"Attrition_Flag\",\"pred_y\")])\n\n# extract a new case\nnew_observation <- score_churn[14,]\nnew_observation$Attrition_Flag=NULL\nnew_observation\n\n# see the pred prob of yes such new case: we expect this value\n# when measuring contribution of vars to predictions for a new cases\npredProb=predict(gradient_boost, score_churn, type=\"prob\")[,2]\n\n# see pred probs to be yes for a new case\npredProb[14]\n\npredict.fun <- function(model, x) predict(model, x, type = \"prob\")[,2]\n\n# explain the prediction based on x profile\nlibrary(DALEX)\nlibrary(caret)\nlibrary(\"breakDown\")\nexplain_3 <- broken(gradient_boost, new_observation, data = train_churn, predict.function = predict.fun)\nexplain_3\n\nlibrary(ggplot2)\nplot(explain_3)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}