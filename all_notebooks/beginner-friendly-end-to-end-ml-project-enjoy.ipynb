{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Hi all.  üôã‚Äç‚ôÇÔ∏è \n\n#### I have recently published [Beginner Friendly Detailed Explained EDAs ‚Äì For anyone at the beginnings of DS/ML journey](https://www.kaggle.com/general/253911#1393015) series.\n\n#### After getting positive feedback and requests for Beginner-Intermediate Friendly Machine Learning series, I started to publish the Machine Learning Basic Series, which would help anyone who wants to learn or refresh the basics of ML.\n\n#### What we have covered: \n\n#### [BIAS & VARIANCE TRADEOFF](https://www.kaggle.com/kaanboke/ml-basics-bias-variance-tradeoff) ‚úîÔ∏è\n\n#### [LINEAR ALGORITHMS](https://www.kaggle.com/kaanboke/ml-basics-linear-algorithms)  ‚úîÔ∏è\n\n#### [NONLINEAR ALGORITHMS](https://www.kaggle.com/kaanboke/nonlinear-algorithms)  ‚úîÔ∏è\n\n#### [The Most Used Methods to Deal with MISSING VALUES](https://www.kaggle.com/kaanboke/the-most-used-methods-to-deal-with-missing-values)  ‚úîÔ∏è\n\n#### By this post, we are starting to implement machine learning algorithms.\n\n#### In this notebook we will step by step implement end to end machine learning project.\n\n#### We will use **classification algorithms with imbalanced data**, which will be very fun. **Enjoy** ü§ò\n\n","metadata":{}},{"cell_type":"markdown","source":"![](https://media.giphy.com/media/tkYpAbKdWj4TS/giphy.gif)","metadata":{}},{"cell_type":"markdown","source":"gif credit: https://giphy.com","metadata":{}},{"cell_type":"markdown","source":"#### **By the way, when you like the topic, you can show it by supporting** üëç\n\n####  **Feel free to leave a comment in the notebook**. \n\n\n#### All the best ü§ò","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*FUZS9K4JPqzfXDcC83BQTw.png)","metadata":{}},{"cell_type":"markdown","source":"Image Credit: https://miro.medium.com/","metadata":{}},{"cell_type":"markdown","source":"<a id=\"toc\"></a>\n\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\">Table of Contents</h3>\n    \n* [Data](#0)\n* [Exploratory Data Analysis](#1)\n    * [Insights from the First Glance](#2)\n    * [What Problem We Have?](#3)\n    * [Target Variable](#4)\n    * [Imbalance Data](#5)\n    * [Decide the Metric](#6)\n    * [Missing Values](#7)\n    * [Numerical Features](#8)\n    * [Categorical Features](#9)    \n    * [Bivariate Analysis](#10)\n    * [Insights from the Exploratory Data Analysis](#11)\n    \n    \n* [Model Selection](#12)    \n    * [Load the Data](#13)\n    * [Our Evaluation Model](#14)\n    * [Baseline Model](#15)\n    * [Our Models](#16)\n    * [Analyze the Models](#17)    \n    * [Visualize the Results](#18)\n    * [Our First Model](#19)    \n    * [Our Second Model with SMOTE](#20)\n\n\n* [Conclusion](#21)\n\n* [References & Further Reading](#22)\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"0\"></a>\n<font color=\"lightseagreen\" size=+2.5><b>Data</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"#### Stroke Prediction Dataset","metadata":{}},{"cell_type":"markdown","source":"![](https://expertchikitsa.com/wp-content/uploads/2017/05/stroke.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credit : https://expertchikitsa.com","metadata":{}},{"cell_type":"markdown","source":"**Context**\n\n- According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths. This dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.\n\n**Attribute Information**\n1. **id**: unique identifier\n\n2. **gender**: \"Male\", \"Female\" or \"Other\"\n\n3. **age**: age of the patient\n\n4. **hypertension**: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n\n5. **heart_disease**: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n\n6. **ever_married**: \"No\" or \"Yes\"\n\n7. **work_type**: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n\n8. **Residence_type**: \"Rural\" or \"Urban\"\n\n9. **avg_glucose_level**: average glucose level in blood\n\n10. **bmi**: body mass index\n\n11. **smoking_status**: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n\n12. **stroke**: 1 if the patient had a stroke or 0 if not\n\n*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient\n\nReference: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<font color=\"lightseagreen\" size=+2.5><b>Exploratory Data Analysis</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Let's import libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \n\n\n\nfrom sklearn.model_selection import KFold,cross_val_score, RepeatedStratifiedKFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.dummy import DummyClassifier\nfrom imblearn.over_sampling import SMOTE\n\n\nimport plotly \nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\nimport missingno as msno\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T11:40:29.451833Z","iopub.execute_input":"2021-08-10T11:40:29.45435Z","iopub.status.idle":"2021-08-10T11:40:33.615479Z","shell.execute_reply.started":"2021-08-10T11:40:29.45382Z","shell.execute_reply":"2021-08-10T11:40:33.614641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Read csv and see the top 5 instances of the data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndf=df.drop('id', axis=1)\ndf.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T11:40:33.617394Z","iopub.execute_input":"2021-08-10T11:40:33.618035Z","iopub.status.idle":"2021-08-10T11:40:33.686424Z","shell.execute_reply.started":"2021-08-10T11:40:33.617987Z","shell.execute_reply":"2021-08-10T11:40:33.685482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (f' We have {df.shape[0]} instances with the {df.shape[1]-1} features and 1 output variable')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:43:23.265617Z","iopub.execute_input":"2021-08-10T07:43:23.266017Z","iopub.status.idle":"2021-08-10T07:43:23.272338Z","shell.execute_reply.started":"2021-08-10T07:43:23.265982Z","shell.execute_reply":"2021-08-10T07:43:23.271016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T11:40:59.450615Z","iopub.execute_input":"2021-08-10T11:40:59.450971Z","iopub.status.idle":"2021-08-10T11:40:59.466146Z","shell.execute_reply.started":"2021-08-10T11:40:59.450941Z","shell.execute_reply":"2021-08-10T11:40:59.465347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:43:32.359383Z","iopub.execute_input":"2021-08-10T07:43:32.359782Z","iopub.status.idle":"2021-08-10T07:43:32.386549Z","shell.execute_reply.started":"2021-08-10T07:43:32.359747Z","shell.execute_reply":"2021-08-10T07:43:32.385084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Insights from the First Glance</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- In our dataset, we have both numerical and categorical variables.\n- It is essential to see whether columns are correctly inferred.\n- The most important one to look for is our target variable 'stroke'\n- 'Stroke' is detected as an integer, not as an object.\n- Target variable is coded as 1 for positive cases (has a stroke) and 0 for negative cases (does not have a stroke)\n- Both 'Hypertension' and 'heart disease\" are detected as an integer, not as an object. \n- Just remember from the data definition part, they are coded as 1 for the positive cases(has hypertension/heart disease) \n- And 0 for the negative cases (does not have hypertension/heart disease)\n- We don't need to change them, but it is good to see and be aware of it.\n- In addition to them, we have 3 categorical variables, which we have to encode as numerical.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>What Problem We Have?</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- We have binary classification problem.\n- We make prection on the target variable **STROKE**\n- And we will build a model to get best prediction on the stroke variable.","metadata":{}},{"cell_type":"markdown","source":"> ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Target Variable</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- One of the first steps of exploratory data analysis should always be to look at what the values of y look like.","metadata":{}},{"cell_type":"code","source":"y = df['stroke']\nprint(f'Percentage of patient had a stroke: % {round(y.value_counts(normalize=True)[1]*100,2)} --> ({y.value_counts()[1]} patient)\\nPercentage of patient did not have a stroke: % {round(y.value_counts(normalize=True)[0]*100,2)} --> ({y.value_counts()[0]} patient)')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:30:25.698444Z","iopub.execute_input":"2021-08-10T08:30:25.698994Z","iopub.status.idle":"2021-08-10T08:30:25.711932Z","shell.execute_reply.started":"2021-08-10T08:30:25.69896Z","shell.execute_reply":"2021-08-10T08:30:25.710243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Almost %95 of the instances of our target variable is 'No stroke'\n-  4861 patient does not have a stroke\n- %5  of the instances of our target variable is 'Stroke'\n- 249 patient have a stroke.\n\n- We have imbalanced data.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(df, x=\"stroke\", title='Stroke', width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:44:16.879529Z","iopub.execute_input":"2021-08-10T07:44:16.880021Z","iopub.status.idle":"2021-08-10T07:44:18.093371Z","shell.execute_reply.started":"2021-08-10T07:44:16.879978Z","shell.execute_reply":"2021-08-10T07:44:18.092524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Our  stroke dataset is an example of a so-called imbalanced dataset.\n- There are 19 times more people who didn‚Äôt have stroke in our data than who had, and we say that the non-stroke class dominates the stroke class.\n- We can clearly see that: the stroke rate in our data is 0.048\n- Which is a strong indicator of class imbalance","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Imbalance Data</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Instances across classes are imbalanced, like in our dataset, we have imbalance data.\n\n- The problem is, most of the machine learning algorithm do not work well with the imbalanced data.\n\n- Some of the metrics (like accuracy) give us misleading results.\n\n- Most of the time in classification problems our interest is to get better predict on the minority class.\n\n- In our example: People had a stroke is minority class.\n\n- Otherwise our machine learning algorithm falsely predicts majority class.\n\n- In our example: No stroke is majority class.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Decide the Metric</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- This is the first step when approaching a machine learning problem: decide the metric!\n\n- The choice of the wrong metric can mean choosing the wrong algorithm.\n\n- We see that the target is skewed and thus the best metric for this binary classification problem would be Area Under the ROC Curve (AUC). \n- We can use precision and recall too, but AUC combines these two metrics.\n\n- We have already seen the label/target distribution, and we know that it is a binary classification problem with skewed targets. Thus, we will be using StratifiedKFold to split the data\n\n- Just for further info, it is not advisable to use accuracy as an evaluation metric, when dealing with higly imbalanced data. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Missing Values</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Look for the detailed info on the missing values  ---> **[The Most Used Methods to Deal with MISSING VALUES](https://www.kaggle.com/kaanboke/the-most-used-methods-to-deal-with-missing-values)**","metadata":{}},{"cell_type":"code","source":"def missing (df):\n    missing_number = df.isnull().sum().sort_values(ascending=False)\n    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n    return missing_values\n\nmissing(df)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:44:30.408286Z","iopub.execute_input":"2021-08-10T07:44:30.408657Z","iopub.status.idle":"2021-08-10T07:44:30.438135Z","shell.execute_reply.started":"2021-08-10T07:44:30.408623Z","shell.execute_reply":"2021-08-10T07:44:30.43739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(df);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:44:37.408607Z","iopub.execute_input":"2021-08-10T07:44:37.409141Z","iopub.status.idle":"2021-08-10T07:44:38.335434Z","shell.execute_reply.started":"2021-08-10T07:44:37.40909Z","shell.execute_reply":"2021-08-10T07:44:38.334346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:44:46.579744Z","iopub.execute_input":"2021-08-10T07:44:46.580531Z","iopub.status.idle":"2021-08-10T07:44:47.225832Z","shell.execute_reply.started":"2021-08-10T07:44:46.580487Z","shell.execute_reply":"2021-08-10T07:44:47.224564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have missing values on the 'bmi', which is at around %4. \n- It seem that we have random missing values.\n- We will handle it by using pipeline during the modeling.","metadata":{}},{"cell_type":"markdown","source":"-Let's see our numerical and categorical features seperately.","metadata":{}},{"cell_type":"code","source":"categorical = ['gender', 'hypertension', 'heart_disease', 'ever_married',\n'work_type', 'Residence_type', 'smoking_status']\n\nnumerical = ['avg_glucose_level', 'bmi']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:30:35.52547Z","iopub.execute_input":"2021-08-10T08:30:35.525881Z","iopub.status.idle":"2021-08-10T08:30:35.531106Z","shell.execute_reply.started":"2021-08-10T08:30:35.525846Z","shell.execute_reply":"2021-08-10T08:30:35.530311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Numerical Features</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"df[numerical].describe()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:46:53.726606Z","iopub.execute_input":"2021-08-10T07:46:53.727029Z","iopub.status.idle":"2021-08-10T07:46:53.753818Z","shell.execute_reply.started":"2021-08-10T07:46:53.72699Z","shell.execute_reply":"2021-08-10T07:46:53.752906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have two numerical features in our dataset. \n\n- Both of our numerical features are measured in different scales.\n\n- Many machine learning algorithms perform better standard range scaled numerical variables (such as Linear models,artificial neural networks, K-nearest Neighbors,support vector machines, etc.) \n\n- Tree models (such as, decision trees,random forest, etc.) work fine with different range numerical features.\n\n- Based on the mean & median score differences, we can expect slightly right skew on the 'bmi' (mean: 28.89 & median: 28.10)\n- And right skew distribution on the 'avg_glucose_level' (mean: 106.14 & median: 91.88)\n\n- Let's see the skewness.","metadata":{}},{"cell_type":"markdown","source":"### **Skewness**","metadata":{}},{"cell_type":"code","source":"df[numerical].skew()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:47:01.439383Z","iopub.execute_input":"2021-08-10T07:47:01.439749Z","iopub.status.idle":"2021-08-10T07:47:01.451297Z","shell.execute_reply.started":"2021-08-10T07:47:01.439717Z","shell.execute_reply":"2021-08-10T07:47:01.450203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Based on the result, both of the fetures have right tail, positively skewed shape distribution.","metadata":{}},{"cell_type":"markdown","source":"### **Univariate Analysis**","metadata":{}},{"cell_type":"code","source":"df[numerical].hist(figsize=(6,4));","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:47:11.049052Z","iopub.execute_input":"2021-08-10T07:47:11.049436Z","iopub.status.idle":"2021-08-10T07:47:11.385651Z","shell.execute_reply.started":"2021-08-10T07:47:11.049407Z","shell.execute_reply":"2021-08-10T07:47:11.384414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As seen in both skewness result and histograms, numerical features have righ skewness in different degrees.\n- In case of positive skewness, and without zero values, **log transformations** usually works well.","metadata":{}},{"cell_type":"markdown","source":"- Before making the log transformation, let's see the correlation between them.","metadata":{}},{"cell_type":"code","source":"df[numerical].corr()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:20:54.317549Z","iopub.execute_input":"2021-08-10T08:20:54.318073Z","iopub.status.idle":"2021-08-10T08:20:54.329675Z","shell.execute_reply.started":"2021-08-10T08:20:54.318027Z","shell.execute_reply":"2021-08-10T08:20:54.328598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There is very small positive correlation between numerical features.","metadata":{}},{"cell_type":"markdown","source":"- Let' see their mean scores with the target variable","metadata":{}},{"cell_type":"code","source":"df.groupby('stroke')[numerical].mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:23:08.118937Z","iopub.execute_input":"2021-08-10T08:23:08.119339Z","iopub.status.idle":"2021-08-10T08:23:08.135671Z","shell.execute_reply.started":"2021-08-10T08:23:08.119308Z","shell.execute_reply":"2021-08-10T08:23:08.134113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- And the correlation with the target variable","metadata":{}},{"cell_type":"code","source":"df[['avg_glucose_level','bmi','stroke']].corr()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:27:07.169216Z","iopub.execute_input":"2021-08-10T08:27:07.169624Z","iopub.status.idle":"2021-08-10T08:27:07.185167Z","shell.execute_reply.started":"2021-08-10T08:27:07.16959Z","shell.execute_reply":"2021-08-10T08:27:07.183644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Average glucose level's mean scores have differences between a person who has a stroke or not.\n- Bmi mean scores are close to each other.\n- Corrleations with the target variable are very small. ","metadata":{}},{"cell_type":"markdown","source":"- Finally let's see the scatter plot","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(df, y='avg_glucose_level', x='bmi', title='Average Glucose Level & BMI ',color='stroke', hover_data = df[['stroke']])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:26:03.929674Z","iopub.execute_input":"2021-08-10T08:26:03.930102Z","iopub.status.idle":"2021-08-10T08:26:04.053255Z","shell.execute_reply.started":"2021-08-10T08:26:03.930044Z","shell.execute_reply":"2021-08-10T08:26:04.05208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Before moving to the categorical variable, let's put numerical features in order.","metadata":{}},{"cell_type":"code","source":"df[numerical] = np.log(df[numerical])\nprint(f'Skewness:{df[numerical].skew()}\\n')\ndf[numerical].hist(figsize=(6,4));","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:30:44.960096Z","iopub.execute_input":"2021-08-10T08:30:44.960677Z","iopub.status.idle":"2021-08-10T08:30:45.323069Z","shell.execute_reply.started":"2021-08-10T08:30:44.960641Z","shell.execute_reply":"2021-08-10T08:30:45.322016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[numerical].describe()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:30:48.907554Z","iopub.execute_input":"2021-08-10T08:30:48.907955Z","iopub.status.idle":"2021-08-10T08:30:48.930717Z","shell.execute_reply.started":"2021-08-10T08:30:48.907921Z","shell.execute_reply":"2021-08-10T08:30:48.929632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have much better distribution than before.\n- Both variables' mean and median scores are very close to each other\n- Both variables are in similar ranges.\n- Maximum and minum numbers are close to 25 % and 75 % quartiles.\n- Log transformation did a good job on this case.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Categorical Features</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"#### **Gender**","metadata":{}},{"cell_type":"code","source":"print (f'{round(df[\"gender\"].value_counts(normalize=True)*100,2)}')\nfig = px.histogram(df, x=\"gender\", title='Gender', width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:48:34.499521Z","iopub.execute_input":"2021-08-10T07:48:34.499939Z","iopub.status.idle":"2021-08-10T07:48:34.64181Z","shell.execute_reply.started":"2021-08-10T07:48:34.499901Z","shell.execute_reply":"2021-08-10T07:48:34.640376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have 2994 female and 2115 male and 1 other gender people.","metadata":{}},{"cell_type":"markdown","source":"#### Hypertension","metadata":{}},{"cell_type":"code","source":"print (f'{round(df[\"hypertension\"].value_counts(normalize=True)*100,2)}')\nfig = px.histogram(df, x=\"hypertension\", title='hypertension', width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:50:33.47929Z","iopub.execute_input":"2021-08-10T07:50:33.479687Z","iopub.status.idle":"2021-08-10T07:50:33.570319Z","shell.execute_reply.started":"2021-08-10T07:50:33.479653Z","shell.execute_reply":"2021-08-10T07:50:33.569227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have 498 patient with hypertension which represents at raound 10 % of the sample.","metadata":{}},{"cell_type":"markdown","source":"#### Heart Disease","metadata":{}},{"cell_type":"code","source":"print (f'{round(df[\"heart_disease\"].value_counts(normalize=True)*100,2)}')\nfig = px.histogram(df, x=\"heart_disease\", title='heart_disease', width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:51:47.967727Z","iopub.execute_input":"2021-08-10T07:51:47.96815Z","iopub.status.idle":"2021-08-10T07:51:48.063111Z","shell.execute_reply.started":"2021-08-10T07:51:47.968113Z","shell.execute_reply":"2021-08-10T07:51:48.061863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have 276 patient with heart disease which is 5.4 % of the sample.","metadata":{}},{"cell_type":"markdown","source":"#### Married","metadata":{}},{"cell_type":"code","source":"print (f'{round(df[\"ever_married\"].value_counts(normalize=True)*100,2)}')\nfig = px.histogram(df, x=\"ever_married\", title='ever_married', width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:52:40.282718Z","iopub.execute_input":"2021-08-10T07:52:40.283143Z","iopub.status.idle":"2021-08-10T07:52:40.419269Z","shell.execute_reply.started":"2021-08-10T07:52:40.283099Z","shell.execute_reply":"2021-08-10T07:52:40.417914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 3353 people have been married and 1757 people are not married before.","metadata":{}},{"cell_type":"markdown","source":"#### Work Type","metadata":{}},{"cell_type":"code","source":"print (f'{round(df[\"work_type\"].value_counts(normalize=True)*100,2)}')\nfig = px.histogram(df, x=\"work_type\", title='work_type', width=400, height=400)\nfig.update_layout(xaxis={'categoryorder':'total descending'})\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:55:05.239533Z","iopub.execute_input":"2021-08-10T07:55:05.240051Z","iopub.status.idle":"2021-08-10T07:55:05.387713Z","shell.execute_reply.started":"2021-08-10T07:55:05.240013Z","shell.execute_reply":"2021-08-10T07:55:05.38666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 2925 people work in the private sector.\n- 819 people are self-employed\n- 657 people work at the government job.\n","metadata":{}},{"cell_type":"markdown","source":"#### Residence Type","metadata":{}},{"cell_type":"code","source":"print (f'{round(df[\"Residence_type\"].value_counts(normalize=True)*100,2)}')\nfig = px.histogram(df, x=\"Residence_type\", title='Residence_type', width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:57:41.997684Z","iopub.execute_input":"2021-08-10T07:57:41.998157Z","iopub.status.idle":"2021-08-10T07:57:42.138367Z","shell.execute_reply.started":"2021-08-10T07:57:41.998107Z","shell.execute_reply":"2021-08-10T07:57:42.137182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 2596 people live in the urban area\n- 2514 people live in the rural area","metadata":{}},{"cell_type":"markdown","source":"#### Smoking","metadata":{}},{"cell_type":"code","source":"print (f'{round(df[\"smoking_status\"].value_counts(normalize=True)*100,2)}')\nfig = px.histogram(df, x=\"smoking_status\", title='smoking_status', width=400, height=400)\nfig.update_layout(xaxis={'categoryorder':'total descending'})\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T07:58:46.718796Z","iopub.execute_input":"2021-08-10T07:58:46.719187Z","iopub.status.idle":"2021-08-10T07:58:46.858047Z","shell.execute_reply.started":"2021-08-10T07:58:46.719155Z","shell.execute_reply":"2021-08-10T07:58:46.856982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 1892 people are never smoked\n- 789 people smoke","metadata":{}},{"cell_type":"markdown","source":"<a id=\"10\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Bivariate Analysis</b></font>\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n","metadata":{}},{"cell_type":"markdown","source":"#### **Hypertension & Stroke**","metadata":{}},{"cell_type":"code","source":"print (f'A person with hypertension has a probability of {round(df[df[\"hypertension\"]==1][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person without hypertension has a probability of  {round(df[df[\"hypertension\"]==0][\"stroke\"].mean()*100,2)} % get a stroke')\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:02:09.600333Z","iopub.execute_input":"2021-08-10T08:02:09.600755Z","iopub.status.idle":"2021-08-10T08:02:09.609987Z","shell.execute_reply.started":"2021-08-10T08:02:09.600709Z","shell.execute_reply":"2021-08-10T08:02:09.609078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"hypertension\", color=\"stroke\",width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:02:19.318823Z","iopub.execute_input":"2021-08-10T08:02:19.319211Z","iopub.status.idle":"2021-08-10T08:02:19.433103Z","shell.execute_reply.started":"2021-08-10T08:02:19.319179Z","shell.execute_reply":"2021-08-10T08:02:19.431976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we have seen, stroke probability for those who has hypertension are quite different than for those who don't.\n- %13.2 and %3.9 respectively\n- It means that **person with hypertension are almost 3.3 time more likely to get stroke than the ones who don't have hypertension**.","metadata":{}},{"cell_type":"markdown","source":"#### **Gender & Stroke**","metadata":{}},{"cell_type":"code","source":"print (f'A female person has a probability of {round(df[df[\"gender\"]==\"Female\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A male person has a probability of {round(df[df[\"gender\"]==\"Male\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person from  the other category of gender has a probability of {round(df[df[\"gender\"]==\"Other\"][\"stroke\"].mean()*100,2)} % get a stroke')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:04:10.929254Z","iopub.execute_input":"2021-08-10T08:04:10.929605Z","iopub.status.idle":"2021-08-10T08:04:10.943397Z","shell.execute_reply.started":"2021-08-10T08:04:10.929577Z","shell.execute_reply":"2021-08-10T08:04:10.94233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"gender\", color=\"stroke\",width=400, height=400)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:04:40.429433Z","iopub.execute_input":"2021-08-10T08:04:40.429804Z","iopub.status.idle":"2021-08-10T08:04:40.564339Z","shell.execute_reply.started":"2021-08-10T08:04:40.429769Z","shell.execute_reply":"2021-08-10T08:04:40.56356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Male compare to female are more likelyto get stroke, but difference between female and male is very small.**","metadata":{}},{"cell_type":"markdown","source":"#### **Heart Disease & Stroke**","metadata":{}},{"cell_type":"code","source":"print (f'A person with heart disease has a probability of {round(df[df[\"heart_disease\"]==1][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person without heart disease has a probability of {round(df[df[\"heart_disease\"]==0][\"stroke\"].mean()*100,2)} % get a stroke')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:05:28.527333Z","iopub.execute_input":"2021-08-10T08:05:28.527825Z","iopub.status.idle":"2021-08-10T08:05:28.537986Z","shell.execute_reply.started":"2021-08-10T08:05:28.527794Z","shell.execute_reply":"2021-08-10T08:05:28.537221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"heart_disease\", color=\"stroke\",width=400, height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T08:05:46.608955Z","iopub.execute_input":"2021-08-10T08:05:46.60966Z","iopub.status.idle":"2021-08-10T08:05:46.713942Z","shell.execute_reply.started":"2021-08-10T08:05:46.60959Z","shell.execute_reply":"2021-08-10T08:05:46.712799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we have seen, stroke probability for those who has heart disease are quite different than for those who don't.\n- % 17.03 and % 4.18 respectively\n- It means that **person with heart diease are 4.07 times more likely to get stroke than the ones who don't have heart disease.**","metadata":{}},{"cell_type":"markdown","source":"#### **Married & Stroke**","metadata":{}},{"cell_type":"code","source":"print (f'A person married (or married before) has a probability of {round(df[df[\"ever_married\"]==\"Yes\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person never married has a probability of {round(df[df[\"ever_married\"]==\"No\"][\"stroke\"].mean()*100,2)} % get a stroke')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:06:33.298738Z","iopub.execute_input":"2021-08-10T08:06:33.299145Z","iopub.status.idle":"2021-08-10T08:06:33.311456Z","shell.execute_reply.started":"2021-08-10T08:06:33.299113Z","shell.execute_reply":"2021-08-10T08:06:33.310157Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"ever_married\", color=\"stroke\",width=400, height=400)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:06:45.389315Z","iopub.execute_input":"2021-08-10T08:06:45.389802Z","iopub.status.idle":"2021-08-10T08:06:45.523636Z","shell.execute_reply.started":"2021-08-10T08:06:45.38977Z","shell.execute_reply":"2021-08-10T08:06:45.522929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we have seen, stroke probability for those who has marriage history are quite different than for those who don't.\n- % 6.56 and % 1.65 respectively\n- It means that **person is married(or married before) are 5.7 times more likely to get stroke than the ones who don't have marriage history**.","metadata":{}},{"cell_type":"markdown","source":"![](https://media.giphy.com/media/xT5LMzIK1AdZJ4cYW4/giphy.gif)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://giphy.com/","metadata":{}},{"cell_type":"markdown","source":"#### **Work Type & Stroke**","metadata":{}},{"cell_type":"code","source":"print (f'A person with private work type has a probability of {round(df[df[\"work_type\"]==\"Private\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'Self-employed person has a probability of {round(df[df[\"work_type\"]==\"Self-employed\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person with a goverment job has a probability of {round(df[df[\"work_type\"]==\"Govt_job\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A child has a probability of {round(df[df[\"work_type\"]==\"children\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person never worked has a probability of {round(df[df[\"work_type\"]==\"Never_worked\"][\"stroke\"].mean()*100,2)} % get a stroke')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:11:36.970588Z","iopub.execute_input":"2021-08-10T08:11:36.971148Z","iopub.status.idle":"2021-08-10T08:11:36.990745Z","shell.execute_reply.started":"2021-08-10T08:11:36.971115Z","shell.execute_reply":"2021-08-10T08:11:36.989814Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"work_type\", color=\"stroke\",width=600, height=600)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:11:44.799159Z","iopub.execute_input":"2021-08-10T08:11:44.799513Z","iopub.status.idle":"2021-08-10T08:11:44.93423Z","shell.execute_reply.started":"2021-08-10T08:11:44.799483Z","shell.execute_reply":"2021-08-10T08:11:44.93314Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- If you have never worked, you will not die by stroke !!! Just kidding.\n\n- Self employed person has more probability to get stroke than other work type.\n\n- Person with private job and goverment job almost has same probability to get stroke.","metadata":{}},{"cell_type":"markdown","source":"#### **Residence Type & Stroke**","metadata":{}},{"cell_type":"code","source":"print (f'A person, who lives in urban area, has a probability of {round(df[df[\"Residence_type\"]==\"Urban\"][\"stroke\"].mean()*100,2)} %  get a stroke')\n\nprint()\n\nprint (f'A person, who lives in rural area, has a probability of {round(df[df[\"Residence_type\"]==\"Rural\"][\"stroke\"].mean()*100,2)} % get a stroke')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:12:38.280025Z","iopub.execute_input":"2021-08-10T08:12:38.280663Z","iopub.status.idle":"2021-08-10T08:12:38.292429Z","shell.execute_reply.started":"2021-08-10T08:12:38.280628Z","shell.execute_reply":"2021-08-10T08:12:38.291472Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"Residence_type\", color=\"stroke\",width=400, height=400)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:12:45.609279Z","iopub.execute_input":"2021-08-10T08:12:45.609913Z","iopub.status.idle":"2021-08-10T08:12:45.747525Z","shell.execute_reply.started":"2021-08-10T08:12:45.609877Z","shell.execute_reply":"2021-08-10T08:12:45.746454Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As seen, there is not much difference between person residence type.\n- Person who lives in rural area slightly has more probablity to get sroke than a person who lives in rural area. Difference is small.","metadata":{}},{"cell_type":"markdown","source":"#### **Smoking & Stroke**","metadata":{}},{"cell_type":"code","source":"print (f'A formerly smoked person has a probability of {round(df[df[\"smoking_status\"]==\"formerly smoked\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person never smoked has a probability of {round(df[df[\"smoking_status\"]==\"never smoked\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person smokes has a probability of {round(df[df[\"smoking_status\"]==\"smokes\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()\n\nprint (f'A person whom smoking history is not known,has a probability of {round(df[df[\"smoking_status\"]==\"Unknown\"][\"stroke\"].mean()*100,2)} % get a stroke')\n\nprint()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:14:06.288463Z","iopub.execute_input":"2021-08-10T08:14:06.288818Z","iopub.status.idle":"2021-08-10T08:14:06.30756Z","shell.execute_reply.started":"2021-08-10T08:14:06.288788Z","shell.execute_reply":"2021-08-10T08:14:06.306499Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"smoking_status\", color=\"stroke\",width=600, height=600)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T08:14:45.55941Z","iopub.execute_input":"2021-08-10T08:14:45.559767Z","iopub.status.idle":"2021-08-10T08:14:45.701258Z","shell.execute_reply.started":"2021-08-10T08:14:45.559737Z","shell.execute_reply":"2021-08-10T08:14:45.700237Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are differeneces based on the smoking habits.\n- A formerly smoked person has a probability to get stroke 1.66 times more than person never smoked.\n- A person smokes has a a probability to get stroke 1.11 times more than person never smoked.\n- It is smal difference between who smokes and who does not smoke in regard to probability of getting stroke.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"11\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Insights from the Exploratory Data Analysis</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Average glucose level's mean scores on the target have differences between a person who has a stroke or not. But this differences are small.\n- BMI does not have any significant relationship with the target variable. \n- **A person with hypertension are almost 3.3 time more likely to get stroke than the ones who don't have hypertension**.\n- Male compare to female are more likelyto get stroke, but difference between female and male is very small.\n- **A person with heart diease are 4.07 times more likely to get stroke than the ones who don't have heart disease.**\n- **A person is married(or married before) are 5.7 times more likely to get stroke than the ones who don't have marriage history**.\n- Self employed person has more probability to get stroke than other work type. Be carefull !!!\n- Person who lives in rural area slightly has more probablity to get sroke than a person who lives in rural area. Difference is small.\n- It is smal difference between who smokes and who does not smoke in regard to probability of getting stroke.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"12\"></a>\n<font color=\"lightseagreen\" size=+2.5><b>MODEL SELECTION</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"![](https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs42003-019-0440-4/MediaObjects/42003_2019_440_Fig1_HTML.png)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.nature.com","metadata":{}},{"cell_type":"markdown","source":"#### Below code-snippets are mostly generated through https://machinelearningmastery.com. I have made changes and modified them to adjust to the problem at hand.\n\nReference : https://machinelearningmastery.com\n\n","metadata":{}},{"cell_type":"markdown","source":"- We will go step by step.\n  - We will load the data\n  - Then first we decide our evaluation method\n  - Then we will make baseline algorithm to give us lower limit\n  - Then we define our models\n  - We make our pipeline\n  - Analyze the models by evaluation results and boxplot.\n  - Decide which model perform the best in the evaluated models.\n  - We try to improve oour models.\n\n\n- Let's start.\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"13\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Load the Data</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n","metadata":{}},{"cell_type":"code","source":"# def load_data (df):\n  #  df=df.drop('id', axis=1)\n   # categorical = ['gender', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type', 'smoking_status']\n   # numerical = ['avg_glucose_level', 'bmi']\n   # df[numerical] = np.log(df[numerical])\n   # y= df['stroke']\n   # X = df.drop('stroke', axis=1)\n   # cat = X.select_dtypes(include=['object', 'bool']).columns\n   # ct = ColumnTransformer([('o',OneHotEncoder(),cat)], remainder='passthrough')\n   # X = ct.fit_transform(X)\n   # return X,y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We will design and test several models, for that reason, each time we will start fresh with the data load.\n- First we drop the 'id' column, which is not useful for our model.\n- We defined, categorical and numerical columns.\n- We made log transformation on the positively skewed and non zero value numerical features.\n- We defined our target variable and our features.\n- We encoded categorical variable in a manner to work with our machine learning algorithms.\n- We fit and transform them to use in our models.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"14\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Our Evaluation Model</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"# def evaluate_model(X, y, model):\n  #  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n   # scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n    # return scores\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:33:38.677272Z","iopub.execute_input":"2021-08-10T04:33:38.677689Z","iopub.status.idle":"2021-08-10T04:33:38.683228Z","shell.execute_reply.started":"2021-08-10T04:33:38.677651Z","shell.execute_reply":"2021-08-10T04:33:38.682513Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- K fold repeated stratified cross validation will be our evaluation tool for our proposed models.\n- 10 fold (n_splits=10) will be hold our instances.\n- Each fold will hold sample size / number of fold (5110 / 10) 511 instances.\n- Stratified version of k fold would be used to ensure both stroke and no stroke would be represented as their representation in the sample.\n- Each fold would have 5 % stroke and 95 % no stroke instances.\n- Better capture the variance of the chosen model, k fold evaluation process would be repeated 3 times. (n_repeats=3)\n- In a more detailed explanation: Each model will be evaluated n_splits * n_repeats time (10*3 =30) and the mean and standard deviation of these repeatations will be reported.\n- Models will be  evaluated and compared by using the area under ROC Curve or ROC AUC.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"15\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Baseline Model</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"#def load_data (df):\n #   df=df.drop('id', axis=1)\n  #  categorical = ['gender', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type', 'smoking_status']\n   # numerical = ['avg_glucose_level', 'bmi']\n   # df[numerical] = np.log(df[numerical])\n    #y= df['stroke']\n    #X = df.drop('stroke', axis=1)\n    #cat = X.select_dtypes(include=['object', 'bool']).columns\n    #ct = ColumnTransformer([('o',OneHotEncoder(),cat)], remainder='passthrough')\n    #X = ct.fit_transform(X)\n    #return X,y\n\n\n#def baseline_model(X, y, model):\n #   imputer = SimpleImputer(strategy='median')\n  #  model = DummyClassifier(strategy='constant', constant=1)\n   # pipeline = Pipeline(steps=[('imputer', imputer),('model', model)])\n   # cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n   # scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n   # return scores\n\n# df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\n#X,y= load_data(df)\n# model = DummyClassifier(strategy='constant', constant=1)\n# scores = baseline_model(X, y, model)\n# print('Mean roc_auc: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2021-08-10T09:09:56.619054Z","iopub.execute_input":"2021-08-10T09:09:56.619455Z","iopub.status.idle":"2021-08-10T09:09:59.681933Z","shell.execute_reply.started":"2021-08-10T09:09:56.619421Z","shell.execute_reply":"2021-08-10T09:09:59.680695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As name states, this our baseline model. \n- Any model gets better score than baseline has skill on our problem.\n- Any model gets lower score than baseline model, does not have skill on our problem.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"16\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Our Models</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n","metadata":{}},{"cell_type":"code","source":"#def get_models():\n #   models, names = list(), list()\n  #  models.append(LogisticRegression(solver='liblinear'))    \n   # names.append('LR')\n   # models.append(LinearDiscriminantAnalysis())\n   # names.append('LDA')\n   # models.append(SVC(gamma='scale'))\n   # names.append('SVM')\n   # models.append(RandomForestClassifier(n_estimators=1000))\n   # names.append('RF')\n   # models.append(GaussianNB())\n   # names.append('NB')\n   # return models, names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- First we have two list to contain models and their names\n- We decide to use several different Machine Learning classification algorithms.\n- We have defined them","metadata":{}},{"cell_type":"markdown","source":"<a id=\"17\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Analyze the Models</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n","metadata":{}},{"cell_type":"code","source":"# for i in range(len(models)):\n  #  imputer = SimpleImputer(strategy='median')  \n   # pipeline = Pipeline(steps=[('imputer', imputer), ('m', models[i])])    \n   # scores = evaluate_model(X, y, pipeline)\n   # results.append(scores)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In order to evaluate each model, we use for loop.\n- As  we have seen in the exploratory data nalysis part, our dataset has missing values.\n- Most of the machine learning algorithms do not work with the missing values.\n- We have decided to use median imputation.\n- To avoid data leakage we impute the missing values by using pipeline.\n- By using pipleline, model first impute the missing values in the training data and then repeat the process with the test data.\n- By using evaluate model function we have defined before, we evaluate each model and save their scores into score list.\n- By evaluating each model we will find out which algorithm works well with the problem in hand.\n- After finding the best algorithm, we will look deeper on that algorithm. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"18\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Visualize the Results</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"# plt.boxplot(results, labels=names, showmeans=True)\n# plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- After getting results, we will look at each Machine Learning algorithm by using box and whisker plots.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"19\"></a>\n<font color=\"lightseagreen\" size=+1.5><b> Our First Model </b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"def load_data (df):\n    df=df.drop('id', axis=1)\n    categorical = ['gender', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type', 'smoking_status']\n    numerical = ['avg_glucose_level', 'bmi']\n    df[numerical] = np.log(df[numerical])\n    y= df['stroke']\n    X = df.drop('stroke', axis=1)\n    cat = X.select_dtypes(include=['object', 'bool']).columns\n    ct = ColumnTransformer([('o',OneHotEncoder(),cat)], remainder='passthrough')\n    X = ct.fit_transform(X)\n    return X,y\n\n\ndef evaluate_model(X, y, model):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n    scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n    return scores\n\ndef get_models():\n    models, names = list(), list()\n    models.append(LogisticRegression(solver='liblinear'))    \n    names.append('LR')\n    models.append(LinearDiscriminantAnalysis())\n    names.append('LDA')\n    models.append(SVC(gamma='scale'))\n    names.append('SVM')\n    return models, names\n\ndf = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\nX,y= load_data(df)\nmodels, names = get_models()\nresults = list()\n\nfor i in range(len(models)):\n    imputer = SimpleImputer(strategy='median')  \n    pipeline = Pipeline(steps=[('imputer', imputer), ('m', models[i])])    \n    scores = evaluate_model(X, y, pipeline)\n    results.append(scores)\n    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n# plot the results\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T10:24:54.669104Z","iopub.execute_input":"2021-08-10T10:24:54.66966Z","iopub.status.idle":"2021-08-10T10:25:00.296713Z","shell.execute_reply.started":"2021-08-10T10:24:54.669609Z","shell.execute_reply":"2021-08-10T10:25:00.295505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The results suggest that logistic regression achieves a slightly better score than Linear Discriminant Analysis. \n- The distribution between the two top-performing models appears roughly equivalent, LR gets a slightly bigger mean score than LDA.\n-  A box and whisker plot is created summarizing the distribution of results. \n- All methods sshow skill on the problem., \n- SVM gave the worst performance, but let's see in our second model, how it performs?","metadata":{}},{"cell_type":"markdown","source":"<a id=\"20\"></a>\n<font color=\"lightseagreen\" size=+1.5><b> Our Second Model with SMOTE </b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"from imblearn.pipeline import Pipeline\n\ndef load_data (df):\n    df=df.drop('id', axis=1)\n    categorical = ['gender', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type', 'smoking_status']\n    numerical = ['avg_glucose_level', 'bmi']\n    df[numerical] = np.log(df[numerical])\n    y= df['stroke']\n    X = df.drop('stroke', axis=1)\n    cat = X.select_dtypes(include=['object', 'bool']).columns\n    ct = ColumnTransformer([('o',OneHotEncoder(),cat)], remainder='passthrough')\n    X = ct.fit_transform(X)\n    return X,y\n\n\ndef evaluate_model(X, y, model):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n    scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n    return scores\n\ndef get_models():\n    models, names = list(), list()\n    models.append(LogisticRegression(solver='liblinear'))    \n    names.append('LR')\n    models.append(LinearDiscriminantAnalysis())\n    names.append('LDA')\n    models.append(SVC(gamma='scale'))\n    names.append('SVM')\n    return models, names\n\ndf = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\nX,y= load_data(df)\nmodels, names = get_models()\nresults = list()\n# evaluate each model\nfor i in range(len(models)):\n    imputer = SimpleImputer(strategy='median')  \n    pipeline = Pipeline(steps=[('imputer', imputer),('over', SMOTE()), ('m', models[i])])    \n    scores = evaluate_model(X, y, pipeline)\n    results.append(scores)\n    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n# plot the results\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we have mentioned before, we have imbalanced data and majority class (no stroke) oversamples the examples.\n- To deal with we used stratified method to get percentages same in the examples (5% & 95%)\n- Synthetic Minority Oversampling Technique (SMOTE) deals with the imbalanced data by adding random minority class instances ( a stroke) by using k nearest (a stroke) neighbor.\n- In our second model we used SMOTE technique and increased the minority class representation to the same level with the majority class (no stroke)","metadata":{}},{"cell_type":"markdown","source":"- There is a significant jump on the SVM (from .588 to .833). \n- Very small changes on the LR and LDA \n- All methods still show skill on the problem. \n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"21\"></a>\n<font color=\"darkblue\" size=+1.5><b>Conclusion</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n","metadata":{}},{"cell_type":"markdown","source":"- We have developed model to predict classification problem.\n\n- First, we  made the detailed exploratory analysis.\n- We have decided which metric to use.\n- We analyzed both target and features in detail.\n- We transform categorical variables into numeric so we can use them in the model.\n- We transform numerical variables to reduce skewness and get close to normal  distribution.\n- We define our functions to use in our model.\n- We use cross validation model to evaluate our models.\n- We use pipeline to avoid data leakage.\n- We looked at the results of the each model and selected the best one for the problem in hand.\n- We have seen two different methods to use when developing model on the imbalanced data.\n\n- After this point it is up to you to develop and improve the models.  **Enjoy** ü§ò","metadata":{}},{"cell_type":"markdown","source":"![](https://media.giphy.com/media/6pUbJKgj2nI3GDytPN/giphy.gif)","metadata":{}},{"cell_type":"markdown","source":"#### By the way, when you like the topic, you can show it by supporting üëç\n\n####  **Feel free to leave a comment**. \n\n#### All the best ü§ò","metadata":{}},{"cell_type":"markdown","source":"<a id=\"22\"></a>\n<font color=\"darkblue\" size=+1.5><b>References & Further Reading</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n\n\n[Machine Learning - Beginner &Intermediate-Friendly BOOKS](https://www.kaggle.com/general/255972)","metadata":{}}]}