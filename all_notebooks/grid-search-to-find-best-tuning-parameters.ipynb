{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py"}},"nbformat":4,"cells":[{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a75e9475f91ef2c72c73853377de5610faadeddc","_cell_guid":"ed765350-0437-495c-a1aa-ac31bb81a8a6","collapsed":true},"source":"#import required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport seaborn as sns"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"scrolled":false},"source":"#load the input data using pandas\ndf = pd.read_csv('../input/data.csv')\ndf.head(3)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"#Split the data into training and test set\ntrain, test = train_test_split(df, random_state=42)\nX_train = train[train.columns[2:-1]]\ny_train = train['diagnosis']\nX_test = test[test.columns[2:-1]] \ny_test = test['diagnosis']"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"#Lets build a simple Linear SVC model and test it\n#SVC Models are good when the data is scaled. Lets scale the data and build the model\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nsvc_model = SVC(random_state=0).fit(X_train_scaled,y_train)\nprint(\"train score - \" + str(svc_model.score(X_train_scaled, y_train)))\nprint(\"test score - \" + str(svc_model.score(X_test_scaled, y_test)))"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"#Lets see the default parameters used\nprint(svc_model)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"#We can use a grid search to find the best parameters for this model. Lets try\n\n#Define a list of parameters for the models\nparams = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n\n#We can build Grid Search model using the above parameters. \n#cv=5 means cross validation with 5 folds\ngrid_search = GridSearchCV(SVC(random_state=0), params, cv=5, n_jobs=-1)\ngrid_search.fit(X_train_scaled, y_train)\n\nprint(\"train score - \" + str(grid_search.score(X_train_scaled, y_train)))\nprint(\"test score - \" + str(grid_search.score(X_test_scaled, y_test)))"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"#We got a better score now. Lets check the best parameters the model used.\nprint(grid_search.best_params_)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"#We can visualize the parameter dependency with the models\nresults_df = pd.DataFrame(grid_search.cv_results_)\nscores = np.array(results_df.mean_test_score).reshape(6, 6)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{},"source":"sns.heatmap(scores, annot=True, \n            xticklabels=params['gamma'], yticklabels=params['C'])"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"source":""}],"nbformat_minor":1}