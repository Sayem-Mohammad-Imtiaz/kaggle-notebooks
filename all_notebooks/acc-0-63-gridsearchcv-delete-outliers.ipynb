{"cells":[{"metadata":{},"cell_type":"markdown","source":"# UPDATE 14.03.21"},{"metadata":{},"cell_type":"markdown","source":"# IMPORT LIBS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport missingno as msno\n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)\n\n#import the necessary modelling algos.\n\n#classifiaction.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb\nfrom sklearn.ensemble import AdaBoostClassifier\n \n\n#regression\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nimport statsmodels.api as sm\nimport os\nimport random\n\n\n#model selection\nfrom sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n#preprocessing\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n\n#evaluation metrics\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA LOADING AND OVERVIEW"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/music-genre-classification/dataset.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['label']:\n    print(df[i].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['label'])\ndf = df.drop('filename', axis = 1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REMOVE OUTLIERS"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Thanks for the function https://www.kaggle.com/ankitak46\n\ndef remove_outliers(data):\n    arr=[]\n    #print(max(list(data)))\n    q1=np.percentile(data,25)\n    q3=np.percentile(data,75)\n    iqr=q3-q1\n    mi=q1-(1.5*iqr)\n    ma=q3+(1.5*iqr)\n    #print(mi,ma)\n    for i in list(data):\n        if i<mi:\n            i=mi\n            arr.append(i)\n        elif i>ma:\n            i=ma\n            arr.append(i)\n        else:\n            arr.append(i)\n    #print(max(arr))\n    return arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['chroma_stft'] = remove_outliers(df['chroma_stft'])\ndf['rmse'] = remove_outliers(df['rmse'])\ndf['spectral_centroid'] = remove_outliers(df['spectral_centroid'])\ndf['spectral_bandwidth'] = remove_outliers(df['spectral_bandwidth'])\ndf['rolloff'] = remove_outliers(df['rolloff'])\ndf['zero_crossing_rate'] = remove_outliers(df['zero_crossing_rate'])\ndf['mfcc1'] = remove_outliers(df['mfcc1'])\ndf['mfcc2'] = remove_outliers(df['mfcc2'])\ndf['mfcc3'] = remove_outliers(df['mfcc3'])\ndf['mfcc4'] = remove_outliers(df['mfcc4'])\ndf['mfcc5'] = remove_outliers(df['mfcc5'])\ndf['mfcc6'] = remove_outliers(df['mfcc6'])\ndf['mfcc7'] = remove_outliers(df['mfcc7'])\ndf['mfcc8'] = remove_outliers(df['mfcc8'])\ndf['mfcc9'] = remove_outliers(df['mfcc9'])\ndf['mfcc10'] = remove_outliers(df['mfcc10'])\ndf['mfcc11'] = remove_outliers(df['mfcc11'])\ndf['mfcc12'] = remove_outliers(df['mfcc12'])\ndf['mfcc13'] = remove_outliers(df['mfcc13'])\ndf['mfcc14'] = remove_outliers(df['mfcc14'])\ndf['mfcc15'] = remove_outliers(df['mfcc15'])\ndf['mfcc16'] = remove_outliers(df['mfcc16'])\ndf['mfcc17'] = remove_outliers(df['mfcc17'])\ndf['mfcc18'] = remove_outliers(df['mfcc18'])\ndf['mfcc19'] = remove_outliers(df['mfcc19'])\ndf['mfcc20'] = remove_outliers(df['mfcc20'])\n\nprint('Outliers successfully removed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('label', axis = 1)\ny = df.label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [LogisticRegression(),LinearSVC(),SVC(kernel='rbf'),KNeighborsClassifier(),RandomForestClassifier(),\n        DecisionTreeClassifier(),GradientBoostingClassifier(),GaussianNB()]\nmodel_names=['LogisticRegression','LinearSVM','rbfSVM','KNearestNeighbors','RandomForestClassifier','DecisionTree',\n             'GradientBoostingClassifier','GaussianNB']\n\nacc=[]\nd={}\n\nfor model in range(len(models)):\n    clf=models[model]\n    clf.fit(X_train,y_train)\n    pred=clf.predict(X_test)\n    acc.append(accuracy_score(pred,y_test))\n     \nd={'Modelling Algo':model_names,'Accuracy':acc}\nd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_frame=pd.DataFrame(d)\nacc_frame.sort_values(by = 'Accuracy', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(y='Modelling Algo',x='Accuracy',data=acc_frame.sort_values(by = 'Accuracy', ascending = False))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x='Modelling Algo',y='Accuracy',data=acc_frame.sort_values(by = 'Accuracy', ascending = False),kind='point',size=4,aspect=3.5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GRID SEARCH"},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_valid_scores = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_desicion_tree = DecisionTreeClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_desicion_tree = GridSearchCV(\n    model_desicion_tree, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_desicion_tree.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_desicion_tree.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \\\n    f'{model_desicion_tree.best_score_:.3f}'\n)\ncross_valid_scores['desicion_tree'] = model_desicion_tree.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25], \n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_random_forest = RandomForestClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_random_forest = GridSearchCV(\n    model_random_forest, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_random_forest.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_random_forest.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_random_forest.best_score_:.3f}'\n)\ncross_valid_scores['random_forest'] = model_random_forest.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25, 50, 75, 100], \n    \"learning_rate\": [0.001, 0.01, 0.1, 1.],\n}\n\nmodel_adaboost = AdaBoostClassifier(\n    random_state=42,\n)\n\nmodel_adaboost = GridSearchCV(\n    model_adaboost, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_adaboost.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_adaboost.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_adaboost.best_score_:.3f}'\n)\ncross_valid_scores['ada_boost'] = model_adaboost.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    'max_depth': [3, 5, 7, 9], \n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\n\nmodel_xgb = xgb.XGBClassifier(\n    random_state=42, verbosity = 0\n)\n\nmodel_xgb = GridSearchCV(\n    model_xgb, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_xgb.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_xgb.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_xgb.best_score_:.3f}'\n)\ncross_valid_scores['xgboost'] = model_xgb.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'num_leaves': [7, 15, 31],\n}\n\nmodel_lgbm = lgbm.LGBMClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_lgbm = GridSearchCV(\n    model_lgbm, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_lgbm.fit(\n    X_train, \n    y_train,\n)\n\nprint('-----')\nprint(f'Best parameters {model_lgbm.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_lgbm.best_score_:.3f}'\n)\ncross_valid_scores['lightgbm'] = model_lgbm.best_score_\nprint('-----')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"penalty\": [\"l1\", \"l2\"]\n}\n\nmodel_logistic_regression = LogisticRegression(\n    random_state=42,\n    class_weight=\"balanced\",\n    solver=\"liblinear\",\n)\n\nmodel_logistic_regression = GridSearchCV(\n    model_logistic_regression, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_logistic_regression.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_logistic_regression.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_logistic_regression.best_score_:.3f}'\n)\ncross_valid_scores['logistic_regression'] = model_logistic_regression.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n    \"gamma\": [\"scale\", \"auto\"],\n}\n\nmodel_svc = SVC(\n    random_state=42,\n    class_weight=\"balanced\",\n    probability=True,\n)\n\nmodel_svc = GridSearchCV(\n    model_svc, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_svc.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_svc.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_svc.best_score_:.3f}'\n)\ncross_valid_scores['svc'] = model_svc.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"weights\": [\"uniform\", \"distance\"],\n}\n\nmodel_k_neighbors = KNeighborsClassifier(\n)\n\nmodel_k_neighbors = GridSearchCV(\n    model_k_neighbors, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_k_neighbors.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {model_k_neighbors.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_k_neighbors.best_score_:.3f}'\n)\ncross_valid_scores['k_neighbors'] = model_k_neighbors.best_score_\nprint('-----')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame(cross_valid_scores, index=['cross_valid_score']).T\nround(submit.sort_values(by = 'cross_valid_score', ascending = False),3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thanks for watching!\n\n# If you liked my fork then upvoted or write your opinion"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}