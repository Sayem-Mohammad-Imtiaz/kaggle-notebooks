{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\n#from sklearn.pipeline import make_pipeline\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nimport plotly.express as px\nimport ipywidgets as widgets\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed=18453","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"># 1. DIABETES-DATA"},{"metadata":{},"cell_type":"markdown","source":"># 1.1. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"\n\nEl conjunto de datos que emplearemos es `diabetes`. Proviene del Instituto Nacional de Diabetes y enfermedades digestivas y renales. La base de datos está formada por varias variables predictoras y una variable objetivo,`Outcome`. El objetivo de esta base de datos es predecir si un paciente tiene diabetes o no, basándonos en las variables predictoras.\n\nPor tanto, nuestro conjunto de datos está formado por 8 variables predictoras y una variable objetivo. La variable objetivo `Outcome` consta de 768 instancias, tomando valores de 0 y 1. Nuestas variables predictoras son las siguientes:\n\n*     Número de veces preñada\n*     Glucosa\n*     Presión Sanguinea\n*     Espesor de la piel\n*     Insulina\n*     Índice de masa corporal\n*     Diabetes heredada\n*     Años\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath= \"../input/pima-indians-diabetes-database/diabetes.csv\"\ntarget = \"Outcome\"\n\ndata = utils.load_data(filepath,None,target)\ndata.index=range(data.shape[0])\ndata.sample(8,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como vemos, hemos cargado el conjunto de datos y hemos mostrado 8 instancias, obtenidas de forma aleatoria para evitar una muestra sesgada. A continuación, obtendremos nuestras variables predictoras por un lado y la variable objetivo por otro, con el fin de obtener una muestra de entrenamiento y una muestra de prueba."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")\nX.sample(5,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size= 0.7\n(X_train,X_test,y_train,y_test)= train_test_split(X,y,stratify=y,\n                                                  random_state=seed,train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nUna vez dividido nuestro conjunto de datos en entrenamiento y prueba, nos aseguraremos que funciona correctamente. Para ello, utilizaremos siempre la muestra de entrenamiento, evitando así una fuga de datos.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, uniremos las variables predictos con la variable clase, lo cual nos facilitará realizar operaciones más adelante."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train= utils.join_dataset(X_train,y_train)\ndata_test= utils.join_dataset(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y mostramos el data_train para comprobar si se ha realizado correctamente la unión."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(10,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"># 1.2. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{},"cell_type":"markdown","source":"En primer lugar, profundizaremos en la descripción del conjunto de datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos que nuestro conjunto de datos, efectivamente está formado por 9 variables, 8 predictoras y 1 objetivo. Además, obtendemos la información de que tenemos 537 casos."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos el tipo de nuestras variables. Observamos que las variables predictoras, de la muestra entrenamiento, son variables continuas. Además, podemos observar que todas tienen 537 instancias, que corresponde al 70% de la muestra de entrenamiento, por tanto, ninguna variable tiene valores perdidos. Por último, vemos que nuestra variable objetivo es una variable continua, con valores 0 y 1."},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"**Estudio de histogramas**"},{"metadata":{},"cell_type":"markdown","source":"En segundo lugar, proseguimos con un análisis de nuestras variables. Esto nos servirá para identificar posibles outliers y falicitarnos la tarea de preprocesar datos. Comenzaremos mostrando las distribuciones que siguen nuestras variables predictivas en un histograma."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nGenerado el histograma, veamos que sucede con cada variable predictora:\n\n*     Pregnancies: sigue una distribución normal.\n*     Glucosa: sigue una distribución normal. Aparecen registros con glucosa igual a 0, cosa que no puede suceder en una persona,         por tanto, se consideran dato ruidoso.\n*     Presión sanguinea: sigue una distribución normal. Sucede lo mismo que en el atributo glucosa, que aparecen datos ruidosos.\n*     Espesor de la piel: vemos que,existe un número elevado de registros con valor 0, pero, tras el ruido, sigue una distribución          normal.\n*     Insulina: ocurre exactamente lo mismo que con la variable \"Espesor de la piel\", pero esta presenta outliers.\n*     Indice de Masa Corporal: sigue una distribución normal, pero existen registros con valor 0.\n*     Diabetes heredada: sigue una distribución normal. Existen registros con valor 0, pero en este caso es algo coherente, porque existirán personas que no hereden la diabetes.\n*     Edad:sigue una distribución normal.\n\nPara confirmar que siguen una distribución normal, lo haremos con la gráfica Quantile-Quantile. Cuanto más cerca estén los puntos a la linea recta, mas parecida será su distrubición a la normal. (Para ver correctamente las representaciónes, pulsar en el boton ><, que aparece en la derecha tras ejectuar el código, para que se escondan los elementos, y volver a pulsarlo para ver correctamente las representaciones).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pylab\nimport scipy.stats as stats\n\na= list(X_train.columns.values)\n\n\nfor col in a:\n    print(col)\n    stats.probplot(X_train[col],dist=\"norm\",plot=pylab)\n    pylab.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver, las variables se asemejan con lo visto en los histogramas. Incluso con esta representación, vemos más claro los datos ruidosos y outliers en varias variables predictoras."},{"metadata":{},"cell_type":"markdown","source":"Hemos visto antes, que existen variables predictoras con datos ruidosos igual a 0, vamos a calcular el porcentaje que representan y decidiremos si imputar o eliminar dichas variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"a=X_train.loc[X_train['Glucose'] == 0].count()[1]\nprint((a/X_train.count()[1])*100)\na=X_train.loc[X_train['BloodPressure'] == 0].count()[1]\nprint((a/X_train.count()[1])*100)\na=X_train.loc[X_train['SkinThickness'] == 0].count()[1]\nprint((a/X_train.count()[1])*100)\na=X_train.loc[X_train['Insulin'] == 0].count()[1]\nprint((a/X_train.count()[1])*100)\na=X_train.loc[X_train['BMI'] == 0].count()[1]\nprint((a/X_train.count()[1])*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visto esto, vemos que con la insulina existe un 46% de datos ruidosos, por lo que eliminaremos dicha variable, porque no aporta suficiente información. Lo mismo haremos con la variable \"Espesor de la piel\". Mientras que, con las otras 3 variables, haremos una imputación."},{"metadata":{},"cell_type":"markdown","source":"**Detección de Outliers**"},{"metadata":{},"cell_type":"markdown","source":"En el apartado anterior, usando histogramas y diagramas Quantile-Quantile, vimos que algunas variables presentaban outliers. A continuación, realizaremos un estudio sobre ellos."},{"metadata":{"trusted":true},"cell_type":"code","source":"a= list(X_train.columns.values)\n\nfor col in a:\n    plt.title(col)\n    plt.boxplot(X_train[col], vert=False)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para la detección de outliers, hemos utilizado los diagramas de bigotes. Un diagrama de bigote es una caja, formado por el primer cuartil (Q1), que representa el inicio de la caja y es el valor por debajo del cual se encuentran el 25% de los datos; el tercerl cuartil (Q3), representa el final de la caja y es el valor por debajo del cual se encuentran el 75% de los datos; mediana, es la línea que se encuentra dentro de la caja. Con ello, podemos observar que las distintas varibles predictoras contienen outliers.\n\n*     Pregnancies: presenta tres outliers por encima del bigote superior.\n*     Glucosa: presenta un outlier por debajo del bigote inferior.\n*     Presión de la sangre: presenta varios outliers tanto por encima como por debajo.\n*     Espesor de la piel: no presenta outliers.\n*     Insulina: presenta una gran cantidad de outliers por encima del bigote superior.\n*     Indice de Masa Coporal: presenta varios outliers tanto por encima como por debajo.\n*     Diabetes heredada: presenta una gran cantidad de outliers por encima del bigote superior.\n*     Edad: presenta outliers por encima del bigote superior.\n\nEn el apartado de preprocesamiento eliminaremos los outliers, con el objetivo de tener más limpios nuestros datos.\n"},{"metadata":{},"cell_type":"markdown","source":"**Correlación de los datos**"},{"metadata":{},"cell_type":"markdown","source":"En este apartado, vamos a estudiar la correlación de nuestras variables predictoras. Nuestro objetivo será seleccionar las que tengan correlación, para luego representarlos en un pairplot."},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_mat=X_train.corr()\nsns.heatmap(correlation_mat,annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hemos generado una matriz cuadrada, que muestra la correlación entre cada par de variables predictoras. Además, muestra la medida de fuerza de asociación, de las cuales nos quedaremos con las correlaciones mayores y menores a 0.5, porque significa que existe correlación entre las variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_pairs = correlation_mat.unstack()\nsorted_pairs = corr_pairs.sort_values(kind=\"quicksort\")\ncorr_fuerte=sorted_pairs[((sorted_pairs > 0.5) & (sorted_pairs < 1)) | (sorted_pairs < -0.5)]\nprint(corr_fuerte)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que sólo existe correlación entre las variables `Pregnancies` y `Edad`."},{"metadata":{},"cell_type":"markdown","source":"**Pairplot**"},{"metadata":{},"cell_type":"markdown","source":"Realizaremos un pairplot, para observar que se distribuyen los registros, en base a la clase, para decidir que tipo de discretización realizaremos más adelante."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que para realizar la clasificación no es una tarea sencilla, porque hay una gran cantidad de información. Al haber tantos datos, lo mejor es descretizar en varios intervalos que en 2, por tanto, discretizaremos en 3 intervalos."},{"metadata":{},"cell_type":"markdown","source":" ># 1.3.  Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Una vez hecho el análisis exploratorio de datos, procederemos a realizar el preprocesamiento de datos. Con lo anteriormente visto, debemos imputar variables, eliminar outliers y realizar la discretización. Para ello nos ayudaremos de la creación de varios transformadores de datos, los cuales nos permitirán realizar las tareas descritas anteriormente."},{"metadata":{},"cell_type":"markdown","source":"#### Imputar Variables"},{"metadata":{},"cell_type":"markdown","source":"Utilizaremos el transformador `SimpleImputer`. Este nos permitirá imputar las variables BMI,Glucose y BloodPressure, es decir, en estas 3 variables sustituiremos los 0 por la media correspondiente a cada atributo. Para ello debemos utilizar un `ColumnTransformer`, por el cual nos permite realizar la imputación a las variables indicadas."},{"metadata":{"trusted":true},"cell_type":"code","source":"variables=['BMI','Glucose','BloodPressure']\n\nimputador= make_column_transformer(\n    (make_pipeline(\n        SimpleImputer(missing_values=0, strategy='median')\n    ),variables))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Eliminar columnas"},{"metadata":{},"cell_type":"markdown","source":"Visto en el análisis exploratorio, que las variables Insulin y SkinThickness tenían más del 20% de datos perdidos, eliminaremos dichas variables, porque no aportan información. Para ello debemos implementar nuestra propio transformador, el cual será dropVar, el cual se basa en eliminar las columnas que le lleguen como argumento. Hemos utilizado el siguiente [tutorial](https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156) para implementar la clase correctamente."},{"metadata":{"trusted":true},"cell_type":"code","source":"class dropVar():\n    \n    def __init__(self, column):\n        self.column=column\n    \n    def fit(self, x, y=None):\n        return self\n    \n    def transform(self, x, y=None):\n        cop=x.copy()\n        cop.drop(self.column,axis=1)\n        return cop","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Eliminar Outliers"},{"metadata":{},"cell_type":"markdown","source":"Vimos en el análisis exploratorio, concretamente en los diagramas de cajas y bigotes, que existen outliers en nuestras variables predictoras. Para reducir los outliers, implementaremos un método que se encargue de eliminar dichos outliers. Utilizaremos el transformador `FunctionSampler`, el cual utilizará el método outlier_rejection, para llevar a cabo la reducción de outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_rejection(X, y):\n    \n    model = IsolationForest(max_samples=100,\n                            contamination=0.4,\n                            random_state=seed)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Discretizador"},{"metadata":{},"cell_type":"markdown","source":"En la explicación de la práctica se nos explicó la importancia de discretizar variables, ya que, nos permitía que modelos lineales resuelvan problemas no lineales. Para ello utilizaremos el transformador `KBinsDiscretizer`. En el análisis de datos, no se apreciaba la forma más efectiva para dividir los datos, porque había una gran cantidad de registros. Al tener tanta información dispersada, lo mejor será construir 3 intervalos de igual anchura."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"># 1.4 Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"Llegados a este punto, debemos de declarar los algoritmos de clasificación que se nos pedía para esta práctica. Estos algoritmos son Zero-R y Árbol de Decisión (con y sin descritización)."},{"metadata":{},"cell_type":"markdown","source":"## Zero-R"},{"metadata":{},"cell_type":"markdown","source":"El algoritmo de Zero-R predice sobre la clase o categoría principal, del conjunto entrenamiento, a los nuevos casos."},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r=DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Algoritmo CART (Classification and Regression Trees): Inducción de árboles de decisión"},{"metadata":{},"cell_type":"markdown","source":"Es un algoritmo que sirve para clasificar utilizando particiones sucesivas. Es apropiado cuando hay un número elevado de datos, aportando un carácter descriptivo que permite entender e interpretar fácilmente las decisiones tomadas por el modelo. Primero creamos un árbol sin discretizar."},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Árbol discretizado"},{"metadata":{},"cell_type":"markdown","source":"Para realizar un clasificador discretizado, utilizaremos los Pipelines. Este toma como parámetros la lista de transformadores a aplicar al conjunto de datos y, al final de este, el estimador a utilizar. Para ello nuestros transformadores serán los descritos en el apartado 4. Crearemos tres pipelines, uno aplicando todos los transformadores, otro donde se apliquen todos menos el discretizador. Lo anterior nos servirá para evaluar nuestros modelos."},{"metadata":{"trusted":true},"cell_type":"code","source":"lista= ['Insulin','SkinThickness']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(dropVar(lista),imputador,FunctionSampler(func=outlier_rejection),discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model_cleaned= make_pipeline(dropVar(lista),imputador,FunctionSampler(func=outlier_rejection), tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"># 1.5. Evaluación de modelos."},{"metadata":{},"cell_type":"markdown","source":"Por último, nos queda entrenar nuestros modelos y validarlos. Comenzaremos con el Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Realizaremos lo mismo con los árboles de clasificación."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model_cleaned,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De estas validaciones podemos sacar las siguientes conclusiones:\n* El algoritmo de árboles de decisión funciona mejor que el Zero-R, como era de esperar.\n* El modelo de árbol de decisión, con los transformadores de limpieza, obtiene un 69% lo cual supone un 1% menos que el modelo de árbol de decisión. Esto significa que empeoramos el modelo realizando el proceso de limpieza, puede ser que se elimine información valiosa. Además, influye el factor de la semilla a la hora de realizar las divisiones en el árbol de decisión.\n* El modelo de árbol de decisión, discretizado y con todos los transformadores, obtiene un 71%, por tanto, obtenemos un mejor modelo que los 3 anteriores descritos. Esto se debe a que discretizamos de forma eficiente nuestro conjunto de datos. Al igual que antes, el factor de la semilla influye."},{"metadata":{},"cell_type":"markdown","source":"# 2. WINCONSIN-DATA"},{"metadata":{},"cell_type":"markdown","source":"# 2.1. Acceso y almacenamiento de datos"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 17102","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El conjunto de datos a tratar ahora es `wisconsin`. En este conjunto se detalla una bbdd en la que se examinan características de las células de un cáncer benigno o maligno. Encontramos 569 casos donde la variable objetivo, que denomina el tipo de cáncer`diagnosis`, puede ser:\n\n* `M = malignant`: Maligno\n* `B = benign`: Benigno\n\nPara determinar el tipo de cáncer se han tomado varias de las características que hacen referencia a la media, el error estándar y \"peor\" o mayor (media de los tres valores más grandes) para cada imagen de las células, resultando en 30 variables predictoras, todas ellas continuas:\n\n* `radius`: radio, distancia media desde el centro hasta los puntos del perímetro.\n* `texture`: textura, desviación estándar de los valores de la escala de grises.\n* `perimeter`: perímetro, suma de las longitudes del contorno de las figuras/formas.\n* `area`: concepto métrico que puede permitir asignar una medida a la extensión de una superficie.\n* `smoothness`: suavidad, variación local en longitudes de radio.\n* `compactness`: compacidad, (perímetro^2 / area - 1.0)\n* `concavity`: concavidad, severidad de las porciones cóncavas del contorno\n* `concave points`: puntos cóncavos, número de puntos cóncavos del contorno\n* `symmetry`: simetría\n* `fractal dimension`: dimensión fractal, (\"aproximación de la costa\" - 1)\n\nEl objetivo sería clasificar nuevos casos como malignos o benignos en función de sus propiedades."},{"metadata":{},"cell_type":"markdown","source":"Cargamos el conjunto de datos `wisconsin`"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindex = 'id'\ntarget = 'diagnosis'\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora comprobamos que la base de datos se ha cargado correctamente cargando los 5 ejemplos aleatorios"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar que por error se nos genera una última columna que, comprobando la descripción de nuestra base `wisconsin`,se debe a que en la última variable introduce una coma al final, lo que acaba generando una especie de \"variable vacía\" que eliminaremos"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns=['Unnamed: 32'])\ndata.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora separaemos nuestro conjunto de datos en 2, uno con las variables predictoras (X) y otro con la variable objetivo `diagnosis` (y)."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De nuevo, comprobamos que todo esté correcto"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para el análisis exploratorio hemos dividido nuestro conjunto de datos en 2 con los siguientes porcentajes:\n\n* Una muestra de entrenamiento (típicamente, 70%)\n* Una muestra de prueba (típicamente, 30%)\n"},{"metadata":{},"cell_type":"markdown","source":"Ahora aleatorizamos nuestros datos e iniciamos el proceso de holdout"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De nuevo, comprobamos que esta división se ha llevado a cabo correctamente"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.2. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de cualquier operación es indispensable identificar:\n* Número de casos\n* Número de variables\n    * Tipo de las variables: Continuas (t.c.c. numéricas) o discretas (t.c.c. categóricas)\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"(número de casos, númerero de variables): \",data.shape,'\\n') \nprint(\"información de las varibles:\\n\")\nprint(data.info(memory_usage=False))\nprint(\"\\nvalores de la variable objetivo: \\n\",y.cat.categories)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como ya hemos comentado, tenemos **569 casos** y **31 variables**, 30 discretas (`float64`) y 1 categórica (`category`) que es nuestra variable objetivo cuyos valores pueden ser `B`o `M`\n\nA parte también observamos que no existen nulos ya que la cuenta de todas las variables es el total, 569"},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"Para empezar con la visualización, vamos a observar la diferencia de casos que hay en la partición de entrenamientos referidas a la variable `diagnosis`"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creamos una variable auxiliar con todos los datos para las gráficas, como están ordenadas de la misma manera simplifica el resultado\nX_y_train = X_train[0:]\nX_y_train['diagnosis'] = y_train\nutils.plot_barplot(X_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar que abundan más casos donde el cáncer acaba siendo benigno (63% = 250) que maligno (37% = 148)"},{"metadata":{},"cell_type":"markdown","source":"Como ya hemos mencionado, esta bbdd tiene 30 variables, que realmente son 10, pero resultan en 30 debido a que se calculan en relación a la media, el error y la media de los 3 valores mas grandes. Luego para verlo mejor, dividiremos esta sección en 10 graficas, para que de esta forma puedan ser más visuales."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(X_train.columns)\n\nX_train1 = X_train[[cols[0]] + [cols[10]]+ [cols[20]]]\nutils.plot_histogram(X_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2 = X_train[[cols[1]] + [cols[11]] + [cols[21]]]\nutils.plot_histogram(X_train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train3 = X_train[[cols[2]] + [cols[12]] + [cols[22]]]\nutils.plot_histogram(X_train3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train4 = X_train[[cols[3]] + [cols[13]]+ [cols[23]]]\nutils.plot_histogram(X_train4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train5 = X_train[[cols[4]] + [cols[14]]+ [cols[24]]]\nutils.plot_histogram(X_train5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train6 = X_train[[cols[5]] + [cols[15]]+ [cols[25]]]\nutils.plot_histogram(X_train6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train7 = X_train[[cols[6]] + [cols[16]]+ [cols[26]]]\nutils.plot_histogram(X_train7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train8 = X_train[[cols[7]] + [cols[17]]+ [cols[27]]]\nutils.plot_histogram(X_train8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train9 = X_train[[cols[8]] + [cols[18]]+ [cols[28]]]\nutils.plot_histogram(X_train9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train10 = X_train[[cols[9]] + [cols[19]]+ [cols[29]]]\nutils.plot_histogram(X_train10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Las conclusiones que podemos sacar de estas gráficas son varias, comenzando con que todas las variables siguen más o menos (en algunos casos necesitamos ampliar para verlo) que las distribuciones tienen una tendencia en forma de campana, a parte, también podemos ver que las gráficas `mean` son semejantes entre si, lo mismo ocurre con `se` y `worst`.\n\nTambién podemos observar que los mayores outliers se encuentran en las gráficas de `mean` y `worst`"},{"metadata":{},"cell_type":"markdown","source":"Antes de echar un vistazo a las gráficas de discretización, vamos a inspeccionar todas variables para ver cómo evoluciona el cáncer dependiendo de los valores de dichas variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _plot_barplot2(variable, color):\n    fig = px.histogram(X_y_train, x=variable, color=color)\n    fig.show()\n\ncategorical_data = utils._filter_numerical_data(X_y_train)\nvar = categorical_data.columns\ndata = widgets.fixed(categorical_data)\n\nwidgets.interact(_plot_barplot2, variable=var,color=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo que primeramente podemos observar de estas gráficas es que los casos de beningno alcanzan valores `count` más altos en general que los de maligno, esto se debe a lo ya analizado anteriormente y es que tenemos más casos benignos que malignos luego es algo norlmal.\n\nRespecto a los valores hay algo que siguen la totalidad de las variables, esto es que a valores bajos siempre predominan los casos de benigno, mientras que a valores altos tenemos 2 opciones bastante reñidas, una es que más o menos estén en igualdad de casos o que el caso maligno predomine (hay algunas excepciones donde en valores altos predomina los casos benignos estos son `fractal_dimension_mean`, `fractal_dimension_se`), esto podría influir entonces a la hora de discretizar.\n\nOtra cosa bastante observable es que las gráficas describen figuras en forma de campana y en muchos casos también podemos darnos cuenta de como ambos casos, beningno y maligno, coinciden a la hora de crecer, el punto más alto y la disminución, como ocurre en `smoothness_mean`"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En las próximas gráficas podemos ver que las diagonales se corresponden con las anteriores, luego ya, llevamos algo de adelanto para la hora de discretizar. Nos quedaría el resto, luego:\n\n**¿Cuáles serían buenas variables para discretizar?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#MEAN\ncols = list(X_y_train.columns)\nX_y_train11 = X_y_train[[cols[-1]] + cols[0:10]]\nutils.plot_pairplot(X_y_train11, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el caso de `mean` podríamos discretizar por`radius_mean`, `perimeter_mean`, `area_mean` y `concave pointes_mean` (eje x) ya que al combinarlas con el resto de variables, estas 4 provocan que a mayor número de ellas, el cáncer sea maligno y a menor benigno, luego podriamos discretizar bastante bien con ellas. Además de que prácticamente no hay muchos outliers en estos casos, cosa que por ejemplo si ocurre en bastantes combinaciones de la variable `concavity_mean` (eje x)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#SE\nX_y_train12 = X_y_train[[cols[-1]] + cols[10:20]]\nutils.plot_pairplot(X_y_train12, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Respecto a los casos `se` podemos observar que de principio existen bastantes outliers en la mayoría de las gráficas, y que básicamente las discretizaciones podrían salir de`perimeter_se` y `area_se` (eje x) junto con todas sus combinaciones. Además algunas discretizaciones adicionales también podrían ser algunas combinaciones de `radius_se` (aunque nos puedan empeorar algo los outliers)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#WORST\nX_y_train13 = X_y_train[cols[20:]]\nutils.plot_pairplot(X_y_train13, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último los `worst`, existen batantes casos por los que se podría realizar una buena discretización, por ejemplo todas las combinaciones de las variables `radius_worst`, `perimeter_worst`, `area_worst`, `compactness_worst`, `concave points_worst`.\n\nA parte, ya no las voy a nombrar porque son muchísimas, el resto también tiene combinaciones de variables muy buenas para discretizar como es el caso de por ejemplo la combinación (x,y) (`texture_worst`,`area_worst`)."},{"metadata":{},"cell_type":"markdown","source":"# 2.3. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Dentro del preprocesamiento de datos, podemos destacar las siguientes tareas:\n\n* Limpieza de datos (imputación de valores perdidos, suavizado del ruido, etc.)\n* Integración de datos (a partir de múltiples fuentes)\n* Transformación de datos (normalización, construcción, etc.)\n* Reducción de datos (discretización de variables numéricas, selección de variables, selección de instancias, etc.)\n\nSin embargo siguiendo las directrices de la práctica, solo nos centraremos en la discretización de variables numéricas"},{"metadata":{},"cell_type":"markdown","source":"### Discretización"},{"metadata":{},"cell_type":"markdown","source":"Observando las gráficas, una discretización por anchura puede que no sea una buena manera, luego probaremos con frecuencia y a parte divideremos en más intervalos ya que viendo las gráficas al divirlas en más podremos dejar casos más aislados ya que la mezcla de variables, menigno y maligno, se encuentra más o menos cerca del centro y en los principios y finales de las gráficas suele predominar una variabble"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=4, strategy=\"quantile\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.4. Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"## Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Árbol de decisión"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *Pipeline*"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(FunctionSampler(func=outlier_rejection),discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model_1 = make_pipeline(discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.5. Evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"## Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Árbol de decisión sin discretización\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Árbol de decisión con discretización y filtrado"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Árbol de decisión con discretización sin filtrado"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model_1,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En estas evaluaciónes, podemos sacar las siguientes conclusiones:\n* El modelo obtenido del Zero-R es el peor, tal y como esperabamos, por su funcionamiento.\n* El árbol sin discretización obtiene un 95% de accuracy, siendo mejor que los modelos discretizados y con filtrado.\n* El árbol discretizado sin filtrado obtiene mejor modelo que el filtrado. Puede darse que, eliminando outliers afectamos a la discretización, por tanto, sin la eliminación de estos se discretiza mejor el conjunto de datos.\n\nUtilizar `Accuracy` no es lo más apropiado. Estamos diagnosticando una enfermedad, encima muy grave, no sería lo mismo fallar diagnosticando un cáncer benigno que maligno. Luego un método de validación sensible al coste, donde se penalizara más el equivocarnos al diagnosticar un cáncer, que debe ser maligno, tendría más sentido que utilizar el `Accuracy`."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}