{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n# Install java\n! apt-get update -qq\n! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n! java -version\n# Install pyspark\n! pip install --ignore-installed pyspark==2.4.5\n# Install Spark NLP\n! pip install --ignore-installed spark-nlp==2.7.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sparknlp\nspark = sparknlp.start()\nsparknlp.version()\nspark.version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.ml import Pipeline\nfrom sparknlp.annotator import *\nfrom sparknlp.common import *\nfrom sparknlp.base import *\nfrom pyspark.ml.feature import *\nfrom pyspark.ml.classification import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark_df = spark.read.option(\"header\", \"true\").option(\"multiLine\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"inferSchema\", \"true\").csv('../input/suicide-watch/Cleaned_Depression_Vs_Suicide.csv', sep = ',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark_df.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark_split_df = spark_df\n\n(train_data, test_data, val_data) = spark_split_df.randomSplit([0.1, 0.01, 0.8], 24)\n\nprint(\"Train length\", train_data.count())\nprint(\"Test length\", test_data.count())\nprint(\"validation length\", val_data.count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"document = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nuse = UniversalSentenceEncoder.pretrained() \\\n .setInputCols([\"document\"])\\\n .setOutputCol(\"sentence_embeddings\")\n\n# the classes/labels/categories are in category column\nsentimentdl = SentimentDLApproach()\\\n  .setInputCols([\"sentence_embeddings\"])\\\n  .setOutputCol(\"prediction\")\\\n  .setLabelColumn(\"class\")\\\n  .setMaxEpochs(20)\\\n  .setEnableOutputLogs(True)\n\npipeline = Pipeline(\n    stages = [\n        document,\n        use,\n        sentimentdl\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipelineModel = pipeline.fit(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pipelineModel.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\ndf = preds.select('class', 'text', \"prediction.result\").toPandas()\n\ndf['result'] = df['result'].apply(lambda x: x[0])\n\nprint(accuracy_score(df['class'], df.result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}