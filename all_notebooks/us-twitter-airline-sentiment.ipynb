{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79464c75-c324-41f2-91ea-a7d8062803a7"},"outputs":[],"source":"# This R environment comes with all of CRAN preinstalled, as well as many other helpful packages\n# The environment is defined by the kaggle/rstats docker image: https://github.com/kaggle/docker-rstats\n# For example, here's several helpful packages to load in \n\nlibrary(ggplot2) # Data visualization\nlibrary(readr) # CSV file I/O, e.g. the read_csv function\nlibrary(tm)\nlibrary(SnowballC)\nlibrary(RColorBrewer)\nlibrary(wordcloud)\nlibrary(biclust)\nlibrary(cluster)\nlibrary(igraph)\nlibrary(fpc)\n\n\nlibrary(gridExtra)\nlibrary(cowplot)\nlibrary(reshape2)\nlibrary(scales)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nsystem(\"ls ../input\")\n\n# Any results you write to the current directory are saved as output.\n########################################################################\n# LOAD THE DATASET\n########################################################################\nairline = read.csv(\"../input/Tweets.csv\")\nstr(airline)\n\n\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96e55a86-d3dd-43b2-9577-06cd388cc459"},"outputs":[],"source":"########################################################################\n# 1. HISTOGRAM PLOT\n########################################################################\n# 1. Plot of summary global sentiment.\noverallSentiment = as.data.frame(table(airline$airline_sentiment))\ncolnames(overallSentiment) = c(\"Sentiment\",\"Freq\")\n\nhistPlot1 = ggplot(overallSentiment) + aes(x=Sentiment, y=Freq, fill=Sentiment) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\nhistPlot1 = histPlot1 + geom_bar(stat=\"identity\")\nhistPlot1\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e2950f9-9ff7-4678-9a6d-dad1e3c51a06"},"outputs":[],"source":"########################################################################\n# 2. BREAKDOWN FOR COMPANIES\n########################################################################\n# 2. Repeat the histogram plot but showing the number of tweets + sentiment\n#    each airline has.\n\nairlineSentiment = as.data.frame(table(airline$airline,airline$airline_sentiment))\ncolnames(airlineSentiment) = c(\"Airline\",\"Sentiment\",\"Freq\")\n#airlineSentiment\n\ncolours = c(\"firebrick1\",\"deepskyblue\",\"chartreuse3\")\n\nhistPlot2 = ggplot(airlineSentiment) + aes(x=Airline,y=Freq,fill=Sentiment) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\nhistPlot2 = histPlot2 + geom_bar(stat=\"identity\") \nhistPlot2"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c891db9-b358-4b9b-b2b6-11be388dc287"},"outputs":[],"source":"# 2.1. Individual pie charts for each Airline\n# AMERICAN AIRLINES ##############################################\nsentAmerican = subset(airlineSentiment, Airline == \"American\")\nAmerican = ggplot(sentAmerican) + aes(x=\"American\", y=Freq, fill=Sentiment) +\n     geom_bar(stat=\"identity\") +\n     coord_polar(\"y\") +\n     theme(axis.text.x=element_text(color=\"black\")) +\n     theme(axis.ticks=element_blank(), axis.title=element_blank(), axis.text.y=element_blank())\n\ny.breaks = cumsum(sentAmerican$Freq) - sentAmerican$Freq/2\n\nAmerican = American + scale_y_continuous(breaks=y.breaks, labels=sentAmerican$Sentiment) +\n    ggtitle(\"American\") + theme(plot.title = element_text(face=\"bold\")) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\n\n# DELTA AIRLINES  #####################################################\nsentDelta = subset(airlineSentiment, Airline == \"Delta\")\nDelta = ggplot(sentDelta) + aes(x=\"Delta\", y=Freq, fill=Sentiment) +\n  geom_bar(stat=\"identity\") +\n  coord_polar(\"y\") +\n  theme(axis.text.x=element_text(color=\"black\")) +\n  theme(axis.ticks=element_blank(), axis.title=element_blank(), axis.text.y=element_blank())\n\ny.breaks = cumsum(sentDelta$Freq) - sentDelta$Freq/2\n\nDelta = Delta + scale_y_continuous(breaks=y.breaks, labels=sentDelta$Sentiment) +\n  ggtitle(\"Delta\") + theme(plot.title = element_text(face=\"bold\")) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\n\n# SOUTHWEST AIRLINES  #####################################################\nsentSouthwest = subset(airlineSentiment, Airline == \"Southwest\")\nSouthwest = ggplot(sentSouthwest) + aes(x=\"Southwest\", y=Freq, fill=Sentiment) +\n  geom_bar(stat=\"identity\") +\n  coord_polar(\"y\") +\n  theme(axis.text.x=element_text(color=\"black\")) +\n  theme(axis.ticks=element_blank(), axis.title=element_blank(), axis.text.y=element_blank())\n\ny.breaks = cumsum(sentSouthwest$Freq) - sentSouthwest$Freq/2\n\nSouthwest = Southwest + scale_y_continuous(breaks=y.breaks, labels=sentSouthwest$Sentiment) +\n  ggtitle(\"Southwest\") + theme(plot.title = element_text(face=\"bold\")) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\n\n# UNITED AIRLINES  #####################################################\nsentUnited = subset(airlineSentiment, Airline == \"United\")\nUnited = ggplot(sentUnited) + aes(x=\"United\", y=Freq, fill=Sentiment) +\n  geom_bar(stat=\"identity\") +\n  coord_polar(\"y\") +\n  theme(axis.text.x=element_text(color=\"black\")) +\n  theme(axis.ticks=element_blank(), axis.title=element_blank(), axis.text.y=element_blank())\n\ny.breaks = cumsum(sentUnited$Freq) - sentUnited$Freq/2\n\nUnited = United + scale_y_continuous(breaks=y.breaks, labels=sentUnited$Sentiment) +\n  ggtitle(\"United\") + theme(plot.title = element_text(face=\"bold\")) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\n\n  # VIRGIN AMERICA  #####################################################\nsentVAirways = subset(airlineSentiment, Airline == \"Virgin America\")\nVAirways = ggplot(sentVAirways) + aes(x=\"Virgin America\", y=Freq, fill=Sentiment) +\n  geom_bar(stat=\"identity\") +\n  coord_polar(\"y\") +\n  theme(axis.text.x=element_text(color=\"black\")) +\n  theme(axis.ticks=element_blank(), axis.title=element_blank(), axis.text.y=element_blank())\n\ny.breaks = cumsum(sentVAirways$Freq) - sentVAirways$Freq/2\n\nVAirways = VAirways + scale_y_continuous(breaks=y.breaks, labels=sentVAirways$Sentiment) +\n  ggtitle(\"Virgin America\") + theme(plot.title = element_text(face=\"bold\")) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\n\n# US AIRWAYS  #####################################################\nsentUSAirways = subset(airlineSentiment, Airline == \"US Airways\")\nUSAirways = ggplot(sentUSAirways) + aes(x=\"US Airways\", y=Freq, fill=Sentiment) +\n  geom_bar(stat=\"identity\") +\n  coord_polar(\"y\") +\n  theme(axis.text.x=element_text(color=\"black\")) +\n  theme(axis.ticks=element_blank(), axis.title=element_blank(), axis.text.y=element_blank())\n\ny.breaks = cumsum(sentUSAirways$Freq) - sentUSAirways$Freq/2\n\nUSAirways = USAirways + scale_y_continuous(breaks=y.breaks, labels=sentUSAirways$Sentiment) +\n  ggtitle(\"US Airways\") + theme(plot.title = element_text(face=\"bold\")) + scale_fill_manual(values=c(\"indianred1\",\"deepskyblue\",\"chartreuse3\"))\n\n\nplot_grid(American,Delta,Southwest,United,VAirways,USAirways,ncol=2,nrow=3) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89ba9f29-c6a1-4142-a914-a6e95e488e81"},"outputs":[],"source":"########################################################################\n# 3. BREAKDOWN FOR COMPANIES\n########################################################################\n# 3. In this case we are looking to understand the reasons behind each\n#    sentiment for each airline\n\n# Initial Global analysis\n#str(airline)\ntable(airline$negativereason, airline$airline)\n\nglobalSentReasons = as.data.frame(table(airline$negativereason, airline$airline))\ncolnames(globalSentReasons) = c(\"Reason\",\"Airline\", \"Freq\")\n#globalSentReasons\n\nggplot(globalSentReasons) + aes(y = Freq, x = Reason, group = Airline, colour = Airline) + coord_polar() + geom_point() + geom_path() + labs(x = NULL)\n\n\n## TYRING TO CALCULATE PERCENTAGES\naggregate(Freq ~ Airline, globalSentReasons, sum)\nglobalSentReasons$TotalTwAirline = 0\nglobalSentReasons[1:11,4] = 2759\nglobalSentReasons[12:22,4] = 2222\nglobalSentReasons[23:33,4] = 2420\nglobalSentReasons[34:44,4] = 3822\nglobalSentReasons[45:55,4] = 2913\nglobalSentReasons[56:66,4] = 503\nglobalSentReasons$PercentOfTotal = (globalSentReasons[,3]/globalSentReasons[,4])*100\n\nggplot(globalSentReasons) + aes(y = PercentOfTotal, x = Reason, group = Airline, colour = Airline) + coord_polar() + geom_point() + geom_path() + labs(x = NULL)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68e2e83e-c43d-4c72-ab73-1bc6873f18e3"},"outputs":[],"source":"########################################################################\n# 4. UNDERSTANDING TEXT\n########################################################################\n# Globally understand which terms come together when analysing\n# negative and positive sentiment.\nstr(airline)\n\n########################################################################\n# NEGATIVE SENTIMENT\n########################################################################\nnegativeSubset = subset(airline, airlineSentiment == \"negative\")\nstr(negativeSubset)\n\n\n########################################################################\n# 4.1. PRE-PROCESSING THE DATA - CREATING THE CORPUS AND CLEANING\n########################################################################\n\n#### \ncorpus = Corpus(VectorSource(negativeSubset$text))\nstrwrap(corpus[[8]])\ncorpus <- tm_map(corpus, stripWhitespace)\nstrwrap(corpus[[8]])\ncorpus <- tm_map(corpus, content_transformer(tolower))\nstrwrap(corpus[[8]])\n\n# Remove stopwords\ncorpus = tm_map(corpus, removeWords, stopwords(\"english\"))\nstrwrap(corpus[[8]])\n# Want to get rid of @virginamerica, @usairways, @united, @@southwestair, @jetblue, @americanair\ncorpus <- tm_map(corpus, function(x) gsub('@', 'KeepAtPunct', x))\nstrwrap(corpus[[8]])\ncorpus = tm_map(corpus, removeWords, c(\"KeepAtPunctvirginamerica\",\"KeepAtPunctusairways\",\"KeepAtPunctunited\",\"KeepAtPunctsouthwestair\",\"KeepAtPunctjetblue\",\"KeepAtPunctamericanair\"))\nstrwrap(corpus[[8]])\n\n\n# We want to keep #\n# 1. Replace # --> GarciaParrenoJose\ncorpus <- tm_map(corpus, function(x) gsub('#', 'KeepHashPunct', x))\nstrwrap(corpus[[8]])\n\n# Remove remaining punctuation\ncorpus <- tm_map(corpus, removePunctuation)\nstrwrap(corpus[[8]])\n\n\n# Revert replacements\ncorpus <- tm_map(corpus, function(x) gsub('KeepAtPunct', '@', x))\ncorpus <- tm_map(corpus, function(x) gsub('KeepHashPunct', '#', x))\nstrwrap(corpus[[8]])\n\n# Remove \"x.\"\n# corpus <- tm_map(corpus, function(x) gsub('x.', '', x))\n\n# Remove all http links\ncorpus <- tm_map(corpus, function(x) gsub('http[[:alnum:]]*', '', x))\nstrwrap(corpus[[8]])\n\n# We dont want to remove numbers in case it states something like 3 hours late\n# corpus <- tm_map(corpus, removeNumbers)\n\n# Stem the document\ncorpus = tm_map(corpus, stemDocument)\ncorpus = tm_map(corpus, PlainTextDocument)\nstrwrap(corpus[[8]])\n\n########################################################################\n# 4.2. CREATING THE MATRIX\n########################################################################\n\n# Create matrix\ndtm = DocumentTermMatrix(corpus)\ndtm"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d5eac68a-e428-4a35-83f0-f061275bbce2"},"outputs":[],"source":"##########################################################################\n## 4.3. DESCRIPTIVE ANALYTICS\n##########################################################################\n\nfreq = colSums(as.matrix(dtm)) \nord = order(freq)\n\nwf = data.frame(word=names(freq), freq=freq)   \n\np = ggplot(subset(wf, freq>50), aes(word, freq, fill = freq))    \np = p + geom_bar(stat=\"identity\", show.legend = TRUE)   \np = p + theme(axis.text.x=element_text(angle=45, hjust=1, size = rel(1)))   \np "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e8a08b3-f2d3-467d-b87f-974358bfef66"},"outputs":[],"source":"###########################################################################\n## 4.4. CONVERTING TO DATA FRAME\n###########################################################################\ntweets = as.data.frame(as.matrix(dtm))\ncolnames(tweets) = make.names(colnames(tweets))\ntweets$airline_sentiment = negativeSubset$airline_sentiment\n#str(tweets)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6decfc40-e6ca-4f2d-b0a7-bed5a3ea3930"},"outputs":[],"source":"###########################################################################\n## 4.5. HIERARCHICAL CLUSTERING\n###########################################################################\n## CLUSTERING BY TERM SIMILARITY - HIERARCHICAL CLUSTERING\n\nsparse = removeSparseTerms(dtm, 0.97)\nsparse\n\nlibrary(cluster)\nd <- dist(t(sparse), method = \"euclidian\")\nfit <- hclust(d=d, method=\"ward.D\")\nfit\nplot(fit, hang=-1)\ngroups <- cutree(fit, k=5)   \nrect.hclust(fit, k=5, border=\"red\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4518c4f6-6027-477e-8f91-6a89e5bc8731"},"outputs":[],"source":"########################################################################\n# POSITIVE SENTIMENT\n########################################################################\npositiveSubset = subset(airline, airlineSentiment == \"positive\")\nstr(positiveSubset)\n\n\n########################################################################\n# 4.1. PRE-PROCESSING THE DATA - CREATING THE CORPUS AND CLEANING\n########################################################################\n\n#### \ncorpus = Corpus(VectorSource(positiveSubset$text))\nstrwrap(corpus[[8]])\ncorpus <- tm_map(corpus, stripWhitespace)\nstrwrap(corpus[[8]])\ncorpus <- tm_map(corpus, content_transformer(tolower))\nstrwrap(corpus[[8]])\n\n# Remove stopwords\ncorpus = tm_map(corpus, removeWords, stopwords(\"english\"))\nstrwrap(corpus[[8]])\n# Want to get rid of @virginamerica, @usairways, @united, @@southwestair, @jetblue, @americanair\ncorpus <- tm_map(corpus, function(x) gsub('@', 'KeepAtPunct', x))\nstrwrap(corpus[[8]])\ncorpus = tm_map(corpus, removeWords, c(\"KeepAtPunctvirginamerica\",\"KeepAtPunctusairways\",\"KeepAtPunctunited\",\"KeepAtPunctsouthwestair\",\"KeepAtPunctjetblue\",\"KeepAtPunctamericanair\"))\nstrwrap(corpus[[8]])\n\n\n# We want to keep #\n# 1. Replace # --> GarciaParrenoJose\ncorpus <- tm_map(corpus, function(x) gsub('#', 'KeepHashPunct', x))\nstrwrap(corpus[[8]])\n\n# Remove remaining punctuation\ncorpus <- tm_map(corpus, removePunctuation)\nstrwrap(corpus[[8]])\n\n\n# Revert replacements\ncorpus <- tm_map(corpus, function(x) gsub('KeepAtPunct', '@', x))\ncorpus <- tm_map(corpus, function(x) gsub('KeepHashPunct', '#', x))\nstrwrap(corpus[[8]])\n\n# Remove \"x.\"\n# corpus <- tm_map(corpus, function(x) gsub('x.', '', x))\n\n# Remove all http links\ncorpus <- tm_map(corpus, function(x) gsub('http[[:alnum:]]*', '', x))\nstrwrap(corpus[[8]])\n\n# We dont want to remove numbers in case it states something like 3 hours late\n# corpus <- tm_map(corpus, removeNumbers)\n\n# Stem the document\ncorpus = tm_map(corpus, stemDocument)\ncorpus = tm_map(corpus, PlainTextDocument)\nstrwrap(corpus[[8]])\n\n\n########################################################################\n# 4.2. CREATING THE MATRIX\n########################################################################\n\n# Create matrix\ndtm = DocumentTermMatrix(corpus)\ndtm"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"efc12530-b258-4c32-a69d-91ee35604341"},"outputs":[],"source":"##########################################################################\n## 4.3. DESCRIPTIVE ANALYTICS\n##########################################################################\n\nfreq = colSums(as.matrix(dtm)) \nord = order(freq)\n\nwf = data.frame(word=names(freq), freq=freq)   \n\np = ggplot(subset(wf, freq>50), aes(word, freq, fill = freq))    \np = p + geom_bar(stat=\"identity\", show.legend = TRUE)   \np = p + theme(axis.text.x=element_text(angle=45, hjust=1, size = rel(1)))   \np \n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8f8a490-dc31-4aa4-a8dd-bb27a4e5fded"},"outputs":[],"source":"###########################################################################\n## 4.4. CONVERTING TO DATA FRAME\n###########################################################################\ntweets = as.data.frame(as.matrix(dtm))\ncolnames(tweets) = make.names(colnames(tweets))\ntweets$airline_sentiment = negativeSubset$airline_sentiment\n#str(tweets)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89270438-c609-470d-ad19-bd2d2baecc40"},"outputs":[],"source":"###########################################################################\n## 4.5. HIERARCHICAL CLUSTERING\n###########################################################################\n## CLUSTERING BY TERM SIMILARITY - HIERARCHICAL CLUSTERING\n\nsparse = removeSparseTerms(dtm, 0.97)\nsparse\n\nlibrary(cluster)\nd <- dist(t(sparse), method = \"euclidian\")\nfit <- hclust(d=d, method=\"ward.D\")\nfit\nplot(fit, hang=-1)\ngroups <- cutree(fit, k=3)   \nrect.hclust(fit, k=3, border=\"green\")"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}