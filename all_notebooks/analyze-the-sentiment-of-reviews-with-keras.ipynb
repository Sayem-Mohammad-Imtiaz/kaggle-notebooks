{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Keras is an open-source Python library that dramatically simplifies the building of neural networks.With Keras, you can build sophisticated neural networks with just a few dozen lines of code and train them to classify images, analyze text for sentiment, do natural-language processing, and perform other tasks at which deep learning excels.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Keras is to build a neural network that scores text for sentiment","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.datasets import imdb\ntop_words = 10000\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variable named x_train is a list of 25,000 lists, each of which represents one movie review. (x_test is also a list of 25,000 lists representing 25,000 reviews. x_train will be used for training, while x_test will be used for testing.) But the inner lists — the ones representing movie reviews — don't contain words; they contain integers.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The reason the inner lists contain numbers rather than text is that you don't train a neural network with text; you train it with numbers. Specifically, you train it with tensors. In this case, each review is a 1-dimensional tensor (think of a 1-dimensional array) containing integers identifying the words contained in the review.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The first number in the list — 1 — doesn't represent a word at all. It marks the start of the review and is the same for every review in the dataset. The numbers 0 and 2 are reserved as well, and you subtract 3 from the other numbers to map an integer in a review to the corresponding integer in the dictionary. The second number — 14 — references the word that corresponds to the number 11 in the dictionary, the third number represents the word assigned the number 19 in the dictionary, and so on.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb.get_word_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Show the first review in x_train in textual format","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"word_dict = imdb.get_word_index()\nword_dict = { key:(value + 3) for key, value in word_dict.items() }\nword_dict[''] = 0  # Padding\nword_dict['>'] = 1 # Start\nword_dict['?'] = 2 # Unknown word\nreverse_word_dict = { value:key for key, value in word_dict.items() }\nprint(' '.join(reverse_word_dict[id] for id in x_train[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When you train a neural network with collection of tensors, each tensor needs to be the same length. At present, the lists representing reviews in x_train and x_test have varying lengths.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fortunately, Keras includes a function that takes a list of lists as input and converts the inner lists to a specified length by truncating them if necessary or padding them with 0s. Enter the following code into the notebook and run it to force all the lists representing movie reviews in x_train and x_test to a length of 500 integers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import sequence\nmax_review_length = 500\nx_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\nx_test = sequence.pad_sequences(x_test, maxlen=max_review_length)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a neural network that performs sentiment analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Flatten\n\nembedding_vector_length = 32\nmodel = Sequential()\nmodel.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\nmodel.add(Flatten())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1] * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function to analyze for other sentences","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport numpy as np\n\ndef analyze(text):\n    # Prepare the input by removing punctuation characters, converting\n    # characters to lower case, and removing words containing numbers\n    translator = str.maketrans('', '', string.punctuation)\n    text = text.translate(translator)\n    text = text.lower().split(' ')\n    text = [word for word in text if word.isalpha()]\n\n    # Generate an input tensor\n    input = [1]\n    for word in text:\n        if word in word_dict and word_dict[word] < top_words:\n            input.append(word_dict[word])\n        else:\n            input.append(2)\n    padded_input = sequence.pad_sequences([input], maxlen=max_review_length)\n\n    # Invoke the model and return the result\n    result = model.predict(np.array([padded_input][0]))[0][0]\n    return result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"analyze('Easily the most stellar experience I have ever had.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analyze('The long lines and poor customer service really turned me off.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}