{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input columns:\ndataset.iloc[:,:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output column:\ndataset['DEATH_EVENT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']\nnumerical_columns = ['age', 'creatinine_phosphokinase', 'ejection_fraction', \n                     'platelets', 'serum_creatinine', 'serum_sodium', 'time'],","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Significant correlation with DEATH_EVENT observed for the following features:\n* Age: 0.253729\n* Serum creatinine: 0.294278 \n* Serum sodium: -0.195204\n* Time:  -0.526964\n* Ejection Fraction: -0.268603 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(x=\"DEATH_EVENT\", data=dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of deaths are half that of the number of patients alive, i.e. 100 deaths against 200 alive.\nThis data needs to be balanced, via oversampling of the minority class(deaths) or undersampling the majority class(alive).\n\nHere, we use the SMOTE technique to oversample the minority class.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\noversampling_func = SMOTE(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To oversample the dataset needs to split into X and y\nX = dataset.iloc[:,:-1]\ny = dataset[[\"DEATH_EVENT\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Size of dataset before oversampling: \"+str(len(X)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SMOTE is used to oversample X and y, and are saved into new data frames X_smote and y_smote.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_smote, y_smote = oversampling_func.fit_resample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote_dataset = pd.concat((X_smote,y_smote),axis=1) # X_smote and y_smote are combined to create the countplot below","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"DEATH_EVENT\", data=smote_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of SMOTE dataset: '+str(len(X_smote)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote_dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Significant correlation with DEATH_EVENT observed for the following features:\n\n* Age\n* Serum creatinine\n* Serum sodium\n* Time\n* Ejection Fraction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Only the significant features observed in the correlation are captured here. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"age\", \"serum_creatinine\", \"serum_sodium\", \"time\", \"ejection_fraction\"]\ninput_data = smote_dataset[features]\noutput_data = smote_dataset[\"DEATH_EVENT\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size = 0.2, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the features like age, serum_sodium, serum_creatinine are on different scales, the data is scaled, using StandardScaler. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[0:5]  # Training data after scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[0:5]  # Testing data after scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier(max_depth=15, random_state = 42)\nrf_clf.fit(X_train, y_train)\ny_pred = rf_clf.predict(X_test)\nrf_acc = accuracy_score(y_test, y_pred)\nprint(\"Accuracy of Random Forest Classifier: \"+str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterating through various K Nearest Neighbours Classifiers \nfrom sklearn.neighbors import KNeighborsClassifier\nacc_list = []\nmax_val = 0\nfor neighbours in range(1,41):\n    knn_clf = KNeighborsClassifier(n_neighbors=neighbours)\n    knn_clf.fit(X_train, y_train)\n    y_pred = knn_clf.predict(X_test)\n    accuracy_val = accuracy_score(y_test, y_pred)\n    acc_list.append(int(accuracy_val))\n    print(str(neighbours)+\": \"+str(accuracy_val))\n    if accuracy_val > max_val:\n        no_of_neighbours = neighbours\n        max_val = accuracy_val\n        \nprint(\"Optimal number of neighbours: \"+str(no_of_neighbours)+\" with accuracy \"+str(max_val))\nknn_acc = max_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_clf = SVC(random_state=42)\nsvc_clf.fit(X_train, y_train)\ny_pred = svc_clf.predict(X_test)\nprint(\"Accuracy of SVM classifier \"+str(accuracy_score(y_test, y_pred)))\nsvc_acc = accuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_list=[svc_acc,knn_acc,rf_acc]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Maximum Accuracy achieved: \"+str(max(acc_list)))\nprint(\"Accuracy of various classifiers:\")\nprint(\"* SVM Classifier: \"+str(svc_acc))\nprint(\"* KNN Classifier: \"+str(knn_acc))\nprint(\"* Random Forest Classifier: \"+str(rf_acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}