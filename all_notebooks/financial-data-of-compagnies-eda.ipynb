{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # graph\nimport seaborn as sns # advanced graph\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-08T14:48:02.566812Z","iopub.execute_input":"2021-07-08T14:48:02.567146Z","iopub.status.idle":"2021-07-08T14:48:02.57296Z","shell.execute_reply.started":"2021-07-08T14:48:02.567117Z","shell.execute_reply":"2021-07-08T14:48:02.571316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import data\nape = pd.read_csv('/kaggle/input/financial-data-of-french-compagnies/ape_fusion.csv')\ndata = pd.read_csv('/kaggle/input/financial-data-of-french-compagnies/data_kaggle.csv')\ndata = data.drop('Unnamed: 0', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:02.618249Z","iopub.execute_input":"2021-07-08T14:48:02.618723Z","iopub.status.idle":"2021-07-08T14:48:03.44773Z","shell.execute_reply.started":"2021-07-08T14:48:02.618662Z","shell.execute_reply":"2021-07-08T14:48:03.446401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis of data\nGoal :\n     Understand our data as well as possible\n     \nShape Analysis:\n*      rows and columns: (100 000, 88)\n*      types of variables: qualitative: 12, quantitative: 76\n*      The amplitudes of the values are very important. We need to use the log fonction for the graph.\n*      Analysis of missing values: Lots of missing values. Some columns are practically empty.\n\nBackground Analysis:\n*      Some family links are present in the columns, it would be necessary to check that these links are correct.","metadata":{}},{"cell_type":"markdown","source":"## Shape Analysis","metadata":{}},{"cell_type":"code","source":"# Missing values\ncol_info = pd.DataFrame(index=data.columns, columns=['type', '% mv']) # information about the columns\nprint('data.shape: ',data.shape) # nombres de lignes et de colonnes\ncol_info['type'] = [str(x) for x in data.dtypes] # type\nprint('\\ndata.dtypes.value_counts():\\n', data.dtypes.value_counts())\n\n# Histogram of the missing values\ncol_info['% mv'] = data.isna().sum(axis=0)/data.shape[0]\n\nsns.histplot(data=col_info, x='% mv', hue='type',  multiple=\"stack\")\nplt.title('% of missing value per column')\nplt.ylabel('Number of column')\nplt.xlabel('%')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:03.449836Z","iopub.execute_input":"2021-07-08T14:48:03.450151Z","iopub.status.idle":"2021-07-08T14:48:03.762567Z","shell.execute_reply.started":"2021-07-08T14:48:03.450126Z","shell.execute_reply":"2021-07-08T14:48:03.761349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The vast majority of columns are numeric columns. The filling rate of the columns is very variable. Some columns are completely empty!","metadata":{}},{"cell_type":"code","source":"# visualization of the missing values\ndict_colors = {'float64':'blue', 'int64':'orange', 'object': 'green', 'bool':'red'}  # colors of each type\n\nfig = plt.figure(figsize=(25,5), dpi=150)\nax = sns.heatmap(data.sample(100).isna(), cbar=False)\nplt.title('Display of the values present in black', fontsize=20)\n\n# We modify the color of the x-axis\nax.xaxis.set_visible(False)\ntext_kwargs = dict(rotation='vertical', fontsize=14, va='top', ha='center')\noffset = 100\nfor x, col in zip(ax.xaxis.get_ticklocs(), data.columns):\n    type_col = data.dtypes.loc[col].name # get the type of the column\n    ax.text(x, offset, col, **text_kwargs, color=dict_colors.get(type_col))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:03.76418Z","iopub.execute_input":"2021-07-08T14:48:03.764416Z","iopub.status.idle":"2021-07-08T14:48:06.218825Z","shell.execute_reply.started":"2021-07-08T14:48:03.764391Z","shell.execute_reply":"2021-07-08T14:48:06.217511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Background Analysis:","metadata":{}},{"cell_type":"code","source":"# Values taken by the qualitative variables\nfor col in data.select_dtypes(include=['object']):\n    print(col, 'nunique=', data[col].nunique(), '\\n',data[col].unique()[:5], '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:54:37.020313Z","iopub.execute_input":"2021-07-08T14:54:37.020672Z","iopub.status.idle":"2021-07-08T14:54:37.231857Z","shell.execute_reply.started":"2021-07-08T14:54:37.020642Z","shell.execute_reply":"2021-07-08T14:54:37.230061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:06.511218Z","iopub.execute_input":"2021-07-08T14:48:06.511565Z","iopub.status.idle":"2021-07-08T14:48:06.95093Z","shell.execute_reply.started":"2021-07-08T14:48:06.511527Z","shell.execute_reply":"2021-07-08T14:48:06.949684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[:,'Total des charges d’exploitation'].hist()\nplt.title('Total des charges d’exploitation')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:06.952547Z","iopub.execute_input":"2021-07-08T14:48:06.952923Z","iopub.status.idle":"2021-07-08T14:48:07.18629Z","shell.execute_reply.started":"2021-07-08T14:48:06.952882Z","shell.execute_reply":"2021-07-08T14:48:07.184276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The histogram of a column isn't interesting, because the amplitude of the data is too important. The histogram of continuous variables gives nothing, because the variables have very large amplitudes.","metadata":{}},{"cell_type":"code","source":"# List of the columns with the selected type (object, float, int, str)\ndata.dtypes[data.dtypes == 'object']","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:07.188412Z","iopub.execute_input":"2021-07-08T14:48:07.188843Z","iopub.status.idle":"2021-07-08T14:48:07.19874Z","shell.execute_reply.started":"2021-07-08T14:48:07.188801Z","shell.execute_reply":"2021-07-08T14:48:07.197303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sorts columns by percentage of missing values \ndata.isna().sum(axis=0).sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:07.201174Z","iopub.execute_input":"2021-07-08T14:48:07.201501Z","iopub.status.idle":"2021-07-08T14:48:07.333719Z","shell.execute_reply.started":"2021-07-08T14:48:07.201469Z","shell.execute_reply":"2021-07-08T14:48:07.33209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we create the following function in order to visualize the data with high scale\ndef obtention_log10(val):\n  \"\"\" Transform a number : 100 000 becomes 5 and -100 becomes -2 \"\"\"\n  if val == np.nan: return np.nan\n  elif (isinstance(val, float)) or (isinstance(val, int)):\n    signe, nb = np.sign(val), np.absolute(val)\n    if nb < 1: return 0\n    else : return math.log10(nb) * signe\n  else: return val\n\n# we apply the function on the right columns\ndata_log10 = pd.concat([data.iloc[:,0],data.iloc[:,1:69].applymap(obtention_log10), data.iloc[:,69:-1]], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:07.335394Z","iopub.execute_input":"2021-07-08T14:48:07.335715Z","iopub.status.idle":"2021-07-08T14:48:30.421995Z","shell.execute_reply.started":"2021-07-08T14:48:07.335667Z","shell.execute_reply":"2021-07-08T14:48:30.419886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Histogram of continuous variable\ndata_log10.select_dtypes(include=float).hist(bins=30, figsize=(20, 60), layout=(20,5))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T14:48:30.42397Z","iopub.execute_input":"2021-07-08T14:48:30.424385Z","iopub.status.idle":"2021-07-08T14:48:44.445034Z","shell.execute_reply.started":"2021-07-08T14:48:30.424352Z","shell.execute_reply":"2021-07-08T14:48:44.44337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe the wealth of information at our disposal. Log data regularly represent normal distributions. Which is a good sign. We can also observe normal bimodal distributions.","metadata":{}}]}