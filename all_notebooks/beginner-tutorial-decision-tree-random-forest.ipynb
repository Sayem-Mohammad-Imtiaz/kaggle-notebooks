{"cells":[{"metadata":{"_uuid":"85bfba3262386b107aca6880ded2d3107bc0c855"},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true,"_uuid":"24f63763c77e5a1afed3fdab5e9c62a44f9f9132"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d0b0359a5e568bffc5020b00be3432bcf39bce85"},"cell_type":"markdown","source":"# Get the Data\n\nUse pandas to read Dataset_spine.csv as a dataframe called train.\n"},{"metadata":{"trusted":true,"_uuid":"b186c6b5ce2a3e8ea3bbadac7c7fb6de8bd30cb4"},"cell_type":"code","source":"train = pd.read_csv(\"../input/Dataset_spine.csv\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"9d6add5939a5162580181679494509c7566eb5cb"},"cell_type":"markdown","source":"Check out the info(), head(), and describe() methods on the data."},{"metadata":{"trusted":true,"_uuid":"5a801d2dedd1a0b2248e2ab9e7b8d769b860b1f1"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7d66aec90df92da58d48460a8bf14391836e0f1"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67033d90d5edfe868fdb14010ba9204dce4807fc"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72b9c1d9fca43b52a5a54b351694a67612dc457b"},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37bebf6e9881dbf1f94da461ac1c2804b36cf6ca"},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nLet's do some data visualization!\n"},{"metadata":{"trusted":true,"_uuid":"8af520afc0e5033fa5382ee9446c5b9c526777e2"},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Class_att',data=train,palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4d016b0107e5d6c32c814345d58a30ef9ade345"},"cell_type":"markdown","source":"Data is not balanced."},{"metadata":{"trusted":true,"_uuid":"a50a9ec2d36f38e947f4ac38b404315dcda87143"},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nc=train.corr()\nsns.heatmap(c,cmap=\"BrBG\",annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"662dd4c9ca208a4e8cc8d1a153a99fea8bfab194"},"cell_type":"markdown","source":"# Train Test Split\n\nNow its time to split our data into a training set and a testing set!\n\nUse sklearn to split your data into a training set and a testing set as we've done in the past.\n"},{"metadata":{"trusted":true,"_uuid":"2e74ae76f417197c76fa14bbbe67922833aaee7d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f937b730c3a64d8cebcdb7c0ccdd015bd1e4a9d2"},"cell_type":"code","source":"X= train [['Col1', 'Col2', 'Col3', 'Col4', 'Col5', 'Col6',]]\ny= train['Class_att']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9635ef76e4525bedda4c514aa2c6d5b9e329e29c"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, \n                                                    random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc17e346d0d2d62e46c46e42fea2a275ef558e10"},"cell_type":"markdown","source":"# Training a Decision Tree Model\n\nLet's start by training a single decision tree first!\n\n**Import DecisionTreeClassifier**\n"},{"metadata":{"trusted":true,"_uuid":"f2e06565e9e7368232a6300929e6c5c273be851a"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8251ba22f82b25477e3c9bb760ed158acd36be5e"},"cell_type":"markdown","source":"**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**"},{"metadata":{"trusted":true,"_uuid":"1c0016f631f1d13f0a966f1f6ac0c14db4796f20"},"cell_type":"code","source":"dtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caaeca8aef2eea2ef4dd42cab80e6a1dcd06db6a"},"cell_type":"markdown","source":"**Predictions and Evaluation of Decision Tree**\n\nCreate predictions from the test set and create a classification report and a confusion matrix.\n"},{"metadata":{"trusted":true,"_uuid":"4e20f83332caa6b6986c9fc9085924c1140ee271"},"cell_type":"code","source":"predictions = dtree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f65a39c493dcf380e2ac5dbf04017b778536d66"},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85137e8e7fc10adce378fac93e1499c436611ebf"},"cell_type":"code","source":"print(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed05fa7347b0e9445d2ed985588cd3d8b36369e5"},"cell_type":"markdown","source":"# Training the Random Forest model\n\nNow its time to train our model!\n\nCreate an instance of the RandomForestClassifier class and fit it to our training data from the previous step.\n"},{"metadata":{"trusted":true,"_uuid":"c13c46f3a02f46b950effe0ddf89abad26dd2b12"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7e35058af97bbb18ec7ea186f90a0b27d0ba390"},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c4a1e342b15d8028dc97b59add58143a097adff"},"cell_type":"code","source":"rfc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e508ef405d78732dc6099a9120d9c5f7dd710bf5"},"cell_type":"markdown","source":"**Predictions and Evaluation**\n\nLet's predict off the y_test values and evaluate our model.\n\n Predict on the X_test data.\n"},{"metadata":{"trusted":true,"_uuid":"3d33b42f49795e35a3b7a0f2357334d9e55e5797"},"cell_type":"code","source":"predictions = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"602f503342ab4eabdfae6620231e198049d35f0e"},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d6b9c6443479ef4ebb6d4ad65e8a4c7c2ed5b993"},"cell_type":"markdown","source":"Show the classification report and Confusion Matrix for the predictions."},{"metadata":{"trusted":true,"_uuid":"654e7fa1ef75a167b7a378c7b094492b1e40b6cc"},"cell_type":"code","source":"print(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"416e9c1673c2f7537006396253b37ac2a1916013"},"cell_type":"markdown","source":"**What performed better the random forest or the decision tree?**"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"34b654d9ea81eb786c0adbde9530c482e62518f6"},"cell_type":"markdown","source":"Random Forest performed slightly better."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}