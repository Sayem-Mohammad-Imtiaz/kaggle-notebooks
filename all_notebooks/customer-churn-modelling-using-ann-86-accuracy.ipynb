{"cells":[{"cell_type":"markdown","source":"# About Dataset\n\n## Context\nThis is the dataset used in the section \"ANN (Artificial Neural Networks)\" of the Udemy course from Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist), called Deep Learning A-Z™: Hands-On Artificial Neural Networks. The dataset is very useful for beginners of Machine Learning, and a simple playground where to compare several techniques/skills.\n\nIt can be freely downloaded here: https://www.superdatascience.com/deep-learning/\n\nThe story: A bank is investigating a very high rate of customer leaving the bank. Here is a 10.000 records dataset to investigate and predict which of the customers are more likely to leave the bank soon.\n\n## Acknowledgements\nUdemy instructors Kirill Eremenko (Data Scientist & Forex Systems Expert) and Hadelin de Ponteves (Data Scientist), and their efforts to provide this dataset to their students.\n\n# Solution\nThis problem is solved by using an Artificial Nueral Network (ANN). The instructors of __Deep Learning A-Z™: Hands-On Artificial Neural Networks__ set the milestone for the accuracies as follows:\n* 84% Accuracy = Bronze\n* 85% Accuracy = Silver\n* 86%+ Accuracy = Gold\n\nI tired different topologies for the ANN (Deeper Topology vs Wider Topology. [Read More](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)) with the combinations of different optimizers, dropouts etc. and found out that the deeper architecture with no dropout resulted in __86.8%__ Accuracy. Following is my code.","metadata":{"_cell_guid":"fc28948c-1bdc-4e9d-a453-d7d07730b1db","_uuid":"826f1dbc00c8075b68be4675bd948b0f279570e2"}},{"cell_type":"markdown","source":"Importing Dataset and splitting features and label","metadata":{"_cell_guid":"8cb763f3-dda0-4d69-9b1f-888e4f814880","_uuid":"da7e03adc6d73f4a8314421b123e79e3a9747616"}},{"execution_count":null,"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(1)\n\n\ndataset = pd.read_csv('../input/Churn_Modelling.csv')\nX = dataset.iloc[:, 3:13].values\ny = dataset.iloc[:, 13].values","outputs":[],"metadata":{"_cell_guid":"e0c29ef6-3721-42af-a215-115f4e94ad4b","collapsed":true,"_uuid":"4746ad2ad2e31d6d669f1eb13a0f842b386ab9e6"}},{"cell_type":"markdown","source":"Encoding categorical features which are __sex__ & __Geography__. We will also do one hot encoding for __Geography__ to avoid dummy variable trap","metadata":{"_cell_guid":"730a5fac-97c2-4f20-8e1f-8fdf7bc37e7a","_uuid":"b618af3f0d62e3e0178a3b72bd3abd8988b4c134"}},{"execution_count":null,"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nlabelencoder_X_1 = LabelEncoder()\nX[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\nlabelencoder_X_2 = LabelEncoder()\nX[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n\nonehotencoder = OneHotEncoder(categorical_features=[1])\nX = onehotencoder.fit_transform(X).toarray()\n","outputs":[],"metadata":{"_cell_guid":"58ee1d05-08fa-422c-a6f2-abbbf0da3c99","collapsed":true,"_uuid":"60f818bcb98ca395e330e114282f977ad15f94ab"}},{"cell_type":"markdown","source":"Splitting into training and testing sets","metadata":{"_cell_guid":"18c7d5b3-8e63-4baf-a321-8a55f23aad1f","_uuid":"f57a6975fb45486ea7572bd5245801ef82435386"}},{"execution_count":null,"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","outputs":[],"metadata":{"_cell_guid":"1055560d-de4f-4b0d-8d43-2e31b4e9d292","collapsed":true,"_uuid":"d115d2110cfed505076e4eb772b0ef45ea48a541"}},{"cell_type":"markdown","source":"Applying features scaling","metadata":{"_cell_guid":"21f05e11-6057-4918-bea5-1374c07de1f2","collapsed":true,"_uuid":"52b8d3d3fc14887cc23876c1e8ac20eeb0ca44ac"}},{"execution_count":null,"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","outputs":[],"metadata":{"_cell_guid":"5ba8005f-5595-4e03-a060-d9b12109f0f8","collapsed":true,"_uuid":"22fcf3b93053aa45e675f8dddc672db9c979ccf7"}},{"cell_type":"markdown","source":"Defining architecture for our neural network","metadata":{"_cell_guid":"07a24a1a-1606-45a5-a372-e39cda29d883","_uuid":"6003f2376c324dd052c16d730c2dc5ba7f54192c"}},{"execution_count":null,"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\ndef deep_model():\n    classifier = Sequential()\n    classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu', input_dim=12))\n    classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu'))\n    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n    classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return classifier","outputs":[],"metadata":{"_cell_guid":"46b2dce0-37ab-40e8-9c38-882f9410a76e","_uuid":"874b3337948f020eb79c3989c27e3c0af27b4fcf"}},{"cell_type":"markdown","source":"Running our ANN","metadata":{"_cell_guid":"7c9c4d90-ec40-449b-a107-04766e9c3ecb","_uuid":"2e2da6bde9e65938aca767850f142cdb6900c9d4"}},{"execution_count":null,"cell_type":"code","source":"from keras.models import load_model\n\n# classifier = load_model('Churn_Modelling.h5')","outputs":[],"metadata":{"_cell_guid":"4f70d33e-d500-4bda-9438-cefa661b0a25","collapsed":true,"_uuid":"d2aeb83a2f98a72e4097f20993a5795ff40867a2"}},{"execution_count":null,"cell_type":"code","source":"# Uncomment to train new model otherwise it will used trained model\nclassifier = deep_model()\nclassifier.fit(X_train, y_train, batch_size=4, epochs=128)\n\n\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\naccuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\nprint(\"Accuracy: \"+ str(accuracy*100)+\"%\")","outputs":[],"metadata":{"_cell_guid":"8383a13f-a226-4de0-ab17-444bf3b03fe3","_uuid":"c6b010b51cfe2c9b8ccf29e21bd085e88338c32a"}},{"execution_count":null,"cell_type":"code","source":"classifier.save('Churn_Modelling.h5')","outputs":[],"metadata":{"_cell_guid":"f8c1c7e7-c504-49b5-8fd7-f7d7e97adf76","collapsed":true,"_uuid":"69e59882c6b0ee872015101e4a77d139335bae9d"}},{"execution_count":null,"cell_type":"code","source":"","outputs":[],"metadata":{"_cell_guid":"67ba0847-dead-4486-8a0a-04a7c8e7cfe5","collapsed":true,"_uuid":"14910693628449461e671e4a3f1761732de282b1"}}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","version":"3.6.4","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py"}}}