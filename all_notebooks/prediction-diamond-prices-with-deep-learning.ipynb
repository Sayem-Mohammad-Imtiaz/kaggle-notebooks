{"cells":[{"metadata":{},"cell_type":"markdown","source":"Import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score , mean_squared_error,make_scorer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nimport random\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond = pd.read_csv(os.path.join(dirname, filename),index_col = 'Unnamed: 0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check if there are missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values\ndiamond.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There are 146 duplicated row to drop"},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond = diamond.loc[~diamond.duplicated(),:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" we note that there are some rows with x,y,z = 0 \n it's technically not possible we display and drop this row"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_values = (diamond.loc[:,'x'] == 0) | (diamond.loc[:,'y'] == 0)| (diamond.loc[:,'z'] == 0)\nzero_values.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond = diamond.loc[~zero_values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = px.histogram(diamond, x=\"price\",\n                   hover_data=diamond.columns,)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(diamond, x=\"carat\",\n                   hover_data=diamond.columns)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,6))\n\n\nsns.factorplot(x='color', data=diamond , kind='count',aspect=3)\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\n\nsns.factorplot(x='cut', data=diamond , kind='count',aspect=3)\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\n\nsns.factorplot(x='clarity', data=diamond , kind='count',aspect=3)\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_features = list(diamond.columns)\ndrop_f = ['price','cut','color','clarity']\n\nfor index in drop_f:\n  lst_features.remove(index)\n\nfig = go.Figure()\n\nfor feature in lst_features:\n\n   fig.add_trace(go.Box(y=diamond.loc[:,feature],name = feature))\n\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Diamonds with color D are most common for character sizes <1.3\nD colors are rare so it is normal to find only a few stone with this color for large stones\nwe can see that the price depends on the weight of the stone (carat)\nLarger diamonds> 2 carat are usually medium H, J colors"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(diamond, x=\"carat\", y=\"price\",color = 'color')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nwe can see that the cheapest diamonds are those with a low clarity (I1)\nwe see that some diamonds with very high clarity (IF) even being light 1 carat are worth in the 20k dollars\nhigh quality diamonds> 2.5 carats are diamonds with low clarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(diamond, x=\"carat\", y=\"price\",color = 'clarity')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.box(diamond, x=\"cut\", y=\"price\",color = 'color')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\n\nsns.heatmap(diamond.corr(),annot = True,linewidths=3,linecolor='black',cbar = False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond = pd.get_dummies(data = diamond,drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling of data , We fit_transform the train and just transform the test to avoid data linkage"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = diamond.drop('price',axis = 1)\ny = diamond.loc[:,'price']\nX_train,X_test, y_train ,y_test = train_test_split(X,y,test_size = .2, random_state = 42)\n\nscaler = StandardScaler()\nX_train_scaled = pd.DataFrame(scaler.fit_transform(X_train.loc[:,['carat','depth','table','x','y','z']]),columns = ['carat','depth','table','x','y','z'],index = X_train.index)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test.loc[:,['carat','depth','table','x','y','z']]),columns = ['carat','depth','table','x','y','z'], index = X_test.index)\n\nX_train_scale_final = X_train.copy()\nX_test_scale_final = X_test.copy()\n\nX_train_scale_final.loc[:,['carat','depth','table','x','y','z']] = X_train_scaled.loc[:,['carat','depth','table','x','y','z']]\nX_test_scale_final.loc[:,['carat','depth','table','x','y','z']] = X_test_scaled.loc[:,['carat','depth','table','x','y','z']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train_scale_final,y_train)\ny_pred = lr.predict(X_test_scale_final)\n\nmse = (mean_squared_error(y_test,y_pred)) \n\nrmse = mse**.5\nrmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSE means that on average we are wrong by 1128 dollars"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(256,activation='relu',input_dim= X_train_scale_final.shape[1]))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(1,activation='linear'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss = 'mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x = X_train_scale_final,y = y_train,validation_data=(X_test_scale_final,y_test),epochs = 200,batch_size=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test_scale_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test,y_pred) ** 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSE means that on average we are wrong by 534 dollars so it's a good performance "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}