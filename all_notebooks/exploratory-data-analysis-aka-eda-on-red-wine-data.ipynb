{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nExploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n\nBefore making inferences from data it is essential to examine all your variables.\nWhy?\n\n1). To listen to the data\n\n2). To catch errors, anomalies\n\n3). To see patterns in the data\n\n4). To find violations of statistical assumptions\n\n5). To generate hypotheses\n\nExploratory data analysis involves a number of processes or activities including :-\n\n1). Generating and analyzing descriptive statistics for each of the features\n\n2). Checking correlations\n\n3). Checking outliers\n\n4). Analyzing target variables\n\n5). Finding errors and anomalies in the features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Most Important Exploratory Data Analysis Questions\n\n- How will you understand Target Variable Distribution, and why is this so important ?\n- How can you visually discover Correlation between features, and why is it so important ?\n- How can we identify Outliers in a given Feature Space ?\n- How can we find Distribution-Skewness in a given Feature Space ?\n\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n#Setting Style for Plotting\nplt.style.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To starts with,I imported necessary libraries (for this example pandas, numpy,matplotlib and seaborn) and loaded the data set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Loading Data and Initial Exploration to Understand Data","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find total number of rows and columns in the dataset using shape ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is also a good practice to know the columns and their corresponding data types, along with finding whether they contain null values or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Descriptive Statistics\n\nDescriptive statistics can give you great insight into the shape of each attribute.\n\nOften you can create more summaries than you have time to review. The describe() function on the Pandas DataFrame lists 8 statistical properties of each attribute:\n\na). Count\n\nb). Mean\n\nc). Standard Deviation\n\nd). Minimum Value\n\ne). 25th Percentile\n\nf). 50th Percentile (Median)\n\ng). 75th Percentile\n\nh). Maximum Value\n\nThe describe() function in pandas is very handy in getting various summary statistics.This function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The describe() function in pandas is very handy in getting various summary statistics.This function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data.\n\nThere is notably a large difference between 75th %tile and max values of predictors “residual sugar”,”free sulfur dioxide”,”total sulfur dioxide”.\nThus observation suggests that there are extreme values-Outliers in our data set.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How will you understand Target Variable Distribution, and why is this so important ?\n\nFew key insights just by looking at dependent variable.\n\n1. Target variable/Dependent variable is discrete and categorical in nature.\n2. “quality” score scale ranges from 1 to 10;where 1 being poor and 10 being the best.\n3. You can identify class imbalance which can help you understand and hopefully fix classification errors at a later stage","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.quality.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThis tells us vote count of each quality score in descending order.“quality” has most values concentrated in the categories 5, 6 and 7.\nOnly a few observations made for the categories 3 and 8.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.quality.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['quality'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How can you visually discover Correlation between features ?\n\nTo use linear regression for modelling,its necessary to remove correlated variables to improve your model. One can find correlations using pandas “.corr()” function and can visualize the correlation matrix using a heatmap in seaborn.\n\nDark shades represents positive correlation while lighter shades represents negative correlation.\nIf you set annot=True, you’ll get values by which features are correlated to each other in grid-cells.\n\n1). Here we can infer that “density” has strong positive correlation with “residual sugar” whereas it has strong negative correlation with “alcohol”.\n\n2). “free sulphur dioxide” and “citric acid” has almost no correlation with “quality”.\n\nSince correlation is zero we can infer there is no linear relationship between these two predictors (“free sulphur dioxide” and “citric acid”).However it is safe to drop these features in case you’re applying Linear Regression model to the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,7))\nsns.heatmap(df.corr(),cmap='viridis', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How can we identify Outliers in a given Feature Space ?\n\nThis is a commonly overlooked mistake we tend to make. The temptation is to start building models on the data you’ve been given. But that’s essentially setting yourself up for failure.\n\nData exploration consists of many things, such as variable identification, treating missing values, feature engineering, etc. Detecting and treating outliers is also a major cog in the data exploration stage. The quality of your inputs decide the quality of your output!\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"l = df.columns.values\nnumber_of_columns=12\nnumber_of_rows = len(l)-1/number_of_columns\nplt.figure(figsize=(number_of_columns,5*number_of_rows))\nfor i in range(0,len(l)):\n    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n    sns.set_style('whitegrid')\n    sns.boxplot(df[l[i]],color='green',orient='v')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How can we find Distribution-Skewness in a given Feature Space ?\n\nAccording to Wikipedia,” In probability theory and statistics, skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean.”","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(2*number_of_columns,5*number_of_rows))\nfor i in range(0,len(l)):\n    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n    sns.distplot(df[l[i]],kde=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Skewness  \\n \",df.skew())\nprint(\"\\n Kurtosis  \\n \", df.kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Skewness and Kurtosis on House Price Prediction\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read and load Data\ntrain = pd.read_csv(\"../input/housepricesadvancedregressiontechniquestrain/train.csv\")\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Histogram for 'SalePrice'\nsns.distplot(train['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Skewness and Kurtosis\nprint(\"Skewness : %f\" % train['SalePrice'].skew())\nprint(\"Kurtosis : %f\" % train['SalePrice'].kurt())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = np.log(train.SalePrice)\nprint(\"Skewness : %f\" % target.skew())\nprint(\"Kurtosis : %f\" % target.kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding Outliers\n\nFocusing on outliers, defined by Gladwell as people who do not fit into our normal understanding of achievement. Outliers deals with exceptional people, especially those who are smart, rich, and successful, and those who operate at the extreme outer edge of what is statistically plausible. An outlier is a data point that is distant from other similar points. They may be due to variability in the measurement or may indicate experimental errors. If possible, outliers should be excluded from the data set. We'll do a quick analysis through the standard deviation of 'SalePrice' and a set of scatter plots.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['GarageArea'] < 1200]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram and normal probability plot\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\n\nsns.distplot(train['SalePrice'], fit = norm)\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'],plot = plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Please Upvote, Share and Comment to show your Support and Appreciation. Thanks for all the support.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}