{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Forecasting Monthly Armed Robberies in Boston","metadata":{}},{"cell_type":"markdown","source":"**Contents**\n\n1. Splitting dataset into data and validation\n2. Transforming date column\n3. Data analysis\n4. Dickey-Fuller test for stationarity\n5. ACF PACF plots\n6. Defferencing to make the series stationary\n7. Train-test split\n8. Box-Cox transformation\n9. Building ARIMA model\n10. Hyperparameter tuning\n11. Rolling forecasting to capture random variation\n12. Exponential Smoothning\n13. Validation\n14. Forecasting for next 1 year","metadata":{}},{"cell_type":"code","source":"import scipy as sp\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pandas as pd\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom datetime import  datetime, timedelta\nfrom statsmodels.tsa.stattools import  adfuller\nfrom statsmodels.graphics.tsaplots import  plot_pacf, plot_acf\nfrom statsmodels.graphics.tsaplots import  plot_acf\nfrom statsmodels.graphics.gofplots import  qqplot\nfrom statsmodels.tsa.seasonal import  seasonal_decompose\nfrom statsmodels.tsa.arima_model import  ARIMA\nfrom statsmodels.tsa.statespace.sarimax import  SARIMAX\nfrom sklearn.metrics import mean_squared_error\nimport itertools\nfrom scipy.stats import boxcox\nfrom statsmodels.tsa.api  import ExponentialSmoothing\n\n\nfrom  pylab import rcParams\nrcParams['figure.figsize'] = 25,8\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading data ","metadata":{}},{"cell_type":"markdown","source":"## Splitting data onto dataset and validation","metadata":{}},{"cell_type":"code","source":"series = pd.read_csv('../input/monthly-armed-robberies-in-boston/Robberies.csv')\nsplit_point = len(series) - 12\ndataset, validation = series[0:split_point], series[split_point:]\nprint('Dataset %d, Validation %d' % (len(dataset), len(validation)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"dataset.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transforming date column","metadata":{}},{"cell_type":"code","source":"# creating date range according to the data\n# data has dates from 1966-01-31 to 1974-10-31 with monthly frequency\ndate = pd.date_range(start='1/1/1966', end='11/1/1974', freq='M')\ndate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replacing original date column with newly created\ndataset['Months'] = date\n\n# setting date column as index of the dataframe\ndataset.set_index('Months', inplace=True)\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data analysis","metadata":{}},{"cell_type":"code","source":"# stats\ndataset.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference**\n1. Total of 106 records\n2. Mean robberies as 173.10\n3. Standard deviation is larger than mean: robberies are increasing yearly","metadata":{}},{"cell_type":"code","source":"dataset.plot()\nplt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** Linear up-trend but no seasionality","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x = dataset.index.month, y = dataset['Robberies'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monthly_rabberies_across_years = pd.pivot_table(dataset,\n                                                values = 'Robberies',\n                                                columns = dataset.index.year,\n                                                index = dataset.index.month_name())\nmonthly_rabberies_across_years.plot()\nplt.grid()\nplt.legend(loc='best');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** Both graph shows no strong seasonality","metadata":{}},{"cell_type":"markdown","source":"# Stationary test\n**Stationary test means all the data are around mean and varience of the entire data. To forecast any time series, stationary data is required. In case, data is not stationary we use differencing technique to transform non-stationary series into stationary series** ","metadata":{}},{"cell_type":"code","source":"# year wise box plot\nsns.boxplot(x = dataset.index.year, y = dataset['Robberies'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** Graph shows strong up-trend, which means presence of non-stationary data. Let's check bt **A**uto**c**orrelation **F**unction plot and **P**artial **A**utocorrelation **F**unction plot.","metadata":{}},{"cell_type":"markdown","source":"## ACF and PCAF plots","metadata":{}},{"cell_type":"code","source":"# ACF plot\nplot_acf(dataset, lags=100);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PACF plot\nplot_pacf(dataset);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** Slow decay in in ACF and random trend in PACF shows trend in data. Let's conform by statistical test.","metadata":{}},{"cell_type":"markdown","source":"## Dickey-Fuller test","metadata":{}},{"cell_type":"code","source":"'''\nNull hypothesis:Series is not stationary\nAlternate hypothesis: Series is stationary\n'''\n\ntest_result = adfuller(dataset.values)\nprint('ADF Statistic: %f' % test_result[0])\nprint('p-value: %f' % test_result[1])\nprint('Critical Values:')\nfor key, value in test_result[4].items():\n    print('\\t%s: %.5f' % (key, value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** p-value is greater than threshold 0.05(commenly taken threshold in statistics). Hence, we fail to reject hull hypothesis.So the series is  non-stationary.<br>\n**Differencing is required**","metadata":{}},{"cell_type":"markdown","source":"# Differencing by 1 lab value\n(`y` at time `t`) - (`y` at time `t-1`)","metadata":{}},{"cell_type":"code","source":"df_diff1 = dataset.diff(periods=1).dropna()\n\ntest_result = adfuller(df_diff1.values)\nprint('ADF Statistic: %f' % test_result[0])\nprint('p-value: %f' % test_result[1])\nprint('Critical Values:')\nfor key, value in test_result[4].items():\n    print('\\t%s: %.5f' % (key, value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** p-value is less than threshold 0.05(commenly taken threshold in statistics). Hence, we  reject hull hypothesis.So the series is stationary at t-1 differencing.<br>","metadata":{}},{"cell_type":"code","source":"plot_acf(df_diff1, lags=100);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pacf(df_diff1);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-test split","metadata":{}},{"cell_type":"code","source":"dataset.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split data such that last two years are taken into test data remainig for train data\ntrain_end = datetime(1972, 12, 31)\ntest_end = datetime(1974, 10, 31)\n\ntrain = dataset[ : train_end]\ntest = dataset[train_end+timedelta(days=1) : test_end]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ARIMA model\n**Since, we have trend to capture ARIMA model is best suited**","metadata":{}},{"cell_type":"markdown","source":"## Building the model","metadata":{}},{"cell_type":"code","source":"# order = (1, 1, 1): ACF value 1, Differencing by 1, PACF value 1\narima_model = ARIMA(train, order = (1, 1, 1))\nmodel_fit = arima_model.fit()\nprint(model_fit.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Forecasting","metadata":{}},{"cell_type":"code","source":"arima_forecast = model_fit.forecast(steps = len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train, label='Train')\nplt.plot(test, label='Test')\nplt.plot(test.index, arima_forecast[0], label='Forecast')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(test.Robberies, arima_forecast[0]))\nprint(rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mean Absolute Percentage Error","metadata":{}},{"cell_type":"code","source":"def MAPE(y_true, y_pred):\n    return np.mean((np.abs(y_true-y_pred))/(y_true))*100\n\nmape = MAPE(test['Robberies'].values, arima_forecast[0])\nmape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Incerence:** There is almost 14% of error","metadata":{}},{"cell_type":"code","source":"results_df = pd.DataFrame({'Test RMSE': rmse,'Test MAPE':mape}\n                           ,index=['ARIMA(1,1,1)'])\n\nresults_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter tuning\n**We will look for paramerers with least AIC value**","metadata":{}},{"cell_type":"code","source":"# parameters for grid search\np = q = range(0, 4)\nd= range(1,2)\npdq = list(itertools.product(p, d, q))\nprint('parameter combinations for the Model')\nfor i in range(1,len(pdq)):\n    print('Model: {}'.format(pdq[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grid search technique\narima_df = pd.DataFrame(columns=['param', 'AIC'])\n\nfor param in pdq:\n    try:\n        model = ARIMA(train, order = param)\n        model_fit = model.fit()\n        print('ARIMA_params',param, '- AIC{}', model_fit.aic)\n        arima_df = arima_df.append({'param': param, 'AIC': model_fit.aic}, ignore_index = True)\n    except:\n        continue\n\nprint('==============================================')\narima_df = arima_df.sort_values('AIC')\nprint('Best params for ARIMA')\nprint(arima_df.head(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arima_model = ARIMA(train, order = (0, 1, 2))\nmodel_fit = arima_model.fit()\n\narima_forecast = model_fit.forecast(steps = len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(test.Robberies, arima_forecast[0]))\nprint(rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mape = MAPE(test['Robberies'].values, arima_forecast[0])\nprint(mape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Tuned ARIMA(0, 1, 2)'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** No much improvement in the model accuracy","metadata":{}},{"cell_type":"code","source":"residuals = test['Robberies'] - arima_forecast[0]\nqqplot(residuals,line=\"s\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformation\n**Let's check if transforming the data with Box-Cox method will improve our model** ","metadata":{}},{"cell_type":"code","source":"data = [x[0] for x in train.values]\ntransformed, lam = boxcox(data)\n\n# the forecast will be Box-Cox transformed values.\n# Hence, we need to invest the values back to original scale.\ndef boxcox_inverse(value, lam):\n    if lam == 0:\n        return np.exp(value)\n    return np.exp(np.log(lam * value + 1) / lam)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model with transformed data\narima_model = ARIMA(transformed, order=(0, 1, 2))\nmodel_fit = arima_model.fit()\n\n# Forecast for test\narima_forecast = model_fit.forecast(steps = len(test))\n\n# Invert the transformation\narima_forecast = boxcox_inverse(arima_forecast[0], lam)\n\n# Check RMSE\nrmse = np.sqrt(mean_squared_error(test.Robberies, arima_forecast))\n\n# Check error\nmape = MAPE(test['Robberies'].values, arima_forecast[0])\n\nresults_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Transformed ARIMA(0, 1, 2)'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** Error increased, transformation is a bad idea","metadata":{}},{"cell_type":"markdown","source":"**Concluion:** We will stick to paramerets which we got from hyper parameter tuning. That is, ACF=0, Differencing=1 and PACF=2 (0, 1, 2) withoud transformation","metadata":{}},{"cell_type":"markdown","source":"## Rolling forecasting to capture random variation","metadata":{}},{"cell_type":"code","source":"predictions = []\ndata = [x[0] for x in train.values]\n\n\nfor i in range(0, len(test)):\n        \n    # predict\n    model = ARIMA(data, order=(0, 1, 2))\n    model_fit = model.fit()\n    yhat = model_fit.forecast()[0]\n    predictions.append(yhat)\n    \n    # observation\n    obs = test.iloc[i].values[0]\n    data.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(test.Robberies, predictions))\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mape = MAPE(test['Robberies'].values, predictions)\nmape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Rolling ARIMA(0, 1, 2)'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train, label='Train')\nplt.plot(test.index,test, label='Test')\nplt.plot(test.index, predictions, label='Forecast')\nplt.legend(loc='best')\nplt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** Our goal is to reduce MAPE. Let's see if Exponential Smoothing will do a better job.","metadata":{}},{"cell_type":"markdown","source":"# Exponential Smoothing model","metadata":{}},{"cell_type":"code","source":"model_TES_add = ExponentialSmoothing(train, trend='additive', seasonal='additive', initialization_method='estimated')\nmodel_TES_add = model_TES_add.fit(optimized=True)\nmodel_TES_add.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TES_add_predict =  model_TES_add.forecast(len(test))\n\nrmse = np.sqrt(mean_squared_error(test.Robberies, TES_add_predict))\nmape = MAPE(test['Robberies'], TES_add_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Exponential Smoothing'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference:** Final model is Exponential Smoothing","metadata":{}},{"cell_type":"code","source":"plt.plot(train, label='Train')\nplt.plot(test.index,test, label='Test')\nplt.plot(test.index, TES_add_predict, label='Forecast')\nplt.legend(loc='best')\nplt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"validation.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing validation data","metadata":{}},{"cell_type":"code","source":"date = pd.date_range('11/1/1974', '11/1/1975', freq='M')\ndate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation['Months'] = date\nvalidation.set_index('Months', inplace=True)\nvalidation.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model fitting and forecasting","metadata":{}},{"cell_type":"code","source":"model_TES_add = ExponentialSmoothing(dataset, trend='additive', seasonal='additive', initialization_method='estimated')\nmodel_TES_add = model_TES_add.fit(optimized=True)\nmodel_TES_add.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TES_add_predict =  model_TES_add.forecast(len(validation))\nplt.plot(validation, label='Validation')\nplt.plot(validation.index, TES_add_predict, label='Forecast')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forecasting for next 1 year","metadata":{}},{"cell_type":"code","source":"series.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing original dada","metadata":{}},{"cell_type":"code","source":"date = pd.date_range('1/1/1966', '11/1/1975', freq='M')\ndate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series['Months'] = date\nseries.set_index('Months', inplace=True)\nseries.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Manually creating next 1 year date fields","metadata":{}},{"cell_type":"code","source":"forecast_date = pd.date_range('11/1/1975', '11/1/1976', freq='M')\nforecast_date","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model builting and forecasting the trend","metadata":{}},{"cell_type":"code","source":"model_TES_add = ExponentialSmoothing(series, trend='additive', seasonal='additive', initialization_method='estimated')\nmodel_TES_add = model_TES_add.fit(optimized=True)\nTES_add_predict =  model_TES_add.forecast(12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(series, label='Data')\nplt.plot(forecast_date, TES_add_predict, label='Forecast')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n**It is forecasted that armed robberies are going to be increased in the next one year. Government and police has to take measure accordingly by imposing strict measures and deploying more man-force for patrolling**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}