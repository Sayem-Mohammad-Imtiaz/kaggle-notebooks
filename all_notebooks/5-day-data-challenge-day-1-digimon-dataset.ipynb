{"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"name":"python","file_extension":".py","version":"3.6.3","mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"cells":[{"metadata":{"_uuid":"49dd763312e6b36cb8f8d0d1e2a776602a014d2b","_cell_guid":"e74ee36d-aadc-4043-977f-915f39f3fc19"},"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Day 1\n\nIt seems like the datasets are readily available in the `../input/` directory; hmm, quite handy.  Let's list out the objectives for this excercise before we go further.\n\n1. Find a Kaggle dataset -- been there\n2. Start a new kernel -- done that\n3. Pick your language -- Python 3 (as always)\n4. Read in the libraries -- done in the first cell for us\n5. Read your data into a dataframe\n6. Summarize your data\n7. Optional: make this public\n\nThe first four is done so lets get to step 5.\n\n## Read your data into a dataframe\n\nSince we are using Python's `pandas` package, I'm going for the `read_csv()` function."},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"dList = pd.read_csv(\"../input/DigiDB_digimonlist.csv\")\ndMoves = pd.read_csv(\"../input/DigiDB_movelist.csv\")\ndSupport = pd.read_csv(\"../input/DigiDB_supportlist.csv\")","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That didn't take long. Let's view it"},{"metadata":{"scrolled":true},"execution_count":null,"cell_type":"code","source":"dList","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"dMoves","outputs":[]},{"metadata":{"scrolled":true},"execution_count":null,"cell_type":"code","source":"dSupport","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summarize your data\n\nThe `read_csv()` command loads the data into a `DataFrame` object. `describe()` is a function of the DataFrame class which is supposed to 'summarize' the data. Let's check out what it can do."},{"metadata":{},"execution_count":null,"cell_type":"code","source":"dList.describe()","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"dMoves.describe()","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"dSupport.describe()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like `describe()` acts differently depending on the data of the columns specified in each dataframe table.\n\n## Optional: make this notebook public\n\nWell, if you could view this, then this step is a success."},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"","outputs":[]}],"nbformat":4}