{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/amexpert-2019/train.csv')\nsubmission = pd.read_csv('../input/amexpert-2019/sample_submission_Byiv0dS.csv')\ncoupon_item_mapping = pd.read_csv('../input/amexpert-2019/coupon_item_mapping.csv')\ntest = pd.read_csv('../input/amexpert-2019/test_QyjYwdj.csv')\ncampaign_data = pd.read_csv('../input/amexpert-2019/campaign_data.csv')\nitem_data = pd.read_csv('../input/amexpert-2019/item_data.csv')\ncustomer_transaction_data = pd.read_csv('../input/amexpert-2019/customer_transaction_data.csv')\ncustomer_demographics = pd.read_csv('../input/amexpert-2019/customer_demographics.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train :',train.shape)\nprint('submission :',submission.shape)\nprint('coupon_item_mapping :',coupon_item_mapping.shape)\nprint('test :',test.shape)\nprint('campaign_data :',campaign_data.shape)\nprint('item_data :',item_data.shape)\nprint('customer_transaction_data :',customer_transaction_data.shape)\nprint('customer_demographics :',customer_demographics.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['redemption_status'].value_counts()/train.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.countplot(train['campaign_id'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(['campaign_id']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' col1 ',train[train.columns[0]].value_counts().count())\nprint(' col2 ',train[train.columns[1]].value_counts().count())\nprint(' col3 ',train[train.columns[2]].value_counts().count())\nprint(' col4 ',train[train.columns[3]].value_counts().count())\nprint(' col5 ',train[train.columns[4]].value_counts().count())\nprint('shape ', train.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# campaign_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"campaign_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(campaign_data.columns[0],':', campaign_data[campaign_data.columns[0]].value_counts().count())\nprint(campaign_data.columns[1],':', campaign_data[campaign_data.columns[1]].value_counts().count())\nprint(campaign_data.columns[2],':', campaign_data[campaign_data.columns[2]].value_counts().count())\nprint(campaign_data.columns[3],':', campaign_data[campaign_data.columns[3]].value_counts().count())\nprint('shape : ',campaign_data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kl, axes = plt.subplots(2,2,figsize=(10,10))\nk=0\nfor i in range(2):\n    for j in range(2):\n        sns.countplot(campaign_data[campaign_data.columns[k]], ax=axes[i,j])\n        k+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"campaign_data.start_date[0][1:4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# coupon_item_mapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('coupon id:',coupon_item_mapping['coupon_id'].value_counts().count())\nprint('coupon id:',coupon_item_mapping['item_id'].value_counts().count())\nprint('coupon shape:',coupon_item_mapping.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping['coupon_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# item_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data.category.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# customer_transaction_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.coupon_discount.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.coupon_discount.value_counts().index.to_frame().plot.hist(bins=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.quantity.value_counts().index.to_frame().plot.hist(bins=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.other_discount.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.other_discount.value_counts().index.to_frame().plot.hist(bins=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.selling_price.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.selling_price.value_counts().index.to_frame().plot.hist(bins=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.date.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.customer_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# customer_demographics"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.age_range.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.marital_status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.rented.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.family_size.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.no_of_children.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['no_of_children'].fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics[['marital_status','family_size','no_of_children']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['family_size'].loc[customer_demographics['family_size'] == '5+'] = '5'\ncustomer_demographics['no_of_children'].loc[customer_demographics['no_of_children'] == '3+'] = '3'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['marital_status'].loc[(customer_demographics['marital_status'].isna()) & \n                      ((customer_demographics['family_size'].astype(int)-customer_demographics['no_of_children'].astype(int)) > 1 )] = 'Married'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['marital_status'].fillna('Single', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.distplot(test['campaign_id'], bins=30)\nsns.distplot(train['campaign_id'],bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.distplot(test['coupon_id'], bins=200)\nsns.distplot(train['coupon_id'], bins=200)\nplt.legend(['train','test'])\n# sns.distplot(coupon_item_mapping['coupon_id'], bins=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.distplot(test['customer_id'], bins=200)\nsns.distplot(train['customer_id'], bins=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.distplot(test['id'], bins=200)\nsns.distplot(train['id'], bins=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# feature engineering"},{"metadata":{},"cell_type":"markdown","source":"## train to campaign_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"campaign_data.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef month_year(row):\n    return row[3:]\n\nfrom datetime import date\n\ndef date_diff(row):\n    d0 = date(int('20'+str(row.start_date[6:])), int(row.start_date[3:5]), int(row.start_date[:2]))\n    d1 = date(int('20'+str(row.end_date[6:])), int(row.end_date[3:5]), int(row.end_date[:2]))\n    delta = d1 - d0\n    return int(delta.days)\n\ncampaign_data['date_diff'] = campaign_data.apply(date_diff,axis=1)\ncampaign_data['start_month_year'] = campaign_data.start_date.map(month_year)\ncampaign_data['end_month_year'] = campaign_data.end_date.map(month_year)\ncampaign_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"campaign_data = campaign_data.drop(['start_date','end_date'],axis=1)\ncampaign_data['campaign_type'] = campaign_data['campaign_type'].map({'Y':1, 'X':0})\ncampaign_data= pd.concat((campaign_data.drop(['start_month_year','end_month_year'],axis=1),pd.get_dummies(campaign_data[['start_month_year','end_month_year']])),axis=1)\ncampaign_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ncampaign_data['date_diff'] = scaler.fit_transform(campaign_data[['date_diff']])\ncampaign_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(campaign_data,on = 'campaign_id', how='left')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## train to coupon_item_mapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(coupon_item_mapping.shape)\ncoupon_item_mapping.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping.item_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## coupon_item_mapping to item_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(item_data.shape)\nitem_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping = coupon_item_mapping.merge(item_data,on='item_id', how='left')\nprint(coupon_item_mapping.shape)\ncoupon_item_mapping.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping.item_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = coupon_item_mapping.groupby('coupon_id', as_index=False)['item_id'].count()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(item_data.shape)\nitem_data.item_id.value_counts().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data = pd.concat((item_data, pd.get_dummies(item_data.brand_type)), axis=1)\nitem_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data = pd.concat((item_data, pd.get_dummies(item_data.category)), axis=1)\nitem_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(item_data.shape)\nitem_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data = item_data.drop(['brand_type', 'category'], axis=1)\nprint(item_data.shape)\nitem_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping = coupon_item_mapping.merge(item_data, on='item_id', how=\"left\")\ncoupon_item_mapping.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [ 'brand_x', 'brand_type', 'category', 'brand_y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping = coupon_item_mapping.drop(cols,axis=1).groupby('coupon_id', as_index = False).agg(['count','sum']).reset_index()\ncoupon_item_mapping.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of column names\ncolumns = ['coupon_id']\n\n# Iterate through the variables names\nfor var in coupon_item_mapping.columns.levels[0]:\n    # Skip the id name\n    if var != 'coupon_id':\n        \n        # Iterate through the stat names\n        for stat in coupon_item_mapping.columns.levels[1][:-1]:\n            # Make a new column name for the variable and stat\n            columns.append('item_%s_%s' % (var, stat))\n\nprint(len(columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coupon_item_mapping.columns = columns\ncoupon_item_mapping.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['coupon_id',\n    'item_item_id_count',\n 'item_Established_sum',\n 'item_Local_sum',\n 'item_Alcohol_sum',\n 'item_Bakery_sum',\n 'item_Dairy, Juices & Snacks_sum',\n 'item_Flowers & Plants_sum',\n 'item_Fuel_sum',\n 'item_Garden_sum',\n 'item_Grocery_sum',\n 'item_Meat_sum',\n 'item_Miscellaneous_sum',\n 'item_Natural Products_sum',\n 'item_Packaged Meat_sum',\n 'item_Pharmaceutical_sum',\n 'item_Prepared Food_sum',\n 'item_Restauarant_sum',\n 'item_Salads_sum',\n 'item_Seafood_sum',\n 'item_Skin & Hair Care_sum',\n 'item_Travel_sum',\n 'item_Vegetables (cut)_sum']\ncoupon_item_mapping = coupon_item_mapping[drop_cols]\ncoupon_item_mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nminmax = MinMaxScaler()\nx = minmax.fit_transform(coupon_item_mapping.drop('coupon_id',axis=1))\nx = pd.DataFrame(x,columns = drop_cols[1:])\nx['coupon_id'] = coupon_item_mapping.coupon_id\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = train.merge(coupon_item_mapping, on='coupon_id', how='left')\ntrain = train.merge(x, on='coupon_id', how='left')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train to customer_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_ex = ['date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data =customer_transaction_data.drop(cols_ex,axis=1).groupby('customer_id', as_index = False).agg(['count','sum','mean','median']).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of column names\ncolumns = ['customer_id']\n\n# Iterate through the variables names\nfor var in customer_transaction_data.columns.levels[0]:\n    # Skip the id name\n    if var != 'customer_id':\n        \n        # Iterate through the stat names\n        for stat in customer_transaction_data.columns.levels[1][:-1]:\n            # Make a new column name for the variable and stat\n            columns.append('customer_%s_%s' % (var, stat))\n\nprint(len(columns))\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_transaction_data.columns = columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_cols = ['customer_id',\n 'customer_item_id_count',\n     'customer_quantity_count',\n 'customer_quantity_sum',\n 'customer_quantity_mean',\n 'customer_quantity_median',\n 'customer_selling_price_count',\n 'customer_selling_price_sum',\n 'customer_selling_price_mean',\n 'customer_selling_price_median',\n 'customer_other_discount_count',\n 'customer_other_discount_sum',\n 'customer_other_discount_mean',\n 'customer_other_discount_median',\n 'customer_coupon_discount_count',\n 'customer_coupon_discount_sum',\n 'customer_coupon_discount_mean',\n 'customer_coupon_discount_median'\n]\ncustomer_transaction_data = customer_transaction_data[useful_cols]\ncustomer_transaction_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minmax2 = MinMaxScaler()\nx2 = minmax2.fit_transform(customer_transaction_data.drop('customer_id',axis=1))\nx2 = pd.DataFrame(x2,columns = useful_cols[1:])\nx2['customer_id'] = customer_transaction_data.customer_id\nx2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(x2, on='customer_id', how='left')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train to customer_demographic"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['no_of_children'].fillna(0,inplace=True)\ncustomer_demographics['family_size'].loc[customer_demographics['family_size'] == '5+'] = '5'\ncustomer_demographics['no_of_children'].loc[customer_demographics['no_of_children'] == '3+'] = '3'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['marital_status'].loc[(customer_demographics['marital_status'].isna()) & \n                      ((customer_demographics['family_size'].astype(int)-customer_demographics['no_of_children'].astype(int)) > 1 )] = 'Married'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['marital_status'].fillna('Single', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics =pd.concat((customer_demographics.drop('age_range',axis=1), pd.get_dummies(customer_demographics['age_range'])),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics['marital_status'] = customer_demographics['marital_status'].map({'Married':0, 'Single':1})\ncustomer_demographics.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_demographics =customer_demographics.astype(int)\ncustomer_demographics.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler2 =MinMaxScaler()\ncustomer_demographics[['family_size','no_of_children','income_bracket']] = scaler2.fit_transform(customer_demographics[['family_size','no_of_children','income_bracket']])\ncustomer_demographics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(customer_demographics, on='customer_id',how='left')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/amexpert-2019/test_QyjYwdj.csv')\ntest = test.merge(campaign_data,on = 'campaign_id', how='left')\ntest = test.merge(x, on='coupon_id', how='left')\ntest = test.merge(x2, on='customer_id', how='left')\ntest = test.merge(customer_demographics, on='customer_id',how='left')\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False)[:20].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['id','campaign_id','coupon_id','customer_id','redemption_status'], axis=1)\ny = pd.DataFrame(train[['redemption_status']], columns=['redemption_status'])\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = X.corrwith(y['redemption_status'])\nc1 = corrmat.sort_values()[0:20].index.tolist()\nc1.extend(corrmat.sort_values()[-20:].index.tolist())\nlen(c1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = test.drop(['id','campaign_id','coupon_id','customer_id'], axis=1)\ntest_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X[c1], y,test_size=0.25, random_state=78)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nmodel = lgb.LGBMClassifier(random_state=50)\n\n# Training set\ntrain_sets = lgb.Dataset(X_train, label = y_train)\ntest_sets = lgb.Dataset(X_test, label = y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Default hyperparamters\nhyperparameters = model.get_params()\n\n# Using early stopping to determine number of estimators.\ndel hyperparameters['n_estimators']\n\n# Perform cross validation with early stopping\ncv_results = lgb.cv(hyperparameters, train_sets, num_boost_round = 10000, nfold = 5, metrics = 'auc', \n           early_stopping_rounds = 100, verbose_eval = False, seed = 42)\n\n# Highest score\nbest = cv_results['auc-mean'][-1]\n\n# Standard deviation of best score\nbest_std = cv_results['auc-stdv'][-1]\n\nprint('The maximium ROC AUC in cross validation was {:.5f} with std of {:.5f}.'.format(best, best_std))\nprint('The ideal number of iterations was {}.'.format(len(cv_results['auc-mean'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report, roc_auc_score\n\n# Optimal number of esimators found in cv\nmodel.n_estimators = len(cv_results['auc-mean'])\n\n# Train and make predicions with model\nmodel.fit(X_train, y_train)\npreds = model.predict_proba(X_test)[:, 1]\nbaseline_auc = roc_auc_score(y_test, preds)\n\nprint('The baseline model scores {:.5f} ROC AUC on the test set.'.format(baseline_auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport csv\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\n\ndef objective(hyperparameters):\n    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n       Writes a new line to `outfile` on every iteration\"\"\"\n    \n    # Keep track of evals\n    global ITERATION\n    \n    ITERATION += 1\n    \n    # Using early stopping to find number of trees trained\n    if 'n_estimators' in hyperparameters:\n        del hyperparameters['n_estimators']\n    \n    # Retrieve the subsample\n    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n    \n    # Extract the boosting type and subsample to top level keys\n    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n    hyperparameters['subsample'] = subsample\n    \n    # Make sure parameters that need to be integers are integers\n    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n\n    start = timer()\n    \n    # Perform n_folds cross validation\n    cv_results = lgb.cv(hyperparameters, train_sets, num_boost_round = 10000, nfold = 5, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n\n    run_time = timer() - start\n    \n    # Extract the best score\n    best_score = cv_results['auc-mean'][-1]\n    \n    # Loss must be minimized\n    loss = 1 - best_score\n    \n    # Boosting rounds that returned the highest cv score\n    n_estimators = len(cv_results['auc-mean'])\n    \n    # Add the number of estimators to the hyperparameters\n    hyperparameters['n_estimators'] = n_estimators\n\n    # Write to the csv file ('a' means append)\n    of_connection = open(OUT_FILE, 'a')\n    writer = csv.writer(of_connection)\n    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n    of_connection.close()\n\n    # Dictionary with information for evaluation\n    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n            'train_time': run_time, 'status': STATUS_OK}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import hp\nfrom hyperopt.pyll.stochastic import sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the learning rate\nlearning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2))}\nlearning_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_dist = []\n\n# Draw 10000 samples from the learning rate domain\nfor _ in range(10000):\n    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n    \nplt.figure(figsize = (8, 6))\nsns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\nplt.title('Learning Rate Distribution', size = 18); plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Discrete uniform distribution\nnum_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\nnum_leaves_dist = []\n\n# Sample 10000 times from the number of leaves distribution\nfor _ in range(10000):\n    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n    \n# kdeplot\nplt.figure(figsize = (8, 6))\nsns.kdeplot(num_leaves_dist, linewidth = 2, shade = True);\nplt.title('Number of Leaves Distribution', size = 18); plt.xlabel('Number of Leaves', size = 16); plt.ylabel('Density', size = 16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# boosting type domain \nboosting_type = {'boosting_type': hp.choice('boosting_type', \n                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n                                             {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n                                             {'boosting_type': 'goss', 'subsample': 1.0}])}\n\n# Draw a sample\nhyperparams = sample(boosting_type)\nhyperparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Retrieve the subsample if present otherwise set to 1.0\nsubsample = hyperparams['boosting_type'].get('subsample', 1.0)\n\n# Extract the boosting type\nhyperparams['boosting_type'] = hyperparams['boosting_type']['boosting_type']\nhyperparams['subsample'] = subsample\n\nhyperparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the search space\nspace = {\n    'boosting_type': hp.choice('boosting_type', \n                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample from the full space\nx = sample(space)\n\n# Conditional logic to assign top-level keys\nsubsample = x['boosting_type'].get('subsample', 1.0)\nx['boosting_type'] = x['boosting_type']['boosting_type']\nx['subsample'] = subsample\n\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sample(space)\nsubsample = x['boosting_type'].get('subsample', 1.0)\nx['boosting_type'] = x['boosting_type']['boosting_type']\nx['subsample'] = subsample\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new file and open a connection\nOUT_FILE = 'bayes_test.csv'\nof_connection = open(OUT_FILE, 'w')\nwriter = csv.writer(of_connection)\n\nITERATION = 0\n\n# Write column names\nheaders = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\nwriter.writerow(headers)\nof_connection.close()\n\n# Test the objective function\nresults = objective(sample(space))\nprint('The cross validation loss = {:.5f}.'.format(results['loss']))\nprint('The optimal number of estimators was {}.'.format(results['hyperparameters']['n_estimators']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import tpe\n\n# Create the algorithm\ntpe_algorithm = tpe.suggest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import Trials\n\n# Record results\ntrials = Trials()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a file and open a connection\nOUT_FILE = 'bayes_test.csv'\nof_connection = open(OUT_FILE, 'w')\nwriter = csv.writer(of_connection)\n\nITERATION = 0\n\n# Write column names\nheaders = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\nwriter.writerow(headers)\nof_connection.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import fmin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Global variable\nglobal  ITERATION\n%time\nITERATION = 0\nMAX_EVALS = 5\n# Run optimization\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n            max_evals = MAX_EVALS)\n\nbest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort the trials with lowest loss (highest AUC) first\ntrials_dict = sorted(trials.results, key = lambda x: x['loss'])\ntrials_dict[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.read_csv(OUT_FILE)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\n\ndef evaluate(results, name):\n    \"\"\"Evaluate model on test data using hyperparameters in results\n       Return dataframe of hyperparameters\"\"\"\n    \n    new_results = results.copy()\n    # String to dictionary\n    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n    \n    # Sort with best values on top\n    new_results = new_results.sort_values('score', ascending = False).reset_index(drop = True)\n    \n    # Print out cross validation high score\n    print('The highest cross validation score from {} was {:.5f} found on iteration {}.'.format(name, new_results.loc[0, 'score'], new_results.loc[0, 'iteration']))\n    \n    # Use best hyperparameters to create a model\n    hyperparameters = new_results.loc[0, 'hyperparameters']\n    model = lgb.LGBMClassifier(**hyperparameters)\n    \n    # Train and make predictions\n    model.fit(X_train, y_train)\n    preds = model.predict_proba(X_test)[:, 1]\n    \n    print('ROC AUC from {} on test data = {:.5f}.'.format(name, roc_auc_score(y_test, preds)))\n    \n    # Create dataframe of hyperparameters\n    hyp_df = pd.DataFrame(columns = list(new_results.loc[0, 'hyperparameters'].keys()))\n\n    # Iterate through each set of hyperparameters that were evaluated\n    for i, hyp in enumerate(new_results['hyperparameters']):\n        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n                               ignore_index = True)\n        \n    # Put the iteration and score in the hyperparameter dataframe\n    hyp_df['iteration'] = new_results['iteration']\n    hyp_df['score'] = new_results['score']\n    \n    return hyp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nbayes_results = evaluate(results, name = 'Bayesian')\nbayes_results\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_EVALS = 10\n\n# Continue training\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n            max_evals = MAX_EVALS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\n# Save the trial results\nwith open('trials.json', 'w') as f:\n    f.write(json.dumps(trials_dict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bayes_results = pd.read_csv('../input/home-credit-model-tuning/bayesian_trials_1000.csv').sort_values('score', ascending = False).reset_index()\nrandom_results = pd.read_csv('../input/home-credit-model-tuning/random_search_trials_1000.csv').sort_values('score', ascending = False).reset_index()\nrandom_results['loss'] = 1 - random_results['score']\n\nbayes_params = evaluate(bayes_results, name = 'Bayesian')\nrandom_params = evaluate(random_results, name = 'random')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe of just scores\nscores = pd.DataFrame({'ROC AUC': random_params['score'], 'iteration': random_params['iteration'], 'search': 'Random'})\nscores = scores.append(pd.DataFrame({'ROC AUC': bayes_params['score'], 'iteration': bayes_params['iteration'], 'search': 'Bayesian'}))\n\nscores['ROC AUC'] = scores['ROC AUC'].astype(np.float32)\nscores['iteration'] = scores['iteration'].astype(np.int32)\n\nscores.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_random_params = random_params.iloc[random_params['score'].idxmax(), :].copy()\nbest_bayes_params = bayes_params.iloc[bayes_params['score'].idxmax(), :].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot of scores over the course of searching\nsns.lmplot('iteration', 'ROC AUC', hue = 'search', data = scores, size = 8);\nplt.scatter(best_bayes_params['iteration'], best_bayes_params['score'], marker = '*', s = 400, c = 'orange', edgecolor = 'k')\nplt.scatter(best_random_params['iteration'], best_random_params['score'], marker = '*', s = 400, c = 'blue', edgecolor = 'k')\nplt.xlabel('Iteration'); plt.ylabel('ROC AUC'); plt.title(\"Validation ROC AUC versus Iteration\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import altair as alt\n\nalt.renderers.enable('notebook')\n\nc = alt.Chart(scores).mark_circle().encode(x = 'iteration', y = alt.Y('ROC AUC', \n                                                                  scale = alt.Scale(domain = [0.64, 0.74])),\n                                       color = 'search')\nc.title = 'Validation ROC AUC vs Iteration'\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 8))\nplt.rcParams['font.size'] = 18\n\n# Density plots of the learning rate distributions \nsns.kdeplot(learning_rate_dist, label = 'Sampling Distribution', linewidth = 4)\nsns.kdeplot(random_params['learning_rate'], label = 'Random Search', linewidth = 4)\nsns.kdeplot(bayes_params['learning_rate'], label = 'Bayes Optimization', linewidth = 4)\nplt.vlines([best_random_params['learning_rate'], best_bayes_params['learning_rate']],\n           ymin = 0.0, ymax = 50.0, linestyles = '--', linewidth = 4, colors = ['orange', 'green'])\nplt.legend()\nplt.xlabel('Learning Rate'); plt.ylabel('Density'); plt.title('Learning Rate Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate through each hyperparameter\nfor i, hyper in enumerate(random_params.columns):\n    if hyper not in ['class_weight', 'n_estimators', 'score', 'is_unbalance',\n                    'boosting_type', 'iteration', 'subsample', 'metric', 'verbose', 'loss', 'learning_rate']:\n        plt.figure(figsize = (14, 6))\n        # Plot the random search distribution and the bayes search distribution\n        if hyper != 'loss':\n            sns.kdeplot([sample(space[hyper]) for _ in range(1000)], label = 'Sampling Distribution', linewidth = 4)\n        sns.kdeplot(random_params[hyper], label = 'Random Search', linewidth = 4)\n        sns.kdeplot(bayes_params[hyper], label = 'Bayes Optimization', linewidth = 4)\n        plt.vlines([best_random_params[hyper], best_bayes_params[hyper]],\n                     ymin = 0.0, ymax = 10.0, linestyles = '--', linewidth = 4, colors = ['orange', 'green'])\n        plt.legend(loc = 1)\n        plt.title('{} Distribution'.format(hyper))\n        plt.xlabel('{}'.format(hyper)); plt.ylabel('Density');\n        plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 4, figsize = (24, 6))\ni = 0\n\n# Plot of four hyperparameters\nfor i, hyper in enumerate(['colsample_bytree', 'learning_rate', 'min_child_samples', 'num_leaves']):\n    \n        # Scatterplot\n        sns.regplot('iteration', hyper, data = bayes_params, ax = axs[i])\n        axs[i].scatter(best_bayes_params['iteration'], best_bayes_params[hyper], marker = '*', s = 200, c = 'k')\n        axs[i].set(xlabel = 'Iteration', ylabel = '{}'.format(hyper), title = '{} over Search'.format(hyper));\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 4, figsize = (24, 6))\ni = 0\n\n# Scatterplot of next three hyperparameters\nfor i, hyper in enumerate(['reg_alpha', 'reg_lambda', 'subsample_for_bin', 'subsample']):\n        sns.regplot('iteration', hyper, data = bayes_params, ax = axs[i])\n        axs[i].scatter(best_bayes_params['iteration'], best_bayes_params[hyper], marker = '*', s = 200, c = 'k')\n        axs[i].set(xlabel = 'Iteration', ylabel = '{}'.format(hyper), title = '{} over Search'.format(hyper));\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, sharey = True, sharex = True)\n\n# Bar plots of boosting type\nrandom_params['boosting_type'].value_counts().plot.bar(ax = axs[0], figsize = (14, 6), color = 'orange', title = 'Random Search Boosting Type')\nbayes_params['boosting_type'].value_counts().plot.bar(ax = axs[1], figsize = (14, 6), color = 'green', title = 'Bayes Optimization Boosting Type');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bars = alt.Chart(random_params, width = 500).mark_bar(color = 'orange').encode(x = 'boosting_type', y = alt.Y('count()', scale = alt.Scale(domain = [0, 400])))\ntext = bars.mark_text(size = 20, align = 'center', baseline = 'bottom').encode(text = 'count()')\n\nbars + text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bars = alt.Chart(bayes_params, width = 500).mark_bar(color = 'green').encode(x = 'boosting_type', y = alt.Y('count()', scale = alt.Scale(domain = [0, 800])))\ntext = bars.mark_text(size = 20, align = 'center', baseline = 'bottom').encode(text = 'count()')\n\nbars + text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_results['hyperparameters'] = random_results['hyperparameters'].map(ast.literal_eval)\nbayes_results['hyperparameters'] = bayes_results['hyperparameters'].map(ast.literal_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set2 = lgb.Dataset(X, label = y)\n\nhyperparameters = dict(**random_results.loc[0, 'hyperparameters'])\ndel hyperparameters['n_estimators']\n\n# Cross validation with n_folds and early stopping\ncv_results = lgb.cv(hyperparameters, train_set2,\n                    num_boost_round = 10000, early_stopping_rounds = 100, \n                    metrics = 'auc', nfold = 5)\n\nprint('The cross validation score on the full dataset  for Random Search= {:.5f} with std: {:.5f}.'.format(\n    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\nprint('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\nmodel.fit(X, y)\n\nfinal_preds = model.predict_proba(test_set)[:, 1]\n\n# submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': preds})\n# submission.to_csv('submission_random_search.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\nprint(classification_report(preds, y_test))\nprint(f1_score(preds, y_test))\nprint(roc_auc_score(preds, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(test_set[c1])\nsubmission['redemption_status'] = prediction\nprint(submission.shape)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y['redemption_status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['redemption_status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport base64\n\ndef create_download_link(df, title = \"Download CSV file\", filename = \"output.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}