{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[['diagnosis']].groupby('diagnosis').size()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['diagnosis'] == 'M'].groupby(data['diagnosis']).count()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['diagnosis'] != 'M'].groupby(data['diagnosis']).count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns=['Unnamed: 32'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns=['id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndata['diagnosis'] = le.fit_transform(data['diagnosis'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source=data.drop(columns=['Unnamed: 32','id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrainingDataSet, evaluationDataSet = train_test_split(data_source, test_size = 0.2)\nprint(\n    \" Training data set : \",\n     trainingDataSet.shape,\n     \"\\n\",\n    \"Evalutation data set : \",\n    evaluationDataSet.shape\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\nimport torch.utils.data as data_utils","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data_utils.TensorDataset(torch.Tensor(np.array(trainingDataSet.drop(columns=['diagnosis']))), torch.Tensor(np.array(trainingDataSet['diagnosis'])))\ntrain_loader = data_utils.DataLoader(train, batch_size = 150, shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = data_utils.TensorDataset(torch.Tensor(np.array(evaluationDataSet.drop(columns=['diagnosis']))), torch.Tensor(np.array(evaluationDataSet['diagnosis'])))\ntest_loader = data_utils.DataLoader(test, batch_size = 150, shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in train_loader:\n    images, labels = batch \n    out = images                  # Generate predictions\nprint(out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CancerClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        labels=labels.view(len(labels),1)\n        loss = F.binary_cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)  \n        #return {'val_loss': loss.detach(), 'val_acc': acc}\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)     # Generate predictions\n        labels=labels.view(len(labels),1)\n        loss = F.binary_cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\ndef evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SGD Plain Vannila\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(train_loss,test_loss):\n    losses_test = [x['val_loss'] for x in test_loss]\n    losses_train = [x['val_loss'] for x in train_loss]\n    plt.plot(losses_test, '-x',label='Test Loss')\n    plt.plot(losses_train, '--',label='Training Loss')\n    plt.legend([\"Test Loss\", \"Training Loss\"], loc =\"lower right\") \n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.title('Loss vs. No. of epochs');\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(test_accuracy,train_accuracy):\n    accuracy_test = [x['val_acc'] for x in test_accuracy]\n    accuracy_train = [x['val_acc'] for x in train_accuracy]\n    plt.plot(accuracy_test, '-x',label='Test Accuracy')\n    plt.plot(accuracy_train, '--',label='Training Accuracy')\n    plt.legend([\"Test Accuracy\", \"Training Accuracy\"], loc =\"lower right\") \n    plt.xlabel('epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy vs. No. of epochs');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Actual Model\nclass BreastCancerIndentification(CancerClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(30, 60)\n        self.linear2 = nn.Linear(60, 30)\n        self.linear3 = nn.Linear(30, 1)\n        #            layers.Dense(1, activation=\"sigmoid\")(x)\n    def forward(self, xb):\n        # Max pooling over a (2, 2) window\n        #print(self.num_flat_features(xb))\n        xb = F.relu(self.linear1(xb))\n        xb = F.relu(self.linear2(xb))\n        xb = F.sigmoid(self.linear3(xb))\n        return xb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BreastCancerIndentification()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1=BreastCancerIndentification()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [evaluate(model, test_loader)]\nhistory_train=[evaluate(model1, train_loader)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history += fit(100, 1e-1, model, train_loader, test_loader)\nhistory_train += fit(100, 1e-1, model1, train_loader, train_loader)\n#history += fit(10, 1e-2, model, train_loader, test_loader)\n#history_train += fit(10, 1e-2, model1, train_loader, train_loader)\n#history += fit(10, 1e-3, model, train_loader, test_loader)\n#history_train += fit(10, 1e-3, model1, train_loader, train_loader)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model1, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history,history_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history,history_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_Probability=[]\nY_Actual=[]\nfor batch in test_loader:\n   img,label=batch\n   try:\n    outputs2=model(img)\n    if len(Y_Probability)==0:\n        _,pred = torch.max(outputs2, 1)\n        Y_Probability=pred.detach().numpy()\n        Y_Actual=label.detach().numpy()\n    else:\n       if len(outputs2.detach().numpy()[:,-1])==len(label.detach().numpy()):\n           _,pred = torch.max(outputs2, 1)\n           pred=pred.detach().numpy()\n           Y_Actual=np.append(Y_Actual,label.detach().numpy())        #print('hihi')\n           Y_Probability=np.append(Y_Probability, pred)\n   except:\n       print('skipped')\n        \nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_Actual, Y_Probability))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SGD with momentum\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr, momentum=0.9)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BreastCancerIndentification()\nmodel1=BreastCancerIndentification()\n\nhistory = [evaluate(model, test_loader)]\nhistory_train=[evaluate(model1, train_loader)]\nhistory += fit(50, 1e-1, model, train_loader, test_loader)\nhistory_train += fit(50, 1e-1, model1, train_loader, train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_Probability=[]\nY_Actual=[]\nfor batch in test_loader:\n   img,label=batch\n   try:\n    outputs2=model(img)\n    if len(Y_Probability)==0:\n        _,pred = torch.max(outputs2, 1)\n        Y_Probability=pred.detach().numpy()\n        Y_Actual=label.detach().numpy()\n    else:\n       if len(outputs2.detach().numpy()[:,-1])==len(label.detach().numpy()):\n           _,pred = torch.max(outputs2, 1)\n           pred=pred.detach().numpy()\n           Y_Actual=np.append(Y_Actual,label.detach().numpy())        #print('hihi')\n           Y_Probability=np.append(Y_Probability, pred)\n   except:\n       print('skipped')\n        \nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_Actual, Y_Probability))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adam Vannila\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BreastCancerIndentification()\nmodel1=BreastCancerIndentification()\n\nhistory = [evaluate(model, test_loader)]\nhistory_train=[evaluate(model1, train_loader)]\nhistory += fit(50, 1e-1, model, train_loader, test_loader)\nhistory_train += fit(50, 1e-1, model1, train_loader, train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_Probability=[]\nY_Actual=[]\nfor batch in test_loader:\n   img,label=batch\n   try:\n    outputs2=model(img)\n    if len(Y_Probability)==0:\n        _,pred = torch.max(outputs2, 1)\n        Y_Probability=pred.detach().numpy()\n        Y_Actual=label.detach().numpy()\n    else:\n       if len(outputs2.detach().numpy()[:,-1])==len(label.detach().numpy()):\n           _,pred = torch.max(outputs2, 1)\n           pred=pred.detach().numpy()\n           Y_Actual=np.append(Y_Actual,label.detach().numpy())        #print('hihi')\n           Y_Probability=np.append(Y_Probability, pred)\n   except:\n       print('skipped')\n        \nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_Actual, Y_Probability))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RNN Model\nclass BreastCancerIndentification(CancerClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.hidden_dim = 60\n        self.n_layers = 1\n        self.rnn = nn.RNN(30, self.hidden_dim, self.n_layers, batch_first=True)   \n        # Fully connected layer\n        self.fc = nn.Linear(60, 1)\n\n    def forward(self, xb):\n        # Max pooling over a (2, 2) window\n        #print(self.num_flat_features(xb))\n        hidden = self.init_hidden(batch_size=len(xb))\n        # Passing in the input and hidden state into the model and obtaining outputs\n        xb=xb.resize_((len(xb),1,30))\n        #print(xb.size())\n        out, hidden = self.rnn(xb, hidden)\n        #print(out.size())\n        # Reshaping the outputs such that it can be fit into the fully connected layer\n        out = out.contiguous().view(-1, self.hidden_dim)\n        out = F.sigmoid(self.fc(out))\n        return out\n    \n    def init_hidden(self, batch_size):\n        # This method generates the first hidden state of zeros which we'll use in the forward pass\n        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n        return hidden\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SGD Plain Vannila\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BreastCancerIndentification()\nmodel1=BreastCancerIndentification()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [evaluate(model, test_loader)]\nhistory += fit(50, 1e-2, model, train_loader, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_train=[evaluate(model1, train_loader)]\nhistory_train += fit(50, 1e-2, model1, train_loader, train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history,history_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history,history_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_Probability=[]\nY_Actual=[]\nfor batch in test_loader:\n   img,label=batch\n   try:\n    outputs2=model(img)\n    if len(Y_Probability)==0:\n        _,pred = torch.max(outputs2, 1)\n        Y_Probability=pred.detach().numpy()\n        Y_Actual=label.detach().numpy()\n    else:\n       if len(outputs2.detach().numpy()[:,-1])==len(label.detach().numpy()):\n           _,pred = torch.max(outputs2, 1)\n           pred=pred.detach().numpy()\n           Y_Actual=np.append(Y_Actual,label.detach().numpy())        #print('hihi')\n           Y_Probability=np.append(Y_Probability, pred)\n   except:\n       print('skipped')\n        \nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_Actual, Y_Probability))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}