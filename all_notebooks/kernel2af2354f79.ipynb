{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Отток клиентов"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n\nНужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n\nПостройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n\nДополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n\nИсточник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"},{"metadata":{},"cell_type":"markdown","source":"# 1. Подготовка данных"},{"metadata":{},"cell_type":"markdown","source":"## 1.1. Проверка качества данных "},{"metadata":{"trusted":true},"cell_type":"code","source":"#импортируем библиотеки необходимые для подготовки данных\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/bank-customer-churn-modeling/Churn_Modelling.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"целевой признак Exited — факт ухода клиента — категориальный признак => задача будет достигаться методами классификации."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Tenure'] = data['Tenure'].fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Geography'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Датасет содержить 10000 строк, явных пропусков не обнаружено.  \nТребуемые изменения: \n1. RowNumber — столбец дублирует информацию стандартного датафрейма и не несетя ценности для обучения модели. Поэтому столбец можно удалить\n2. CustomerId — является идентификатором пользователя (по данному столбцу значению необходимо проверить наличие дубликатов) и если отсутсвуют — стоблец также можно удалить. \t\n3. Surname — является идентифицирующей пользователя информацией, содержит 2932 уникальных значений (данные kaggle), что сильно усложняет задачу, но не несет ценности для качества будущей модели — столбец можно удалить. \n4. CreditScore — следует проверить распределение и сохранить данный столбец. \n5. Geography — всего 3 уникальных значения France', 'Spain', 'Germany' — выполнить преобразование OHE / ordinal encoding \n6. Gender — значение преобразовать — OHE / ordinal encoding. \n7. Age — Exited — тип данных верны, требуется проработка OHE. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['CustomerId'].value_counts().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Дупликатов в данных не обнаружено.  \nПриступим к изменению оптимизации всего датафрейма. Сначала уберем лишние столбцы. "},{"metadata":{},"cell_type":"markdown","source":"## 1.2. Подготовка данных для машинного обучения"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Обозначим новый датафрейм \"data_ml\" — данные для машинного обучения\n#Удалим столбцы-идентификаторы, не представляющие ценностия для алгоритма \n#for_drop = ['RowNumber','CustomerId', 'Surname']\nfor_drop = ['RowNumber','CustomerId', 'Surname']\ndata_ml = data.drop(for_drop, axis=1)\ndata_ml.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ml.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Данные подготовим методом OHE, что позволит нам использовать модели, деревое решений, случайный лес и логистическую регрессию."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ml = pd.get_dummies(data_ml, drop_first=True)\ndata_ml.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ml.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В новом датафрейме мы получили 12 столбцов.  \nСтолбец Geography содержал 3 класса,  Gender_Male 2 класса — в результате мы получили только 2 и 1 столбцов соответственно, что позволяет избежать дами-ловушки. "},{"metadata":{},"cell_type":"markdown","source":"## 1.3. Формирование выборок: обучающая, валидационная, тестовая"},{"metadata":{},"cell_type":"markdown","source":"В нашем случае нет отдельно выделенной тестовой выборки, поэтому существющие данные мы делим на три выборки: \n- обучающая 60% для обучения модели\n- валидационная 20% для выбора лучшего алгоритма и оптимальных параметров\n- тестовая 20% для финального теста лучшей модели."},{"metadata":{"trusted":true},"cell_type":"code","source":"#разделим на признаки и целевой признак\nfeatures = data_ml.drop('Exited', axis=1)\ntarget = data_ml['Exited']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Разделение выборки произведем в 2 этапа:\n1. Выделим валидационную 60%\n2. Разделим оставшиеся 40% на 2 равные части (валидационная и тестовая)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Выделим валидационную 60%\nfeatures_train, features_validtest, target_train, target_validtest = train_test_split(features,\n                                                    target,\n                                                    train_size=0.6,\n                                                    random_state=12345, \n                                                    stratify=target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Признаки обучающей выборки:',features_train.shape,  \n      'Целевой признак обучающей выборки:', target_train.shape, \n      'Валидационная и тестовая вместе', features_validtest.shape, target_validtest.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2. Разделим оставшиеся 40% на 2 равные части (валидационная и тестовая)\nfeatures_valid, features_test, target_valid, target_test = train_test_split(features_validtest,\n                                                    target_validtest,\n                                                    train_size=0.5,\n                                                    random_state=12345, \n                                                    stratify=target_validtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(features_valid.shape, target_valid.shape, features_test.shape, target_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Полученые выбрки:   \n**Обучающая**   \nfeatures_train  \ntarget_train  \n\n**Валидационная**   \nfeatures_valid  \ntarget_valid  \n\n**Тестовая**   \nfeatures_test  \ntarget_test  "},{"metadata":{},"cell_type":"markdown","source":"## 1.4. Масштабирование признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"#импортируем библиотеку для стандартноо масштабирования\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Для масштабирования зафиксируем численные признаки\nnumeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создадим объект этой структуры и настроим его на обучающих данных:\nscaler = StandardScaler()\nscaler.fit(features_train[numeric])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Масштабируем численные признаки обучающей выборки \nfeatures_train[numeric] = scaler.transform(features_train[numeric])\nfeatures_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Масштабируем численные признаки валидационной выборки \nfeatures_valid[numeric] = scaler.transform(features_valid[numeric])\nfeatures_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Масштабируем численные признаки тестовой выборки \nfeatures_test[numeric] = scaler.transform(features_test[numeric])\nfeatures_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В результате мы получили масштабированные признаки для трех выборок. Перейдем к исследованию задачим моделями машинного обучения. "},{"metadata":{},"cell_type":"markdown","source":"# 2. Исследование задачи"},{"metadata":{},"cell_type":"markdown","source":"Для исследовательского обучения используем три модели"},{"metadata":{},"cell_type":"markdown","source":"2.1 Обучение моделей"},{"metadata":{"trusted":true},"cell_type":"code","source":"#импорт библиотек трех моделей\n#Деревое решений\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Случайный лес \nfrom sklearn.ensemble import RandomForestClassifier\n\n#Логистическая регрессия\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Импортируем необходимые метики\n#метика accuracy\nfrom sklearn.metrics import accuracy_score\n\n#матрица ошибок\nfrom sklearn.metrics import confusion_matrix\n\n#полнота\nfrom sklearn.metrics import recall_score\n\n#точность\nfrom sklearn.metrics import precision_score\n\n#F-1 мера\nfrom sklearn.metrics import f1_score\n\n#AUC-ROC\nfrom sklearn.metrics import roc_auc_score\n\n#ROC-кривая\nfrom sklearn.metrics import roc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.1. Точность разных моделей**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def all_models_accuracy(features_train, target_train, features_valid, target_valid):\n    model_DTC = DecisionTreeClassifier(random_state=123)\n    DTC_score = model_DTC.fit(features_train, target_train).score(features_valid, target_valid)\n    \n    model_RFC = RandomForestClassifier(random_state=12345, n_estimators = 100)\n    RFC_score = model_RFC.fit(features_train, target_train).score(features_valid, target_valid)\n    \n    model_LgR = LogisticRegression(solver = 'liblinear')\n    LgR_score = model_LgR.fit(features_train, target_train).score(features_valid, target_valid)\n    print(\"Точность:\" \"дерево решений\", DTC_score, \"случайный лес \", RFC_score, \"логистческая регрессия\", LgR_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_models_accuracy(features_train, target_train, features_valid, target_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.2 Проверка баланса классов выборки**"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_train.value_counts(normalize = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_valid.value_counts(normalize = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"У обучающией и валидационной выборок наблюдается заметный дисбаланс класов. Ответы 0 ≈80% , 1 ≈ 20%  \nМожно ожидать, что результаты предсказаний моделей будут сильно склоняться к одному варианту ответов. "},{"metadata":{},"cell_type":"markdown","source":"**2.3 Проверка адекватности**"},{"metadata":{},"cell_type":"markdown","source":"Проверим какое соотношение ответов выдает каждая модель."},{"metadata":{"trusted":true},"cell_type":"code","source":"def all_models_share(features_train, target_train, features_valid, target_valid):\n    model_DTC = DecisionTreeClassifier(random_state=123)\n    model_DTC.fit(features_train, target_train)\n    DTC_share = pd.Series(model_DTC.predict(features_valid)).value_counts(normalize = 1)\n    \n    \n    \n    model_RFC = RandomForestClassifier(random_state=12345, n_estimators = 100)\n    model_RFC.fit(features_train, target_train)\n    RFC_share = pd.Series(model_RFC.predict(features_valid)).value_counts(normalize = 1)\n    \n    model_LgR = LogisticRegression(solver = 'liblinear')\n    model_LgR.fit(features_train, target_train)\n    LgR_share = pd.Series(model_LgR.predict(features_valid)).value_counts(normalize = 1)\n    \n\n    \n    print(\"Доли ответов:\" \"дерево решений\", DTC_share, \"случайный лес \", RFC_share, \"логистческая регрессия\", LgR_share , end='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_models_share(features_train, target_train, features_valid, target_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Логистичесая регрессия показывала самую высокую точность, но данная модель выдает 100% одинаковый результат = 0  \nСравним качество предсказаний с константной моделью. За константу примем пример 0, так как это значение встречается 80% случаев "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создаем константную модель\ntarget_predict_constant = pd.Series([0]*len(target_valid))\ntarget_predict_constant.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score_constant = accuracy_score(target_valid, target_predict_constant)\naccuracy_score_constant","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность моделей: дерево решений 0.2915 случайный лес  0.5 логистческая регрессия 0.796  \nТочность константной модели: 0.796    \nНи одна модель не показал результат выше констентной модели, вероятно проблема кроется в дисбалансе классов.    \n\nЧтобы разобраться подбробнее ознакомися с матрицой ошибок для каждой модели.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#матрица ошибок для дерево решений\nmodel_DTC = DecisionTreeClassifier(random_state=123)\nmodel_DTC.fit(features_train, target_train)\nDTC_prediction = model_DTC.predict(features_valid)\nconfusion_matrix(target_valid, DTC_prediction)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Дерево решений склонно выдавать позитивные предсказания, очень высокое количество ложных позитивных предсказания (FP)  \nИзучим полноту, точность и F1-меру"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rec_prec_f1(target_valid, prediction):\n    print(\"Полнота\" , recall_score(target_valid, prediction))\n    print(\"Точность\", precision_score(target_valid, prediction))\n    print(\"F1-мера\", f1_score(target_valid, prediction))\n    print(\"AUC-ROC\", roc_auc_score(target_valid, prediction))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#полнота, точность и F1-мера для дерева решений\nrec_prec_f1(target_valid, DTC_prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Низкое значние F1- меры свидетельствует о низком качестве модели, проблема в точности. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#матрица ошибок для случайного леса\nmodel_RFC = RandomForestClassifier(random_state=12345, n_estimators = 100)\nmodel_RFC.fit(features_train, target_train)\nRFC_prediction = model_RFC.predict(features_valid)\nconfusion_matrix(target_valid, RFC_prediction)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Случайный лес примерно равную пропорцию позитивных и негативных предсказаний, выдает заметно больше качественных предсказаний, но также сильно склоняется к ложно позитивным предсказаниям (FP)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#полнота, точность и F1-мера для случайного леса\nrec_prec_f1(target_valid, RFC_prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Низкое значние F1- меры свидетельствует о низком качестве модели, проблема в точности. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#матрица ошибок для логистической регрессии\nmodel_LgR = LogisticRegression(solver = 'liblinear')\nmodel_LgR.fit(features_train, target_train)\nLgR_prediction = model_LgR.predict(features_valid)\nconfusion_matrix(target_valid, LgR_prediction)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для логистической регрессии расчитаем метрику AUC-ROC"},{"metadata":{"trusted":true},"cell_type":"code","source":"LgR_probabilities_one_valid = model_LgR.predict_proba(features_valid)[:, 1]\n\nauc_roc_LgR = roc_auc_score(target_valid, LgR_probabilities_one_valid)\n\nauc_roc_LgR","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(target_valid, LgR_probabilities_one_valid) \n\nplt.figure()\nplt.plot(fpr, tpr)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-кривая')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LgR_probabilities_one_valid = model_LgR.predict_proba(features_valid)[:, 1]\n\nauc_roc_LgR = roc_auc_score(target_valid, LgR_probabilities_one_valid)\n\nauc_roc_LgR","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(target_valid, LgR_probabilities_one_valid) \n\nplt.figure()\nplt.plot(fpr, tpr)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-кривая')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#попробуем обучать логистическую регресию сбалансировав классы\nmodel_LgR = LogisticRegression(solver = 'liblinear', class_weight='balanced')\nmodel_LgR.fit(features_train, target_train)\nLgR_probabilities_one_valid_class_weight = model_LgR.predict_proba(features_valid)[:, 1]\nprint(\"Score\", model_LgR.score(features_valid, target_valid))\nprint(\"AUC-ROC\", roc_auc_score(target_valid, LgR_probabilities_one_valid_class_weight))\n\nfpr, tpr, thresholds = roc_curve(target_valid, LgR_probabilities_one_valid_class_weight) \nplt.figure()\nplt.plot(fpr, tpr)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-кривая')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность предсказаний не улучшилась."},{"metadata":{},"cell_type":"markdown","source":"Логистическая регрессия выдает 100% негативных предсказаний — высокая точность модели объясняется высокой долей негативных ответов в валидационной выборке.  \n\nПерейдем к формированию сбалансированных выборок"},{"metadata":{},"cell_type":"markdown","source":"# 3. Исследование и обучение моделей на сбалансированной выборке"},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Борьба с дисбалансом"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как мы выяснили ранее в нашей выборке отрицательны ответов ≈80% , положитительных ≈ 20%.   \nНам необходмо увеличить количество положительных ответов в 4 раза для достижения баланса.   "},{"metadata":{},"cell_type":"markdown","source":"1. Разделим обучающую выборку на отрицательные и положительные объекты;\n2. Скопируем несколько раз положительные объекты;\n3. С учётом полученных данных создадим новую обучающую выборку;\n4. Перемешаем данные: идущие друг за другом одинаковые вопросы не помогут обучению.\n5. Обучим новые модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ознакомимся с пероначальным распределением классов\ntarget_train.value_counts(normalize = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_train.plot(kind ='hist', bins=2, figsize=(1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#создадим функцию для увеличения представленной класса в выборке \ndef upsample(features, target, repeat, upsampled_сlass):\n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n    \n    if upsampled_сlass == 0:\n        features_upsampled = pd.concat([features_zeros]* repeat + [features_ones] )\n        target_upsampled = pd.concat([target_zeros]* repeat + [target_ones] )\n        features_upsampled, target_upsampled = shuffle(\n        features_upsampled, target_upsampled, random_state=12345)\n        \n    elif upsampled_сlass == 1:\n        features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n        target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n        features_upsampled, target_upsampled = shuffle(\n        features_upsampled, target_upsampled, random_state=12345)\n    else:\n        features_upsampled = 0\n        target_upsampled = 0  \n        \n        \n       \n    return features_upsampled, target_upsampled\n    \"Функция принимаем значение признаков (features[]), целевого признака (target[]), repeat(int / float), \"\n    \" класс который будет увеличен (upsampled_сlass (0 or 1))\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Протестируем функцию (верное значение)\nfeatures_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 4, 0)\nprint(target_train_upsampled.value_counts(normalize = 1))\nprint(target_train_upsampled.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Протестируем функцию (верное значение)\nfeatures_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 4, 3)\nfeatures_train_upsampled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#применим функцию upsample \n#увеличим количество положительных ответов в 4 раза\nfeatures_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 4, 1)\nprint(target_train_upsampled.value_counts(normalize = 1))\nprint(target_train_upsampled.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_train_upsampled.plot(kind ='hist', bins=2, figsize=(1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы получили сбалансированное количество классов, перейдем к обучению моеделей на новы данных."},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Обучение моделей на сбаланированной выборке"},{"metadata":{},"cell_type":"markdown","source":"#### Точность (score)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#точность моделей на выборке с дисбалансом\nall_models_accuracy(features_train, target_train, features_valid, target_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#точность моделей на сбалансированной выборке\nall_models_accuracy(features_train_upsampled, target_train_upsampled, features_valid, target_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность моделей изменились незначительно, но проверим изменилось ли качество ответов. "},{"metadata":{},"cell_type":"markdown","source":"#### Качество предсказаний"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Решающее дерево\nmodel_DTC_upsampled = DecisionTreeClassifier(random_state=123)\nmodel_DTC_upsampled.fit(features_train_upsampled, target_train_upsampled)\nDTC_prediction_upsampled = model_DTC_upsampled.predict(features_valid)\nrec_prec_f1(target_valid, DTC_prediction_upsampled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Случайный лес\nmodel_RFC_upsampled = RandomForestClassifier(random_state=12345, n_estimators = 100)\nmodel_RFC_upsampled.fit(features_train_upsampled, target_train_upsampled)\nRFC_prediction_upsampled = model_RFC_upsampled.predict(features_valid)\nrec_prec_f1(target_valid, RFC_prediction_upsampled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Логистическая регрессия\nmodel_LgR_upsampled = LogisticRegression(solver = 'liblinear')\nmodel_LgR_upsampled.fit(features_train_upsampled, target_train_upsampled)\nLgR_prediction_upsampled = model_LgR_upsampled.predict(features_valid)\nrec_prec_f1(target_valid, LgR_prediction_upsampled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Показаели всех моделей улучшились.   \nЛучшие результаты показывает алгоритм случайный лес (RandomForestClassifier). \nНа валидационной выборке RandomForestClassifier уже показывает резульаты F1 меры = 0.63, что выше целевого целевого значения.    \nПопробуем улучшить модель путем изменения параметров. "},{"metadata":{},"cell_type":"markdown","source":"## 3.3 Улучшение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product\nimport tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RandomForestQuality(features_train, target_train, features_valid, target_valid):\n    \n    #Параметры для перебора\n    bootstrap = [True, False]\n    class_weight = ['balanced', 'balanced_subsample', None]\n    max_features = ['auto', 'sqrt', 'log2'] \n    max_depth = [] #диапазон изменения параметра мксимальной глубины каждого дерева\n    for i in range(1, 20):\n        max_depth.append(i)\n\n    #Метод itertools.product для перебора нескольких параметров\n    myproduct = product(bootstrap, class_weight, max_features, max_depth)\n    \n    #Строки, котоыре будут наполняться циклом при переборе параметров\n    bootstrap_table = []\n    class_weight_table = []\n    features_table = []\n    depth_table = []\n    f1_table = []\n    recall_table = []\n    precision_table = []\n    score_train_table = []\n    score_valid_table = []\n    \n    #Цикл перебора всех параметров: bootstrap, class_weight, max_features, max_depth\n    for p in tqdm.tqdm(myproduct,):\n        #Обучение модели\n        model_forest = RandomForestClassifier(\n            bootstrap=p[0] , class_weight= p[1], max_features = p[2], max_depth = p[3], \n            n_estimators = 10, random_state=12345)\n        model_forest.fit(features_train, target_train)\n        prediction = model_forest.predict(features_valid) #предсказание целевого признака\n        \n        #расчет параметров\n        f1 = f1_score(target_valid, prediction)\n        recall = recall_score(target_valid, prediction)\n        precision = precision_score(target_valid, prediction)\n        score_train = model_forest.score(features_train, target_train)\n        score_valid = model_forest.score(features_valid, target_valid)\n        \n        #внесение значиний параметров в строки\n        bootstrap_table.append(p[0])\n        class_weight_table.append(p[1])\n        features_table.append(p[2])\n        depth_table.append(p[3])\n\n        #внесение значений метрик в строки\n        f1_table.append(f1)\n        recall_table.append(recall)\n        precision_table.append(precision)\n        score_train_table.append(score_train)\n        score_valid_table.append(score_valid)\n               \n    \n    #Обоъединение строк в датафрем\n    quality_table = pd.DataFrame(data = (\n        bootstrap_table, class_weight_table, features_table, depth_table, \n        f1_table, recall_table, precision_table, score_train_table, score_valid_table)).T\n    quality_table.columns = (\n        'bootstrap', 'class_weight', 'max_features', 'max_depth', 'f1', 'recall', 'precision', 'score_train', 'score_valid')\n    return quality_table\n\n    \"4 параметра: features_train, target_train — признаки и целевой признак обучающей выборки\"\n    \"features_valid, target_valid — признаки и целевой признак обучающей выборки\"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nquality_table = RandomForestQuality(features_train_upsampled, target_train_upsampled, features_valid, target_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quality_table.query('score_valid>=score_train').sort_values('f1', ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Лучшие параметры модели:   \nmodel = RandomForestClassifier(bootstrap = True, class_weight = 'balanced', max_depth= 7,  n_estimators = 10, random_state=12345)\n\nПараметр \"max_features\" не влияет на параметры модели, оставляем параметр без изменений (default=”auto”). "},{"metadata":{},"cell_type":"markdown","source":"#### Обучим финальную модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RFC_final = RandomForestClassifier(\n    bootstrap = True, class_weight = 'balanced', max_depth= 7,  n_estimators = 100, random_state=12345)\nmodel_RFC_final.fit(features_train_upsampled, target_train_upsampled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RFC_final_prediction = model_RFC_final.predict(features_valid)\nrec_prec_f1(target_valid, model_RFC_final_prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Проверим финальную модель на адекватность"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создаем константную модель\ntarget_predict_constant = pd.Series([0]*len(target_valid))\ntarget_predict_constant.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Сравним показатель точности (accuracy_score) константной модели и финальной\nprint('accuracy_score константой модели:', accuracy_score(target_valid, target_predict_constant))\nprint('accuracy_score финальной модели:', accuracy_score(target_valid, model_RFC_final_prediction))\n#Дополнительно сравним AUC-ROC — единственный параметр подающийся сравнению, потому что константная подель содержит только негативные ответы\nprint('AUC-ROC константой модели:', roc_auc_score(target_valid, target_predict_constant))\nprint('AUC-ROC финальной модели:', roc_auc_score(target_valid, model_RFC_final_prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Финальная модель показывает результаты лучше, чем константная модель — модель можно считать адекватной. "},{"metadata":{},"cell_type":"markdown","source":"## Вывод по результатам исследования"},{"metadata":{},"cell_type":"markdown","source":"1. **В первоначальные данных наблюдался значительный дисбаланс** (80% ответов целевого признака были негативными и только 20% позитивными), из-за чего обученная на этих данных модель не проходила проверку на адекватность.  **Все модели не первоначальных данных характеризовались высокой степенью ошибок и низким качеством взвешенной величины (F1)** — модели показывали низкие результаты точности и полноты. \n\n2. Мы устранили дисбаланс классов в обучающей выборки методом upsampling — увеличили количество значений позитивного класса в 4 раза. Так **мы достигли баланса классо в обучеющей выборки: 1 = 0.50569, 0 = 0.49431**. \n\n3. **На новых данных все модели показали результат выше, чем на несбалансированной выборке**. Лучшие показатели были у модели случайного леса:  \nПолнота 0.5784313725490197  \nТочность 0.6880466472303207  \nF1-мера 0.6284953395472703  \nAUC-ROC 0.755610158636319  \n\n    Было принято решение продолжать улучшение модели на основании алгоритма случайный лес (RandomForestClassifier)\n\n4. Улучшение модели происходило путем цикла выбора параметров, которые показывали наиболее высокое значение F1 меры и не приводили модель к переобучению. \nИзменяемые параметры: bootstrap, class_weight, max_depth от 1 до 19\nПараметр n_estimators был занижен для ускорения выполнения цикла\n\n5. **Финальные параметры выбранной модели** RandomForestClassifier(bootstrap = True, class_weight = 'balanced', max_depth= 7,  n_estimators = 100, random_state=12345).   \n**Результаты модели:**  \nПолнота 0.755    \nТочность 0.549   \nF1-мера 0.636   \nAUC-ROC 0.798  \n6. **Финальная модель прошла проверку на адекватность** в сравнении с контантной моделью:\naccuracy_score константой модели: 0.796  \naccuracy_score финальной модели: 0.8235  \nAUC-ROC константой модели: 0.5  \nAUC-ROC финальной модели: 0.798  "},{"metadata":{},"cell_type":"markdown","source":"# 4. Тестирование модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RFC_final\nmodel_RFC_final_prediction = model_RFC_final.predict(features_test)\nrec_prec_f1(target_test, model_RFC_final_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model_probabilities_one = model_LgR.predict_proba(features_test)[:, 1]\n\nfpr, tpr, thresholds = roc_curve(target_test, final_model_probabilities_one) \n\nplt.figure()\nplt.plot(fpr, tpr)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-кривая')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Финальная достигла заданой метрики (F1 > 0.59) и показывает адекватные результаты.  \nМодель характеризуется высоким показателем полноты = 0.715 (min = 0, max = 1), поэтому она с высокой вероятностью предскажит уход клиента из банка.  \nПоказатель точности не высокий = 0.517 (min = 0, max = 1) — модель верно предсказывает только половину ухода клиентов.   \nС точки зрения бизнеса полученная модель поможет маркетологам лучше определять килентов, которые могут уйти в ближайшее время. Важно, что модель покрывает большое количество клиентов, в данном случае это важнее чем точность.  \n\nДля улучшения модели следует использовать данные, отражающие отношения клиента с банком в динамике. "},{"metadata":{},"cell_type":"markdown","source":"## Выгрузка результата"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame(model_RFC_final_prediction)\nresults.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.to_csv('/kaggle/working/Churn_Modelling_results.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}