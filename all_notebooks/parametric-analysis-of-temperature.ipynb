{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Parametric Analysis based on behavior **\n\nResearch is available showing that Temperature has significant effect on the performance of motor.\n\nhttps://ieeexplore.ieee.org/abstract/document/7732809/\n\nFrom above research it has been concluded that\n\n* The torque produced by the motor decreases in inverse proportion to the increased magnet temperature.\n* Motor reaches steady state speed faster in lower magnetic temperature\n* It was observed that there was an increase in the phase currents that the motor drew along with the increased magnet temperature.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tslearn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy\nfrom tslearn.clustering import TimeSeriesKMeans\nfrom tslearn.datasets import CachedDatasets\nfrom tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n    TimeSeriesResampler\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nseed = 0\nnumpy.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read data\ndf = pd.read_csv('/kaggle/input/electric-motor-temperature/pmsm_temperature_data.csv')\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['ambient'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['coolant'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['u_d'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['u_q'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['motor_speed'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['torque'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['i_d'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['i_q'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['pm'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['stator_yoke'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['stator_tooth'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['stator_winding'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train=df['profile_id'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# DBA-k-means\nprint(\"DBA k-means\")\ndba_km = TimeSeriesKMeans(n_clusters=3,\n                          n_init=2,\n                          metric=\"dtw\",\n                          verbose=True,\n                          max_iter_barycenter=10,\n                          random_state=seed)\ny_pred = dba_km.fit_predict(X_train)\n\nfor yi in range(3):\n    plt.subplot(3, 3, 4 + yi)\n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"DBA $k$-means\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Soft-DTW-k-means\nprint(\"Soft-DTW k-means\")\nsdtw_km = TimeSeriesKMeans(n_clusters=3,\n                           metric=\"softdtw\",\n                           metric_params={\"gamma\": .01},\n                           verbose=True,\n                           random_state=seed)\ny_pred = sdtw_km.fit_predict(X_train)\n\nfor yi in range(3):\n    plt.subplot(3, 3, 7 + yi)\n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Soft-DTW $k$-means\")\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}