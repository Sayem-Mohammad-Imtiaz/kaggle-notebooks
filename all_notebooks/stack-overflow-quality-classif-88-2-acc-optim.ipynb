{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Libraries and Data importation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scikit-optimize --upgrade","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport re\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron, RidgeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier \n\nimport skopt\nfrom skopt import gp_minimize\nfrom skopt.space import Real, Integer\nfrom skopt.utils import use_named_args\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"file_path = '/kaggle/input/60k-stack-overflow-questions-with-quality-rate/data.csv'\ndata = pd.read_csv(file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Some data preprocessing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Body'] = data['Title'] + \" \" + data['Body']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean the data\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^(a-zA-Z)\\s]','', text)\n    return text\n\ndata['Body'] = data['Body'].apply(clean_text)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def remove_stopword\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \n  \nexample_sent = \"This is a sample sentence, showing off the stop words filtration.\"  \nstop_words = set(stopwords.words('english')) \n\ndef remove_stopword(words):\n    list_clean = [w for w in words.split(' ') if not w in stop_words]\n    return ' '.join(list_clean)\n\ndata['Body'] = data['Body'].apply(remove_stopword)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the machine learning modelisation and optimization part, go directly to **\"Train and test sets splitting\"** section","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Train and test sets splitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"N = len(data)\nTRAIN_PERC = 0.8\nind_train = np.random.rand(N) < TRAIN_PERC\ntrain, test = data[ind_train], data[~ind_train]\nprint(f'len(train)={len(train)}; len(test)={len(test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Building the TFIDF features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(train.Body)\nX_train_counts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_counts = count_vect.transform(test.Body)\nX_test_counts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nX_train_tfidf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_tfidf = tfidf_transformer.transform(X_test_counts)\nX_test_tfidf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I tried to add the length of Title, length of Body and number of tags, but it seems to globally decrease the accuracy!\n\"\"\"\nfrom scipy.sparse import hstack\n\ndef add_len_feat(X_tfidf, train_or_test):\n    list_title_len = [[len(title)] for title in train_or_test.Title]\n    list_body_len = [[len(body)] for body in train_or_test.Body]\n    list_tag_len = [[len(tag)] for tag in train_or_test.tags_processed]\n    return hstack([X_tfidf, list_title_len, list_body_len, list_tag_len])\n\nX_train_tfidf = add_len_feat(X_train_tfidf, train)\nX_test_tfidf = add_len_feat(X_test_tfidf, test)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Models benchmarking**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_dict = {\n    'LogisticRegression': LogisticRegression,\n    'MultinomialNB': MultinomialNB,\n    'DecisionTreeClassifier': DecisionTreeClassifier,\n    'SGDClassifier': SGDClassifier,\n    'Perceptron': Perceptron,\n    'RidgeClassifier': RidgeClassifier,\n    'LinearSVC': LinearSVC,\n    'RandomForestClassifier': RandomForestClassifier,\n    'GradientBoostingClassifier': GradientBoostingClassifier,\n    #'MLPClassifier': MLPClassifier,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_accuracy(clf, n_estimators=None, max_depth=None, learning_rate=None, max_iter=None):\n    start = time.time()\n    text_clf = clf(**params).fit(X_train_tfidf, train.Y)\n    predicted = text_clf.predict(X_test_tfidf)\n    print(f'Accuracy gets in {round(time.time()-start, 2)}s.')\n    return np.mean(predicted == test.Y)\n\nresult_dict = {}\n\nfor clf_str, clf_fn in clf_dict.items():\n    if clf_str == 'LogisticRegression':\n        params = {'max_iter': 200}\n    elif clf_str == 'RandomForestClassifier':\n        params = {'n_estimators': 50,\n                  'max_depth': 10}\n    elif clf_str == 'DecisionTreeClassifier':\n        params = {'max_depth': 10}\n    elif clf_str == 'GradientBoostingClassifier':\n        params = {'n_estimators': 50,\n                  'learning_rate': 0.1}\n    else:\n        params = {}\n    accuracy = get_accuracy(clf=clf_fn, **params)\n    result_dict[clf_str] = accuracy\n    print(f\"Clf={clf_str}; Accuracy={accuracy}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict = {\n    k: v\n    for k, v in sorted(\n        result_dict.items(),\n        key=lambda x: x[1],\n        reverse=True\n    )\n}\n\nresult_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIM_Logistic = [\n    Integer(100, 400, name='max_iter')\n]\n\nDIM_SVC = [\n    Real(1e-5, 1, name='tol', prior='log-uniform'),\n    Real(0.1, 1.5, name='C', prior='log-uniform')\n]\n\nDIM_SGDC = [\n    Real(1e-5, 1e-2, name='alpha', prior='log-uniform')\n]\n\nDIM_RF = [\n    Integer(1, 100, name='n_estimators'),\n    Integer(5, 30, name='max_depth')\n]\n\nDIMS = {\n    'LogisticRegression': DIM_Logistic,\n    'LinearSVC': DIM_SVC,\n    'SGDClassifier': DIM_SGDC,\n    'RandomForestClassifier': DIM_RF\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimize(clf_str='LinearSVC'):\n    \n    dimensions = DIMS[clf_str]\n    print(dimensions)\n    \n    @use_named_args(dimensions=dimensions)\n    def fitness(**params):\n        clf = clf_dict[clf_str](**params)\n        text_clf = clf.fit(X_train_tfidf, train.Y)\n        predicted = text_clf.predict(X_test_tfidf)\n        accuracy = np.mean(predicted == test.Y)\n        print(f'accuracy={accuracy} with params={params}')\n        return -1.0 * accuracy\n    \n    res = gp_minimize(func=fitness,\n                      dimensions=dimensions,\n                      acq_func='EI', # Expected Improvement.\n                      n_calls=10,\n                      random_state=666)\n    print(f'best accuracy={-1.0 * res.fun} with {res.x}')\n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_dict = {}\nfor clf_str, clf_dim in DIMS.items():\n    print(f'start optimizaton for {clf_str}')\n    res = optimize(clf_str=clf_str)\n    res_dict[clf_str] = res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Best accuracy per model and the respective hyperparameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for clf_str, res in res_dict.items():\n    hyperparameters_label = [hp.name for hp in DIMS[clf_str]]\n    best_hyperparameters = dict(zip(hyperparameters_label, res.x))\n    print(f'clf={clf_str}\\nbest accuracy={-res.fun}\\nbest hyperparameters={best_hyperparameters}\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Next steps","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"WIP\n\nNext steps:\n- continue hyperparameters optimization\n- include title, tags, date as features\n- try other ML models like stacking, Keras/TF","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# please upvote if you liked it :D","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}