{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Performing a Sentiment Analysis of Energy Crude Oil Tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#installing contractions library\n!pip -q install contractions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries & Loading Dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Generic Data Processing & Visualization Libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re,string,unicodedata\nimport contractions #import contractions_dict\nfrom bs4 import BeautifulSoup\n%matplotlib inline\n\n\n#Importing text processing libraries\nimport spacy\nimport spacy.cli\nimport nltk\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.lancaster import LancasterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\n#downloading wordnet/punkt dictionary\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('stopwords')\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Loading Dataset\nurl = '../input/sentiment-analysis-in-energy-crude-oil/tweets.csv'\nraw_data = pd.read_csv(url, header='infer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the Sentiment Analysis, we would only be requiring the following columns:\n* text\n* screenName\n* retweetCount\n\nRest all the columns are not relevant."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a seperate dataset with specific columns.\ndata = raw_data[['text','screenName','retweetCount']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Resetting Index\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Backup of the newly created dataset\ndata_backup = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lowering cases\ndata['text'] = data['text'].str.lower()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stripping leading spaces (if any)\ndata['text'] = data['text'].str.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing HTML tags\ndef strip_html_tags(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    stripped_text = soup.get_text()\n    return stripped_text\n\n#apply to the dataset\ndata['text'] = data['text'].apply(strip_html_tags)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove URL and links\ndef strip_url(text):\n    strip_url_text = re.sub(r'http\\S+', '', text)\n    return strip_url_text\n\n#Applying the dataset\ndata['text'] = data['text'].apply(strip_url)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing punctuations\nfrom string import punctuation\n\ndef remove_punct(text):\n  for punctuations in punctuation:\n    text = text.replace(punctuations, '')\n  return text\n\n#apply to the dataset\ndata['text'] = data['text'].apply(remove_punct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to remove special characters\ndef remove_special_chars(text, remove_digits=True):\n  pattern = r'[^a-zA-z0-9\\s]'\n  text = re.sub(pattern, '', text)\n  return text\n\n#applying the function on the clean dataset\ndata['text'] = data['text'].apply(remove_special_chars)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to remove macrons & accented characters\ndef remove_accented_chars(text):\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return text\n\n#applying the function on the clean dataset\ndata['text'] = data['text'].apply(remove_accented_chars)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to expand contractions\ndef expand_contractions(con_text):\n  con_text = contractions.fix(con_text)\n  return con_text\n\n#applying the function on the clean dataset\ndata['text'] = data['text'].apply(expand_contractions)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a new column in the dataset for word count\ndata ['word_count'] = data['text'].apply(lambda x:len(str(x).split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking Backup\ndata_clean = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Preprocessing & Normalisation"},{"metadata":{},"cell_type":"markdown","source":"### Removing Stop Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to remove stopwords\ndef remove_stopwords(text, is_lower_case=False):\n    stopword_list = set(stopwords.words('english'))\n    tokenizer = ToktokTokenizer()\n    tokens = tokenizer.tokenize(text)\n    tokens = [token.strip() for token in tokens]\n    if is_lower_case:\n        filtered_tokens = [token for token in tokens if token not in stopword_list]\n    else:\n        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n    filtered_text = ' '.join(filtered_tokens)    \n    return filtered_text\n\n#applying the function\ndata ['text'] = data['text'].apply(remove_stopwords) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stemming"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function for stemming\ndef simple_stemmer(text):\n  ps = nltk.porter.PorterStemmer()\n  text = ' '.join([ps.stem(word) for word in text.split()])\n  return text\n\n#applying the function\ndata['Stemd_text'] = data['text'].apply(simple_stemmer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rearranging columns\ndata = data[['screenName','text','Stemd_text','retweetCount','word_count']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking Backup\ndata_preproc = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Analysis - TextBlob Library"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Textblob Library\nfrom textblob import TextBlob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to perform Textblob Sentiment Analyis\ndef sentiment_analysis(text):\n    polarity = round(TextBlob(text).sentiment.polarity, 3)\n    sentiment_categories = ['positive','negative','neutral']\n    if polarity > 0:\n        return sentiment_categories[0]\n    elif polarity < 0:\n        return sentiment_categories[1]\n    else:\n        return sentiment_categories[2]  \n        \n#Apply to the Stemd_Text\ndata['Sentiments'] = [sentiment_analysis(txt) for txt in data['Stemd_text']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis & Visualisation"},{"metadata":{},"cell_type":"markdown","source":"### Distribution of Word Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_bins = 50\nplt.figure(figsize=(10,6))\nn, bins, patches = plt.hist(data.word_count, num_bins, facecolor='blue', alpha=0.5)\nplt.xlabel('Word Count')\nplt.ylabel('Tweet Count')\nplt.title('Histogram of Word Count')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analysis:** A majority of tweets are between 15 - 20 words long"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a Count Plot\nsns.set(style=\"darkgrid\")\nfig, ax = plt.subplots(figsize=(8,8))\nax = sns.countplot(x=\"Sentiments\", data=data)\nplt.title('Sentiments Count')\nplt.ylabel('Count')\nplt.xlabel('Sentiments')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analysis:** Majority of the tweets are netural with 'negative' tweets being the second highest"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.boxenplot(x='Sentiments', y='word_count', data=data)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.stripplot(x='Sentiments', y='retweetCount', data=data)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Who are the users who had negative sentiments & a high retweet count ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data.Sentiments == 'negative') & (data.retweetCount > 35)]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}