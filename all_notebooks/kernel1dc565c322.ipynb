{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Prepared training data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\ndata=pd.read_csv('/kaggle/input/fergit/FERGIT.csv')\nprint(data)\nimgs=data['pixels'].to_numpy()\nusage=data['Usage'].to_numpy()\nY=np.array(data['emotion'].to_numpy(), dtype='int32')\nmask=usage=='Training'\n#print(np.sum(mask))\nimgs=imgs[mask]\nprint(imgs.shape)\nY=Y[mask]\nimg2=str(imgs[0])\nx=img2.split(' ')\nx=np.array(x, dtype='int32')\nx=x.reshape(48, 48)\nX=x[np.newaxis, :, :]\nprint(X.shape)\ncount=0\nimport glob\nfiles=glob.glob('/kaggle/input/ckplus/CK+48/anger/*.png')\nY=np.concatenate((Y, np.repeat(0, len(files))))\nfor img in imgs[1:]:\n    img2=str(img)\n    x=img2.split(' ')\n    x=np.array(x, dtype='int32')\n    x=x.reshape(48, 48)\n    X=np.concatenate((X, x[np.newaxis, :, :]), axis=0)\n    print(count)\n    count=count+1\nfor name in files:\n    img=plt.imread(name)\n    X=np.concatenate((X, img[np.newaxis, :, :]), axis=0)\nfiles=glob.glob('/kaggle/input/ckplus/CK+48/disgust/*.png')\nY=np.concatenate((Y, np.repeat(1, len(files))))\nfor name in files:\n    img=plt.imread(name)\n    X=np.concatenate((X, img[np.newaxis, :, :]), axis=0)\nfiles=glob.glob('/kaggle/input/ckplus/CK+48/fear/*.png')\nY=np.concatenate((Y, np.repeat(2, len(files))))\nfor name in files:\n    img=plt.imread(name)\n    X=np.concatenate((X, img[np.newaxis, :, :]), axis=0)\nfiles=glob.glob('/kaggle/input/ckplus/CK+48/sadness/*.png')\nY=np.concatenate((Y, np.repeat(4, len(files))))\nfor name in files:\n    img=plt.imread(name)\n    X=np.concatenate((X, img[np.newaxis, :, :]), axis=0)\nfiles=glob.glob('/kaggle/input/ckplus/CK+48/surprise/*.png')\nY=np.concatenate((Y, np.repeat(5, len(files))))\nfor name in files:\n    img=plt.imread(name)\n    X=np.concatenate((X, img[np.newaxis, :, :]), axis=0)\nX=X.reshape(X.shape[0], 48*48)\nnp.savetxt(\"/kaggle/working/imgs.csv\", X, delimiter=\",\")\nnp.savetxt(\"/kaggle/working/lab.csv\", Y, delimiter=\",\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test  data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\ndata=pd.read_csv('/kaggle/input/fergit/FERGIT.csv')\nprint(data)\nimgs=data['pixels'].to_numpy()\nusage=data['Usage'].to_numpy()\nY=np.array(data['emotion'].to_numpy(), dtype='int32')\nmask=np.logical_not(usage=='Training')\n#print(np.sum(mask))\nimgs=imgs[mask]\nprint(imgs.shape)\nY=Y[mask]\nimg2=str(imgs[0])\nx=img2.split(' ')\nx=np.array(x, dtype='int32')\nx=x.reshape(48, 48)\nX=x[np.newaxis, :, :]\ncount=0\nfor img in imgs[1:]:\n    img2=str(img)\n    x=img2.split(' ')\n    x=np.array(x, dtype='int32')\n    x=x.reshape(48, 48)\n    X=np.concatenate((X, x[np.newaxis, :, :]), axis=0)\n    print(count)\n    count=count+1\nX=X.reshape(X.shape[0], 48*48)\nX=np.concatenate((X, Y[:, np.newaxis]), axis=1)\nnp.savetxt(\"/kaggle/working/test.csv\", X, delimiter=\",\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nhist=np.zeros(7, dtype='int32')\nY=np.genfromtxt('/kaggle/input/facialexpression/lab.csv', delimiter=',')\nfor i in range(7):\n    hist[i]=np.sum(Y==i)\nprint(hist)\nplt.bar(range(7), hist, color='green')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(48, 48, 1)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())  # this converts our 2D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\nfor ctount in range(5):\n    X=np.genfromtxt('/kaggle/input/facialexpression/data1.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    #model.fit(X, Y, batch_size=100, epochs=1)\n    X=np.genfromtxt('/kaggle/input/facialexpression/data2.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    for i in range (50):\n        plt.imshow(X[i, :, :, 0])\n        plt.show()\n    model.fit(X, Y, batch_size=100, epochs=1)\n    X=np.genfromtxt('/kaggle/input/facialexpression/data3.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1)\n    X=np.genfromtxt('/kaggle/input/facialexpression/data4.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1)\nmodel.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\n#K.set_image_dim_ordering('th')\nimport tensorflow as tf\nimport numpy as np\ndef swish_activation(x):\n    return (K.sigmoid(x) * x)\n\nmodel = Sequential()\nmodel.add(Conv2D(48, (7, 7), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Conv2D(96, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(GlobalAveragePooling2D())\n#model.add(Flatten())\nmodel.add(Dense(256, activation=swish_activation))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation=swish_activation))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation=swish_activation))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nX_test=np.genfromtxt('/kaggle/input/testfacialexpression/test.csv', delimiter=',')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)/255.0\nfor ctount in range(10):\n    X=np.genfromtxt('/kaggle/input/facialexpression/data1.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)/255.0\n    model.fit(X, Y,validation_data=(X_test, y_test), batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/facialexpression/data2.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)/255.0\n    model.fit(X, Y, validation_data=(X_test, y_test), batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/facialexpression/data3.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)/255.0\n    model.fit(X, Y, validation_data=(X_test, y_test), batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/facialexpression/data4.csv', delimiter=',')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)/255.0\n    model.fit(X, Y, validation_data=(X_test, y_test), batch_size=100, epochs=1, shuffle=True)\n    print(model.predict(X_test[0:10, :, :, :]), y_test[0:10])\nmodel.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nimport tensorflow as tf\nimport numpy as np\nX=np.genfromtxt('/kaggle/input/facialexpression/imgs.csv', delimiter=',')\nY=np.genfromtxt('/kaggle/input/facialexpression/lab.csv', delimiter=',')\nX=np.concatenate((X, Y[:, np.newaxis]), axis=1)\nprint(\"not_shuffled1\")\nnp.random.shuffle(X)\nnp.random.shuffle(X)\nnp.random.shuffle(X)\nnp.savetxt(\"/kaggle/working/data.csv\", X, delimiter=\",\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nX=np.genfromtxt('/kaggle/input/facialexpression/data.csv', delimiter=',')\nnp.savetxt(\"/kaggle/working/data1.csv\", X[:int(X.shape[0]/4), :], delimiter=\",\")\nnp.savetxt(\"/kaggle/working/data2.csv\", X[int(X.shape[0]/4):int(X.shape[0]/2), :], delimiter=\",\")\nnp.savetxt(\"/kaggle/working/data3.csv\", X[int(X.shape[0]/2):int(3*X.shape[0]/4), :], delimiter=\",\")\nnp.savetxt(\"/kaggle/working/data4.csv\", X[int(3*X.shape[0]/4):, :], delimiter=\",\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Mix CKPlus48 and FER2018+MUX dataset and train, oversample or undersample when required","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom matplotlib import pyplot as plt\nfrom keras import backend as K\n#K.set_image_dim_ordering('th')\nimport tensorflow as tf\nimport numpy as np\ndef swish_activation(x):\n    return (K.sigmoid(x) * x)\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n#X=np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ')\n#print(X.shape)\n#print(X[0, :])\n#X=np.concatenate((np.genfromtxt('/kaggle/input/datanfer/data1N/data1N.csv', delimiter=','), np.genfromtxt('/kaggle/input/datanfer/data2N/data2N.csv', delimiter=',')), axis=0)\n#Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n#X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\nX_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nfor ctount in range(30):\n    X=np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data34/data3N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data34/data4N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, validation_data=(X_test, y_test), batch_size=100, epochs=1, shuffle=True)\n    model.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\n#K.set_image_dim_ordering('th')\nimport tensorflow as tf\nimport numpy as np\ndef swish_activation(x):\n    return (K.sigmoid(x) * x)\n\nmodel = Sequential()\nmodel.add(Conv2D(48, (7, 7), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Conv2D(96, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n#model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n#model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=swish_activation))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation=swish_activation))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation=swish_activation))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation=swish_activation))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation=swish_activation))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation=swish_activation))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nX_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nfor ctount in range(30):\n    X=np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data34/data3N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data34/data4N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, validation_data=(X_test, y_test), batch_size=100, epochs=1, shuffle=True)\n    model.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Saved version\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom matplotlib import pyplot as plt\nfrom keras import backend as K\n#K.set_image_dim_ordering('th')\nimport tensorflow as tf\nimport numpy as np\ndef swish_activation(x):\n    return (K.sigmoid(x) * x)\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n#X=np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ')\n#print(X.shape)\n#print(X[0, :])\n#X=np.concatenate((np.genfromtxt('/kaggle/input/datanfer/data1N/data1N.csv', delimiter=','), np.genfromtxt('/kaggle/input/datanfer/data2N/data2N.csv', delimiter=',')), axis=0)\n#Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n#X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\nX_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nwhile True:\n    X=np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data34/data3N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, batch_size=100, epochs=1, shuffle=True)\n    X=np.genfromtxt('/kaggle/input/datanfer/data34/data4N.csv', delimiter=' ')\n    Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\n    X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n    model.fit(X, Y, validation_data=(X_test, y_test), batch_size=100, epochs=1, shuffle=True)\n    model.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.filters import gabor\nfrom matplotlib import pyplot as plt\nimport numpy as np\nX=np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ')\nY=X[:, X.shape[1]-1]\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48)\nfilt_real, filt_imag = gabor(X[1, :, :], frequency=0.25, sigma_x=np.sqrt(2), sigma_y=np.sqrt(2), theta=0)\nres=np.sqrt(filt_real*filt_real+filt_imag*filt_imag)\nplt.imshow(X[1, :, :], cmap='gray')\nplt.show()\nplt.imshow(res, cmap='gray')\nplt.show()\nfilt_real, filt_imag = gabor(X[1, :, :], frequency=0.25, sigma_x=np.sqrt(2), sigma_y=np.sqrt(2), theta=3.141592653/4)\nres=np.sqrt(filt_real*filt_real+filt_imag*filt_imag)\nplt.imshow(res, cmap='gray')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom matplotlib import pyplot as plt\nfrom keras import backend as K\n#K.set_image_dim_ordering('th')\nimport tensorflow as tf\nimport numpy as np\ndef swish_activation(x):\n    return (K.sigmoid(x) * x)\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nX=np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ')\nprint(X.shape)\nprint(X[0, :])\n#X=np.concatenate((np.genfromtxt('/kaggle/input/datanfer/data1N/data1N.csv', delimiter=','), np.genfromtxt('/kaggle/input/datanfer/data2N/data2N.csv', delimiter=',')), axis=0)\nY=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\nX_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nmodel.fit(X, Y, validation_data=(X_test, y_test), batch_size=100, epochs=40, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nX=np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ')\nY=X[:, X.shape[1]-1]\nhist=np.zeros(7)\nfor i in range(7):\n    hist[i]=np.sum(Y==i)\nplt.bar(range(7), hist)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nfrom skimage.filters import gabor\nX=np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ')\nY=X[:int(X.shape[0]/5), X.shape[1]-1]\nX=X[:int(X.shape[0]/5), :X.shape[1]-1]\nX=X.reshape(X.shape[0], 48, 48)\nZ=np.zeros((X.shape[0], 40, 48, 48))\nfor i in range(X.shape[0]):\n    for u in range(5):\n        for v in range(8):\n            filt_real, filt_imag = gabor(X[1, :, :], frequency=0.2/pow(2, u/2.0), sigma_x=np.sqrt(2), sigma_y=np.sqrt(2), theta=v*3.141592653/8)\n            res=np.sqrt(filt_real*filt_real+filt_imag*filt_imag)\n            Z[i, u*5+v, :, :]=res\n    print(i)\nnp.savetxt(\"/kaggle/working/data1G1.csv\", np.concatenate((Z.reshape(Z.shape[0], 40*48*48), Y[:, np.newaxis]), axis=1), delimiter=\",\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfrom sklearn.decomposition import KernelPCA\nkpca = KernelPCA(kernel=\"linear\",coef0=0, degree=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nX=np.genfromtxt('/kaggle/working/data1G1.csv', delimiter=',')\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\nimport numpy as np\n#K.set_image_dim_ordering('th')\n#import tensorflow as tf\n#import numpy as np\nX=np.concatenate((np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data34/data3N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data34/data4N.csv', delimiter=' ', dtype='float32')), axis=0)\nY=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\nX_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ', dtype='float32')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nmodel = Sequential()\nmodel.add(Conv2D(256, (5, 5), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(1024, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\n#adam=tf.keras.optimizers.Adam(learning_rate=0.1)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=15,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=1,\n    min_lr=0.00001\n)\nopt = SGD(lr=0.001, momentum=0.9, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.fit(X, Y, validation_data=(X_test, y_test), epochs=1000, batch_size=500, shuffle=True, callbacks=[reduce_lr])\nmodel.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For FER\nfrom keras.models import Sequential\nfrom imblearn.over_sampling import RandomOverSampler \nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\nimport numpy as np\nros = RandomOverSampler(random_state=42)\ndef ConfusionMatrix(X_test, Y_test, model):\n    Y_pred=np.argmax(model.predict(X_test), axis=1)\n    Y_test=np.argmax(Y_test, axis=1)\n    print(Y_pred.shape)\n    conf_Mat=np.zeros((7,7))\n    for i in range(7):\n        for j in range(7):\n            conf_Mat[i, j]=np.sum(np.logical_and(Y_test==i, Y_pred==j))\n    return conf_Mat\n#K.set_image_dim_ordering('th')\n#import tensorflow as tf\n#import numpy as np\nX=np.concatenate((np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data34/data3N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data34/data4N.csv', delimiter=' ', dtype='float32')), axis=0)\n#Y=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\nY=X[:, X.shape[1]-1]\n#X=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\nX=X[:, :X.shape[1]-1]\nX_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ', dtype='float32')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nhist=np.zeros(7)\n#Yor=np.argmax(Y, axis=1)\nfor i in range(7):\n    #hist[i]=np.sum(Yor==i)\n    hist[i]=np.sum(Y==i)\nX, Y = ros.fit_resample(X, Y)\nX=X.reshape(X.shape[0], 48, 48, 1)\nY=tf.keras.utils.to_categorical(Y)\nmodel = Sequential()\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\n#adam=tf.keras.optimizers.Adam(learning_rate=0.1)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=15,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=1,\n    min_lr=0.00001\n)\nopt = SGD(lr=0.001, momentum=0.9, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\ntry:\n    model.fit(X, Y, validation_data=(X_test, y_test), epochs=1000, batch_size=500, shuffle=True, callbacks=[reduce_lr])\nexcept:\n    conf=ConfusionMatrix(X_test, y_test, model)\n    conf=conf/np.sum(conf, axis=1)\n    print(conf)\n    print(np.sum(conf, axis=1))\n    model.save('/kaggle/working/model1.h5')\n    plt.bar(range(7), hist)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For CKPlus\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf\nimport numpy as np\ndef ConfusionMatrix(X_test, Y_test, model):\n    Y_pred=np.argmax(model.predict(X_test), axis=1)\n    Y_test=np.argmax(Y_test, axis=1)\n    print(Y_pred.shape)\n    conf_Mat=np.zeros((7,7))\n    for i in range(7):\n        for j in range(7):\n            conf_Mat[i, j]=np.sum(np.logical_and(Y_test==i, Y_pred==j))\n    return conf_Mat\n\n#K.set_image_dim_ordering('th')\n#import tensorflow as tf\n#import numpy as np\nX=np.genfromtxt('/kaggle/input/ckplusfinal/CKPlusFinalN.csv', delimiter=' ', dtype='float32')\nY=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n#X_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ', dtype='float32')\n#y_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\n#X_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\ndef genModel():\n    model = Sequential()\n    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(512, (3, 3), activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(7 , activation='softmax'))\n    #print(model.summary())\n    return model\nhistory=[]\nes=EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0.0001,\n    patience=40,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=True,\n)\nfor k in range(5):\n    dbyf=X.shape[0]/5.0\n    X_test=X[int(k*dbyf):int((k+1)*dbyf), :, :, :]\n    Y_test=Y[int(k*dbyf):int((k+1)*dbyf), :]\n    X_train=np.concatenate((X[0:int(k*dbyf), :, :, :], X[int((k+1)*dbyf):, :, :, :]), axis=0)\n    Y_train=np.concatenate((Y[0:int(k*dbyf), :], Y[int((k+1)*dbyf):, :]), axis=0)\n    model=genModel()\n    model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n    history.append(model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=220, batch_size=500, shuffle=True, callbacks=[es]))\n    if k==0:\n        conf=ConfusionMatrix(X_test, Y_test, model)\n    else:\n        conf=conf+ConfusionMatrix(X_test, Y_test, model)\n    model.save('/kaggle/working/model1.h5')\nprint(conf/np.sum(conf, axis=1))\n#print(history.history.keys())\nfor  i in range(5):\n    print(i)\n    plt.plot(history[i].history['val_accuracy'])\n    plt.plot(history[i].history['accuracy'])\n    plt.show()\n    plt.plot(history[i].history['val_loss'])\n    plt.plot(history[i].history['loss'])\n    plt.show()\nprint(max(history[0].history['val_accuracy']))\nprint(max(history[1].history['val_accuracy']))\nprint(max(history[2].history['val_accuracy']))\nprint(max(history[3].history['val_accuracy']))\nprint(max(history[4].history['val_accuracy']))\n#print(max(history[5].history['val_accuracy']))\n#adam=tf.keras.optimizers.Adam(learning_rate=0.1)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=15,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=1,\n    min_lr=0.00001\n)\nopt = SGD(lr=0.001, momentum=0.9, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n#ct_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cleaned FER\n#For FER\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf\nimport numpy as np\nearlystop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\ndef ConfusionMatrix(X_test, Y_test, model):\n    Y_pred=np.argmax(model.predict(X_test), axis=1)\n    Y_test=np.argmax(Y_test, axis=1)\n    print(Y_pred)\n    conf_Mat=np.zeros((5,5))\n    for i in range(5):\n        for j in range(5):\n            conf_Mat[i, j]=np.sum(np.logical_and(Y_test==i, Y_pred==j))\n    return conf_Mat\n\n#K.set_image_dim_ordering('th')\n#import tensorflow as tf\n#import numpy as np\nX=np.genfromtxt('/kaggle/input/datanfer/CleanedFERNFinal/FERFinalN.csv', delimiter=' ', dtype='float32')\n#np.random.shuffle(X)\nX_test=X[X.shape[0]-2000:, :]\nX=X[:X.shape[0]-2000, :]\n#X_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ', dtype='float32')\nY=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=5)\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=5)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nmodel = Sequential()\np=0.2\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Dropout(p))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(p))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(p))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(p))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(Dropout(p))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(p))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(p))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(p))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(p))\nmodel.add(Dense(5 , activation='softmax'))\nprint(model.summary())\n#adam=tf.keras.optimizers.Adam(learning_rate=0.1)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=15,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=1,\n    min_lr=0.00001\n)\nopt = SGD(lr=0.001, momentum=0.9, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\ntry:\n    model.fit(X, Y, validation_data=(X_test, y_test), epochs=1000, batch_size=500, shuffle=True, callbacks=[reduce_lr])\n    conf=ConfusionMatrix(X_test, y_test, model)\n    print(conf)\n    print(np.sum(conf))\n    print(conf/np.repeat(np.sum(conf, axis=1)[:, np.newaxis], 5, axis=1)) \n    model.save('/kaggle/working/model1.h5')\nexcept:\n    conf=ConfusionMatrix(X_test, y_test, model)\n    print(conf)\n    print(np.sum(conf))\n    print(conf/np.repeat(np.sum(conf, axis=1)[:, np.newaxis], 5, axis=1)) \n    model.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cleaned CKPLUS extra\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\nimport numpy as np\ndef ConfusionMatrix(X_test, Y_test, model):\n    Y_pred=np.argmax(model.predict(X_test), axis=1)\n    Y_test=np.argmax(Y_test, axis=1)\n    print(Y_pred.shape)\n    conf_Mat=np.zeros((7,7))\n    for i in range(7):\n        for j in range(7):\n            conf_Mat[i, j]=np.sum(np.logical_and(Y_test==i, Y_pred==j))\n    return conf_Mat\n#K.set_image_dim_ordering('th')\n#import tensorflow as tf\n#import numpy as np\nX=np.genfromtxt('/kaggle/input/ckplusfinal/CKPlusFinalN.csv', delimiter=' ', dtype='float32')\nnp.random.shuffle(X)\nX_test=X[X.shape[0]-150:, :]\nX=X[:X.shape[0]-150, :]\n#X_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ', dtype='float32')\nY=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nmodel = Sequential()\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\n#adam=tf.keras.optimizers.Adam(learning_rate=0.1)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=15,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=1,\n    min_lr=0.00001\n)\nopt = SGD(lr=0.001, momentum=0.9, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\ntry:\n    model.fit(X, Y, validation_data=(X_test, y_test), epochs=1000, batch_size=500, shuffle=True)\nexcept:\n    model.save('/kaggle/working/modelCK.h5')\n    print(ConfusionMatrix(X_test, y_test, model))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For CKPlus\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf\nimport numpy as np\ndef ConfusionMatrix(X_test, Y_test, model):\n    Y_pred=np.argmax(model.predict(X_test), axis=1)\n    Y_test=np.argmax(Y_test, axis=1)\n    print(Y_pred.shape)\n    conf_Mat=np.zeros((7,7))\n    for i in range(7):\n        for j in range(7):\n            conf_Mat[i, j]=np.sum(np.logical_and(Y_test==i, Y_pred==j))\n    return conf_Mat\n\n#K.set_image_dim_ordering('th')\n#import tensorflow as tf\n#import numpy as np\nX=np.genfromtxt('/kaggle/input/ckplusfinal/CKPlusFinalN.csv', delimiter=' ', dtype='float32')\nY=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\n#X_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ', dtype='float32')\n#y_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\n#X_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\ndef genModel():\n    p=0.3\n    model = Sequential()\n    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\n    model.add(Dropout(p))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(p))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(Dropout(p))\n    model.add(Conv2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(p))\n    model.add(Conv2D(512, (3, 3), activation='relu'))\n    model.add(Dropout(p))\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(p))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(p))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(p))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(p))\n    model.add(Dense(7 , activation='softmax'))\n    #print(model.summary())\n    return model\nhistory=[]\nes=EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0.0001,\n    patience=40,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=True,\n)\nfor k in range(5):\n    dbyf=X.shape[0]/5.0\n    X_test=X[int(k*dbyf):int((k+1)*dbyf), :, :, :]\n    Y_test=Y[int(k*dbyf):int((k+1)*dbyf), :]\n    X_train=np.concatenate((X[0:int(k*dbyf), :, :, :], X[int((k+1)*dbyf):, :, :, :]), axis=0)\n    Y_train=np.concatenate((Y[0:int(k*dbyf), :], Y[int((k+1)*dbyf):, :]), axis=0)\n    model=genModel()\n    model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n    history.append(model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=220, batch_size=500, shuffle=True, callbacks=[es]))\n    if k==0:\n        conf=ConfusionMatrix(X_test, Y_test, model)\n    else:\n        conf=conf+ConfusionMatrix(X_test, Y_test, model)\n    model.save('/kaggle/working/model1.h5')\nprint(conf/np.sum(conf, axis=1))\n#print(history.history.keys())\nfor  i in range(5):\n    print(i)\n    plt.plot(history[i].history['val_accuracy'])\n    plt.plot(history[i].history['accuracy'])\n    plt.show()\n    plt.plot(history[i].history['val_loss'])\n    plt.plot(history[i].history['loss'])\n    plt.show()\nprint(max(history[0].history['val_accuracy']))\nprint(max(history[1].history['val_accuracy']))\nprint(max(history[2].history['val_accuracy']))\nprint(max(history[3].history['val_accuracy']))\nprint(max(history[4].history['val_accuracy']))\n#print(max(history[5].history['val_accuracy']))\n#adam=tf.keras.optimizers.Adam(learning_rate=0.1)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=15,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=1,\n    min_lr=0.00001\n)\nopt = SGD(lr=0.001, momentum=0.9, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\nimport numpy as np\n#K.set_image_dim_ordering('th')\n#import tensorflow as tf\n#import numpy as np\ndef ConfusionMatrix(X_test, Y_test, model):\n    Y_pred=np.argmax(model.predict(X_test), axis=1)\n    Y_test=np.argmax(Y_test, axis=1)\n    print(Y_pred.shape)\n    conf_Mat=np.zeros((7,7))\n    for i in range(7):\n        for j in range(7):\n            conf_Mat[i, j]=np.sum(np.logical_and(Y_test==i, Y_pred==j))\n    return conf_Mat\n\nX=np.concatenate((np.genfromtxt('/kaggle/input/datanfer/data12/data1N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data12/data2N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data34/data3N.csv', delimiter=' ', dtype='float32'), np.genfromtxt('/kaggle/input/datanfer/data34/data4N.csv', delimiter=' ', dtype='float32')), axis=0)\nY=tf.keras.utils.to_categorical(X[:, X.shape[1]-1], num_classes=7)\nX=X[:, :X.shape[1]-1].reshape(X.shape[0], 48, 48, 1)\nX_test=np.genfromtxt('/kaggle/input/datanfer/testN2/testN.csv', delimiter=' ', dtype='float32')\ny_test=tf.keras.utils.to_categorical(X_test[:, X_test.shape[1]-1], num_classes=7)\nX_test=X_test[:, :X_test.shape[1]-1].reshape(X_test.shape[0], 48, 48, 1)\nmodel = Sequential()\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48,48, 1)))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.4))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(7 , activation='softmax'))\nprint(model.summary())\n#adam=tf.keras.optimizers.Adam(learning_rate=0.1)\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=15,\n    verbose=1,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=1,\n    min_lr=0.00001\n)\nopt = SGD(lr=0.001, momentum=0.9, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\ntry:\n    model.fit(X, Y, validation_data=(X_test, y_test), epochs=1000, batch_size=500, shuffle=True, callbacks=[reduce_lr])\nexcept:\n    conf=ConfusionMatrix(X_test, y_test, model)\n    print(conf/np.sum(conf, axis=1))\nmodel.save('/kaggle/working/model1.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}