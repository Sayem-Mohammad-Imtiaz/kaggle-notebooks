{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, we will look at the code in a random script picked from Github, and predict its programming language. This data has been pulled from the public dataset, available via BigQuery, of open source [Github repos](https://www.kaggle.com/github/github-repos). I've extracted the relevant data in [this](https://www.kaggle.com/priteshshrivastava/language-classifier-clustering-data-prep) notebook using Kaggle's Bigquery helper functions."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\nfrom sklearn.metrics import plot_confusion_matrix, confusion_matrix\nimport eli5\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sample_code = pd.read_csv(\"/kaggle/input/sample-github-code/sample_code.csv\", \n                          lineterminator='\\n')  \n## read CSV error : https://stackoverflow.com/questions/33998740/error-in-reading-a-csv-file-in-pandascparsererror-error-tokenizing-data-c-err\n\nsample_code.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_code.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Combine .C, .cpp, .cc, .h to C++ file, .cpp, say  ## Source : ## http://gcc.gnu.org/onlinedocs/gcc-4.4.1/gcc/Overall-Options.html#index-file-name-suffix-71\nsample_code.loc[sample_code['type'].isin(['C', 'cpp', 'cc', 'h']), 'type'] = 'cpp'\n## Combine .html & .htm to .html, say\nsample_code.loc[sample_code['type'].isin(['html', 'htm']), 'type'] = 'html'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_counts = sample_code['type'].value_counts().to_frame().reset_index()\ntype_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Filter irrelevant files like null, .gitignore using value counts\ntop_languages = type_counts[type_counts['type'] >= 1000]\ntop_languages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data=top_languages, x='index', y='type')\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Filtering files created by IDEs, version control & data files\ntop_languages = top_languages[~top_languages['index'].isin(['sublime-snippet', 'xcworkspacedata', 'gitignore', \n                                                            'project', 'properties', 'conf', 'config', 'cfg',\n                                                            'meta', 'test', 'gradle', 'patch', 'ebuild', 'ini',\n                                                           'csv', 'json', 'txt', 'geojson', 'svg', \n                                                            'tpl', 'less', 'cmake', 'mk', 'd'])]\n\nsns.barplot(data=top_languages, x='index', y='type')\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Filter with top_languages\ntrain = sample_code[sample_code['type'].isin(top_languages['index'].values)]\n\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=10\nprint(\"\\n\".join(train['content'][i].split(\"\\n\")[:10]))\nprint(train['type'].values[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting data & training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, val_x, train_y, val_y = model_selection.train_test_split(train['content'], train['type'], test_size=0.2)\n\nprint(len(train_x), len(val_x) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoder = preprocessing.LabelEncoder()  ## For neural networks\n#train_y = encoder.fit_transform(train_y)\n#encoder.classes_\n#val_y = encoder.transform(val_y)  ## For neural networks\n#print(val_y[0])\n#print(encoder.inverse_transform([val_y[0]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec = TfidfVectorizer(max_df = 0.6, min_df = 0.01, max_features = 10000, analyzer = 'word', \n                      #ngram_range=(2,3),\n                      use_idf=True, token_pattern=r'\\w{1,}')\n#tfidf = TfidfTransformer()\n#clf = MultinomialNB()  ## eli5 not supported\n#clf = linear_model.LogisticRegression()  ## Too slow\nclf = linear_model.SGDClassifier(loss = 'log', max_iter=50, tol=1e-3) ## Logistic regession only\n\n#pipe = make_pipeline(vec, tfidf, clf)\npipe = make_pipeline(vec, clf)\n\npipe.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking Model Performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_y = pipe.predict(val_x)\nreport = metrics.classification_report(val_y, pred_y)\nprint(report)\nprint(\"accuracy: {:0.2f}\".format(metrics.accuracy_score(val_y, pred_y)))\nprint(\"F1-score (weighted): {:0.2f}\".format(metrics.f1_score(val_y, pred_y, average = 'weighted')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = clf.classes_.tolist()\nprint(type(labels))\nprint(list(reversed(labels)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ncm = confusion_matrix(val_y, pred_y, labels)\nprint(cm)\nfig = plt.figure()\nax = fig.add_subplot(111) \ncax = ax.matshow(cm) \nplt.title('Confusion matrix of the classifier') \nfig.colorbar(cax) \nax.set_xticklabels([''] + labels) \nax.set_yticklabels([''] + labels) \nplt.xlabel('Predicted') \nplt.ylabel('True') \nplt.show()\n####################\nax = plt.subplot()\nsns.heatmap(cm, annot=False, ax = ax, cmap=\"Blues\"); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix')\nax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(list(reversed(labels)))\nplt.rcParams[\"figure.figsize\"] = (27,25)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that a JS has a lot of False Positives !"},{"metadata":{},"cell_type":"markdown","source":"## Feature Importance"},{"metadata":{},"cell_type":"markdown","source":"Let's see the most important keywords for every programming language !"},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(clf, vec=vec, top=10)\n## Source : https://eli5.readthedocs.io/en/latest/_notebooks/debug-sklearn-text.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's zoom in on 1 example and see which keywords within the script and most important in making a classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"i=25\nprint(\"\\n\".join(val_x.values[i].split(\"\\n\")[:10]))\nprint(\"Actual class : \", val_y.values[i], \"\\nPredicted class : \", pred_y[i])\neli5.show_prediction(clf, val_x.values[i], vec=vec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Most common mistakes made by our classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"val = pd.concat([val_x, val_y], axis=1)\nval['pred'] = pred_y\nprint(val.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"misclassified_examples = val[val.type != val.pred]\nmisclassified_examples.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_prediction(clf, misclassified_examples['content'].values[1], vec=vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}