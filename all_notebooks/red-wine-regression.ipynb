{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_df = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\nwine_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display\n\nstyle = {'description_width': 'initial'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding f allowed the computations under curly brackets\nprint(f\"Dataset has {wine_df.shape[0]} rows and {wine_df.shape[1]} columns\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check Nulls\n\nwine_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_df.columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classifying Dependent and independent variables\n# Double brackets to make X while single brcket for Y as it's series\nX = wine_df[[col for col in wine_df.columns if col not in ('quality')]]\ny = wine_df['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nIdependent Variables :\\n\\n\", X[:5])\nprint(\"\\nDependent Variable (Score):\\n\\n\", y[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create Train and Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating training set and testing set using test_size floater\nfrom sklearn.model_selection import train_test_split\ntest_size = widgets.FloatSlider(min=0.01, max=0.6, value=0.2, description=\"Test Size :\", tooltips=['Usually 20-30%'])\ndisplay(test_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Divide the dataset into Train and Test sets\nX_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=test_size.value, random_state = 0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Set :\\n----------------\\n\")\nprint(\"X = \\n\", X_train[:3])\nprint(\"y = \\n\", y_train[:3])\n\nprint(\"\\n\\nTest Set :\\n----------------\\n\")\nprint(\"X = \\n\",X_test[:3])\nprint(\"y = \\n\", y_test[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Shape of Training set is {X_train.shape}\")\nprint(f\"Shape of Testing set is {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ML Model Application"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Regressor\n\nfrom sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the regressor and predict outcomes\nregressor_lin = SVR(kernel='linear')\nregressor_pol = SVR(kernel='poly', degree=3)\nregressor_rbf = SVR(kernel='rbf', gamma=0.1)\n\ny_pred_lin = regressor_lin.fit(X_train, y_train).predict(X_test)\ny_pred_pol = regressor_pol.fit(X_train, y_train).predict(X_test)\ny_pred_rbf = regressor_rbf.fit(X_train, y_train).predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Metrics and evaluating the results"},{"metadata":{},"cell_type":"markdown","source":"RMLSE(Root Mean Squared Log Error)\nRMSLE metric only considers the relative error between and the Predicted and the actual value and the scale of the error is not significant. On the other hand, we have RMSE value Increases in magnitude if the scale of error increase. Apart from it, RMLSE incurs a larger penalty for the underestimation of the Actual variable than the Overestimation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmlse(y_test, y_predic):\n    error = np.square(np.log10(y_predic +1) - np.log10(y_test +1)).mean() ** 0.5\n    score = 1 - error\n    return score\n\n# Printing the score\nprint(\"\\n----------------------------\\nRMLSE_lin Score = \", rmlse(y_test, y_pred_lin))\nprint(\"\\n----------------------------\\nRMLSE_pol Score = \", rmlse(y_test, y_pred_pol))\nprint(\"\\n----------------------------\\nRMLSE_rbf Score = \", rmlse(y_test, y_pred_rbf))\n\n\n# #9 Comparing Actual and Predicted Salaries for he test set\n# print(\"\\nActual vs Predicted Scores \\n------------------------------\\n\")\n# error_df = pd.DataFrame({\"Actual\" : y_test,\n#                          \"Predicted\" : y_pred,\n#                          \"Abs. Error\" : np.abs(y_test - y_pred)})\n\n# error_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor_lin.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance (defined for linear kernel) & plot a horizontal bar plot\npd.Series(abs(regressor_lin.coef_[0]), index=X.columns).sort_values(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}