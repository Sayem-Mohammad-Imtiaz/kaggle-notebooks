{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/Consumer_Complaints.csv')\n\n# Remove rows at random to avoid memory error \nnp.random.seed(10)\nremove_n = 1000000\ndrop_indices = np.random.choice(df.index, remove_n, replace=False)\ndf = df.drop(drop_indices)\ndf.shape\n# Remove above code after mem optimization\ndf.head()\n# We need “Product”(OUT) and “Consumer complaint narrative”(IN) columns.","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8def7076401bd66594b8d27a5ba85f80d0ca430"},"cell_type":"code","source":"# Remove Missing values\n# Add a column encoding the product as an integer\n\nfrom io import StringIO\ncol = ['Product', 'Consumer Complaint']\ndf = df[col]\ndf = df[pd.notnull(df['Consumer Complaint'])]\ndf.columns = ['Product', 'Consumer_Complaint']\ndf['category_id'] = df['Product'].factorize()[0]\ncategory_id_df = df[['Product', 'category_id']].drop_duplicates().sort_values('category_id')\ncategory_to_id = dict(category_id_df.values)\nid_to_category = dict(category_id_df[['category_id', 'Product']].values)\ndf.head()","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d60076aebfe977c225b64cd49d7dcd9d0987e45"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,6))\ndf.groupby('Product').Consumer_Complaint.count().plot.bar(ylim=0)\nplt.show()\n\n# We see here imbalance of classes\n# We want a classifier that gives high prediction accuracy over the majority class,\n# while maintaining reasonable accuracy for the minority classes as the majority classes might be of use","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d9dca279dfc7ea587440174d692d3914f7fd536"},"cell_type":"code","source":"# Model: Bag-of-words\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\nfeatures = tfidf.fit_transform(df.Consumer_Complaint).toarray()\nlabels = df.category_id\nfeatures.shape","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86de3cca1e82e9c08e5290492a93eb5b9047e30b"},"cell_type":"code","source":"# Use 'sklearn.feature_selection.chi2' to find the terms that are the most correlated with each of the products\n\nfrom sklearn.feature_selection import chi2\nimport numpy as np\nN = 2\nfor Product, category_id in sorted(category_to_id.items()):\n  features_chi2 = chi2(features, labels == category_id)\n  indices = np.argsort(features_chi2[0])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n  print(\"--> '{}':\".format(Product))\n  print(\"  . Most Correlated Unigrams are :\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n  print(\"  . Most Correlated Bigrams are :\\n. {}\".format('\\n. '.join(bigrams[-N:])))","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"545791d1b63ce8fcccc4c931b9a26f00de77aaf2"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nX_train, X_test, y_train, y_test = train_test_split(df['Consumer_Complaint'], df['Product'], random_state = 0)\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train)\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nclf = MultinomialNB().fit(X_train_tfidf, y_train)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7c17cb10ae6b4868a17e4b36215ac4bd898bd6e"},"cell_type":"code","source":"print(clf.predict(count_vect.transform([\"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"])))","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3524a9e7e54f35d3fbff679b44f4c19bef8f0277"},"cell_type":"code","source":"df[df['Consumer_Complaint'] == \"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"]","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64659acb2c81d20bdf7b114f4ca17cd121426740"},"cell_type":"code","source":"print(clf.predict(count_vect.transform([\"I am disputing the inaccurate information the Chex-Systems has on my credit report. I initially submitted a police report on XXXX/XXXX/16 and Chex Systems only deleted the items that I mentioned in the letter and not all the items that were actually listed on the police report. In other words they wanted me to say word for word to them what items were fraudulent. The total disregard of the police report and what accounts that it states that are fraudulent. If they just had paid a little closer attention to the police report I would not been in this position now and they would n't have to research once again. I would like the reported information to be removed : XXXX XXXX XXXX\"])))","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb8c0e90c9bb2bd3ab54f193e9523dfa49c251e5"},"cell_type":"code","source":"df[df['Consumer_Complaint'] == \"I am disputing the inaccurate information the Chex-Systems has on my credit report. I initially submitted a police report on XXXX/XXXX/16 and Chex Systems only deleted the items that I mentioned in the letter and not all the items that were actually listed on the police report. In other words they wanted me to say word for word to them what items were fraudulent. The total disregard of the police report and what accounts that it states that are fraudulent. If they just had paid a little closer attention to the police report I would not been in this position now and they would n't have to research once again. I would like the reported information to be removed : XXXX XXXX XXXX\"]","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b011a625d098357c62427169d86745259ebd40c"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nmodels = [\n    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n    LinearSVC(),\n    MultinomialNB(),\n    LogisticRegression(random_state=0),\n]\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\nentries = []\nfor model in models:\n  model_name = model.__class__.__name__\n  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n  for fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\nimport seaborn as sns\nsns.boxplot(x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(x='model_name', y='accuracy', data=cv_df, \n              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\nplt.show()","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14b8b0bab5c5215c9261a7f0ff0fc0d8d5105a20"},"cell_type":"code","source":"cv_df.groupby('model_name').accuracy.mean()\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4be94b52c54cd4681b40b0250d23d7630a62103f"},"cell_type":"code","source":"model = LinearSVC()\nX_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nconf_mat = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(conf_mat, annot=True, fmt='d',\n            xticklabels=category_id_df.Product.values, yticklabels=category_id_df.Product.values)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"670cb277a04e54842730b2c064de432610af2c7f"},"cell_type":"code","source":"from IPython.display import display\nfor predicted in category_id_df.category_id:\n  for actual in category_id_df.category_id:\n    if predicted != actual and conf_mat[actual, predicted] >= 10:\n      print(\"'{}' predicted as '{}' : {} examples.\".format(id_to_category[actual], id_to_category[predicted], conf_mat[actual, predicted]))\n      display(df.loc[indices_test[(y_test == actual) & (y_pred == predicted)]][['Product', 'Consumer_Complaint']])\n      print('')","execution_count":35,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"279a4400af7f02f3e8afcb25194b73564eeec28c"},"cell_type":"code","source":"model.fit(features, labels)\nN = 2\nfor Product, category_id in sorted(category_to_id.items()):\n  indices = np.argsort(model.coef_[category_id])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n  bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n  print(\"# '{}':\".format(Product))\n  print(\"  . Top unigrams:\\n       . {}\".format('\\n       . '.join(unigrams)))\n  print(\"  . Top bigrams:\\n       . {}\".format('\\n       . '.join(bigrams)))","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"94ed85de36b8f57802f89166b605b572b2d55013"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}