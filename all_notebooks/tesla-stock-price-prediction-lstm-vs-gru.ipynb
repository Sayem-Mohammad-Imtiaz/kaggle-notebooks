{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.hdcarwallpapers.com/walls/tesla_roadster_4k-HD.jpg)"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n## Recurrent Neural Networks"},{"metadata":{},"cell_type":"markdown","source":"https://colah.github.io/posts/2015-08-Understanding-LSTMs/"},{"metadata":{},"cell_type":"markdown","source":"Humans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. Your thoughts have persistence.\n\nTraditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.\n\nRecurrent neural networks address this issue. They are networks with loops in them, allowing information to persist."},{"metadata":{},"cell_type":"markdown","source":"## LSTM Networks"},{"metadata":{},"cell_type":"markdown","source":"LSTM Networks\n\nLong Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.\n\nLSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n\nAll recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.\nLSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way."},{"metadata":{},"cell_type":"markdown","source":"## GRU"},{"metadata":{},"cell_type":"markdown","source":"The GRU is the newer generation of Recurrent Neural networks and is pretty similar to an LSTM. GRU’s got rid of the cell state and used the hidden state to transfer information. It also only has two gates, a reset gate and update gate.\n\nThe update gate acts similar to the forget and input gate of an LSTM. It decides what information to throw away and what new information to add.\nThe reset gate is another gate is used to decide how much past information to forget.\n\nAnd that’s a GRU. GRU’s has fewer tensor operations; therefore, they are a little speedier to train then LSTM’s. There isn’t a clear winner which one is better. Researchers and engineers usually try both to determine which one works better for their use case."},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*yBXV9o5q7L_CvY7quJt3WQ.png)"},{"metadata":{},"cell_type":"markdown","source":"# Preparation"},{"metadata":{},"cell_type":"markdown","source":"## Load dataset"},{"metadata":{},"cell_type":"markdown","source":"https://ru.investing.com/equities/tesla-motors-historical-data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, GRU\nfrom keras.layers import *\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam, SGD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert date\ndef to_datetime(df):\n    date = datetime.strptime(df, '%d.%m.%Y')\n    return date.strftime(\"%Y-%m-%d\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/tesla-stock-price-new/Price Tesla.csv', sep=';')\ndf['Date'] = df['Date'].apply(lambda x: to_datetime(x))\ndf = df.sort_values('Date').reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select the column \"Price\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Price'] = df['Price'].astype(float)\n\nplt.figure(figsize=(20,7))\nplt.plot(df['Date'].values, df['Price'].values, label = 'Tesla Stock Price', color = 'red')\nplt.xticks(np.arange(100,df.shape[0],200))\nplt.xlabel('Date')\nplt.ylabel('Price ($)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_shape = 1900\n\ntrain = df.iloc[:num_shape, 1:2].values\ntest = df.iloc[num_shape:, 1:2].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling our features using normalization. Normalizing data helps the algorithm in converging i.e. to find local/ global minimum efficiently."},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = MinMaxScaler(feature_range = (0, 1))\ntrain_scaled = sc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we take one row and cut it with a window of 60 elements"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = []\n\n#Price on next day\ny_train = []\n\nwindow = 60\n\nfor i in range(window, num_shape):\n    X_train_ = np.reshape(train_scaled[i-window:i, 0], (window, 1))\n    X_train.append(X_train_)\n    y_train.append(train_scaled[i, 0])\nX_train = np.stack(X_train)\ny_train = np.stack(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression"},{"metadata":{},"cell_type":"markdown","source":"## Recurrent Neural Network"},{"metadata":{},"cell_type":"markdown","source":"### Training of the basic LSTM model"},{"metadata":{},"cell_type":"markdown","source":"We'll use the LSTM for time series prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing the Recurrent Neural Network\nmodel = Sequential()\n#Adding the first LSTM layer with a sigmoid activation function and some Dropout regularization\n#Units - dimensionality of the output space\n\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units = 50))\nmodel.add(Dropout(0.2))\n\n# Adding the output layer\nmodel.add(Dense(units = 1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nmodel.fit(X_train, y_train, epochs = 1000, batch_size = 32);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_volume = np.vstack((train, test))\n\ninputs = df_volume[df_volume.shape[0] - test.shape[0] - window:]\ninputs = inputs.reshape(-1,1)\ninputs = sc.transform(inputs)\n\nnum_2 = df_volume.shape[0] - num_shape + window\n\nX_test = []\n\nfor i in range(window, num_2):\n    X_test_ = np.reshape(inputs[i-window:i, 0], (window, 1))\n    X_test.append(X_test_)\n    \nX_test = np.stack(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(X_test)\npredict = sc.inverse_transform(predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff = predict - test\n\nprint(\"MSE:\", np.mean(diff**2))\nprint(\"MAE:\", np.mean(abs(diff)))\nprint(\"RMSE:\", np.sqrt(np.mean(diff**2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,7))\nplt.plot(df['Date'].values[1800:], df_volume[1800:], color = 'red', label = 'Real Tesla Stock Price')\nplt.plot(df['Date'][-predict.shape[0]:].values, predict, color = 'blue', label = 'Predicted Tesla Stock Price')\nplt.xticks(np.arange(100,df[1800:].shape[0],200))\nplt.title('Tesla Stock Price Prediction')\nplt.xlabel('Date')\nplt.ylabel('Price ($)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 20-day prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ = predict[-1].copy()\nprediction_full = []\nwindow = 60\ndf_copy = df.iloc[:, 1:2][1:].values\n\nfor j in range(20):\n    df_ = np.vstack((df_copy, pred_))\n    train_ = df_[:num_shape]\n    test_ = df_[num_shape:]\n    \n    df_volume_ = np.vstack((train_, test_))\n\n    inputs_ = df_volume_[df_volume_.shape[0] - test_.shape[0] - window:]\n    inputs_ = inputs_.reshape(-1,1)\n    inputs_ = sc.transform(inputs_)\n\n    X_test_2 = []\n\n    for k in range(window, num_2):\n        X_test_3 = np.reshape(inputs_[k-window:k, 0], (window, 1))\n        X_test_2.append(X_test_3)\n\n    X_test_ = np.stack(X_test_2)\n    predict_ = model.predict(X_test_)\n    pred_ = sc.inverse_transform(predict_)\n    prediction_full.append(pred_[-1][0])\n    df_copy = df_[j:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_full_new = np.vstack((predict, np.array(prediction_full).reshape(-1,1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_date = df[['Date']]\n\nfor h in range(20):\n    df_date_add = pd.to_datetime(df_date['Date'].iloc[-1]) + pd.DateOffset(days=1)\n    df_date_add = pd.DataFrame([df_date_add.strftime(\"%Y-%m-%d\")], columns=['Date'])\n    df_date = df_date.append(df_date_add)\ndf_date = df_date.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,7))\nplt.plot(df['Date'].values[1700:], df_volume[1700:], color = 'red', label = 'Real Tesla Stock Price')\nplt.plot(df_date['Date'][-prediction_full_new.shape[0]:].values, prediction_full_new, color = 'blue', label = 'Predicted Tesla Stock Price')\nplt.xticks(np.arange(100,df[1700:].shape[0],200))\nplt.title('Tesla Stock Price Prediction')\nplt.xlabel('Date')\nplt.ylabel('Price ($)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# GRU"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The GRU architecture\nmodelGRU = Sequential()\n\nmodelGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nmodelGRU.add(Dropout(0.2))\n\nmodelGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nmodelGRU.add(Dropout(0.2))\n\nmodelGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nmodelGRU.add(Dropout(0.2))\n\nmodelGRU.add(GRU(units=50))\nmodelGRU.add(Dropout(0.2))\n\nmodelGRU.add(Dense(units=1))\nmodelGRU.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelGRU.compile(optimizer='sgd', loss='mean_squared_error')\nmodelGRU.fit(X_train, y_train, epochs=1000, batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = modelGRU.predict(X_test)\npredict = sc.inverse_transform(predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff = predict - test\n\nprint(\"MSE:\", np.mean(diff**2))\nprint(\"MAE:\", np.mean(abs(diff)))\nprint(\"RMSE:\", np.sqrt(np.mean(diff**2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,7))\nplt.plot(df['Date'].values[1800:], df_volume[1800:], color = 'red', label = 'Real Tesla Stock Price')\nplt.plot(df['Date'][-predict.shape[0]:].values, predict, color = 'blue', label = 'Predicted Tesla Stock Price')\nplt.xticks(np.arange(100,df[1800:].shape[0],20))\nplt.title('Tesla Stock Price Prediction')\nplt.xlabel('Date')\nplt.ylabel('Price ($)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 20-day prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ = predict[-1].copy()\nprediction_full = []\nwindow = 60\ndf_copy = df.iloc[:, 1:2][1:].values\n\nfor j in range(20):\n    df_ = np.vstack((df_copy, pred_))\n    train_ = df_[:num_shape]\n    test_ = df_[num_shape:]\n    \n    df_volume_ = np.vstack((train_, test_))\n\n    inputs_ = df_volume_[df_volume_.shape[0] - test_.shape[0] - window:]\n    inputs_ = inputs_.reshape(-1,1)\n    inputs_ = sc.transform(inputs_)\n\n    X_test_2 = []\n\n    for k in range(window, num_2):\n        X_test_3 = np.reshape(inputs_[k-window:k, 0], (window, 1))\n        X_test_2.append(X_test_3)\n\n    X_test_ = np.stack(X_test_2)\n    predict_ = modelGRU.predict(X_test_)\n    pred_ = sc.inverse_transform(predict_)\n    prediction_full.append(pred_[-1][0])\n    df_copy = df_[j:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_full_new = np.vstack((predict, np.array(prediction_full).reshape(-1,1)))\n\ndf_date = df[['Date']]\n\nfor h in range(20):\n    kk = pd.to_datetime(df_date['Date'].iloc[-1]) + pd.DateOffset(days=1)\n    kk = pd.DataFrame([kk.strftime(\"%Y-%m-%d\")], columns=['Date'])\n    df_date = df_date.append(kk)\ndf_date = df_date.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,7))\nplt.plot(df['Date'].values[1700:], df_volume[1700:], color = 'red', label = 'Real Tesla Stock Price')\nplt.plot(df_date['Date'][-prediction_full_new.shape[0]:].values, prediction_full_new, color = 'blue', label = 'Predicted Tesla Stock Price')\nplt.xticks(np.arange(100,df_date[1700:].shape[0],20))\nplt.title('Tesla Stock Price Prediction')\nplt.xlabel('Date')\nplt.ylabel('Price ($)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}