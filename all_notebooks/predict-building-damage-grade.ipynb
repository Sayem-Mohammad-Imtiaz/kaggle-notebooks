{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5453a159b2951026071160a6f604dc606af3ab8d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0b4bb9a3b7436c6d7021e61a1303fd9f003e2ea"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nfrom sklearn.ensemble import ExtraTreesClassifier\n\ntrain_csv = pd.read_csv('../input/train.csv')\ntest_csv = pd.read_csv('../input/test.csv')\nbuilding_csv = pd.read_csv('../input/Building_Structure.csv')\nownership_csv = pd.read_csv('../input/Building_Ownership_Use.csv')\n\nb_id_train = train_csv['building_id']\nb_id_test = test_csv['building_id']\nb_id_building = building_csv['building_id']\nb_id_ownership = ownership_csv['building_id']\n\ndamage_train = train_csv['damage_grade']\n\ntrain_csv = train_csv.drop(['building_id'], axis = 1)\ntest_csv = test_csv.drop(['building_id'], axis = 1)\nbuilding_csv = building_csv.drop(['building_id'], axis = 1)\nownership_csv = ownership_csv.drop(['building_id'], axis = 1)\n\ntrain_csv = train_csv.drop(['damage_grade'], axis = 1)\n\ntrain_csv = pd.get_dummies(train_csv)\ntest_csv = pd.get_dummies(test_csv)\nbuilding_csv = pd.get_dummies(building_csv)\nownership_csv = pd.get_dummies(ownership_csv)\n\nbuilding_csv['building_id'] = b_id_building\nownership_csv['building_id'] = b_id_ownership\nbsou_csv = pd.merge(building_csv, ownership_csv, on = 'building_id', how = 'inner')\nbsou_csv = bsou_csv.drop(['district_id_y', 'vdcmun_id_y', 'ward_id_y'], axis = 1)\nbsou_csv.rename(columns = {'district_id_x': 'district_id', 'vdcmun_id_x': 'vdcmun_id', 'ward_id_x': 'ward_id'}, inplace = True)\n\ntrain_csv['building_id'] = b_id_train\ntrain_csv['damage_grade'] = damage_train\ntrain = pd.merge(train_csv, bsou_csv, on = 'building_id', how = 'inner')\ntrain = train.drop(['district_id_y', 'vdcmun_id_y'], axis = 1)\ntrain.rename(columns = {'district_id_x': 'district_id', 'vdcmun_id_x': 'vdcmun_id'}, inplace = True)\n\ntest_csv['building_id'] = b_id_test\ntest = pd.merge(test_csv, bsou_csv, on = 'building_id', how = 'inner')\ntest = test.drop(['district_id_y', 'vdcmun_id_y'], axis = 1)\ntest.rename(columns = {'district_id_x': 'district_id', 'vdcmun_id_x': 'vdcmun_id'}, inplace = True)\n\ndef missing_data(df):\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round((df.isnull().sum()/df.isnull().count()*100), 1).sort_values(ascending = False)\n    missing = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\n    return missing\n\nmissing_data_train = missing_data(train)\nmissing_data_train.head(10)\n\nmissing_data_test = missing_data(test)\nmissing_data_test.head(10)\n\ntrain = train[train['age_building']<=300]\n\ncfpreq = train['count_floors_pre_eq'].values\ncfpoeq = train['count_floors_post_eq'].values\ntrain['cfd'] = cfpreq - cfpoeq\n\nhpreq = train['height_ft_pre_eq'].values\nhpoeq = train['height_ft_post_eq'].values\ntrain['hd'] = hpreq - hpoeq\n\ntrain['column_length'] = train['height_ft_pre_eq'].values/train['count_floors_pre_eq'].values\n\ntrain = train[((train['column_length']<40) & (train['damage_grade'] == \"Grade 1\")) | ((train['column_length']<40) & (train['damage_grade'] == \"Grade 2\")) | (train['damage_grade'] == \"Grade 3\") | (train['damage_grade'] == \"Grade 4\") | (train['damage_grade'] == \"Grade 5\")]\ntrain = train[((train['count_floors_pre_eq']<3) & (train['damage_grade'] == \"Grade 1\")) | ((train['count_floors_pre_eq']<3) & (train['damage_grade'] == \"Grade 2\")) | ((train['count_floors_pre_eq']<3) & (train['damage_grade'] == \"Grade 3\")) | ((train['count_floors_pre_eq']<5) & (train['damage_grade'] == \"Grade 4\")) | ((train['count_floors_pre_eq']<5) & (train['damage_grade'] == \"Grade 5\"))]\ntrain = train[((train['height_ft_pre_eq']<50) & (train['damage_grade'] == \"Grade 1\")) | ((train['height_ft_pre_eq']<50) & (train['damage_grade'] == \"Grade 2\")) | ((train['height_ft_pre_eq']<50) & (train['damage_grade'] == \"Grade 3\")) | ((train['height_ft_pre_eq']<60) & (train['damage_grade'] == \"Grade 4\")) | (train['damage_grade'] == \"Grade 5\")]\ntrain = train[(train['damage_grade'] == \"Grade 1\") | ((train['count_floors_post_eq']<4) & (train['damage_grade'] == \"Grade 2\")) | ((train['count_floors_post_eq']<4) & (train['damage_grade'] == \"Grade 3\")) | ((train['count_floors_post_eq']<4) & (train['damage_grade'] == \"Grade 4\")) | (train['damage_grade'] == \"Grade 5\")]\n\ntrain = train.drop(['height_ft_pre_eq', 'height_ft_post_eq'], axis = 1)\ntrain = train.drop(['count_floors_pre_eq', 'count_floors_post_eq'], axis = 1)\n\nt_cfpreq = test['count_floors_pre_eq'].values\nt_cfpoeq = test['count_floors_post_eq'].values\ntest['cfd'] = np.absolute(t_cfpreq - t_cfpoeq)\n\nt_hpreq = test['height_ft_pre_eq'].values\nt_hpoeq = test['height_ft_post_eq'].values\ntest['hd'] = np.absolute(t_hpreq - t_hpoeq)\n\ntest['column_length'] = test['height_ft_pre_eq'].values/test['count_floors_pre_eq'].values\ntest = test.drop(['height_ft_pre_eq', 'height_ft_post_eq'], axis = 1)\ntest = test.drop(['count_floors_pre_eq', 'count_floors_post_eq'], axis = 1)\n\nitrain = train.copy()\nitest = test.copy()\n\nb_id_itrain = itrain['building_id']\nnull_itrain = itrain[itrain.isnull().any(axis = 1)]\nfull_itrain = itrain.dropna(axis = 0)\n\nfull_itrain_Y = full_itrain['has_repair_started']\nfull_itrain_X = full_itrain.drop(['damage_grade', 'building_id', 'has_repair_started'], axis = 1)\n\niX = full_itrain_X.values\niY = full_itrain_Y.values\n\nimodel = ExtraTreesClassifier()\nimodel.fit(iX, iY)\n\nifeature_importances = pd.Series(list(imodel.feature_importances_))\nifeatures = pd.Series(list(full_itrain_X.columns))\nifi = pd.concat([ifeatures, ifeature_importances], axis = 1, keys = ['Feature', 'Importance']).sort_values(by = ['Importance'], ascending = False)\n\nimportant_ifeatures = list(ifi.iloc[0:50]['Feature'])\n\nit = full_itrain_X[important_ifeatures]\niXt = it.values\niYt = full_itrain_Y.values\n\nfrom sklearn.ensemble import RandomForestClassifier\nirf = RandomForestClassifier(n_estimators = 300, random_state = 42)\nirf.fit(iXt, iYt)\n\nnull_itrain_X = null_itrain.drop(['damage_grade', 'building_id', 'has_repair_started'], axis = 1)\nnull_itrain_X = null_itrain_X.fillna(0)\n\nt_null_itrain = null_itrain_X[important_ifeatures]\nt_null_itrain_X = t_null_itrain.values\n\npred_null_itrain_y = pd.Series(list(irf.predict(t_null_itrain_X)))\n\nb_id_null_itrain = null_itrain['building_id']\nb_id_full_itrain = full_itrain['building_id']\n\nnull_itrain['has_repair_started'] = pred_null_itrain_y.values\n\nitrain['has_repair_started'] = null_itrain['has_repair_started']\n\ntrain_f = pd.concat([null_itrain, full_itrain], axis = 0)\nmissing_data(train_f).head()\ntrain_f = train_f.fillna(0)\n\ntrain_f_Y = train_f['damage_grade']\ntrain_f_X = train_f.drop(['damage_grade', 'building_id'], axis = 1)\nX = train_f_X.values\nY = train_f_Y.values\n\nmodel = ExtraTreesClassifier()\nmodel.fit(X, Y)\n\nfeature_importances = pd.Series(list(model.feature_importances_))\nfeatures = pd.Series(list(train_f_X.columns))\nfi = pd.concat([features, feature_importances], axis = 1, keys = ['Feature', 'Importance']).sort_values(by = ['Importance'], ascending = False)\nfi.head(30)\n\nimportant_features = list(fi.iloc[0:70]['Feature'])\n\nt = train_f_X[important_features]\nXt = t.values\nYt = train_f_Y.values\n\ntest = test.fillna(0)\ntest_X = test.drop(['building_id'], axis = 1)\nt_test = test_X[important_features]\nX_t_test = t_test.values\n\nfrom xgboost import XGBClassifier\nxgbc = XGBClassifier(n_estimators=1000, learning_rate=0.2, max_depth=6, random_state=42)\nxgbc.fit(Xt, Yt)\npred_test_y = pd.Series(list(xgbc.predict(X_t_test)))\n\npredictions = pd.concat([b_id_test, pred_test_y], axis = 1, keys = ['building_id', 'damage_grade'])\n\npredictions.to_csv('submission.csv',index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}