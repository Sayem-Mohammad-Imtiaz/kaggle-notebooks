{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","version":"3.6.1","file_extension":".py","name":"python","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_cell_guid":"a297035e-d98e-4a8d-b993-74bf6fd1c126","_uuid":"a6c38c361785004c7edcfda73e33112a0201a49c"},"cell_type":"markdown","source":""},{"metadata":{"collapsed":true,"_cell_guid":"4b0a8f96-f701-4d93-9782-d66566e1259a","_uuid":"cb80f8fb4eb1a1253a84fdf5d1e7efc1c8240e87"},"cell_type":"code","execution_count":null,"outputs":[],"source":"import numpy as np \nimport pandas as pd \nimport datetime as datetime\nimport matplotlib.pyplot as plt\nimport folium\npd.options.display.max_rows = 100"},{"metadata":{"_cell_guid":"30cf6896-198b-4240-9a4b-413af478ac1c","_uuid":"ffe3ba4f9cfc9c968c5975d4424ea8d72435fcd0"},"cell_type":"markdown","source":"Files in the input folder."},{"metadata":{"_cell_guid":"b0f21b88-0014-4647-876b-6aac4a8b931b","_uuid":"b8934cc9bd99d9dc58807ea588403340d7542bd8"},"cell_type":"code","execution_count":null,"outputs":[],"source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"metadata":{"_cell_guid":"867f07c0-60b7-4bfc-add3-26150eea3910","_uuid":"fba802b746e7ee928f4b6c87c394b46c867d6bcf"},"cell_type":"markdown","source":"**Bicycle Sharing System:**\n           \n   Bicycle sharing system (BSS) is a service in which bicycles are made available for shared use to individuals on a very short term basis. Bike share schemes allow people to borrow a bike from point A and return it at point B (Wiki). \n\n**Context:**\n   \n   In this survey we will explore bicycle sharing system, the city of Austin. It consists of ~ 649k trips over 2013-2017, there is also information about 72 stations.\n   \n** Objective**\n\nOur end goal is to be able to predict station usage to improve the ability of bike share employees to supply high-use stations. Station usage depends on a lot of factors, we would divide them into 3 main categories:\n\n* temporal   \n    Everything connected with time. Station usage depends on season, month, day of week, working day or holiday, time of day, special events (football matches, concerts, festivals, etc.)\n    \n* positional   \n  Everything connected with location: average distance to other stations, station altitude, infrastructure around the station\n  \n* Weather   \n  Weather s a key factor. Temperature, rain, fog, wind  - everything strongly affects station usage.\n \nIn this notebook we'll simply explore the dataset we have, find some patterns and similarities in stations usage, but to build an accurate model which is able to predict station usage we will need more data about the average distance to other stations, station altitude, weather conditions for each day, day duration, dates of state holidays and all events which could influence stations usage dramatically (festivals, football matches, concerts, etc.), some metric to estimate infras\ntructure around stations and probably many more characteristics. So, let's do it step by step, starting from exploration."},{"metadata":{"_cell_guid":"509ec619-c051-41e2-b747-8164bf169111","_uuid":"ecb9d02346e19a9a1ece6f8d926255a9918ddea7"},"cell_type":"markdown","source":"Information about trips:"},{"metadata":{"_cell_guid":"2562adaa-7c23-4013-9b6d-6b52b8c9bace","_uuid":"dd8d13b2ea89b5a898c4782e8cb626b4a9f26bc4"},"cell_type":"code","execution_count":null,"outputs":[],"source":"trips = pd.read_csv('../input/austin_bikeshare_trips.csv')\nprint('Shape: ', trips.shape)\ntrips.head()"},{"metadata":{"_cell_guid":"f7a8825a-4571-45a9-84ed-b30199284ef1","_uuid":"5f5fed25a10ab59f714380e6c6e319f082efd514"},"cell_type":"markdown","source":"Information about stations:"},{"metadata":{"_cell_guid":"8fa84115-d1d0-41b6-af9c-e7e0410dbf9f","_uuid":"d994f06a211a28378936339c03f7d1569ee8b479"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations = pd.read_csv('../input/austin_bikeshare_stations.csv')\nprint('Shape: ', stations.shape)\nstations.head()"},{"metadata":{"_cell_guid":"1432f44d-4e06-45f2-aeac-d20586dbb21b","_uuid":"fc0783d0ab2f69eca4b104c7caec8bd6a8363062"},"cell_type":"markdown","source":"**Dealing with missing values**\n\nBefore we dive into our analysis let's treat missing values  "},{"metadata":{"_cell_guid":"b27b39f4-d0e6-48b3-a919-e554ca186cba","_uuid":"654a070c5b01afb50fdb54c9e5327032356bcae0"},"cell_type":"code","execution_count":null,"outputs":[],"source":"print('Stations missing values:')\nstations.isnull().sum()"},{"metadata":{"_cell_guid":"781b43cb-d2ab-4fae-ad3e-c72b022195c4","_uuid":"3c402ffc849fea4ffaeeca07f54a058434fe15a8"},"cell_type":"markdown","source":"Stations table has no missing values. Great! Move on to trips table"},{"metadata":{"_cell_guid":"35eee7c4-4328-4ba8-8927-35caa26200e1","_uuid":"610cf108c5b27875c6f41d0f96431082d2452817"},"cell_type":"code","execution_count":null,"outputs":[],"source":"print('Trips missing values: ')\ntrips.isnull().sum()"},{"metadata":{"_cell_guid":"41141a84-dcaf-4ae6-a834-874e4bbcc70c","_uuid":"ad719ab790bbcc34b05d3dd1f4047dac787f8481"},"cell_type":"markdown","source":"Trips table has some missing values, let's treat them column by column. We transform start_time to dateTime Object and adding 'end_time' column. We'll need it in order to treat mssing values and for further analysis."},{"metadata":{"collapsed":true,"_cell_guid":"33cf8997-c087-4af7-8366-9f3432d6f284","_uuid":"954a5df65966c9f2fddd1f73eeb4fbe56530bdb2"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# transforming start_time to dateTime Object, adding 'end_time' column\ntrips['start_time'] = pd.to_datetime(trips['start_time'])\ndeltas = trips['duration_minutes'].values\nendTimes = []\nfor i in range(trips.shape[0]):\n    value = trips['start_time'][i] + datetime.timedelta(minutes=int (trips['duration_minutes'][i]))\n    endTimes.append(value)\ntrips['end_time'] = endTimes"},{"metadata":{"collapsed":true,"_cell_guid":"4f43f511-1eec-4bf2-8ce7-6a05f60eb017","_uuid":"44b9a329d7bb08c892b7d1f55ee55c2737797fe7"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# year missing values\ntrips['year'] = trips['year'].fillna(trips['start_time'].dt.year)\n\n# month missing values\ntrips['month'] = trips['month'].fillna(trips['start_time'].dt.month)\n\n# subscriber_type missing values 2077 (0.3%) - filling with the most frequent 'Walk Up'\ntrips['subscriber_type'] = trips['subscriber_type'].fillna('Walk Up')\n\n# bikeid missing values. 723 (0.1%), fill all n/a with -1, unknown value\ntrips['bikeid'] = trips['bikeid'].fillna(-1)"},{"metadata":{"_cell_guid":"c6849068-2633-4a22-93b6-6014dd3db3ed","_uuid":"95378d3d0f14f7d0f96c1a17ad206e4d4252e622"},"cell_type":"markdown","source":"As you can see we aren't doing anything fancy to treat missing values for columns 'year', 'month', 'subscriber_type' and 'bikeid'. For 'year' and 'month' we actually have all the information in column 'start_time', those columns are a bit redundant, but we'll leave them for now. For 'subscriber_type' column we filled it with the most frequent occurence 'Walk Up', 'bikeid' missing values we filled with -1, to indicate unknown value.\n\nWe have only 2 columns left which have missing values 'start_station_id' and 'end_station_id'. However, there are no missing values in 'start_station_name' and 'end_station_name'. So, we try to get information from those columns,  map them to station_id from stations table and fill missing values accordingly. "},{"metadata":{"_cell_guid":"a5eefbf0-0bb9-4ec4-89c3-065e7aadc9a8","_uuid":"caa5ef9ab897a0c503bcce224f0b5cbae587b082"},"cell_type":"code","execution_count":null,"outputs":[],"source":"trips[trips.start_station_id.isnull()]['start_station_name'].value_counts()"},{"metadata":{"collapsed":true,"_cell_guid":"33a47cde-481f-48d6-a19c-d1202dac0f58","_uuid":"c7dd3a40d0cdf3c3485baa2ed26165de4293798b"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def fillMissingStartId(missingName, correctedName):\n    ind = trips[(trips.start_station_id.isnull()) & \n       (trips.start_station_name == missingName)].index\n    trips.loc[ind, 'start_station_id'] = stations[stations.name ==correctedName]['station_id'].values[0]\n\nmissingCorrNames = []\nmissingCorrNames.append(('Zilker Park at Barton Springs & William Barton Drive', 'Zilker Park'))\nmissingCorrNames.append(('ACC - West & 12th', 'ACC - West & 12th Street'))\nmissingCorrNames.append(( 'Convention Center/ 3rd & Trinity', 'Convention Center / 3rd & Trinity'))\nmissingCorrNames.append(('Mobile Station', 'Convention Center / 4th St. @ MetroRail'))\nmissingCorrNames.append(('East 11th Street at Victory Grill',  'East 11th St. at Victory Grill'))\nmissingCorrNames.append(('Red River @ LBJ Library', 'Red River & LBJ Library'))\nmissingCorrNames.append(('Mobile Station @ Bike Fest', '4th & Congress'))\nmissingCorrNames.append(('Main Office', 'OFFICE/Main/Shop/Repair'))\nmissingCorrNames.append(('Shop', 'OFFICE/Main/Shop/Repair'))\n    \nfor missingCorrName in missingCorrNames:\n    fillMissingStartId(missingCorrName[0], missingCorrName[1])\n\n# All the other (130 - 0.02%) na fill the most frequent. 2575 - Riverside @ S. Lamar \ntrips['start_station_id'] = trips['start_station_id'].fillna(2575)\n"},{"metadata":{"_cell_guid":"cab53d05-cfe7-44b1-9c38-999463040734","_uuid":"245296a2969988d52102d78a2af3bc155215e1b8"},"cell_type":"markdown","source":"The same strategy for missing end_station_id."},{"metadata":{"_cell_guid":"96bd0675-e2e0-4e0f-8c0f-1c6f0feb7012","_uuid":"7986222daa5e34d45fe1b393c14f9737fda8ba4d"},"cell_type":"code","execution_count":null,"outputs":[],"source":"trips[trips.end_station_id.isnull()]['end_station_name'].value_counts()"},{"metadata":{"collapsed":true,"_cell_guid":"56f376aa-3e58-4998-a05c-0d535beb4e71","_uuid":"e44e77d32d162c44275eedb653787af83d2d86fe"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def fillMissingEndId(missingName, correctedName):\n    ind = trips[(trips.end_station_id.isnull()) & \n       (trips.end_station_name == missingName)].index\n    trips.loc[ind, 'end_station_id'] = stations[stations.name ==correctedName]['station_id'].values[0]\n\nmissingCorrNames = []\nmissingCorrNames.append(('Zilker Park at Barton Springs & William Barton Drive', 'Zilker Park'))\nmissingCorrNames.append(('ACC - West & 12th', 'ACC - West & 12th Street'))\nmissingCorrNames.append(( 'Convention Center/ 3rd & Trinity',  'Convention Center / 3rd & Trinity'))\nmissingCorrNames.append(('Mobile Station', 'Convention Center / 4th St. @ MetroRail'))\nmissingCorrNames.append(('East 11th Street at Victory Grill', 'East 11th St. at Victory Grill'))\nmissingCorrNames.append(('Red River @ LBJ Library', 'Red River & LBJ Library'))\nmissingCorrNames.append(('Main Office', 'OFFICE/Main/Shop/Repair'))\nmissingCorrNames.append(( 'Customer Service', 'OFFICE/Main/Shop/Repair'))\nmissingCorrNames.append(('Repair Shop', 'OFFICE/Main/Shop/Repair'))\nmissingCorrNames.append(('Mobile Station @ Bike Fest', '5th & Bowie'))\nmissingCorrNames.append(('Shop', 'OFFICE/Main/Shop/Repair'))\n\nfor missingCorrName in missingCorrNames:\n    fillMissingEndId(missingCorrName[0], missingCorrName[1])\n    \n# All the other (186 - 0.03%) na fill the most frequent. 2499 - City Hall / Lavaca & 2nd \ntrips['end_station_id'] = trips['end_station_id'].fillna(2499)"},{"metadata":{"_cell_guid":"fd632b6d-9ef3-44fe-80cd-ef5bf588ae08","_uuid":"baca26d079234d03e31a31bafa4b98fde0416b59"},"cell_type":"code","execution_count":null,"outputs":[],"source":"trips.isnull().sum().any()"},{"metadata":{"_cell_guid":"bdc2a4ab-2789-4af9-8fe6-d30fee55eb74","_uuid":"d0c08ae3c505dd3516b69ec3a5a9949903002b86"},"cell_type":"markdown","source":"Great, no more missing values left, we can move on to actual analysis."},{"metadata":{"_cell_guid":"ef2f9324-11a3-432e-8293-d35d6e43b270","_uuid":"9086f6f1e7ea985df1f1faf3334f900fdb71fc6d"},"cell_type":"markdown","source":"**Stations**\n\nLet us analyze the info about the stations first. There are 72 stations in total, among them 55 - active, closed - 11, moved - 5 and 1 station which is active only during Austin City Limits Music Festival (ACL only). Let's plot them on the map."},{"metadata":{"_cell_guid":"2efdecfc-4627-45fa-8c5a-f4839d6d4b73","_uuid":"cad1c047035f55572ba3d184fbb614cf4b6fc825"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations['status'].value_counts()"},{"metadata":{"_cell_guid":"981c63d7-423c-457c-8aa0-9cccb5ffa47c","_uuid":"72bb94bacb649bbd5d6b5c5e4c9f6684e42c3fdb"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def getLatLon(allStations):\n    res = []\n    resNames = []    \n    latitudes = allStations['latitude']\n    longitudes = allStations['longitude']\n    names = allStations['name']    \n    for latitude, longitude, name in zip(latitudes,longitudes, names):\n        res.append((latitude, longitude))\n        resNames.append(name)        \n    return res, resNames\n\nactiveStations = stations[stations.status == 'active']\nmovedStations = stations[stations.status == 'moved']\nclosedStations = stations[stations.status == 'closed']\nACLStations = stations[stations.status == 'ACL only']\n\nlatlonActive, namesStationsActive = getLatLon(activeStations)\nlatlonMoved, namesStationsMoved = getLatLon(movedStations)\nlatlonClosed, namesStationsClosed = getLatLon(closedStations)\nlatlonACL, namesStationsACL = getLatLon(ACLStations)\n\nmapStations = folium.Map( location=[30.26754, -97.74154], zoom_start=14 )\nfor latlon, names, color in zip((latlonActive, latlonMoved, latlonClosed, latlonACL), \n                                 (namesStationsActive, namesStationsMoved, \n                                  namesStationsClosed, namesStationsACL),\n                                ('green', 'blue', 'red', 'purple')):\n    i=0\n    for coord in latlon:\n        folium.Marker( location=[ coord[0], coord[1]], icon=folium.Icon(color=color), \n                      popup=names[i]).add_to( mapStations )\n        i += 1\nmapStations"},{"metadata":{"collapsed":true,"_cell_guid":"54e82f04-49fb-456f-bad8-f270fc514cfe","_uuid":"ebbae0d4f860b569499c703cb8caaf66eac9a3ac"},"cell_type":"markdown","source":"We have information about the trips from 2013-12-21 to 2017-07-31. All those stations were opened or closed on different dates, therefore the number of days they worked during this time period is different. The number of days stations worked is a very important information if we want to compare the number of trips per station. It is different if a station has 1000 trips during 1 month or the same 1000 trips during 1 year. \n\nLet's find out the starting date (when 1st trip happened), closing date (when last trip happened) and number of working days per station. Each trip involves a starting point and endpoint. They can be the same if it's a roundtrip. Station is considered working for the day if it has at least one trip this day (as a starting point or endpoint).  "},{"metadata":{"collapsed":true,"_cell_guid":"782a3ca9-5e42-4910-a14e-b8348522b2d5","_uuid":"f01fd3544bfa88c0da1123b85e1c5b2603548c61"},"cell_type":"code","execution_count":null,"outputs":[],"source":"station_ids = stations['station_id'].values\nfirst_trip = []\nlast_trip = []\nworkDays = []\nfor station_id in station_ids:\n    wDays = len(trips[(trips.start_station_id == station_id) | (trips.end_station_id == station_id)]['start_time'].dt.date.value_counts())\n    start = trips[(trips['start_station_id'] == station_id) | \n                  (trips['end_station_id'] == station_id)].sort_values(by='start_time')\n    start_date = start['start_time'].iloc[0]\n    end = trips[(trips['start_station_id'] == station_id) | \n                  (trips['end_station_id'] == station_id)].sort_values(by='end_time')\n    end_date = end['end_time'].iloc[len(end) - 1]\n    \n    first_trip.append(start_date)\n    last_trip.append(end_date)\n    workDays.append(wDays)\nstations['First trip'] = first_trip\nstations['Last trip'] = last_trip\nstations['First trip'] = stations['First trip'].dt.date\nstations['Last trip'] = stations['Last trip'].dt.date\nstations['Working Days'] = workDays"},{"metadata":{"_cell_guid":"98e2e4ce-d803-4095-ad78-983d6e576aaf","_uuid":"ed00704badb88a335e0ba1305730be16f8fe1e49"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations.sort_values(by='Working Days', ascending=False)[:5]"},{"metadata":{"_cell_guid":"6bea27b9-fb5f-4eca-bc23-566ed4e6d501","_uuid":"da6a90169c5483955c1c9f686854b0c7e47759ef"},"cell_type":"markdown","source":"After carefully analyzing the dates of first trip, last trip and number of working days for each station we can find a few inconsistencies. Remember we have info about trips up to 2017-07-31, so if the status of a station is 'active' the date of last trip should be this date or very close to it (in case it's not very popular station and it didn't have any visitors last dates).\n\n- station 'Guadalupe & 6th', First Trip: 2017-01-01, Last trip: 2017-04-30, status: active. We should change the status to 'closed' or 'moved'\n- station 'Guadalupe & 21st', First Trip: 2014-02-01, Last trip: 2017-07-31, status: moved. We should change the status to 'active'\n- station 'Pease Park', First Trip: 2016-06-02, Last trip: 2017-04-25, status: moved. We should change the status to 'closed' or 'moved'\n\nI contacted the team of Austin BCycle, it's where the data is originally coming from, also on their site (https://austin.bcycle.com/stations/station-locations) we can see iformation about the number of docks for each station. Number of docks is an important information for analyzing station's efficiency. Let's fill the gaps."},{"metadata":{"_cell_guid":"9c3138b8-4f57-40ee-a397-2895e951a60f","_uuid":"9f87d2ca16a81290154f0f533eebd1319fd77101"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations[(stations.name == 'Guadalupe & 6th') | (stations.name == 'Guadalupe & 21st') \n         |(stations.name == 'Pease Park')]"},{"metadata":{"_cell_guid":"6d3d231a-1d30-4e45-9a10-3df8154d01bc","_uuid":"f8ed74575949f7d4548e83ce942f8a153cfd1078"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations.loc[stations.name == 'Guadalupe & 6th', 'status'] = 'moved'\nstations.loc[stations.name == 'Guadalupe & 21st', 'status'] = 'active'\nstations.loc[stations.name == 'Pease Park', 'status'] = 'closed'\n\nstations = stations.sort_values(by='name')\nstations['docks_total'] = [12, 13, 12, 15, 13, 15, 15, 9, 11, 13, 14, 11, 5, 11, 11, 16,\n                          13, 9, 9, 14, 13, 18, 19, 11, 13, 17, 19, 11, 11, 10, 9, 11,\n                          13, 5, 13, 11, 13, 12, 13, 11, 19, 11, 11, 13, 15, 13, 19, 12,\n                          14, 17, 13, 13, 9, 13, 13, 15, 13, 10, 13, 13, 9, 11, 13, 18,\n                          12, 13, 11, 15, 13, 11, 16, 6]\nstations = stations.sort_index()\nstations.head()"},{"metadata":{"_cell_guid":"d22ba15a-0e93-4043-aaf9-bcc1f33f00b4","_uuid":"ec958cd70a6bcb8c6b4c5b911e057c8e044c435e"},"cell_type":"markdown","source":"Good, we corrected those inconsistencies and added information about number of docks for each station. Let's visuzlize it."},{"metadata":{"_cell_guid":"bcd60e6b-ff94-4b73-9770-1d027a82ad9b","_uuid":"2a9db9af17f392f70b5ee4024702e869ab33a271"},"cell_type":"code","execution_count":null,"outputs":[],"source":"colorsSt = {'active':'green', 'closed':'red', 'moved':'blue','ACL only': 'purple'}\nstation_names = stations['name'].values\n\ndef genTicks(size):\n    res = []\n    res.append(0)\n    step = size / (size - 1)\n    total = step\n    for i in range(size-1):\n        res.append(total)\n        total += step\n    return res\n\ndef showStationOpenDays(wDays):\n    colors = stations['status'].map(colorsSt)\n    sortedStationNames = [x for (y,x) in sorted(zip(wDays, station_names))]\n    colSorted = [x for (y,x) in sorted(zip(wDays, colors))]\n    sortedWdays = sorted(wDays)\n    \n    \n    x = np.linspace(0, len(sortedWdays), len(sortedWdays))\n    y = sortedWdays\n  \n    plt.figure(figsize=(15,10))\n    plt.bar(x, y, color=colSorted)\n\n    ticksX = genTicks(len(sortedStationNames))\n    plt.xticks(ticksX, sortedStationNames, rotation=90)\n    plt.ylabel('Days')\n    plt.title('Open days by station')\n#     plt.legend(loc='upper left')\n    plt.show()\n    \nshowStationOpenDays(stations['Working Days'])"},{"metadata":{"_cell_guid":"14808d79-e551-43f3-af27-35f2ea062d50","_uuid":"935b742b69822fa37d98b0d4a11538346baa7ca4"},"cell_type":"code","execution_count":null,"outputs":[],"source":"plt.xlabel('Docks')\nplt.ylabel('Stations')\nplt.title('Number of docks per station')\nplt.hist(stations['docks_total'], bins=13);\n"},{"metadata":{"_cell_guid":"eb342e3a-6f93-45c0-91b1-0902d513e730","_uuid":"72ef707dbbe7a7a4101c20aef8bffff8cab44514"},"cell_type":"markdown","source":"We can see that all the stations which have been working the longest weren't moved or closed and the number of days different stations were open varies from 25 to 1256 days. \n\nThe number of docks varies from 5 to 19, with 11 and 13 the most common. Station is considered empty if it has no bikes (all the docks are free), and full if it has no docks (all the bikes are free). Station works properly if it has free bikes and free docks most of the time.  An interesting thing, for the majority of stations the number of docks is an odd number. If someone knows the answer why it's this way, please write in the comments."},{"metadata":{"_cell_guid":"dbe415ee-9059-4c66-8a07-4d71a5f220e7","_uuid":"d8b25ad98653e0f5218e62ad56f656dad509b107"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations.head()"},{"metadata":{"collapsed":true,"_cell_guid":"addea646-c3ae-442e-a49c-2deeb7affb51","_uuid":"cc078b0ff07f47eb71cbb83ea20116cd05ba5ab8"},"cell_type":"markdown","source":"**Trips**\n"},{"metadata":{"_cell_guid":"a1df8aef-3ef8-495b-befa-88b3ae2cb6b5","_uuid":"769d498d7eab8d8ef3ab006fd3c47c376aa3f391"},"cell_type":"markdown","source":"Let's move on  to the trips table."},{"metadata":{"_cell_guid":"632a15b0-8246-4153-89c4-79523e0fe475","_uuid":"0b83bc0cd251573089c666b0b2422d77efd7350d"},"cell_type":"code","execution_count":null,"outputs":[],"source":"trips.head()"},{"metadata":{"_cell_guid":"543939d6-98fb-4782-b04b-a05fb03df3e7","_uuid":"6311b632456c2e2baddff220f99c7066b502965d"},"cell_type":"markdown","source":"We start from overall stations load, for each station it consists of station load as a starting point plus station load as endpoint."},{"metadata":{"_cell_guid":"b5aaaf87-8bd7-453c-9403-26134268fd56","_uuid":"31848289e9eef6629b613033153eb3afec698219"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def loadByStation(tr, station_id):\n    beg = len(tr[tr['start_station_id'] == station_id])\n    end = len(tr[tr['end_station_id'] == station_id]) \n    return beg, end\n\ndef showLoadTotal(tr, title, workingDays = []):    \n    tripsTotalStations = []\n    for i in range(len(stations)):\n        startSt, endSt = loadByStation(tr, stations['station_id'].values[i])\n        if len(workingDays) == 0:\n            tripsTotalStations.append(startSt + endSt)\n        else:\n            tripsTotalStations.append((startSt + endSt) / workingDays[i])\n     \n    colors = stations['status'].map(colorsSt)\n    colSorted = [x for (y,x) in sorted(zip(tripsTotalStations, colors))]\n    sortedStationNames = [x for (y,x) in sorted(zip(tripsTotalStations, station_names))]   \n    sortedTotalStations = sorted(tripsTotalStations)    \n    \n    x = np.linspace(0, len(sortedTotalStations), len(sortedTotalStations))\n    y = sortedTotalStations\n    plt.figure(figsize=(15,10))\n    plt.bar(x, y, color=colSorted)\n    ticksX = genTicks(len(sortedStationNames))\n    plt.xticks(ticksX, sortedStationNames, rotation=90)\n    plt.ylabel('Load')\n    plt.title(title)\n    plt.show()\n    \n    return tripsTotalStations\n\ntotalLoads = showLoadTotal(trips, 'Total stations load')\nstations['Total load'] = totalLoads"},{"metadata":{"_cell_guid":"e8fd9139-dd31-4505-971e-108cea399fb9","_uuid":"34bf5e8ab773ef6e1bed95180d83c09374efd51b"},"cell_type":"markdown","source":"We have info about 649231 trips and, the overall load is twice as big – 1298462. That’s because each trip involves 2 stations, a starting point and endpoint. Active stations are marked green, closed – red, moved – blue, ACL only - purple. \n\nThis picture shows us which stations have been the most visited over time, however it doesn’t take time frame the stations have been opened into account. Let's find out daily average load for all stations and see if it's similar to overall load.\n"},{"metadata":{"_cell_guid":"b26c1290-7777-4979-b305-26d0b7130481","_uuid":"ca54462bba635b0d495668444a79e02233a6f30e"},"cell_type":"code","execution_count":null,"outputs":[],"source":"dailyLoads = showLoadTotal(trips, 'Average Daily stations load', stations['Working Days'].values)\nstations['Daily load'] = dailyLoads"},{"metadata":{"_cell_guid":"2b430068-e83c-46df-aae1-2ac22affb2c9","_uuid":"defe33663a532fa12d7de30b9dff05f4ac954462"},"cell_type":"markdown","source":"We can see that it changes things quite a bit, the biggest daily load is for the station 'Zilker Park West', about 110 daily loads on average (as starting point and endpoint). This station is open only during Austin City Limits Music Festival, it has been opened only during 27 days, that's why total load isn't big, but daily load is more then twice as big as any other station. What's more, Austin City Limits Music Festival is mostly active during weekends, and the average daily load during weekends is much higher, around 250. \n\nFor all the other stations, the average daily load varies between about 3 to 45 loads per day. But again, it's daily average load, it doesn't take wheather, season, whether it's holiday or not and any other factors into account. And of course, daily load changes depending on those factors, that's why standard deviation has to be pretty big.\n\nAs we can see daily average load is a good estimator to understand whether station works well or not, and is there a reason to close it or not. All stations with higher daily loads are active, 'Nueces @ 3rd' and 'Republic Square @ Guadalupe'   moved, but just a very little bit. It's also quite interesting, 'Republic Square' has moved already 2 times, they are definitely looking for a better place and not everything going smooth now, the average load of the station which was moved is higher then the one which is currently active. The same is true for 'Nueces @ 3rd'. However, it's only the tip of the iceberg, we analyze station performance based on average daily load, which depends on so many factors. What's more we analyze each station work in vacuum, but not all system as a whole. Drop in one station's performance can lead to boost in other stations performance, and it can lead to better distribution of bikes between stations. So, we won't make any conclusions out of that. "},{"metadata":{"_cell_guid":"4242e4f3-81fc-4d65-a531-1453a17405af","_uuid":"dcf1825b83d7a2212ffdecc299f4ec233bec3311"},"cell_type":"markdown","source":"We'll explore how daily average load changes through the years next."},{"metadata":{"collapsed":true,"_cell_guid":"0a814d11-b9c8-4d3d-b527-be8f93f90339","_uuid":"98d939905e8679270f3a0534c893f4da27f13a98"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def getLoadWorkingDays(tr):\n    loadStart = tr[(tr.start_time.dt.weekday >=0) & (tr.start_time.dt.weekday < 5)]\n    return loadStart\n\ndef getLoadNotWorkingDays(tr):   \n    loadStart = tr[(tr.start_time.dt.weekday >=5) & (tr.start_time.dt.weekday <= 6)]\n    return loadStart\n\ndef getLoadByMonth(tr, month):\n    loadRes = tr[tr.month == month]\n    return loadRes\n\ndef getLoadBySeason(tr, season):\n    res = []\n    if season == 1:\n        res = tr[(tr.month == 1) | (tr.month == 2) | (tr.month == 12)]\n    elif season == 2:\n        res = tr[(tr.month == 3) | (tr.month == 4) | (tr.month == 5)]\n    elif season == 3:\n        res = tr[(tr.month == 6) | (tr.month == 7) | (tr.month == 8)]\n    elif season == 4:\n        res = tr[(tr.month == 9) | (tr.month == 10) | (tr.month == 11)]\n    return res\n\n# year \ndef showLoadByYear(ax, tr, station_id=2575, allSt=False):\n    if allSt:\n        tr = tr\n    else:\n        tr = tr[(tr.start_station_id == station_id) | (tr.end_station_id == station_id)]\n    \n    tr_work = getLoadWorkingDays(tr)\n    tr_hol = getLoadNotWorkingDays(tr)\n    \n    len_year_work = []\n    len_year_hol = []\n    \n    for year in range(2013,2018):\n        len_year_work.append(len(tr_work[tr_work.year == year]['start_time'].dt.date.value_counts()))\n        len_year_hol.append(len(tr_hol[tr_hol.year == year]['start_time'].dt.date.value_counts()))\n    \n    tripsByYearInd_work = []\n    tripsByYearVal_work = []\n    tripsByYearInd_hol = []\n    tripsByYearVal_hol = []\n    \n    for year in range(2013,2018):\n        if allSt:\n            st_work = len(tr_work[tr_work.year == year])\n            end_work = len(tr_work[tr_work.year == year])\n            st_hol = len(tr_hol[tr_hol.year == year])\n            end_hol = len(tr_hol[tr_hol.year == year])\n        else:\n            st_work = len(tr_work[(tr_work.year == year) & (tr_work.start_station_id == station_id)])\n            end_work = len(tr_work[(tr_work.year == year) & (tr_work.end_station_id == station_id)])\n            st_hol = len(tr_hol[(tr_hol.year == year) & (tr_hol.start_station_id == station_id)])\n            end_hol = len(tr_hol[(tr_hol.year == year) & (tr_hol.end_station_id == station_id)])\n        tot_work = st_work + end_work\n        tot_hol = st_hol + end_hol\n        tripsByYearInd_work.append(year)\n        tripsByYearVal_work.append(tot_work)\n        tripsByYearInd_hol.append(year)\n        tripsByYearVal_hol.append(tot_hol)\n        \n    for i in range(len(tripsByYearVal_work)):\n        if len_year_work[i] != 0:\n            tripsByYearVal_work[i] = tripsByYearVal_work[i] / len_year_work[i]\n        else:\n            tripsByYearVal_work[i] = 0\n        if len_year_hol[i] != 0:\n            tripsByYearVal_hol[i] = tripsByYearVal_hol[i] / len_year_hol[i]\n        else:\n            tripsByYearVal_hol[i] = 0\n    \n    sortedTripsByYearVal_work = [x for (y,x) in sorted(zip(tripsByYearInd_work, tripsByYearVal_work))]\n    sortedTripsByYearInd_work= sorted(tripsByYearInd_work)\n    sortedTripsByYearVal_hol = [x for (y,x) in sorted(zip(tripsByYearInd_hol, tripsByYearVal_hol))]\n    sortedTripsByYearInd_hol= sorted(tripsByYearInd_hol)\n    \n    n_groups = 5\n    index = np.arange(n_groups)\n    bar_width = 0.4\n#     fig, ax = plt.subplots(1,1, figsize=(16,8))\n        \n    ax.bar(sortedTripsByYearInd_work, sortedTripsByYearVal_work, bar_width, label = 'Work')\n    ax.bar(np.array(sortedTripsByYearInd_hol) + bar_width, sortedTripsByYearVal_hol, bar_width, label='Holiday')    \n    ax.set_ylabel('Daily Load')\n    \n    ax.set_xticks(sortedTripsByYearInd_work)\n    ax.set_xticklabels(['2013', '2014', '2015', '2016', '2017'], rotation=90);\n    ax.legend()\n    \n    if allSt:\n        ax.set_title('Daily Average Load by year, All Stations')\n    else:\n        ax.set_title('Daily Average Load by year, Station ' + str(station_id))\n        \n    return ax"},{"metadata":{"_cell_guid":"0d9c31b9-73f8-46b3-80f5-10ed140169d2","_uuid":"b9378804cc09be50dddcbccec0c7cf81e5921381"},"cell_type":"code","execution_count":null,"outputs":[],"source":"fig, ax = plt.subplots(1,1, figsize=(16,10))\nshowLoadByYear(ax, trips, allSt=True);"},{"metadata":{"_cell_guid":"9cad4346-95c1-4c2c-89d4-a6b33cfeb98f","_uuid":"08bd4f5c5872d88c4fada74be870ed6fd1814f24"},"cell_type":"markdown","source":"We can see a steady increase in daily station usage through 2013-2016, however there is small decrease in 2017 in comparison to 2016. And there is a decrease only during holidays, for working days it stays the same. It can be due to bad weather during holidays or people just tend to use bike share stations less, it needs further investigation. \n\nWe can check the changes of daily load for stations with the highest daily loads."},{"metadata":{"_cell_guid":"e4974ea4-2e79-49b5-a023-08d9e4aa65a9","_uuid":"0836cd82af3094371720a7bfa9f877f8515c69d3"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations.sort_values(by='Daily load')[['station_id', 'name', 'Daily load']][-11:]"},{"metadata":{"_cell_guid":"f8cf5f1c-ee0f-4987-a19a-1af937c7177e","_uuid":"e8e89ea57ed92aeeeab4234856202e06fa67150d"},"cell_type":"code","execution_count":null,"outputs":[],"source":"fig, ax = plt.subplots(1,1, figsize=(16,10))\nshowLoadByYear(ax, trips, 1006);"},{"metadata":{"_cell_guid":"bd57e0b9-9f7e-458f-a00e-6752f2b2b0be","_uuid":"f6daf55af8131a8b4515d795859f9a1ff229952f"},"cell_type":"code","execution_count":null,"outputs":[],"source":"highestLoads = stations.sort_values(by='Daily load')['station_id'].values[-11:-1]\nfig, ax = plt.subplots(5,2, figsize=(16,36), sharey=True)\nnum = 0\nfor i in range(5):\n    for j in range(2):\n        showLoadByYear(ax[i][j], trips, highestLoads[num])\n        num += 1"},{"metadata":{"collapsed":true,"_cell_guid":"9d379987-81f2-45e4-b0aa-fa532545a1b7","_uuid":"a7f00775b6058d906b30f264b5f3ae48a98df015"},"cell_type":"markdown","source":"We can see that the daily load for the station 1006 - Zilker Park West changes dramatically for holidays and weekdays. This station was opened in 2015 and it is open only during Austin City Limits Music Festival in October.\n\nThen there are daily loads through the years for stations with the highest daily loads. We can see how each station is doing through the years. Another interesting note, from the difference between holiday and work load we can guess  if people mostly have fun and relax close to the station or work somewhere nearby. For example, for the station 2574 - Zilker Park average daily load during weekdays is about 40, while during holidays is close to 80, and in contrast for the station 2501 - 5th & Bowie it's about 40 for holidays and weekdays. Can you guess, which station people mostly have fun at and which station they go to work to? \n"},{"metadata":{"_cell_guid":"1f88e7e7-5430-4253-87e5-3e97db12e53d","_uuid":"7e4440aa95d7f633a422c94b1bf45355cc742355"},"cell_type":"markdown","source":"Average daily load by month"},{"metadata":{"collapsed":true,"_cell_guid":"1db192ef-3558-4e22-a174-3d2410f1c773","_uuid":"669875f0cef5f50f219916a6a591bce390ac3935"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# month \ndef showLoadByMonth(ax, tr, station_id=2575, allSt=False):\n    \n    if allSt:\n        tr = tr\n    else:\n        tr = tr[(tr.start_station_id == station_id) | (tr.end_station_id == station_id)]\n    \n    tr_work = getLoadWorkingDays(tr)\n    tr_hol = getLoadNotWorkingDays(tr)\n        \n  \n    len_month_work = []\n    len_month_hol = []\n\n    for month in range(1,13):\n        len_month_work.append(len(tr_work[tr_work.month == month]['start_time'].dt.date.value_counts()))\n        len_month_hol.append(len(tr_hol[tr_hol.month == month]['start_time'].dt.date.value_counts()))\n    \n    tripsByMonthInd_work = []\n    tripsByMonthVal_work = []\n    tripsByMonthInd_hol = []\n    tripsByMonthVal_hol = []\n    \n    for month in range(1,13):\n        if allSt:\n            st_work = len(tr_work[tr_work.month == month])\n            end_work = len(tr_work[tr_work.month == month])\n            st_hol = len(tr_hol[tr_hol.month == month])\n            end_hol = len(tr_hol[tr_hol.month == month])\n        else:\n            st_work = len(tr_work[(tr_work.month == month) & (tr_work.start_station_id == station_id)])\n            end_work = len(tr_work[(tr_work.month == month) & (tr_work.end_station_id == station_id)])\n            st_hol = len(tr_hol[(tr_hol.month == month) & (tr_hol.start_station_id == station_id)])\n            end_hol = len(tr_hol[(tr_hol.month == month) & (tr_hol.end_station_id == station_id)])\n        tot_work = st_work + end_work\n        tot_hol = st_hol + end_hol\n        tripsByMonthInd_work.append(month)\n        tripsByMonthVal_work.append(tot_work)\n        tripsByMonthInd_hol.append(month)\n        tripsByMonthVal_hol.append(tot_hol)\n    tripsByMonthVal_work = np.array(tripsByMonthVal_work) / np.array(len_month_work)\n    tripsByMonthVal_hol = np.array(tripsByMonthVal_hol) / np.array(len_month_hol)\n\n    sortedTripsByMonthVal_work = [x for (y,x) in sorted(zip(tripsByMonthInd_work, tripsByMonthVal_work))]\n    sortedTripsByMonthInd_work= sorted(tripsByMonthInd_work)\n    sortedTripsByMonthVal_hol = [x for (y,x) in sorted(zip(tripsByMonthInd_hol, tripsByMonthVal_hol))]\n    sortedTripsByMonthInd_hol= sorted(tripsByMonthInd_hol)\n    \n    n_groups = 12\n    index = np.arange(n_groups)\n    bar_width = 0.4\n#     fig, ax = plt.subplots(1,1, figsize=(16,8))\n        \n    ax.bar(sortedTripsByMonthInd_work, sortedTripsByMonthVal_work, bar_width, label = 'Work')\n    ax.bar(np.array(sortedTripsByMonthInd_hol) + bar_width, sortedTripsByMonthVal_hol, bar_width, label='Holiday')    \n    ax.set_ylabel('Daily Load')\n    \n    ax.set_xticks(sortedTripsByMonthInd_work)\n    ax.set_xticklabels(['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August',\n                        'September', 'October', 'November', 'December'], rotation=90);\n    ax.legend()\n    \n    if allSt:\n        ax.set_title('Daily Average Load by month, All Stations')\n    else:\n        ax.set_title('Daily Average Load by month, Station ' + str(station_id))"},{"metadata":{"_cell_guid":"5a70a9b5-289b-4449-b3c7-d883e7a3107b","_uuid":"2535d1daffbca1bf64067f47402cfeb5903c8b53"},"cell_type":"code","execution_count":null,"outputs":[],"source":"fig, ax = plt.subplots(1,1, figsize=(16,10))\nshowLoadByMonth(ax, trips, allSt=True)\n"},{"metadata":{"_cell_guid":"1901a690-cfaa-4a2e-8b8b-7b36b9132175","_uuid":"143e763329e5ba8c00b4640d87871e23008fdab0"},"cell_type":"markdown","source":"The most popular months are March and October, with about 2300 daily load (as start point and endpoint). People tend to use bike share stations about 1.5 times more often during holidays in comparison to working days. There is quite an interesting exception – October,  daily load during holidays is more then 2 times higher then during working days. We already know the reason - ACL festival.\n\nYou can experiment and see how daily load by months change for different stations. You can find out which stations are more poplar during different seasons, find differences between work and holiday load and see what kind of station it is. "},{"metadata":{"_cell_guid":"aa43a72c-2103-491f-be43-b6508a107393","_uuid":"f5b138a2b50f77f75f48299fe9420c7ba17cafdb"},"cell_type":"markdown","source":"Let’s move further, let's analyze daily average load by hour. Here we separate overall load of the station into load as as a starting point (someone takes a bike from the station) and load as endpoint (someone returns a bike to the station). "},{"metadata":{"_cell_guid":"cd1ca622-095b-4d58-97a6-d7825ca8e7de","_uuid":"aeb792d8e79c19083804a90395cb065e7038e01c"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def getTotalHorLoad(tr):\n    asStartinPoint = []\n    asEndingPoint = []\n    asStartinPointAv = []\n    asEndingPointAv = []\n    \n    meansStart = []\n    meansEnd = []\n    stdStart = []\n    stdEnd = []\n    \n    unStart = tr['start_time'].dt.date.value_counts().index\n    totWorkingDays = unStart\n    \n    for hour in range(24):\n        oneStart = len(tr[tr.start_time.dt.hour == hour])\n        oneEnd = len(tr[tr.end_time.dt.hour == hour])\n        \n        oneStart_std = tr[tr.start_time.dt.hour == hour]['start_time'].dt.date.value_counts()\n        oneEnd_std = tr[tr.end_time.dt.hour == hour]['end_time'].dt.date.value_counts()\n        \n        \n        if (len(totWorkingDays) != 0):\n            oneStartAv = oneStart / len(totWorkingDays)\n            oneEndAv = oneEnd / len(totWorkingDays)\n        else:\n            oneStartAv = 0\n            oneEndAv = 0\n        \n        a = list(set(totWorkingDays) - set(oneStart_std.index))\n        s1 = pd.Series(np.zeros(len(a), int), index=a)\n        oneStart_std = oneStart_std.append(s1)\n        \n        b = list(set(totWorkingDays) - set(oneEnd_std.index))\n        s2 = pd.Series(np.zeros(len(b), int), index=b)\n        oneEnd_std = oneEnd_std.append(s2)\n\n        oneStd_start = np.std(oneStart_std)\n        oneStd_end = np.std(oneEnd_std)    \n        stdStart.append(oneStd_start)\n        stdEnd.append(oneStd_end)\n        \n        asStartinPoint.append(oneStart)\n        asEndingPoint.append(oneEnd)\n        asStartinPointAv.append(oneStartAv)\n        asEndingPointAv.append(oneEndAv)\n    \n    return asStartinPoint, asEndingPoint, asStartinPointAv, asEndingPointAv, len(totWorkingDays), stdStart, stdEnd\n\ndef showLoad(ax, stLoadAv, wDays, title, yerr=False):\n    n_groups = 24\n    index = np.arange(n_groups)\n    bar_width = 0.4\n    \n    if yerr:\n        rects1 = ax.bar(range(len(stLoadAv[0])), stLoadAv[0], bar_width, yerr=[np.zeros(len(stLoadAv[2]), int), stLoadAv[2]],\n                 label='As start point: ' + str(np.round(np.sum(stLoadAv[0]),2)) + ' (per day)')\n\n        rects2 = ax.bar(np.array(range(len(stLoadAv[1]))) + bar_width, stLoadAv[1], bar_width, yerr=[np.zeros(len(stLoadAv[3]), int), stLoadAv[3]],\n                 label='As end point: ' + str(np.round(np.sum(stLoadAv[1]),2)) + ' (per day)')\n    else:\n        rects1 = ax.bar(range(len(stLoadAv[0])), stLoadAv[0], bar_width,\n                 label='As start point: ' + str(np.round(np.sum(stLoadAv[0]),2)) + ' (per day)')\n\n        rects2 = ax.bar(np.array(range(len(stLoadAv[1]))) + bar_width, stLoadAv[1], bar_width,\n                 label='As end point: ' + str(np.round(np.sum(stLoadAv[1]),2)) + ' (per day)')\n    \n#     ax.set_xlabel('Hour')\n    ax.set_ylabel('Daily Load')\n    ax.set_title('Daily Average Load by hour (' + title +')')\n    ax.set_xticks(range(24))\n    ax.set_xticklabels(index)\n    ax.legend()\n\ndef showTotalHourLoad(tr, st_id=-1):\n    stationsHourLoad_total = []\n    stationHourLoadAverage_total = []\n    if st_id== -1:\n        asStart, asEnd, asStartAv, asEndAv, totWorkingDays, std_start, std_end = getTotalHorLoad(tr)\n    else:\n        asStart, asEnd, asStartAv, asEndAv, totWorkingDays, std_start, std_end = getStationHourLoad(tr, st_id)\n\n    stationsHourLoad_total.append([asStart, asEnd])\n    stationHourLoadAverage_total.append([asStartAv, asEndAv, std_start, std_end])\n    workingDays_total = totWorkingDays\n\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,10))\n    if st_id == -1:\n        title = ' all stations'\n    else:\n        title = 'Station ' + str(st_id)\n    showLoad(ax, stationHourLoadAverage_total[0], workingDays_total, title, False)\n    \nshowTotalHourLoad(trips)"},{"metadata":{"_cell_guid":"ee15cf28-e3a4-4b84-b73a-20c311ff4b2f","_uuid":"c14bace7a2c03e3d7e790319e312609e33551f09"},"cell_type":"markdown","source":"We can see that there are 516 trips on average daily and the most popular hours are between 13 and 17. In the first part of a day, from 6 to 15, people tend to take bikes more often and in return in the second part of a day, from 15 to 24, they return them more often. It gives us overall view of all stations average load during the day, however load for each station is unique, some stations are more poplar in the morning, some in the evening. We can’t see how load by hour change for different seasons, for working days and holidays separately. That's for further analysis."},{"metadata":{"_cell_guid":"f299801d-6e71-4dbf-bab9-159efa238b4f","_uuid":"a932742cfabc1c45455e8ee768e893c97fa93228"},"cell_type":"markdown","source":"**Subscriber_type**  \nLet's see categories of subscribers and find out if they have different patterns in stations usage."},{"metadata":{"_cell_guid":"35b68def-2099-44d4-840f-eee321926803","_uuid":"1a495a26b5949d91deea5a04d3b712a67bc54bf5"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# subscriber \ndef showSuscriberTypes(tr, num=10):\n      \n    n_groups = num\n    index = np.arange(n_groups)\n    bar_width = 0.4\n    fig, ax = plt.subplots(1, 2, figsize=(16,8), sharey=True)\n    \n    tr_work = getLoadWorkingDays(tr)\n    tr_hol = getLoadNotWorkingDays(tr)\n    work_days = len(getLoadWorkingDays(tr)['start_time'].dt.date.value_counts())\n    hol_days = len(getLoadNotWorkingDays(tr)['start_time'].dt.date.value_counts())\n    \n    x_work = tr_work['subscriber_type'].value_counts().index\n    x_work = x_work[::-1]\n    x_work = x_work[-num:]\n    \n    y_work = tr_work['subscriber_type'].value_counts().values\n    y_work = y_work[::-1]\n    y_work = y_work[-num:]\n    y_work = np.array(y_work) / work_days\n    \n    x_hol = tr_hol['subscriber_type'].value_counts().index\n    x_hol = x_hol[::-1]\n    x_hol = x_hol[-num:]\n    \n    y_hol = tr_hol['subscriber_type'].value_counts().values\n    y_hol = y_hol[::-1]\n    y_hol = y_hol[-num:]\n    y_hol = np.array(y_hol) / hol_days\n    \n    ax[0].set_xticks(range(len(x_work)))\n    ax[0].set_xticklabels(x_work, rotation=90);\n    ax[0].bar(range(len(x_work)), y_work)\n    ax[0].set_title('Daily Average load by Subscriber - Work')\n    ax[0].set_ylabel('Trips')\n    \n    ax[1].set_xticks(range(len(x_hol)))\n    ax[1].set_xticklabels(x_hol, rotation=90);\n    ax[1].bar(range(len(x_hol)), y_hol, color='orange')\n    ax[1].set_title('Daily Average load by Subscriber - Holiday')\n    \nshowSuscriberTypes(trips, 6)\n"},{"metadata":{"_cell_guid":"3018ad2e-cd01-49fd-8a10-8bad76e2f2ad","_uuid":"d22e2320aa5559682defdf7fa401c5c4dffc9a08"},"cell_type":"markdown","source":"There are many many more categories of subscribers (52 in total), but those 6 are the most common and they make about 95% of all trips. \n\nLocal365, Local30, Annual Membership - those are people who have monthly or annual membership, they tend to use bicycle share stations more often in comparison to people who don't have membership and as we can see from the picture they mostly use it during weekdays to get to work.  \nWeekender - 72-hours of access to all stations  \n24-Hour Kiosk -  24 hours of access to all stations  \nWalk-Up - probably just single trip  \n'Walk Up' is the most common category of subscriber, the relative difference between 'Walk Up' and other categories is much bigger during holidays, that's because a lot of people who don't have any particular membership feel like riding a bike during holidays. The same reason implies for 'Local 365', for workdays it's much more popular because people who have annual membership use bicycle share stations mostly during weekdays to get to work. You can continue with the same logic for other categories of subscribers.  \n"},{"metadata":{"_cell_guid":"149553cc-b6ea-4125-815b-c195f219f2de","_uuid":"c295d8efe583c0986d76b35622f2d2818fc6fa7b"},"cell_type":"markdown","source":"**Duration**  \nLet's analyze trip duration then, we do it for all categories of subscribers first and then one by one to see the patterns for each category. "},{"metadata":{"collapsed":true,"_cell_guid":"a373eae7-2eec-489f-9f8a-d432eb85d7db","_uuid":"2deefcdfc0f74bf555b52125ccae5e9813b70520"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def calculateMinutesCat(minutes):\n    categoriesMinutes = []\n    for oneMinutes in minutes:\n        if oneMinutes <=5:\n            categoriesMinutes.append('0 - 5')\n            continue\n        if oneMinutes <=10:\n            categoriesMinutes.append('5 - 10')\n            continue\n        if oneMinutes <=20:\n            categoriesMinutes.append('10 - 20')\n            continue\n        if oneMinutes <=30:\n            categoriesMinutes.append('20 - 30')\n            continue\n        if oneMinutes <=40:\n            categoriesMinutes.append('30 - 40')\n            continue\n        if oneMinutes <=50:\n            categoriesMinutes.append('40 - 50')\n            continue\n        if oneMinutes <=60:\n            categoriesMinutes.append('50 - 60')\n            continue\n        if oneMinutes <=80:\n            categoriesMinutes.append('60 - 80')\n            continue\n        if oneMinutes <=100:\n            categoriesMinutes.append('80 - 100')\n            continue\n        if oneMinutes <=120:\n            categoriesMinutes.append('100 - 120')\n            continue\n        if oneMinutes <=180:\n            categoriesMinutes.append('120 - 180')\n            continue\n        if oneMinutes <=360:\n            categoriesMinutes.append('180 - 360')\n            continue\n        if oneMinutes <=720:\n            categoriesMinutes.append('360 - 720')\n            continue\n        if oneMinutes <=1440:\n            categoriesMinutes.append('720 - 1440')\n            continue\n        categoriesMinutes.append('> 1440')\n    return categoriesMinutes\n\ntrips['duration_minutes_cat'] = calculateMinutesCat(trips['duration_minutes'].values)\n\ndef findIndMinRes(indMin):\n    indMinRes = []\n    for i in indMin:\n        one = i.split('-')[0].strip()\n        if one == '> 1440':\n            one = one.split('>')[1].strip()        \n        indMinRes.append(int(one))\n    return indMinRes\n\n\ndef showTripsDuration(ax, tr, title):\n    tr_work = getLoadWorkingDays(tr)\n    tr_hol = getLoadNotWorkingDays(tr)\n    \n    tr_work_len = len(getLoadWorkingDays(trips)['start_time'].dt.date.value_counts())\n    tr_hol_len = len(getLoadNotWorkingDays(trips)['start_time'].dt.date.value_counts())\n    \n    categoriesMinutes = ['0 - 5', '5 - 10', '10 - 20', '20 - 30', '30 - 40', '40 - 50', '50 - 60',\n                     '60 - 80', '80 - 100', '100 - 120', '120 - 180', '180 - 360', '360 - 720', '720 - 1440', '> 1440']\n    x = categoriesMinutes\n    indMin_work = tr_work['duration_minutes_cat'].value_counts().index\n    valMin_work = tr_work['duration_minutes_cat'].value_counts().values\n    indMinRes_work = findIndMinRes(indMin_work)\n    sortedY_work = [x for (y,x) in sorted(zip(indMinRes_work, valMin_work))]\n    sortedY_work = np.array(sortedY_work) / tr_work_len\n    \n    indMin_hol = tr_hol['duration_minutes_cat'].value_counts().index\n    valMin_hol = tr_hol['duration_minutes_cat'].value_counts().values\n    indMinRes_hol = findIndMinRes(indMin_hol)\n    sortedY_hol = [x for (y,x) in sorted(zip(indMinRes_hol, valMin_hol))]\n    sortedY_hol = np.array(sortedY_hol) / tr_hol_len\n    \n    n_groups = len(categoriesMinutes)\n    index = np.arange(n_groups)\n    bar_width = 0.4\n    \n    ax.bar(range(len(sortedY_work)), sortedY_work, bar_width, label = 'Work, Average duration: ' + str(np.round(np.mean(tr_work['duration_minutes']),2)))\n    ax.bar(np.array(range(len(sortedY_hol))) + bar_width, sortedY_hol, bar_width, label = 'Holiday, Average duration: ' + str(np.round(np.mean(tr_hol['duration_minutes']),2)))\n    ax.set_xticks(range(len(categoriesMinutes)))\n    ax.set_xticklabels(categoriesMinutes, rotation=90);\n    \n    ax.set_xlabel('Minutes')\n    ax.set_ylabel('Trips')\n    ax.set_title('Daily Average Trip Duration (in minutes) - ' + title)\n    ax.legend()\n    return ax\n"},{"metadata":{"_cell_guid":"4936221f-c518-4e1c-b030-ca9c051f7c74","_uuid":"67893429cc04aea5bacd87dca7d4c55ba98bbff9"},"cell_type":"code","execution_count":null,"outputs":[],"source":"fig, ax = plt.subplots(1,1,figsize=(16,10))\nshowTripsDuration(ax, trips[trips.subscriber_type =='Walk Up'], 'All Subscribers'); "},{"metadata":{"_cell_guid":"bf82b57b-ab73-4b1f-9785-4ffda08064ff","_uuid":"68a244a412394a32e9ffbc8164d85afd9562b037"},"cell_type":"code","execution_count":null,"outputs":[],"source":"fig, ax = plt.subplots(3,2,figsize=(16,16))\n\nnum = 0\nmostFreqSubscribers = trips['subscriber_type'].value_counts().index[:6]\nfor i in range(3):\n    for j in range(2):\n        showTripsDuration(ax[i][j], trips[trips.subscriber_type ==mostFreqSubscribers[num]], mostFreqSubscribers[num])\n        num += 1\nplt.tight_layout()\n        "},{"metadata":{"_cell_guid":"28098d85-8650-4537-acac-8109ef45d777","_uuid":"f018199f1114007cc300f890853f76f73aefee67"},"cell_type":"markdown","source":"Ok, let's analyze it, first of all there are different limits on y axis for different categories of subscribers. That's because we are more interested in ratio then actual number of trips.\n\nWe can see that for all the categories of subscribers who have long membership ('Local365', 'Local30' and 'Annual Membership') average duration during working days is about 10 minutes and during holidays about 15 minutes. That's much less then for other categories.  They use BSS more during working days and most of the trips are also just between 0-10 minutes. That proves our theory that people who have longer terms membership use BSS to get to work. It's kind of transport for them. \n\nOther categories tend to use bike more often during holidays and average duration of their trips is about 35-40 minutes. There is also quite an interesting pattern if we compare '24 Hour Kiosk' category to 'Weekender'. As you remember, 1st category has access to all stations for 24 hours while 2nd category for 72 hours. And we see that average trip duration is about 37 minutes if you have 1 day access and only 23 minutes for 3 day access. That's a fact, the longer access you have the shorter are your travels!  "},{"metadata":{"_cell_guid":"82e52440-5e53-4b9a-afab-550aa898e4d1","_uuid":"55f75f8b2baa521ecaad22108ea74a35b32b1617"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def showTripDurationBySubscriber(tr, num=10):\n    n_groups = num\n    index = np.arange(n_groups)\n    bar_width = 0.4\n    fig, ax = plt.subplots(1, 1, figsize=(12,8))\n    \n    tr_work = getLoadWorkingDays(tr)\n    tr_hol = getLoadNotWorkingDays(tr)\n    work_days = len(getLoadWorkingDays(tr)['start_time'].dt.date.value_counts())\n    hol_days = len(getLoadNotWorkingDays(tr)['start_time'].dt.date.value_counts())\n    \n    x_work = tr_work['subscriber_type'].value_counts().index\n    x_work = x_work[::-1]\n    x_work = x_work[-num:]\n    \n    y_dur_work = []\n    for oneSubs in x_work:\n        one = tr_work[tr_work.subscriber_type == oneSubs]['duration_minutes'].values\n        y_dur_work.append(np.mean(one))\n        \n    y_dur_hol = []\n    for oneSubs in x_work:\n        one = tr_hol[tr_hol.subscriber_type == oneSubs]['duration_minutes'].values\n        y_dur_hol.append(np.mean(one))\n    \n    ax.set_xticks(range(len(x_work)))\n    ax.set_xticklabels(x_work, rotation=90);\n    ax.bar(range(len(x_work)), y_dur_work, bar_width, label='Work')\n    ax.bar(np.array(range(len(x_work))) + bar_width, y_dur_hol, bar_width, label='Holiday')\n    ax.set_title('Average trip duration by Subscriber')\n    ax.set_ylabel('Minutes')\n    ax.legend()\nshowTripDurationBySubscriber(trips, 6)"},{"metadata":{"_cell_guid":"9333d32f-687d-4918-b8eb-21495340a10b","_uuid":"67e23fa9feef27c8b79066f32818290fa2202add"},"cell_type":"markdown","source":"**BIkeId**\n"},{"metadata":{"_cell_guid":"d960ffd4-9309-4343-b655-27b5b5cdf31d","_uuid":"a2e66d8d3a25f11590d4e34fd9777ae35433c24f"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def showTripsByBikeId():\n    x = range(len(trips['bikeid'].value_counts()))\n    y = trips['bikeid'].value_counts()\n    \n    minutesBike = []\n    for bike in y.index:\n        one = np.sum(trips[trips.bikeid == bike]['duration_minutes'])\n        minutesBike.append(one)\n    \n    fig, ax = plt.subplots(1,2, figsize=(16,8))\n    ax[0].plot(x, y)\n    ax[0].set_ylabel('Trips')\n    ax[0].set_xlabel('BikeId')\n    ax[0].set_title('Number of trips by bike')    \n    ax[1].plot(x, minutesBike)\n    ax[1].set_ylabel('Minutes')\n    ax[1].set_xlabel('BikeId')\n    ax[1].set_title('Total minutes by bike')  \nshowTripsByBikeId()"},{"metadata":{"_cell_guid":"a9849c10-c3eb-4b96-93a4-0df04d374131","_uuid":"ec4385f709bebad223ad4ff1643a6c9a45941c12"},"cell_type":"markdown","source":"There are a bit more then 400 bikes, number of trips per bike varies between 17 and 2049, and more then a half of all bikes travelled around 50000-60000 minutes. 60000 minutes, it's 1000 hours or around 42 days non-stop. We don't know the timeframe those bikes have been used, but it's not more then 1256 days (the biggest number of working days for all stations). So, about 1 hour per day on average, that's quite a lot, not sure I use my bike that much!"},{"metadata":{"collapsed":true,"_cell_guid":"2b496cba-affc-4e67-8f3c-bade3a956141","_uuid":"75a011828fb8dbbf791fddf0d9befc19e0859b94"},"cell_type":"markdown","source":"**Elevation and average distance between stations**\n\nWe have latitudes and longitudes of all stations, based on this information we can calculate station elevation and average distance to other stations. "},{"metadata":{"collapsed":true,"_cell_guid":"69e18e31-fc2c-4546-a898-c3631659343f","_uuid":"01f6eb42ec77b08451e1b54026a2f467e7351f35"},"cell_type":"code","execution_count":null,"outputs":[],"source":"from math import radians, cos, sin, asin, sqrt\nimport urllib.request\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points \n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians \n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    # haversine formula \n    dlon = lon2 - lon1 \n    dlat = lat2 - lat1 \n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a)) \n    km = 6367 * c\n    return km\n\ndistance_stations = []\nfor i in range(len(stations)):\n    oneSt = []\n    lon1 = stations.iloc[i]['longitude']\n    lat1 = stations.iloc[i]['latitude']\n    for j in range(len(stations)):\n        lon2 = stations.iloc[j]['longitude']\n        lat2 = stations.iloc[j]['latitude']\n        dist = haversine(lon1, lat1, lon2, lat2)\n        oneSt.append(dist)\n    distance_stations.append(oneSt)\n\nav_distance = []\nfor i in range(len(distance_stations)):\n    sum_one = 0\n    for j in range(len(distance_stations)):\n        sum_one += distance_stations[i][j]\n    av_distance.append(sum_one / 71)\nstations['av_distance'] = av_distance"},{"metadata":{"_cell_guid":"ad70abcb-1d23-4a2b-9336-86246f3d5a21","_uuid":"570dc90854d375c654ad02d16eb8e127f44064da"},"cell_type":"markdown","source":"We calculate haversine distance. The haversine formula determines the great-circle distance between two points on a sphere. It's just a straight line between two points, doesn't matter if there are roads or not, buildings in the way. It's not exactly the route you would travel by bike, but still shorter haversine distances mean shorter routes by bike in the majority of cases. And actual route by bike between 2 data points will always be bigger, then haversine distance. Let's visualize it. "},{"metadata":{"_cell_guid":"4792fc94-7163-4d0c-b9f4-93417551793a","_uuid":"f2b11a71b293fd636ee45fefcc58d25df13d4f54"},"cell_type":"code","execution_count":null,"outputs":[],"source":"plt.figure(figsize = (16,10))\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.title('Average haversine distance for stations')\nplt.scatter(x=stations['longitude'], y=stations['latitude'], s =stations['av_distance']*50, c=stations['av_distance'])\nplt.colorbar()"},{"metadata":{"_cell_guid":"98f2964e-5bfe-4a1f-82bb-e69dc3ffbe58","_uuid":"0bb7a73ebf17df5b815e1b1d69bade711f045a04"},"cell_type":"markdown","source":"We can see that average haversine distance varies between 1.3 to 3.5km. Makes sense, the stations in the center have small haversine distances and bigger in the corners."},{"metadata":{"collapsed":true,"_cell_guid":"f7639777-0ad4-4ad7-a3b2-9de96c1476b0","_uuid":"11f608f356b1140d78607ff722839d3280ea70bc"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# def elevation(lat, lng):\n#     apikey = \"AIzaSyDLwT37dkueEXk2U1wfnfPoMisFA0YBIW0\" # you need to provide your own API key here\n#     url = \"https://maps.googleapis.com/maps/api/elevation/json\"\n#     request = urllib.request.urlopen(url+\"?locations=\"+str(lat)+\",\"+str(lng)+\"&key=\"+apikey)\n#     results = json.load(request).get('results')\n#     if 0 < len(results):\n#         elevation = results[0].get('elevation')           \n#     return elevation\n\n# elevations = []\n# for i in range(len(stations)):\n#     elev = elevation(stations.iloc[i]['latitude'], stations.iloc[i]['longitude'])\n#     elevations.append(elev)\n#     print(i)\n    \n# stations['elevation'] = elevations"},{"metadata":{"_cell_guid":"bb9c1629-83c4-471b-a805-ddb684e346d1","_uuid":"5662f8ffd2829205fd257af28fa0c9343d0653fe"},"cell_type":"markdown","source":"I commented the code above, you need to provide your own api key, however it will throw an exception if you fork and run kernerl just from kaggle because all external network requests are blocked. You can either run it separately or just copy elevations further down."},{"metadata":{"collapsed":true,"_cell_guid":"4c5797fe-97a6-4d99-a0c0-117bb3fe1b98","_uuid":"ed38fb7681c679857e570864ac6cc3c17930994d"},"cell_type":"code","execution_count":null,"outputs":[],"source":"stations = stations.sort_values(by='name')\nelevations = [166.0672760009766, 159.7005615234375, 165.21728515625, 144.1920013427734, 142.1951446533203,\n 146.9313659667969, 144.1340789794922, 143.1091766357422, 150.1666564941406, 149.4506988525391, 152.5222625732422,\n 163.6567993164062, 157.7004699707031, 153.0662231445312, 137.1873779296875, 139.5315399169922, 138.5940093994141,\n 136.789306640625, 149.4154052734375, 160.9741516113281, 139.0222778320312, 157.8820037841797, 143.2070007324219,\n 141.8021545410156, 142.6670837402344, 142.8450622558594, 142.3974456787109, 159.2362213134766, 164.0555114746094,\n 139.8280487060547, 145.1390228271484, 143.8266448974609, 144.6851959228516, 140.6478271484375, 172.4871215820312,\n 151.3396453857422, 143.3318939208984, 154.7284851074219, 135.8721466064453, 150.1439056396484, 137.0628509521484,\n 145.014404296875, 144.6419525146484, 162.0620574951172, 136.9876556396484, 149.5563659667969, 137.22412109375,\n 144.1656951904297, 137.2400054931641, 137.1984710693359, 147.4045562744141, 178.4207458496094, 144.5030364990234,\n 144.363037109375, 147.4530334472656, 137.4808959960938, 155.9356689453125, 151.7225952148438, 138.4862060546875,\n 164.6349182128906, 152.5728302001953, 165.1692199707031, 164.1784057617188, 156.5611114501953, 141.0511169433594,\n 139.8759765625, 148.5473175048828, 176.1220703125, 149.1334533691406, 141.8068084716797, 143.5822296142578,\n 143.4732971191406]\nstations['elevation'] = elevations\nstations = stations.sort_index()"},{"metadata":{"_cell_guid":"092ff55c-ec9f-41b3-a7aa-ef00b6eeba88","_uuid":"bb2dba2b25f3dab5eb8c1cda394ebe9498e2e49e"},"cell_type":"code","execution_count":null,"outputs":[],"source":"plt.hist(stations['elevation'])\nplt.xlabel('Elevation')\nplt.xlabel('Count')\nplt.title('Stations elevation')"},{"metadata":{"_cell_guid":"104b841e-fc40-48d0-8778-615c52017544","_uuid":"bb1149b90398e6d052e902d3c9c4ca6764b80278"},"cell_type":"markdown","source":"We can see that for most of the stations elevation is around 140. Station elevation has quite a big effect on stations daily load. People mostly want to ride bike down the hill then to climb uphill. It's a problem for a station which is located on the hill. There is a big disproportion in the number of bikes people take from the station and return to it. Some programs even offer some time bonus for people who return bike to the station which is located uphill. \n\nLet's see if average elevation differs for different categories of subscribers"},{"metadata":{"_cell_guid":"8b57e722-5f0e-4489-907f-51b357d7c83f","_uuid":"d45d346267388c745e3567289afbf8e9bb66dfd3"},"cell_type":"code","execution_count":null,"outputs":[],"source":"trips['elevation_start'] = '-'\ntrips['elevation_end'] = '-'\nids = stations['station_id']\nfor oneId in ids:\n    trips.loc[trips.start_station_id == oneId, 'elevation_start'] = stations[stations.station_id == oneId]['elevation'].values[0]\n    trips.loc[trips.end_station_id == oneId, 'elevation_end'] = stations[stations.station_id == oneId]['elevation'].values[0]\n\ndef showElevationBySuscriber(tr, num=10):\n      \n    n_groups = num\n    index = np.arange(n_groups)\n    bar_width = 0.4\n    fig, ax = plt.subplots(1, 2, figsize=(16,8), sharey=False)\n    \n    tr_work = getLoadWorkingDays(tr)\n    tr_hol = getLoadNotWorkingDays(tr)\n    work_days = len(getLoadWorkingDays(tr)['start_time'].dt.date.value_counts())\n    hol_days = len(getLoadNotWorkingDays(tr)['start_time'].dt.date.value_counts())\n    \n    x_work = tr_work['subscriber_type'].value_counts().index\n    x_work = x_work[::-1]\n    x_work = x_work[-num:]\n    \n    y_elev_work_start = [] \n    y_elev_work_end = []\n    for oneSubs in x_work:\n        one = tr_work[tr_work.subscriber_type == oneSubs]['elevation_start'].values\n        two = tr_work[tr_work.subscriber_type == oneSubs]['elevation_end'].values\n        y_elev_work_start.append(np.sum(one) / len(one))\n        y_elev_work_end.append(np.sum(two) / len(two))\n            \n    y_elev_hol_start = [] \n    y_elev_hol_end = []\n    for oneSubs in x_work:\n        one = tr_hol[tr_hol.subscriber_type == oneSubs]['elevation_start'].values\n        two = tr_hol[tr_hol.subscriber_type == oneSubs]['elevation_end'].values\n        y_elev_hol_start.append(np.sum(one) / len(one))\n        y_elev_hol_end.append(np.sum(two) / len(two))\n    \n\n    ax[0].set_xticks(range(len(x_work)))\n    ax[0].set_xticklabels(x_work, rotation=90);\n    ax[0].bar(range(len(x_work)), y_elev_work_start, bar_width, label='Start point')\n    ax[0].bar(np.array(range(len(x_work))) + bar_width, y_elev_work_end, bar_width, label = 'End point')\n    ax[0].set_title('Average Elevation by Subscriber - Work')\n    ax[0].set_ylabel('Elevation')\n    ax[0].set_ylim([140, 150])\n    ax[0].legend()\n    \n    ax[1].set_xticks(range(len(x_work)))\n    ax[1].set_xticklabels(x_work, rotation=90);\n    ax[1].bar(range(len(x_work)), y_elev_hol_start, bar_width, label='Start point')\n    ax[1].bar(np.array(range(len(x_work))) + bar_width, y_elev_hol_end, bar_width, label='End point')\n    ax[1].set_title('Average Elevation by Subscriber - Holiday')\n    ax[1].set_ylim([140, 150])\n    ax[1].legend()\n\nshowElevationBySuscriber(trips, 6)"},{"metadata":{"_cell_guid":"7532bdb5-0a08-407c-bddc-25b1d00a2cd0","_uuid":"de07019011354ab8daaf7d79da792e68623c1dd9"},"cell_type":"markdown","source":"We can see that for all categories of subscribers starting point is a bit higher then ending point. That proves our point that people prefer to ride downhill. And again we see quite an interesting correlation, the longer mebership you have the lower is average elevations of stations you go to. It's reasonable, if you use BSS regularly you know the easiest and fastest routes, so your trips are naturally shorter and easier. That sounds good, the bad part is that people with longer membership use BSS mostly as a kind of transport, not just to relax and have fun. "},{"metadata":{"collapsed":true,"_cell_guid":"8fe2a633-3e8d-42fa-95b9-1d77c870b5a3","_uuid":"f804226a65ea50c64282bf7a2342ab6f15cc83f4"},"cell_type":"markdown","source":"**Conclusion** \n\nIt was just a short exploration notebook for Austin bikeshare dataset. We can see that predicting station usage is a difficult task. The standard deviation of daily usage for different stations is very high. Daily load depends on many factors, we visualized some of them, but there are many more factors variance in the data can be explained on. \n\nSome key points we get from this exploration: \n- the most popular seasons are Spring and Autumn, months - March and October, days of week Saturaday and Sunday\n- peak hours for the day between 13-17\n- people ride bikes about 1.5 times more often during holidays\n- long term members use bike share stations more often during working days, and their average trip is about 10-15 minutes. We can guess, that it's kind of transport for them\n- short term members use BSS more often during holidays, and their average trip duration is about 30-40 minutes. We can guess, that riding a bike is mostly to have fun and relax for them.\n- there are about 2 times more short term members\n- the longer membership, the easier (in terms of stations elevation) and shorter trips\n\nIt's interesting to compare bicycle share stations of different cities. In Austin we can see, that people mostly use BSS to have fun and relax (a good indicator of that is the number of trips during working days and holidays). It's good and bad at the same time, good because people have good time riding a bike, and bad because they don't see it as a kind of transport. "},{"metadata":{"_cell_guid":"56a01bb1-40fd-4680-8988-634bc1855c88","_uuid":"4715a8e5066638f348b5b772611510eec82713a6"},"cell_type":"markdown","source":"**Hope you enjoyed this notebook!\nPlease upvote if you find it useful :)**"}]}