{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Part 0: Prologue","metadata":{}},{"cell_type":"markdown","source":"Итак, собственно, подходит к концу соревнование. Всегда любил наблюдать за лидербордами в последние 24 часа. Они, по сути, \"вскипают\" и в его середине, а иногда и в верхней части происходят бурные трансформации. А если данные разбиты в сильно разных пропорциях, или сильно отличаются по характеристикам то бывает ещё и сильный шафл. Страшно, но бесценно. \n\nВпрочем, сейчас не об этом. Этот кернел пишется за сутки до надвигающихся событий, а потому просто опишу своё решение и пожелаю всем удачи. ","metadata":{}},{"cell_type":"markdown","source":"Если описать кратко, то всё довольно просто. Построим рекомендательный алгоритм на тех юзерах, о которых мы что-то знаем, а остальным ~~дадим пиццу, ведь её все любят~~ предложим что-то просто популярное. Звучит как план, скажи же, Джеффри...","metadata":{}},{"cell_type":"markdown","source":"![Lebowski](https://i.postimg.cc/cHGZVC6K/That-s-a-great-plan-Walter-That-s-fuckin-ingenious-if-I-understand-it-correctly-It-s-a-Swiss-fu.png)","metadata":{}},{"cell_type":"markdown","source":"## Part I. Preparation ","metadata":{}},{"cell_type":"markdown","source":"Собственно, начнём. ","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Загрузим данные и импортируем нужные библиотеки","metadata":{}},{"cell_type":"code","source":"!mkdir cookbook","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/input/cookbook/recsys.py cookbook/recsys.py\n!cp /kaggle/input/cookbook/generic_preprocessing.py cookbook/generic_preprocessing.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# Несколько утилиток для предпроцессинга данных\nfrom cookbook.recsys import * \nfrom cookbook.generic_preprocessing import * \n\nimport scipy\nimport random\nimport scipy.sparse as sp\nfrom itertools import cycle, islice\nfrom implicit.nearest_neighbours import BM25Recommender\nfrom datetime import date\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (20,10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" В - Воспроизводимость. Зафиксируем все сиды, чтобы гарантировать неслучайную работу псевдослучайного ГСЧ.","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Книг слишком много(на самом деле книг много не бывает). Но тем не менее возьмём топ наиболее популярных","metadata":{}},{"cell_type":"code","source":"\nBOOK_CNT = 4000\n\n# Директории с данными\nDATA_DIR = \"/kaggle/input/mts-ml-summer-school/\"\n\nSUB_DIR = \"/kaggle/input/cookbook/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"items = pd.read_csv(os.path.join(DATA_DIR, \"items.csv\"))\nusers = pd.read_csv(os.path.join(DATA_DIR, \"users.csv\"))\ninteractions = pd.read_csv(os.path.join(DATA_DIR, \"interactions.csv\"))\n\n# Топ за 30 дней. Нужен в качестве примера сабмита\nsub = pd.read_csv(os.path.join(SUB_DIR, \"submission_pop_30.csv\"))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_set = pd.merge( \n    pd.merge(interactions, items, how='left', left_on=\"item_id\", right_on=\"id\"),\n    users, how=\"left\", left_on=\"user_id\", right_on=\"user_id\").drop([\"id\"], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part II. Preprocessing\n","metadata":{}},{"cell_type":"markdown","source":"Для начала нужно немного трансформировать исходные данные, обработать пропуски и вот это всё. Здесь стоит сделать одну ремарку. Далее пойдёт только то, что связано с тем, что зашло. Потому что перепробовано слишком много и ещё больше даже не проверено. ","metadata":{}},{"cell_type":"code","source":"full_set.age.fillna(\"unknown_age\", inplace=True)\nfull_set.sex.fillna(\"unknown_sex\", inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_set['age'] = full_set.age.apply(lambda x: x.split(\"_\")[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Просто получение последнего автора (для наглядности)","metadata":{}},{"cell_type":"code","source":"def get_info_last(x, word):\n    try: \n        x = x.replace('\\n', '').replace('\\t', '').replace('  ', ' ').replace('/', ',').lower()\n        return x.split(',')[-1].strip().rstrip()\n    except Exception as e:\n        return word","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_set['one_author'] = full_set.authors.apply(lambda x: get_info_last(x, 'неизвестен'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_set.start_date = pd.to_datetime(full_set.start_date)\nfull_set['init_date'] = \"2017-12-31\"\nfull_set.init_date = pd.to_datetime(full_set.init_date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_set['diff'] = full_set.start_date -  full_set.init_date\n\nfull_set['weight'] = full_set['diff'].apply(lambda x: 1.2578890000000001e-46*pow(x.days,17.08534) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Идея преобразования выше состоит в следующем. Возьмём количество дней прошедших к 31 декабря 2017 года и взвесим нелинейной функцией, таким образом, взаимодействия в последний месяц будут иметь значительно большый и быстрее растущий вес, чем за период до декабря, а в последнюю неделю и того значительнее. \n\nЧем ближе к 31 декабря наблюдение, тем важнее для нас предсказать его правильно. ","metadata":{}},{"cell_type":"code","source":"x = np.array(range(730))\ny = 1.2578890000000001e-46*(x**17.08534)\n\nplt.plot(x,y,label='y = 1.257889e-46*x^17.08534')\nplt.title('Вес в зависимости от дня')\nplt.grid()\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users_ids = sub.Id.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Возьмём первые BOOK_CNT книг по встречаемости\n\nitems_list = full_set[full_set.start_date  > \"2019-10-30\"].groupby('item_id')['progress'].count().reset_index().sort_values(by='progress', ascending=False)['item_id'][:BOOK_CNT]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Для модели оставим только их\n\ninteractions_existing = full_set[full_set.item_id.isin(items_list)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part III. Simple and curious EDA (The second part solution)","metadata":{}},{"cell_type":"markdown","source":"Вообще, начнём наверное с конца, а именно с того, чем будем заполнять пропуски в сабмите. Тут всё довольно просто и одновременно интересно. Все указаннные ID предподсчитаны за месяц для разных групп отдельно, чтобы не захлямлять код здесь. ","metadata":{}},{"cell_type":"code","source":"_temp = full_set[full_set.start_date >= \"2019-12-01\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_items_info(sex_type, book_list):\n    \n    print(\"_\"*100)\n    print(sex_type) \n    for i in book_list:\n        print(items[items.id ==i]['title'].values[0])\n\n        \ndef get_items_info_by_sex_and_age(sex, age):\n    _temp[(_temp.sex==1.0) & (_temp.age==\"18\") ].groupby(['item_id'])['user_id'].count().reset_index().sort_values(by=['user_id'], ascending=[False]).head(10)['item_id'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_items_info(\"Unknown sex:\", [276903, 168963, 187325, 352049, 79499, 267817, 33801, 283713, 93751, 50718]))  \nprint(get_items_info('Male sex', [283713, 184549, 276903, 357309, 55466, 385281, 143175, 168963, 352049, 287060]))  \nprint(get_items_info('Female sex', [283713, 184549, 143175, 168963, 80003, 357309, 56877, 55466, 276903, 385281]))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_books_by_stats(desc, sex=1.0, age=\"18\"):\n    \n    \n    top_items = _temp[(_temp.sex==sex) & (_temp.age==age) ].groupby(['item_id'])['user_id'].count().reset_index().sort_values(by=['user_id'], ascending=[False]).head(10)['item_id'].tolist()\n    return get_items_info(desc, top_items) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим в срезе возраста. Для начала посмотрим по женщинам.","metadata":{}},{"cell_type":"code","source":"print(get_books_by_stats(\"Women 18\", sex=1.0, age=\"18\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_books_by_stats(\"Women 65\", sex=1.0, age=\"65\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"И по мужчинам","metadata":{}},{"cell_type":"code","source":"print(get_books_by_stats(\"Men 18\", sex=1.0, age=\"18\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_books_by_stats(\"Men 65\", sex=1.0, age=\"65\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Очевидно, что в какой-то момент, людям становится не очень интересно двигаться вперёд, ~~доминировать, властвовать, унижать~~ убеждать и воздействовать. Является ли причиной этого достижение всего, или потеря желания, вопрос дискуссионный.\n\nКроме того в ТОПе очень часто появляются представители своего рода книжного \"арт-хауса\", вроде произведений братьев Стругацких \"Пикник на обочине\" и \"Понедельник начинается в субботу\". Это те, кто писали о сталкерах до того, как это стало мейнстримом, до ребят из GSC Game World, да и до самой аварии на ЧАЭС. **Press F to pay respect.** ~~То что водка спасает от радиации, они там не писали.~~ \n\n","metadata":{}},{"cell_type":"markdown","source":"Cкорее всего это связано с наличием тематических подборок в самом приложении, что тоже к слову, открывает пространство для маневров и изысканий в этом направлении. ","metadata":{}},{"cell_type":"markdown","source":"![Screen](https://i.postimg.cc/7ZG9V6wj/photo-2021-05-16-22-54-03.jpg)","metadata":{}},{"cell_type":"markdown","source":"Собственно, мораль. Наверно лучше будет разделить популярные книги по полу и возрасту. А почему бы собственно и нет.","metadata":{}},{"cell_type":"code","source":"conditions = { (0.0, \"18\"):[80003, 283713, 287060, 184549, 267817, 385281, 56877, 262464, 168963, 131612],\n              (1.0, \"18\"):[184549, 276903, 80003, 385281, 55466, 283713, 112869, 168963, 364570, 264133],\n              (0.0, \"25\"):[80003, 56877, 262464, 184549, 357309, 168963, 276903, 385281, 143175, 287060],\n              (1.0, \"25\"):[385281, 283713, 276903, 357309, 187325, 229030, 287060, 184549, 168963, 112869],\n              (0.0, \"35\"):[283713, 184549, 357309, 80003, 56877, 168963, 302067, 242176, 385281, 344047],\n              (1.0, \"35\"):[184549, 357309, 283713, 385281, 276903, 112869, 287060, 5408, 143175, 168963],\n              (0.0, \"45\"):[283713, 184549, 143175, 321351, 168963, 55466, 357309, 323949, 190198, 112869],\n              (1.0, \"45\"):[283713, 184549, 357309, 276903, 55466, 168963, 50718, 143175, 246948, 242176],\n              (0.0, \"55\"):[283713, 143175, 168963, 55466, 184549, 160349, 357309, 323949, 190198, 51423],\n              (1.0, \"55\"):[283713, 184549, 352049, 55466, 143175, 276903, 58480, 51581, 112869, 40953],\n              (0.0, \"65\"):[283713, 143175, 184549, 55466, 374648, 160349, 168963, 267817, 178529, 352049],\n              (1.0, \"65\"):[283713, 55466, 51423, 143526, 276903, 126630, 184549, 232758, 143175, 49054],\n              \n              (1.0):[283713, 184549, 276903, 357309, 55466, 385281, 143175, 168963, 352049, 287060],\n              (0.0):[283713, 184549, 143175, 168963, 80003, 357309, 56877, 55466, 276903, 385281],\n              ('unknown_sex'):[276903, 168963, 187325, 352049, 79499, 267817, 33801, 283713, 93751, 50718]\n            }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"На этом с тем, чем будем заполнять вроде бы разобрались. ","metadata":{}},{"cell_type":"markdown","source":"## Part IV. BM25Recommender + Prediction","metadata":{}},{"cell_type":"markdown","source":"Вообще, я честно долго пытался сварить  LightFM, но что-то пошло не так. ","metadata":{}},{"cell_type":"code","source":"users_inv_mapping = dict(enumerate(interactions_existing['user_id'].unique()))\nusers_mapping = {v: k for k, v in users_inv_mapping.items()}\nprint(len(users_mapping))\n\n\nitems_inv_mapping = dict(enumerate(interactions_existing['item_id'].unique()))\nitems_mapping = {v: k for k, v in items_inv_mapping.items()}\nprint(len(items_mapping))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_coo_matrix(df, \n                   user_col='user_id', \n                   item_col='item_id', \n                   weight_col=None, \n                   users_mapping=users_mapping, \n                   items_mapping=items_mapping):\n    if weight_col is None:\n        weights = np.ones(len(df), dtype=np.float32)\n    else:\n        weights = df[weight_col].astype(np.float32)\n\n    interaction_matrix = sp.coo_matrix((\n        weights, \n        (\n            df[user_col].map(users_mapping.get), \n            df[item_col].map(items_mapping.get)\n        )\n    ))\n    return interaction_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = get_coo_matrix(interactions_existing, weight_col='weight').tocsr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b25_model = BM25Recommender(K=10, K1=2.0, B=0.75)\nb25_model.fit(train.T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Параметры позаимствованы отсюда   [BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)","metadata":{}},{"cell_type":"code","source":"top_N = 10\nuser_id = sub['Id'].iloc[2]\nrow_id = users_mapping[user_id]\nprint(f'Рекомендации для пользователя {user_id}, номер строки - {row_id}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_implicit_recs_mapper(model, train_matrix, N, user_mapping, item_inv_mapping):\n    def _recs_mapper(user):\n        user_id = user_mapping[user]\n        recs = model.recommend(user_id, \n                               train_matrix, \n                               N=N, \n                               filter_already_liked_items=True)\n        return [item_inv_mapping[item] for item, _ in recs]\n    return _recs_mapper\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapper = generate_implicit_recs_mapper(b25_model, train, top_N, users_mapping, items_inv_mapping)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\nrecs = pd.DataFrame({\n    'user_id': interactions_existing['user_id'].unique()\n})\nrecs['item_id'] = recs['user_id'].map(mapper)\nrecs.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Таким образом, удалось получить предсказания по следующему количеству пользователей","metadata":{}},{"cell_type":"code","source":"recs[recs.user_id.isin(sub.Id) ].shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_ids = sub[~sub.Id.isin(recs[recs.user_id.isin(sub.Id)]['user_id'])]['Id'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(missing_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recs_metric = recs.explode('item_id')\nrecs_metric['rank'] = recs_metric.groupby('user_id').cumcount() + 1\nrecs_metric.head(top_N + 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(df_true, df_pred, top_N):\n    result = {}\n    test_recs = df_true.set_index(['user_id', 'item_id']).join(df_pred.set_index(['user_id', 'item_id']))\n    test_recs = test_recs.sort_values(by=['user_id', 'rank'])\n\n    test_recs['users_item_count'] = test_recs.groupby(level='user_id')['rank'].transform(np.size)\n    test_recs['reciprocal_rank'] = (1 / test_recs['rank']).fillna(0)\n    test_recs['cumulative_rank'] = test_recs.groupby(level='user_id').cumcount() + 1\n    test_recs['cumulative_rank'] = test_recs['cumulative_rank'] / test_recs['rank']\n    \n    users_count = test_recs.index.get_level_values('user_id').nunique()\n    for k in range(1, top_N + 1):\n        hit_k = f'hit@{k}'\n        test_recs[hit_k] = test_recs['rank'] <= k\n        result[f'Precision@{k}'] = (test_recs[hit_k] / k).sum() / users_count\n        result[f'Recall@{k}'] = (test_recs[hit_k] / test_recs['users_item_count']).sum() / users_count\n\n    result[f'MAP@{top_N}'] = (test_recs[\"cumulative_rank\"] / test_recs[\"users_item_count\"]).sum() / users_count\n    \n    #print(result)\n    result[f'MRR'] = test_recs.groupby(level='user_id')['reciprocal_rank'].max().mean()\n    return pd.Series(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(compute_metrics(interactions_existing, recs_metric, top_N))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = recs[recs.user_id.isin(sub.Id)]\nrecs_dict =  {i[0]:i[1] for  i in res[['user_id', \t'item_id']].values}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part V. Blend it all","metadata":{}},{"cell_type":"code","source":"\nclass Restoring:\n    \"\"\"Restore missing values. Just filling by common according user's features\"\"\"\n    def __init__(self):\n        self.users = users\n        self.users.age.fillna(\"unknown_age\", inplace=True)\n        self.users.sex.fillna(\"unknown_sex\", inplace=True)\n        self.users['age'] = users.age.apply(lambda x: x.split(\"_\")[0])\n        self.conditions = conditions\n        self.missing_ids = missing_ids\n        self.conditions_cnt = {}\n\n    def get_users_sex(self, user_id):\n        if len(self.users[self.users.user_id == user_id]) > 0:\n            return self.users[self.users.user_id == user_id]['sex'].values[0]\n        else:\n            return None\n    \n    def get_users_age(self, user_id):\n        if len(self.users[self.users.user_id == user_id]) > 0:\n            return self.users[self.users.user_id == user_id]['age'].values[0]\n        else:\n            return None\n    \n    def restore_values(self, x):\n\n        key = None\n        sex = self.get_users_sex(x['Id'])\n        age = self.get_users_age(x['Id'])  \n\n        ## Формируем ключ для извлечения популярного значения\n        if age in [None, 'age'] or sex in [None, 'unknown_sex']:\n            if sex in [None, 'unknown_sex']:\n                key = ('unknown_sex')\n            else:\n                key = (sex)\n\n        else:\n            key = (sex, age)  \n        \n        ## Если нет предсказания добавим популярное\n        if x['Id'] in self.missing_ids:\n\n            if key in self.conditions_cnt.keys():\n                self.conditions_cnt[key] +=1\n            else:\n                self.conditions_cnt[key] = 1\n            \n            return ' '.join([str(i) for i in self.conditions[key]])\n        else:\n            ##  Если есть трансформируем его в строку\n            if x['Id'] in recs_dict.keys():\n                return ' '.join([str(i) for i in recs_dict[x['Id']]])\n            else:\n            ## Или оставим всё как есть\n                return x['Predicted']\n    \n    def clear_dict(self):\n        self.conditions_cnt = {}\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rest = Restoring()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub2 = sub.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub2['Predicted'] = sub2.apply(lambda x: rest.restore_values(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub2.to_csv(\"submission.csv\", index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Количество замен","metadata":{}},{"cell_type":"code","source":"rest.conditions_cnt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part VI. Epilogue","metadata":{}},{"cell_type":"markdown","source":"Вроде всё. Здесь должно быть что-то важное, но ~~важный и вычурный~~ эпилог я придумать не смог. Ну разве что совет любить то, что делаешь и читать хорошие книги. Всем *peace*. ","metadata":{}},{"cell_type":"markdown","source":"by MEMPHIS","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}