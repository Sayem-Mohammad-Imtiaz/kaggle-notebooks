{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Trabalho Final de Estágio Docente\n## Estagiário: Douglas Macedo Sgrott\n## Aluno: Vinicius Gasparini\n## Data de entrega: 21/06/2021 (segunda-feira)\n## O trabalho está organizado em partes:\n - ### **Dataset: Onde você irá limpar e pre processar o dataset. Atribua a versão final do dataset em um dataframe chamado df.**\n - Separação dos dados: Aqui os dados são normalizados e divididos em Treino/Validação. Não precisa modificar o código.\n - ### **Arquitetura da Rede Neural: Onde você vai definir a arquitetura da rede neural.**\n - ### **Parâmetros de otimização da Rede Neural: Onde você vai definir outros parâmetros da rede neural.**\n - Visualização dos resultados: Onde os resultados são obtidos\n - Exemplos: Servir como exemplo de análise, data cleaning e pré-processamento.\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# importing stuff\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# a lot of stuff\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Z-score / outliers stuff\nfrom scipy import stats\n\n# Rede Neural stuff\nfrom tensorflow.keras import regularizers, callbacks\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.utils import plot_model\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-21T12:44:22.143038Z","iopub.execute_input":"2021-06-21T12:44:22.143384Z","iopub.status.idle":"2021-06-21T12:44:22.155194Z","shell.execute_reply.started":"2021-06-21T12:44:22.143355Z","shell.execute_reply":"2021-06-21T12:44:22.15383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset\n#### Coloque aqui seu data cleaning e seu pre-processamento e atribua o dataset para um dataframe chamado **df**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/aula-2-ia-dataset/CasasParaAlugar.csv', index_col=0)\n\n# Analizando as features para auxiliar na caracterização\nfeatures = list(df.head(0))\nsorted({feat:df[feat].nunique() for feat in features}.items(),key=lambda item: item[1])","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.163993Z","iopub.execute_input":"2021-06-21T12:44:22.164616Z","iopub.status.idle":"2021-06-21T12:44:22.21937Z","shell.execute_reply.started":"2021-06-21T12:44:22.164582Z","shell.execute_reply":"2021-06-21T12:44:22.218358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Iremos definir como variáveis categóricas `animal, furniture` e `city`\n\nVamos dar uma olhada nos tipos de dado padrão do nosso dataframe","metadata":{}},{"cell_type":"code","source":"categorical_features = ['animal', 'furniture', 'city']\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.220986Z","iopub.execute_input":"2021-06-21T12:44:22.22127Z","iopub.status.idle":"2021-06-21T12:44:22.241363Z","shell.execute_reply.started":"2021-06-21T12:44:22.221243Z","shell.execute_reply":"2021-06-21T12:44:22.239908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Olhando para o tipo das variáveis vemos que `floor` esta como `object`, isso pode indicar alguma inconsistência nos dados","metadata":{}},{"cell_type":"code","source":"# Listando os valores únicos\nfloor_unique = df.floor.unique()\nprint(f\"{len(floor_unique)} valores unicos.\\nSendo eles {list(floor_unique)}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.243891Z","iopub.execute_input":"2021-06-21T12:44:22.244309Z","iopub.status.idle":"2021-06-21T12:44:22.251732Z","shell.execute_reply.started":"2021-06-21T12:44:22.244268Z","shell.execute_reply":"2021-06-21T12:44:22.25048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vemos que existe o valor `'-'`, vamos alterar estes e os não informados para `0` e assim manter consistência nos dados","metadata":{}},{"cell_type":"code","source":"df.floor.replace(to_replace='-',value='0',inplace=True)\ndf.floor.fillna(value='0',inplace=True)\ndf.floor = pd.to_numeric(df['floor'], downcast='float')\n\n# Listando os valores únicos\nfloor_unique = df.floor.unique()\nprint(f\"{len(floor_unique)} valores unicos.\\nSendo eles {list(floor_unique)}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.253545Z","iopub.execute_input":"2021-06-21T12:44:22.253862Z","iopub.status.idle":"2021-06-21T12:44:22.279965Z","shell.execute_reply.started":"2021-06-21T12:44:22.253833Z","shell.execute_reply":"2021-06-21T12:44:22.278693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analizando dados inválidos ou ausentes","metadata":{}},{"cell_type":"code","source":"percent_missing = df.isnull().sum() * 100 / len(df)\npd.DataFrame({'column_name': df.columns, 'percent_missing': percent_missing})","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.281564Z","iopub.execute_input":"2021-06-21T12:44:22.28199Z","iopub.status.idle":"2021-06-21T12:44:22.303989Z","shell.execute_reply.started":"2021-06-21T12:44:22.28195Z","shell.execute_reply":"2021-06-21T12:44:22.302673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para que nossa análise seja mais precisa, vamos imputar alguns dados nas colunas `furniture`e `animal`\n\nEm `furniture` iremos considerar que se não foi informado, isso corresponde ao valor `not furnished`. Quanto a `animal`, será criado um terceiro valor, `unknown` para quando não houve especificação.","metadata":{}},{"cell_type":"code","source":"df.furniture.fillna('not furnished',inplace=True)\ndf.animal.fillna('unknown',inplace=True)\n\n# Checando as alterações\npercent_missing = df.isnull().sum() * 100 / len(df)\npd.DataFrame({'column_name': df.columns, 'percent_missing': percent_missing})","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.305257Z","iopub.execute_input":"2021-06-21T12:44:22.305522Z","iopub.status.idle":"2021-06-21T12:44:22.329002Z","shell.execute_reply.started":"2021-06-21T12:44:22.305497Z","shell.execute_reply":"2021-06-21T12:44:22.327768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uma vez com esses valores preenchidos, conseguimos prosseguir com a análise dos dados faltantes por linha","metadata":{}},{"cell_type":"code","source":"# Gerando histograma para analisar a quantidade de ocorrências de dados ausentes por linha\ndf_hist_missing = pd.DataFrame()\nfor col in df.columns:\n    missing = df[col].isnull()\n    miss_count = np.sum(missing)\n    if miss_count > 0:  \n        df_hist_missing['{}_miss_count'.format(col)] = missing\n\n\nmiss_count_cols = df_hist_missing.columns\ndf_hist_missing['miss_count'] = df_hist_missing.sum(axis=1)\ndf_hist_missing['miss_count'].value_counts().reset_index().sort_values(by='index').plot.bar(x='index', y='miss_count')","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.330604Z","iopub.execute_input":"2021-06-21T12:44:22.330974Z","iopub.status.idle":"2021-06-21T12:44:22.533153Z","shell.execute_reply.started":"2021-06-21T12:44:22.330944Z","shell.execute_reply":"2021-06-21T12:44:22.5319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sob posse dessas informações, vamos então remover as linhas cujo falta de dados ultrapasse 2 colunas\n\nind_missing = df[df_hist_missing['miss_count'] > 2].index\ndf.drop(ind_missing, axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.535837Z","iopub.execute_input":"2021-06-21T12:44:22.536128Z","iopub.status.idle":"2021-06-21T12:44:22.545119Z","shell.execute_reply.started":"2021-06-21T12:44:22.5361Z","shell.execute_reply":"2021-06-21T12:44:22.544017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Iremos utilizar uma modelagem de regressão para predizer alguns dados de `rent amount, area, property tax e total`","metadata":{}},{"cell_type":"code","source":"# Criamos um dataframe com os dados de rent amount (R$), area, property tax (R$) e total (R$)\ndf_regress = pd.concat([df['rent amount (R$)'], df['area'], df['property tax (R$)'], df['total (R$)']], axis=1)\ndf_regress.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.547028Z","iopub.execute_input":"2021-06-21T12:44:22.547333Z","iopub.status.idle":"2021-06-21T12:44:22.565461Z","shell.execute_reply.started":"2021-06-21T12:44:22.547298Z","shell.execute_reply":"2021-06-21T12:44:22.56426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# Criamos um objeto que fará a Imputação por Regressão\nimp_mean = IterativeImputer(random_state=0)\n# Treinamos a regressão com os dados disponiveis\nimp_mean.fit(df_regress.values)\n\n# Agora, faremos uma regressão nos mesmos dados usados no treinamento, para\n# gerar valores numéricos para substituir os valores ausentes de LotFrontage\nX = df_regress.values\nregr_output = imp_mean.transform(X)\npd.DataFrame(regr_output).describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.566999Z","iopub.execute_input":"2021-06-21T12:44:22.567291Z","iopub.status.idle":"2021-06-21T12:44:22.686921Z","shell.execute_reply.started":"2021-06-21T12:44:22.567262Z","shell.execute_reply":"2021-06-21T12:44:22.685971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aparentemente a regressão foi bem sucedida, vamos incorporar esses dados ao nosso dataframe com excessão do `total (R$)`","metadata":{}},{"cell_type":"code","source":"df['rent amount (R$)'] = regr_output[:, 0]\ndf['area'] = regr_output[:, 1]\ndf['property tax (R$)'] = regr_output[:, 2]","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.688403Z","iopub.execute_input":"2021-06-21T12:44:22.689056Z","iopub.status.idle":"2021-06-21T12:44:22.697282Z","shell.execute_reply.started":"2021-06-21T12:44:22.689013Z","shell.execute_reply":"2021-06-21T12:44:22.696321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vamos agora preencher os dados de `city` utilizando a estratégia de copiar o valor do registro anterior","metadata":{}},{"cell_type":"code","source":"df['city'].fillna(method='ffill',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.698873Z","iopub.execute_input":"2021-06-21T12:44:22.699285Z","iopub.status.idle":"2021-06-21T12:44:22.710535Z","shell.execute_reply.started":"2021-06-21T12:44:22.699241Z","shell.execute_reply":"2021-06-21T12:44:22.709627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Irei retirar a coluna `hoa (R$)` e preencher os dados de `fire insurance (R$)` com valores da média\n\nDados como `rooms, bathroom, parking spaces` serão preenchidos pela mediana.","metadata":{}},{"cell_type":"code","source":"features.remove('hoa (R$)')\ndf = df.loc[:, features]\n\ndf['fire insurance (R$)'] = df['fire insurance (R$)'].fillna(df['fire insurance (R$)'].mean())\n\ndf['rooms'] = df['rooms'].fillna(df['rooms'].median())\ndf['bathroom'] = df['bathroom'].fillna(df['bathroom'].median())\ndf['parking spaces'] = df['parking spaces'].fillna(df['parking spaces'].median())","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.712138Z","iopub.execute_input":"2021-06-21T12:44:22.712645Z","iopub.status.idle":"2021-06-21T12:44:22.728609Z","shell.execute_reply.started":"2021-06-21T12:44:22.7126Z","shell.execute_reply":"2021-06-21T12:44:22.727473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Detecção de outliers","metadata":{}},{"cell_type":"code","source":"def features_boxplot():\n    selected_features = [feature for feature in df.columns if feature not in categorical_features]\n    df_without_missing = df.dropna()\n    fig, axes = plt.subplots(ncols=len(selected_features), figsize=(20, 5))\n\n    for i,col in enumerate(selected_features):\n        axes[i].boxplot(df_without_missing[col])\n        axes[i].set_title(col)\n\n    plt.tight_layout()\nfeatures_boxplot()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:22.730328Z","iopub.execute_input":"2021-06-21T12:44:22.731056Z","iopub.status.idle":"2021-06-21T12:44:23.742743Z","shell.execute_reply.started":"2021-06-21T12:44:22.731012Z","shell.execute_reply":"2021-06-21T12:44:23.74198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vemos claramente que há um `outlier` em `floor`","metadata":{}},{"cell_type":"code","source":"print(\"Outlier:\", df.floor.max())\ndf.drop(df.loc[df['floor'] == df.floor.max()].index, inplace=True)\n\nprint(\"Novo boxplot\")\ndf_without_missing = df.dropna()\nfig, axes = plt.subplots(ncols=1, figsize=(3, 5))\n\naxes.boxplot(df_without_missing['floor'])\naxes.set_title('floor')\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:23.744258Z","iopub.execute_input":"2021-06-21T12:44:23.744949Z","iopub.status.idle":"2021-06-21T12:44:23.916725Z","shell.execute_reply.started":"2021-06-21T12:44:23.744904Z","shell.execute_reply":"2021-06-21T12:44:23.915923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vemos que possuimos dois boxplot muito semelhantes, o de `total (R$)` e o de `area`\n\nVamos então plotar um gráfico de dispersão para tentar analisar a relação entre essas duas features","metadata":{}},{"cell_type":"code","source":"def graph_scatter(x,y):\n    fig, ax = plt.subplots()\n\n    ax.scatter(x=df[x], y=df[y])\n    ax.set_ylabel(x)\n    ax.set_xlabel(y)\n    plt.show()\ngraph_scatter(\"area\",\"total (R$)\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:23.918449Z","iopub.execute_input":"2021-06-21T12:44:23.91913Z","iopub.status.idle":"2021-06-21T12:44:24.101356Z","shell.execute_reply.started":"2021-06-21T12:44:23.919084Z","shell.execute_reply":"2021-06-21T12:44:24.100129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analisando este gráfico, iremos filtrar:\n* area >= 3000\n* total (R$) >= 0.4e6","metadata":{}},{"cell_type":"code","source":"print(\"Tamanho do dataset antes dos filtros: {}\".format(df.shape))\n\nmask = df['area'] < 3000\ndf = df[mask]\nmask = df['total (R$)'] < 0.4e6\ndf = df[mask]\n\nprint(\"Tamanho do dataset depois dos filtros: {}\".format(df.shape))\n\ngraph_scatter(\"area\",\"total (R$)\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:24.102715Z","iopub.execute_input":"2021-06-21T12:44:24.103069Z","iopub.status.idle":"2021-06-21T12:44:24.29034Z","shell.execute_reply.started":"2021-06-21T12:44:24.103036Z","shell.execute_reply":"2021-06-21T12:44:24.289072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos refinar ainda mais diminuindo nosso filtro de area para 1250 e total (R$) para 30000","metadata":{}},{"cell_type":"code","source":"print(\"Tamanho do dataset antes dos filtros: {}\".format(df.shape))\n\nmask = df['area'] < 1250\ndf = df[mask]\nmask = df['total (R$)'] < 3e4\ndf = df[mask]\n\nprint(\"Tamanho do dataset depois dos filtros: {}\".format(df.shape))\n\ngraph_scatter(\"area\",\"total (R$)\")","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:24.291724Z","iopub.execute_input":"2021-06-21T12:44:24.292074Z","iopub.status.idle":"2021-06-21T12:44:24.469102Z","shell.execute_reply.started":"2021-06-21T12:44:24.292043Z","shell.execute_reply":"2021-06-21T12:44:24.467649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Após essa correções, vamos olhar novamente para os boxplot","metadata":{}},{"cell_type":"code","source":"features_boxplot()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:24.47108Z","iopub.execute_input":"2021-06-21T12:44:24.471501Z","iopub.status.idle":"2021-06-21T12:44:25.769318Z","shell.execute_reply.started":"2021-06-21T12:44:24.471459Z","shell.execute_reply":"2021-06-21T12:44:25.767981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como último passo, iremos normalizar os dados categóricos para valores numéricos","metadata":{}},{"cell_type":"code","source":"df['city'] = pd.Categorical(df.city)\ndf['city'] = df.city.cat.codes\ndf['city'] = pd.to_numeric(df['city'], downcast='float')\n\ndf['animal'] = pd.Categorical(df.animal)\ndf['animal'] = df.animal.cat.codes\ndf['animal'] = pd.to_numeric(df['animal'], downcast='float')\n\ndf['furniture'] = pd.Categorical(df.furniture)\ndf['furniture'] = df.furniture.cat.codes\ndf['furniture'] = pd.to_numeric(df['furniture'], downcast='float')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:25.770984Z","iopub.execute_input":"2021-06-21T12:44:25.771378Z","iopub.status.idle":"2021-06-21T12:44:25.806744Z","shell.execute_reply.started":"2021-06-21T12:44:25.771343Z","shell.execute_reply":"2021-06-21T12:44:25.805833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Novas features\n\nSerão criadas 4 novas features\n\n### Razão entre $\\frac{area}{rooms}$\n### Valor $\\frac{rent\\ amount\\ (R\\$)}{rooms + bathroom}$\n### $area^2$\n### $rent\\ amount\\ (R\\$) + property\\ tax\\ (R\\$) + fire\\ insurance\\ (R\\$)$\n","metadata":{}},{"cell_type":"code","source":"df['area_per_room'] = df.area / df.rooms \ndf['rent_per_ambient'] = df['rent amount (R$)'] / (df.rooms + df.bathroom)\ndf['area_squared'] = df.area ** 2\ndf['sum_taxes'] = df['rent amount (R$)'] + df['property tax (R$)'] + df['fire insurance (R$)']\n","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:25.810815Z","iopub.execute_input":"2021-06-21T12:44:25.811215Z","iopub.status.idle":"2021-06-21T12:44:25.821662Z","shell.execute_reply.started":"2021-06-21T12:44:25.811179Z","shell.execute_reply":"2021-06-21T12:44:25.820369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Separação dos dados","metadata":{}},{"cell_type":"code","source":"# Normalizamos os dados de df em uma escala de [0, 1]\n# Estou fazendo isto aqui pois temos que \"desnormalizar\" na hora de gerar os gráficos de R²\ncolumn_names = df.columns\nscaler = MinMaxScaler()\nscaler.fit(df)\ndf = scaler.transform(df)\ndf = pd.DataFrame(df)\ndf.columns = column_names\n\n# Pegamos o dataset df e separamos em x (entrada) e y (saida), numa separação 70% treino e 30% validação\ninput_dim = df.shape[1] - 1\nx = df.drop(columns='total (R$)')\ny = df['total (R$)']\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:25.82388Z","iopub.execute_input":"2021-06-21T12:44:25.824349Z","iopub.status.idle":"2021-06-21T12:44:25.846877Z","shell.execute_reply.started":"2021-06-21T12:44:25.824293Z","shell.execute_reply":"2021-06-21T12:44:25.845595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Arquitetura da Rede Neural\n#### Criei um código bem simples pra permitir criar diferentes redes neurais modificando apenas algumas variáveis (EM CAPSLOCK),\n#### Mas se quiser criar sua própria arquitetura mais customizada, fique a vontade","metadata":{}},{"cell_type":"code","source":"NEURONIOS_CAMADA_INICIAL = 20\n\n# Número de camadas intermediárias e neurônios. Tamanho do array são os números de camadas, elementos do array são números de neurônios.\n# Ex: [30, 15] = 2 camadas intermediárias com 30 neurônios na primeira e 15 neurônios na segunda\n# Ex: [] = Nenhuma camada intermediária\n# Ex: [10, 10, 10, 10, 50] = 5 camadas intermediárias, com 10 neurônios nas 4 primeiras e 50 neurônios na última\nNEURONIOS_CAMADAS_INTERMEDIARIAS = [10, 5]\n\n# Usar dropout: True para usar, False para não usar\nUSAR_DROPOUT = False\n\n# Porcentagem de Dropout: valor entre 0 e 1\nDROPOUT_VALUE = 0.2\n\n# Regularizador: None = Não usar regularizador, 'l1' = Reg L1, 'l2' = Reg L2\nTIPO_REGULARIZADOR = None\n\n# Função de ativação: 'relu', 'tanh', 'sigmoid', 'softmax', 'softplus', 'elu'\nFN_ATIVACAO = 'elu'\n\n# #####################################################################################\n# Definição da ARQUITETURA da Rede Neural\nmodel = Sequential()\n\n# Primeira camada da RNA (input_dim entradas)\nmodel.add(Dense(units=NEURONIOS_CAMADA_INICIAL, input_dim=input_dim, activation=FN_ATIVACAO, kernel_regularizer=TIPO_REGULARIZADOR))\n# Camadas intermediárias\nfor UNITS in NEURONIOS_CAMADAS_INTERMEDIARIAS:\n    model.add(Dense(units=UNITS, activation=FN_ATIVACAO, kernel_regularizer=TIPO_REGULARIZADOR))\n    if USAR_DROPOUT:\n        model.add(Dropout(DROPOUT_VALUE, input_shape=(120,)))\n# Última camada da RNA (1 saída)\nmodel.add(Dense(units=1, activation=FN_ATIVACAO))\n\n\n# \"Doug, mas que código tosco!\" Também acho... Caso você queira criar sua própria arquitetura\n# sem usar os parâmetros acima, é bem simples. Segue abaixo um exemplo meio doideira:\n# model = Sequential()\n# model.add(Dense(units=30, input_dim=input_dim, activation='relu', kernel_regularizer='l1'))\n# model.add(Dropout(0.4, input_shape=(30,)))\n# model.add(Dense(units=20, activation='tanh', kernel_regularizer='l2'))\n# model.add(Dense(units=20, activation='relu', kernel_regularizer=None))\n# model.add(Dense(units=1, activation='relu'))\n\nplot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:25.850121Z","iopub.execute_input":"2021-06-21T12:44:25.850598Z","iopub.status.idle":"2021-06-21T12:44:26.020209Z","shell.execute_reply.started":"2021-06-21T12:44:25.850566Z","shell.execute_reply":"2021-06-21T12:44:26.018807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parâmetros de otimização da Rede Neural\n#### Pode alterar os valores das variáveis que estão EM CAPSLOCK","metadata":{}},{"cell_type":"code","source":"CALLBACKS = [callbacks.TerminateOnNaN()] # Definição dos callbacks a serem utilizados. Isso aqui é opcional, mas pode ajudar: https://keras.io/api/callbacks/early_stopping/\nLOSS = 'mean_squared_error' # 'mean_absolute_error', 'mean_squared_error'\nBATCH_SIZE = 128\nEPOCHS = 50\nOPTIMIZER = 'adam' # 'adam' é o mais utilizado. Caso prefira outro, como 'sgd', boa sorte!\n\n# Compilação do modelo + Definição da Função de Loss e do Otimizador\nmodel.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=LOSS)\n\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=CALLBACKS,\n    validation_data=(x_valid, y_valid),\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:26.022704Z","iopub.execute_input":"2021-06-21T12:44:26.023253Z","iopub.status.idle":"2021-06-21T12:44:35.243057Z","shell.execute_reply.started":"2021-06-21T12:44:26.023189Z","shell.execute_reply":"2021-06-21T12:44:35.242075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualização dos resultados","metadata":{}},{"cell_type":"code","source":"\ndf_valid_scaled = np.column_stack((x_valid, y_valid))\ndf_valid = scaler.inverse_transform(df_valid_scaled)\ny_true = y_valid\n\n\ny_pred = model.predict(x_valid)\npred_df = pd.concat([pd.DataFrame(x_valid).reset_index(drop=True), pd.DataFrame(y_pred)], axis=1)\npred_df = scaler.inverse_transform(pred_df)\npred_df = pd.DataFrame(pred_df)\npred_df.columns = df.columns\npred_df\n\nr2 = r2_score(y_true, y_pred)\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\naxes[0].plot(history.history['loss'])\naxes[0].plot(history.history['val_loss'])\naxes[0].set_title('model loss | \"Quantidade de dados e colunas usadas: {}'.format(df.shape))\naxes[0].set_ylabel('loss')\naxes[0].set_xlabel('epoch')\naxes[0].legend(['train', 'val'], loc='upper left')\n\naxes[1].scatter(x=df_valid[:, -1], y=pred_df['total (R$)'])\n# axes[0].plot(history.history['val_loss'])\naxes[1].set_title('R² = {}'.format(r2))\naxes[1].set_ylabel('y_pred')\naxes[1].set_xlabel('y_true')\n\nprint(\"Quantidade de dados e colunas usadas: {}\".format(df.shape))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T12:44:35.244852Z","iopub.execute_input":"2021-06-21T12:44:35.24535Z","iopub.status.idle":"2021-06-21T12:44:35.742952Z","shell.execute_reply.started":"2021-06-21T12:44:35.245315Z","shell.execute_reply":"2021-06-21T12:44:35.74166Z"},"trusted":true},"execution_count":null,"outputs":[]}]}