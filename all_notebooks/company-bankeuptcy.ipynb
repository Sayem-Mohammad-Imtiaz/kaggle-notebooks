{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_colwidth',None)\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/company-bankruptcy-prediction/data.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = data['Bankrupt?']\ndata = data.drop(['Bankrupt?'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1) Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"# 1.1) Remove too low variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_mean = np.mean(data, axis=0)\n\nvariance = np.var(data/data_mean, axis=0)\nvar_df = pd.DataFrame(variance,columns=['variance'])\nvar_df.sort_values(by='variance').style.background_gradient(sns.light_palette('green', as_cmap=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\n\nvt = VarianceThreshold(5.0).fit(data/data_mean)\n\nvt_transform = vt.transform(data/data_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_var_cols = data.columns[vt.get_support()]\nlow_var_cols = data.columns[~vt.get_support()]\n\nprint(\"Removed cols :\",len(low_var_cols))\nprint(\"Remaining cols :\",len(high_var_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.2) Inspect Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mat = np.corrcoef(vt_transform, rowvar=False)\ncorr_mat = pd.DataFrame(corr_mat)\n\ncorr_mat.style.background_gradient(sns.light_palette('blue', as_cmap=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.3) Recursive Feature Elimination <br>\nUsing Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFE\n\nrfe = RFE(estimator = RandomForestClassifier(n_estimators=300, class_weight={0:1,1:2}), n_features_to_select=18, verbose=1).fit(vt_transform, Y.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vt_transform_rfe = rfe.transform(vt_transform)\nvt_transform_rfe.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Predictive models"},{"metadata":{},"cell_type":"markdown","source":"This data is **Highly imbalanced class** because not so many companies are bankrupted. <br>\nThus, we need to concern very much about **Recall** score because we don't want to misclassified the bankrupted.<br>\n\n\"This company is bankrupted, but we predicted that this company is safe\" -> We don't want this to happen."},{"metadata":{"trusted":true},"cell_type":"code","source":"Y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.1) Build the models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\nimport xgboost  \n\nX_train, X_test,y_train, y_test = train_test_split(vt_transform_rfe, Y.values, test_size=0.25, stratify=Y.values)\nscaler = StandardScaler().fit(X_train)\n\nmodels = dict()\n\nmodels['Random Forest'] = RandomForestClassifier(n_estimators=300, class_weight={0:1,1:3})\nmodels['Logreg'] = LogisticRegression(penalty='elasticnet',  class_weight={0:1,1:3}, solver='saga', l1_ratio=0.7)\nmodels['GradientBoost'] = GradientBoostingClassifier(n_estimators=300)\nmodels['AdaBoost'] = AdaBoostClassifier(n_estimators=300)\nmodels['XGBoost'] = xgboost.XGBClassifier()\n\nfor model in models:\n    if model == 'Logreg':\n        train = scaler.transform(train)\n    else:\n        train = X_train\n    models[model].fit(train, y_train)\n    print(model + ' : fit')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.2) Performance in train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor x in models:\n\n    if x == 'Logreg':\n        train = scaler.transform(X_train)\n    else:\n        train = X_train\n        \n    print('------------------------'+x+'------------------------')\n    model = models[x]\n    y_train_pred = model.predict(train)\n    arg_train = {'y_true':y_train, 'y_pred':y_train_pred}\n    print(confusion_matrix(**arg_train))\n    print(classification_report(**arg_train))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that XGBoost has done a very good job!!"},{"metadata":{},"cell_type":"markdown","source":"# 2.3) Performance in test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in models:\n    \n    if x == 'Logreg':\n        test = scaler.transform(X_test)\n    else:\n        test=X_test\n    print('------------------------'+x+'------------------------')\n    model = models[x]\n    y_test_pred = model.predict(test)\n    arg_test = {'y_true':y_test, 'y_pred':y_test_pred}\n    print(confusion_matrix(**arg_test))\n    print(classification_report(**arg_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost have the greatest Recall !!"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"'''\nPrecision = เราอยากทาย 1 ให้ถูก/ ให้โมเดลทาย 1 แม่นๆ <br>\nRecall = เราไม่อยากทาย 1 ผิด\n\nบริษัทนี้จะล้มละลาย(1) แต่เราทายผิดว่ามันไม่ล้ม(0) = ทาย 1 ผิด = ไม่อยากให้เกิดสิ่งนี้ขึ้น = ต้องการ recall สูงๆ \n\nโมเดลนี้มี recall ต่ำมาก = เป็นโมเดลที่ไม่ดี\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.4) Take care of XGB"},{"metadata":{},"cell_type":"markdown","source":"### Lower the probability threshold to improve Recall score"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set\nmodel = models['XGBoost']\ny_test_pred_prob = model.predict_proba(X_test)\n\ny_test_pred_prob_lowerThres = y_test_pred_prob[:,1] > 0.1\n\narg_test = {'y_true':y_test, 'y_pred':y_test_pred_prob_lowerThres}\nprint(\"TEST\\n\")\nprint(confusion_matrix(**arg_test))\nprint(classification_report(**arg_test))\n\n\n# Train set\ny_train_pred_prob = model.predict_proba(X_train)\n\ny_train_pred_prob_lowerThres = y_train_pred_prob[:,1] > 0.1\n\narg_train = {'y_true':y_train, 'y_pred':y_train_pred_prob_lowerThres}\nprint(\"TRAIN\\n\")\nprint(confusion_matrix(**arg_train))\nprint(classification_report(**arg_train))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"rfe.ranking_ \n#array([1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1])\n#--> 1 คืดไม่โดนตัดออกไป, 4 คือโดนตัดออกไปคนแรก, 3 คือโดนตัดคนถัดไป\n\n#array([False, False, False, False, False, False,  True, False, False, False, False, False, False, False, False, False,  True, False, False, False, False])\n#array([10, 17, 14, 15, 11,  9,  1, 16, 19,  2, 13, 20, 18,  4,  7, 12,  1,  3,  5,  6,  8])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross validation score on Recall score"},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.metrics import make_scorer, recall_score\n\nrecall_scorer = make_scorer(recall_score)\ncv_score = cross_val_score(models['XGBoost'], X_train, y_train, cv=5, scoring=recall_scorer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('cv_score :', cv_score)\nprint('mean :',cv_score.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.5) ROC curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\nfig, ax = plt.subplots()\nfig.set_size_inches(13,6)\n\nfor m in models:\n    y_pred = models[m].predict_proba(X_test)\n    fpr, tpr, _ = roc_curve(y_test, y_pred[:,1].ravel())\n    plt.plot(fpr,tpr, label=m)\nplt.xlabel('False-Positive rate')\nplt.ylabel('True-Positive rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.6) Randomized search "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nparams = {'eta':[0.2,0.3,0.4],\n         'max_depth':[5,6,7],\n         'sampling_method':['uniform','gradient_based'],\n         'lambda':[1,1.5],\n         'alpha':[0,0.5],\n         }\n\nsearch = RandomizedSearchCV(estimator = models['XGBoost'], n_iter=50, scoring = recall_scorer, cv=5, verbose=1, param_distributions=params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best cv score :\",search.best_score_)\nprint(\"Best params :\",search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that cv_score is improved."},{"metadata":{"trusted":true},"cell_type":"code","source":"models['XGB_searched'] = search.best_estimator_\n\nmodel = models['XGB_searched']\ntest=X_test\nprint('TEST')\nprint('------------------------'+x+'------------------------')\ny_test_pred = model.predict_proba(test)[:,1] > 0.1\narg_test = {'y_true':y_test, 'y_pred':y_test_pred}\nprint(confusion_matrix(**arg_test))\nprint(classification_report(**arg_test))\n\n\ntrain = X_train\nprint(\"TRAIN\")\nprint('------------------------'+x+'------------------------')\ny_train_pred = model.predict_proba(train)[:,1] > 0.1\narg_train = {'y_true':y_train, 'y_pred':y_train_pred}\nprint(confusion_matrix(**arg_train))\nprint(classification_report(**arg_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall is also improved."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}