{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n## imported library for visualizations\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_data = pd.read_csv('/kaggle/input/california-housing-prices/housing.csv')\n## load data and check head of the data\ncf_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check shape of the data\n\ncf_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check info of the dataset\n\ncf_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_data.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check the missing values percentage\n\nround(100*(cf_data.isnull().sum()/cf_data.shape[0]),3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Only total bedrooms has missig values."},{"metadata":{"trusted":true},"cell_type":"code","source":"## check my only one categorical variable\n\ncf_data['ocean_proximity'].value_counts(normalize=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## visualize ocean proximity\n\nplt.figure(figsize=(12,6))\nsns.countplot(x='ocean_proximity',data=cf_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## create one copy for visualization\n\ncf_data_copy = cf_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## convert categorical variable into numerical variables using dummy encoding\n\nstat = pd.get_dummies(cf_data['ocean_proximity'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## concat stat and dro original categorical variable\n\ncf_data = pd.concat([cf_data,stat],axis=True)\ncf_data.drop('ocean_proximity',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We will use the iterative imputer to impute missing values . We will use linear regression model to predict the missing value using other columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn \nfrom sklearn.experimental import enable_iterative_imputer \nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\n\niterimp = IterativeImputer(estimator=LinearRegression(),random_state=100)\ncf_data_clean = pd.DataFrame(iterimp.fit_transform(cf_data))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_data_clean.columns = cf_data.columns.tolist() ## rename our new data frame ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = 0\nfor i in cf_data_clean.columns.tolist():\n    total = total + cf_data_clean[i].isnull().sum()\nprint(\"Total Number Of Null Values : \",total)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Let's now check our column whose null value is imputed. First we will check mean of that column before imputation and after imputation statistically."},{"metadata":{"trusted":true},"cell_type":"code","source":"## check before imputation stats\n\ncf_data['total_bedrooms'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check after imputation stats\n\ncf_data_clean['total_bedrooms'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There is a very minor difference between before mean and after mean of total bedrooms variable."},{"metadata":{},"cell_type":"markdown","source":"* To check more clearly we will do a hypothesis test on it \n\nNull Hypothesis : mean before imputation = mean after imputation\nAlternative Hypothesis : mean before imputation != mean after imputation\n\nwe will use scipy to do it"},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy \nfrom scipy.stats import ttest_ind\nttest_ind(cf_data['total_bedrooms'],cf_data_clean['total_bedrooms'],nan_policy='omit')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* From the p value we fail to reject the null hypothesis."},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_var = ['housing_median_age','total_rooms','total_bedrooms','population','households','median_income','median_house_value']\n\nplt.figure(figsize=(30,15))\n\nfor i in enumerate(plots_var):\n    plt.subplot(2,4,i[0]+1)\n    ax = sns.distplot(cf_data_clean[i[1]])\n    ax.set_xlabel(i[1],fontsize=15)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## visualize house value with respect to occen proximity\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x='ocean_proximity',y='median_house_value',data=cf_data_copy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Those houses which are in island areas are all costly compared to other houses\n* Some houses are very costly which are inland areas also."},{"metadata":{"trusted":true},"cell_type":"code","source":"## visualize household with respect to occen proximity\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x='ocean_proximity',y='median_house_value',data=cf_data_copy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## visualize house value with respect to occen proximity\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x='ocean_proximity',y='households',data=cf_data_copy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Maximum house holds stays at less than 1h ocean than inland area then near ocean and after that near bay and at last island areas."},{"metadata":{"trusted":true},"cell_type":"code","source":"## visualize population value with respect to occen proximity\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x='ocean_proximity',y='population',data=cf_data_copy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Maximum population stays at less than 1h ocean than inland area then near ocean and after that near bay and at last island areas."},{"metadata":{"trusted":true},"cell_type":"code","source":"## visualize housing median age value with respect to occen proximity\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x='ocean_proximity',y='housing_median_age',data=cf_data_copy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Near bay and island houses are older than other area houses."},{"metadata":{},"cell_type":"markdown","source":"* create one boundary box to define our range of geo spatial data"},{"metadata":{"trusted":true},"cell_type":"code","source":"BBox = ((cf_data_clean.longitude.min(),   cf_data_clean.longitude.max(),      \n         cf_data_clean.latitude.min(), cf_data_clean.latitude.max()))\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Save the image as mymap."},{"metadata":{"trusted":true},"cell_type":"code","source":"mymap = plt.imread('../input/california-map/map.png') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Import the map from  opestreetmap.org website and export the desired map as an image by first entering the bounding box data.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (30,15))\nax=sns.scatterplot(x='longitude', y='latitude',data = cf_data_copy ,hue='ocean_proximity' ,alpha = 0.5)\nax.set_title('Plotting Spatial Data on California Map')\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(mymap, zorder=0, extent = BBox, aspect= 'equal')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Clusters are clearly visible on the above data."},{"metadata":{"trusted":true},"cell_type":"code","source":"## check the pairplots\n\nsns.pairplot(cf_data_copy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Total Bedrooms and Household , Total Rooms and Total bedrooms are having a linear relationhip."},{"metadata":{},"cell_type":"markdown","source":"# Data Preproccessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"## first make train test split \n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\ntrain,test = train_test_split(cf_data_clean,train_size=0.7,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## use power transform to make data outlier robust and less skewed\n\nfrom sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer()\n\ntrain = pd.DataFrame(pt.fit_transform(train))\ntest = pd.DataFrame(pt.transform(test))\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## use scaler transform for linear regression\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\ntrain = pd.DataFrame(sc.fit_transform(train))\ntest = pd.DataFrame(sc.transform(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## renaming train and test\n\ntrain.columns = cf_data_clean.columns.tolist()\ntest.columns = cf_data_clean.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train.pop('median_house_value') ## train split\nX_train = train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = test.pop('median_house_value') ## test split\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Build (Linear Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"## use linear regression model to predict\n\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression().fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## let's predict the test data and check r2 score \n\nfrom sklearn.metrics import r2_score\n\nscore1 = r2_score(y_test,lr.predict(X_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## score of our first model\n\nscore1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Build(Linear Regression using Stats model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"## use of stats models to check the multi colinearity \n\nimport statsmodels.api as sm\n\nlr2 = sm.OLS(y_train,sm.add_constant(X_train)).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['features'] = X_train.columns\nvif['vif'] = [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\nvif['vif'] = round(vif['vif'],2)\nvif = vif.sort_values(by='vif',ascending=False)\n#vif.drop(vif.index[0],inplace=True)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## hence remove total_bedrooms\n\nX_train_sm = X_train.copy()\nX_train_sm.drop('total_bedrooms',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr3 = sm.OLS(y_train,sm.add_constant(X_train_sm)).fit()\nprint(lr3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['features'] = X_train_sm.columns\nvif['vif'] = [variance_inflation_factor(X_train_sm.values,i) for i in range(X_train_sm.shape[1])]\nvif['vif'] = round(vif['vif'],2)\nvif = vif.sort_values(by='vif',ascending=False)\n#vif.drop(vif.index[0],inplace=True)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## hence remove latitude\n\nX_train_sm.drop('latitude',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr4 = sm.OLS(y_train,sm.add_constant(X_train_sm)).fit()\nprint(lr4.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['features'] = X_train_sm.columns\nvif['vif'] = [variance_inflation_factor(X_train_sm.values,i) for i in range(X_train_sm.shape[1])]\nvif['vif'] = round(vif['vif'],2)\nvif = vif.sort_values(by='vif',ascending=False)\n#vif.drop(vif.index[0],inplace=True)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## remove near occean\n\nX_train_sm.drop('NEAR OCEAN',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr5 = sm.OLS(y_train,sm.add_constant(X_train_sm)).fit()\nprint(lr5.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['features'] = X_train_sm.columns\nvif['vif'] = [variance_inflation_factor(X_train_sm.values,i) for i in range(X_train_sm.shape[1])]\nvif['vif'] = round(vif['vif'],2)\nvif = vif.sort_values(by='vif',ascending=False)\n#vif.drop(vif.index[0],inplace=True)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## remove households \nX_train_sm.drop('households',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr6 = sm.OLS(y_train,sm.add_constant(X_train_sm)).fit()\nprint(lr6.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['features'] = X_train_sm.columns\nvif['vif'] = [variance_inflation_factor(X_train_sm.values,i) for i in range(X_train_sm.shape[1])]\nvif['vif'] = round(vif['vif'],2)\nvif = vif.sort_values(by='vif',ascending=False)\n#vif.drop(vif.index[0],inplace=True)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## r2 score of new created model\nscore2 = r2_score(y_test,lr6.predict(sm.add_constant(X_test[X_train_sm.columns.tolist()])))\nscore2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This linear model is slightly better than before ."},{"metadata":{},"cell_type":"markdown","source":"* I will add more models one by one to improve prediction. To be continued..."},{"metadata":{},"cell_type":"markdown","source":"# Ridge Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"## implement ridge regression \n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score\n\nridge = Ridge()\nparams = {'alpha' :np.arange(0,100,0.01).reshape(10000,1).tolist()}\nridge_grd = GridSearchCV(estimator = ridge,param_grid = params,scoring = 'neg_mean_absolute_error',return_train_score=True).fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check the cv results\n\ncv_results_ridge = pd.DataFrame(ridge_grd.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check results for different fit\n\ncv_results_ridge.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting mean test and train scoes with alpha \n#cv_results_ridge['param_alpha'] = cv_results_ridge['param_alpha'].astype('int')\n\n# plotting\nplt.figure(figsize=(20,10))\nplt.plot( cv_results_ridge['mean_train_score'])\nplt.plot( cv_results_ridge['mean_test_score'])\nplt.grid()\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check best params \n\nridge_grd.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_grd.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## train my model with best estimator \n\nfinal_ridge = ridge_grd.best_estimator_\nfinal_ridge = final_ridge.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check test score on test data set\n\nscore_ridge = r2_score(y_test,final_ridge.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_ridge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}