{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import random\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42 # \"Answer to the Ultimate Question of Life, the Universe, and Everything\"\n\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nbatch_size = 16","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"diabetes_data = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\n#diabetes_data.fillna(0)\ndiabetes_data.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_data = pd.DataFrame(columns=['Insulin/Age', 'BMI/Age', 'Pregnancies/Age', 'Insulin*Glucose', 'BloodPressure', 'SkinThickness', 'DiabetesPedigreeFunction'])\n\nmodel_data['Insulin/Age']                = diabetes_data['Insulin'] / diabetes_data['Age']\nmodel_data['BMI/Age']                    = diabetes_data['BMI'] / diabetes_data['Age']\nmodel_data['Pregnancies/Age']            = diabetes_data['Pregnancies'] / diabetes_data['Age']\nmodel_data['Insulin*Glucose']            = diabetes_data['Insulin'] * diabetes_data['Glucose']\nmodel_data['BloodPressure']              = diabetes_data['BloodPressure']\nmodel_data['SkinThickness']              = diabetes_data['SkinThickness']\nmodel_data['DiabetesPedigreeFunction']   = diabetes_data['DiabetesPedigreeFunction']\nmodel_data['DiabetesDetected']           = diabetes_data['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_data_size = len(model_data)\nscaler = MinMaxScaler()\nscaler.fit(model_data.iloc[:int(0.7*model_data_size), :-1])\n\ntrain = model_data[:int(0.7*model_data_size)].reset_index(drop=True)\nx_train, y_train = train.iloc[:, :-1], train.iloc[:, -1]\nx_train = scaler.transform(x_train)\n\nvalid = model_data[int(0.7*model_data_size):int(0.7*model_data_size+0.2*model_data_size)].reset_index(drop=True)\nx_valid, y_valid = valid.iloc[:, :-1], valid.iloc[:, -1]\nx_valid = scaler.transform(x_valid)\n\ntest  = model_data[int(0.7*model_data_size+0.2*model_data_size):].reset_index(drop=True)\nx_test, y_test = test.iloc[:, :-1], test.iloc[:, -1]\nx_test = scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_valid[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Full dataset:')\nprint(model_data['DiabetesDetected'].unique())\nprint(model_data['DiabetesDetected'].value_counts())\n\nprint()\nprint('Train set:')\nprint(train['DiabetesDetected'].unique())\nprint(train['DiabetesDetected'].value_counts())\n\nprint()\nprint('Valid set:')\nprint(valid['DiabetesDetected'].unique())\nprint(valid['DiabetesDetected'].value_counts())\n\nprint()\nprint('Test set:')\nprint(test['DiabetesDetected'].unique())\nprint(test['DiabetesDetected'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(model_data['DiabetesDetected'].unique(), model_data['DiabetesDetected'].value_counts())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n    \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        features = np.array(self.x[idx, :].tolist())\n        labels = np.array(self.y[idx].tolist())\n        \n        sample = features, labels\n        return sample\n    \ndef unbalanced_dataset_weights(instances, num_classes):\n    count = [0] * num_classes\n    for item in instances:\n        count[item[1]] += 1\n        \n    class_weight = [0.] * num_classes\n    total = float(sum(count))\n    \n    for i in range(num_classes):\n        class_weight[i] = total/float(count[i])\n    \n    weight = [0] * len(instances)\n    \n    for index, value in enumerate(instances):\n        weight[index] = class_weight[value[1]]\n        \n    return weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = Dataset(x_train, y_train)\nweights = torch.tensor(unbalanced_dataset_weights(train_dataset, 2), dtype=torch.float)\nsampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, sampler=sampler)\n\nvalid_dataset = Dataset(x_valid, y_valid)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n\ntest_dataset = Dataset(x_test, y_test)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item = next(iter(train_dataloader))\nitem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        \n        self.linear1 = nn.Linear(7, 16)\n        self.linear2 = nn.Linear(16, 32)\n        self.linear3 = nn.Linear(32, 64)\n        self.linear4 = nn.Linear(64, 32)\n        self.linear5 = nn.Linear(32, 16)\n        self.linear6 = nn.Linear(16, 1)\n        \n        self.gelu    = nn.GELU()\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        hidden = self.gelu(self.linear1(x))\n        hidden = self.gelu(self.linear2(hidden))\n        hidden = self.gelu(self.linear3(hidden))\n        hidden = self.gelu(self.linear4(hidden))\n        hidden = self.gelu(self.linear5(hidden))\n        \n        out = self.sigmoid(self.linear6(hidden))\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MLP()\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.SGD(model.parameters(), lr=10e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\ncriterion = nn.BCELoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5\ntrain_size = len(train_dataset)\nvalid_size = len(valid_dataset)\n\nfor epoch in range(epochs):    \n    labels = np.array([])\n    preds  = np.array([])\n    \n    train_running_loss = 0.0\n    \n    for index, data in enumerate(train_dataloader):\n        model.train()\n        \n        batch_inputs, batch_labels = data[0][:].to(device).type(torch.float), data[1][:].to(device).type(torch.float)\n        \n        outputs = model(batch_inputs)\n        outputs = outputs.squeeze()\n        \n        loss    = criterion(outputs, batch_labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        for i, output in enumerate(outputs):\n            if output <= 0.5:\n                outputs[i] = 0\n            else:\n                outputs[i] = 1\n                \n        labels = np.concatenate((labels, batch_labels.cpu().numpy()))\n        preds  = np.concatenate((preds, outputs.detach().cpu().numpy()))\n        \n        train_running_loss += loss.mean()\n        \n        if index+1 == int(train_size / batch_size):\n            print(f'Train Epoch: {epoch+1}, step: {index+1}, mean training loss: {train_running_loss / 2000}')\n            train_running_loss = 0.0\n    \n    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n        \n    correct_preds_count = tn + tp\n    total_count         = tn + fp + fn + tp\n        \n    print(f'Train Epoch {epoch+1}:\\n    Accuracy: {correct_preds_count} out of {total_count} ({correct_preds_count/total_count}%)\\n    Precision: {tp / (tp + fp)}\\n    Recall: {tp / (tp + tn)}\\n    Conf. Mat:\\n    [{tp}, {fp}]\\n    [{fn}, {tn}]')\n    print()\n    \n    labels = np.array([])\n    preds  = np.array([])\n    \n    valid_running_loss = 0.0\n    \n    for index, data in enumerate(valid_dataloader):\n        model.eval()\n        batch_inputs, batch_labels = data[0][:].to(device).type(torch.float), data[1][:].to(device).type(torch.float)\n        \n        outputs = model(batch_inputs)\n        outputs = outputs.squeeze()\n        \n        loss    = criterion(outputs, batch_labels)\n        \n        for i, output in enumerate(outputs):\n            if output <= 0.5:\n                outputs[i] = 0\n            else:\n                outputs[i] = 1\n                \n        labels = np.concatenate((labels, batch_labels.cpu().numpy()))\n        preds  = np.concatenate((preds, outputs.detach().cpu().numpy()))\n               \n        valid_running_loss += loss.mean()\n        \n        if index+1 == int(valid_size / batch_size):\n            print(f'Valid Epoch: {epoch+1}, mini_batch: {index+1}, mean validation loss: {valid_running_loss / int(valid_size/batch_size)}')\n            valid_running_loss = 0.0\n            \n    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n    \n    correct_preds_count = tn + tp\n    total_count         = tn + fp + fn + tp\n        \n    print(f'Valid Epoch {epoch+1}:\\n    Accuracy: {correct_preds_count} out of {total_count} ({correct_preds_count/total_count}%)\\n    Precision: {tp / (tp + fp)}\\n    Recall: {tp / (tp + tn)}\\n    Conf. Mat:\\n    [{tp}, {fp}]\\n    [{fn}, {tn}]\\n\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}