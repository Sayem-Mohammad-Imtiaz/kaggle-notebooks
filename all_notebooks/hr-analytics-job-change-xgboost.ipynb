{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Is the candidate looking for a new job? by Martina Raabe\n"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://images.unsplash.com/photo-1455849318743-b2233052fcff?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1950&q=80\" width=\"500\" height=\"400\" align=\"center\"/>\n\n\n[Source](https://unsplash.com/@goian)"},{"metadata":{},"cell_type":"markdown","source":"<h1 style='background: black; border:1; color: white'><center>Introduction</center></h1>\n\n\nThis dataset is designed to understand the factors that lead to a person to leave their current job. This notebook uses XGBoostClassifier to determine whether it is likely for a person to look for a new job. The whole data is divided to train and test. \n\nThe following steps are performed in the notebook:\n\n1.  The training data is cleaned and missing values are handled via imputation and substitution.\n2.  A short EDA is performed with the goal to better understand the data.\n3.  A model (XGBoost) is trained in order to predict whether a candidate is looking for a new job or not.\n\n\nIf you like this notebook, please don't forget to **upvote**. Thanks!"},{"metadata":{},"cell_type":"markdown","source":"<h1 style='background: black; border:1; color: white'><center>Importing, preparing and getting to know the data</center></h1>"},{"metadata":{},"cell_type":"markdown","source":"**Features**\n\nenrollee_id : Unique ID for candidate\n\ncity: City code\n\ncity_ development _index : Developement index of the city (scaled)\n\ngender: Gender of candidate\n\nrelevent_experience: Relevant experience of candidate\n\nenrolled_university: Type of University course enrolled if any\n\neducation_level: Education level of candidate\n\nmajor_discipline :Education major discipline of candidate\n\nexperience: Candidate total experience in years\n\ncompany_size: No of employees in current employer's company\n\ncompany_type : Type of current employer\n\nlastnewjob: Difference in years between previous job and current job\n\ntraining_hours: training hours completed\n\ntarget: 0 – Not looking for job change, 1 – Looking for a job change"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set() # Setting seaborn as default style even if use only matplotlib\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom imblearn.over_sampling import SMOTE \nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve\n\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import test dataset into DataFrame\n\ndata = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"The above output shows that the column 'gender' has the most missing values. All missing values will be handled and imputed or substituted.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill nan-values of 'gender' with last valid value and 'experience' with 0 (since it probably is 0 years)\ndata['gender'] = data['gender'].fillna(method='ffill')\ndata['experience'] = data['experience'].fillna(0)\n\n\n#replacing nan-values with most common values in the column\ncols_nan_replace = ['enrolled_university','education_level', 'major_discipline', 'company_size', 'company_type', 'last_new_job']\nfor col in cols_nan_replace:\n    most_common_value = data[col].mode().iloc[0]\n    data[col] = data[col].fillna(most_common_value)\n\n    \n# replacing values in columns 'experience' and 'last_new_job' and converting them to int64 type\n\ndata['experience'] = data['experience'].replace('>20', '21').replace('<1', 0)\ndata['last_new_job'] = data['last_new_job'].replace('>4', 5).replace('never', 0)\n\n# converting cols to data type int\nconvert_cols = ['experience', 'last_new_job']\ndata[convert_cols] = data[convert_cols].apply(lambda x: x.astype(int)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping unnecessary column 'city'\n\ndata.drop(['city', 'enrollee_id'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating countplots for selected columns\n\nfig, axes = plt.subplots(1,4, figsize=(20, 5))\nn = 0\nfig.suptitle('Countplots of various columns')\n\ncols = ['gender', 'education_level', 'relevent_experience', 'major_discipline']\n\nfor col in cols:\n    sns.countplot(ax=axes[n], data=data, x=col, palette='rocket')\n    axes[n].set_title('Count of {}'.format(col))\n    axes[n].set_xlabel('')\n    axes[n].set_ylabel('')\n    axes[n].tick_params('x',labelrotation=70)\n    n += 1\n    \n  \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot mean of training hours per gender\ntraining_hours = data.groupby('gender')['training_hours'].mean().sort_values(ascending=False)\ntraining_hours = pd.DataFrame(training_hours)\n\nn = training_hours.index\ns = training_hours['training_hours']\n\ntraining_hours.plot(kind='bar', color='green')\nplt.title('Mean of training hours by gender')\nplt.xticks(rotation=70)\nplt.xlabel('')\nplt.legend().remove()\n\n#adding annotations to the bars\n\nfor i in range(len(n)):\n    plt.annotate(str(round(s[i],2)), xy=(n[i],s[i]), ha='center', va='bottom')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graphic shows that the gender 'Other' had the most training hours whereas the men have the least training hours."},{"metadata":{},"cell_type":"markdown","source":"<h1 style='background: black; border:1; color: white'><center>OneHotEncoding of categorical features</center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create X(training data) and y (target variable) by subsetting the data \n\nX,y  = data.iloc [:, :-1], data.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using pd.get_dummies to encode features without ordinal relationship\n# only the relevant columns are encoded with pd.get_dummies\n\n# select categorical columns which will be encoded\ncategorical_cols = X.columns[X.dtypes == 'object'].to_list()\n\n# get_dummies takes the whole dataframe and encodes only the categorical columns\nX_encoded = pd.get_dummies(X, columns = categorical_cols, drop_first=True)\n\nprint('The shape of the Dataframe changed from formerly {}'.format(X.shape[1]), 'to now {}'.format(X_encoded.shape[1]), 'columns.' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_encoded.rename(columns={'company_size_10000+': 'company_size_10000_more', 'company_size_<10':'company_size_10_more'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style='background: black; border:1; color: white'><center>Prediction with XGBoost</center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating countplots for selected columns\n\nfig, axes = plt.subplots(1,4, figsize=(20, 5))\nn = 0\nfig.suptitle('Countplots of various columns')\n\ncols = ['experience', 'last_new_job', 'gender_Male', 'relevent_experience_No relevent experience']\n\nfor col in cols:\n    sns.countplot(ax=axes[n], data=X_encoded, x=col, palette='rocket')\n    axes[n].set_title('Count of {}'.format(col))\n    axes[n].set_xlabel('')\n    axes[n].set_ylabel('')\n    axes[n].tick_params('x',labelrotation=70)\n    n += 1\n    \n  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the data is imbalanced. This will affect the performance of the model. Hence, the data will be balanced in the next step."},{"metadata":{"trusted":true},"cell_type":"code","source":"# As the data is imbalanced we use SMOTE for balancing of the data\n\nsmote = SMOTE(random_state = 402)\nX_smote, y_smote = smote.fit_resample(X_encoded,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating countplots for selected columns to check how smote changed the distribution\n\nfig, axes = plt.subplots(1,4, figsize=(20, 5))\nn = 0\nfig.suptitle('Countplots of various columns')\n\ncols = ['experience', 'last_new_job', 'gender_Male', 'relevent_experience_No relevent experience']\n\nfor col in cols:\n    sns.countplot(ax=axes[n], data=X_smote, x=col, palette='rocket')\n    axes[n].set_title('Count of {}'.format(col))\n    axes[n].set_xlabel('')\n    axes[n].set_ylabel('')\n    axes[n].tick_params('x',labelrotation=70)\n    n += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into train and test set\n\nX_train, X_test, y_train, y_test = train_test_split(X_smote,y_smote, test_size=0.3, random_state=42)\n\n\n# Normalizing the dataset with StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate XGBoost Classifier\n# Define params for RandomizedSearchCV\n# Instantiate RandomizedSearchCV object with params\n\nclf = xgb.XGBClassifier(objective='binary:logistic', seed=42)\n\nparams = {'max_depth': np.arange(2, 10),\n          'n_estimators': [5, 10, 15, 20, 25],\n          'colsample_bytree': [0.3, 0.7],\n          'subsample': [0.4, 0.6, 0.8, 1.0]\n         }\n\nrandomized_cv = RandomizedSearchCV(estimator=clf,param_distributions=params, scoring='roc_auc', n_iter=5, cv=5, verbose=1, n_jobs=1, \n                                   return_train_score=True)\n\n# Fit the data\nrandomized_cv.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best parameters found: \", randomized_cv.best_params_)\n\nprint(\"Best score found: \", randomized_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiating a classifier with the obtained params\n\nclf = xgb.XGBClassifier(colsample_bytree= 0.3,\n                       n_estimators= 25,\n                       max_depth= 9,\n                       subsample= 0.4)\n\nmodel_fit = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the probability and set threshold at 0.5\n\ny_proba = clf.predict_proba(X_train)[:,1]\ny_pred = (y_proba > 0.5).astype(bool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC curve chart\n\nfallout, sensitivity, thresholds = roc_curve(y_train, y_proba)\nplt.plot(fallout, sensitivity, color = 'darkorange')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.title ('Area under the curve')\nplt.show()\n\n# Printing AUC score\nprint ('The AUC score is {}'.format (round(metrics.roc_auc_score(y_train,y_pred),3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the feature importance\nfeature_importance_dict = {}\nfeature_importance = clf.get_booster().get_score(importance_type = 'weight')\n\n\nfor feat, importance in zip(X_encoded.columns, feature_importance.values()):\n    feature_importance_dict[feat] = importance\n\n# Print the 5 most important features\nprint (sorted(feature_importance_dict.items(), key=lambda x:x[1])[-5:])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}