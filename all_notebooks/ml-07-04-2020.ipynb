{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning & Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"petrol_data = pd.read_csv(\"/kaggle/input/petrol-consumption/petrol_consumption.csv\")\npetrol_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_reg_y = petrol_data['Petrol_Consumption']\ndata_reg_X = petrol_data.drop(['Petrol_Consumption'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bill_data = pd.read_csv(\"/kaggle/input/bill_authentication/bill_authentication.csv\")\nbill_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_class_y = bill_data['Class']\ndata_class_X = bill_data.drop(['Class'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sklearn Implementation of Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_class_X, test_class_X, train_class_y, test_class_y = train_test_split(data_class_X, data_class_y, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_class = RandomForestClassifier()\nrandom_class.fit(train_class_X, train_class_y)\nrandom_class.score(test_class_X, test_class_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sklearn implentation of Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reg_X, test_reg_X, train_reg_y, test_reg_y = train_test_split(data_reg_X, data_reg_y, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_reg = RandomForestRegressor()\nrandom_reg.fit(train_reg_X, train_reg_y)\nrandom_reg.score(test_reg_X, test_reg_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scratch Implementation of Random Forrest Classifier"},{"metadata":{},"cell_type":"markdown","source":"## Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_potential_splits(data,random_subspace):\n    \n    potential_splits = {}\n    column_indices = list(range(data.shape[1]-1))\n    \n    \n    if random_subspace and random_subspace < data.shape[1]:\n        column_indices = random.sample(population = column_indices,k = random_subspace)\n    \n    for column_index in  column_indices :\n            \n            values =data[:,column_index] \n            \n            if FEATURE_TYPES[column_index] == 'Continious':\n                \n                unique_values = np.unique(values)\n                potential_splits[column_index] = []\n                \n                for i in range(len(unique_values)-1):\n                    current_value = unique_values[i]\n                    next_value = unique_values[i+1]\n                    potential_split = (current_value+next_value)/2\n                \n                    potential_splits[column_index].append(potential_split)\n            \n            else:\n                potential_splits[column_index]=list(set(values))\n             \n            \n    return potential_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def determine_type_of_feature(data):\n    \n    feature_types = []\n    threshold = 15\n    \n    for column_index in range(data.shape[1]-1):\n        \n        unique_values = np.unique(data[:,column_index])\n            \n        if(len(unique_values)<=threshold)or isinstance(unique_values[0],str):\n            feature_types.append('Categorical')\n        else:\n            feature_types.append('Continious')\n            \n    return feature_types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_data(data,split_column,split_value):\n    \n    values = data[:,split_column]\n    type_of_feature = FEATURE_TYPES[split_column] \n    \n    if type_of_feature == 'Continious':\n        data_above = data[values > split_value]\n        data_below = data[values <= split_value]\n    else:\n        data_below = data[values == split_value]\n        data_above = data[values != split_value]\n        \n    return data_below,data_above","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metric Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def gini(data):\n    \n    label_column= data[:,-1]\n    _,counts = np.unique(label_column,return_counts=True)\n    \n    p=counts/counts.sum()\n    gini =1- np.dot(p,p)\n    \n    return gini","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def entropy(data):\n    \n    label_columns = data[:,-1]\n    _,counts = np.unique(label_columns,return_counts= True)\n    \n    p = counts/counts.sum()\n    entropy = sum(p*-np.log2(p))\n    \n    \n    return entropy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def overall_metric(data_below,data_above,metric_function):\n    \n    n=len(data_above)+len(data_below)\n    p_data_below = len(data_below)/n\n    p_data_above = len(data_above)/n\n    \n    overall_metric = p_data_above*metric_function(data_above) + p_data_below*metric_function(data_below)\n    \n    return overall_metric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_best_split(data, potential_splits, metric_function = gini):\n    \n    first_iteration = True\n    for column_index in potential_splits:\n        for value in potential_splits[column_index]:\n            \n            data_below,data_above = split_data(data,split_column=column_index,split_value = value)\n            current_metric = overall_metric(data_above,data_below,metric_function)\n            \n            if first_iteration:\n                \n                best_metric = current_metric\n                first_iteration = False\n            \n            if current_metric <= best_metric :\n                \n                best_metric = current_metric\n                best_column =column_index\n                best_value = value\n                \n                \n    return best_column,best_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def  check_purity(data):\n    label_columns = data[:,-1]\n    \n    if len(np.unique(label_columns))==1:\n        return True\n    else:\n        return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_leaf(data):\n    \n    label_columns = data[:,-1]\n    unique_labels,counts = np.unique(label_columns,return_counts =True)\n    \n    index = counts.argmax()\n    leaf = unique_labels[index]\n    \n    return leaf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bootstrap(data,n_bootstrap):\n    \n    indices =np.random.randint(low=0,high=len(data),size=n_bootstrap)\n    \n    return data[indices]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"def decision_tree_algorithm(data,counter =0, max_depth =5,min_samples = 10,random_subspace=None,metric_function = gini):\n    \n    if counter == 0:\n    \n        global FEATURE_TYPES\n        FEATURE_TYPES = determine_type_of_feature(data)\n    \n    \n    if (check_purity(data)) or (counter == max_depth) or (len(data) < min_samples):\n        return create_leaf(data)\n    \n    else:\n        \n        counter += 1\n        \n        potential_splits = get_potential_splits(data, random_subspace)\n        column_index,split_value = get_best_split(data, potential_splits, metric_function)\n        data_below,data_above = split_data(data, column_index, split_value)\n         \n        if len(data_below)==0 or len(data_above)==0 :\n            return create_leaf(data)\n        \n        \n        type_of_feature = FEATURE_TYPES[column_index]\n        #column_name = COLUMN_NAMES[column_index]\n        \n        if type_of_feature == 'Continious':\n            question = \"{} <= {}\".format(column_index,split_value)\n        else:\n            question =\"{} = {}\".format(column_index,split_value)\n        sub_tree={question:[]}\n        \n        yes_answer = decision_tree_algorithm(data_below, counter, max_depth, min_samples,random_subspace  ,metric_function )\n        no_answer = decision_tree_algorithm(data_above, counter, max_depth, min_samples,random_subspace  ,metric_function )\n        \n        if yes_answer == no_answer:\n            sub_tree =yes_answer\n        else:\n            sub_tree[question].append(yes_answer)\n            sub_tree[question].append(no_answer)\n       \n        return sub_tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"def decision_tree_classifer(example,tree):\n    question = list(tree.keys())[0]\n    column_index,comparison_operator,value =question.split()\n    column_index =int(column_index)\n    \n    if comparison_operator == \"<=\":\n        if example[column_index] <= float(value):\n            answer = tree[question][0]\n        else:\n            answer = tree[question][1]\n    \n    \n    else:\n        if str(example[column_index]) == value:\n            answer = tree[question][0]\n        else:\n            answer = tree[question][1]\n\n    if not isinstance(answer,dict):\n        return answer\n    \n    else:\n        residual_tree = answer\n        return decision_tree_classifer(example, residual_tree)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_forest_algorithm(train_data, n_trees,max_depth = 5,min_samples =10,random_state = 123, n_features = 3, n_bootstrap=50,metric_function =gini):\n    \n    np.random.seed(random_state)\n    forest = []\n    for i in range(n_trees):\n        \n        bootstrapped_data = bootstrap(train_data,n_bootstrap)\n        tree = decision_tree_algorithm(data = bootstrapped_data, counter=0, random_subspace = n_features, max_depth = max_depth,metric_function=metric_function)\n        forest.append(tree)\n        \n    return forest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_tree_classifier(example,forest):\n    \n    results =[]\n    for index in range(len(forest)):\n        \n        result = decision_tree_classifer(example, forest[index] )\n        results.append(result)\n        \n    mode = max(set(results),key=results.count)\n    return mode","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify_data(test_df,forest):\n    \n    Predictions = test_df.apply(func = random_tree_classifier, axis = 1, raw=True,args=(forest,))\n    \n    return Predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_accuracy(labels,predictions):\n        \n \n    accuracy = np.array(labels == predictions).mean()\n    \n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementing our scratch Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.concat([train_class_X, train_class_y], axis=1)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.concat([test_class_X, test_class_y], axis=1)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest=random_forest_algorithm(train_df.values,n_trees = 5,n_features=2,n_bootstrap=100,random_state =120)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = classify_data(test_df.iloc[:,:-1],forest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = test_df.iloc[:,-1]\n\nprint(\"Accuracy is : {}\".format(calculate_accuracy(predictions,labels)*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}