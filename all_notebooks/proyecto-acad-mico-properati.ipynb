{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyecto : Análisis de mercado inmobiliario. Modelos Avanzados","metadata":{}},{"cell_type":"markdown","source":"Creado por Vanesa Flores.","metadata":{}},{"cell_type":"markdown","source":"## Objetivo\n\nCrear un modelo Machine Learning que, dadas ciertas características de una propiedad, prediga su precio de venta.\n","metadata":{}},{"cell_type":"markdown","source":"### Librerías útiles","metadata":{}},{"cell_type":"code","source":"#Importo algunas Librerías\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\n\n#Preprocesamiento\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\n\n#Machine Learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.metrics import silhouette_samples, silhouette_score","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:01.74123Z","iopub.execute_input":"2021-06-17T14:19:01.741705Z","iopub.status.idle":"2021-06-17T14:19:01.753526Z","shell.execute_reply.started":"2021-06-17T14:19:01.74167Z","shell.execute_reply":"2021-06-17T14:19:01.751796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ingeniería de Features","metadata":{}},{"cell_type":"markdown","source":"Cargamos los datos usando la librería `Pandas` y observamos sus características:","metadata":{}},{"cell_type":"code","source":"df= pd.read_csv('../input/ds-proyecto-01-datos-properati/DS_Proyecto_01_Datos_Properati.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:01.755381Z","iopub.execute_input":"2021-06-17T14:19:01.755694Z","iopub.status.idle":"2021-06-17T14:19:07.146794Z","shell.execute_reply.started":"2021-06-17T14:19:01.755665Z","shell.execute_reply":"2021-06-17T14:19:07.145718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.148229Z","iopub.execute_input":"2021-06-17T14:19:07.148676Z","iopub.status.idle":"2021-06-17T14:19:07.154385Z","shell.execute_reply.started":"2021-06-17T14:19:07.148643Z","shell.execute_reply":"2021-06-17T14:19:07.153602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.155726Z","iopub.execute_input":"2021-06-17T14:19:07.156122Z","iopub.status.idle":"2021-06-17T14:19:07.177496Z","shell.execute_reply.started":"2021-06-17T14:19:07.156093Z","shell.execute_reply":"2021-06-17T14:19:07.176766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consideraremos descartar algunas columnas que no aportan información relevante relacionada al objetivo del proyecto y renombramos otras para un mejor entendimiento: ","metadata":{}},{"cell_type":"code","source":"df=df.drop(columns=['lat', 'lon', 'start_date', 'end_date', 'created_on','title', 'description', 'currency','operation_type','l1'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.178639Z","iopub.execute_input":"2021-06-17T14:19:07.179122Z","iopub.status.idle":"2021-06-17T14:19:07.221228Z","shell.execute_reply.started":"2021-06-17T14:19:07.179091Z","shell.execute_reply":"2021-06-17T14:19:07.220114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= df.rename(columns={'l2':'provincia','l3':'barrio'})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.222289Z","iopub.execute_input":"2021-06-17T14:19:07.222599Z","iopub.status.idle":"2021-06-17T14:19:07.251643Z","shell.execute_reply.started":"2021-06-17T14:19:07.22257Z","shell.execute_reply":"2021-06-17T14:19:07.250459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Basándonos en lo estudiado en el primer proyecto, se considera tomar los tipos de propiedad que presentan mayor cantidad de anuncios en nuestro dataset: Departamento, Casa y PH, que representa un 97.6% del total de instancias. También nos quedamos con los anuncios en la provincia: Capital Federal la cual contiene el 63.1% de nuestras observaciones. ","metadata":{}},{"cell_type":"code","source":"df= df[(df.property_type.isin(['Departamento', 'Casa','PH']) & (df.provincia== 'Capital Federal'))]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.253169Z","iopub.execute_input":"2021-06-17T14:19:07.253614Z","iopub.status.idle":"2021-06-17T14:19:07.317181Z","shell.execute_reply.started":"2021-06-17T14:19:07.253569Z","shell.execute_reply":"2021-06-17T14:19:07.316337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.319547Z","iopub.execute_input":"2021-06-17T14:19:07.319953Z","iopub.status.idle":"2021-06-17T14:19:07.325206Z","shell.execute_reply.started":"2021-06-17T14:19:07.319924Z","shell.execute_reply":"2021-06-17T14:19:07.324426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ésto nos deja con un muestra que conserva el 62.37% de nuestro dataset original. Observemos inicialmente cómo se correlacionan estas variables:","metadata":{}},{"cell_type":"code","source":"#Correlación inicial\ncorr_0=df.corr()\n\nplt.figure(figsize=(8,8))\nax=sns.heatmap(corr_0, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           cmap= 'coolwarm')\nplt.xticks(rotation = 45)\nplt.yticks(rotation = 45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.327023Z","iopub.execute_input":"2021-06-17T14:19:07.327522Z","iopub.status.idle":"2021-06-17T14:19:07.831621Z","shell.execute_reply.started":"2021-06-17T14:19:07.327486Z","shell.execute_reply":"2021-06-17T14:19:07.830709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se tiene que no existe correlaciones elevadas entre las variables independientes y la variable objetivo `Price`. Sin embargo, la mayor correlación la presentan las variables `rooms`, `bedrooms` y `bathrooms`.","metadata":{}},{"cell_type":"markdown","source":"# Imputación de datos faltantes","metadata":{}},{"cell_type":"markdown","source":"En lo que sigue vamos a observar de forma detallada la presencia de datos faltantes en nuestro dataset.","metadata":{}},{"cell_type":"code","source":"faltantes=df.isna().sum()\nprint('Valores faltantes por columnas:', faltantes)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.833017Z","iopub.execute_input":"2021-06-17T14:19:07.833352Z","iopub.status.idle":"2021-06-17T14:19:07.867543Z","shell.execute_reply.started":"2021-06-17T14:19:07.83332Z","shell.execute_reply":"2021-06-17T14:19:07.866457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculemos el porcentaje de faltantes en los atributos de Bathrooms, Surface_total y Surface_covered.","metadata":{}},{"cell_type":"code","source":"cant_total=df.barrio.count()\nporcentaje_Na=(faltantes/cant_total)*100\nporcentaje_Na","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:07.868919Z","iopub.execute_input":"2021-06-17T14:19:07.869322Z","iopub.status.idle":"2021-06-17T14:19:08.021824Z","shell.execute_reply.started":"2021-06-17T14:19:07.869266Z","shell.execute_reply":"2021-06-17T14:19:08.02099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tenemos un total de 91485 instancias. Donde las variables `bathrooms`, `surface_total` y `surface_covered` poseen un 2.37%, 9.74% y 10.09% de valores faltantes en nuestro dataset, respectivamente. Considerando que el porcentaje de datos faltantes es bajo se decide eliminar las instancias que los contengan.","metadata":{}},{"cell_type":"markdown","source":"Con ésto estaríamos evitando realizar una imputación de nulos que quizás luego pudiese sesgar de alguna manera nuestros datos. Sabiendo que los métodos de imputación se basan en medidas de tendencia central como la media o la mediana que presentan poca robutez.","metadata":{}},{"cell_type":"markdown","source":"Sin embargo, con intención de evidenciar lo antes mencionado se planteará una imputación de datos faltantes usando la clase `SimpleImputer` de `scikit-learn`. Para luego, al final del proyecto considerar realizar de nuevo la evaluación de los modelos sin eliminar los datos faltantes y poder establecer una comparación. ","metadata":{}},{"cell_type":"code","source":"df_sinNA= df.dropna()\ndf_sinNA.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.023052Z","iopub.execute_input":"2021-06-17T14:19:08.024194Z","iopub.status.idle":"2021-06-17T14:19:08.069813Z","shell.execute_reply.started":"2021-06-17T14:19:08.024143Z","shell.execute_reply":"2021-06-17T14:19:08.068737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sinNA.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.071101Z","iopub.execute_input":"2021-06-17T14:19:08.071582Z","iopub.status.idle":"2021-06-17T14:19:08.104602Z","shell.execute_reply.started":"2021-06-17T14:19:08.071537Z","shell.execute_reply":"2021-06-17T14:19:08.103248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sinNA= df_sinNA.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.106316Z","iopub.execute_input":"2021-06-17T14:19:08.106811Z","iopub.status.idle":"2021-06-17T14:19:08.12198Z","shell.execute_reply.started":"2021-06-17T14:19:08.106765Z","shell.execute_reply":"2021-06-17T14:19:08.120919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Implementación de la clase `SimpleImputer`:","metadata":{}},{"cell_type":"code","source":"#Imputaremos con la media\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.123568Z","iopub.execute_input":"2021-06-17T14:19:08.124168Z","iopub.status.idle":"2021-06-17T14:19:08.13054Z","shell.execute_reply.started":"2021-06-17T14:19:08.124121Z","shell.execute_reply":"2021-06-17T14:19:08.129582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imput= df.drop(columns=[ 'provincia', 'barrio','property_type'])\nimp_mean.fit(df_imput)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.132173Z","iopub.execute_input":"2021-06-17T14:19:08.132728Z","iopub.status.idle":"2021-06-17T14:19:08.171752Z","shell.execute_reply.started":"2021-06-17T14:19:08.132678Z","shell.execute_reply":"2021-06-17T14:19:08.170632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_mean.transform(df_imput)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.173087Z","iopub.execute_input":"2021-06-17T14:19:08.173412Z","iopub.status.idle":"2021-06-17T14:19:08.189904Z","shell.execute_reply.started":"2021-06-17T14:19:08.173381Z","shell.execute_reply":"2021-06-17T14:19:08.189136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_impt= pd.DataFrame(imp_mean.transform(df_imput), columns=['rooms', 'bedrooms', 'bathrooms', 'surface_total', 'surface_covered',\n       'price'])\ndf_impt.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.191154Z","iopub.execute_input":"2021-06-17T14:19:08.191736Z","iopub.status.idle":"2021-06-17T14:19:08.220369Z","shell.execute_reply.started":"2021-06-17T14:19:08.191688Z","shell.execute_reply":"2021-06-17T14:19:08.219188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_impt.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.221667Z","iopub.execute_input":"2021-06-17T14:19:08.221966Z","iopub.status.idle":"2021-06-17T14:19:08.230598Z","shell.execute_reply.started":"2021-06-17T14:19:08.221934Z","shell.execute_reply":"2021-06-17T14:19:08.229607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"De esta forma tenemos dos datasets, ambos sin datos faltantes, uno con nulos eliminados (`df_sinNA`) y otro con nulos imputados (`df_impt`). En lo que sigue, y basándonos en lo antes expuesto continuaremos con el dataset con los faltantes eliminados. ","metadata":{}},{"cell_type":"markdown","source":"# Detección de outliers","metadata":{}},{"cell_type":"markdown","source":"Siguiendo con el preprocesamiento de nuestro dataset, veamos ahora cómo es la distribución de la variables realizando boxplots para cada una de ellas:","metadata":{}},{"cell_type":"code","source":"df_num= df_sinNA.drop(columns=['index','provincia', 'barrio', 'property_type'])\nfig, axs = plt.subplots(6)\nfig.suptitle('Distribución de Variables')\nfor i,el in enumerate(list(df_num.columns.values)[:]):\n    a = df_sinNA.boxplot(el, ax=axs.flatten()[i],vert=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:08.23189Z","iopub.execute_input":"2021-06-17T14:19:08.232172Z","iopub.status.idle":"2021-06-17T14:19:09.700003Z","shell.execute_reply.started":"2021-06-17T14:19:08.232145Z","shell.execute_reply":"2021-06-17T14:19:09.698876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se observa presencia de valores atípicos en todas las variables. Éstos parecen encontrarse con mayor peso en las últimas tres donde ni siquiera es posible distinguir una distribución de forma clara.","metadata":{}},{"cell_type":"markdown","source":"Para detectar la cantidad de outliers presente en cada variable, se utilizará la técnica del rango intercuartílico. ","metadata":{}},{"cell_type":"markdown","source":"### Cálculo de Rango Intercuartílico","metadata":{}},{"cell_type":"code","source":"columnas=['rooms','bedrooms','bathrooms','surface_total','surface_covered', 'price']\nprint('Valores= (q25,q75, IQR, mínimo, máximo)')\nfor i,columna in enumerate([df_sinNA.rooms,df_sinNA.bedrooms,df_sinNA.bathrooms,df_sinNA.surface_total,df_sinNA.surface_covered,df_sinNA.price]):\n    q25,q75 = np.percentile(columna.values, [25,75])\n    iqr = q75 - q25\n    minimo = q25 - 1.5*iqr\n    maximo = q75 + 1.5*iqr\n    mascara_outliers = (columna < minimo) | (columna > maximo)\n    cant_outliers=mascara_outliers.sum()\n    print(f'Valores para {columnas[i]}:',q25,q75,iqr, minimo, maximo)\n    print(f'Cantidad de outliers:',cant_outliers)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:09.701635Z","iopub.execute_input":"2021-06-17T14:19:09.702072Z","iopub.status.idle":"2021-06-17T14:19:09.748218Z","shell.execute_reply.started":"2021-06-17T14:19:09.702027Z","shell.execute_reply":"2021-06-17T14:19:09.746999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que existe presencia de valores atípicos en todas nuestras variables. Sin embargo, sólo los eliminaremos para nuestra la variable objetivo, el precio.","metadata":{}},{"cell_type":"code","source":"df_sin_out=df_sinNA[(df_sinNA.price > 0 ) & (df_sinNA.price < 512500.0)]\n\ndf_sin_out=df_sin_out.reindex(columns=['index','provincia','barrio','rooms','bedrooms','bathrooms', 'surface_total', 'surface_covered', 'price','property_type'])\ndf_sin_out.drop(['index'], axis=1, inplace=True)\ndf_sin_out.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:09.749855Z","iopub.execute_input":"2021-06-17T14:19:09.750539Z","iopub.status.idle":"2021-06-17T14:19:09.79582Z","shell.execute_reply.started":"2021-06-17T14:19:09.750487Z","shell.execute_reply":"2021-06-17T14:19:09.794514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observemos ahora la distribución de la variable precio luego de eliminar valores atípicos","metadata":{}},{"cell_type":"code","source":"sns.distplot(df_sin_out.price)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:09.801931Z","iopub.execute_input":"2021-06-17T14:19:09.80229Z","iopub.status.idle":"2021-06-17T14:19:10.555422Z","shell.execute_reply.started":"2021-06-17T14:19:09.80226Z","shell.execute_reply":"2021-06-17T14:19:10.554254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(df_sin_out.price)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:10.55804Z","iopub.execute_input":"2021-06-17T14:19:10.558358Z","iopub.status.idle":"2021-06-17T14:19:10.694324Z","shell.execute_reply.started":"2021-06-17T14:19:10.558329Z","shell.execute_reply":"2021-06-17T14:19:10.693028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nos encontramos con una distribución que presenta asimetría positiva que pudiese estar relacionada a propiedades que tengan una superficie grande o que se encuentren en algún barrio que por sus características sea más costoso en la Ciudad. Agrupemos por tipo de propiedad y barrio para observarlo:","metadata":{}},{"cell_type":"code","source":"df_sin_out.loc[df_sin_out.price > 400000].groupby(['property_type']).size()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:10.695629Z","iopub.execute_input":"2021-06-17T14:19:10.696058Z","iopub.status.idle":"2021-06-17T14:19:10.712611Z","shell.execute_reply.started":"2021-06-17T14:19:10.696012Z","shell.execute_reply":"2021-06-17T14:19:10.711059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sin_out.loc[df_sin_out.price > 400000].groupby(['barrio']).size()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:10.714622Z","iopub.execute_input":"2021-06-17T14:19:10.715168Z","iopub.status.idle":"2021-06-17T14:19:10.731388Z","shell.execute_reply.started":"2021-06-17T14:19:10.715042Z","shell.execute_reply":"2021-06-17T14:19:10.730167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Los barrios que poseen mayor cantidad de propiedades costosas son los más residenciales y que además, están categorizados como \"caros\" en la Capital Federal.","metadata":{}},{"cell_type":"markdown","source":"# Encoders","metadata":{}},{"cell_type":"markdown","source":"Buscaremos generar variables binarias para los atributos `barrio` y `property_type` con el objetivo de incluirlas en los modelos y encontrar mejor desempeño de los mismos. Para esto haremos la codificación de la variable utilizando la funcionalidad `OneHotEncoder` de `Scikit-Learn`.","metadata":{}},{"cell_type":"code","source":"ohe = OneHotEncoder(sparse=False).fit_transform(df_sin_out[['barrio','property_type']])\ncategoricas = pd.DataFrame(ohe)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:10.732913Z","iopub.execute_input":"2021-06-17T14:19:10.73373Z","iopub.status.idle":"2021-06-17T14:19:10.862001Z","shell.execute_reply.started":"2021-06-17T14:19:10.733683Z","shell.execute_reply":"2021-06-17T14:19:10.860855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categoricas = categoricas.set_index(df_sin_out.index)\ndf_encoding_mean = pd.concat([df_sin_out, categoricas], axis=1)\ndf_encoding_mean.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:10.863348Z","iopub.execute_input":"2021-06-17T14:19:10.863685Z","iopub.status.idle":"2021-06-17T14:19:11.01275Z","shell.execute_reply.started":"2021-06-17T14:19:10.863654Z","shell.execute_reply":"2021-06-17T14:19:11.011527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_encoding_mean.columns=['provincia','barrio','rooms','bedrooms','bathrooms', 'surface_total', 'surface_covered', 'price','property_type',\n                                                   'Abasto', 'Agronomía', 'Almagro', 'Balvanera', 'Barracas', 'Barrio Norte', 'Belgrano', 'Boca', 'Boedo',\n                                                   'Caballito', 'Catalinas', 'Centro / Microcentro', 'Chacarita', 'Coghlan', 'Colegiales', 'Congreso',\n                                                   'Constitución', 'Flores', 'Floresta', 'Las Cañitas', 'Liniers', 'Mataderos', 'Monserrat', 'Monte Castro',\n                                                   'Nuñez', 'Once', 'Palermo', 'Parque Avellaneda', 'Parque Centenario', 'Parque Chacabuco', 'Parque Chas',\n                                                   'Parque Patricios', 'Paternal', 'Pompeya', 'Puerto Madero', 'Recoleta', 'Retiro', 'Saavedra', 'San Cristobal',\n                                                   'San Nicolás', 'San Telmo', 'Tribunales', 'Velez Sarsfield', 'Versalles', 'Villa Crespo', 'Villa Devoto',\n                                                   'Villa General Mitre', 'Villa Lugano', 'Villa Luro', 'Villa Ortuzar', 'Villa Pueyrredón', 'Villa Real',\n                                                   'Villa Riachuelo', 'Villa Santa Rita', 'Villa Soldati', 'Villa Urquiza','Villa del Parque','Casa', \n                                                   'Departamento', 'PH']\ndf_encoding_mean.drop(columns='provincia', inplace=True)\ndf_encoding_mean.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.014033Z","iopub.execute_input":"2021-06-17T14:19:11.014375Z","iopub.status.idle":"2021-06-17T14:19:11.127616Z","shell.execute_reply.started":"2021-06-17T14:19:11.014341Z","shell.execute_reply":"2021-06-17T14:19:11.126521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Escalado de datos","metadata":{}},{"cell_type":"markdown","source":"Sabiendo que algunos algoritmos Machine Learning son sensibles a la escala en las que se miden nuestros atributos, procedemos a realizar un escalado de los mismos utilizando la clase `MinMaxScaler` de `scikit-learn` que nos permite obtener atributos escalados en un rango determinado. Esto con la intención de evitar falsos resultados de nuestros modelos más adelante.","metadata":{}},{"cell_type":"markdown","source":"En este punto, para facilitar volver después a nuestros datos no escalados se realizará el escalado por separado de las variables independientes y las variables dependientes.","metadata":{}},{"cell_type":"code","source":"scaler_independientes= MinMaxScaler(feature_range=(0,1))\nscaler_dependientes=MinMaxScaler(feature_range=(0,1))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.128768Z","iopub.execute_input":"2021-06-17T14:19:11.129044Z","iopub.status.idle":"2021-06-17T14:19:11.135104Z","shell.execute_reply.started":"2021-06-17T14:19:11.129017Z","shell.execute_reply":"2021-06-17T14:19:11.134342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En lo que sigue, selecciono las variables con las que más adelante trabajaré con mis modelos. ","metadata":{}},{"cell_type":"code","source":"#Selecciono variables numéricas\nvariables_independientes=df_encoding_mean[['rooms','bedrooms','bathrooms', 'surface_total', 'surface_covered',\n                                                   'Abasto', 'Agronomía', 'Almagro', 'Balvanera', 'Barracas', 'Barrio Norte', 'Belgrano', 'Boca', 'Boedo',\n                                                   'Caballito', 'Catalinas', 'Centro / Microcentro', 'Chacarita', 'Coghlan', 'Colegiales', 'Congreso',\n                                                   'Constitución', 'Flores', 'Floresta', 'Las Cañitas', 'Liniers', 'Mataderos', 'Monserrat', 'Monte Castro',\n                                                   'Nuñez', 'Once', 'Palermo', 'Parque Avellaneda', 'Parque Centenario', 'Parque Chacabuco', 'Parque Chas',\n                                                   'Parque Patricios', 'Paternal', 'Pompeya', 'Puerto Madero', 'Recoleta', 'Retiro', 'Saavedra', 'San Cristobal',\n                                                   'San Nicolás', 'San Telmo', 'Tribunales', 'Velez Sarsfield', 'Versalles', 'Villa Crespo', 'Villa Devoto',\n                                                   'Villa General Mitre', 'Villa Lugano', 'Villa Luro', 'Villa Ortuzar', 'Villa Pueyrredón', 'Villa Real',\n                                                   'Villa Riachuelo', 'Villa Santa Rita', 'Villa Soldati', 'Villa Urquiza','Villa del Parque','Casa', \n                                                   'Departamento', 'PH']]\nvariables_dependientes=df_encoding_mean[['price']]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.136173Z","iopub.execute_input":"2021-06-17T14:19:11.136538Z","iopub.status.idle":"2021-06-17T14:19:11.167903Z","shell.execute_reply.started":"2021-06-17T14:19:11.136507Z","shell.execute_reply":"2021-06-17T14:19:11.166764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_independientes=scaler_independientes.fit(variables_independientes)\nfit_dependientes=scaler_dependientes.fit(variables_dependientes)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.169355Z","iopub.execute_input":"2021-06-17T14:19:11.169722Z","iopub.status.idle":"2021-06-17T14:19:11.209158Z","shell.execute_reply.started":"2021-06-17T14:19:11.169691Z","shell.execute_reply":"2021-06-17T14:19:11.207964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"escalados_independientes=scaler_independientes.transform(variables_independientes)\nescalados_dependientes=scaler_dependientes.transform(variables_dependientes)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.210723Z","iopub.execute_input":"2021-06-17T14:19:11.211033Z","iopub.status.idle":"2021-06-17T14:19:11.258184Z","shell.execute_reply.started":"2021-06-17T14:19:11.211004Z","shell.execute_reply":"2021-06-17T14:19:11.256874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_escalados_independientes=pd.DataFrame(escalados_independientes, columns=['rooms','bedrooms','bathrooms', 'surface_total', 'surface_covered',\n                                                   'Abasto', 'Agronomía', 'Almagro', 'Balvanera', 'Barracas', 'Barrio Norte', 'Belgrano', 'Boca', 'Boedo',\n                                                   'Caballito', 'Catalinas', 'Centro / Microcentro', 'Chacarita', 'Coghlan', 'Colegiales', 'Congreso',\n                                                   'Constitución', 'Flores', 'Floresta', 'Las Cañitas', 'Liniers', 'Mataderos', 'Monserrat', 'Monte Castro',\n                                                   'Nuñez', 'Once', 'Palermo', 'Parque Avellaneda', 'Parque Centenario', 'Parque Chacabuco', 'Parque Chas',\n                                                   'Parque Patricios', 'Paternal', 'Pompeya', 'Puerto Madero', 'Recoleta', 'Retiro', 'Saavedra', 'San Cristobal',\n                                                   'San Nicolás', 'San Telmo', 'Tribunales', 'Velez Sarsfield', 'Versalles', 'Villa Crespo', 'Villa Devoto',\n                                                   'Villa General Mitre', 'Villa Lugano', 'Villa Luro', 'Villa Ortuzar', 'Villa Pueyrredón', 'Villa Real',\n                                                   'Villa Riachuelo', 'Villa Santa Rita', 'Villa Soldati', 'Villa Urquiza','Villa del Parque','Casa', \n                                                   'Departamento', 'PH'])\ndf_escalados_dependientes=pd.DataFrame(escalados_dependientes, columns=[\"price\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.259952Z","iopub.execute_input":"2021-06-17T14:19:11.260793Z","iopub.status.idle":"2021-06-17T14:19:11.269402Z","shell.execute_reply.started":"2021-06-17T14:19:11.26074Z","shell.execute_reply":"2021-06-17T14:19:11.268367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_escalados_independientes.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.270427Z","iopub.execute_input":"2021-06-17T14:19:11.271019Z","iopub.status.idle":"2021-06-17T14:19:11.325853Z","shell.execute_reply.started":"2021-06-17T14:19:11.270984Z","shell.execute_reply":"2021-06-17T14:19:11.325011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_escalados = pd.concat([df_escalados_independientes,df_escalados_dependientes], axis=1)\ndf_escalados.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.327286Z","iopub.execute_input":"2021-06-17T14:19:11.327909Z","iopub.status.idle":"2021-06-17T14:19:11.394149Z","shell.execute_reply.started":"2021-06-17T14:19:11.327861Z","shell.execute_reply":"2021-06-17T14:19:11.392836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df_escalados.price)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:11.395834Z","iopub.execute_input":"2021-06-17T14:19:11.396181Z","iopub.status.idle":"2021-06-17T14:19:12.133094Z","shell.execute_reply.started":"2021-06-17T14:19:11.396152Z","shell.execute_reply":"2021-06-17T14:19:12.132066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se observa que la distribución de los datos es la misma, y que nuestra variable precio esta contemplada en un rango del 0 al 1. ","metadata":{}},{"cell_type":"markdown","source":"# Relación entre variables ","metadata":{}},{"cell_type":"markdown","source":"Observemos un poco las características de nuestros atributos:","metadata":{}},{"cell_type":"code","source":"df_escalados.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:12.134499Z","iopub.execute_input":"2021-06-17T14:19:12.134811Z","iopub.status.idle":"2021-06-17T14:19:12.544814Z","shell.execute_reply.started":"2021-06-17T14:19:12.134781Z","shell.execute_reply":"2021-06-17T14:19:12.543396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veamos cómo están correlacionadas nuestras variables ","metadata":{}},{"cell_type":"code","source":"#Estudio de correlaciones\nplt.figure(figsize = (8*3,8))\n\ncorr1=df_escalados[['rooms','bedrooms','bathrooms', 'surface_total', 'surface_covered',\n                                                   'Abasto', 'Agronomía', 'Almagro', 'Balvanera', 'Barracas', 'Barrio Norte', 'Belgrano', 'Boca', 'Boedo',\n                                                   'Constitución', 'Flores', 'Floresta', 'Las Cañitas', 'Liniers', 'Mataderos', 'Monserrat', 'Monte Castro',\n                                                   'Nuñez', 'Once', 'Palermo', 'Parque Avellaneda', 'Parque Centenario', 'Parque Chacabuco', 'Parque Chas',\n                                                   'San Nicolás', 'San Telmo', 'Tribunales', 'Velez Sarsfield', 'Versalles', 'Villa Crespo', 'Villa Devoto',\n                                                   'Villa General Mitre', 'Villa Lugano', 'Villa Luro', 'Villa Ortuzar', 'Villa Pueyrredón', 'Villa Real','Casa', \n                                                   'Departamento', 'PH','price']].corr()\nplt.subplot(1, 2, 1)\nax=sns.heatmap(corr1, cbar = True,  square = True, annot=False, fmt= '.2f',annot_kws={'size': 15},\n           cmap= 'coolwarm')\nplt.xticks(rotation = 60)\nplt.yticks(rotation = 15)\n\nplt.subplot(1, 2, 2)\ncorr2=df_escalados[['rooms', 'bedrooms', 'bathrooms','surface_total', 'surface_covered', 'Casa','Departamento','PH','price']].corr()\nax=sns.heatmap(corr2, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           cmap= 'coolwarm')\nplt.xticks(rotation = 45)\nplt.yticks(rotation = 15)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:12.546123Z","iopub.execute_input":"2021-06-17T14:19:12.546469Z","iopub.status.idle":"2021-06-17T14:19:15.291065Z","shell.execute_reply.started":"2021-06-17T14:19:12.546429Z","shell.execute_reply":"2021-06-17T14:19:15.289925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El mapa de calor del lado izquierdo muestra que las variables binarias generadas para los barrios no muestran correlación significativa con la variable target. \n\nSin embargo, para el gráfico del lado derecho se filtran las variables a fin observar con mayor claridad las correlaciones. Se obtiene que comparándo con el Proyecto 1, se observa gran diferencia en las correlaciones respecto a la variable objetivo. Ésta variación pudiese estar relacionada a la eliminación de valores atípicos sobre las variables de superficie. ","metadata":{}},{"cell_type":"markdown","source":"# Reducción de la Dimensionalidad (PCA)","metadata":{}},{"cell_type":"markdown","source":"En lo que sigue, aplicaremos el método de Análisis de Componentes Principales para indagar si a partir de la reducción de atributos y generación de nuevas variables que obtengan la mayor variabilidad, se encontraran mejores resultados en nuestros modelos.","metadata":{}},{"cell_type":"markdown","source":"Lo primero que haremos será separar nuestras variables dependientes de las independientes.","metadata":{}},{"cell_type":"code","source":"X=df_escalados[['rooms','bedrooms','bathrooms', 'surface_total', 'surface_covered',\n                                                   'Abasto', 'Agronomía', 'Almagro', 'Balvanera', 'Barracas', 'Barrio Norte', 'Belgrano', 'Boca', 'Boedo',\n                                                   'Caballito', 'Catalinas', 'Centro / Microcentro', 'Chacarita', 'Coghlan', 'Colegiales', 'Congreso',\n                                                   'Constitución', 'Flores', 'Floresta', 'Las Cañitas', 'Liniers', 'Mataderos', 'Monserrat', 'Monte Castro',\n                                                   'Nuñez', 'Once', 'Palermo', 'Parque Avellaneda', 'Parque Centenario', 'Parque Chacabuco', 'Parque Chas',\n                                                   'Parque Patricios', 'Paternal', 'Pompeya', 'Puerto Madero', 'Recoleta', 'Retiro', 'Saavedra', 'San Cristobal',\n                                                   'San Nicolás', 'San Telmo', 'Tribunales', 'Velez Sarsfield', 'Versalles', 'Villa Crespo', 'Villa Devoto',\n                                                   'Villa General Mitre', 'Villa Lugano', 'Villa Luro', 'Villa Ortuzar', 'Villa Pueyrredón', 'Villa Real',\n                                                   'Villa Riachuelo', 'Villa Santa Rita', 'Villa Soldati', 'Villa Urquiza','Villa del Parque','Casa', \n                                                   'Departamento', 'PH']]\ny=df_escalados[['price']]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:15.292461Z","iopub.execute_input":"2021-06-17T14:19:15.292785Z","iopub.status.idle":"2021-06-17T14:19:15.317757Z","shell.execute_reply.started":"2021-06-17T14:19:15.292753Z","shell.execute_reply":"2021-06-17T14:19:15.316621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Utilizamos la función `PCA` de `scikit-learn` para calcular las componentes principales. Para empezar, consideraremos graficar la variabilidad explicada respecto al número de componentes calculadas y estableciendo un umbral de corte que nos indique cuántas componentes nos explican el 95% de la varianza. ","metadata":{}},{"cell_type":"code","source":"pca = PCA().fit(X)\n\nplt.rcParams[\"figure.figsize\"] = (18,6)\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 66, step=1)\nyi = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, yi, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Número de componentes')\nplt.xticks(np.arange(0, 66, step=1), rotation=90) \nplt.ylabel('Varianza acumulada (%)')\nplt.title('Número de componentes necesarias para explicar la varianza')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, 'Umbral de corte: 95%', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:15.31923Z","iopub.execute_input":"2021-06-17T14:19:15.319568Z","iopub.status.idle":"2021-06-17T14:19:16.811028Z","shell.execute_reply.started":"2021-06-17T14:19:15.319535Z","shell.execute_reply":"2021-06-17T14:19:16.809855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nos quedamos entonces con las primeras 40 componentes principales calculadas.","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=40)\nX_nuevo = pca.fit_transform(X) ","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:16.812688Z","iopub.execute_input":"2021-06-17T14:19:16.813088Z","iopub.status.idle":"2021-06-17T14:19:18.156822Z","shell.execute_reply.started":"2021-06-17T14:19:16.813045Z","shell.execute_reply":"2021-06-17T14:19:18.155702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.components_","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:18.15809Z","iopub.execute_input":"2021-06-17T14:19:18.15841Z","iopub.status.idle":"2021-06-17T14:19:18.166579Z","shell.execute_reply.started":"2021-06-17T14:19:18.158379Z","shell.execute_reply":"2021-06-17T14:19:18.165387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.cumsum(pca.explained_variance_ratio_)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:18.168445Z","iopub.execute_input":"2021-06-17T14:19:18.168891Z","iopub.status.idle":"2021-06-17T14:19:18.182755Z","shell.execute_reply.started":"2021-06-17T14:19:18.168847Z","shell.execute_reply":"2021-06-17T14:19:18.181684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparemos con el Proyecto 1","metadata":{}},{"cell_type":"markdown","source":"Luego del preprocesamiento de datos realizado, consideraremos entrenar tres modelos Machine Learning. Un árbol de decisión, KNN y regresión lineal con los mismos parámetros utilizados en el Proyecto 1 con el fin de comparar resultados. ","metadata":{}},{"cell_type":"markdown","source":"### Modelo 1: Árbol de Decisión con PCA","metadata":{}},{"cell_type":"markdown","source":"Realizamos ahora la división de nuestros datos, considerando un conjunto de datos de entrenamiento y otro de testeo. Es importante resaltar que en este punto nuestros atributos son las dos componentes pricipales calculadas (`X_nuevo`).","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_nuevo, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:18.183974Z","iopub.execute_input":"2021-06-17T14:19:18.184465Z","iopub.status.idle":"2021-06-17T14:19:18.21558Z","shell.execute_reply.started":"2021-06-17T14:19:18.184433Z","shell.execute_reply":"2021-06-17T14:19:18.214319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_regressor = DecisionTreeRegressor(max_depth=8, random_state=42)\ntree_regressor.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:18.216971Z","iopub.execute_input":"2021-06-17T14:19:18.217271Z","iopub.status.idle":"2021-06-17T14:19:19.09162Z","shell.execute_reply.started":"2021-06-17T14:19:18.217243Z","shell.execute_reply":"2021-06-17T14:19:19.090534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Definiremos una función que nos permitirá evaluar cada modelo de manera más fácil y además, nos mostrará los errores obtenidos mediante el cálculo del RMSE con las valores en la escala real y el valor de r2_score que nos indica el desempeño del modelo.","metadata":{}},{"cell_type":"code","source":"def evaluar_modelo(model, scaler, X_train, X_test, y_train, y_test):\n    \n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    ### VOLVEMOS A LAS VARIABLES NO ESCALADAS\n    y_train_pred_desesc = scaler.inverse_transform(y_train_pred.reshape(-1, 1))\n    y_test_pred_desesc = scaler.inverse_transform(y_test_pred.reshape(-1, 1))\n    \n    y_train_desesc = scaler.inverse_transform(y_train)\n    y_test_desesc = scaler.inverse_transform(y_test)\n    \n    ### CALCULAMOS EL ERROR\n    rmse_train = np.sqrt(mean_squared_error(y_train_desesc, y_train_pred_desesc))\n    rmse_test = np.sqrt(mean_squared_error(y_test_desesc, y_test_pred_desesc))\n\n    print(f'Raíz del error cuadrático medio en Train: {rmse_train}')\n    print(f'Raíz del error cuadrático medio en Test: {rmse_test}')\n    r2=r2_score(y_true=y_test_desesc, y_pred=y_test_pred_desesc)\n    print(f'El valor del r2 score : {r2}')\n    \n    plt.figure(figsize = (15,4))\n\n    plt.subplot(1,2,1)\n    sns.distplot(y_train_desesc - y_train_pred_desesc, bins = 20, label = 'train')\n    sns.distplot(y_test_desesc - y_test_pred_desesc, bins = 20, label = 'test')\n    plt.xlabel('errores')\n    plt.legend()\n\n\n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test_desesc,y_test_pred_desesc, s =2)\n   \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n      ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n   \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:19.092801Z","iopub.execute_input":"2021-06-17T14:19:19.093125Z","iopub.status.idle":"2021-06-17T14:19:19.106707Z","shell.execute_reply.started":"2021-06-17T14:19:19.093097Z","shell.execute_reply":"2021-06-17T14:19:19.105126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluar_modelo(tree_regressor, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:19.108976Z","iopub.execute_input":"2021-06-17T14:19:19.109377Z","iopub.status.idle":"2021-06-17T14:19:20.254168Z","shell.execute_reply.started":"2021-06-17T14:19:19.109338Z","shell.execute_reply":"2021-06-17T14:19:20.253092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 2: KNN con PCA","metadata":{}},{"cell_type":"code","source":"knn_regressor = KNeighborsRegressor(n_neighbors=10)\nknn_regressor.fit(X_train, y_train)\nevaluar_modelo(knn_regressor, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:19:20.255447Z","iopub.execute_input":"2021-06-17T14:19:20.255758Z","iopub.status.idle":"2021-06-17T14:20:41.345732Z","shell.execute_reply.started":"2021-06-17T14:19:20.25573Z","shell.execute_reply":"2021-06-17T14:20:41.344576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 3: Regresión Lineal con PCA","metadata":{}},{"cell_type":"code","source":"linear_model = LinearRegression() #Benchmark\nlinear_model.fit(X_train, y_train)\nevaluar_modelo(linear_model, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:41.347025Z","iopub.execute_input":"2021-06-17T14:20:41.347324Z","iopub.status.idle":"2021-06-17T14:20:42.659189Z","shell.execute_reply.started":"2021-06-17T14:20:41.347281Z","shell.execute_reply":"2021-06-17T14:20:42.657678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metricas= [[57286.50, 57958.02,-0.02, 65750.65, 64776.66, 0.56],\n         [46297.29, 47935.92, 0.48, 55369.93,55594.84,0.68],\n         [ 41839.18, 45999.04,0.57,39261.32,42334.09,0.81]]\n\ncolumnas = ['RMSE_Train_P1', 'RMSE_Test_P1', 'R2_score_P1', 'RMSE_Train P2_PCA', 'RMSE_Test_P2_PCA', 'R2_score_P2_PCA'] # definimos los nombres de las columnas\nfilas = ['Regresión lineal', 'Árbol de Decisión', 'KNN'] # definimos los nombres de las filas\n\ncomparacion = pd.DataFrame(metricas, columns=columnas, index=filas)\ncomparacion.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:42.660637Z","iopub.execute_input":"2021-06-17T14:20:42.660963Z","iopub.status.idle":"2021-06-17T14:20:42.683735Z","shell.execute_reply.started":"2021-06-17T14:20:42.660931Z","shell.execute_reply":"2021-06-17T14:20:42.682443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se puede observar que el performance de los tres modelos indicados mejoran su desempeño respecto a los resultados obtenidos en el Proyecto 1, considerando los mismos hiperparámetros. Podemos resaltar que el modelo de vecinos más cercanos arroja el r2_score más alto y además, presenta similitud en la distribuciones de los errores de train y test, por lo que podemos inferir que no existe un sobreajuste significativo del modelo. ","metadata":{}},{"cell_type":"markdown","source":"Veamos ahora, cómo es el desempeño de nuestro modelos sin usar las componentes principales calculadas (PCA) y en cambio, usando sólo las variables predictoras que presentan mayor correlación con la variable objetivo.","metadata":{}},{"cell_type":"code","source":"X=df_escalados[['rooms','bedrooms','bathrooms']]\ny=df_escalados[['price']]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:42.685444Z","iopub.execute_input":"2021-06-17T14:20:42.685864Z","iopub.status.idle":"2021-06-17T14:20:42.700075Z","shell.execute_reply.started":"2021-06-17T14:20:42.68582Z","shell.execute_reply":"2021-06-17T14:20:42.698642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:42.701944Z","iopub.execute_input":"2021-06-17T14:20:42.702463Z","iopub.status.idle":"2021-06-17T14:20:42.72678Z","shell.execute_reply.started":"2021-06-17T14:20:42.702412Z","shell.execute_reply":"2021-06-17T14:20:42.725595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 4: Árbol de Decisión (Variables mayor corr)","metadata":{}},{"cell_type":"code","source":"tree_regressor1 = DecisionTreeRegressor(max_depth=8, random_state=42)\ntree_regressor1.fit(X_train, y_train)\nevaluar_modelo(tree_regressor1, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:42.728579Z","iopub.execute_input":"2021-06-17T14:20:42.729113Z","iopub.status.idle":"2021-06-17T14:20:43.92506Z","shell.execute_reply.started":"2021-06-17T14:20:42.729006Z","shell.execute_reply":"2021-06-17T14:20:43.924109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 5: KNN (Variables mayor corr)","metadata":{}},{"cell_type":"code","source":"knn_regressor1 = KNeighborsRegressor(n_neighbors=10)\nknn_regressor1.fit(X_train, y_train)\nevaluar_modelo(knn_regressor1, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:43.926405Z","iopub.execute_input":"2021-06-17T14:20:43.926714Z","iopub.status.idle":"2021-06-17T14:20:54.553908Z","shell.execute_reply.started":"2021-06-17T14:20:43.926685Z","shell.execute_reply":"2021-06-17T14:20:54.552599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 6: Regresión Lineal (Variables mayor corr)","metadata":{}},{"cell_type":"code","source":"linear_model1 = LinearRegression() #Benchmark\nlinear_model1.fit(X_train, y_train)\nevaluar_modelo(linear_model1, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:54.555525Z","iopub.execute_input":"2021-06-17T14:20:54.555861Z","iopub.status.idle":"2021-06-17T14:20:55.730083Z","shell.execute_reply.started":"2021-06-17T14:20:54.55583Z","shell.execute_reply":"2021-06-17T14:20:55.728742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metricas= [[57286.50, 57958.02,-0.02, 65750.65, 64776.66, 0.56,72248.10, 71127.17,0.47],\n         [46297.29, 47935.92, 0.48, 55369.93,55594.84,0.68, 68869.13, 68466.13, 0.51],\n         [ 41839.18, 45999.04,0.57,39261.32,42334.09,0.81, 71935.27, 71387.44,  0.47]]\n\ncolumnas = ['RMSE_Train_P1', 'RMSE_Test_P1', 'R2_score_P1', 'RMSE_Train P2_PCA', 'RMSE_Test_P2_PCA', 'R2_score_P2_PCA', 'RMSE_Train_var_corr', 'RMSE_Test_var_corr', \n            'R2_score_var_corr'] # definimos los nombres de las columnas\nfilas = ['Regresión lineal', 'Árbol de Decisión', 'KNN'] # definimos los nombres de las filas\n\ncomparacion = pd.DataFrame(metricas, columns=columnas, index=filas)\ncomparacion.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:55.731404Z","iopub.execute_input":"2021-06-17T14:20:55.731815Z","iopub.status.idle":"2021-06-17T14:20:55.757888Z","shell.execute_reply.started":"2021-06-17T14:20:55.731785Z","shell.execute_reply":"2021-06-17T14:20:55.756666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"De esta primera parte en donde hemos considerado evaluar los modelos con hiperparámetros definidos e iguales para cada iteración de los modelos, se obtiene:\n\n- Realizar la reducción de dimensionalidad mediante el análisis de componentes principales nos ofrece mejoras significativas a nuestros modelos.\n\n- El modelo que mejor performance arroja hasta ahora es el KNN.\n\n- El modelo de regresión lineal mejora en relación a lo obtenido el el proyecto anterior, sin embargo, es el modelo que peor performance arroja.\n\n- Se resalta que la distribución de densidad para los errores de los conjuntos de train y test no difieren significativamente en cada modelo. Además, los histogramas son bastantes simétricos y parecidos para ambos conjuntos.","metadata":{}},{"cell_type":"markdown","source":"# PARTE B.  Optimización de Hiperparámetros","metadata":{}},{"cell_type":"markdown","source":"En lo que sigue, se intentará optimizar los modelos anteriores haciendo uso de la funcionalidad `RandomizedSearchCV` de `scikit-learn`, la cual nos permite hacer variaciones de los hiperparámetros del modelo de forma aleatoria y además incluye la estrategia de Validación Cruzada para obtener independencia de la partición de nuestros datos.","metadata":{}},{"cell_type":"markdown","source":"Empecemos haciendo el entrenamiento de los modelos considerando la variables que presentan más correlación con nuestra variable objetivo. En esta parte sólo consideraremos los modelos árbol de decisión y knn ya que más adelante se propone realizar regresión con regularización y atributos polinómicos.","metadata":{}},{"cell_type":"code","source":"X=df_escalados[['rooms','bedrooms','bathrooms']]\ny=df_escalados[['price']]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:55.760186Z","iopub.execute_input":"2021-06-17T14:20:55.760558Z","iopub.status.idle":"2021-06-17T14:20:55.777741Z","shell.execute_reply.started":"2021-06-17T14:20:55.760525Z","shell.execute_reply":"2021-06-17T14:20:55.776913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:55.778738Z","iopub.execute_input":"2021-06-17T14:20:55.779013Z","iopub.status.idle":"2021-06-17T14:20:55.801028Z","shell.execute_reply.started":"2021-06-17T14:20:55.778985Z","shell.execute_reply":"2021-06-17T14:20:55.79983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 7: Árbol de Decisión CV (Variables mayor corr) ","metadata":{}},{"cell_type":"code","source":"tree_regressor2 = DecisionTreeRegressor(random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:55.803544Z","iopub.execute_input":"2021-06-17T14:20:55.804051Z","iopub.status.idle":"2021-06-17T14:20:55.809966Z","shell.execute_reply.started":"2021-06-17T14:20:55.803999Z","shell.execute_reply":"2021-06-17T14:20:55.808592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Construyamos ahora la grilla de hiperparámetros los cuales serán generados de forma aleatoria para nuestro random search:","metadata":{}},{"cell_type":"code","source":"# Grilla para Random Search\nparam_dist = {'max_depth':np.arange(1,30),                #Profundidad del árbol\n              'min_samples_split': [2,3,4],        #El número mínimo de muestras necesarias para dividir un nodo interno.\n              }","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:55.811812Z","iopub.execute_input":"2021-06-17T14:20:55.812214Z","iopub.status.idle":"2021-06-17T14:20:55.823558Z","shell.execute_reply.started":"2021-06-17T14:20:55.812169Z","shell.execute_reply":"2021-06-17T14:20:55.822152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Busquemos optimizar parámetros","metadata":{}},{"cell_type":"code","source":"random_search = RandomizedSearchCV(tree_regressor2, param_dist,n_iter=20, random_state=42, cv=5)\nrandom_search.fit(X_train, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:55.825172Z","iopub.execute_input":"2021-06-17T14:20:55.825607Z","iopub.status.idle":"2021-06-17T14:20:57.694024Z","shell.execute_reply.started":"2021-06-17T14:20:55.825573Z","shell.execute_reply":"2021-06-17T14:20:57.69277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reentrenamos con los mejores parámetros:","metadata":{}},{"cell_type":"code","source":"tree_regressor3 = DecisionTreeRegressor(max_depth=23, min_samples_split=4, random_state=42)\ntree_regressor3.fit(X_train, y_train)\nevaluar_modelo(tree_regressor3, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:57.695446Z","iopub.execute_input":"2021-06-17T14:20:57.695798Z","iopub.status.idle":"2021-06-17T14:20:58.90563Z","shell.execute_reply.started":"2021-06-17T14:20:57.695768Z","shell.execute_reply":"2021-06-17T14:20:58.904399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 8: KNN CV (Variables mayor corr)","metadata":{}},{"cell_type":"code","source":"knn_regressor2 = KNeighborsRegressor()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:58.907184Z","iopub.execute_input":"2021-06-17T14:20:58.907658Z","iopub.status.idle":"2021-06-17T14:20:58.913079Z","shell.execute_reply.started":"2021-06-17T14:20:58.907612Z","shell.execute_reply":"2021-06-17T14:20:58.911745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Search\nparam_dist = {'n_neighbors':np.arange(10,30),     #Número de vecinos\n              'weights': ['uniform', 'distance']}        #Función de peso (cómo se ponderan los scores)\nrandom_search = RandomizedSearchCV(knn_regressor2, param_dist,n_iter=10, random_state=42, cv=5)\nrandom_search.fit(X_train, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:20:58.914913Z","iopub.execute_input":"2021-06-17T14:20:58.91538Z","iopub.status.idle":"2021-06-17T14:22:44.452716Z","shell.execute_reply.started":"2021-06-17T14:20:58.915334Z","shell.execute_reply":"2021-06-17T14:22:44.451502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_regressor3 = KNeighborsRegressor(n_neighbors=29, weights='distance')\nknn_regressor3.fit(X_train, y_train)\nevaluar_modelo(knn_regressor3, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:22:44.454164Z","iopub.execute_input":"2021-06-17T14:22:44.454561Z","iopub.status.idle":"2021-06-17T14:22:55.819349Z","shell.execute_reply.started":"2021-06-17T14:22:44.454529Z","shell.execute_reply":"2021-06-17T14:22:55.818065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ahora, veamos el performance de los modelos considerando utilizar la variables generadas con Componentes Principales:","metadata":{}},{"cell_type":"code","source":"X=X_nuevo\ny=df_escalados[['price']]\n#Realizamos la partición de los datos\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:22:55.820679Z","iopub.execute_input":"2021-06-17T14:22:55.820983Z","iopub.status.idle":"2021-06-17T14:22:55.843697Z","shell.execute_reply.started":"2021-06-17T14:22:55.820953Z","shell.execute_reply":"2021-06-17T14:22:55.842884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 9: Árbol de Decisión CV y PCA ","metadata":{}},{"cell_type":"code","source":"tree_regressor4 = DecisionTreeRegressor(random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:22:55.851257Z","iopub.execute_input":"2021-06-17T14:22:55.851806Z","iopub.status.idle":"2021-06-17T14:22:55.856426Z","shell.execute_reply.started":"2021-06-17T14:22:55.851773Z","shell.execute_reply":"2021-06-17T14:22:55.855208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Search\nparam_dist = {'max_depth':np.arange(1,80),                #Profundidad del árbol\n              'min_samples_split': [2,3,4],        #El número mínimo de muestras necesarias para dividir un nodo interno.\n              }\nrandom_search = RandomizedSearchCV(tree_regressor4, param_dist,n_iter=20, random_state=42, cv=5)\nrandom_search.fit(X_train, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:22:55.858479Z","iopub.execute_input":"2021-06-17T14:22:55.858785Z","iopub.status.idle":"2021-06-17T14:24:36.362397Z","shell.execute_reply.started":"2021-06-17T14:22:55.858756Z","shell.execute_reply":"2021-06-17T14:24:36.360752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_regressor5 = DecisionTreeRegressor(max_depth=39, min_samples_split=3, random_state=42)\ntree_regressor5.fit(X_train, y_train)\nevaluar_modelo(tree_regressor5, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:24:36.364229Z","iopub.execute_input":"2021-06-17T14:24:36.364717Z","iopub.status.idle":"2021-06-17T14:24:38.930886Z","shell.execute_reply.started":"2021-06-17T14:24:36.364671Z","shell.execute_reply":"2021-06-17T14:24:38.929633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 10: KNN CV y PCA","metadata":{}},{"cell_type":"code","source":"knn_regressor4 = KNeighborsRegressor()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:24:38.932271Z","iopub.execute_input":"2021-06-17T14:24:38.932634Z","iopub.status.idle":"2021-06-17T14:24:38.938845Z","shell.execute_reply.started":"2021-06-17T14:24:38.932603Z","shell.execute_reply":"2021-06-17T14:24:38.937402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Search\nparam_dist = {'n_neighbors':np.arange(10,100),     #Número de vecinos\n              'weights': ['uniform', 'distance']}        #Función de peso (cómo se ponderan los scores)\nrandom_search = RandomizedSearchCV(knn_regressor4, param_dist,n_iter=10, random_state=42, cv=5)\nrandom_search.fit(X_train, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:24:38.939841Z","iopub.execute_input":"2021-06-17T14:24:38.940137Z","iopub.status.idle":"2021-06-17T14:32:32.795177Z","shell.execute_reply.started":"2021-06-17T14:24:38.940109Z","shell.execute_reply":"2021-06-17T14:32:32.793945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_regressor5 = KNeighborsRegressor(n_neighbors=19, weights='distance')\nknn_regressor5.fit(X_train, y_train)\nevaluar_modelo(knn_regressor5, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:32:32.79696Z","iopub.execute_input":"2021-06-17T14:32:32.797421Z","iopub.status.idle":"2021-06-17T14:33:55.365666Z","shell.execute_reply.started":"2021-06-17T14:32:32.797376Z","shell.execute_reply":"2021-06-17T14:33:55.364412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metricas1= [[68734.79, 68479.18, 0.51, 41058.51, 49137.44, 0.75],\n         [69899.82, 69611.44, 0.50,18377.27,39262.54,0.84]]\n\ncolumnas1 = ['RMSE_Train_var_corr', 'RMSE_Test_var_corr', 'R2_score_var_corr','RMSE_Train_PCA', 'RMSE_Test_PCA', 'R2_score_PCA'] # definimos los nombres de las columnas\nfilas1 = ['Árbol de Decisión', 'KNN'] # definimos los nombres de las filas\n\ncomparacion1 = pd.DataFrame(metricas1, columns=columnas1, index=filas1)\ncomparacion1.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:33:55.369048Z","iopub.execute_input":"2021-06-17T14:33:55.369414Z","iopub.status.idle":"2021-06-17T14:33:55.389334Z","shell.execute_reply.started":"2021-06-17T14:33:55.36938Z","shell.execute_reply":"2021-06-17T14:33:55.388556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En la tabla comparativa se observa:\n    \n- Existe una pequeña mejoría en el desempeño de ambos modelos considerando las variables con mayor correlación después de la optimización de los hiperparámetros.\n\n- Se encuentran distribuciones de densidad de errores que difieren bastante entre el conjunto de train y test, indicando así la presencia de un sobreajuste en nuestros modelos.  \n","metadata":{}},{"cell_type":"markdown","source":"# Modelos Avanzados","metadata":{}},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"markdown","source":"Veamos ahora el desempeño de un modelo Random Forest entrenado tanto con la variables de mayor correlación con le precio como con las componentes principales.","metadata":{}},{"cell_type":"markdown","source":"En principio, entrenaremos el modelo con hiperparámetros puestos de forma manual para observar su desempeño. Luego, realizaremos la validación de hiperparámetros soportándonos en el error Out-of-Bag. Calcularemos los errores de entrenamiento y los oob_scores de forma iterativa variando la cantidad de estimadores en el modelo. De esta manera, podemos obtener cuántos árboles debe modelar el random forest para obtener el mejor performance.","metadata":{}},{"cell_type":"markdown","source":"No se realizará el método de optimización de parámetros por Validación Cruzada ya que presenta un costo computacional elevado.","metadata":{}},{"cell_type":"markdown","source":"### Modelo 11: Random Forest con PCA","metadata":{}},{"cell_type":"code","source":"X=X_nuevo\ny=df_escalados[['price']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:33:55.390458Z","iopub.execute_input":"2021-06-17T14:33:55.390914Z","iopub.status.idle":"2021-06-17T14:33:55.419684Z","shell.execute_reply.started":"2021-06-17T14:33:55.390868Z","shell.execute_reply":"2021-06-17T14:33:55.418808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest = RandomForestRegressor(\n            n_estimators = 10,\n            criterion    = 'mse',\n            max_depth    = None,\n            max_features = 'auto',\n            oob_score    = False,\n            n_jobs       = -1,               #Con -1 se utilizan todos los cores disponibles\n            random_state = 42\n         )\nrandom_forest.fit(X_train, y_train)\nevaluar_modelo(random_forest, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:33:55.420837Z","iopub.execute_input":"2021-06-17T14:33:55.421331Z","iopub.status.idle":"2021-06-17T14:34:01.056574Z","shell.execute_reply.started":"2021-06-17T14:33:55.421276Z","shell.execute_reply":"2021-06-17T14:34:01.054848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validación con Out-of-Bag error\ntrain_scores = []\noob_scores   = []\n\n# Número de estimadores a considerar\nestimator_range = range(1, 50, 5)\n\n# Iteramos para distintos valores de n_estimators\nfor n_estimators in estimator_range:\n    random_forest1 = RandomForestRegressor(\n                n_estimators = n_estimators,\n                criterion    = 'mse',\n                max_depth    = None,\n                max_features = 'auto',\n                oob_score    = True,\n                n_jobs       = -1,\n                random_state = 42\n             )\n    random_forest1.fit(X_train, y_train)\n    train_scores.append(random_forest1.score(X_train, y_train))\n    oob_scores.append(random_forest1.oob_score_)\n    \n# Graficamos el comportamiento de los errores train y obb_score respecto al número de estimadores\nfig, ax = plt.subplots(figsize=(6, 3.84))\nax.plot(estimator_range, train_scores, label=\"train scores\")\nax.plot(estimator_range, oob_scores, label=\"out-of-bag scores\")\nax.plot(estimator_range[np.argmax(oob_scores)], max(oob_scores),\n        marker='o', color = \"red\", label=\"max score\")\nax.set_ylabel(\"R^2\")\nax.set_xlabel(\"n_estimators\")\nax.set_title(\"Evolución del out-of-bag-error vs número árboles\")\nplt.legend();\n#Imprimimos el valor óptimo \nprint(f\"Valor óptimo de n_estimators: {estimator_range[np.argmax(oob_scores)]}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:34:01.058553Z","iopub.execute_input":"2021-06-17T14:34:01.058942Z","iopub.status.idle":"2021-06-17T14:35:39.618562Z","shell.execute_reply.started":"2021-06-17T14:34:01.058908Z","shell.execute_reply":"2021-06-17T14:35:39.617393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se observa que aproximadamente a partir de los 10 estimadores el error obb_score del modelo se estabiliza y se vuelve constante, llegando así a su valor más elevado. Por lo que ahora entrenaremos de nuevo modelo con el valor óptimo obtenido.","metadata":{}},{"cell_type":"code","source":"random_forest2 = RandomForestRegressor(\n            n_estimators = 46,\n            criterion    = 'mse',\n            max_depth    = None,\n            max_features = 'auto',\n            oob_score    = False,\n            n_jobs       = -1,               #Con -1 se utilizan todos los cores disponibles\n            random_state = 42\n         )\nrandom_forest2.fit(X_train, y_train)\nevaluar_modelo(random_forest2, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:35:39.620104Z","iopub.execute_input":"2021-06-17T14:35:39.620457Z","iopub.status.idle":"2021-06-17T14:35:59.364606Z","shell.execute_reply.started":"2021-06-17T14:35:39.620425Z","shell.execute_reply":"2021-06-17T14:35:59.362887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observemos la importancia de los features:","metadata":{}},{"cell_type":"code","source":"df_X_nuevo=pd.DataFrame(X_nuevo)\nsns.barplot(df_X_nuevo.columns, random_forest2.feature_importances_)\nplt.xlabel(\"Componentes Principales\")\nplt.ylabel(\"Importancias\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:35:59.366385Z","iopub.execute_input":"2021-06-17T14:35:59.366785Z","iopub.status.idle":"2021-06-17T14:36:00.117126Z","shell.execute_reply.started":"2021-06-17T14:35:59.366754Z","shell.execute_reply":"2021-06-17T14:36:00.115972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se puede observar que sólo 4 componentes principales (14,24,34,35) son las que aportan al modelo una importancia mayor al 5%. Se esperaba que las primeras componentes que respresentaban mayor variabilidad de los datos fuesen las mejores variables predictoras para el modelo. Sin embargo, por ser estas componentes generadas al condensar la información de las variables originales, es difícil interpretar qué representan además de ser las más relevantes del modelo. ","metadata":{}},{"cell_type":"markdown","source":"### Modelo 11: Random Forest con variables más corr","metadata":{}},{"cell_type":"code","source":"X=df_escalados[['rooms','bedrooms','bathrooms']]\ny=df_escalados[['price']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:00.118221Z","iopub.execute_input":"2021-06-17T14:36:00.11851Z","iopub.status.idle":"2021-06-17T14:36:00.139933Z","shell.execute_reply.started":"2021-06-17T14:36:00.118483Z","shell.execute_reply":"2021-06-17T14:36:00.13881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest3 = RandomForestRegressor(\n            n_estimators = 10,\n            criterion    = 'mse',\n            max_depth    = None,\n            max_features = 'auto',\n            oob_score    = False,\n            n_jobs       = -1,               #Con -1 se utilizan todos los cores disponibles\n            random_state = 42\n         )\nrandom_forest3.fit(X_train, y_train)\nevaluar_modelo(random_forest3, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:00.141588Z","iopub.execute_input":"2021-06-17T14:36:00.142364Z","iopub.status.idle":"2021-06-17T14:36:01.668552Z","shell.execute_reply.started":"2021-06-17T14:36:00.142317Z","shell.execute_reply":"2021-06-17T14:36:01.667586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validación con Out-of-Bag error\ntrain_scores = []\noob_scores   = []\n\n# Número de estimadores a considerar\nestimator_range = range(1, 50, 5)\n\n# Iteramos para distintos valores de n_estimators\nfor n_estimators in estimator_range:\n    random_forest4 = RandomForestRegressor(\n                n_estimators = n_estimators,\n                criterion    = 'mse',\n                max_depth    = None,\n                max_features = 'auto',\n                oob_score    = True,\n                n_jobs       = -1,\n                random_state = 42\n             )\n    random_forest4.fit(X_train, y_train)\n    train_scores.append(random_forest4.score(X_train, y_train))\n    oob_scores.append(random_forest4.oob_score_)\n    \n# Graficamos el comportamiento de los errores train y obb_score respecto al número de estimadores\nfig, ax = plt.subplots(figsize=(6, 3.84))\nax.plot(estimator_range, train_scores, label=\"train scores\")\nax.plot(estimator_range, oob_scores, label=\"out-of-bag scores\")\nax.plot(estimator_range[np.argmax(oob_scores)], max(oob_scores),\n        marker='o', color = \"red\", label=\"max score\")\nax.set_ylabel(\"R^2\")\nax.set_xlabel(\"n_estimators\")\nax.set_title(\"Evolución del out-of-bag-error vs número árboles\")\nplt.legend();\n#Imprimimos el valor óptimo \nprint(f\"Valor óptimo de n_estimators: {estimator_range[np.argmax(oob_scores)]}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:01.669934Z","iopub.execute_input":"2021-06-17T14:36:01.67027Z","iopub.status.idle":"2021-06-17T14:36:05.353994Z","shell.execute_reply.started":"2021-06-17T14:36:01.670238Z","shell.execute_reply":"2021-06-17T14:36:05.352709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se observa nuevamente que aproximadamente a partir de los 10 estimadores el error obb_score del modelo se estabiliza y se vuelve constante, llegando así a su valor más elevado (n_estimators: 41)","metadata":{}},{"cell_type":"code","source":"random_forest5 = RandomForestRegressor(\n            n_estimators = 41,\n            criterion    = 'mse',\n            max_depth    = None,\n            max_features = 'auto',\n            oob_score    = False,\n            n_jobs       = -1,               #Con -1 se utilizan todos los cores disponibles\n            random_state = 42\n         )\nrandom_forest5.fit(X_train, y_train)\nevaluar_modelo(random_forest5, scaler_dependientes,X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:05.355246Z","iopub.execute_input":"2021-06-17T14:36:05.355695Z","iopub.status.idle":"2021-06-17T14:36:07.217173Z","shell.execute_reply.started":"2021-06-17T14:36:05.355576Z","shell.execute_reply":"2021-06-17T14:36:07.21612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(X.columns, random_forest5.feature_importances_)\nplt.xlabel(\"Componentes Principales\")\nplt.ylabel(\"Importancias\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:07.218377Z","iopub.execute_input":"2021-06-17T14:36:07.218689Z","iopub.status.idle":"2021-06-17T14:36:07.503035Z","shell.execute_reply.started":"2021-06-17T14:36:07.218657Z","shell.execute_reply":"2021-06-17T14:36:07.501717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En este caso, el modelo se está entrenando con las variables originales y se obtiene que el atributo que representa la mayor importancia para el modelo es 'bathrooms'. Esto se esperaba ya que es la variable que presenta mayor correlación con la variable a predecir 'price'. ","metadata":{}},{"cell_type":"code","source":"metricas2= [[40082.58, 46003.66, 0.78],\n         [68739.02, 68422.15, 0.51]]\n\n\ncolumnas2 = ['RMSE_Train', 'RMSE_Test', 'R2_score',] # definimos los nombres de las columnas\nfilas2 = ['Random_Forest_PCA', 'Random_Forest_var_corr'] # definimos los nombres de las filas\n\ncomparacion2 = pd.DataFrame(metricas2, columns=columnas2, index=filas2)\ncomparacion2.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:07.504705Z","iopub.execute_input":"2021-06-17T14:36:07.505139Z","iopub.status.idle":"2021-06-17T14:36:07.523142Z","shell.execute_reply.started":"2021-06-17T14:36:07.505095Z","shell.execute_reply":"2021-06-17T14:36:07.521854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest con componentes principales representa hasta ahora el mejor score y la distribución del error global para el conjunto de train y test con mayor similitud, indicando que no hay existencia de sobreajuste significativa. Además el histograma de errores es bastante simétrico.","metadata":{}},{"cell_type":"markdown","source":"## Regresión con Regularización y Atributos Polinómicos","metadata":{}},{"cell_type":"markdown","source":"Como hemos visto en la parte A del proyecto, el modelo de regresión lineal es el que peor performance ha arrojado. Esto pudiese estar ligado a la falta de linealidad en nuestro problema. Pensando en esto, consideremos ahora entrenar un modelo de regresión agregando atributos polinómicos usando la función `PolynomialFeatures` de `Scikit-Learn`. ","metadata":{}},{"cell_type":"markdown","source":"Además, entrenaremos los modelos aplicandos dos tipos de regularización; la de Ridge y la de Lasso. También, se realizará optimización del parámetro `alpha` que es el que penaliza nuestra función de costo.","metadata":{}},{"cell_type":"markdown","source":"### Modelo 12: Regresión Avanzada con PCA","metadata":{}},{"cell_type":"code","source":"X=X_nuevo\ny=df_escalados[['price']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:07.525565Z","iopub.execute_input":"2021-06-17T14:36:07.526839Z","iopub.status.idle":"2021-06-17T14:36:07.554896Z","shell.execute_reply.started":"2021-06-17T14:36:07.526784Z","shell.execute_reply":"2021-06-17T14:36:07.553866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly = PolynomialFeatures(2, include_bias=False)\nX_train_new1 = poly.fit_transform(X_train)\nX_test_new1 = poly.fit_transform(X_test)\nprint(X_train_new1.shape, X_test_new1.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:07.556368Z","iopub.execute_input":"2021-06-17T14:36:07.556695Z","iopub.status.idle":"2021-06-17T14:36:08.159539Z","shell.execute_reply.started":"2021-06-17T14:36:07.556664Z","shell.execute_reply":"2021-06-17T14:36:08.158366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Regularización de Ridge:","metadata":{}},{"cell_type":"code","source":"reg_ridge = Ridge()\n\n#Random Search\nparam_dist = {'alpha':np.logspace(-10, 2, 100),   #Esta funcionalidad de numpy nos genera 100 muestras desde 1e-10 a 1e+2, con espaciado logaritmico.\n             }       \nrandom_search = RandomizedSearchCV(reg_ridge, param_dist,n_iter=10, random_state=42, cv=5)\nrandom_search.fit(X_train_new1, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:08.161188Z","iopub.execute_input":"2021-06-17T14:36:08.161631Z","iopub.status.idle":"2021-06-17T14:36:56.5727Z","shell.execute_reply.started":"2021-06-17T14:36:08.161584Z","shell.execute_reply":"2021-06-17T14:36:56.571497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_ridge1 = Ridge(alpha=0.030538555088334123)\nreg_ridge1.fit(X_train_new1,y_train)\nevaluar_modelo(reg_ridge1, scaler_dependientes,X_train_new1, X_test_new1, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:56.574316Z","iopub.execute_input":"2021-06-17T14:36:56.575016Z","iopub.status.idle":"2021-06-17T14:36:59.015535Z","shell.execute_reply.started":"2021-06-17T14:36:56.574962Z","shell.execute_reply":"2021-06-17T14:36:59.014385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Regularización de Lasso:","metadata":{}},{"cell_type":"code","source":"reg_lasso = Lasso()\n\n#Random Search\nparam_dist = {'alpha':np.logspace(-10, 2, 100),   \n             }       \nrandom_search = RandomizedSearchCV(reg_lasso, param_dist,n_iter=10, random_state=42, cv=5)\nrandom_search.fit(X_train_new1, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:36:59.016879Z","iopub.execute_input":"2021-06-17T14:36:59.017166Z","iopub.status.idle":"2021-06-17T14:53:38.328351Z","shell.execute_reply.started":"2021-06-17T14:36:59.017139Z","shell.execute_reply":"2021-06-17T14:53:38.327181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_lasso1 = Lasso(alpha = 5.336699231206313e-06)\nreg_lasso1.fit(X_train_new1,y_train)\nevaluar_modelo(reg_lasso1, scaler_dependientes,X_train_new1, X_test_new1, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:53:38.330045Z","iopub.execute_input":"2021-06-17T14:53:38.330805Z","iopub.status.idle":"2021-06-17T14:54:06.381765Z","shell.execute_reply.started":"2021-06-17T14:53:38.330756Z","shell.execute_reply":"2021-06-17T14:54:06.380549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelo 13: Regresión Avanzada con variables más corr","metadata":{}},{"cell_type":"code","source":"X=df_escalados[['rooms','bedrooms','bathrooms']]\ny=df_escalados[['price']]\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:06.383511Z","iopub.execute_input":"2021-06-17T14:54:06.383959Z","iopub.status.idle":"2021-06-17T14:54:06.404195Z","shell.execute_reply.started":"2021-06-17T14:54:06.383914Z","shell.execute_reply":"2021-06-17T14:54:06.402881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly = PolynomialFeatures(3, include_bias=False)\nX_train_new2 = poly.fit_transform(X_train)\nX_test_new2 = poly.fit_transform(X_test)\nprint(X_train_new2.shape, X_test_new2.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:06.406039Z","iopub.execute_input":"2021-06-17T14:54:06.406478Z","iopub.status.idle":"2021-06-17T14:54:06.434651Z","shell.execute_reply.started":"2021-06-17T14:54:06.406435Z","shell.execute_reply":"2021-06-17T14:54:06.433246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Regularización de Ridge:","metadata":{}},{"cell_type":"code","source":"reg_ridge2 = Ridge()\n\n#Random Search\nparam_dist = {'alpha':np.logspace(-10, 2, 200),   \n             }       \nrandom_search = RandomizedSearchCV(reg_ridge2, param_dist,n_iter=10, random_state=42, cv=5)\nrandom_search.fit(X_train_new2, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:06.436051Z","iopub.execute_input":"2021-06-17T14:54:06.436498Z","iopub.status.idle":"2021-06-17T14:54:07.886824Z","shell.execute_reply.started":"2021-06-17T14:54:06.436463Z","shell.execute_reply":"2021-06-17T14:54:07.885546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_ridge3 = Ridge(alpha= 0.005231099308056258)\nreg_ridge3.fit(X_train_new2,y_train)\nevaluar_modelo(reg_ridge3, scaler_dependientes,X_train_new2, X_test_new2, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:07.888848Z","iopub.execute_input":"2021-06-17T14:54:07.889737Z","iopub.status.idle":"2021-06-17T14:54:09.14055Z","shell.execute_reply.started":"2021-06-17T14:54:07.88968Z","shell.execute_reply":"2021-06-17T14:54:09.13936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Regularización de Lasso:","metadata":{}},{"cell_type":"code","source":"reg_lasso2 = Lasso()\n\n#Random Search\nparam_dist = {'alpha':np.logspace(-10, 2, 100),   \n             }       \nrandom_search = RandomizedSearchCV(reg_lasso2, param_dist,n_iter=10, random_state=42, cv=5)\nrandom_search.fit(X_train_new2, y_train)\nprint(\"Mejores parametros: \"+str(random_search.best_params_))\nprint(\"Mejor Score: \"+str(random_search.best_score_)+'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:09.142657Z","iopub.execute_input":"2021-06-17T14:54:09.143091Z","iopub.status.idle":"2021-06-17T14:54:26.640327Z","shell.execute_reply.started":"2021-06-17T14:54:09.143047Z","shell.execute_reply":"2021-06-17T14:54:26.638961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_lasso3 = Lasso(alpha = 4.641588833612782e-08)\nreg_lasso3.fit(X_train_new2,y_train)\nevaluar_modelo(reg_lasso3, scaler_dependientes,X_train_new2, X_test_new2, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:26.645975Z","iopub.execute_input":"2021-06-17T14:54:26.649268Z","iopub.status.idle":"2021-06-17T14:54:28.692967Z","shell.execute_reply.started":"2021-06-17T14:54:26.646749Z","shell.execute_reply":"2021-06-17T14:54:28.691729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metricas3= [[58194.57, 57439.64, 0.66,69594.88, 68981.78, 0.51],\n            [ 59466.23, 58648.54, 0.64, 69591.36, 68975.65, 0.51]]\n\ncolumnas3 = ['RMSE_Train_PCA', 'RMSE_Test_PCA', 'R2_score_PCA','RMSE_Train_var_corr','RMSE_Test_var_corr','R2_score_var_corr'] # definimos los nombres de las columnas\nfilas3 = ['Regularización_Ridge', 'Regularización_Lasso'] # definimos los nombres de las filas\n\ncomparacion3 = pd.DataFrame(metricas3, columns=columnas3, index=filas3)\ncomparacion3.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.69438Z","iopub.execute_input":"2021-06-17T14:54:28.694773Z","iopub.status.idle":"2021-06-17T14:54:28.715117Z","shell.execute_reply.started":"2021-06-17T14:54:28.694735Z","shell.execute_reply":"2021-06-17T14:54:28.714078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar que existen mejoras en el modelo de Regresión, considerando atributos polinómicos y regularización de Ridge y de Lasso. Sin embargo, sigue teniendo un performance bastante bajo y con errores muy elevados.","metadata":{}},{"cell_type":"markdown","source":"- Para los modelos de regresión avanzada considerados, el mejor performance lo arrojan los entrenados con las componentes principales.\n- Es importante destacar que la regularización de Lasso arroja una distribución de densidad de error muy similar para los conjuntos de train y test, además de histogramas simétricos, por lo que si bien no es modelo con mejor r2 score, es el que no presenta sobreajuste.\n- La inclusión de atributos polinómicos aporta gran mejoría en los modelos de regresión con regularización respecto a un modelo de regresión lineal benchmark como el considerado en la parte A del proyecto. ","metadata":{}},{"cell_type":"code","source":"#Tabla final\nmetricas4= [[65750.65, 64776.66, 0.56,72248.10, 71127.17,0.47],\n         [55369.93,55594.84,0.68, 68869.13, 68466.13, 0.51],\n         [39261.32,42334.09,0.81, 71935.27, 71387.44,  0.47],\n          [41058.51, 49137.44, 0.75,68734.79, 68479.18, 0.51],\n         [18377.27,39262.54,0.84,69899.82, 69611.44, 0.50],\n          [40082.58, 46003.66, 0.78, 68739.02, 68422.15, 0.51],\n          [58194.57, 57439.64, 0.66,69594.88, 68981.78, 0.51],\n            [ 59466.23, 58648.54, 0.64, 69591.36, 68975.65, 0.51]]\n\ncolumnas4 = ['RMSE_Train_PCA', 'RMSE_Test_PCA', 'R2_score_PCA', 'RMSE_Train_var_corr', 'RMSE_Test_var_corr', \n            'R2_score_var_corr'] # definimos los nombres de las columnas\nfilas4 = ['Regresión lineal', 'Árbol de Decisión', 'KNN','Árbol de Decisión CV', 'KNN CV', 'Random Forest', 'Regresión Reg Ridge', 'Regresión Reg Lasso'] # definimos los nombres de las filas\n\ncomparacion4 = pd.DataFrame(metricas4, columns=columnas4, index=filas4)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.716641Z","iopub.execute_input":"2021-06-17T14:54:28.716967Z","iopub.status.idle":"2021-06-17T14:54:28.738914Z","shell.execute_reply.started":"2021-06-17T14:54:28.716936Z","shell.execute_reply":"2021-06-17T14:54:28.737573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusiones","metadata":{}},{"cell_type":"markdown","source":"A lo largo de todo el proyecto se ha trabajado de forma iterativa para encontrar el modelo que mejor prediga el precio de una propiedad en base a sus características. Comparando el desempeño de los modelos tomando en cuenta las componentes principales que aportan mayor variabilidad al problema y también, considerando usar las variables predictoras que presentan mayor correlación con la variable objtivo.","metadata":{}},{"cell_type":"markdown","source":"En la siguiente tabla recolectamos todos los resultados:","metadata":{}},{"cell_type":"code","source":"comparacion4","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.741589Z","iopub.execute_input":"2021-06-17T14:54:28.742102Z","iopub.status.idle":"2021-06-17T14:54:28.771062Z","shell.execute_reply.started":"2021-06-17T14:54:28.74205Z","shell.execute_reply":"2021-06-17T14:54:28.769769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* El modelo de vecinos más cercanos arroja un R2 alto, pero presenta overfitting ya que los errores de train y test difieren bastante, lo que indica que el modelo está aprendiendo demasiado de los datos pero esta prediciendo de forma fallida. Es importante resaltar que KNN presenta menor overfitting cuando se considera estimar los pesos de forma uniforme que con el inverso de la distancia.","metadata":{}},{"cell_type":"markdown","source":"* El mejor modelo entrenado con nuestros datos es el Random Forest, arroja los errores más bajos, con distribuciones de errores de train y test menor sobreajuste y un R2 score de 0.78. Lo cual indica que estamos aproximando nuestros datos de buena manera. ","metadata":{}},{"cell_type":"markdown","source":"* Los modelos regresión mejoran con la transformación de los datos, la inclusión de atributos polinómicos y regularización con una variación considerable del parámetro alpha. El modelo de regularización de Lasso presenta una muy buena distribución de errores para los conjuntos de train y test, además el gráfico de valores predichos y valores reales presentan menor dispersión y se ajustan más a la recta, lo cual indica que es un buen regresor.","metadata":{}},{"cell_type":"markdown","source":"* Se resalta la importancia de la reducción de la dimensionalidad. Los modelos de árboles, vecinos y random forest; son los que presentan mejor performance con estas variables.","metadata":{}},{"cell_type":"markdown","source":"Considero que se podría mejorar el desempeño de los modelos prestando atención a las variables de superficie total y cubierta. Evaluar con los expertos el tema de si éstas variables tienen un distribución común o están sesgadas de alguna forma y por esto presentan valores atípicos que podamos luego remover con mayor certeza.","metadata":{}},{"cell_type":"markdown","source":"# Clustering Prueba (Extra)","metadata":{}},{"cell_type":"markdown","source":"Después de algunas iteraciones encontré que agregando las variables binarias generadas a partir de la variable property_type, la el diagrama de dispersión de las dos primeras componentes principales muestran cierto patrón de agrupamiento, tal como se muestra a continuación:","metadata":{}},{"cell_type":"code","source":"X=df_escalados[['Casa','Departamento','PH','rooms','bedrooms','bathrooms', 'surface_total', 'surface_covered']]\ny=df_escalados[['price']]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.772406Z","iopub.execute_input":"2021-06-17T14:54:28.772906Z","iopub.status.idle":"2021-06-17T14:54:28.788499Z","shell.execute_reply.started":"2021-06-17T14:54:28.772859Z","shell.execute_reply":"2021-06-17T14:54:28.787259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=2)\nX_nuevo = pca.fit_transform(X) ","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.789768Z","iopub.execute_input":"2021-06-17T14:54:28.790103Z","iopub.status.idle":"2021-06-17T14:54:28.936882Z","shell.execute_reply.started":"2021-06-17T14:54:28.79007Z","shell.execute_reply":"2021-06-17T14:54:28.935622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.components_","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.938434Z","iopub.execute_input":"2021-06-17T14:54:28.93923Z","iopub.status.idle":"2021-06-17T14:54:28.94811Z","shell.execute_reply.started":"2021-06-17T14:54:28.939166Z","shell.execute_reply":"2021-06-17T14:54:28.946432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.explained_variance_ratio_","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.950529Z","iopub.execute_input":"2021-06-17T14:54:28.952514Z","iopub.status.idle":"2021-06-17T14:54:28.964953Z","shell.execute_reply.started":"2021-06-17T14:54:28.952444Z","shell.execute_reply":"2021-06-17T14:54:28.963503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(X_nuevo[:,0], X_nuevo[:,1] )\nplt.xlabel('PC1')\nplt.ylabel('PC2')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:28.967143Z","iopub.execute_input":"2021-06-17T14:54:28.967738Z","iopub.status.idle":"2021-06-17T14:54:29.370608Z","shell.execute_reply.started":"2021-06-17T14:54:28.967685Z","shell.execute_reply":"2021-06-17T14:54:29.369399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se observan 3 grupos bien definidos. Apliquemos ahora la técnica de K-means","metadata":{}},{"cell_type":"code","source":"# Preparamos una lista donde vamos a ir agregando las distancias medias\nSum_of_squared_distances = []\n# Fiteammos un modelo para cada numero de cluster que queremos testear\nK = np.arange(2,14)\nfor k in K:\n    # Definimos y entrenamos el modelo\n    km = KMeans(n_clusters=k)\n    km = km.fit(X_nuevo)\n    # Calculamos la distancia media y agregamos a la lista\n    distancia_total = km.inertia_\n    distancia_media = np.divide(distancia_total,X_nuevo.shape[0]) #OJO\n    Sum_of_squared_distances.append(distancia_media)\n    \nplt.figure(figsize = (10,7))\nplt.plot(K, Sum_of_squared_distances, lw=3)\nplt.scatter(K, Sum_of_squared_distances,s=55,c='r')\nplt.xlabel('Cantidad de Clusters K')\nplt.ylabel('Inercia media')\nplt.title('Método del codo')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:29.372123Z","iopub.execute_input":"2021-06-17T14:54:29.372584Z","iopub.status.idle":"2021-06-17T14:54:47.338523Z","shell.execute_reply.started":"2021-06-17T14:54:29.372528Z","shell.execute_reply":"2021-06-17T14:54:47.337741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se evidencia de forma clara que el número de clusters idóneo es k=3, ahora entrenemos el modelo:","metadata":{}},{"cell_type":"code","source":"# Defino y entreno el modelo\nkm = KMeans(n_clusters=3)\nkm = km.fit(X_nuevo)\n# Obtengo la posición de los centros y las etiquetas\netiquetas_ = km.labels_\ncentros_ = km.cluster_centers_\n# Plotting the cluster centers and the data points on a 2D plane\nsns.scatterplot(X_nuevo[:,0], X_nuevo[:,1], hue = etiquetas_)\nsns.scatterplot(centros_[:, 0], centros_[:, 1],color='black', marker=\"+\", s=1000)\nplt.title('Data points and cluster centroids')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T14:54:47.339721Z","iopub.execute_input":"2021-06-17T14:54:47.340335Z","iopub.status.idle":"2021-06-17T14:54:50.732037Z","shell.execute_reply.started":"2021-06-17T14:54:47.340286Z","shell.execute_reply":"2021-06-17T14:54:50.730958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si bien el objetivo del proyecto es predecir el precio de una propiedad a partir de sus características, acá podemos evidenciar un modelo que nos permita clasificar propiedades de acuerdo a su tipo. En este caso, los clusters encontrados probablemente están relacionados con el hecho de si una propiedad es de tipo Casa, Departamento o PH.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}