{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Building a Recommender system using un-supervised learning\n\nIn this script, we have tried to build a recommender system with  the help of three of the most common unsupervised learning algorithm for NLP. 1. Latent Semantic Analysis, 2. Matrix Factorization, 3. Latent Dirichlet Allocation.\n![Work meme](https://bbsradio.com/sites/default/files/archive/picture-2-16-17/productivity-meme.jpg)\n ","metadata":{"_uuid":"c8ca5035-bb5e-4d47-a4ec-daf93cd2903e","_cell_guid":"b9c3ba5f-4524-4682-9878-f1e9c74d0cb4","trusted":true}},{"cell_type":"markdown","source":"## What is a Recommender System?\nThe recommender system is a system that is capable of predicting the possible \npreferences for a particular set of items that a user might prefer based on his \nprevious behavior or preferences. For example, you ask your dad to bring you \nchocolate ice-cream whenever the weather is very hot, from his previous experience \nhe found that you love chocolate flavor much more than any other flavor. \nTherefore on your birthday, he thought of giving you a surprise by presenting\nyou a chocolate cake without your advice expecting that you would definitely\nlove the chocolate cake.<br>\n![Recommendation System](https://image2.slideserve.com/4030528/recommender-system-l.jpg)\n<br>The same thing goes for recommender systems also, varoius websites like YouTube,\nGoogle Adds, Imdb etc use this recommender system to recommend you items based\non your previous tastes or items that have been viewed by similar persons like you.","metadata":{"_uuid":"1d5cb18b-d14a-4169-8967-77aa36710579","_cell_guid":"350c4a3c-928a-4ece-925b-3f638d079df2","trusted":true}},{"cell_type":"markdown","source":"## What is a Unsupervised Learning?\n\nArtificially intelligent Algorithms or models could learn and train from two types\nof data, one that have target labels and another that do not have target labels. When these algorithms\nare trained through labeled data then the learning technique is called Supervised\nLearning. And when we are training the model through unlabeled data we call it \nUnsupervised Learning. For more Information you could google it out.\n![Unsupervised](https://lawtomated.com/wp-content/uploads/2019/04/supVsUnsup.png)\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import TruncatedSVD, NMF,LatentDirichletAllocation\nimport seaborn as sns\nfrom tqdm import tqdm as tqdm_base\nfrom gensim.models.ldamodel import LdaModel\nfrom gensim.corpora import Dictionary\nimport umap\n\ndef tqdm(*args, **kwargs):\n    if hasattr(tqdm_base, '_instances'):\n        for instance in list(tqdm_base._instances):\n            tqdm_base._decr_instances(instance)\n    return tqdm_base(*args, **kwargs)\n\n'''Loading the movie dataset'''\nmovie_df = pd.read_csv('/kaggle/input/wikipedia-movie-plots/wiki_movie_plots_deduped.csv')\n#movie_df.head()\n#movie_df['Genre'].value_counts()","metadata":{"_uuid":"27f4b6aa-63e9-412a-bec1-25c7f3df8bd0","_cell_guid":"dd1a042a-19e6-4ef6-84a6-40b60a6d9670","execution":{"iopub.status.busy":"2021-07-14T14:04:15.473576Z","iopub.execute_input":"2021-07-14T14:04:15.473907Z","iopub.status.idle":"2021-07-14T14:04:22.405947Z","shell.execute_reply.started":"2021-07-14T14:04:15.473824Z","shell.execute_reply":"2021-07-14T14:04:22.404674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Data_Cleaning(Genre):\n    '''\n    Here we have cleaned the entire Genre column of the dataset by removing unwanted symbols, categories, and \n    replacing categories which meant the same with a common category name. It reduduces our number of target labels.\n    NOTE: This function is inspired from the kernel - https://www.kaggle.com/aminejallouli/genre-classification-based-on-wiki-movies-plots\n    I have only improved it a bit further according to my requirements.\n    '''\n    movie_df['Genre_improved'] = movie_df['Genre']\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.strip()\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' - ', '|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' / ', '|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('/', '|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' & ', '|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(', ', '|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('; ', '|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('bio-pic', 'biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biopic', 'biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biographical', 'biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biodrama', 'biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('bio-drama', 'biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biographic', 'biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(film genre\\)', '')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('animated','animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('anime','animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('children\\'s','children')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('comedey','comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\[not in citation given\\]','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' set 4,000 years ago in the canadian arctic','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('historical','history')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('romantic','romance')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('3-d','animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('3d','animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('viacom 18 motion pictures','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('sci-fi','science_fiction')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('ttriller','thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('.','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('based on radio serial','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' on the early years of hitler','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('sci fi','science_fiction')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('science fiction','science_fiction')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' (30min)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('16 mm film','short')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\[140\\]','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\[144\\]','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' for ','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('adventures','adventure')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('kung fu','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('kung-fu','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('martial arts','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('world war ii','war')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('world war i','war')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biography about montreal canadiens star|maurice richard','biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('bholenath movies|cinekorn entertainment','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(volleyball\\)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('spy film','spy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('anthology film','anthology')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biography fim','biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('avant-garde','avant_garde')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biker film','biker')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('buddy cop','buddy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('buddy film','buddy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('comedy 2-reeler','comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('films','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('film','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biography of pioneering american photographer eadweard muybridge','biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('british-german co-production','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('bruceploitation','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('comedy-drama adaptation of the mordecai richler novel','comedy-drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('movies by the mob\\|knkspl','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('movies','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('movie','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('coming of age','coming_of_age')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('coming-of-age','coming_of_age')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('drama about child soldiers','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('(( based).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('(( co-produced).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('(( adapted).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('(( about).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('musical b','musical')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('animationchildren','animation|children')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' period','period')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('drama loosely','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(aquatics|swimming\\)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(aquatics|swimming\\)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(\"yogesh dattatraya gosavi's directorial debut \\[9\\]\",'')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(\"war-time\",\"war\")\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(\"wartime\",\"war\")\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(\"ww1\",\"war\")\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('unknown','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(\"wwii\",\"war\")\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('psychological','psycho')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('rom-coms','romance')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('true crime','crime')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|007','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('slice of life','slice_of_life')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('computer animation','animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('gun fu','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('j-horror','horror')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(shogi|chess\\)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('afghan war drama','war drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|6 separate stories','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(30min\\)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' (road bicycle racing)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' v-cinema','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('tv miniseries','tv_miniseries')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|docudrama','\\|documentary|drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' in animation','|animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('((adaptation).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('((adaptated).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('((adapted).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('(( on ).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('american football','sports')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dev\\|nusrat jahan','sports')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('television miniseries','tv_miniseries')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(artistic\\)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\|direct-to-dvd','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('history dram','history drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('martial art','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('psycho thriller,','psycho thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|1 girl\\|3 suitors','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' \\(road bicycle racing\\)','')\n    filterE = movie_df['Genre_improved']==\"ero\"\n    movie_df.loc[filterE,'Genre_improved']=\"adult\"\n    filterE = movie_df['Genre_improved']==\"music\"\n    movie_df.loc[filterE,'Genre_improved']=\"musical\"\n    filterE = movie_df['Genre_improved']==\"-\"\n    movie_df.loc[filterE,'Genre_improved']=''\n    filterE = movie_df['Genre_improved']==\"comedy–drama\"\n    movie_df.loc[filterE,'Genre_improved'] = \"comedy|drama\"\n    filterE = movie_df['Genre_improved']==\"comedy–horror\"\n    movie_df.loc[filterE,'Genre_improved'] = \"comedy|horror\"\n    \n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(' ','|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace(',','|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('-','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actionadventure','action|adventure')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actioncomedy','action|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actiondrama','action|drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actionlove','action|love')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actionmasala','action|masala')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actionchildren','action|children')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('fantasychildren\\|','fantasy|children')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('fantasycomedy','fantasy|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('fantasyperiod','fantasy|period')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('cbctv_miniseries','tv_miniseries')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dramacomedy','drama|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dramacomedysocial','drama|comedy|social')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dramathriller','drama|thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('comedydrama','comedy|drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dramathriller','drama|thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('comedyhorror','comedy|horror')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('sciencefiction','science_fiction')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('adventurecomedy','adventure|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('animationdrama','animation|drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|\\|','|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('muslim','religious')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('thriler','thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('crimethriller','crime|thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('fantay','fantasy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actionthriller','action|thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('comedysocial','comedy|social')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('martialarts','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|\\(children\\|poker\\|karuta\\)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('epichistory','epic|history')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('erotica','adult')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('erotic','adult')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('((\\|produced\\|).+)','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('chanbara','chambara')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('comedythriller','comedy|thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biblical','religious')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biblical','religious')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('colour\\|yellow\\|productions\\|eros\\|international','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|directtodvd','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('liveaction','live|action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('melodrama','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('superheroes','superheroe')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('gangsterthriller','gangster|thriller')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('heistcomedy','comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('heist','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('historic','history')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('historydisaster','history|disaster')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('warcomedy','war|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('westerncomedy','western|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('ancientcostume','costume')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('computeranimation','animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dramatic','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('familya','family')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('familya','family')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dramedy','drama|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dramaa','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('famil\\|','family')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('superheroe','superhero')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('biogtaphy','biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('devotionalbiography','devotional|biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('docufiction','documentary|fiction')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('familydrama','family|drama')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('espionage','spy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('supeheroes','superhero')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('romancefiction','romance|fiction')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('horrorthriller','horror|thriller')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('suspensethriller','suspense|thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('musicaliography','musical|biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('triller','thriller')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|\\(fiction\\)','|fiction')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('romanceaction','romance|action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('romancecomedy','romance|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('romancehorror','romance|horror')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('romcom','romance|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('rom\\|com','romance|comedy')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('satirical','satire')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('science_fictionchildren','science_fiction|children')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('homosexual','adult')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('sexual','adult')\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('mockumentary','documentary')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('periodic','period')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('romanctic','romance')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('politics','political')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('samurai','martial_arts')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('tv_miniseries','series')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('serial','series')\n\n    filterE = movie_df['Genre_improved']==\"musical–comedy\"\n    movie_df.loc[filterE,'Genre_improved'] = \"musical|comedy\"\n\n    filterE = movie_df['Genre_improved']==\"roman|porno\"\n    movie_df.loc[filterE,'Genre_improved'] = \"adult\"\n\n\n    filterE = movie_df['Genre_improved']==\"action—masala\"\n    movie_df.loc[filterE,'Genre_improved'] = \"action|masala\"\n\n\n    filterE = movie_df['Genre_improved']==\"horror–thriller\"\n    movie_df.loc[filterE,'Genre_improved'] = \"horror|thriller\"\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('family','children')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('martial_arts','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('horror','thriller')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('war','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('adventure','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('science_fiction','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('western','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('western','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('noir','black')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('spy','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('superhero','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('social','')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('suspense','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('sex','adult')\n\n\n    filterE = movie_df['Genre_improved']==\"drama|romance|adult|children\"\n    movie_df.loc[filterE,'Genre_improved'] = \"drama|romance|adult\"\n\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('\\|–\\|','|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.strip(to_strip='\\|')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('actionner','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('love','romance')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('crime','mystery')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('kids','children')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('boxing','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('buddy','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('cartoon','animation')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('cinema','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('religious','supernatural')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('christian','supernatural')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('lgbtthemed','romance')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('detective','mystery')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('nature','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('fiction','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('music','artistic')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('musical','artistic')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('short','artistic')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('mythology','supernatural')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('mythological','supernatural')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('masala','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('military','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('sexploitation','adult')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('tragedy','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('murder','mystery')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('disaster','drama')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('documentary','biography')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('dance','artistic')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('cowboy','action')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('anthology','artistic')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('artistical','artistic')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.replace('art','artistic')\n    movie_df['Genre_improved']=movie_df['Genre_improved'].str.strip()\n    return movie_df['Genre_improved']","metadata":{"_uuid":"23274ccf-4a2a-4c80-89d8-6f67b04965bb","_cell_guid":"ef2f0499-6bca-498b-8cfb-71f23390b10c","execution":{"iopub.status.busy":"2021-07-14T14:04:22.407919Z","iopub.execute_input":"2021-07-14T14:04:22.408663Z","iopub.status.idle":"2021-07-14T14:04:22.521243Z","shell.execute_reply.started":"2021-07-14T14:04:22.408608Z","shell.execute_reply":"2021-07-14T14:04:22.52053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![meme](http://katbailey.github.io/mf/images/netflix-problems.jpeg)","metadata":{}},{"cell_type":"code","source":"def group_genre(Genre_improved):\n    '''\n    After cleaning the Genre we have grouped similar set of genres together. For Example: action|comedy and \n    comedy|action were considered two different set of genres previously but in this function we have rectified it.\n    We have also restricted our genre categories to some selected categories as mentioned in the list \"list_genre\".\n    \n    '''\n    movie_df['Genre_grouped'] = movie_df['Genre_improved']\n    list_genre = ['action','adult','animation','children','comedy','drama','fantasy','romance','supernatural',\n                 'biography','history','thriller','science','mystery','series','artistic']\n    for i in range(len(movie_df['Genre_improved'])):\n        genre = movie_df['Genre_improved'][i]\n        k = genre.split(\"|\")\n        k = set(k)\n        k = sorted(k)\n        k = [u for u in k if u in list_genre]\n        k = [x for x in k if x]\n        final = \"|\".join(k)\n        movie_df['Genre_grouped'][i] = final\n    movie_df['Genre_grouped'] = movie_df['Genre_grouped'].replace('','Default')\n    return movie_df['Genre_grouped']","metadata":{"_uuid":"5ead110c-b9eb-40cb-9666-c2e42dcb54e0","_cell_guid":"761a4192-06cb-4a3f-98fe-1c6527f8ad2a","execution":{"iopub.status.busy":"2021-07-14T17:15:55.172658Z","iopub.execute_input":"2021-07-14T17:15:55.172944Z","iopub.status.idle":"2021-07-14T17:15:55.18104Z","shell.execute_reply.started":"2021-07-14T17:15:55.172897Z","shell.execute_reply":"2021-07-14T17:15:55.180182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_Process_data(documents):\n    '''\n    For preprocessing we have regularized, transformed each upper case into lower case, tokenized,\n    Normalized and remove stopwords. For normalization, we have used PorterStemmer. Porter stemmer transforms \n    a sentence from this \"love loving loved\" to this \"love love love\"\n    \n    '''\n    STOPWORDS = set(stopwords.words('english'))\n    stemmer = PorterStemmer()\n    Tokenized_Doc=[]\n    print(\"Pre-Processing the Data.........\\n\")\n    for data in tqdm(documents):\n        review = re.sub('[^a-zA-Z]', ' ', data)\n        gen_docs = [w.lower() for w in word_tokenize(review)] \n        tokens = [stemmer.stem(token) for token in gen_docs if not token in STOPWORDS]\n        final_=' '.join(tokens)\n        Tokenized_Doc.append(final_)\n    return Tokenized_Doc","metadata":{"_uuid":"26decfae-c37e-4658-90d6-d1f8f61141bf","_cell_guid":"d274d058-3298-4b84-bf95-37061e872bed","execution":{"iopub.status.busy":"2021-07-14T17:15:55.919957Z","iopub.execute_input":"2021-07-14T17:15:55.92043Z","iopub.status.idle":"2021-07-14T17:15:55.929364Z","shell.execute_reply.started":"2021-07-14T17:15:55.92039Z","shell.execute_reply":"2021-07-14T17:15:55.927598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Term-document matrix\n**term-document matrix** describes the occurrences of terms in documents; it is a sparse matrix whose rows correspond to terms and whose columns correspond to documents. A typical example of the weighting of the elements of the matrix is tf-idf (term frequency–inverse document frequency): the weight of an element of the matrix is proportional to the number of times the terms appear in each document, where rare terms are upweighted to reflect their relative importance. <br>\nThis matrix is also common to standard semantic models, though it is not necessarily explicitly expressed as a matrix, since the mathematical properties of matrices are not always used. <br>\nSource - Wikipedia","metadata":{}},{"cell_type":"code","source":"def Vectorization(processed_data):\n    '''\n    Vectorization is an important step in Natural Language Processing. We have\n    Used Tf_Idf vectorization in this script. The n_gram range for vectorization \n    lies between 2 and 3, that means minimum and maximum number of words in \n    the sequence that would be vectorized is two and three respectively. There\n    are other different types of vectorization algorithms also, which could be added to this \n    function as required.\n    \n    '''\n    vectorizer = TfidfVectorizer(stop_words='english', \n                                    max_features= 20000,#200000, # keep top 200000 terms \n                                    min_df = 1, ngram_range=(1,1), #(2,3),\n                                    smooth_idf=True)\n    X = vectorizer.fit_transform(processed_data)\n    print(\"\\n Shape of the document-term matrix\")\n    print(X.shape) # check shape of the document-term matrix\n    return X, vectorizer","metadata":{"_uuid":"6ea6b8dc-4707-48aa-b597-130de0bfc82d","_cell_guid":"a82cc84a-36eb-4675-8437-704e3a042e12","execution":{"iopub.status.busy":"2021-07-14T17:15:58.985203Z","iopub.execute_input":"2021-07-14T17:15:58.986132Z","iopub.status.idle":"2021-07-14T17:15:58.992766Z","shell.execute_reply.started":"2021-07-14T17:15:58.985436Z","shell.execute_reply":"2021-07-14T17:15:58.991616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def topic_modeling(model,X):\n    '''\n    We have used three types of decomposition algorithm for unsupervised learning, anyone could \n    be selected with the help of the \"model\" parameter. Three of them are TruncatedSVD ,Latent\n    Dirichlet Allocation and Matrix Factorization. This function is useful for comparing\n    different model performances, by switching between different algorithms with the help of \n    the \"model\" parameter and also more algorithms could be easily added to this function.\n    \n    '''\n    components = 16\n    if model=='svd':\n        print(\"\\nTrying out Truncated SVD......\")\n        model_ = TruncatedSVD(n_components=components, algorithm='randomized', n_iter=1000, random_state=42)\n        model_.fit(X)\n    if model=='MF':\n        print(\"\\nTrying out Matrix Factorization......\")\n        model_ = NMF(n_components=components, random_state=1,solver='mu',\n                      beta_loss='kullback-leibler', max_iter=1000, alpha=.1,\n                      l1_ratio=.5).fit(X)\n        model_.fit(X)\n    if model=='LDA':\n        print(\"\\nTrying out Latent Dirichlet Allocation......\")\n        #Tokenized_Doc=[doc.split() for doc in processed_data]\n        #dictionary = Dictionary(Tokenized_Doc)\n        #corpus = [dictionary.doc2bow(tokens) for tokens in Tokenized_Doc]\n        #model_ = LdaModel(corpus, num_topics=components, id2word = dictionary)\n        model_ = LatentDirichletAllocation(n_components=components,max_iter=40,n_jobs=-1,\n                                           random_state=42,verbose=0,learning_decay=0.3,\n                                           learning_offset=30.\n                                          )\n        model_.fit(X)\n\n    return model_","metadata":{"_uuid":"16012694-ad26-4cac-8d4f-f38af4433774","_cell_guid":"73273b78-a13f-4540-9a4d-82f857b18663","execution":{"iopub.status.busy":"2021-07-14T17:16:00.279738Z","iopub.execute_input":"2021-07-14T17:16:00.280013Z","iopub.status.idle":"2021-07-14T17:16:00.288553Z","shell.execute_reply.started":"2021-07-14T17:16:00.279967Z","shell.execute_reply":"2021-07-14T17:16:00.287023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Get_MostImportant_words(model, vectorizer):\n    '''\n    This function is used to evaluate top twenty most important words under each category.\n    '''\n    terms = vectorizer.get_feature_names()\n\n    for i, comp in enumerate(model.components_):\n        terms_comp = zip(terms, comp)\n        sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:30]\n        print(\"Category \"+str(i)+\": \")\n        for t in sorted_terms:\n            print(t[0],end =\", \")\n        print(\"\\n\")","metadata":{"_uuid":"84e735a1-a683-43e3-b4a5-14c4b7e28003","_cell_guid":"b246a793-8041-4636-b8bf-8c3e3a51e68e","execution":{"iopub.status.busy":"2021-07-14T17:16:01.636483Z","iopub.execute_input":"2021-07-14T17:16:01.636784Z","iopub.status.idle":"2021-07-14T17:16:01.642852Z","shell.execute_reply.started":"2021-07-14T17:16:01.636735Z","shell.execute_reply":"2021-07-14T17:16:01.642171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Visualize_clusters(model_, title):\n    '''\n    This function is used to visualize the clusters generated by our \n    model through unsupervised learning. We have used UMAP for better \n    visualization of clusters.\n    \n    '''\n    X_topics = model_.fit_transform(X)\n    embedding = umap.UMAP(n_neighbors=10,random_state=42).fit_transform(X_topics)#20\n\n    plt.figure(figsize=(20,20))\n    plt.title(title,fontsize=16)\n    plt.scatter(embedding[:, 0], embedding[:, 1], \n    c = movie_df['Genre_grouped'],cmap='Spectral', alpha=1.0,\n    s = 10, # size\n    )\n    plt.show()","metadata":{"_uuid":"9c2ffa57-3e4f-4591-946e-115e333df392","_cell_guid":"a61659af-25d2-4f49-8da1-c8d8eec2674b","execution":{"iopub.status.busy":"2021-07-14T17:16:10.852897Z","iopub.execute_input":"2021-07-14T17:16:10.853476Z","iopub.status.idle":"2021-07-14T17:16:10.861051Z","shell.execute_reply.started":"2021-07-14T17:16:10.85343Z","shell.execute_reply":"2021-07-14T17:16:10.860369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#movie_df['Genre_improved'] = Data_Cleaning(movie_df['Genre'])\nmovie_df['Plot'][0]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T17:16:12.4573Z","iopub.execute_input":"2021-07-14T17:16:12.457832Z","iopub.status.idle":"2021-07-14T17:16:12.737287Z","shell.execute_reply.started":"2021-07-14T17:16:12.457791Z","shell.execute_reply":"2021-07-14T17:16:12.735438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_df['Genre_improved'] = Data_Cleaning(movie_df['Genre'])\nmovie_df['Genre_grouped'] = group_genre(movie_df['Genre_improved'])\nmovie_df = movie_df[movie_df['Genre_grouped']!='Default']# Defalut categories are removed\nprocessed_data = pre_Process_data(movie_df['Plot'])","metadata":{"_uuid":"93af2e93-2312-45df-9ff2-78b2f72aa551","_cell_guid":"3beb82fd-78cd-4aea-9583-908013dc2590","execution":{"iopub.status.busy":"2021-07-14T14:10:59.772124Z","iopub.execute_input":"2021-07-14T14:10:59.772408Z","iopub.status.idle":"2021-07-14T14:15:20.119595Z","shell.execute_reply.started":"2021-07-14T14:10:59.772375Z","shell.execute_reply":"2021-07-14T14:15:20.118264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique, counts = np.unique(movie_df['Genre_grouped'], return_counts=True)\nfor x,y in zip(unique,counts):\n    print(x+\" -> \"+str(y))","metadata":{"_uuid":"2b5a87e1-f453-4b97-9037-24c2bef7acc8","_cell_guid":"7296793a-3b4d-475e-ba8a-e4a38588fc58","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-14T14:15:20.120986Z","iopub.execute_input":"2021-07-14T14:15:20.121205Z","iopub.status.idle":"2021-07-14T14:15:20.163525Z","shell.execute_reply.started":"2021-07-14T14:15:20.121175Z","shell.execute_reply":"2021-07-14T14:15:20.162298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_df['Genre_grouped'] = movie_df['Genre_grouped'].astype(\"category\").cat.codes","metadata":{"_uuid":"88e51f39-585c-4467-8974-415961d30995","_cell_guid":"00a0f4ac-7602-481f-8b15-5cc96a2f3525","execution":{"iopub.status.busy":"2021-07-14T14:15:55.386034Z","iopub.execute_input":"2021-07-14T14:15:55.386326Z","iopub.status.idle":"2021-07-14T14:15:55.405286Z","shell.execute_reply.started":"2021-07-14T14:15:55.386278Z","shell.execute_reply":"2021-07-14T14:15:55.403738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, vectorizer = Vectorization(processed_data)","metadata":{"_uuid":"3d115bb1-0870-4242-9c7c-54e0a55c096b","_cell_guid":"e05eb2da-8dda-42ed-8373-a3f8d8fd6b09","execution":{"iopub.status.busy":"2021-07-14T15:17:28.123249Z","iopub.execute_input":"2021-07-14T15:17:28.123664Z","iopub.status.idle":"2021-07-14T15:17:33.679214Z","shell.execute_reply.started":"2021-07-14T15:17:28.123631Z","shell.execute_reply":"2021-07-14T15:17:33.678636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vectorizer.get_feature_names()","metadata":{"_uuid":"0331df80-fa99-4928-a260-d0b5061a7859","_cell_guid":"d3df8b91-fa4d-40fc-b43f-737f11ebfbc4","execution":{"iopub.status.busy":"2021-07-14T15:17:37.126796Z","iopub.execute_input":"2021-07-14T15:17:37.127132Z","iopub.status.idle":"2021-07-14T15:17:37.130822Z","shell.execute_reply.started":"2021-07-14T15:17:37.127047Z","shell.execute_reply":"2021-07-14T15:17:37.130033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Different types of Recommender System Algorithm\n![Collaborative filtering](https://miro.medium.com/max/4056/1*yrkvweErbifbPFkBUyZlOw.png)\n1. Content based filtering - This algorithm recommends products \n    which are similar to the ones that a user has liked in the past.\n    The example which I elaborated to explain what is a recommendation system \n    at the beginning of this Notebook, strictly belong to this category.\n\n2. Collaborative filtering - It is strictly based on the proverb \"Birds of Same\n    feather flock together\". Persons of similar taste are assumed to have similar\n    topics of interest.\n\nFor more detailed Explaination \nplease refer to this link -  https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/\n","metadata":{"_uuid":"d661a413-3f9b-4a72-b36c-8becdf09c043","_cell_guid":"a490712a-3b29-4f56-9bbb-899fc85f2e21","trusted":true}},{"cell_type":"markdown","source":"## Matrix Factorization\nMatrix factorization is a class of collaborative filtering algorithms used\nin recommender systems. Matrix factorization algorithms work by decomposing\nthe user-item interaction matrix into the product of two lower dimensionality\nrectangular matrices.The idea behind matrix factorization is to represent users\nand items in a lower dimensional latent space. Source: Wikipedia.<br>Division of matrix is such that if we multiply factorized matrix we will get original matrix.<br> \nMatrix Factorization is another technique for unsupervised NLP machine learning. \nThis uses “latent factors”  to break a large matrix down into the combination of\ntwo smaller matrices. Latent factors are similarities between the items.\nSource: https://www.lexalytics.com/lexablog/machine-learning-vs-natural-language-processing-part-1.\nTo know about Matrix Factorization refer to this \nlink - http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/,\nhttps://medium.com/@paritosh_30025/recommendation-using-matrix-factorization-5223a8ee1f4\n","metadata":{"_uuid":"e9c4f748-f7d0-4418-90b7-03c188ca9c10","_cell_guid":"0f48435b-ede6-4e0c-ac8f-263d9dc76eec","trusted":true}},{"cell_type":"code","source":"model_1 = topic_modeling('MF',X)","metadata":{"_uuid":"fcc4676a-91f0-4675-9db8-44c23ed848c1","_cell_guid":"3cff2d9b-f297-4148-9429-6b5edcedd815","execution":{"iopub.status.busy":"2021-07-14T17:16:31.397365Z","iopub.execute_input":"2021-07-14T17:16:31.397674Z","iopub.status.idle":"2021-07-14T17:21:30.924005Z","shell.execute_reply.started":"2021-07-14T17:16:31.397609Z","shell.execute_reply":"2021-07-14T17:21:30.923138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Most Important words under each Category using Matrix Factorization.\\n\")\nGet_MostImportant_words(model_1, vectorizer)","metadata":{"_uuid":"393a545a-248a-4580-ac16-699062b9ddf4","_cell_guid":"e5cb894d-9e98-468c-ac69-6a2d09e2f55a","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-14T17:21:30.925359Z","iopub.execute_input":"2021-07-14T17:21:30.925534Z","iopub.status.idle":"2021-07-14T17:21:31.255134Z","shell.execute_reply.started":"2021-07-14T17:21:30.925506Z","shell.execute_reply":"2021-07-14T17:21:31.254238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Visualize_clusters(model_1, \"Clustering for Matrix Factorization\")","metadata":{"_uuid":"a7152bfd-d60f-4226-9d67-25139728af11","_cell_guid":"27afb11d-dc25-447c-ac07-afe5e42501db","execution":{"iopub.status.busy":"2021-07-14T17:21:31.256298Z","iopub.execute_input":"2021-07-14T17:21:31.256532Z","iopub.status.idle":"2021-07-14T17:24:27.907386Z","shell.execute_reply.started":"2021-07-14T17:21:31.256492Z","shell.execute_reply":"2021-07-14T17:24:27.905886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Latent Semantic Analysis (LSA)\nLatent Semantic Indexing (LSI) technique identifies on words and phrases that\nfrequently occur with each other. Data scientists use LSI for faceted searches,\nor for returning search results that aren’t the exact search term.Latent Semantic \nAnalysis (LSA) attempts to leverage the context around the words to capture the \nhidden concepts, also known as topics. singular-value decomposition (SVD) is an \nimportant step in LSA.<br>\nfrom the theory of linear algebra, there exists a decomposition of **X** such that **U** and **V** are orthogonal matrices and **Σ** is a diagonal matrix. This is called a **singular value decomposition (SVD)**\n\n    X = U Σ V T \nA matrix containing word counts per paragraph (rows represent unique words and columns represent each paragraph) is constructed from a large piece of text and a mathematical technique called singular value decomposition (SVD) is used to reduce the number of rows while preserving the similarity structure among columns.<br>\n**Pros:**\n1. LSA is fast and easy to implement.\n2. It gives decent results, much better than a plain vector space model.<br>\n\n**Cons:**\n1. Since it is a linear model, it might not do well on datasets with non-linear dependencies.\n2. LSA assumes a Gaussian distribution of the terms in the documents, which may not be true for all problems.\n3. LSA involves SVD, which is computationally intensive and hard to update as new data comes up.<br>\n\nSource: https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/\n","metadata":{"_uuid":"9a325c2e-75b4-45fe-8261-159f19bb3b34","_cell_guid":"354267a9-231c-4d45-ac6e-dfef7834bdeb","trusted":true}},{"cell_type":"code","source":"model_2 = topic_modeling('svd',X)","metadata":{"_uuid":"5f738b48-b25a-42a1-8365-f623f68c1053","_cell_guid":"0ddda556-5b34-4e01-8397-380717362a5d","execution":{"iopub.status.busy":"2021-07-14T16:56:38.768368Z","iopub.execute_input":"2021-07-14T16:56:38.768694Z","iopub.status.idle":"2021-07-14T17:02:20.347149Z","shell.execute_reply.started":"2021-07-14T16:56:38.768632Z","shell.execute_reply":"2021-07-14T17:02:20.345567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Most Important words under each Category using Latent Semantic Analysis.\\n\")\nGet_MostImportant_words(model_2, vectorizer)","metadata":{"_uuid":"fddb2547-f6f1-40e3-a9eb-b5a250c81c10","_cell_guid":"5c3e2c8a-8fa1-44e7-ac32-5ab14cc8cb1f","execution":{"iopub.status.busy":"2021-07-14T17:02:20.348825Z","iopub.execute_input":"2021-07-14T17:02:20.349024Z","iopub.status.idle":"2021-07-14T17:02:21.482937Z","shell.execute_reply.started":"2021-07-14T17:02:20.348994Z","shell.execute_reply":"2021-07-14T17:02:21.481729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Visualize_clusters(model_2, \"Clustering for Truncated SVD\")","metadata":{"_uuid":"5d91ad0a-b14b-401a-bb53-5957cb1b7b83","_cell_guid":"5f9a5a0f-9eda-4966-900a-cbc5ab7ff3d7","execution":{"iopub.status.busy":"2021-07-14T17:02:21.484191Z","iopub.execute_input":"2021-07-14T17:02:21.484473Z","iopub.status.idle":"2021-07-14T17:08:26.900647Z","shell.execute_reply.started":"2021-07-14T17:02:21.484414Z","shell.execute_reply":"2021-07-14T17:08:26.899343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Latent Dirichlet Allocation for Topic Modeling\nIn natural language processing, latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics.<br>\nSource - Wikipedia<br>\nlatent Dirichlet allocation(LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in-turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document.<br>\nSource - [Journal of Machine Learning Research 3 (2003) 993-1022Submitted 2/02; Published 1/03Latent Dirichlet Allocation](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)","metadata":{}},{"cell_type":"code","source":"model_3 = topic_modeling('LDA',X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Most Important words under each Category using Latent Dirichlet Allocation.\\n\")\nGet_MostImportant_words(model_3, vectorizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Visualize_clusters(model_3, \"Clustering for LDA\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**According to my opinion Matrix Factorization and LDA clustered in a much better way compared to SVD.\nApart from LDA There are other advanced and efficient topic modeling techniques also\nwhich could be applied and analyze their performance in case of unsupervised learning.\n**","metadata":{"_uuid":"c2987e24-d56d-4800-8cec-0348f537b5e9","_cell_guid":"8ea75798-c716-489d-b7f8-fefb7e57c7ca","trusted":true}},{"cell_type":"markdown","source":"**I have also created a utility Script concerning this kernel. You could use my Utility Script to develop your model by adding it to your notebook or even improve my work to further level.**<br>\n**Link -** http://bit.ly/2MdWq3g","metadata":{}},{"cell_type":"markdown","source":"### ======  **I hope this Kernel was informative and was helpful to you** ===========\n## ======================= **(ﾉ^_^)ﾉ** =============================\n### =============== **Please Upvote this Kernel if you like it....** ================\n\n### ======================== **Thank you** ====================================","metadata":{}}]}