{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grocery Expenses Analysis\n\nHere's I'm gonna to analyze all the data that I've collected about my family grocery expenses","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filepath = '../input/grocery-exprenses/spesa_dataset.csv'\ndf = pd.read_csv(filepath, delimiter=\";\", encoding = \"cp1252\")\ndf.head(-10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preliminary Pre-processing\n\nFirst of all, let's check if there are any inconsistencies in the dataset. We're going to do it by checking the type of the dataframe columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fixme:to remove, it's just a temporary error\ndf.loc[df['giorno'] == 'Lidl24/08/2020']\ndf.loc[907, 'giorno'] = '24/08/2020'\n\ndf.loc[906, 'supermercato'] = 'Lidl'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parsing dates\n\nSince 'giorno' (in italian) means day in english, let's cast the 'giorno' column as a datetime object. This will allow us to group our data using this column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['giorno'] = pd.to_datetime(df['giorno'], infer_datetime_format=True)\n\nprint(df.giorno.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean incosistent text entries\n\nNow let's just see if the text values has some error in it.\n\nWe're going to look at the supermarket feature first.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"supermarkets = df['supermercato'].unique()\n\nsupermarkets.sort()\nsupermarkets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking the previos result, we can see a incosistent data entry: 'Lidl' and 'Lidl ' due to an additional space in the second entry. \nSo by just removing the white space, everything should be fine.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['supermercato'] = df['supermercato'].str.strip()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we going the same process for the 'tipo' column ('tipo' means 'type' in english). But before doing it, let's see if there are some missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_types = df['tipo'].isnull().sum()\n\nmissing_types","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So by default, to the grocery items which I don't know how to categorize, I give them the type 'none'. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tipo'] = df['tipo'].fillna('none')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After we have no more missing values, let's list all the unique values in the type columns in order to seek for inconsistencies.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"types = df['tipo'].unique()\n\ntypes.sort()\ntypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking at the types list we can see that there are a lot inconsistencies. For example: 'frutta secca' and 'fruttasecca' or 'dolce' and 'dolci' and a lot more.\n\nHere's I'm gonna make a list with all the inconsistencies in the types, and I'm gonna use the fuzzywuzzy package to help me identify which string are closest to each other. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import fuzzywuzzy\nfrom fuzzywuzzy import process\nimport chardet\n\nincostencies = [\"frutta secca\", \"passata pomodoro\", \"bevande\",\"dolce\",\"integratore\",\"briosche\",\"aceto\",\"borsa spesa\",\"gnocchi\",\"crackers\"]\n\nmatches_list = []\n\nfor el in incostencies:\n    matches = fuzzywuzzy.process.extract(el, types, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n    print(matches, end='\\n\\n')\n    matches_list.append(matches)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What I'm interestin in here is to replace all the second values of the matches with the first, so let's write a function to help us to  do that. We'll call it *replace_second_match()*.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_second_match(df:pd.DataFrame, column:str, matches:list):\n    close_matches = [matches[1][0]]\n    row_with_matches = df[column].isin(close_matches)\n    \n    df.loc[row_with_matches, column] = matches[0][0] \n    \nfor el in matches_list:\n    replace_second_match(df, 'tipo', el)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types = df['tipo'].unique()\n\ntypes.sort()\ntypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see now the list looks better, even though we have to make some adjustment manually because some types that are synonyms or includes other types , but they doesn't looks similar.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"row_with_matches = df['tipo'].isin(['arachidi'])\n    \ndf.loc[row_with_matches, 'tipo'] = 'frutta secca'\n\nrow_with_matches = df['tipo'].isin(['bibite'])\n    \ndf.loc[row_with_matches, 'tipo'] = 'bevande'\n\nrow_with_matches = df['tipo'].isin(['gnochetti'])\n    \ndf.loc[row_with_matches, 'tipo'] = 'gnocchi'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Basic Statistic About Each feature of the dataset\n\nAfter cleaning the inconsistencies let's take a look at the basic stats about each feature of the dataset. \n\nWe'll start by looking the numerical Features and then we'll look at the categorical feature.\n\n### Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# just a simple description of the dataset\ndf.describe(include=np.number)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# most frequent name in the grocery dataset\ndf['nome'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# most frequent type of grocery item in the dataset\ndf['tipo'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# most frequent supermarket on the dataset\ndf['supermercato'].mode()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Most bought items","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def fromSeriesToLists(pd_serie, threshold=0):\n    keys = []\n    values = []\n    \n    for key, value in pd_serie.items():\n        if value > threshold:\n            keys.append(key)\n            values.append(value)\n            \n    return keys, values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_freq_items = df.nome.value_counts()\n\nnames, values = fromSeriesToLists(most_freq_items, 4)\n\nfreq_items_df = pd.DataFrame(\n    data = {\n        'Names': names, \n        'Values':values\n    }\n)\n\nsns.barplot(x=freq_items_df['Names'], y=freq_items_df['Values'])\nplt.xticks(rotation=70)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Most Frequent Grocery Item Types","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"most_freq_types = df.tipo.value_counts()\n\nnames, values = fromSeriesToLists(most_freq_types, 15)\n\n\nfreq_types_df = pd.DataFrame(\n    data = {\n        'Names': names, \n        'Values':values\n    }\n)\n\nsns.barplot(x=freq_types_df['Names'], y=freq_types_df['Values'])\nplt.xticks(rotation=70)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Supermarket Frequencies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"most_freq_super = df.supermercato.value_counts()\n\nnames, values = fromSeriesToLists(most_freq_super)\n\n\nfreq_super_df = pd.DataFrame(\n    data = {\n        'Names': names, \n        'Values':values\n    }\n)\n\nsns.barplot(x=freq_super_df['Names'], y=freq_super_df['Values'])\nplt.xticks(rotation=70)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Price Analysis\n\n- price distribution: First of all let's visualize how the price is distributing in the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(a=df['prezzo'], kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- how much we spend per type (the most frequent type)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# tot = df.groupby(['tipo']).sum()\n# freq_type_name = freq_types_df.Names\n\n# tot.reset_index(drop=True, inplace=True)\n\n# # tot = tot[tot['tipo'].isin(freq_type_name)]\n\n# tot\n# # sns.barplot(x=tot[tot.isin(freq_type_name)], y=tot[tot['prezzo'].isin(freq_type_name)])\n# # plt.xticks(rotation=70)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- total expenditure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# total for now\ndf['prezzo'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weekly stats\n\nIn the weekly statistic I include how much we spend per week, the average price we spend per day, and the medium price we spend per item and its standard deviation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['giorno'] = pd.to_datetime(df['giorno'], infer_datetime_format=True)\nweekly_gr = df.groupby(df.giorno.dt.strftime('%W'))\n\nweekly = {\n    'week':[],\n    'weekly_shopping': [], \n    'amount_per_day': [], \n    'price_mean': [],\n    'price_std': [],\n    'most_freq_item': [],\n    'most_freq_type':[]\n}\n\nfor name, group in weekly_gr:\n    if len(group) > 0:\n        tot = group.prezzo.sum()\n        tot_per_day = tot / 7\n        mean = group.prezzo.mean()\n        std = group.prezzo.std()\n        weekly['week'].append(name)\n        weekly['weekly_shopping'].append(tot)\n        weekly['amount_per_day'].append(tot_per_day)\n        weekly['price_mean'].append(mean)\n        weekly['price_std'].append(std)\n        weekly['most_freq_item'].append(group.nome.value_counts().idxmax())\n        weekly['most_freq_type'].append(group.tipo.value_counts().idxmax())\n\nweekly_df = pd.DataFrame(weekly)\nweekly_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stats about the weekly expenditure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly_df.describe(include=np.number)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of the weekly expenses and daily amount \nNow Let's see the distribution of the weekly shopping amount and the weekly expense amount per day.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2)\nsns.distplot(a=weekly_df['weekly_shopping'], kde=False, ax=axs[0])\nsns.distplot(a=weekly_df['amount_per_day'], kde=False,bins=5, ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Monthly Stats\n\nSame parameters of the weekly stats but monthly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_gr = df.groupby(df.giorno.dt.strftime('%m'))\n\nmonthly = {\n    'month':[],\n    'monthly_shopping': [], \n    'amount_per_week': [], \n    'price_mean': [],\n    'price_std': [],\n    'most_freq_item': [],\n    'most_freq_type':[]\n}\n\nfor name, group in monthly_gr:\n    if len(group) > 0:\n        tot = group.prezzo.sum()\n        tot_per_day = tot / 4\n        mean = group.prezzo.mean()\n        std = group.prezzo.std()\n        monthly['month'].append(name)\n        monthly['monthly_shopping'].append(tot)\n        monthly['amount_per_week'].append(tot_per_day)\n        monthly['price_mean'].append(mean)\n        monthly['price_std'].append(std)\n        monthly['most_freq_item'].append(group.nome.mode()[0])\n        monthly['most_freq_type'].append(group.tipo.mode()[0])\n\nmonthly_df = pd.DataFrame(monthly)\nmonthly_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stats about the monthly expenditure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_df.describe(include=np.number)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of monthly expenses","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(a=monthly_df['monthly_shopping'], kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Yearly stats","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yearly_gr = df.groupby(df.giorno.dt.strftime('%Y'))\n\nyearly = {\n    'year':[],\n    'yearly_shopping': [], \n    'amount_per_month': [], \n    'price_mean': [],\n    'price_std': [],\n    'most_freq_item': [],\n    'most_freq_type':[]\n}\n\nfor name, group in yearly_gr:\n    if len(group) > 0:\n        tot = group.prezzo.sum()\n        tot_per_day = tot / 4\n        mean = group.prezzo.mean()\n        std = group.prezzo.std()\n        yearly['year'].append(name)\n        yearly['yearly_shopping'].append(tot)\n        yearly['amount_per_month'].append(tot_per_day)\n        yearly['price_mean'].append(mean)\n        yearly['price_std'].append(std)\n        yearly['most_freq_item'].append(group.nome.mode()[0])\n        yearly['most_freq_type'].append(group.tipo.mode()[0])\n\nyearly_df = pd.DataFrame(yearly)\nyearly_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}