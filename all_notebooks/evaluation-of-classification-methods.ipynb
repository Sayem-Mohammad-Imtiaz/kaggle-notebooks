{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Evaluation of Classification Methods"},{"metadata":{},"cell_type":"markdown","source":"![](https://healthnavigator.blob.core.windows.net/cache/f/b/e/b/8/f/fbeb8f908aefb57046466d208d4e4444c4ee8f2e.jpg)"},{"metadata":{},"cell_type":"markdown","source":"## Contents\n1. Introduction\n2. Data Analysis\n3. Preparing Data for Machine Learning\n4. Classification Methods\n    * Logistic Regression Classification\n    * KNN Classification\n    * SVM Classification\n    * Naive Bayes Classification\n    * Decision Tree Classification\n    * Random Forest Classification\n5. Checking Classification Results with Confusion Matrix\n6. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction"},{"metadata":{},"cell_type":"markdown","source":"### What is Diabetes?\n\nDiabetes is a disease that occurs when your blood glucose, also called blood sugar, is too high. Blood glucose is your main source of energy and comes from the food you eat. Insulin, a hormone made by the pancreas, helps glucose from food get into your cells to be used for energy. Sometimes your body doesn’t make enough—or any—insulin or doesn’t use insulin well. Glucose then stays in your blood and doesn’t reach your cells.\n\nOver time, having too much glucose in your blood can cause health problems. Although diabetes has no cure, you can take steps to manage your diabetes and stay healthy."},{"metadata":{},"cell_type":"markdown","source":"### Pupose\n\nI will examine Pima Indians Diabetes Database with supervised learning algorithms and than evaluate classification methods. "},{"metadata":{},"cell_type":"markdown","source":"### Data\n\n\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\n* **Pregnancies**: Number of times pregnant\n* **Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n* **BloodPressure**: Diastolic blood pressure (mm Hg)\n* **SkinThickness**: Triceps skin fold thickness (mm)\n* **Insulin**: 2-Hour serum insulin (mu U/ml)\n* **BMI**: Body mass index (weight in kg/(height in m)^2)\n* **DiabetesPedigreeFunction**: Diabetes pedigree function\n* **Age**: Age (years)\n* **Outcome**: Class variable (0 or 1)\n"},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Analysis"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.Outcome)\nplt.title(\"Diabates Status\",color=\"black\",fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Outcome.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(figsize=(15,15))\nsns.heatmap(data.corr(),annot=True,linecolor=\"blue\",fmt=\".2f\",ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.pairplot(data, hue=\"Outcome\",palette=\"Set2\",diag_kind = \"kde\",kind = \"scatter\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Preparing Data for Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data.drop([\"Outcome\"],axis=1)\ny=data.Outcome.values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx = sc.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Classification Methods"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nlr_prediction= lr.predict(x_test)\n\nlr_cm = confusion_matrix(y_test,lr_prediction)\nprint(\"Logistic Regression Accuracy :\",lr.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 16)\nknn.fit(x_train,y_train)\nknn_prediction= knn.predict(x_test)\n\nknn_cm = confusion_matrix(y_test,knn_prediction)\nprint(\"KNN Classification Accuracy :\",knn.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = []\nfor each in range(1,25):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,25),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\nprint(\"Best accuracy is {} with K = {}\".format(np.max(score_list),1+score_list.index(np.max(score_list))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm=SVC(random_state=1)\nsvm.fit(x_train,y_train)\nsvm_prediction= svm.predict(x_test)\n\nsvm_cm = confusion_matrix(y_test,svm_prediction)\nprint(\"Support Vector Classification Accuracy :\",svm.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb=GaussianNB()\nnb.fit(x_train,y_train)\nnb_prediction= nb.predict(x_test)\n\nnb_cm = confusion_matrix(y_test,nb_prediction)\nprint(\"Naive Bayes Classification Accuracy :\",nb.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\ndt_prediction= dt.predict(x_test)\n\ndt_cm = confusion_matrix(y_test,dt_prediction)\nprint(\"Decision Tree Classification Accuracy :\",dt.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\nrf_prediction= rf.predict(x_test)\n\nrf_cm = confusion_matrix(y_test,rf_prediction)\nprint(\"Random Forest Classification Accuracy :\",rf.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Checking Classification Results with Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\n\nax1 = fig.add_subplot(3, 3, 1) # row, column, position\nax1.set_title('Logistic Regression Classification')\n\nax2 = fig.add_subplot(3, 3, 2)\nax2.set_title('KNN Classification')\n\nax3 = fig.add_subplot(3, 3, 3)\nax3.set_title('SVM Classification')\n\nax4 = fig.add_subplot(3, 3, 4)\nax4.set_title('Naive Bayes Classification')\n\nax5 = fig.add_subplot(3, 3, 5)\nax5.set_title('Decision Tree Classification')\n\nax6 = fig.add_subplot(3, 3, 6)\nax6.set_title('Random Forest Classification')\n\n\nsns.heatmap(data=lr_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax1, cmap='RdGy')\nsns.heatmap(data=knn_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax2, cmap='RdGy')   \nsns.heatmap(data=svm_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax3, cmap='RdGy')\nsns.heatmap(data=nb_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax4, cmap='RdGy')\nsns.heatmap(data=dt_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax5, cmap='RdGy')\nsns.heatmap(data=rf_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax6, cmap='RdGy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Conclusion\n* Our data is not balanced.\n* we need more diabetic patient information (outcome=1)\n* Classfication methods have low accuracy between %82 and %75.\n* Logistic Regression gave the best accuracy to us"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}