{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h3 style=\"background-color:skyblue;font-family:newtimeroman;font-size:200%;text-align:center\">Libraries And Utilities</h3>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport plotly.express as ex\nimport plotly.graph_objs as go\nfrom wordcloud import WordCloud,STOPWORDS\nstopwords = list(STOPWORDS)\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score \nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer as CVTZ\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\ndef RMSE(Y,YHAT):\n    return np.sqrt(mean_squared_error(Y,YHAT))\n\nplt.rc('figure',figsize=(20,11))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1.2\"></a>\n<h3 style=\"background-color:skyblue;font-family:newtimeroman;font-size:200%;text-align:center\">Data Importation And Missing Value Assessment</h3>\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"t_data = pd.read_csv('/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')\nt_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(t_data.isna().sum().to_frame(),annot=True,cmap='mako')\nplt.xlabel('Amount Missing',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1.2\"></a>\n<h3 style=\"background-color:skyblue;font-family:newtimeroman;font-size:200%;text-align:center\">Feature Engineering And Preprocessing</h3>\n"},{"metadata":{},"cell_type":"markdown","source":"### Remove Stopwords From Reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stop_words(sir):\n    splited = sir.split(' ')\n    splited = [word for word in splited if word not in stopwords]\n    return ' '.join(splited)\n\nt_data.Review = t_data.Review.apply(remove_stop_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sid = SentimentIntensityAnalyzer()\n\ndef get_char_count(sir):\n    return len(sir)\ndef get_word_count(sir):\n    return len(sir.split(' '))\ndef get_average_word_length(sir):\n    aux = 0\n    for word in sir.split(' '):\n        aux += len(word)\n    return aux/len(sir.split(' '))\ndef get_pos_sentiment(sir):\n    sent = sid.polarity_scores(sir)\n    return sent['pos']\ndef get_neg_sentiment(sir):\n    sent = sid.polarity_scores(sir)\n    return sent['neg']\ndef get_neu_sentiment(sir):\n    sent = sid.polarity_scores(sir)\n    return sent['neu']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_data['Char_Count'] =  t_data.Review.apply(get_char_count)\nt_data['Word_Count'] =  t_data.Review.apply(get_word_count)\nt_data['Average_Word_Length'] =  t_data.Review.apply(get_average_word_length)\nt_data['Positive_Sentiment'] =   t_data.Review.apply(get_pos_sentiment)\nt_data['Negative_Sentiment'] = t_data.Review.apply(get_neg_sentiment)\nt_data['Neutral_Sentiment'] =t_data.Review.apply(get_neu_sentiment)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1.2\"></a>\n<h3 style=\"background-color:skyblue;font-family:newtimeroman;font-size:200%;text-align:center\">Exploratory Data Analysis</h3>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_list = ''\nfor word in t_data.Review:\n    splited = word.lower()\n    word_list +=splited\n    \nwordcloud = WordCloud(width=800,height=800,background_color='white',stopwords=stopwords,min_font_size=5).generate(word_list)\nplt.figure(figsize = (25, 15), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ex.box(t_data,x='Rating',y='Positive_Sentiment',notched=True,title='Rating Positive Sentiment Distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We see that the higher the average positive sentiment the higher the rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"ex.box(t_data,x='Rating',y='Negative_Sentiment',notched=True,title='Rating Positive Sentiment Distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### And not surprisingly the higher the negative sentiment the lower the rating "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(t_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=t_data['Average_Word_Length'],y=t_data['Positive_Sentiment'],height=15,kind='kde',levels=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average_Word_Length Skew: ',t_data['Average_Word_Length'].skew(),\"  Average_Word_Length Kurtosis\",t_data['Average_Word_Length'].kurt())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average_Word_Length Mean: ',t_data['Average_Word_Length'].mean(),\"  Average_Word_Length Median\",t_data['Average_Word_Length'].median(),' Average_Word_Length Mode : ',t_data['Average_Word_Length'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The Average_Word_Length Is Approximately Normally Distributed"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_info = t_data.describe()\ndata_info.loc['skew'] = t_data.skew()\ndata_info.loc['kurt'] = t_data.kurt()\ndata_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tout_l = t_data.copy()\ntout_l['OLL'] = 'Normal'\ntout_l.loc[tout_l[tout_l['Word_Count']>1000].index,'OLL']= 'Outlier'\ntout_l.loc[tout_l[tout_l['Neutral_Sentiment']<0.25].index,'OLL']= 'Outlier'\ntout_l.loc[tout_l[tout_l['Neutral_Sentiment']>0.98].index,'OLL']= 'Outlier'\n\nex.scatter_3d(tout_l,x='Rating',y='Neutral_Sentiment',z='Word_Count',color='OLL')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outlier Removal"},{"metadata":{"trusted":true},"cell_type":"code","source":"t_data = t_data[t_data['Neutral_Sentiment']>0.25]\nt_data = t_data[t_data['Neutral_Sentiment']<0.98]\nt_data = t_data[t_data['Word_Count']<1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cors = t_data.corr('pearson')\nplt.figure(figsize=(20,13))\nsns.heatmap(cors,annot=True,cmap='mako')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1.2\"></a>\n<h3 style=\"background-color:skyblue;font-family:newtimeroman;font-size:200%;text-align:center\">Model Selection And Evaluation</h3>\n"},{"metadata":{},"cell_type":"markdown","source":"### First Approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x,test_x,train_y,test_y = train_test_split(t_data[['Positive_Sentiment','Negative_Sentiment','Average_Word_Length']],t_data['Rating'])\n\nGN_Pipe = Pipeline(steps=[('model',GaussianNB())])\nGN_Pipe.fit(train_x,train_y)\nGN_predictions= GN_Pipe.predict(test_x)\n#GN_predictions = np.round(LR_predictions)\ncfm = confusion_matrix(GN_predictions,test_y)\n\nplt.figure(figsize=(20,13))\nplt.title('Naive Bayes Confusion Matrix',fontsize=20)\nsns.heatmap(cfm,annot=True,cmap='mako',fmt='d',xticklabels=[1,2,3,4,5],yticklabels=[1,2,3,4,5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('accuracy: ',accuracy_score (LR_predictions,test_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_Pipe = Pipeline(steps=[('model',DecisionTreeClassifier())])\nDT_Pipe.fit(train_x,train_y)\npredictions= DT_Pipe.predict(test_x)\ncfm = confusion_matrix(predictions,test_y)\n\nplt.figure(figsize=(20,13))\nplt.title('Decision Tree Confusion Matrix',fontsize=20)\nsns.heatmap(cfm,annot=True,cmap='mako',fmt='d',xticklabels=[1,2,3,4,5],yticklabels=[1,2,3,4,5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('accuracy: ',accuracy_score (predictions,test_y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### So far we see that using sentiments and basic text features we have no segnificant results, we will know try our second approch in which we will vectorize our text data and use our naive bayes model again to try and predict a reduced version of the vectorized text."},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_model = CVTZ()\nN_COMPONENTS = 900\n\nsvd_model = TruncatedSVD(n_components = N_COMPONENTS)\ndesc_matrix = tf_model.fit_transform(t_data.Review)\ntrunc_matrix = svd_model.fit_transform(desc_matrix)\n\nevr = svd_model.explained_variance_ratio_\nevr_cs = np.cumsum(evr)\ntr1 = go.Scatter(x=np.arange(0,len(evr_cs)),y=evr_cs,name='Explained Variance Cumulative')\ntr2 = go.Scatter(x=np.arange(0,len(evr_cs)),y=evr,name='Explained Variance')\n\nfig = go.Figure(data=[tr1,tr2],layout=dict(title='Explained Variance Ratio Using {} Components'.format(N_COMPONENTS),\n                                          xaxis_title='Number Of Components',yaxis_title='Explained Variance Ratio'))\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dec_df = pd.DataFrame(trunc_matrix,columns=['PC_{}'.format(i) for i in range(0,900)])\ndec_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x,test_x,train_y,test_y = train_test_split(dec_df,t_data['Rating'])\n\nGN_Pipe = Pipeline(steps=[('model',GaussianNB())])\nGN_Pipe.fit(train_x,train_y)\nGN_predictions= GN_Pipe.predict(test_x)\ncfm = confusion_matrix(GN_predictions,test_y)\n\nplt.figure(figsize=(20,13))\nplt.title('Naive Bayes Confusion Matrix',fontsize=20)\nsns.heatmap(cfm,annot=True,cmap='mako',fmt='d',xticklabels=[1,2,3,4,5],yticklabels=[1,2,3,4,5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('accuracy: ',accuracy_score (GN_predictions,test_y))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}