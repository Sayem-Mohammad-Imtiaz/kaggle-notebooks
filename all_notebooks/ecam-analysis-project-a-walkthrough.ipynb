{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"text-align: center;\">\n<!-- <img src=\"jupiter.jpg\" style=\"width:150px; border-radius:100px\" /> <br /> -->\n<h1 style=\"text-align: center; width:100%\">Projet Analyse de Données</h1>\n    Equipe : <a href=\"mailto:Othmene.BENAZIEB@ecam-strasbourg.eu\">Othmène Benazieb</a>, <a href=\"mailto:Bounphathay.CHANTHASAY@ecam-strasbourg.eu\">Bounphathay Chanthasay</a>, <a href=\"mailto:lefoulervincent@gmail.com\">Vincent Le Fouler</a> <br />\n\n    Formateur : <a href=\"mailto:manuel.simoes@cpc-analytics.fr\">Manuel Simoes</a>\n\n</div>\n\n\n\n\n\n\n<style>\ndiv.warn {    \n    background-color: #fcf2f2;\n    border-color: #dFb5b4;\n    border-left: 5px solid #dfb5b4;\n    padding: 0.5em;\n    }\n</style>"},{"metadata":{},"cell_type":"markdown","source":"<div style=\"text-align: center;\">\n\n<h5 style=\"text-align: center; width:100%\">Développement d'un modèle de machine learning pour détecter les tumeurs cancéreuses dans le cadre du cancer du sein.</h5>\n\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### 1. Importation des librairies générales  "},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Chargement des données"},{"metadata":{"trusted":false},"cell_type":"code","source":"raw_data = pd.read_csv('breast_cancer.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Traitement des données\nAnalyse et exploration des données.\n* Traitement des NaN\n* Encodage de la target\n* Sélection des features\n#### 3.1 Affichage des informations"},{"metadata":{"trusted":false},"cell_type":"code","source":"raw_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"D'après la méthode .info(), seule la colonne 32 compte des NaN. Les autres colonnes comportent chacune 569 valeurs non nulles. "},{"metadata":{},"cell_type":"markdown","source":"#### 3.2 Suppression de la colonne vide 32\nLa colonne 32 \"Unname: 32\" est une colonne totalement vide. Celle-ci est supprimée."},{"metadata":{"trusted":false},"cell_type":"code","source":"raw_data.drop(columns = ['id', 'Unnamed: 32'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.3 Encodage de la target\nLa target \"diagnosis\" est encodé de manière à avoir 0 pour la valeur M et 1 pour la valeur B."},{"metadata":{"trusted":false},"cell_type":"code","source":"raw_data.replace({'B': 0, 'M': 1}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.4 Matrice de corrélation\nL'objectif est d'avoir une vue générale sur les données, de savoir qu'elles sont les features corrélées à la target et qu'elles sont les features corrélées entre elles. Et ensuite, de sélectionner les features les plus intéressantes en conséquence."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Fonction affichant une matrice de corrélation sur un set de données.\ndef corr_matrix(data, l = 25):\n    corr = data.corr()\n    plt.figure(figsize=(l,l))\n    sns.heatmap(corr, cmap='coolwarm', linecolor='white', annot=True)\n    plt.show()  \n    \ncorr_matrix(raw_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Pour un jeu de données, une target et un seuil, on retourne un dataframe ne contenant que les features corrélées à plus de x% avec la target choisie.\ndef features_selection(raw_data, target, x):\n    corr = raw_data.corr()\n    names = corr[(corr[target] > x)].index\n    filtered_data = pd.DataFrame()\n    for i in names:\n        filtered_data = pd.concat([filtered_data, raw_data[i]], axis = 1)\n    return filtered_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Application de notre fonction avec un seuil de 0.6 \nfiltered_data = features_selection(raw_data, 'diagnosis', 0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corr_matrix(filtered_data, l = 8) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Après une application de la fonction features_selection avec un seuil de 0.6, on conserve 10 features."},{"metadata":{},"cell_type":"markdown","source":"#### 3.5 Features corrélées entre elles\n\nDans un second temps, on retire les features corrélées entre elles."},{"metadata":{"trusted":false},"cell_type":"code","source":"# filtered_data.drop(columns = ['radius_mean', 'area_mean', 'radius_worst', 'area_worst'], inplace = True, axis = 1)\nfiltered_data.drop(columns = ['radius_worst', 'concave points_mean'], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corr_matrix(filtered_data, l = 6) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Après exploration des données, on conserve 6 features pour poursuivre l'étude."},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(filtered_data['diagnosis'], label = 'Count')\nB, M = filtered_data['diagnosis'].value_counts()\nprint('Number of Benign: ',B)\nprint('Number of Malignant : ',M)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il y a un nombre raisonnable de cas malins par rapport au nombre de cas bénins. Autrement, si par exemple le nombre de cas malins était très faible, notre futur algorithme aurait toujours prédit un résultat bénin, ayant considéré que la probabilité d'un cas malin était très faible."},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfiltered_data.drop('diagnosis', axis = 1).hist(bins = 50 , figsize = (15,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.pairplot(filtered_data, hue = 'diagnosis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Séparation des sets, première opération à faire sur les données\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(filtered_data.drop('diagnosis', axis = 1), filtered_data['diagnosis'], test_size = 0.2, random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.6 Normalisation des données \nPlusieurs méthodes de normalisation vont être utilisées dans le but de les comparer et de garder la plus optimale. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importation des différentes méthodes de normalisation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler \nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Fonction permettant de retourner dans un dictionnaire les données normalisées suivant différentes méthodes de normalisation.\n# La clé représente le nom de la méthode de normalisation. Sa valeur les données normalisées par elles.\ndef scale_data(data):\n    sc_data = {'Raw' : data}\n    noms = ['StandardScaler', 'MinMaxScaler', 'RobustScaler', 'Normalizer']\n    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler(), Normalizer()]\n    sc_data[noms[0]] = data\n    for i in range(0, len(scalers)):\n        sc = scalers[i]\n        sc_data[noms[i]] = sc.fit_transform(data)\n    return sc_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sc_data = scale_data(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.7 Comparaison de différents modèles"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Cross-validation\nfrom sklearn.model_selection import cross_val_predict\n\n# Modèles de classification\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Métriques\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_validation(X_train, y_train):\n    result_table = pd.DataFrame(np.empty((0, 6)))\n    result_table.columns = ['Normalization','Model', 'Precision', 'Recall', 'F1', 'ROC']\n    for k, v in X_train.items():\n        # Séparation des données en un jeu de train et de test\n        # X_train, X_test, y_train, y_test = train_test_split(v, y, test_size = 0.2, random_state = 10)\n\n        noms = ['SGDClassifier', 'LinearSVC', 'KNeighborsClassifier', 'RandomForestClassifier']\n        classifier = [SGDClassifier(random_state = 10), LinearSVC(), KNeighborsClassifier(), RandomForestClassifier()]\n\n        for i in range(0, len(classifier)):\n            cl = classifier[i]\n            # cl.fit(X_train, y_train)\n            # On effectue une cross validation. \n            y_pred = cross_val_predict(cl, v, y_train, cv = 5)\n            precision = round(precision_score(y_train, y_pred), 2)\n            recall = round(recall_score(y_train, y_pred), 2)\n            f = round(f1_score(y_train, y_pred), 2)\n            roc = round(roc_auc_score(y_train, y_pred), 2)\n            df_new_line = pd.DataFrame([[k, noms[i], precision, recall, f, roc]], columns=['Normalization','Model','Precision', 'Recall', 'F1', 'ROC'] )\n            result_table = pd.concat([result_table, df_new_line], ignore_index=True)\n    return result_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"results = train_validation(sc_data, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"results.sort_values(by = ['Recall','Precision','F1'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dans la mesure où nous avons réduit le nombre de dimension à deux features, l'intérêt d'une PCA est inexistant. C'est pour cette raison qu'elle n'a pas été testé dans le cadre du projet. "},{"metadata":{},"cell_type":"markdown","source":"D'après l'ensemble de nos essais, nous pouvons conlure que la méthode de standardisation des données importe peu, sauf dans le cas du Normalizer() qui offre des résultats bien moindre que les autres méthodes. Pour ce qui est des modèles, le LinearSVC() et le KNClassifier() semblent équivalent. En revanche, le SGDClassifier offre de moins bons résultats.\n\nPar conséquent, une étude approfondie sur le modèle LinearSVC() et KNeighborsClassifier() va être réalisées par la suite dans le but de sélectionner les meilleurs hyperparamètres du meilleur des deux modèle pour la résolution de notre problématique. "},{"metadata":{},"cell_type":"markdown","source":"### 4. Utilisation du GridSearchCV"},{"metadata":{"trusted":false},"cell_type":"code","source":"# sc_data_MinMax = sc_data['MinMaxScaler']\nsc_data_MinMax = sc_data['StandardScaler']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.1 LinearSVC"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Différents hyperparamètres de l'algorithme sont modulés, de façon à avoir in fine, les meilleurs paramètres.\nparam_grid = [\n    {'loss' : ['hinge', 'squared_hinge'],\n     'C' : range(1,100)\n    }\n    ]\n\ncl = LinearSVC(max_iter = 1000000)\n\ngrid_search_linearSVC = GridSearchCV(cl, param_grid, cv = 5, scoring = 'recall', return_train_score = True)\n\ngrid_search_linearSVC.fit(sc_data_MinMax, y_train)\nprint(grid_search_linearSVC.best_estimator_)\nprint(grid_search_linearSVC.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.2 KNeighborsClassifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Différents hyperparamètres de l'algorithme sont modulés, de façon à avoir in fine, les meilleurs paramètres.\nparam_grid = [\n    {'n_neighbors' : range(1,25),\n     'algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n     'metric' : ['euclidean', 'manhattan']\n    }\n    ]\n\ncl = KNeighborsClassifier()\n\ngrid_search_knn = GridSearchCV(cl, param_grid, cv = 5, scoring = 'recall', return_train_score = True)\n\ngrid_search_knn.fit(sc_data_MinMax, y_train)\nprint(grid_search_knn.best_estimator_)\nprint(grid_search_knn.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le modèle LinearSVC offre le meilleur recall. \nPour cette raison, il sera sélectionné comme algorithme pour notre modèle final."},{"metadata":{"trusted":false},"cell_type":"code","source":"final_model = grid_search_linearSVC.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Test du modèle final "},{"metadata":{"trusted":false},"cell_type":"code","source":"sc = MinMaxScaler()\ntest_scale_data = sc.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final_predictions = final_model.predict(test_scale_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.1 Résultats sur les métriques "},{"metadata":{"trusted":false},"cell_type":"code","source":"precision = round(precision_score(y_test, final_predictions), 2)\nrecall = round(recall_score(y_test, final_predictions), 2)\nf = round(f1_score(y_test, final_predictions), 2)\nroc = round(roc_auc_score(y_test, final_predictions), 2)\n\nprint('-----------------------------------')\nprint('Final model results')\nprint('-----------------------------------')\nprint('Accuracy : ', precision * 100, ' %')\nprint('Recall : ', recall * 100, ' %')\nprint('F1 : ', f * 100, ' %')\nprint('Auc ROC : ', roc)\nprint('-----------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.2 Résultats de la matrice de confusion"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, final_predictions)\nsns.heatmap(cm, annot = True, cmap = 'Blues_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Sauvegarde du modèle et du scaler "},{"metadata":{"trusted":false},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Sauvegarde du modèle\nfilename = 'final_model.sav'\npickle.dump(final_model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Sauvegarde du scaler\nfilename = 'sc_std.sav'\npickle.dump(sc, open(filename, 'wb'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}