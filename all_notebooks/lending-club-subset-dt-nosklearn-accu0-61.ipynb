{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"Kaggle: https://www.kaggle.com/jiuzhang/lending-club-subset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = '../input/lending-club-subset/loan_sub.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explantory Data Analyisis - Take a Glance at the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(TRAIN_DIR, sep=',', header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explantory Data Analyisis - Look at the Label"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Translate the label column 'bad_loans' (1 is bad, 0 is not bad) into 'safe_loans' (1 is good, -1 is bad)."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['safe_loans'] = train['bad_loans'].apply(lambda x: -1 if x == 1 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['safe_loans'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation: It's a imbalanced dataset, with much fewer bad loans."},{"metadata":{},"cell_type":"markdown","source":"# Explantory Data Analyisis - Look at the Features"},{"metadata":{},"cell_type":"markdown","source":"For simplicity, we only look at several features: 'grade', 'term','home_ownership', 'emp_length'."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train, x='grade', hue='safe_loans',\n              order=['A', 'B', 'C', 'D', 'E', 'F', 'G'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation: Column \"grade\" is useful. Lower grade loans are easy to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train, x='term', hue='safe_loans')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation: Column \"term\" is useful. Longer term loans are easy to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=train, x='home_ownership', hue='safe_loans')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation: Column \"home_ownership\" is useful. Owned home loans are not easy to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=45)\nsns.countplot(data=train, x='emp_length', hue='safe_loans',\n              order=['< 1 year', '1 year', '2 years', '3 years', '4 years',\n                     '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation: Column \"emp-length\" might be useful."},{"metadata":{},"cell_type":"markdown","source":"# Prepare Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def down_sampling(data, label_col):\n    labels = data[label_col].unique()\n    assert len(labels) == 2\n    \n    label1_data = data[data[label_col] == labels[0]]\n    label2_data = data[data[label_col] == labels[1]]\n    if len(label1_data) < len(label2_data):\n        label[0], label[1] = label[1], label[0]\n        label1_data, label2_data = label2_data, label1_data\n        \n    sample_percentage = len(label2_data) / len(label1_data)\n    label1_data = label1_data.sample(frac=sample_percentage)\n    return pd.concat([label1_data, label2_data], axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dummies(data, col):\n    data = pd.concat([data, pd.get_dummies(data[col], prefix=col)], axis=1)\n    return data.drop([col], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_COLUMN, X_COLUMNS = ['safe_loans'], ['grade', 'term','home_ownership', 'emp_length']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.Down-sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"balanced_train = down_sampling(train, 'safe_loans')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"balanced_train['safe_loans'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.Keep Useful Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"balanced_train = balanced_train[Y_COLUMN + X_COLUMNS]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"balanced_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.Get Dummy Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"balanced_train = get_dummies(balanced_train, 'grade')\nbalanced_train = get_dummies(balanced_train, 'term')\nbalanced_train = get_dummies(balanced_train, 'home_ownership')\nbalanced_train = get_dummies(balanced_train, 'emp_length')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"balanced_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_COLUMN, X_COLUMNS = [balanced_train.columns[0]], balanced_train.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.Training Set, Cross Validation Set, Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = balanced_train.loc[:,X_COLUMNS], balanced_train.loc[:,Y_COLUMN]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0,test_size=0.2)\nprint(f'Training Set - X train shape: {X_train.shape}, y train shape: {y_train.shape}')\nprint(f'Validation Set - X val shape: {X_val.shape}, y train shape: {y_val.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model: Decision Tree (No Sklearn)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.Model Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TreeNode:\n    def __init__(self, is_leaf, prediction, split_feature):\n        self.is_leaf = is_leaf\n        self.prediction = prediction\n        self.split_feature = split_feature\n        self.left = None\n        self.right = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecisionTree(BaseEstimator):\n    def __init__(self, max_depth, min_error, verbose=False):\n        self.max_depth = max_depth\n        self.min_error = min_error\n        self.verbose = verbose\n    \n    def fit(self, X, y):\n        features = X.columns\n        data = pd.concat([y, X], axis=1)\n        self.label_col = y.columns[0]\n        self.root_node = self.__create_tree(data, features, curr_depth=0,\n                                            max_depth=self.max_depth, min_error=self.min_error)\n        self.score = self.__calculate_score(X, y)\n        \n    def predict(self, X):\n        return X.apply(lambda row: self.__predict_single_data(self.root_node, row), axis=1)\n    \n    def __create_tree(self, data, features, curr_depth, max_depth, min_error):\n        # Exit Rule 1: No remaining features\n        if len(features) == 0:\n            if self.verbose:\n                print('No remaining features.')\n            return self.__create_leaf(data)\n        # Exit Rule 2: Reached max depth.\n        if curr_depth >= max_depth:\n            if self.verbose:\n                print('Reached max depth.')\n            return self.__create_leaf(data)\n            \n        split_feature = self.__find_best_feature(data, features)\n        features = features.drop(split_feature)\n        if self.verbose:\n            print(f'Split on feature: {split_feature}')\n        \n        left_split = data[data[split_feature] == 0]\n        right_split = data[data[split_feature] == 1]\n        \n        # Exit Rule 3: Perfect Split\n        if len(left_split) == 0:\n            if self.verbose:\n                print('Perfect Split.')\n            return self.__create_leaf(right_split)\n        if len(right_split) == 0:\n            if self.verbose:\n                print('Perfect Split.')\n            return self.__create_leaf(left_split)\n            \n        left_tree = self.__create_tree(left_split, features, curr_depth+1, max_depth, min_error)\n        right_tree = self.__create_tree(right_split, features, curr_depth+1, max_depth, min_error)\n        \n        curr_node = TreeNode(is_leaf=False, prediction=None, split_feature=split_feature)\n        curr_node.left = left_tree\n        curr_node.right = right_tree\n        \n        return curr_node\n    \n    def __create_leaf(self, data):\n        leaf = TreeNode(True, None, None)\n        num_pos = len(data[data[self.label_col] == 1])\n        num_neg = len(data[data[self.label_col] == -1])\n        if num_pos > num_neg:\n            leaf.prediction = 1\n        else:\n            leaf.prediction = -1\n        return leaf\n    \n    def __find_best_feature(self, data, features):\n        original_entropy = self.__entropy(data[self.label_col])\n        num_samples = float(len(data))\n        \n        best_feature, best_info_gain = None, float('-inf')\n        for feature in features:\n            left_split = data[data[feature] == 0]\n            right_split = data[data[feature] == 1]\n            left_entropy = self.__entropy(left_split[self.label_col])\n            right_entropy = self.__entropy(right_split[self.label_col])\n            new_entropy = len(left_split) / num_samples * left_entropy + \\\n                          len(right_split) / num_samples * right_entropy\n            info_gain = original_entropy - new_entropy\n            if info_gain > best_info_gain:\n                best_feature, best_info_gain = feature, info_gain\n        \n        return best_feature\n    \n    def __entropy(self, labels):\n        if len(labels) == 0:\n            return 0\n        \n        p = float((labels==1).sum()) / len(labels)\n        if p == 0 or p == 1:\n            return 0\n        \n        return - p*np.log2(p) - (1-p)*np.log2(1-p)\n    \n    def __predict_single_data(self, tree_node, x):\n        # Exit Rule\n        if tree_node.is_leaf:\n            return tree_node.prediction\n        \n        if x[tree_node.split_feature] == 0:\n            return self.__predict_single_data(tree_node.left, x)\n        else:\n            return self.__predict_single_data(tree_node.right, x)\n        \n    def __calculate_score(self, X, y):\n        y_pred = self.predict(X)\n        print(f'Accuracy of Training Set: {accuracy_score(y, y_pred)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.Fit with Training Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTree(max_depth=10, min_error=1e-15)\ndt.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.Predict for Validation Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = dt.predict(X_val[X_COLUMNS])\naccuracy_score(y_pred, y_val)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}