{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"100% accuracy in Iris Dataset using logitics regeration ","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n# In[38]:\n\n\n# import the libraries\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np \nfrom matplotlib import pyplot as plt, style\nstyle.use('ggplot')\n%matplotlib inline \n\n\n# datapreparation \ndf = pd.read_csv('../input/iriscsv/ird.csv')\ndf.shape\ndf.describe()\ndf.isna().sum()\nsns.pairplot( data=df, kind='scatter')\n\n# assign independent and dependent variable\n\n#heatmap using seaborn\n#set the context for plotting \nsns.set(context=\"paper\",font=\"monospace\")\niris_corr_matrix = df.corr()\n#set the matplotlib figure\nfig, axe = plt.subplots(figsize=(12,8))\n#Generate color palettes \ncmap = sns.diverging_palette(220,10,center = \"light\", as_cmap=True)\n#draw the heatmap\nsns.heatmap(iris_corr_matrix,square =True, cmap=cmap,annot=True );\n\n\n\nx=df.iloc[:,0:-1]\ny=df.Species\n\n# train and test spliting (30)\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)\n\n# standardze the data\nfrom sklearn.preprocessing import StandardScaler\nStandData = StandardScaler()\nStandData.fit(x_train)\nx_train_sd = StandData.transform(x_train)\nx_test_sd = StandData.transform(x_test)\n\n\n## bulding a model using logistic regression \nfrom sklearn.linear_model import LogisticRegression\nlogModel = LogisticRegression()\nlogModel.fit(x_train_sd, y_train)\n\nprint('Logistic regression model performance on train set:', logModel.score(x_train_sd,y_train))\nprint('Logistic regressio model performance on Test set:', logModel.score(x_test_sd,y_test)) \n\n# Picking n_neighbors for KNeighborsClassifier\ntrainAccuracy=[]\ntestAccuracy=[]\n\nfor k in range(1,20):\n    model=KNeighborsClassifier(n_neighbors=k)\n    model.fit(x_train_sd,y_train)\n    trainAccuracy.append(model.score(x_train_sd,y_train))\n    testAccuracy.append(model.score(x_test_sd,y_test))\n\nplt.figure(figsize=(12,6))\nplt.plot(range(1,20),trainAccuracy,label=\"Train Score\",marker=\"o\",markerfacecolor=\"teal\",color=\"blue\",linestyle=\"dashed\")\nplt.plot(range(1,20),testAccuracy,label=\"Test Score\",marker=\"o\",markerfacecolor=\"red\",color=\"black\",linestyle=\"dashed\")\nplt.legend()\nplt.xlabel(\"Number of Neighbors\")\nplt.ylabel(\"Score\")\nplt.title(\"Nbd Vs Score\")\nplt.show()\n\n## bulding model using K_neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nKnnModel = KNeighborsClassifier(n_neighbors=3)\nKnnModel.fit(x_train_sd, y_train)\nprint('KNeighbors model performance on train set:', KnnModel.score(x_train_sd,y_train))\nprint('KNeighbors model performance on Test set:', KnnModel.score(x_test_sd,y_test)) \n\nconfusMatrix = pd.crosstab(y_train, KnnModel.predict(x_train_sd))\nLABELS = ['setosa', 'versicolor', 'virginica']\nplt.figure(figsize=(12, 12))\nsns.heatmap(confusMatrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}