{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-09T15:45:49.975602Z","iopub.execute_input":"2021-07-09T15:45:49.975937Z","iopub.status.idle":"2021-07-09T15:45:50.001971Z","shell.execute_reply.started":"2021-07-09T15:45:49.975907Z","shell.execute_reply":"2021-07-09T15:45:50.001126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set = '/kaggle/input/nlp-news-text/train_set.csv'\ntest_set_a = '/kaggle/input/nlp-news-text/test_a.csv'\ntest_set_b = '/kaggle/input/nlp-news-text/test_b.csv'\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:45:50.003579Z","iopub.execute_input":"2021-07-09T15:45:50.003997Z","iopub.status.idle":"2021-07-09T15:45:50.007995Z","shell.execute_reply.started":"2021-07-09T15:45:50.003962Z","shell.execute_reply":"2021-07-09T15:45:50.006987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"____","metadata":{}},{"cell_type":"markdown","source":"## TextCNN\nTextCNN利用CNN（卷积神经网络）进行文本特征抽取，不同大小的卷积核分别抽取n-gram特征，卷积计算出的特征图经过MaxPooling保留最大的特征值，然后将拼接成一个向量作为文本的表示。\n\n这里我们基于TextCNN原始论文的设定，分别采用了100个大小为2,3,4的卷积核，最后得到的文本向量大小为100*3=300维。","metadata":{}},{"cell_type":"code","source":"import logging\nimport random\n\nimport numpy as np\nimport torch\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')\n\n# set seed \nseed = 666\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.manual_seed(seed)\n\n# set cuda\ngpu = 0\nuse_cuda = gpu >= 0 and torch.cuda.is_available()\nif use_cuda:\n    torch.cuda.set_device(gpu)\n    device = torch.device(\"cuda\", gpu)\nelse:\n    device = torch.device(\"cpu\")\nprint(\"Use cuda: %s, gpu id: %d，device:%s\"%(use_cuda, gpu,device))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:45:50.009795Z","iopub.execute_input":"2021-07-09T15:45:50.010382Z","iopub.status.idle":"2021-07-09T15:45:50.021509Z","shell.execute_reply.started":"2021-07-09T15:45:50.010346Z","shell.execute_reply":"2021-07-09T15:45:50.020705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"数据首先会经过all_data2fold函数，这个函数的作用是把原始的 DataFrame 数据，转换为一个list，有 10 个元素，表示交叉验证里的 10 份，每个元素是 dict，每个dict包括 label 和 text。\n\n首先根据 label 来划分数据行所在 index, 生成 label2id。\n\nlabel2id 是一个 dict，key 为 label，value 是一个 list，存储的是该类对应的 index。\n![image.png](attachment:c08d22a5-30c2-441a-9c68-376694c5331c.png)\n然后根据label2id，把每一类别的数据，划分到 10 份数据中。\n![image-20210704115949214](https://tva1.sinaimg.cn/large/008i3skNgy1gs4s75uovpj317e0jgn2w.jpg)\n最终得到的数据fold_data是一个list，有 10 个元素，每个元素是 dict，包括 label 和 text的列表：[{labels:texts}, {labels:texts}. . .]。\n\n最后，把前 9 份数据作为训练集train_data，最后一份数据作为验证集dev_data，并读取测试集test_data。","metadata":{},"attachments":{"c08d22a5-30c2-441a-9c68-376694c5331c.png":{"image/png":"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"}}},{"cell_type":"code","source":"# split data to 10 fold\nfold_num = 10\ndata_file = data_set\nimport pandas as pd\n\n\ndef all_data2fold(fold_num, num=10000):\n    fold_data = [] # 交叉验证的元素，每个元素是dict，key有两个包括了label和text\n    f = pd.read_csv(data_file, sep='\\t', encoding='UTF-8')\n    texts = f['text'].tolist()[:num]\n    labels = f['label'].tolist()[:num]\n\n    total = len(labels)\n    # 打乱了text和label的顺序\n    index = list(range(total))\n    np.random.shuffle(index)\n\n    all_texts = []\n    all_labels = []\n    for i in index:\n        all_texts.append(texts[i])\n        all_labels.append(labels[i])\n    # label2id 保存label对应的行，一个label可能有很多行，\n    # 所以key为label,value为list，存储该类对应的index\n    label2id = {}\n    for i in range(total):\n        label = str(all_labels[i])\n        if label not in label2id:\n            label2id[label] = [i]\n        else:\n            label2id[label].append(i)\n    # fold_num这里是10，这里是把每个label的对应的index平均分到10份数据中\n    all_index = [[] for _ in range(fold_num)]\n    for label, data in label2id.items():\n        # print(label, len(data))\n        batch_size = int(len(data) / fold_num)# 每个label划到一份数据的元素个数\n        other = len(data) - batch_size * fold_num # 还剩下的元素 other < 10\n        for i in range(fold_num):\n            cur_batch_size = batch_size + 1 if i < other else batch_size # 总是+1执行了other次\n            # print(cur_batch_size)\n            batch_data = [data[i * batch_size + b] for b in range(cur_batch_size)]\n            all_index[i].extend(batch_data)# all_index存每个fold存放的对应的index\n\n    batch_size = int(total / fold_num)# 所有的数据 （num） / 10，即每个fold平均的labels数据\n    other_texts = []\n    other_labels = []\n    other_num = 0\n    start = 0\n    for fold in range(fold_num):\n        # texts 和 labels是每个fold下的text 和 label\n        num = len(all_index[fold])\n        texts = [all_texts[i] for i in all_index[fold]]\n        labels = [all_labels[i] for i in all_index[fold]]\n\n        if num > batch_size:\n            fold_texts = texts[:batch_size]\n            other_texts.extend(texts[batch_size:])\n            fold_labels = labels[:batch_size]\n            other_labels.extend(labels[batch_size:])\n            other_num += num - batch_size\n        elif num < batch_size:\n            end = start + batch_size - num\n            fold_texts = texts + other_texts[start: end]\n            fold_labels = labels + other_labels[start: end]\n            start = end\n        else:\n            fold_texts = texts\n            fold_labels = labels\n\n        assert batch_size == len(fold_labels)\n        \n        # shuffle\n        index = list(range(batch_size))\n        np.random.shuffle(index)\n\n        shuffle_fold_texts = []\n        shuffle_fold_labels = []\n        for i in index:\n            shuffle_fold_texts.append(fold_texts[i])\n            shuffle_fold_labels.append(fold_labels[i])\n\n        data = {'label': shuffle_fold_labels, 'text': shuffle_fold_texts}\n        fold_data.append(data)\n\n    print(\"Fold lens %s\"%(str([len(data['label']) for data in fold_data])))\n\n    return fold_data\n\n\nfold_data = all_data2fold(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:45:50.023038Z","iopub.execute_input":"2021-07-09T15:45:50.02366Z","iopub.status.idle":"2021-07-09T15:46:03.966427Z","shell.execute_reply.started":"2021-07-09T15:45:50.023625Z","shell.execute_reply":"2021-07-09T15:46:03.964946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"把前 9 份数据作为训练集train_data，最后一份数据作为验证集dev_data，并读取测试集test_data。","metadata":{}},{"cell_type":"code","source":"# build train, dev, test data\nfold_id = 9\n\n# dev\ndev_data = fold_data[fold_id]\n\n# train\ntrain_texts = []\ntrain_labels = []\nfor i in range(0, fold_id):\n    data = fold_data[i]\n    train_texts.extend(data['text'])\n    train_labels.extend(data['label'])\n\ntrain_data = {'label': train_labels, 'text': train_texts}\n\n# test\ntest_data_file = test_set_a\nf = pd.read_csv(test_data_file, sep='\\t', encoding='UTF-8')\ntexts = f['text'].tolist()\ntest_data = {'label': [0] * len(texts), 'text': texts}","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:03.967898Z","iopub.execute_input":"2021-07-09T15:46:03.968294Z","iopub.status.idle":"2021-07-09T15:46:07.277029Z","shell.execute_reply.started":"2021-07-09T15:46:03.968254Z","shell.execute_reply":"2021-07-09T15:46:07.276232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vocab 的作用是：\n\n- 创建 词 和 index 对应的字典，这里包括 2 份字典，分别是：_id2word 和 _id2extword。\n- 其中 _id2word 是从新闻得到的， 把词频小于 5 的词替换为了 UNK。对应到模型输入的 batch_inputs1。\n- _id2extword 是从 word2vec.txt 中得到的，有 5976 个词。对应到模型输入的 batch_inputs2。\n- 后面会有两个 embedding 层，其中 _id2word 对应的 embedding 是可学习的，_id2extword 对应的 embedding 是从文件中加载的，是固定的。\n- 创建 label 和 index 对应的字典。\n- 上面这些字典，都是基于train_data创建的。\n","metadata":{}},{"cell_type":"code","source":"# build vocab\nfrom collections import Counter\nfrom transformers import BasicTokenizer\n\nbasic_tokenizer = BasicTokenizer()\n\n# Vocab 的作用是：\n# 1. 创建 词 和 index 对应的字典，这里包括 2 份字典，分别是：_id2word 和 _id2extword\n# 其中 _id2word 是从新闻得到的， 把词频小于 5 的词替换为了 UNK。对应到模型输入的 batch_inputs1。\n# _id2extword 是从 word2vec.txt 中得到的，有 5976 个词。对应到模型输入的 batch_inputs2。\n# 后面会有两个 embedding 层，其中 _id2word 对应的 embedding 是可学习的，_id2extword 对应的 embedding 是从文件中加载的，是固定的\n# 2.创建 label 和 index 对应的字典\n\nclass Vocab():\n    def __init__(self, train_data):\n        self.min_count = 5\n        self.pad = 0\n        self.unk = 1\n        self._id2word = ['[PAD]', '[UNK]']\n        self._id2extword = ['[PAD]', '[UNK]']\n\n        self._id2label = []\n        self.target_names = []\n\n        self.build_vocab(train_data)\n\n        reverse = lambda x: dict(zip(x, range(len(x))))\n        #创建词和 index 对应的字典\n        self._word2id = reverse(self._id2word)\n        #创建 label 和 index 对应的字典\n        self._label2id = reverse(self._id2label)\n\n        logging.info(\"Build vocab: words %d, labels %d.\" % (self.word_size, self.label_size))\n\n    #创建词典\n    def build_vocab(self, data):\n        self.word_counter = Counter()\n        #计算每个词出现的次数\n        for text in data['text']:\n            words = text.split()\n            for word in words:\n                self.word_counter[word] += 1\n        # 去掉频次小于 min_count = 5 的词，把词存到 _id2word\n        for word, count in self.word_counter.most_common():\n            if count >= self.min_count:\n                self._id2word.append(word)\n\n        label2name = {0: '科技', 1: '股票', 2: '体育', 3: '娱乐', 4: '时政', 5: '社会', 6: '教育', 7: '财经',\n                      8: '家居', 9: '游戏', 10: '房产', 11: '时尚', 12: '彩票', 13: '星座'}\n\n        self.label_counter = Counter(data['label'])\n\n        for label in range(len(self.label_counter)):\n            count = self.label_counter[label] # 取出 label 对应的次数\n            self._id2label.append(label) \n            self.target_names.append(label2name[label]) # 根据label数字取出对应的名字\n\n    def load_pretrained_embs(self, embfile):\n        with open(embfile, encoding='utf-8') as f:\n            lines = f.readlines()\n            items = lines[0].split()\n            # 第一行分别是单词数量、词向量维度\n            word_count, embedding_dim = int(items[0]), int(items[1])\n\n        index = len(self._id2extword)\n        embeddings = np.zeros((word_count + index, embedding_dim))\n        # 下面的代码和 word2vec.txt 的结构有关\n        for line in lines[1:]:\n            values = line.split()\n            self._id2extword.append(values[0]) # 首先添加第一列的单词\n            vector = np.array(values[1:], dtype='float64') # 然后添加后面 100 列的词向量\n            embeddings[self.unk] += vector\n            embeddings[index] = vector\n            index += 1\n\n        # unk 的词向量是所有词的平均\n        embeddings[self.unk] = embeddings[self.unk] / word_count\n        # 除以标准差干嘛？\n        embeddings = embeddings / np.std(embeddings)\n\n        reverse = lambda x: dict(zip(x, range(len(x))))\n        self._extword2id = reverse(self._id2extword)\n\n        assert len(set(self._id2extword)) == len(self._id2extword)\n\n        return embeddings\n\n    # 根据单词得到 id\n    def word2id(self, xs):\n        if isinstance(xs, list):\n            return [self._word2id.get(x, self.unk) for x in xs]\n        return self._word2id.get(xs, self.unk)\n    # 根据单词得到 ext id\n    def extword2id(self, xs):\n        if isinstance(xs, list):\n            return [self._extword2id.get(x, self.unk) for x in xs]\n        return self._extword2id.get(xs, self.unk)\n    # 根据 label 得到 id\n    def label2id(self, xs):\n        if isinstance(xs, list):\n            return [self._label2id.get(x, self.unk) for x in xs]\n        return self._label2id.get(xs, self.unk)\n\n    @property\n    def word_size(self):\n        return len(self._id2word)\n\n    @property\n    def extword_size(self):\n        return len(self._id2extword)\n\n    @property\n    def label_size(self):\n        return len(self._id2label)\n\n\nvocab = Vocab(train_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:07.278398Z","iopub.execute_input":"2021-07-09T15:46:07.278723Z","iopub.status.idle":"2021-07-09T15:46:10.041299Z","shell.execute_reply.started":"2021-07-09T15:46:07.278685Z","shell.execute_reply":"2021-07-09T15:46:10.04045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build module\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n        self.weight.data.normal_(mean=0.0, std=0.05)\n\n        self.bias = nn.Parameter(torch.Tensor(hidden_size))\n        b = np.zeros(hidden_size, dtype=np.float32)\n        self.bias.data.copy_(torch.from_numpy(b))\n\n        self.query = nn.Parameter(torch.Tensor(hidden_size))\n        self.query.data.normal_(mean=0.0, std=0.05)\n\n    def forward(self, batch_hidden, batch_masks):\n        # batch_hidden: b * doc_len * hidden_size (2 * hidden_size of lstm)\n        # batch_masks:  b x doc_len\n\n        # linear\n        # key： b * doc_len * hidden\n        key = torch.matmul(batch_hidden, self.weight) + self.bias \n\n        # compute attention\n        # matmul 会进行广播\n        #outputs: b * doc_len\n        outputs = torch.matmul(key, self.query)  \n        # 1 - batch_masks 就是取反，把没有单词的句子置为 0\n        # masked_fill 的作用是 在 为 1 的地方替换为 value: float(-1e32)\n        masked_outputs = outputs.masked_fill((1 - batch_masks).bool(), float(-1e32))\n        #attn_scores：b * doc_len\n        attn_scores = F.softmax(masked_outputs, dim=1)  \n\n        # 对于全零向量，-1e32的结果为 1/len, -inf为nan, 额外补0\n        masked_attn_scores = attn_scores.masked_fill((1 - batch_masks).bool(), 0.0)\n\n        # sum weighted sources\n        # masked_attn_scores.unsqueeze(1)：# b * 1 * doc_len\n        # key：b * doc_len * hidden\n        # batch_outputs：b * hidden\n        batch_outputs = torch.bmm(masked_attn_scores.unsqueeze(1), key).squeeze(1)  \n\n        return batch_outputs, attn_scores\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.043568Z","iopub.execute_input":"2021-07-09T15:46:10.043918Z","iopub.status.idle":"2021-07-09T15:46:10.05523Z","shell.execute_reply.started":"2021-07-09T15:46:10.043882Z","shell.execute_reply":"2021-07-09T15:46:10.05315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 读取训练好的词向量文件\nword2vec_path = '/kaggle/input/nlp-news-text/word2vec100.txt'\ndropout = 0.15\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.057072Z","iopub.execute_input":"2021-07-09T15:46:10.05743Z","iopub.status.idle":"2021-07-09T15:46:10.067621Z","shell.execute_reply.started":"2021-07-09T15:46:10.057395Z","shell.execute_reply":"2021-07-09T15:46:10.066807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 输入是：\n# 输出是：\nclass WordCNNEncoder(nn.Module):\n    def __init__(self, vocab):\n        super(WordCNNEncoder, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.word_dims = 100 # 词向量的长度是 100 维\n        # padding_idx 表示当取第 0 个词时，向量全为 0\n        # 这个 Embedding 层是可学习的\n        self.word_embed = nn.Embedding(vocab.word_size, self.word_dims, padding_idx=0)\n\n        extword_embed = vocab.load_pretrained_embs(word2vec_path)\n        extword_size, word_dims = extword_embed.shape\n        logging.info(\"Load extword embed: words %d, dims %d.\" % (extword_size, word_dims))\n\n        # # 这个 Embedding 层是不可学习的\n        self.extword_embed = nn.Embedding(extword_size, word_dims, padding_idx=0)\n        self.extword_embed.weight.data.copy_(torch.from_numpy(extword_embed))\n        self.extword_embed.weight.requires_grad = False\n\n        input_size = self.word_dims\n\n        self.filter_sizes = [2, 3, 4]  # n-gram window\n        self.out_channel = 100\n        # 3 个卷积层，卷积核大小分别为 [2,100], [3,100], [4,100]\n        self.convs = nn.ModuleList([nn.Conv2d(1, self.out_channel, (filter_size, input_size), bias=True)\n                                    for filter_size in self.filter_sizes])\n\n    def forward(self, word_ids, extword_ids):\n        # word_ids: sentence_num * sentence_len\n        # extword_ids: sentence_num * sentence_len\n        # batch_masks: sentence_num * sentence_len\n        sen_num, sent_len = word_ids.shape\n        \n        # word_embed: sentence_num * sentence_len * 100\n        # 根据 index 取出词向量\n        word_embed = self.word_embed(word_ids)\n        extword_embed = self.extword_embed(extword_ids)\n        batch_embed = word_embed + extword_embed\n\n        if self.training:\n            batch_embed = self.dropout(batch_embed)\n        # batch_embed: sentence_num x 1 x sentence_len x 100\n        # squeeze 是为了添加一个 channel 的维度，成为 B * C * H * W\n        # 方便下面做 卷积\n        batch_embed.unsqueeze_(1)  \n\n        pooled_outputs = []\n        # 通过 3 个卷积核做 3 次卷积核池化\n        for i in range(len(self.filter_sizes)):\n            # 通过池化公式计算池化后的高度: o = (i-k)/s+1\n            # 其中 o 表示输出的长度\n            # k 表示卷积核大小\n            # s 表示步长，这里为 1\n            filter_height = sent_len - self.filter_sizes[i] + 1\n            # conv：sentence_num * out_channel * filter_height * 1\n            conv = self.convs[i](batch_embed)\n            hidden = F.relu(conv)  \n            # 定义池化层\n            mp = nn.MaxPool2d((filter_height, 1))  # (filter_height, filter_width)\n            # pooled：sentence_num * out_channel * 1 * 1 -> sen_num * out_channel\n            # 也可以通过 squeeze 来删除无用的维度\n            pooled = mp(hidden).reshape(sen_num,\n                                        self.out_channel) \n            \n            pooled_outputs.append(pooled)\n        # 拼接 3 个池化后的向量\n        # reps: sen_num * (3*out_channel)\n        reps = torch.cat(pooled_outputs, dim=1)  \n\n        if self.training:\n            reps = self.dropout(reps)\n\n        return reps\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.069449Z","iopub.execute_input":"2021-07-09T15:46:10.069758Z","iopub.status.idle":"2021-07-09T15:46:10.084691Z","shell.execute_reply.started":"2021-07-09T15:46:10.069733Z","shell.execute_reply":"2021-07-09T15:46:10.083927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build sent encoder\nsent_hidden_size = 256\nsent_num_layers = 2\n\n\nclass SentEncoder(nn.Module):\n    def __init__(self, sent_rep_size):\n        super(SentEncoder, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n\n        self.sent_lstm = nn.LSTM(\n            input_size=sent_rep_size, # 每个句子经过 CNN 后得到 300 维向量\n            hidden_size=sent_hidden_size,# 输出的维度\n            num_layers=sent_num_layers,\n            batch_first=True,\n            bidirectional=True\n        )\n\n    def forward(self, sent_reps, sent_masks):\n        # sent_reps:  b * doc_len * sent_rep_size\n        # sent_masks: b * doc_len\n        # sent_hiddens:  b * doc_len * hidden*2\n        # sent_hiddens:  batch, seq_len, num_directions * hidden_size\n        sent_hiddens, _ = self.sent_lstm(sent_reps)  \n        # 对应相乘，用到广播，是为了只保留有句子的位置的数值\n        sent_hiddens = sent_hiddens * sent_masks.unsqueeze(2)\n        \n        if self.training:\n            sent_hiddens = self.dropout(sent_hiddens)\n\n        return sent_hiddens\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.085905Z","iopub.execute_input":"2021-07-09T15:46:10.086312Z","iopub.status.idle":"2021-07-09T15:46:10.098249Z","shell.execute_reply.started":"2021-07-09T15:46:10.086274Z","shell.execute_reply":"2021-07-09T15:46:10.097437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build model\nclass Model(nn.Module):\n    def __init__(self, vocab):\n        super(Model, self).__init__()\n        self.sent_rep_size = 300 # 经过 CNN 后得到的 300 维向量\n        self.doc_rep_size = sent_hidden_size * 2 # lstm 最后输出的向量长度\n        self.all_parameters = {}\n        parameters = []\n        self.word_encoder = WordCNNEncoder(vocab)\n        \n        parameters.extend(list(filter(lambda p: p.requires_grad, self.word_encoder.parameters())))\n\n        self.sent_encoder = SentEncoder(self.sent_rep_size)\n        self.sent_attention = Attention(self.doc_rep_size)\n        parameters.extend(list(filter(lambda p: p.requires_grad, self.sent_encoder.parameters())))\n        parameters.extend(list(filter(lambda p: p.requires_grad, self.sent_attention.parameters())))\n        # doc_rep_size\n        self.out = nn.Linear(self.doc_rep_size, vocab.label_size, bias=True)\n        parameters.extend(list(filter(lambda p: p.requires_grad, self.out.parameters())))\n\n        if use_cuda:\n            self.to(device)\n\n        if len(parameters) > 0:\n            self.all_parameters[\"basic_parameters\"] = parameters\n\n        logging.info('Build model with cnn word encoder, lstm sent encoder.')\n\n        para_num = sum([np.prod(list(p.size())) for p in self.parameters()])\n        logging.info('Model param num: %.2f M.' % (para_num / 1e6))\n    def forward(self, batch_inputs):\n        # batch_inputs(batch_inputs1, batch_inputs2): b * doc_len * sentence_len\n        # batch_masks : b * doc_len * sentence_len\n        batch_inputs1, batch_inputs2, batch_masks = batch_inputs\n        batch_size, max_doc_len, max_sent_len = batch_inputs1.shape[0], batch_inputs1.shape[1], batch_inputs1.shape[2]\n        # batch_inputs1: sentence_num * sentence_len\n        batch_inputs1 = batch_inputs1.view(batch_size * max_doc_len, max_sent_len)  \n        # batch_inputs2: sentence_num * sentence_len\n        batch_inputs2 = batch_inputs2.view(batch_size * max_doc_len, max_sent_len)\n        # batch_masks: sentence_num * sentence_len \n        batch_masks = batch_masks.view(batch_size * max_doc_len, max_sent_len)  \n        # sent_reps: sentence_num * sentence_rep_size\n        # sen_num * (3*out_channel) =  sen_num * 300\n        sent_reps = self.word_encoder(batch_inputs1, batch_inputs2) \n        \n        \n        # sent_reps：b * doc_len * sent_rep_size\n        sent_reps = sent_reps.view(batch_size, max_doc_len, self.sent_rep_size)  \n        # batch_masks：b * doc_len * max_sent_len\n        batch_masks = batch_masks.view(batch_size, max_doc_len, max_sent_len)  \n        # sent_masks：b * doc_len any(2) 表示在 第二个维度上判断\n        # 表示如果如果一个句子中有词 true，那么这个句子就是 true，用于给 lstm 过滤\n        sent_masks = batch_masks.bool().any(2).float()  # b x doc_len\n        # sent_hiddens: b * doc_len * num_directions * hidden_size\n        # sent_hiddens:  batch, seq_len, 2 * hidden_size\n        sent_hiddens = self.sent_encoder(sent_reps, sent_masks)  \n        \n        \n        # doc_reps: b * (2 * hidden_size)\n        # atten_scores: b * doc_len\n        doc_reps, atten_scores = self.sent_attention(sent_hiddens, sent_masks)  \n        \n        # b * num_labels\n        batch_outputs = self.out(doc_reps)  \n\n        return batch_outputs\n\n\nmodel = Model(vocab)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.101484Z","iopub.execute_input":"2021-07-09T15:46:10.101745Z","iopub.status.idle":"2021-07-09T15:46:10.516879Z","shell.execute_reply.started":"2021-07-09T15:46:10.101721Z","shell.execute_reply":"2021-07-09T15:46:10.516048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build optimizer\nlearning_rate = 2e-4\ndecay = .75\ndecay_step = 1000\n\n\nclass Optimizer:\n    def __init__(self, model_parameters):\n        self.all_params = []\n        self.optims = []\n        self.schedulers = []\n\n        for name, parameters in model_parameters.items():\n            if name.startswith(\"basic\"):\n                optim = torch.optim.Adam(parameters, lr=learning_rate)\n                self.optims.append(optim)\n\n                l = lambda step: decay ** (step // decay_step)\n                scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=l)\n                self.schedulers.append(scheduler)\n                self.all_params.extend(parameters)\n\n            else:\n                Exception(\"no nameed parameters.\")\n\n        self.num = len(self.optims)\n\n    def step(self):\n        for optim, scheduler in zip(self.optims, self.schedulers):\n            optim.step()\n            scheduler.step()\n            optim.zero_grad()\n\n    def zero_grad(self):\n        for optim in self.optims:\n            optim.zero_grad()\n\n    def get_lr(self):\n        lrs = tuple(map(lambda x: x.get_lr()[-1], self.schedulers))\n        lr = ' %.5f' * self.num\n        res = lr % lrs\n        return res\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.518837Z","iopub.execute_input":"2021-07-09T15:46:10.519437Z","iopub.status.idle":"2021-07-09T15:46:10.529026Z","shell.execute_reply.started":"2021-07-09T15:46:10.519397Z","shell.execute_reply":"2021-07-09T15:46:10.528294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \n# 作用是：根据一篇文章，把这篇文章分割成多个句子\n# text 是一个新闻的文章\n# vocab 是词典\n# max_sent_len 表示每句话的长度\n# max_segment 表示最多有几句话\n# 最后返回的 segments 是一个list，其中每个元素是 tuple：(句子长度，句子本身)\ndef sentence_split(text, vocab, max_sent_len=256, max_segment=16):\n    \n    words = text.strip().split()\n    document_len = len(words)\n    # 划分句子的索引，句子长度为 max_sent_len\n    index = list(range(0, document_len, max_sent_len))\n    index.append(document_len)\n\n    segments = []\n    for i in range(len(index) - 1):\n        # 根据索引划分句子\n        segment = words[index[i]: index[i + 1]]\n        assert len(segment) > 0\n        # 把出现太少的词替换为 UNK\n        segment = [word if word in vocab._id2word else '<UNK>' for word in segment]\n        # 添加 tuple:(句子长度，句子本身)\n        segments.append([len(segment), segment])\n\n    assert len(segments) > 0\n    # 如果大于 max_segment 句话，则局数减少一半，返回一半的句子\n    if len(segments) > max_segment:\n        segment_ = int(max_segment / 2)\n        return segments[:segment_] + segments[-segment_:]\n    else:\n        # 否则返回全部句子\n        return segments\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.529993Z","iopub.execute_input":"2021-07-09T15:46:10.530267Z","iopub.status.idle":"2021-07-09T15:46:10.543656Z","shell.execute_reply.started":"2021-07-09T15:46:10.530243Z","shell.execute_reply":"2021-07-09T15:46:10.542753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 最后返回的数据是一个 list，每个元素是一个 tuple: (label, 句子数量，doc)\n# 其中 doc 又是一个 list，每个 元素是一个 tuple: (句子长度，word_ids, extword_ids)\ndef get_examples(data, vocab, max_sent_len=256, max_segment=8):\n    label2id = vocab.label2id\n    examples = []\n\n    for text, label in zip(data['text'], data['label']):\n        # label\n        id = label2id(label)\n\n        # sents_words: 是一个list，其中每个元素是 tuple：(句子长度，句子本身)\n        sents_words = sentence_split(text, vocab, max_sent_len, max_segment)\n        doc = []\n        for sent_len, sent_words in sents_words:\n            # 把 word 转为 id\n            word_ids = vocab.word2id(sent_words)\n            # 把 word 转为 ext id\n            extword_ids = vocab.extword2id(sent_words)\n            doc.append([sent_len, word_ids, extword_ids])\n        examples.append([id, len(doc), doc])\n\n    logging.info('Total %d docs.' % len(examples))\n    return examples\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.54531Z","iopub.execute_input":"2021-07-09T15:46:10.545885Z","iopub.status.idle":"2021-07-09T15:46:10.557268Z","shell.execute_reply.started":"2021-07-09T15:46:10.545848Z","shell.execute_reply":"2021-07-09T15:46:10.556432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build loader\n# data 参数就是 get_examples() 得到的\n# data是一个 list，每个元素是一个 tuple: (label, 句子数量，doc)\n# 其中 doc 又是一个 list，每个 元素是一个 tuple: (句子长度，word_ids, extword_ids)\ndef batch_slice(data, batch_size):\n    batch_num = int(np.ceil(len(data) / float(batch_size)))\n    for i in range(batch_num):\n        # 如果 i < batch_num - 1，那么大小为 batch_size，否则就是最后一批数据\n        cur_batch_size = batch_size if i < batch_num - 1 else len(data) - batch_size * i\n        docs = [data[i * batch_size + b] for b in range(cur_batch_size)]\n\n        yield docs\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.560474Z","iopub.execute_input":"2021-07-09T15:46:10.560735Z","iopub.status.idle":"2021-07-09T15:46:10.569854Z","shell.execute_reply.started":"2021-07-09T15:46:10.560712Z","shell.execute_reply":"2021-07-09T15:46:10.569047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data 参数就是 get_examples() 得到的\n# data是一个 list，每个元素是一个 tuple: (label, 句子数量，doc)\n# 其中 doc 又是一个 list，每个 元素是一个 tuple: (句子长度，word_ids, extword_ids)\ndef data_iter(data, batch_size, shuffle=True, noise=1.0):\n    \"\"\"\n    randomly permute data, then sort by source length, and partition into batches\n    ensure that the length of  sentences in each batch\n    \"\"\"\n\n    batched_data = []\n    if shuffle:\n        # 这里是打乱所有数据\n        np.random.shuffle(data)\n        # lengths 表示的是 每篇文章的句子数量\n        lengths = [example[1] for example in data] \n        noisy_lengths = [- (l + np.random.uniform(- noise, noise)) for l in lengths]\n        sorted_indices = np.argsort(noisy_lengths).tolist()\n        sorted_data = [data[i] for i in sorted_indices]\n    else:\n        sorted_data = data\n    # 把 batch 的数据放进一个 list    \n    batched_data.extend(list(batch_slice(sorted_data, batch_size)))\n\n    if shuffle:\n        # 打乱 多个 batch\n        np.random.shuffle(batched_data)\n\n    for batch in batched_data:\n        yield batch\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.572776Z","iopub.execute_input":"2021-07-09T15:46:10.573263Z","iopub.status.idle":"2021-07-09T15:46:10.581833Z","shell.execute_reply.started":"2021-07-09T15:46:10.573229Z","shell.execute_reply":"2021-07-09T15:46:10.580844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some function\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\n\ndef get_score(y_ture, y_pred):\n    y_ture = np.array(y_ture)\n    y_pred = np.array(y_pred)\n    f1 = f1_score(y_ture, y_pred, average='macro') * 100\n    p = precision_score(y_ture, y_pred, average='macro') * 100\n    r = recall_score(y_ture, y_pred, average='macro') * 100\n\n    return str((reformat(p, 2), reformat(r, 2), reformat(f1, 2))), reformat(f1, 2)\n\n# 保留 n 位小数点\ndef reformat(num, n):\n    return float(format(num, '0.' + str(n) + 'f'))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.585186Z","iopub.execute_input":"2021-07-09T15:46:10.585474Z","iopub.status.idle":"2021-07-09T15:46:10.593413Z","shell.execute_reply.started":"2021-07-09T15:46:10.585442Z","shell.execute_reply":"2021-07-09T15:46:10.592564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build trainer\n\nimport time\nfrom sklearn.metrics import classification_report\n\nclip = 5.0\nepochs = 10\nearly_stops = 3\nlog_interval = 50\n\ntest_batch_size = 128\ntrain_batch_size = 128\n\nsave_model = './cnn.bin'\nsave_test = './cnn.csv'\n\nclass Trainer():\n    def __init__(self, model, vocab):\n        self.model = model\n        self.report = True\n\n        # get_examples() 返回的结果是 一个 list\n        # 每个元素是一个 tuple: (label, 句子数量，doc)\n        # 其中 doc 又是一个 list，每个 元素是一个 tuple: (句子长度，word_ids, extword_ids)\n        self.train_data = get_examples(train_data, vocab)\n        self.batch_num = int(np.ceil(len(self.train_data) / float(train_batch_size)))\n        self.dev_data = get_examples(dev_data, vocab)\n        self.test_data = get_examples(test_data, vocab)\n\n        # criterion\n        self.criterion = nn.CrossEntropyLoss()\n\n        # label name\n        self.target_names = vocab.target_names\n\n        # optimizer\n        self.optimizer = Optimizer(model.all_parameters)\n\n        # count\n        self.step = 0\n        self.early_stop = -1\n        self.best_train_f1, self.best_dev_f1 = 0, 0\n        self.last_epoch = epochs\n\n    def train(self):\n        logging.info('Start training...')\n        for epoch in range(1, epochs + 1):\n            train_f1 = self._train(epoch)\n\n            dev_f1 = self._eval(epoch)\n\n            if self.best_dev_f1 <= dev_f1:\n                logging.info(\n                    \"Exceed history dev = %.2f, current dev = %.2f\" % (self.best_dev_f1, dev_f1))\n                torch.save(self.model.state_dict(), save_model)\n\n                self.best_train_f1 = train_f1\n                self.best_dev_f1 = dev_f1\n                self.early_stop = 0\n            else:\n                self.early_stop += 1\n                if self.early_stop == early_stops:\n                    logging.info(\n                        \"Eearly stop in epoch %d, best train: %.2f, dev: %.2f\" % (\n                            epoch - early_stops, self.best_train_f1, self.best_dev_f1))\n                    self.last_epoch = epoch\n                    break\n\n    def test(self):\n        self.model.load_state_dict(torch.load(save_model))\n        self._eval(self.last_epoch + 1, test=True)\n    \n    def _train(self, epoch):\n        self.optimizer.zero_grad()\n        self.model.train()\n\n        start_time = time.time()\n        epoch_start_time = time.time()\n        overall_losses = 0\n        losses = 0\n        batch_idx = 1\n        y_pred = []\n        y_true = []\n        for batch_data in data_iter(self.train_data, train_batch_size, shuffle=True):\n            torch.cuda.empty_cache()\n            # batch_inputs: (batch_inputs1, batch_inputs2, batch_masks)\n            # 形状都是：batch_size * doc_len * sent_len\n            # batch_labels: batch_size\n            batch_inputs, batch_labels = self.batch2tensor(batch_data)\n            # batch_outputs：b * num_labels\n            batch_outputs = self.model(batch_inputs)\n            # criterion 是 CrossEntropyLoss，真实标签的形状是：N\n            # 预测标签的形状是：(N,C)\n            loss = self.criterion(batch_outputs, batch_labels)\n            \n            loss.backward()\n\n            loss_value = loss.detach().cpu().item()\n            losses += loss_value\n            overall_losses += loss_value\n            # 把预测值转换为一维，方便下面做 classification_report，计算 f1\n            y_pred.extend(torch.max(batch_outputs, dim=1)[1].cpu().numpy().tolist())\n            y_true.extend(batch_labels.cpu().numpy().tolist())\n            # 梯度裁剪\n            nn.utils.clip_grad_norm_(self.optimizer.all_params, max_norm=clip)\n            for optimizer, scheduler in zip(self.optimizer.optims, self.optimizer.schedulers):\n                optimizer.step()\n                scheduler.step()\n            self.optimizer.zero_grad()\n\n            self.step += 1\n\n            if batch_idx % log_interval == 0:\n                elapsed = time.time() - start_time\n                \n                lrs = self.optimizer.get_lr()\n                logging.info(\n                    '| epoch {:3d} | step {:3d} | batch {:3d}/{:3d} | lr{} | loss {:.4f} | s/batch {:.2f}'.format(\n                        epoch, self.step, batch_idx, self.batch_num, lrs,\n                        losses / log_interval,\n                        elapsed / log_interval))\n                \n                losses = 0\n                start_time = time.time()\n                \n            batch_idx += 1\n            \n        overall_losses /= self.batch_num\n        during_time = time.time() - epoch_start_time\n\n        # reformat 保留 4 位数字\n        overall_losses = reformat(overall_losses, 4)\n        score, f1 = get_score(y_true, y_pred)\n\n        logging.info(\n            '| epoch {:3d} | score {} | f1 {} | loss {:.4f} | time {:.2f}'.format(epoch, score, f1,\n                                                                                  overall_losses, during_time))\n        # 如果预测和真实的标签都包含相同的类别数目，才能调用 classification_report                                                                        \n        if set(y_true) == set(y_pred) and self.report:\n            report = classification_report(y_true, y_pred, digits=4, target_names=self.target_names)\n            logging.info('\\n' + report)\n\n        return f1\n\n    # 这里验证集、测试集都使用这个函数，通过 test 来区分使用哪个数据集\n    def _eval(self, epoch, test=False):\n        self.model.eval()\n        start_time = time.time()\n        data = self.test_data if test else self.dev_data\n        y_pred = []\n        y_true = []\n        with torch.no_grad():\n            for batch_data in data_iter(data, test_batch_size, shuffle=False):\n                torch.cuda.empty_cache()\n                            # batch_inputs: (batch_inputs1, batch_inputs2, batch_masks)\n            # 形状都是：batch_size * doc_len * sent_len\n            # batch_labels: batch_size                                                                  \n                batch_inputs, batch_labels = self.batch2tensor(batch_data)\n                # batch_outputs：b * num_labels                                                                  \n                batch_outputs = self.model(batch_inputs)\n                # 把预测值转换为一维，方便下面做 classification_report，计算 f1                                                                  \n                y_pred.extend(torch.max(batch_outputs, dim=1)[1].cpu().numpy().tolist())\n                y_true.extend(batch_labels.cpu().numpy().tolist())\n\n            score, f1 = get_score(y_true, y_pred)\n\n            during_time = time.time() - start_time\n            \n            if test:\n                df = pd.DataFrame({'label': y_pred})\n                df.to_csv(save_test, index=False, sep=',')\n            else:\n                logging.info(\n                    '| epoch {:3d} | dev | score {} | f1 {} | time {:.2f}'.format(epoch, score, f1,\n                                                                              during_time))\n                if set(y_true) == set(y_pred) and self.report:\n                    report = classification_report(y_true, y_pred, digits=4, target_names=self.target_names)\n                    logging.info('\\n' + report)\n\n        return f1\n\n    \n    # data 参数就是 get_examples() 得到的，经过了分 batch\n    # batch_data是一个 list，每个元素是一个 tuple: (label, 句子数量，doc)\n    # 其中 doc 又是一个 list，每个 元素是一个 tuple: (句子长度，word_ids, extword_ids)\n    def batch2tensor(self, batch_data):\n        '''\n            [[label, doc_len, [[sent_len, [sent_id0, ...], [sent_id1, ...]], ...]]\n        '''\n        batch_size = len(batch_data)\n        doc_labels = []\n        doc_lens = []\n        doc_max_sent_len = []\n        for doc_data in batch_data:\n            # doc_data 代表一篇新闻，是一个 tuple: (label, 句子数量，doc)\n            # doc_data[0] 是 label\n            doc_labels.append(doc_data[0])\n            # doc_data[1] 是 这篇文章的句子数量\n            doc_lens.append(doc_data[1])\n            # doc_data[2] 是一个 list，每个 元素是一个 tuple: (句子长度，word_ids, extword_ids)\n            # 所以 sent_data[0] 表示每个句子的长度（单词个数）\n            sent_lens = [sent_data[0] for sent_data in doc_data[2]]\n            # 取出这篇新闻中最长的句子长度（单词个数）\n            max_sent_len = max(sent_lens)\n            doc_max_sent_len.append(max_sent_len)\n        \n        # 取出最长的句子数量\n        max_doc_len = max(doc_lens)\n        # 取出这批 batch 数据中最长的句子长度（单词个数）\n        max_sent_len = max(doc_max_sent_len)\n        # 创建 数据\n        batch_inputs1 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)\n        batch_inputs2 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)\n        batch_masks = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.float32)\n        batch_labels = torch.LongTensor(doc_labels)\n\n        for b in range(batch_size):\n            for sent_idx in range(doc_lens[b]):\n                # batch_data[b][2] 表示一个 list，是一篇文章中的句子\n                sent_data = batch_data[b][2][sent_idx] #sent_data 表示一个句子\n                for word_idx in range(sent_data[0]): # sent_data[0] 是句子长度(单词数量)\n                    # sent_data[1] 表示 word_ids\n                    batch_inputs1[b, sent_idx, word_idx] = sent_data[1][word_idx]\n                    # # sent_data[2] 表示 extword_ids\n                    batch_inputs2[b, sent_idx, word_idx] = sent_data[2][word_idx]\n                    # mask 表示 哪个位置是有词，后面计算 attention 时，没有词的地方会被置为 0                                               \n                    batch_masks[b, sent_idx, word_idx] = 1\n\n        if use_cuda:\n            print(\"use gpu\")\n            batch_inputs1 = batch_inputs1.to(device)\n            batch_inputs2 = batch_inputs2.to(device)\n            batch_masks = batch_masks.to(device)\n            batch_labels = batch_labels.to(device)\n\n        return (batch_inputs1, batch_inputs2, batch_masks), batch_labels\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.595001Z","iopub.execute_input":"2021-07-09T15:46:10.595463Z","iopub.status.idle":"2021-07-09T15:46:10.630807Z","shell.execute_reply.started":"2021-07-09T15:46:10.595424Z","shell.execute_reply":"2021-07-09T15:46:10.629935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ntrainer = Trainer(model, vocab)\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-09T15:46:10.631981Z","iopub.execute_input":"2021-07-09T15:46:10.632386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test\ntrainer.test()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}