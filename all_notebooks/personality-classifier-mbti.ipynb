{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom bs4 import BeautifulSoup\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mbti_df = pd.read_csv('../input/mbti_1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Labels that need to be removed from posts\nlbl_rmv=list(mbti_df['type'].unique())\nlbl_rmv = [item.lower() for item in lbl_rmv]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop = stopwords.words('english')\n\nfrom nltk.stem.porter import PorterStemmer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,8675) :  \n    mbti_df['posts'][i] = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', mbti_df['posts'][i])\n    mbti_df['posts'][i] = re.sub(\"[^a-zA-Z]\", \" \", mbti_df['posts'][i])\n    mbti_df['posts'][i] = re.sub(' +', ' ', mbti_df['posts'][i]).lower()\n    for j in range(0,16):\n        mbti_df['posts'][i]=re.sub(lbl_rmv[j], ' ', mbti_df['posts'][i])\n        \nmbti_df['posts'] = mbti_df['posts'].str.strip()\n\n#corpus creation and stopwords and porterstemming \ndef pre_process(post):\n    posts = re.sub('\\s+', ' ', post)\n    posts = posts.lower()\n    posts = posts.split()\n    posts = [word for word in posts if not word in set(stopwords.words('english'))]\n    ps = PorterStemmer()\n    posts = [ps.stem(word) for word in posts]\n    posts = ' '.join(posts)\n    return posts\n    \ncorpus = mbti_df[\"posts\"].apply(pre_process)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting the personality types to 8 respective binary identifiers(I-E,N-S,T-F,J-P)\nmap1 = {\"I\": 0, \"E\": 1}\nmap2 = {\"N\": 0, \"S\": 1}\nmap3 = {\"T\": 0, \"F\": 1}\nmap4 = {\"J\": 0, \"P\": 1}\nmbti_df['I-E'] = mbti_df['type'].astype(str).str[0]\nmbti_df['I-E'] = mbti_df['I-E'].map(map1)\nmbti_df['N-S'] = mbti_df['type'].astype(str).str[1]\nmbti_df['N-S'] = mbti_df['N-S'].map(map2)\nmbti_df['T-F'] = mbti_df['type'].astype(str).str[2]\nmbti_df['T-F'] = mbti_df['T-F'].map(map3)\nmbti_df['J-P'] = mbti_df['type'].astype(str).str[3]\nmbti_df['J-P'] = mbti_df['J-P'].map(map4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bag of words\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 2000)\nfeatures = cv.fit_transform(mbti_df['posts']).toarray()\nIE= mbti_df.iloc[:, 2].values\nNS= mbti_df.iloc[:, 3].values\nTF=mbti_df.iloc[:, 4].values\nJP=mbti_df.iloc[:, 5].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nfeatures_train, features_test, IE_train, IE_test, NS_train, NS_test, TF_train, TF_test, JP_train, JP_test = train_test_split(features, IE,NS,TF,JP, test_size = 0.20, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# fit model on training data\nIEB = XGBClassifier()\nIEB.fit(features_train, IE_train)\nieb_train=IEB.score(features_train,IE_train)\nieb_test=IEB.score(features_test,IE_test)\n\nNSB = XGBClassifier()\nNSB.fit(features_train, NS_train)\nnsb_train=NSB.score(features_train,NS_train)\nnsb_test=NSB.score(features_test,NS_test)\n\n\nTFB = XGBClassifier()\nTFB.fit(features_train, TF_train)\ntfb_train=TFB.score(features_train,TF_train)\ntfb_test=TFB.score(features_test,TF_test)\n\nJPB = XGBClassifier()\nJPB.fit(features_train, JP_train)\njpb_train=JPB.score(features_train,JP_train)\njpb_test=JPB.score(features_test,JP_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Label I-E train score is :',ieb_train)\nprint('Label I-E test score is :',ieb_test)\nprint('Label N-S train score is :',nsb_train)\nprint('Label N-S test score is :',nsb_test)\nprint('Label T-F train score is :',tfb_train)\nprint('Label T-F test score is :',tfb_test)\nprint('Label J-P train score is :',jpb_train)\nprint('Label J-P test score is :',jpb_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}