{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# reading the data\n\ndata = pd.read_csv('../input/spam.csv', encoding = 'latin-1')\n\n# getting the shape\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# deleting the unnamed columns \n\ndata = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n\n# getting the shape of new data\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming v1 and v2\n\ndata = data.rename(columns = {'v1': 'labels', 'v2': 'message'})\n\n# getting the colums of the data\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding a column to represent the length of the tweet\n\ndata['len'] = data['message'].str.len()\n\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# relation between spam messages and length\n\nplt.rcParams['figure.figsize'] = (10, 7)\nsns.boxenplot(x = data['labels'], y = data['len'])\nplt.title('Relation between Messages and Length', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution of length\n\nsns.violinplot(data['len'], data['labels'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shows the spam text has more text than ham "},{"metadata":{"trusted":true},"cell_type":"code","source":"# describing by labels\n\ndata.groupby('labels').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the most common words in the whole dataset\n\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = 'gray', width = 1000, height = 1000, max_words = 50).generate(str(data['message']))\n\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.title('Most Common words in the dataset', fontsize = 20)\nplt.axis('off')\nplt.imshow(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's encode the label attributes\n\ndata['labels'].replace('spam',1,inplace = True)\ndata['labels'].replace('ham', 0, inplace = True)\n\n# checking the values of the labels now\ndata['labels'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize it in pie chart\n\nsize = [4825, 747]\nlabels = ['Ham','Spam']\ncolors = ['brown', 'white']\n\nplt.pie(size, colors=colors, labels=labels, autopct = '%.2f%%', shadow = True)\nplt.axis('equal')\nplt.title('Spam vs Ham', color='white')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# checking the most common words in spam messages\n\nspam = ' '.join(text for text in data['message'][data['labels'] == 0])\n\nwordcloud = WordCloud(background_color = 'pink', max_words = 50, height = 1000, width = 1000).generate(spam)\n\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.axis('off')\nplt.title('Most Common Words in Spam Messages', fontsize = 20)\nplt.imshow(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the most common words in ham messages\n\nham = ' '.join(text for text in data['message'][data['labels'] == 1])\n\nwordcloud = WordCloud(background_color = 'purple', max_words = 50, height = 1000, width = 1000).generate(ham)\n\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.axis('off')\nplt.title('Most Common Words in Ham Messages', fontsize = 20)\nplt.imshow(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n\ncv = CountVectorizer()\nwords = cv.fit_transform(data.message)\n\nsum_words = words.sum(axis=0)\n\nwords_freq = [(word, sum_words[0, i]) for word, i in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n\nfrequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n\nfrequency.head(30).plot(x='word', y='freq', kind='bar', figsize=(15, 7), color = 'orange')\nplt.title(\"Most Frequently Occuring Words - Top 30\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# collecting the hashtags\n\ndef hashtag_extract(x):\n    hashtags = []\n    \n    for i in x:\n        ht = re.findall(r\"#(\\w+)\", i)\n        hashtags.append(ht)\n\n    return hashtags\n\nimport re\n\n# extracting hashtags\nHT_regular = hashtag_extract(data['message'][data['labels'] == 1])\n\n# extracting hashtags\nHT_negative = hashtag_extract(data['message'][data['labels'] == 0])\n\n# unnesting list\nHT_regular = sum(HT_regular,[])\nHT_negative = sum(HT_negative,[])\n\n# let's check no. of hastags\nprint(\"No. of Positive Hashtags :\", HT_regular)\nprint(\"no. of negative Hastags :\", HT_negative)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing unwanted patterns from the data\n\nimport re\nimport nltk\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = []\n\nfor i in range(0, 5572):\n  review = re.sub('[^a-zA-Z]', ' ', data['message'][i])\n  review = review.lower()\n  review = review.split()\n  \n  ps = PorterStemmer()\n  \n  # stemming\n  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n  \n  # joining them back with space\n  review = ' '.join(review)\n  corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating bag of words\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer()\nx = cv.fit_transform(corpus).toarray()\ny = data.iloc[:, 0]\n\nprint(x.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the training data into train and valid sets\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# standardization\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nmodel = RandomForestClassifier()\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nprint(\"Training Accuracy :\", model.score(x_train, y_train))\nprint(\"Testing Accuracy :\", model.score(x_test, y_test))\n\n# classification report\ncr = classification_report(y_test, y_pred)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix\ncm = confusion_matrix(y_test.values, y_pred)\nsns.heatmap(cm, annot = True)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}