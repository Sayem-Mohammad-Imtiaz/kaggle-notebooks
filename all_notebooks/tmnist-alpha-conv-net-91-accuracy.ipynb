{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Thank You very much for passing and check this out \n- This is my very first Convolutional Neural Network\n- In here you will find some amazing charts such as ***Circular Bar Chart**\n- Some technique that I learn - such as *** apply Batch Normalizarion before Passing into Fuction/transformation ***\n\n### Interesting fact\n- I am surprised that the model didnt improve after applied Image Augmentation *** Maybe I was not doing properly***  please let your comment / or any feedback below \n- This is a Very common architecture but it was very porwerfull, Eventually i will use transfer learning with Google models to compare or learn how to improve this model \n","metadata":{}},{"cell_type":"markdown","source":"# Libraries and Fuctions","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nimport tensorflow as tf \nfrom keras.utils import to_categorical\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:09:38.273837Z","iopub.execute_input":"2021-09-13T10:09:38.274241Z","iopub.status.idle":"2021-09-13T10:09:44.610863Z","shell.execute_reply.started":"2021-09-13T10:09:38.274155Z","shell.execute_reply":"2021-09-13T10:09:44.609789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Plotting\ndef Plotting_NeuralNet (data):\n    fig, ax = plt.subplots(1,2 , figsize = (20,7))\n    # summarize history for accuracy\n    ax[0].plot(data.history['accuracy'])\n    ax[0].plot(data.history['val_accuracy'])\n    ax[0].set_title('model accuracy')\n    ax[0].legend(['train', 'test'], loc='upper left')\n\n    # summarize history for loss\n    ax[1].plot(data.history['loss'], label =['loss'])\n    ax[1].plot(data.history['val_loss'] ,label =['val_loss'])\n    ax[1].set_title('model loss')\n    ax[1].legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n#### Visualization\ndef get_label_rotation(angle, offset):\n    # Rotation must be specified in degrees :(\n    rotation = np.rad2deg(angle + offset)\n    if angle <= np.pi:\n        alignment = \"right\"\n        rotation = rotation + 180\n    else: \n        alignment = \"left\"\n    return rotation, alignment\n\ndef add_labels(angles, values, labels, offset, ax):\n    \n    # This is the space between the end of the bar and the label\n    padding = 4\n    \n    # Iterate over angles, values, and labels, to add all of them.\n    for angle, value, label, in zip(angles, values, labels):\n        angle = angle\n        \n        # Obtain text rotation and alignment\n        rotation, alignment = get_label_rotation(angle, offset)\n\n        # And finally add the text\n        ax.text(x=angle, y=value + padding, \n            s=label, ha=alignment, va=\"center\", \n            rotation=rotation, rotation_mode=\"anchor\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:09:44.613718Z","iopub.execute_input":"2021-09-13T10:09:44.614025Z","iopub.status.idle":"2021-09-13T10:09:44.628165Z","shell.execute_reply.started":"2021-09-13T10:09:44.613996Z","shell.execute_reply":"2021-09-13T10:09:44.626817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"# Getting Data <----------\npath = '../input/tmnist-alphabet-94-characters/94_character_TMNIST.csv'\ndf = pd.read_csv(path)\ndf.sample()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:09:44.631639Z","iopub.execute_input":"2021-09-13T10:09:44.632291Z","iopub.status.idle":"2021-09-13T10:10:12.078199Z","shell.execute_reply.started":"2021-09-13T10:09:44.632247Z","shell.execute_reply":"2021-09-13T10:10:12.076945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization\n\n- The following Visualization is known as ***Circular bar chart*** each group A,B,C,D represent the different types of data, ***Numbers, Symbols, Letters, etc***\n- The ***Left circular*** bar chart represents the number of pixels in each image - the represeantion might not be that accuracte because I had to scale and the visualization is for practicing purpose only.\n- The  ***Rigth circular*** bar chart represents the number of imaes or distribution.\n- ***Observation*** The data is well Distributed, each class has equal number of images as you can see in the Circular chart bar ","metadata":{}},{"cell_type":"code","source":"# All labels\nall_ = list(df['labels'].unique())\n\n# Regex Pattern\npattern_uc = re.compile(r\"[A-Z]\")\npattern_lc = re.compile(r\"[a-z]\")\npattern_numbers = re.compile(r\"[0-9]\")\npattern_symbols = re.compile(r\"[\\W]|[\\_\\,]\")\n\n# Extracting Pattern\nlower_case = pattern_lc.findall(str(all_))\nUpper_case = pattern_uc.findall(str(all_))\nNumbers_ = pattern_numbers.findall(str(all_))\nSymbols_ = list(set(pattern_symbols.findall(str(all_))))\nSymbols_.pop(27)\n\n# Creating Gropus\ngroup = 1\nfor list_ in (lower_case,Upper_case,Numbers_,Symbols_):\n    df.loc[df['labels'].isin(list_), 'group'] = str(group)\n    group += 1\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:10:12.080518Z","iopub.execute_input":"2021-09-13T10:10:12.080945Z","iopub.status.idle":"2021-09-13T10:10:12.213902Z","shell.execute_reply.started":"2021-09-13T10:10:12.080904Z","shell.execute_reply":"2021-09-13T10:10:12.212832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VALUES = df.groupby(['labels']).sum().reset_index()\nVALUES = (VALUES.iloc[:,1:-1].sum(axis=1))*0.000001\nIMAGES_ = (df.groupby(['labels']).count()['names'].values)*0.025\nLABELS = df.groupby(['labels','group']).count().reset_index().sort_values('group')['labels'].values\nGROUP = df.groupby(['labels','group']).count().reset_index().sort_values('group')['group'].values\nGROUPS_SIZE = [26, 26, 10, 32]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-13T10:10:12.215372Z","iopub.execute_input":"2021-09-13T10:10:12.215836Z","iopub.status.idle":"2021-09-13T10:10:18.934572Z","shell.execute_reply.started":"2021-09-13T10:10:12.215792Z","shell.execute_reply":"2021-09-13T10:10:18.932912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add three empty bars to the end of each group\nPAD = 3\nANGLES_N = len(VALUES) + PAD * len(np.unique(GROUP))\nANGLES = np.linspace(0, 2 * np.pi, num=ANGLES_N, endpoint=False)\nWIDTH = (2 * np.pi) / len(ANGLES)\n\noffset = 0\nOFFSET = np.pi / 2\nIDXS = []\nGROUPS_SIZE = [26, 26, 10, 32]\n\nfor size in GROUPS_SIZE:\n    IDXS += list(range(offset + PAD, offset + size + PAD))\n    offset += size + PAD\n\nfig, ax = plt.subplots(1,2,figsize=(20, 10), subplot_kw={\"projection\": \"polar\"})\nax[0].set_theta_offset(OFFSET)\nax[0].set_ylim(-100, 100)\nax[0].set_frame_on(False)\nax[0].xaxis.grid(False)\nax[0].yaxis.grid(False)\nax[0].set_xticks([])\nax[0].set_yticks([])\n\nCOLORS = [f\"C{i}\" for i, size in enumerate(GROUPS_SIZE) for _ in range(size)]\n\nax[0].bar(\n    ANGLES[IDXS], VALUES, width=WIDTH, color=COLORS, \n    edgecolor=\"white\", linewidth=2\n)\n\nadd_labels(ANGLES[IDXS], VALUES, LABELS, OFFSET, ax[0])\noffset = 0 \nfor group, size in zip([\"Lower\",\"Upper\",\"Numb\",\"Symb\"], GROUPS_SIZE):\n    # Add line below bars\n    x1 = np.linspace(ANGLES[offset + PAD], ANGLES[offset + size + PAD - 1], num=50)\n    ax[0].plot(x1, [-5] * 50, color=\"#333333\")\n    \n    # Add text to indicate group\n    ax[0].text(\n        np.mean(x1), -20, group, color=\"#333333\", fontsize=14, \n        fontweight=\"bold\", ha=\"center\", va=\"center\"\n    )\n    \n    # Add reference lines at 20, 40, 60, and 80\n    x2 = np.linspace(ANGLES[offset], ANGLES[offset + PAD - 1], num=50)\n    ax[0].plot(x2, [20] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [40] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [60] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [80] * 50, color=\"#bebebe\", lw=0.8)\n    \n    offset += size + PAD\n    \n# -------------------------------------\nPAD = 3\nANGLES_N = len(IMAGES_) + PAD * len(np.unique(GROUP))\nANGLES = np.linspace(0, 2 * np.pi, num=ANGLES_N, endpoint=False)\nWIDTH = (2 * np.pi) / len(ANGLES)\n\noffset = 0\nOFFSET = np.pi / 2\nIDXS = []\nGROUPS_SIZE = [26, 26, 10, 32]\n\nfor size in GROUPS_SIZE:\n    IDXS += list(range(offset + PAD, offset + size + PAD))\n    offset += size + PAD\n    \nax[1].set_theta_offset(OFFSET)\nax[1].set_ylim(-100, 100)\nax[1].set_frame_on(False)\nax[1].xaxis.grid(False)\nax[1].yaxis.grid(False)\nax[1].set_xticks([])\nax[1].set_yticks([])\n\nCOLORS = [f\"C{i}\" for i, size in enumerate(GROUPS_SIZE) for _ in range(size)]\n\nax[1].bar(\n    ANGLES[IDXS], IMAGES_, width=WIDTH, color=COLORS, \n    edgecolor=\"white\", linewidth=2\n)\n\nadd_labels(ANGLES[IDXS], IMAGES_, LABELS, OFFSET, ax[1])\noffset = 0 \nfor group, size in zip([\"Lower\",\"Upper\",\"Numb\",\"Symb\"], GROUPS_SIZE):\n    # Add line below bars\n    x1 = np.linspace(ANGLES[offset + PAD], ANGLES[offset + size + PAD - 1], num=50)\n    ax[1].plot(x1, [-5] * 50, color=\"#333333\")\n    \n    # Add text to indicate group\n    ax[1].text(\n        np.mean(x1), -20, group, color=\"#333333\", fontsize=14, \n        fontweight=\"bold\", ha=\"center\", va=\"center\"\n    )\n    \n    # Add reference lines at 20, 40, 60, and 80\n    x2 = np.linspace(ANGLES[offset], ANGLES[offset + PAD - 1], num=50)\n    ax[1].plot(x2, [20] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [40] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [60] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [80] * 50, color=\"#bebebe\", lw=0.8)\n    \n    offset += size + PAD\n ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:10:18.936664Z","iopub.execute_input":"2021-09-13T10:10:18.937131Z","iopub.status.idle":"2021-09-13T10:10:34.22594Z","shell.execute_reply.started":"2021-09-13T10:10:18.937088Z","shell.execute_reply":"2021-09-13T10:10:34.224985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spliting Labels & Images ","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:, 2:-1].astype('float32') # Splitting and turning into Float\ny  = df[['labels']] #Extracting Labels","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:10:56.440642Z","iopub.execute_input":"2021-09-13T10:10:56.441005Z","iopub.status.idle":"2021-09-13T10:10:57.56281Z","shell.execute_reply.started":"2021-09-13T10:10:56.440972Z","shell.execute_reply":"2021-09-13T10:10:57.561693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = y['labels'].unique()\nvalues = [num for num in range(len(df['labels'].unique()))]\nlabel_dict= dict(zip(labels,values)) #Creating Dictionary \nlabel_dict_inv = dict(zip(values,labels))\n\nprint(sorted(label_dict.items(), key=lambda x:x[1])[35:45])  #For visualization Purpose","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:10:57.564723Z","iopub.execute_input":"2021-09-13T10:10:57.565184Z","iopub.status.idle":"2021-09-13T10:10:57.610917Z","shell.execute_reply.started":"2021-09-13T10:10:57.565139Z","shell.execute_reply":"2021-09-13T10:10:57.60955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming\ny['labels'].replace(label_dict, inplace=True) #Maping Values\ny.tail(5)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:10:59.11042Z","iopub.execute_input":"2021-09-13T10:10:59.110887Z","iopub.status.idle":"2021-09-13T10:11:00.66567Z","shell.execute_reply.started":"2021-09-13T10:10:59.110856Z","shell.execute_reply":"2021-09-13T10:11:00.664574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Training and Test Sets","metadata":{"execution":{"iopub.status.busy":"2021-09-07T01:56:11.331636Z","iopub.execute_input":"2021-09-07T01:56:11.33205Z","iopub.status.idle":"2021-09-07T01:56:11.336283Z","shell.execute_reply.started":"2021-09-07T01:56:11.332015Z","shell.execute_reply":"2021-09-07T01:56:11.335595Z"}}},{"cell_type":"markdown","source":"### Reshaping and Displaying some Images","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:11:04.01552Z","iopub.execute_input":"2021-09-13T10:11:04.016033Z","iopub.status.idle":"2021-09-13T10:11:05.254541Z","shell.execute_reply.started":"2021-09-13T10:11:04.015993Z","shell.execute_reply":"2021-09-13T10:11:05.253397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Length, Height = 28,28  # <---- Defining LxH \nNCl = y_train.nunique()[0] # Unique targets -- > 94 \n\n# ------>  N of images 28x28\nX_train = np.reshape(X_train.values, (X_train.shape[0] ,Length, Height)) \nX_test = np.reshape(X_test.values, (X_test.shape[0] ,Length, Height))\n\n# -------> Target into Categorical Values\ny_train = to_categorical(y_train, NCl, dtype='int' )\ny_test = to_categorical(y_test, NCl, dtype='int' )\n\nprint(f'X:Train, Test data shape:{X_train.shape},{X_test.shape}')\nprint(f'Y:Train, Test data shape:{y_train.shape},{y_test.shape}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:11:05.257749Z","iopub.execute_input":"2021-09-13T10:11:05.258394Z","iopub.status.idle":"2021-09-13T10:11:05.381743Z","shell.execute_reply.started":"2021-09-13T10:11:05.25835Z","shell.execute_reply":"2021-09-13T10:11:05.380574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random = shuffle(X_train[:500]) #Randomly shuffle (array  in a consistent way)\nfig,ax = plt.subplots(3,4 , figsize = (10,10)) \naxes = ax.flatten()\n\nfor i in range(12):\n    _,shu = cv2.threshold(random[i], 30, 200, cv2.THRESH_BINARY)\n    axes[i].imshow(np.reshape(random[i], (Length, Height)), cmap = 'Greys')\nplt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-13T10:11:06.390634Z","iopub.execute_input":"2021-09-13T10:11:06.391019Z","iopub.status.idle":"2021-09-13T10:11:07.66004Z","shell.execute_reply.started":"2021-09-13T10:11:06.390989Z","shell.execute_reply":"2021-09-13T10:11:07.658735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Deep Learning FrameWork\n\n- This is a representation of the Architecture that Iw as using \nStarted with 32 Conv - > Apply some Batch Normalization -> ReLu Transformation X 3 - > Flatten - Dense Layer \n*** My apology*** , the visualization wasnt that good, in my defense I can say I was in my way to my job when I posted this \"Code\".","metadata":{"execution":{"iopub.status.busy":"2021-09-07T02:23:28.039647Z","iopub.execute_input":"2021-09-07T02:23:28.040044Z","iopub.status.idle":"2021-09-07T02:23:28.051258Z","shell.execute_reply.started":"2021-09-07T02:23:28.040012Z","shell.execute_reply":"2021-09-07T02:23:28.050481Z"}}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential,load_model\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D,Flatten,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:11:13.223551Z","iopub.execute_input":"2021-09-13T10:11:13.22395Z","iopub.status.idle":"2021-09-13T10:11:13.232702Z","shell.execute_reply.started":"2021-09-13T10:11:13.223903Z","shell.execute_reply":"2021-09-13T10:11:13.231514Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display\nfrom PIL import Image\npath=('../input/convo-image/Convo.png')\ndisplay(Image.open(path))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:14:27.869114Z","iopub.execute_input":"2021-09-13T10:14:27.869555Z","iopub.status.idle":"2021-09-13T10:14:27.993847Z","shell.execute_reply.started":"2021-09-13T10:14:27.869506Z","shell.execute_reply":"2021-09-13T10:14:27.992845Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reshaping for CNN","metadata":{"execution":{"iopub.status.busy":"2021-09-07T01:34:06.2384Z","iopub.execute_input":"2021-09-07T01:34:06.239039Z","iopub.status.idle":"2021-09-07T01:34:06.262235Z","shell.execute_reply.started":"2021-09-07T01:34:06.238985Z","shell.execute_reply":"2021-09-07T01:34:06.261156Z"}}},{"cell_type":"code","source":"RGB = 1  # In this case only one instead of 3 because we dont have Color images\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1],X_train.shape[2], RGB)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],RGB)\n\n\nX_train = X_train/255\nX_test = X_test/255\nprint(f'Train, Test shapes: {X_train.shape},{X_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:11:18.396849Z","iopub.execute_input":"2021-09-13T10:11:18.397582Z","iopub.status.idle":"2021-09-13T10:11:18.759713Z","shell.execute_reply.started":"2021-09-13T10:11:18.397528Z","shell.execute_reply":"2021-09-13T10:11:18.758248Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First Convolutional Architecture","metadata":{}},{"cell_type":"code","source":"model = Sequential ()\n\n# Conv -> Maxpool - Dropout [1st - 4rd] ~ Flatten - >  Dense - Dense - output \nmodel.add(Conv2D(filters = 32 , kernel_size = (3,3),input_shape = (Length, Height, RGB), padding = 'same',))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32 , kernel_size = (3,3) ,padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64 , kernel_size = (3,3) ,padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(350))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(NCl, activation = 'softmax'))\n# model.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:11:20.101718Z","iopub.execute_input":"2021-09-13T10:11:20.102084Z","iopub.status.idle":"2021-09-13T10:11:22.66097Z","shell.execute_reply.started":"2021-09-13T10:11:20.102053Z","shell.execute_reply":"2021-09-13T10:11:22.659889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer  = Adam(learning_rate=0.01)\ncallback =EarlyStopping(monitor='loss', patience=5)\nBatch_ = 64\nEpochs_ = 50\n\n#Training -------------- >\nmodel.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\nhistory= model.fit(X_train,y_train, validation_data = (X_test,y_test),batch_size = Batch_ ,\n                   epochs = Epochs_, verbose = 0)\n\nscore = model.evaluate(X_test,y_test, batch_size = Batch_)\nprint(f\"Loss:{round(score[0],4)}\")\nprint(f\"Test Accuracy:{round(score[1],4)}\")\nPlotting_NeuralNet(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making Prediction","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28)) # reshaping it for displaying\n    ax.imshow(img, cmap=\"Greys\")\n    img_final =np.reshape(img, (1,28,28,1)) # reshapng it for passing into model for prediction\n    pred = label_dict_inv[np.argmax(model.predict(img_final))]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:12:06.170604Z","iopub.execute_input":"2021-09-13T10:12:06.17096Z","iopub.status.idle":"2021-09-13T10:12:14.435762Z","shell.execute_reply.started":"2021-09-13T10:12:06.170929Z","shell.execute_reply":"2021-09-13T10:12:14.434634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Second Convolutional Architecture + Data Augmentation","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Batch_ = 62\nhistory= model.fit_generator(datagen.flow(X_train,y_train,batch_size = Batch_), \n                             validation_data = (X_test,y_test), epochs = Epochs_,callbacks=[callback], verbose = 0)\nscore = model.evaluate(X_test,y_test, batch_size = Batch_)\nprint(f\"Test Score:{round(score[0],4)}\")\nprint(f\"Test Accuracy:{round(score[1],4)}\")\nPlotting_NeuralNet(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making Predictions","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28)) # reshaping it for displaying\n    ax.imshow(img, cmap=\"Greys\")\n    img_final =np.reshape(img, (1,28,28,1)) # reshapng it for passing into model for prediction\n    pred = label_dict_inv[np.argmax(model.predict(img_final))]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning and More......","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:29:18.613884Z","iopub.execute_input":"2021-09-13T10:29:18.614251Z","iopub.status.idle":"2021-09-13T10:29:18.620352Z","shell.execute_reply.started":"2021-09-13T10:29:18.614221Z","shell.execute_reply":"2021-09-13T10:29:18.618625Z"}}}]}