{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Advanced Python Project – Detecting Fake News\n\nDo you trust all the news you hear from social media? All news are not real, right? So how will you detect the fake news? The answer is Python. By practicing this advanced python project of detecting fake news, you will easily make a difference between real and fake news. Before moving ahead in this advanced Python project, get aware of the terms related to it like fake news, **tfidfvectorizer, PassiveAggressive Classifier.**\n\n![](https://rsf.org/sites/default/files/styles/rsf_full/public/fake-news-dz.png?itok=sa-knSuC&timestamp=1587642210)"},{"metadata":{},"cell_type":"markdown","source":"### A) What is Fake News?\nA type of yellow journalism, fake news encapsulates pieces of news that may be hoaxes and is generally spread through social media and other online media. This is often done to further or impose certain ideas and is often achieved with political agendas. Such news items may contain false and/or exaggerated claims, and may end up being viralized by algorithms, and users may end up in a filter bubble.\n\n### B) What is a TfidfVectorizer?\n\n#### TF:\n(Term Frequency): The number of times a word appears in a document is its Term Frequency. A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms.\n\n#### IDF \n(Inverse Document Frequency): Words that occur many times a document, but also occur many times in many others, may be irrelevant. IDF is a measure of how significant a term is in the entire corpus.\n\nThe TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features.\n\n### C) What is a PassiveAggressiveClassifier?\nPassive Aggressive algorithms are online learning algorithms. Such an algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting. Unlike most other algorithms, it does not converge. Its purpose is to make updates that correct the loss, causing very little change in the norm of the weight vector."},{"metadata":{},"cell_type":"markdown","source":"### The Dataset\nThe dataset we’ll use for this python project- we’ll call it news.csv. This dataset has a shape of 7796×4. The first column identifies the news, the second and third are the title and text, and the fourth column has labels denoting whether the news is REAL or FAKE. The dataset takes up 29.2MB of space and you can download it here."},{"metadata":{},"cell_type":"markdown","source":"# Steps 1 for detecting fake news with Python\n\n\n## 1) Make necessary imports:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#default theme\nplt.style.use('ggplot')\nsns.color_palette(\"tab10\")\nsns.set(context='notebook', style='darkgrid', font='sans-serif', font_scale=1, rc=None)\nmatplotlib.rcParams['figure.figsize'] =[20,8]\nmatplotlib.rcParams.update({'font.size': 15})\nmatplotlib.rcParams['font.family'] = 'sans-serif'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Now, let’s read the data into a DataFrame, and get the shape of the data and the first 5 records."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the data\ndf=pd.read_csv('../input/textdb3/fake_or_real_news.csv')\n\n#Get shape and head\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3) get the labels from the DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"#DataFlair - Get the labels\nlabels=df.label\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=df.label.value_counts()\ntarget","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.label)\nplt.title('the number of news fake/real');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4) Split the dataset into training and testing sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"#DataFlair - Split the dataset\nx_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5) initialize a TfidfVectorizer"},{"metadata":{},"cell_type":"markdown","source":"#### Let’s initialize a TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features. Now, fit and transform the vectorizer on the train set, and transform the vectorizer on the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#DataFlair - Initialize a TfidfVectorizer\ntfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n\n#DataFlair - Fit and transform train set, transform test set\ntfidf_train=tfidf_vectorizer.fit_transform(x_train) \ntfidf_test=tfidf_vectorizer.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6) initialize a PassiveAggressiveClassifier"},{"metadata":{},"cell_type":"markdown","source":"#### Next, we’ll initialize a PassiveAggressiveClassifier. This is. We’ll fit this on tfidf_train and y_train.\n\n#### Then, we’ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"#DataFlair - Initialize a PassiveAggressiveClassifier\npac=PassiveAggressiveClassifier(max_iter=50)\npac.fit(tfidf_train,y_train)\n\n#DataFlair - Predict on the test set and calculate accuracy\ny_pred=pac.predict(tfidf_test)\nscore=accuracy_score(y_test,y_pred)\nprint(f'Accuracy: {round(score*100,2)}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We got an accuracy of 92.82% with this model. Finally, let’s print out a confusion matrix to gain insight into the number of false and true negatives and positives."},{"metadata":{},"cell_type":"markdown","source":"## 7) confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"#DataFlair - Build confusion matrix\nconfusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary\n\nToday, we learned to detect fake news with Python. We took a political dataset, implemented a TfidfVectorizer, initialized a PassiveAggressiveClassifier, and fit our model. We ended up obtaining an accuracy of 92.82% in magnitude.\n\n### Hope you enjoyed my first advanced level Python Project. Keep visiting [my profile](https://www.kaggle.com/midouazerty/code) for more interesting Python data science and machine learning projects."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}