{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Breast Cancer Wisconsin Veri Analizi"},{"metadata":{"trusted":true},"cell_type":"code","source":"#İhtiyacımız olan kütüphaneleri aktif ediyoruz\n#We are including packages\nimport numpy as np\nimport pandas as pd \nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nfrom sklearn.preprocessing import scale \nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom scipy.stats import shapiro\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verimizi df değişkenine atadık \n#we will denote with df to our dataset \ndf=pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\").copy()\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---TR---\nVerimizin ilk 5 satırını baktığımız zaman id ve Unnamed: 32 isimli iki tane gereksiz değişken var bunları veriden çıkaracaz\nAyriyeten bizim bağımlı değişkenimiz olan diagnosis'in kategorik değişken olduğu gözümüze çarpıyor ve diğer değişkenler float biçiminde\n---ENG---\nWhen we look head of our dataset , we have unnecessary variables(id and Unnamed:32). We will remove from dataset. \nDependent variable(diagnosis) is looking like categorical variable.Apart from diagnosis ,the others are looking like float."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"id\",'Unnamed: 32'],axis=1)#We removed unnecessary variables\n#Gereksiz değişkenlerimiz çıkardık","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()#Değişkenlerimizin biçimlerinin doğru olduğunu görüyoruz, diagnosis i belki sonradan kategorik yapabiliriz fakat object ten sıkıntı olmaz\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will not change types of our variables because there is no wrong thing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T#Veri setimizin betimsel istatistikleri \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing descriptive statistics. We can say some variables have got skewness ,and some variables have got normal distribution. However we need clean to data from outliers and missing values."},{"metadata":{},"cell_type":"markdown","source":"### Eksik Veri Analizi\n### Missing Values Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().values.sum()#Veri setimizde eksik veri olmadığını öğreniyoruz\n#We haven't any missing value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aykırı Gözlem Analizi\n### Outliers Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.radius_mean,df.diagnosis)\n#We are seeing outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.smoothness_mean,df.diagnosis)#Veri setimizi incelediğimizde aykırı gözlemlerin olduğunu görüyoruz\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Baskılama Yöntemiyle Aykırı değerlerin çözümü\nfor i in range(1,len(df.columns)):\n    Q1=df.iloc[:,i].quantile(0.25)\n    Q3=df.iloc[:,i].quantile(0.75)\n    IQR=Q3-Q1\n    alt_sinir=Q1-1.5*IQR\n    ust_sinir=Q3+1.5*IQR\n    df.iloc[:,i][(df.iloc[:,i]<alt_sinir)]=alt_sinir\n    df.iloc[:,i][(df.iloc[:,i]>ust_sinir)]=ust_sinir\n##Yukarıda baskılama yöntemi yaptık yani veri setimizdeki aykırı gözlemleri en yakın olduğu sınır noktasına eşitledik\n##Outliers is assigned  to upper and lower limits ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.radius_mean)#Now we can see clean boxplot ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.smoothness_mean)#Gördüğümüz gibi veri setimizde uç noktalar baskılama yöntemiyle temizlendi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Temizlenen Verinin Grafiksel Olarak İncelenmesi\n### Examine Of Clean Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T #Temizlenen verimizin betimsel istatistiklerine tekrardan bakalım\n#Verinin ilk haliyle incelediğimiz standart sapmalarda azalma olduğunu görüyoruz\n#Biraz daha normal dağılıma doğru yöneldiği farkediliyor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we clean our dataset , mean and standart deviation dicreased. Now we can look distribution of variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.diagnosis)#Kanser türlerinin veri setindeki sayıları\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,hue=\"diagnosis\",kind=\"scatter\")\n#  Verimizdeki her değişkenin birbiriyle olan ilişkilerini kategorik değişkenlerimizin kırılımında incelediğimiz zaman\n#Melignant grubunun değişkenlerin çoğunda incelendiğinde Bening grubuna göre daha büyük  değerler aldığı görülüyor\n#  Değişkenlerin dağılımını incelediğimizde normal dağılım gibi duruyor fakat dağılım grafiğine bakıldığında basıklığının \n#çok düşük olduğu yani sivrilikler gözümüze çarpıyor Shapiro_Wilk testi yapılmasında fayda var.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we look pairplot ,we can say \"if variable value increase ,independent variable is being Malignant\".\nVariables distribution are looking normal but we can say when look shapiro test. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.radius_mean,label=\"radius\")\nsns.distplot(df.texture_mean,label=\"texture\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shapiro(df.texture_mean)#Ne kadar texture değişkeni normal dağılmış gibi de dursa shapiro testimizin p-value değeri 0.05 den\n#küçük olduğunda H0:Veriler normal dağılım gösterir hipotezi red edilir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to shapiro test our variables not normal but we won't care because now this is not our topic."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()#Veri setimizin koralesyon grafiği\n#Correlation graphic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nsns.heatmap(df.corr(), annot=True)\n#we can see better like this","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---TR---\nVeri setimizdeki değişkenlerin korelasyonlarını incelediğimiz zaman bazı değişkenler arasında çok yüksek korelasyon bağları\nbağları olduğu görülüyor ki bazılarına baktığımızda bile korelasyon değerimiz 1 olanlar var.Bu da çoklu lineer bağıntı \nproblemine neden olabilir ve değişken sayımızın çokluğundan dolayı verimize ayriyeten temel bileşen analizi yapacaz.\n---ENG---\nfirstly we have a problem . This problem multicollinearity. Maybe we can remove some variables that have correlation above %95 but we won't this because we have two solution. \n1)principal composite analysis\n2)algorithms like random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=df.symmetry_mean,y=df.symmetry_worst,kind=\"reg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelleme \n### Modelling"},{"metadata":{},"cell_type":"markdown","source":"---TR---\nDeğişkenlerimizi dokunmadan modelleme yaptığımızda en yüksek doğruluk oranını RandomForests sınıflandırma algoritması elde etti.\nRandomForests sınıflandırması : temeli birden fazla karar ağacının ürettiği tahminlerin bir arayı getirilerek değerlendirilmesine dayanır.\nRandomForests algoritmasının diğer bir tecih sebebi ise çoklu doğrusal bağlantı ve aşırı öğrenme problemleriyle baş edebilme özelliğindendir.\n---ENG---\nI tried  various algorithms but i chose to RandomForests\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop([\"diagnosis\"],axis=1).copy()\ny=pd.DataFrame(df.diagnosis,dtype=\"category\")\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\nlgbm=RandomForestClassifier().fit(X_train,y_train)\ny_pred=lgbm.predict(X_test)\naccuracy_score(y_test, y_pred)#Modelimizin doğruluk oranı","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(lgbm, X_test, y_test, cv = 10).mean()#Cross valid skorumuz\n","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"#Modelimiz için en iyi parametreleri buluyoruz\n#We will choose best parameters for our model\nrf_params = {\"max_depth\": [2,5,8,10],\n            \"max_features\": [2,5,8],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}\nrf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2).fit(X_train,y_train)\nprint(\"En iyi parametreler: \" + str(rf_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#En iyi parametrelerle oluşan yeni modelimiz\nlgbm=RandomForestClassifier(max_depth= 8, max_features= 8, min_samples_split= 5, n_estimators= 1000).fit(X_train,y_train)\ny_pred=lgbm.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(lgbm, X_test, y_test, cv = 10).mean()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We saw cross_val_score and accuracy score with best parameters, and we will compare after we do pca"},{"metadata":{},"cell_type":"markdown","source":"Kurduğumuz random forests sınıflandırma algoritmasındaki en iyi algoritma değerlerini elde etmek için parametrelere rastgele değer atayarak tek tek hepsi için farklı değerler verdik. \nEn iyi parametre değerleri üzerinden bir modelleme yaptığımız zaman doğruluk oranlarımızın arttığını görüyoruz."},{"metadata":{},"cell_type":"markdown","source":"Cross validation score nedir?\nNormalde veri setimizin belli bir oranını test ve train olarak ikiye ayırırız.Mesela yukarıda verinin %25 lik kısmını test,\n%75 lik kısmını ise train seti olarak ayırdık. Burada amaç bilgisayarı train setiyle eğitip test veri seti üzerinden ise\nsınama yapmaktır. Daha doğru sonuçlara ve aşırı öğrenme sorununun önüne geçmek için ise train veri setimizi k tane parçaya \nayırırız. Mesela yukarıda cv=10 kısma ayırıyoruz. 10 parçadan birini çıkarıp modelimizi 9 parçalık train setiyle eğitim,kalan\nbir parçayla validation hatamızı ölçüyoruz. Bunu diğer parçalara da uygulayıp hepsinin ortalamasını alıyoruz. Bu yaptığımız \nişleme cross validation score adı verilir ve bu test hatamızın kötü bir tahmin edicisidir ve genelde daha düşük bir doğruluk\noranı çıkmasını bekleriz.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Temel Bileşen Analizi ve Modelleme\n### PCA and Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Temel Bileşen Analiziyle Modelleme Yapıyoruz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=df.drop([\"diagnosis\"],axis=1).copy()\nfrom sklearn.preprocessing import StandardScaler\npca1=StandardScaler().fit_transform(pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca2=PCA(n_components=2)#Kaç temel bileşene ayrılacağını gösteriyor\npca2_fit=pca2.fit_transform(pca1)\n#We choose two components because we can explain easier than more components and we will see that we will take best scores\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bilesendf=pd.DataFrame(data=pca2_fit)\npca2.explained_variance_ratio_.cumsum()#Varyansı açıklama oranına bakıldığında 2 bileşenle açıklayabildiğini görüyoruz\n#We have sufficient explained variance ratio and this value must be least %66","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pca2.explained_variance_ratio_.cumsum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bilesenpca=pd.concat([bilesendf,df.diagnosis],axis=1).copy()\nbilesenpca.columns=[\"birinci_bilesen\",\"ikinci_bilesen\",\"diagnosis\"]\nbilesenpca.head()\n#Temel bileşen analizi sonucunda oluşan veri setimize bağımlı değişkenimizi ekleyerek üzerinde modelleme yapacaz.\n#We added our dependent variable to pca dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LGBM algoritmasını deniyoruz burada\nk=[]\nl=[]\nfor i in  range(0,30):\n    pca2=PCA(n_components=i)\n    pca2_fit=pca2.fit_transform(pca)\n    bilesendf=pd.DataFrame(data=pca2_fit)\n    X=bilesendf\n    y=df.diagnosis\n    X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.25)\n    lgbm_model=LGBMClassifier().fit(X_train,y_train)\n    k.append(accuracy_score(y_test,lgbm_model.predict(X_test)))\n    l.append(cross_val_score(lgbm_model, X_test, y_test, cv = 10).mean())\nk=pd.DataFrame(k)\nl=pd.DataFrame(l)\nkl=pd.concat([k,l],axis=1)\nkl.columns=[\"accurary\",\"cross\"]\nprint(kl[kl.accurary==max(kl.accurary)].index[0],\". components for best accurary score:\",kl[kl.accurary==max(kl.accurary)])\nprint(\"------------\")\nprint(kl[kl.cross==max(kl.cross)].index[0],\". components  for best cross_val_score değeri:\",kl[kl.cross==max(kl.cross)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in above we can see in which components we have best accurary score and cross val score but we used LGBMClassifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"#RandomForest Algoritmasını deniyoruz\nX=bilesendf\ny=df.diagnosis\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.25)\nlgbm_model=RandomForestClassifier().fit(X_train,y_train)\naccuracy_score(y_test,lgbm_model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(lgbm_model, X_test, y_test, cv = 10).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we take best scores with pca "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accurary score ve cross_val skorlarına baktığımız zaman en iyi sonuçları randomforest algoritması verdi bizde bu algoritmayı seçiyoruz\nprint(classification_report(y_test, lgbm_model.predict(X_test)))\n#Classification report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the metrics class\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n#Kurduğumuz modeldeki tahminlerin kaç tanesinin doğru ve yanlış olduğu gösteriliyor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelin Başarısının Değerlendirilmesi"},{"metadata":{},"cell_type":"markdown","source":"Actual Label bizim gerçekteki sınıflarımız\nPredicted label tahminlerimizin sınıflarıdır.\nDoğruluk:Gerçekteki değerlerimizle tahmin edilen değerlerin doğru sınıflandırılanların tüm sınıflandırılanlara bölünmesidir\nHata oranı:Yaptığımız yanlış tahminlerin tüm tahminlere bölünmesidir.\nKesinlik:0 ken 0 seçilen gruplarımızın 0 ken 0 ve 0 ken 1 seçilen sınıfların toplamına bölünmesidir.\nAnma : 0 ken 0 seçilen gruplarımızın 0 ken 0 ve 1 ken 0 seçilen sınıfların toplamına bölünmesidir.\n"},{"metadata":{},"cell_type":"markdown","source":"Doğruluk oranımız (86+56)/(86+56+3+4) den 0.95 dir\nHata oranımız (4+7)/(86+56+7) den 0.048 dir\nKesinlik oranımız 86/(86+4) den 0.96 dır. Kesinlik oranının yüksek çıkması ise sınıflandırmanın doğru yapıldığını gösterir.\nAnma oranımız ise 86/(86+3) den 0.97 çıkmıştır. Anma oranımızın yüksek çıkması pozitif sınıfın doğru sınıflandırıldığını gösterir."},{"metadata":{"trusted":true},"cell_type":"code","source":"proba=pd.DataFrame(lgbm_model.predict_proba(X))\nproba.columns=[\"B\",\"M\"]\nproba.head()#Malignant hastalığı olma olasılığı verilmiştir Yani Tahmin olasılıkları","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Modelimizdeki bilesenlerin önem düzeyleri\nImportance = pd.DataFrame({\"Importance\": lgbm_model.feature_importances_*100},\n                         index = bilesenpca.columns[:2])\nImportance.sort_values(by=\"Importance\",axis=0,ascending=True).plot(kind=\"barh\",color=\"red\")\nplt.xlabel(\"Değişken Önem Düzeyleri\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=bilesenpca,kind=\"reg\")#Temel bileşen analizi sonucunda ilişkisiz iki matris oluşmuş","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of pca dataset and we didn't see correlation between first variable and second varible because this feature of pca "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.distplot(df.texture_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}