{"nbformat":4,"cells":[{"cell_type":"code","source":"##################\n#import libs\n##################\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"5cac5042b645ddf337b2b9f0daeb904b75a521cf","_cell_guid":"cc69b2ad-8398-4eac-8e56-32bc42f26ed3","collapsed":true}},{"cell_type":"code","source":"##################\n#read file of all.csv\n##################\ndata=pd.read_csv(\"../input/all.csv\",index_col=None )","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"9f574fc0410767c77ccae622bc015bc86a6c0096","_cell_guid":"587636de-7c7e-4d52-a4f4-37748591aec6","collapsed":true}},{"cell_type":"markdown","source":"#Data cleaning (since the data is from web crawler, it has some faults)","metadata":{"_execution_state":"idle","_uuid":"f2e0f60eefb2139c9deae183e93c37dcc4a12f4c","_cell_guid":"c7f4019f-4da4-4c70-9077-9580a8985d80"}},{"cell_type":"code","source":"##################\n# we remove the copyright data since it is a bad data\n##################\ndata=data[data.content.str.contains(\"Copyright\")==False]","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"792f4bdf88cdf65a81dd8b620d1d8c71e2298222","_cell_guid":"5a429a36-3118-4938-9d53-6698beaaa799","collapsed":true}},{"cell_type":"code","source":"##################\n# check whether there is any null data \n##################\ndata[data.content.isnull()==True].index.tolist()","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"0526dbbcf95401118d83f3ed7b30e6a0eb7b1366","_cell_guid":"b9c6fd08-46c0-4222-afee-dace9379a3bb","collapsed":true}},{"cell_type":"code","source":"# This is the fault data checked by my eye in csv file, so remove it  \ndata=data[data.content.str.contains(\"from Dana, 1904\")==False]","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"2515485704a77527a9fb7678e8eada4c9d84b068","_cell_guid":"77b88ad9-7fdf-487c-b768-13a6bf3af1c5","collapsed":true}},{"cell_type":"code","source":"##################\n#import NLP lib\n##################\nimport nltk","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"0b20d25778fc4ef9eacbb029e27dc195f51e48a1","_cell_guid":"6d5b57b3-52b8-48ab-96e3-d9ae58747b33","collapsed":true}},{"cell_type":"code","source":"##################\n# This function will check the rhyme\n# we call it in the funtion doTheyRhyme\n##################\ndef rhyme(inp, level):\n    entries = nltk.corpus.cmudict.entries()\n    syllables = [(word, syl) for word, syl in entries if word == inp]\n    rhymes = []\n    for (word, syllable) in syllables:\n        rhymes += [word for word, pron in entries if pron[-level:] == syllable[-level:]]\n    return set(rhymes)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"35b5fdefcb945db98789031ca1d4bb24ef85b292","_cell_guid":"ba4751e8-e947-4027-83e7-4f9094cf5675","collapsed":true}},{"cell_type":"code","source":"##################\n# decide the last word of the line to check the rhyme \n# call the function rhyme\n##################\ndef doTheyRhyme ( word1, word2 ):\n    # first, we don't want to report 'glue' and 'unglue' as rhyming words\n    # those kind of rhymes are LAME\n    if word1.find ( word2 ) == len(word1) - len ( word2 ):\n        return False\n    if word2.find ( word1 ) == len ( word2 ) - len ( word1 ): \n        return False\n\n    return word1 in rhyme ( word2, 1 )","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"0a5a0d5928f9cc825b460730d15d1a01bf06dc22","_cell_guid":"82d38e23-7284-498e-9063-4a9b295b9560","collapsed":true}},{"cell_type":"markdown","source":"# Rhyme, similes, repetitions, alliterations of the first poem ","metadata":{"_execution_state":"idle","_uuid":"36565f02b67d8ab4a5f0add7a45b837138cf7d9c","_cell_guid":"d035c49f-8497-41f8-aeb6-886a4ff9162b"}},{"cell_type":"code","source":"##################\n# convert all the content of the poem to lower case\n##################\ndata.content=data.content.str.lower()","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"a624a3adcbd802478fed55c377c3cef7dfe39ab7","_cell_guid":"a7ef2ea4-a6bf-43f6-9dfd-257ea8fb4dbb","collapsed":true}},{"cell_type":"code","source":"##################\n# First poem in our csv file\n##################\ndata.content[0]","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"33fc2fc6e4c7828cbe1efc44b3487a17e5bc1102","_cell_guid":"24464278-4ed4-4faa-9fc4-db629ffe281f","collapsed":true}},{"cell_type":"markdown","source":"make it more readable","metadata":{"_execution_state":"idle","_uuid":"90f5e9e743cb386a2856ad462ab70c2afeb806c8","_cell_guid":"cd73a127-8ed3-4001-98a5-bde873a2a0b0"}},{"cell_type":"code","source":"##################\n# function for checking the rhyme \n# of AAAA , AABB , ABAB , ABBA\n##################\ndef rhymeforpoem(content):\n    lin=(content).replace(\",\",\" \").replace(\".\",\" \").replace(\";\",\" \").replace(\":\",\" \").replace(\"!\",\" \")\n    line=lin.splitlines()\n    i=0\n    Set=[]\n    Sentence_set=[]\n    result=\"\"\n    #print (\"---last word of the sentence, see the below for the result ---\")\n    for li in line:\n        #print(li)\n        Sentence_set.append(li)\n        sp=li.split()\n        if (\"\".join(sp[-1:]) is None or  len(\"\".join(sp[-1:])) == 0 or \"\".join(sp[-1:])==\" \"):\n            continue\n        #print (str(i)+\" \"+\"\".join(sp[-1:]))\n        Set.append(\"\".join(sp[-1:]) )\n        if( len(Set)==4 or len(Set)==8 or len(Set)==12):\n            if(  doTheyRhyme(Set[len(Set)-4], Set[len(Set)-3] )==True and  doTheyRhyme(Set[len(Set)-3], Set[len(Set)-2] )==True and doTheyRhyme(Set[len(Set)-2], Set[len(Set)-1] )==True):\n                result= (\"AAAA\");\n            elif (  doTheyRhyme(Set[len(Set)-4], Set[len(Set)-3] )==True and  doTheyRhyme(Set[len(Set)-3], Set[len(Set)-2] )==False and doTheyRhyme(Set[len(Set)-2], Set[len(Set)-1] )==True):\n                result =(\"AABB\");\n            elif (  doTheyRhyme(Set[len(Set)-4], Set[len(Set)-2] )==True and  doTheyRhyme(Set[len(Set)-3], Set[len(Set)-1] )==False and doTheyRhyme(Set[len(Set)-3], Set[len(Set)-2] )==False):\n                result =(\"ABAB\");\n            elif (  doTheyRhyme(Set[len(Set)-4], Set[len(Set)-1] )==True and  doTheyRhyme(Set[len(Set)-3], Set[len(Set)-1] )==False and doTheyRhyme(Set[len(Set)-3], Set[len(Set)-2] )==True):\n                result =(\"ABBA\");\n        i=i+1\n    if(result==\"\"):    \n        result= (\"--No Rhyme--\");\n    #print(result)\n    return result\nprint(rhymeforpoem(data.content[0]))\n","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"862b470e1d566945fb8c3749e29183ae43c76bdb","_cell_guid":"03c16a18-91ec-4cf0-9b3c-1d36a4e9fca2","collapsed":true}},{"cell_type":"code","source":"##################\n# count the similes \n# first we replace the , ; : to space \n# and we split lines \n# and then we check whether like or as are in the line\n# which are words of similes \n##################\n\ndef similes_and_count (Sentence_set):\n    Sentence_set=(Sentence_set).replace(\",\",\" \").replace(\".\",\" \").replace(\";\",\" \").replace(\":\",\" \").replace(\"!\",\" \")\n    Sentence_set=Sentence_set.splitlines()\n    numb=0\n    for sen in Sentence_set:\n        sen_break = sen.split();\n        if (( \"like\"  in sen_break) or (\"as\"  in sen_break)):\n            #print (sen) \n            numb +=1\n    #print('total number of similes: '+str(numb))\n    return numb\n\n","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"542032ead3b77397bb2623f2565e4dd288c1d118","_cell_guid":"06f25fda-aa18-4f13-8b7f-7a14175ed999","collapsed":true}},{"cell_type":"code","source":"##################\n# function for alliterations\n# first we replace the , ; : to space \n# and we split lines \n# we make sure that the first character repeat again  by checking the stored character\n##################\n\ndef alliterations (Sentence_set):\n    numberofalliter=0\n    Sentence_set=(Sentence_set).replace(\",\",\" \").replace(\".\",\" \").replace(\";\",\" \").replace(\":\",\" \").replace(\"!\",\" \")\n    Sentence_set=Sentence_set.splitlines()\n    #print (\"--sentences for alliterations --\")\n    for sen in Sentence_set:\n        sen_break = sen.split();\n        if (sen_break is None or  len(sen_break) == 0 or sen_break==\" \"):\n            continue\n        counter=1\n        threeorfour=1\n        last_character=''\n        for ele_in in sen_break:\n            if (str(ele_in[0])==str(last_character)):\n                threeorfour+=1\n                if(threeorfour==3):\n                    #print (\" \".join(sen_break) )\n                    numberofalliter+=1\n            if(counter==1):\n                last_character=ele_in[0]\n            counter+=1\n    return numberofalliter          \nalliterations(data.content[153])","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"d32c1cc1340bfd02ed268158d81fe8330ce02ba8","_cell_guid":"894cb1b0-c0cf-4e42-9323-0b8945336ec9","collapsed":true}},{"cell_type":"code","source":"##################\n# testing the function repetitions \n# which will show below\n##################\nprint (\"--sentences for repetitions in I Care Not for These Ladies from docx--\")\nlin2=(data.content[153]).replace(\",\",\" \").replace(\".\",\" \").replace(\";\",\" \").replace(\":\",\" \").replace(\"!\",\" \")\nline2=lin2.splitlines()\nfor sen in line2:\n    line2.remove(sen)\n    if(sen in line2 and (sen is  None or  len(sen) == 0 or sen==\" \")==False  ):\n        print(sen)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"67c49fe46f0baa5a5edbc2460c43cec8117cb2c4","_cell_guid":"6cd5d9f6-4d9e-4821-8258-4e679e9dd29a","collapsed":true}},{"cell_type":"code","source":"##################\n# repetitions for whole line\n# we have to remove , . ; to chekc the repetitioin\n# \n##################\ndef repetitions(data):    # data is like data.content[153]\n    numbb=0\n    lin2=(data).replace(\",\",\" \").replace(\".\",\" \").replace(\";\",\" \").replace(\":\",\" \").replace(\"!\",\" \")\n    line2=lin2.splitlines()\n    for sen in line2:\n        line2.remove(sen)\n        if(sen in line2 and (sen is  None or  len(sen) == 0 or sen==\" \")==False  ):\n            #print(sen)\n            numbb+=1\n    return numbb\nrepetitions(data.content[153])","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"20fd2b2e066e02d556630a5071595de34baa0f3b","_cell_guid":"b0e1f42b-899e-4201-ac55-184f90627766","collapsed":true}},{"cell_type":"code","source":"##################\n# show the result of those function \n# metioned above\n#\n##################\nnumber_list=[\n238,\n497,\n547,\n58,\n411,\n78,\n404,\n247,\n207,\n101,\n356,\n434,\n476,\n560,\n256,\n180,\n495,\n18,\n40,\n473,\n541,\n41,\n159,\n286,\n132,\n290,\n568,\n352,\n80,\n46,\n68,\n50,\n441,\n463,\n156,\n252,\n437,\n540,\n448,\n375,\n254,\n276,\n178,\n281,\n429,\n237,\n71,\n530,\n129,\n144,\n511,\n343,\n133,\n203,\n435,\n255,\n72,\n438,\n235,\n37   \n]\n\nframe=pd.DataFrame({  'content number':[i for i  in number_list],\n                 'poem name': [ data['poem name'][i] for i  in number_list],\n                   'No of similes': [ similes_and_count(data.content[i]) for i  in number_list],\n                 'type of rhyme':[rhymeforpoem(data.content[i]) for i  in number_list ],\n                   'No of alliterations':[alliterations (data.content[i]) for i  in number_list  ],\n                   'No of whole line repetitions': [repetitions(data.content[i]) for i  in number_list]\n                    \n                 })\n\nframe = frame[['content number',  'poem name','No of similes',\n               'type of rhyme','No of alliterations',\n            'No of whole line repetitions' \n              ]]\nframe","outputs":[],"execution_count":null,"metadata":{"_execution_state":"busy","_uuid":"f2c9c19a4d4a6dfa3e0017b883e1dde3722fe4d1","_cell_guid":"eec5834e-93a5-4447-be26-338be05aa0f6","collapsed":true}},{"cell_type":"markdown","source":"#Convert data into feature \n\n 1. Turn all the sentence into lower case \n 2. Remove punctuation and Line break\n 3. Remove the word of the list in doc\n 4.  Find the word map using tfidfvectorizer library\n\n","metadata":{"_execution_state":"idle","_uuid":"7d18f4b0ce5e2a156dc3fdc186048b7192e4f82b","_cell_guid":"5d5b07ac-5e45-4f6c-8c2a-25df2f7bb9ef"}},{"cell_type":"code","source":"##################\n#  cleaning the data \n# by removing those \n# \\n \\t \\r \n##################\ndata.content=data.content.str.replace('\\n', \" \")\ndata.content=data.content.str.replace(\"\\t\", \" \")\ndata.content=data.content.str.replace(\"\\r\", \" \")\ndata.content=data.content.str.replace(\",\",\" \").replace(\".\",\" \")\n","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"0cf2da245381f65c9f5b9c32e53f6c8e21acfc7d","_cell_guid":"0076bf88-a319-4d3d-82c9-fa272c49a547","collapsed":true}},{"cell_type":"code","source":"##################\n# remove list in the document\n##################\nremove_list=[\"A\",\n\"An\",\n\"The\",\n\"Aboard\",\n\"About\",\n\"Above\",\n\"Absent\",\n\"Across\",\n\"After\",\n\"Against\",\n\"Along\",\n\"Alongside\",\n\"Amid\",\n\"Among\",\n\"Amongst\",\n\"Anti\",\n\"Around\",\n\"As\",\n\"At\",\n\"Before\",\n\"Behind\",\n\"Below\",\n\"Beneath\",\n\"Beside\",\n\"Besides\",\n\"Between\",\n\"Beyond\",\n\"But\",\n\"By\",\n\"Circa\",\n\"Concerning\",\n\"Considering\",\n\"Despite\",\n\"Down\",\n\"During\",\n\"Except\",\n\"Excepting\",\n\"Excluding\",\n\"Failing\",\n\"Following\",\n\"For\",\n\"From\",\n\"Given\",\n\"In\",\n\"Inside\",\n\"Into\",\n\"Like\",\n\"Minus\",\n\"Near\",\n\"Of\",\n\"Off\",\n\"On\",\n\"Onto\",\n\"Opposite\",\n\"Outside\",\n\"Over\",\n\"Past\",\n\"Per\",\n\"Plus\",\n\"Regarding\",\n\"Round\",\n\"Save\",\n\"Since\",\n\"Than\",\n\"Through\",\n\"To\",\n\"Toward\",\n\"Towards\",\n\"Under\",\n\"Underneath\",\n\"Unlike\",\n\"Until\",\n\"Up\",\n\"Upon\",\n\"Versus\",\n\"Via\",\n\"With\",\n\"Within\",\n\"Without\"]","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"d2677daaadcd24ced2b476a8b0d4e518e6bc01e8","_cell_guid":"41b57938-c49a-4d16-a1c1-3ec36c1b7d22","collapsed":true}},{"cell_type":"code","source":"##################\n# replace those words with space\n##################\nfor  value in remove_list:\n    data.content=data.content.str.replace(value,\" \")\ndata.content","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"d2548b8d2c730f2ca5cb2ee743d50b13f10d84a8","_cell_guid":"20ee1e72-145c-4653-a814-71e13c323576","collapsed":true}},{"cell_type":"code","source":"import re\n##################\n# regular expression, using stemming: try to replace tail of words like ies to y \n##################","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"9a60cb1fc148e7da9292edfb3a2f215881e093f3","_cell_guid":"7f8f072e-7eec-4009-ae7d-479e540b2c81","collapsed":true}},{"cell_type":"code","source":"##################\n# stemming technique \n# in NLP\n##################\ndata.content = data.content.str.replace(\"ing( |$)\", \" \")\ndata.content = data.content.str.replace(\"[^a-zA-Z]\", \" \")\ndata.content = data.content.str.replace(\"ies( |$)\", \"y \")","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"1bceddc363e9dbdc7d86a44c6070f5231eccec34","_cell_guid":"b6cc5b35-a187-4632-9754-519f1f6d69a9","collapsed":true}},{"cell_type":"code","source":"##################\n# import tfidf lib from sklearn \n##################\nfrom sklearn.feature_extraction.text import TfidfVectorizer","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"906f42ccf06b6e46d0cf9cd5faede607aeb0b48c","_cell_guid":"448fbfca-c8e8-4a0e-a247-957f79bad97d","collapsed":true}},{"cell_type":"code","source":"##################\n# using ngram as one word \n# analyzer as word \n##################\nvectorizer = TfidfVectorizer(ngram_range=(1, 1), sublinear_tf=True, analyzer= 'word')","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"6eaddbe103a222534c11bb44ede322fbf6499875","_cell_guid":"154669d2-7b8f-4a99-9733-b40833e0e621","collapsed":true}},{"cell_type":"code","source":"##################\n# import train test split lib\n##################\nfrom sklearn.model_selection import train_test_split","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"771ca2ef01d80408a94b8f6717117c67c7f0957c","_cell_guid":"be48f6d0-6277-49b1-8a4f-c894d504272b","collapsed":true}},{"cell_type":"code","source":"# if there is any empty data, drop it\ndata.dropna(inplace=True)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"2b59171a559da5c385a9ece7bcc376c459b1b68d","_cell_guid":"3be3d581-463e-442a-80a3-6fda51b080f4","collapsed":true}},{"cell_type":"markdown","source":"#Split the data: 80 % for training data and  20 % for testing data","metadata":{"_execution_state":"idle","_uuid":"78d6d3b0058ad0d164e4aded86df36f96051c8f1","_cell_guid":"cc5bc0e1-ffa5-4c41-b78e-052f901eb2a5"}},{"cell_type":"code","source":"\n#Split the data: 80 % for training data and  20 % for testing data\ndata_content_train,data_content_test, data_train_label,data_test_label =train_test_split(data[[\"content\",\"author\",\"poem name\"]],data.type,test_size = 0.2, random_state = 1)\n","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"01a7f8e52b756af5d7e4f6198d956c8f66616f8b","_cell_guid":"d2723af8-944f-4888-bd02-159c3f151bb6"}},{"cell_type":"code","source":"type(data.type)","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"42c636231a96f3ebddbce365ff64c87013a0b639","_cell_guid":"3b1e25a3-b5c5-4365-9052-160781b8edc7"}},{"cell_type":"code","source":"(data_train_label)","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"9a0aa6e5f44115a1de0a608e73c743344f6b3170","_cell_guid":"12d001b5-5729-4aaa-8d8a-733d92194b93"}},{"cell_type":"code","source":"##################\n# correct data of test data \n# will use in the result \n##################\ndata_test_label_for_age=data.ix[data_test_label.index].age\ndata_train_label_for_age=data.ix[data_train_label.index].age","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"2080bc1b814268091b425ccd0792c205f4f3d85e","_cell_guid":"675689d6-d35c-44f8-8f46-34cc781695f1","collapsed":true}},{"cell_type":"code","source":"##################\n# using fit transform to transform data \n# for fitting vector\n# we got our word map (which is the most important features of the poem)\n##################\ntrain_ = vectorizer.fit_transform(data_content_train.content.as_matrix())\nfeature_names =vectorizer.get_feature_names()\nfeature_names\ntest_ = vectorizer.transform(data_content_test.content.as_matrix())\nprint(\"--word map found by algorithm---\")\nfeature_names","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"917622de62f9b1f8da494061eb423f0b74dc434c","_cell_guid":"64d41a8c-642c-46f9-9b41-1821d5bc4a8b","collapsed":true}},{"cell_type":"code","source":"# check if there is any empty poem name in the file\nremovelist=data_content_train[\"poem name\"].index[data_content_train[\"poem name\"].isnull()==True].tolist()\nremovelist","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"834bb701e1e2e031abb65b70dc0c8bca1eac1344","_cell_guid":"6bec053d-a9a3-456c-9137-b7055dcf7f53","collapsed":true}},{"cell_type":"markdown","source":"#Since our targets contain :\n- age ( Modern, Renaissance ) \n- type (Love, Nature, Mythology & Folklore)\n#We use two xgb predictors to predict each poem and show the result","metadata":{"_execution_state":"idle","_uuid":"0f6703b47245be9d26acc797d743fc970bda5833","_cell_guid":"cdc7e22a-f4c9-48ee-8552-b74e0ddfea5b"}},{"cell_type":"code","source":"##################\n# testing parameters for performance \n##################\nfrom sklearn import preprocessing\nlabel_au = preprocessing.LabelEncoder()\nlabel_author=label_au.fit_transform(data_content_train.author.as_matrix())\nlabel_authorT=label_au.fit_transform(data_content_test.author.as_matrix())\n\nlabel_poe_name =TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0, stop_words = 'english')  \nlabel_poena=label_poe_name.fit_transform(data_content_train[\"poem name\"].as_matrix())\nlabel_poenaT  =label_poe_name.fit_transform(data_content_test[\"poem name\"].as_matrix())\n\n","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"2b2a679dca2f497870b0f0632c92c78fc45856fd","_cell_guid":"e981524b-5533-436e-9114-30e3ad500fb0","collapsed":true}},{"cell_type":"code","source":"#label_author=np.reshape(label_author, (label_author.shape[0], 1))\n#label_authorT=np.reshape(label_authorT, (label_authorT.shape[0], 1))\n#data_content_train.author[data_content_train.author.isnull()==True].index.tolist()","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"611fe56809f637fc95564e9ce8e1944278c1a0b2","_cell_guid":"6811f12f-fbcb-4c21-b2f3-70bcebd41c65","collapsed":true}},{"cell_type":"code","source":"#a_age.shape","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"a40a9018f28a38aae977e0be2482955d5c01716b","_cell_guid":"0d1dbeb0-3940-4cd4-b625-95af33ff819a","collapsed":true}},{"cell_type":"code","source":"from numpy import array","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"bf94c3ad511d9aae725dfb0ee84ea8c12c101336","_cell_guid":"795e0acb-2d94-4b82-8333-9a723bf29e2e","collapsed":true}},{"cell_type":"code","source":"# We try to catch more feature, but it did not make big difference of result\nfrom sklearn.feature_selection import SelectKBest ,chi2\n#y = np.array(data_content_train)\nch2 = SelectKBest(chi2, k=2000)\n#X_train=ch2.fit_transform(train_, data_train_label.tolist() )\n#X_test = ch2.transform(test_)\nX_train=train_;\nX_test=test_;","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"4ab515fdf300c03df506ba17f7cfa822e5200751","_cell_guid":"238488aa-48ed-4972-b90d-6a5592134d55","collapsed":true}},{"cell_type":"code","source":"# It did not make big difference of result if we use dense matrix \n#import scipy.sparse as sp\n#if(sp.issparse(X_train)==True):\n#   X_train = X_train.todense()\n#   X_test = X_test.todense()\n    ","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"5440becfd2486f322488eb88bb34616a186b7ead","_cell_guid":"fcf62872-cc83-4d4a-8de6-7049dbeed991","collapsed":true}},{"cell_type":"code","source":"##################\n# import xgb lib \n# and the parameters are used  as below \n##################\nimport xgboost as xgb","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"df6a6fcb590823ac8d9b58dc00946663bc72541f","_cell_guid":"9c938ddc-452b-4e59-86b5-e89e136879fc","collapsed":true}},{"cell_type":"code","source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 6,\n    'subsample': 0.6,\n    'colsample_bytree': 1,\n    'objective': 'reg:linear',\n    \"eval_metric\": 'logloss',\n    'silent': 1\n}","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"5e4d736d9fffba2094948366296888780d337606","_cell_guid":"4a26cbe0-a33a-4ad5-b8f0-ccbdcb1718b4","collapsed":true}},{"cell_type":"code","source":"xgb_params_age = {\n    'eta': 0.05,\n    'max_depth': 6,\n    'subsample': 0.6,\n    'colsample_bytree': 1,\n    'objective': 'reg:linear',\n    \"eval_metric\": 'error',\n    'silent': 1\n}","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"f302804e52d9cc28d4d81c1014c1f4875bbf4fdd","_cell_guid":"5a758d7a-51da-4d47-8ea9-1fcdfbc93567","collapsed":true}},{"cell_type":"code","source":"xgb_params_author = {\n    'eta': 0.05,\n    'max_depth': 6,\n    'subsample': 0.6,\n    'colsample_bytree': 1,\n    'objective': 'binary:logistic',\n    \"eval_metric\": 'error',\n    'silent': 1\n}","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"05f4d60695669f3262c2b750e2a78321643d7462","_cell_guid":"b533938a-7693-4b3b-86c2-516519a0dd78","collapsed":true}},{"cell_type":"code","source":"##################\n# a are the target for training \n# we have to transfrom to the right form of label\n##################\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\na=le.fit_transform(data_train_label.as_matrix())","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"8dc3cbceead6b6a663a665b6fa83f16b592ca336","_cell_guid":"90845295-77f1-4aee-9dd4-dbc2b0443f6c","collapsed":true}},{"cell_type":"code","source":"##################\n# a_age are the target of age for training \n# we have to transfrom to the right form of label\n##################\nle2 = preprocessing.LabelEncoder()\na_age=le2.fit_transform(data_train_label_for_age.as_matrix())","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"94e8296373f9590578b75d8c8f6246dc0b1528aa","_cell_guid":"dd97ff87-444f-4e71-b2cc-eefa394fc411","collapsed":true}},{"cell_type":"code","source":"# check the correctness of the data \n# to see whether there is any null in it\ns=pd.DataFrame({'author':label_author})\ns.author.ix[s.author.isnull()==True]\n\n\ns_T=pd.DataFrame({'author':label_authorT})\ns_T.author.ix[s_T.author.isnull()==True]\n\n\ns_age=pd.DataFrame({'age':a_age})\ns_age.age.ix[s_age.age.isnull()==True]\n#(s_T)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"5e6bdbb24080bf9c7537b6e059564f4efd3081f3","_cell_guid":"fe2e9d92-6062-4ad0-a242-d2fa125d3a65","collapsed":true}},{"cell_type":"code","source":"#a_age=np.reshape(a_age, (a_age.shape[0], 1))\n#a_age.shape","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"09d71ed40299674f8beb6c559f1b8b7beaec117e","_cell_guid":"6fd01fb4-2550-4954-a71a-2cb4c5bf3b07","collapsed":true}},{"cell_type":"code","source":"##################\n# Dmatrix using for feeding inputs of xgb predictors\n##################\ndtrain = xgb.DMatrix(X_train, a )\ndtest = xgb.DMatrix(X_test)\ndtrain_age = xgb.DMatrix(X_train, a_age )\ndtest_age = xgb.DMatrix(X_test)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"768654cf5e88ff223d9cd9b70caf6cbcdbd8efcb","_cell_guid":"d4934760-3b06-4595-8c9e-361225573c2d","collapsed":true}},{"cell_type":"code","source":"dtrain_author = xgb.DMatrix(s, s_age.age )\ndtest_author = xgb.DMatrix(s_T)\n#dtrain_age = xgb.DMatrix(X_train, a_age )\n#dtest_age = xgb.DMatrix(X_test)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"57899b33a1f7964664eed3ca9e09a7d390b8696f","_cell_guid":"e348eeb4-42aa-4b90-be92-3b16311b9a7f","collapsed":true}},{"cell_type":"code","source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"8e9f020395b38421917c483aa163342e00f55ccd","_cell_guid":"59e85f6e-313c-4b53-be17-a7f398742029"}},{"cell_type":"code","source":"##################\n# train and predict \n##################\nnum_boost_rounds = 422\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\nresult =model.predict(dtest)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"17c06759bb861cf6cd5a390a159093df0eb94ca4","_cell_guid":"390cae35-3870-4b02-9ba3-d41eb18cd7fb","collapsed":true}},{"cell_type":"code","source":"num_boost_rounds = 422\nmodel_age = xgb.train(dict(xgb_params_age, silent=0), dtrain_age, num_boost_round=num_boost_rounds)\nresult_age =model_age.predict(dtest_age)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"94a32d8111ffa789e5a8ed8690d45fc600e32f75","_cell_guid":"2cbfa236-a7b7-4ae7-b3df-dda4f64dd224","collapsed":true}},{"cell_type":"code","source":"num_boost_rounds = 422\nmodel_author = xgb.train(dict(xgb_params_author, silent=0), dtrain_author, num_boost_round=num_boost_rounds)\nresult_author =model_author.predict(dtest_author)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"04ec1b28d465f3a5e4316ebb9594a3a3570f432e","_cell_guid":"7f693c5e-98ec-4668-89ca-3fbb55ea1c88","collapsed":true}},{"cell_type":"code","source":"result_author\n# we need to do more to convert it into our label, which will be renaissance and modern","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"30190cbfc10513d1df78bd5eaf4d9f10bd370527","_cell_guid":"5b2587fb-e65a-4864-89b0-fb95f0dd6da6","collapsed":true}},{"cell_type":"code","source":"presult=pd.DataFrame(result)\npresult_age=pd.DataFrame(result_age)\npresult_author=pd.DataFrame(result_author)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"d1cf571f5123b2e422ef66b775870f3a857f3cf7","_cell_guid":"cab0748b-d04a-47cc-a902-329b4037496b","collapsed":true}},{"cell_type":"code","source":"##################\n# the data after training is in  decimal\n#  we have to tranform it into int for accuracy compare\n# then we can inverse it into label \n##################\npresult[(presult.values >= 0.5) & (presult.values < 1.5) ]= 1;\npresult[(presult.values >= 1.5) & (presult.values < 2.5) ]=2;\npresult[(presult.values >= -0.5) & (presult.values < 0.5) ]=0;\n\npresult_age[(presult_age.values >= -0.5) & (presult_age.values < 0.5) ]=0;\npresult_age[(presult_age.values >= 0.5) & (presult_age.values < 1.5) ]= 1;\n\npresult_author[(presult_author.values >= -0.5) & (presult_author.values < 0.5) ]=0;\npresult_author[(presult_author.values >= 0.5) & (presult_author.values < 1.5) ]= 1;","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"0ee0649b63553e51a54502c4c7a3d6dddef1fceb","_cell_guid":"d2eff3ee-c882-415f-9a93-95c5ec1f875e","collapsed":true}},{"cell_type":"code","source":"presult=presult.astype(int)\npresult_age=presult_age.astype(int)\npresult_author=presult_author.astype(int)","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"fa3e9be8a84d39ca2326738cf9765acebe0da18d","_cell_guid":"b913498a-eb94-4fd3-97a9-e7140c1df912","collapsed":true}},{"cell_type":"code","source":"result_back=le.inverse_transform(presult.values)\nresult_back_age=le2.inverse_transform(presult_age.values)\nresult_back_author=le2.inverse_transform(presult_author.values)\nresult_back_author.ravel()","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"f077ae82002570b12fdc2f68ff20d8cc2d070dff","_cell_guid":"6b665097-ae93-46b3-bb96-462ae58ffe70","collapsed":true}},{"cell_type":"code","source":"# after conversion \nresult_back_age.ravel()","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"a99f57b2c93b7ae25c451bb34cfb28eb7ce9163e","_cell_guid":"11b8f72d-1877-4df6-9789-0f48220b20d5","collapsed":true}},{"cell_type":"code","source":"# accuracy for target type \nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(data_test_label, result_back)\naccuracy","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"29a77d60820fd3b317e1f536806234e0e22346d7","_cell_guid":"eb5c5b42-b628-4e89-b6ee-320382d13dcf","collapsed":true}},{"cell_type":"code","source":"# accuracy for target age\naccuracy_age = accuracy_score(data_test_label_for_age, result_back_age)\naccuracy_age","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"27ec7bc2a60672e802345e23dd884e36e66bc39f","_cell_guid":"b323ed89-07d5-4f1f-b234-5d5e78d74e0c","collapsed":true}},{"cell_type":"code","source":"# after conversion \nresult_back_age","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"f11da796cb02dd140565b09ae1ca0f6818f35f30","_cell_guid":"1a83a207-471d-47ed-aef4-580b3e795a7b","collapsed":true}},{"cell_type":"markdown","source":"#Prediction result ","metadata":{"_execution_state":"idle","_uuid":"34088e8ecee546bcfa0b02336ab3d9ae892510af","_cell_guid":"88936e1f-0f86-4818-a420-cb958db3ccd4"}},{"cell_type":"code","source":"pd.DataFrame({  'poem name': data_content_test[\"poem name\"],\n                'correct_data' : data_test_label_for_age+ \" \" +data_test_label,\n                'predict result' : result_back_age.ravel()+\" \" +result_back.ravel()\n                    })","outputs":[],"execution_count":null,"metadata":{"_execution_state":"idle","_uuid":"067f7d65cd4761bcb25a1284752339f1b3a932e7","_cell_guid":"bce9b995-ca38-4940-838c-a6879a9bce0c","collapsed":true}}],"nbformat_minor":1,"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}}}