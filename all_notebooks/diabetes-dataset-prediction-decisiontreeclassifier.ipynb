{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Load Libraries# "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load dataset# "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/diabetes/diabetes.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature selection\nانتخاب ویژگی ها و تقسیم بندی آن ها بصورت تجربی"},{"metadata":{"trusted":true},"cell_type":"code","source":"featrue_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age', 'Glucose', 'BloodPressure',\n                'DiabetesPedigreeFunction']\nX = df[featrue_cols] #features\ny = df['Outcome'] #Target varible\ndata = X.join(y) #ساخت دیتاست جدید با ستون های دلخواه\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data\nبخش بندی کردن داده ها"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling # "},{"metadata":{},"cell_type":"markdown","source":"روشی است برای عادی سازی و نرمالسازی داده ها که معمولا در مرحله پیش پردازش داده ها انجام داده میشود"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Algorithms on the Training set # \n# Decision Tree # \n**Validate *Criterion* and *Depth* for Decision Tree Algorithm**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#با استفاده از قطعه کد زیر و رسم نمودار،  \"معیار\"  و  \"عمق\"  مناسب برای الگوریتم درخت تصمیم بدست میاوریم\n\nfrom sklearn.metrics import accuracy_score\n\nmax_depth = []\nacc_gini = []\nacc_entropy = []\n\nfor i in range(1,21):\n    dtree = DecisionTreeClassifier(criterion = \"gini\", max_depth = i)\n    dtree.fit(X_train, y_train)\n    pred = dtree.predict(X_test)\n    acc_gini.append(accuracy_score(y_test, pred))\n    \n    dtree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = i)\n    dtree.fit(X_train, y_train)\n    pred = dtree.predict(X_test)\n    acc_entropy.append(accuracy_score(y_test, pred))\n    max_depth.append(i)\n    \nd = pd.DataFrame({\"acc_gini\" : pd.Series(acc_gini),\n                  \"acc_entropy\" : pd.Series(acc_entropy),\n                  \"max_depth\" : pd.Series(max_depth)})\n\nplt.plot(\"max_depth\", \"acc_gini\", data = d, label = \"gini\")\nplt.plot(\"max_depth\", \"acc_entropy\", data = d, label = \"entropy\")\nplt.xlabel(\"Max_depth\")\nplt.ylabel(\"Accuracy\")\nplt.xticks([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"همانطور که در نمودار بالا قابل مشاهده است، در عمق 12 شاخص نارنجی رنگ بالاترین دقت پیش بینی را دارد\n\nشاخص نارنجی: criterion = \"entropy\"\n\nعمق مناسب: max_depth = 12\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 12)\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the Test results # "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making Confusion Matrix and Accuracy # "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ماتریس بالا به ما نشان میدهد که در مقایسه بین داده های درنظر گرفته شده به عنوان تست و داده های پیش بینی شده توسط الگوریتم، 372 نفر که دیابت نداشتند به درستی الگوریتم تشخیص داده که دیابت ندارند و تعداد 201 نفر که دیابت داشت اند را هم نیز درست تشخیص داده که دیابت دارند! میزان خطاها هم داخل جدول مشخص شده است\n\nدر تصویر زیر به خوبی کانفیوژن ماتریس و چهار بخش آن توضیح داده شده است\n\n![](https://blog.faradars.org/wp-content/uploads/2019/06/Confusion-Matrix.png)","attachments":{}},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"دقت پیش بینی به دست آمده حدود 96% است که با پیش پردازش بهتر داده ها و حذف داده های پرت از هر ویژگی، میتوان این دقت را افزایش نیز داد"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}