{"cells":[{"metadata":{},"cell_type":"markdown","source":"Important Libaries ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load dataset into variable and set display size ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/house-price/innercity.csv')\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation: \n\n- Here we can see that data is having data types of Float, int64,object.\n- Data doesn't having null values. Only one variable is categorical.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('No of Rows: ',data.shape[0],'\\nNo of columns: ',data.shape[1]) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation:\n\nAs per the given descriptive statistics that summarize the central tendency,\ndispersion and shape of a dataset distribution, excluding.\nHere most of feature having outlier as looking at mean and median difference.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation\nAs we earlier observed that their is no null values in dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check the details of data \ndef details(dataFrame):\n    df = pd.DataFrame()\n    df['Null_Values'] = dataFrame.isnull().sum()\n    df['Data Type'] = dataFrame.dtypes\n    df['Unique Values'] = dataFrame.nunique()\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"details(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Latitude and Longitude feature extraction into the regions given belows\n\n    ES= Extreme South\n    MS= Middle South\n    MN= Middle North \n    EN = Extreme North \n    EE= Extreme East\n    ME= Middle East\n    MW= Middle West\n    EW = Extreme West\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lst = []\nfor i in data.lat:\n    if i<47.255900:\n        lst.append('ES')\n    elif i>47.255900 and i<47.405900:\n        lst.append('MS')\n    elif i>47.405900 and i<47.555900:\n        lst.append('MN')\n    else:\n        lst.append('EN')\ndata['SN_region'] = lst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst = []\nfor i in abs(data.long):\n    if i<122.105000:\n        lst.append('EE')\n    elif i>122.105000 and i<122.205000:\n        lst.append('ME')\n    elif i>122.205000 and i<122.328000:\n        lst.append('MW')\n    else:\n        lst.append('EW')\ndata['EW_region'] = lst","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Univarient Analysis\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.SN_region)\nplt.title('South and North Region')\nplt.show()\nsns.countplot(data.EW_region)\nplt.title('East and West Region')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bi-varient Analysis\n\nAnalysis is only between numeric feature and Target variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data.EW_region,data.price)\nplt.title('East-West Region and Price of House')\nplt.savefig('EWRegion.jpg')\nplt.show()\nsns.barplot(data.SN_region,data.price)\nplt.title('South-North Region and Price of House')\nplt.savefig('NSRegion.jpg')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Skewness and Kurtosis\nskw = data.skew();sk1 = skw[skw>3]\nkrt = data.kurt();kr = krt[krt>3]\nsk = pd.DataFrame({'Skewness':sk1,'Kurtosis': kr})\nsk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['yr_sold'] = df['dayhours'].str.extract('(\\d\\d\\d\\d)',expand=True)\ndf['yr_sold'] = df['yr_sold'].astype(int)\n\ndf = df.drop('dayhours',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking total quality\ndf['Total_home_quality'] = df.quality + df.condition\ndf['Total_home_quality']  = df['Total_home_quality'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking total area for 2015 remesurement\ndf['total_area15'] = df.living_measure15 + df.lot_measure15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How much house is old\ndf['Age_house'] = df['yr_sold'] - df['yr_built']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age column has negative values so we are simply droping that row\ndf = df.drop(df[df['Age_house']==-1].index)\ndf[df['Age_house']==-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fetch all numeric features\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32',\n'float64']\nnumeric = []\nfor i in df.columns:\n    if df[i].dtype in numeric_dtypes:\n        numeric.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new column for renovation done or not\nlst = []\nfor i in df.yr_renovated:\n    if  i >0:        \n        \n        lst.append(1)\n    else:\n        \n        lst.append(0)\n\ndf['is_renovated']=lst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# House has basement or not\ndf['Have_basement'] = df['basement'].apply(lambda x: 1 if x>1 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.room_bed = df.room_bed.replace(to_replace=33, value=df.room_bed.mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\n\n# Models\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import Ridge, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.svm import SVR\n#from mlxtend.regressor import StackingCVRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n# Misc\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold, cross_val_score\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\npd.set_option('display.max_columns', None)\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df5 = df5.drop(['SN_region','EW_region'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_dum = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndf['SN_region'] = label_encoder.fit_transform(df['SN_region']).astype('float64')\ndf['EW_region'] = label_encoder.fit_transform(df['EW_region']).astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('cid',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\ncorr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = np.full((corr.shape[0],), True, dtype=bool)\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >= 0.9:\n            if columns[j]:\n                columns[j] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_columns = df.columns[columns]\nselected_columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = df[selected_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\ndef backwardElimination(x, Y, sl, columns):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(endog=Y, exog= x).fit()\n        maxVar = max(regressor_OLS.pvalues).astype(float)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n                    columns = np.delete(columns, j)\n                    \n    regressor_OLS.summary()\n    return x, columns\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SL = 0.05\ndata_modeled, selected_columns1 = backwardElimination(data1.iloc[:,1:].values, data1.iloc[:,0].values, SL, selected_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_columns.size\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.iloc[:,0].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame()\nresult['diagnosis'] = data1.iloc[:,0]\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data1[selected_columns1]\nprint(data2.shape)\ndata2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = data2.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"# Remove correlations from the dataframe that are above corr_val def corr_df(x, corr_val):\n# Dont want to remove correlations between Energy Star Score y = x['ENERGY STAR Score']\nx = x.drop(columns = ['price'])\n\n# Matrix of all correlations corr_matrix = x.corr()\niters = range(len(corr_matrix.columns) - 1) drop_cols = []\n\n# Iterate through all correlations for i in iters:\nfor j in range(i):\n    item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)] col = item.columns\n    row = item.index\n \n    val = abs(item.values)\n# If correlation is above the threshold, add to list to remove if val >= corr_val:\n    drop_cols.append(col.values[0])\n\n# Remove collinear variables drops = set(drop_cols)\nx = x.drop(columns = drops)\nx = x.drop(columns = ['Site EUI (kBtu/ft2)'])\n\n# Make sure to add the label back in to the data x['ENERGY STAR Score'] = y\n\nreturn x\n\nIn [11]: new_data = corr_df(data, corr_val = 0.5) print('Old Data Shape:', data.shape)\nprint('New Data Shape with correlated features removed', new_data.shape)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import module to Scale down the data into central scale\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df1.drop(['price'],axis=1)\ny=df1.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = sm.add_constant(x)\nmodel = sm.OLS(y,X).fit()\nmod_pred = model.predict(X)\nresidual = model.resid\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from   statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\n\nvif['VIF Factor'] =[variance_inflation_factor(df1.values,i) for i in range(df1.shape[1])]\nvif['Feature'] = df1.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 =pd.DataFrame( ss.fit_transform(x),columns=x.columns)\nX1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the PCA algorithm with our Data\npca = PCA().fit(X1)\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\nplt.title('House Price Dataset Explained Variance')\nplt.savefig('PCA')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=PCA(0.95)\n\npca.fit_transform(X1)\n\ncompo=pca.n_components_\ncompo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain1, xtest1, ytrain1, ytest1 = train_test_split(X1,y, test_size=0.3, random_state  = 14)\n\nprint('Training Data Shape:', xtrain1.shape)\nprint('Testing Data Shape:', xtest1.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FItting PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_pca = PCA(n_components=compo,svd_solver='full')\n\nnew_train = model_pca.fit_transform(xtrain1)\nnew_test  = model_pca.fit_transform(xtest1)\n\nprint('\\nTraining model with {} dimensions.'.format(new_train.shape[1]))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Establish A Regression Baseline\n    Before we implement a machine learning model, we need to calculate a common-sense baseline. If our model cannot beat this mark, then machine learning may not be appropriate for the task. For regression tasks, a simple baseline is to predict the mean value of the target in the training data for all the testing examples.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Baseline is mean of training label \nbaseline = np.mean(ytrain1)\nbase_error = np.mean(abs(baseline - ytest1))\n\nprint('Baseline Error: {:0.4f}.'.format(base_error))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic Regression Model\n\nA linear regression is extremely straightforward and produces explainable results. It is a good method to start with in machine learning because we can interpret the results. However, if the problem is not linear, then our model will not be very useful.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create object of model\nmodel_new = LinearRegression()\n\n# fit the model with the training data\nmodel_new.fit(new_train,ytrain1)\n# predict the target on the new train dataset\npredict_train_pca = model_new.predict(new_train)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain1,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %model_new.score(new_train, ytrain1))\n\n# predict the target on the new test dataset\npredict_test_pca = model_new.predict(new_test)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest1,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %model_new.score(new_test, ytest1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscoresdt = cross_val_score(model_new, new_train, ytrain1, cv=10)\nscoresdt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(scoresdt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Regression Using PolynomialFeatures and PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsc=StandardScaler()\npca=PCA()\npoly=PolynomialFeatures(degree=1)\nX=df1.drop('price',axis=1)\ny=df1.price\ntrainR2=[]\ntestR2=[]\ntrainR2PCA=[]\ntestR2PCA=[]\nfor i in range(100):\n    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=i)\n    Xtrain=poly.fit_transform(Xtrain)\n    Xtest=poly.transform(Xtest)\n    scaledXtrain=sc.fit_transform(Xtrain)\n    scaledXtest=sc.transform(Xtest)\n    pcascaledXtrain=pca.fit_transform(scaledXtrain)\n    pcascaledXtest=pca.transform(scaledXtest)\n    lr=LinearRegression()\n    lr.fit(scaledXtrain,ytrain)\n    lrpca=LinearRegression()\n    lrpca.fit(pcascaledXtrain,ytrain)\n    trainR2.append(lr.score(scaledXtrain,ytrain))\n    testR2.append(lr.score(scaledXtest,ytest))\n    trainR2PCA.append(lrpca.score(pcascaledXtrain,ytrain))\n    testR2PCA.append(lrpca.score(pcascaledXtest,ytest))\nprint(\"Without PCA\")\nprint(\"Testing R2\")\nprint(np.mean(testR2))\nprint(\"Training R2\")\nprint(np.mean(trainR2))\nprint(\"\")\nprint(\"With PCA\")\nprint(\"Testing R2\")\nprint(np.mean(testR2PCA))\nprint(\"Training R2\")\nprint(np.mean(trainR2PCA))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.set(style='whitegrid')\n# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(14, 8)\n\n# Plot predictions\nax = plt.subplot(121)\nax.hist(predict_test_pca, bins = 100)\nax.set_xlabel('Score'); ax.set_ylabel('Count'); ax.set_title('Predicted Distribution')\n\n# Plot true values\nax2 = plt.subplot(122)\nax2.hist(ytest, bins = 100)\nax2.set_xlabel('Score'); ax2.set_ylabel('Count'); ax2.set_title('Actual Distribution');\nplt.title('RandomForestRegressor')\nplt.savefig('RandomForestRegressor.jpg')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GradientBoostingRegressor:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr = GradientBoostingRegressor(n_estimators=6000,\n                                                    learning_rate=0.01,\n                                                    max_depth=4,\n                                                    max_features='sqrt',\n                                                    min_samples_leaf=15,\n                                                    min_samples_split=10,\n                                                    loss='huber',\n                                                    random_state=42)\n\ngbr.fit(pcascaledXtrain,ytrain)\n\n\n\n# predict the target on the new train dataset\npredict_train_pca = gbr.predict(pcascaledXtrain)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %gbr.score(pcascaledXtrain, ytrain))\n\n# predict the target on the new test dataset\npredict_test_pca = gbr.predict(pcascaledXtest)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %gbr.score(pcascaledXtest, ytest))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross Validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscoresdt = cross_val_score(gbr, pcascaledXtrain, ytrain, cv=10)\nscoresdt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(scoresdt)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.set(style='whitegrid')\n# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(14, 8)\n\n# Plot predictions\nax = plt.subplot(121)\nax.hist(predict_test_pca, bins = 100)\nax.set_xlabel('Score'); ax.set_ylabel('Count'); ax.set_title('Predicted Distribution')\n\n# Plot true values\nax2 = plt.subplot(122)\nax2.hist(ytest, bins = 100)\nax2.set_xlabel('Score'); ax2.set_ylabel('Count'); ax2.set_title('Actual Distribution');\nplt.title('RandomForestRegressor')\nplt.savefig('RandomForestRegressor.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot between predictions and Y_test\nx_axis = np.array(range(0, predict_test_pca.shape[0]))\nplt.figure(figsize=(20,10))\nplt.plot(x_axis, predict_test_pca, linestyle=\"--\", marker=\"o\", alpha=0.7, color='r', label=\"predictions\")\nplt.plot(x_axis, ytest, linestyle=\"--\", marker=\"o\", alpha=0.7, color='g', label=\" Actual(Y_test)\")\nplt.xlabel('Row number')\nplt.ylabel('PRICE')\nplt.title('Predictions vs Actual(Y_test)')\nplt.legend(loc='lower right')\nplt.savefig('RandomFor.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation:\nThat is not very great! We will move on to more serious machine learning models. The problem as we increase in complexity is that while our accuracy will increase, the interpretability will decrease.\n\n\n\n### Random Forest Regression\nNext I implement a random forest regression. The random forest is somewhat interpretable be- cause it returns feature importances which we can use to compare the most helpful variables for making predictions. The random forest is generally very accurate and performs well on non-linear problems with many features because it does implicit feature selection.\nI am using all the scikit-learn defaults for the random forest except I increased the number of trees in the forest from 10 to 200. Generally the default hyperparameters work well but can be tuned using cross-validation.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_reg = RandomForestRegressor(n_estimators=200, n_jobs=-1)\nrf_reg.fit(pcascaledXtrain,ytrain)\n\n\n\n# predict the target on the new train dataset\npredict_train_pca = rf_reg.predict(pcascaledXtrain)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %rf_reg.score(pcascaledXtrain, ytrain))\n\n# predict the target on the new test dataset\npredict_test_pca = rf_reg.predict(pcascaledXtest)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %rf_reg.score(pcascaledXtest, ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscoresdt = cross_val_score(rf_reg, pcascaledXtrain, ytrain, cv=10)\nscoresdt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(scoresdt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(14, 8)\n\n# Plot predictions\nax = plt.subplot(121)\nax.hist(predict_test_pca, bins = 100)\nax.set_xlabel('Score'); ax.set_ylabel('Count'); ax.set_title('Predicted Distribution')\n\n# Plot true values\nax2 = plt.subplot(122)\nax2.hist(ytest, bins = 100)\nax2.set_xlabel('Score'); ax2.set_ylabel('Count'); ax2.set_title('Actual Distribution');\nplt.title('RandomForestRegressor')\nplt.savefig('RandomForestRegressor.jpg')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot between predictions and Y_test\nx_axis = np.array(range(0, predict_test_pca.shape[0]))\nplt.figure(figsize=(20,10))\nplt.plot(x_axis, predict_test_pca, linestyle=\"--\", marker=\"o\", alpha=0.7, color='r', label=\"predictions\")\nplt.plot(x_axis, ytest, linestyle=\"--\", marker=\"o\", alpha=0.7, color='g', label=\" Actual(Y_test)\")\nplt.xlabel('Row number')\nplt.ylabel('PRICE')\nplt.title('Predictions vs Actual(Y_test)')\nplt.legend(loc='lower right')\nplt.savefig('RandomFor.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DecisionTreeRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing decision tree classifier from sklearn library\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Fitting the decision tree with default hyperparameters, apart from\n# max_depth which is 5 so that we can plot and read the tree.\ndt_default = DecisionTreeRegressor(max_depth=5)\ndt_default.fit(pcascaledXtrain,ytrain)\n\n\n# predict the target on the new train dataset\npredict_train_pca = dt_default.predict(pcascaledXtrain)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %dt_default.score(pcascaledXtrain, ytrain))\n\n# predict the target on the new test dataset\npredict_test_pca = dt_default.predict(pcascaledXtest)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %dt_default.score(pcascaledXtest, ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(14, 8)\n\n# Plot predictions\nax = plt.subplot(121)\nax.hist(predict_test_pca, bins = 100)\nax.set_xlabel('Score'); ax.set_ylabel('Count'); ax.set_title('Predicted Distribution')\n\n# Plot true values\nax2 = plt.subplot(122)\nax2.hist(ytest, bins = 100)\nax2.set_xlabel('Score'); ax2.set_ylabel('Count'); ax2.set_title('Actual Distribution');\n#plt.title('DecisionTreeRegressor')\nplt.savefig('DecisionTreeRegressor.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient Boosting Regressor\ngbr = GradientBoostingRegressor(n_estimators=6000,\n                                                    learning_rate=0.01,\n                                                    max_depth=4,\n                                                    max_features='sqrt',\n                                                    min_samples_leaf=15,\n                                                    min_samples_split=10,\n                                                    loss='huber',\n                                                    random_state=42)\n\ngbr.fit(new_train,ytrain1)\n\n\n\n# predict the target on the new train dataset\npredict_train_pca = gbr.predict(new_train)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain1,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %gbr.score(new_train, ytrain1))\n\n# predict the target on the new test dataset\npredict_test_pca = gbr.predict(new_test)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest1,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %gbr.score(new_test, ytest1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(14, 8)\n\n# Plot predictions\nax = plt.subplot(121)\nax.hist(predict_test_pca, bins = 100)\nax.set_xlabel('Score'); ax.set_ylabel('Count'); ax.set_title('Predicted Distribution')\n\n# Plot true values\nax2 = plt.subplot(122)\nax2.hist(ytest, bins = 100)\nax2.set_xlabel('Score'); ax2.set_ylabel('Count'); ax2.set_title('Actual Distribution');\n#plt.title('DecisionTreeRegressor')\nplt.savefig('GradientBoostingRegressor.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot between predictions and Y_test\n#x_axis = np.array(range(0, rf_reg_predict.shape[0]))\n#plt.figure(figsize=(20,10))\n#plt.plot(x_axis, rf_reg_pred, linestyle=\"--\", marker=\"o\", alpha=0.7, color='r', label=\"predictions\")\n#plt.plot(x_axis, ytest1, linestyle=\"--\", marker=\"o\", alpha=0.7, color='g', label=\" Actual(Y_test)\")\n#plt.xlabel('Row number')\n#plt.ylabel('PRICE')\n#plt.title('Predictions vs Actual(Y_test)')\n#plt.legend(loc='lower right')\n#plt.savefig('GradientBoostingRegressor1.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Light Gradient Boosting Regressor\nlightgbm = LGBMRegressor()\n\nlightgbm.fit(pcascaledXtrain,ytrain)\n\n\n\n# predict the target on the new train dataset\npredict_train_pca = lightgbm.predict(pcascaledXtrain)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %lightgbm.score(pcascaledXtrain, ytrain))\n\n# predict the target on the new test dataset\npredict_test_pca = lightgbm.predict(pcascaledXtest)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %lightgbm.score(pcascaledXtest, ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost Regressor\nxgboost = XGBRegressor(learning_rate=0.01,\n                                            n_estimators=6000,\n                                            max_depth=4,\n                                            min_child_weight=0,\n                                            gamma=0.6,\n                                            subsample=0.7,\n                                            colsample_bytree=0.7,\n                                            objective='reg:linear',\n                                            nthread=-1,\n                                            scale_pos_weight=1,\n                                            seed=27,\n                                            reg_alpha=0.00006,\n                                            random_state=42)\n\nxgboost.fit(pcascaledXtrain,ytrain)\n\n\n\n# predict the target on the new train dataset\npredict_train_pca = xgboost.predict(pcascaledXtrain)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %xgboost.score(pcascaledXtrain, ytrain))\n\n# predict the target on the new test dataset\npredict_test_pca = xgboost.predict(pcascaledXtest)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %xgboost.score(pcascaledXtest, ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(14, 8)\n\n# Plot predictions\nax = plt.subplot(121)\nax.hist(predict_test_pca, bins = 100)\nax.set_xlabel('Score'); ax.set_ylabel('Count'); ax.set_title('Predicted Distribution')\n\n# Plot true values\nax2 = plt.subplot(122)\nax2.hist(ytest, bins = 100)\nax2.set_xlabel('Score'); ax2.set_ylabel('Count'); ax2.set_title('Actual Distribution');\n#plt.title('DecisionTreeRegressor')\nplt.savefig('DecisionTreeRegressor.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tpot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tpot import TPOTRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpot = TPOTRegressor(generations=2, population_size=50, verbosity=2)\ntpot.fit(pcascaledXtrain,ytrain)\nprint(tpot.score(pcascaledXtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the target on the new train dataset\npredict_train_pca = tpot.predict(pcascaledXtrain)\n\n# Accuray Score on train dataset\nrmse_train_pca = mean_squared_error(ytrain,predict_train_pca)**(0.5)\nprint('\\nRMSE on new train dataset : ', rmse_train_pca)\n\nprint('R square is %1.3f' %tpot.score(pcascaledXtrain, ytrain))\n\n# predict the target on the new test dataset\npredict_test_pca = tpot.predict(pcascaledXtest)\n\n# Accuracy Score on test dataset\nrmse_test_pca = mean_squared_error(ytest,predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', rmse_test_pca)\n\nprint('R square is %1.3f' %tpot.score(pcascaledXtest, ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\nfigsize(14, 8)\n\n# Plot predictions\nax = plt.subplot(121)\nax.hist(predict_test_pca, bins = 100)\nax.set_xlabel('Score'); ax.set_ylabel('Count'); ax.set_title('Predicted Distribution')\n\n# Plot true values\nax2 = plt.subplot(122)\nax2.hist(ytest, bins = 100)\nax2.set_xlabel('Score'); ax2.set_ylabel('Count'); ax2.set_title('Actual Distribution');\n#plt.title('DecisionTreeRegressor')\nplt.savefig('Genetic Algo.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot between predictions and Y_test\nx_axis = np.array(range(0, predict_test_pca.shape[0]))\nplt.figure(figsize=(20,10))\nplt.plot(x_axis, predict_test_pca, linestyle=\"--\", marker=\"o\", alpha=0.7, color='r', label=\"predictions\")\nplt.plot(x_axis, ytest, linestyle=\"--\", marker=\"o\", alpha=0.7, color='g', label=\" Actual(Y_test)\")\nplt.xlabel('Row number')\nplt.ylabel('PRICE')\nplt.title('Predictions vs Actual(Y_test)')\nplt.legend(loc='lower right')\nplt.savefig('Genetic Algo.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nfigsize(8, 6)\n\n# Dataframe to hold the results\nmodel_comparison = pd.DataFrame({'model': ['Linear Regression', 'PCA LR',\n                                           'Gradient Boosted','Random Forest', \n                                            'Decision Tree','Light GBM','XG Boost'],\n                                 'mae': [lr, lrpca, gbr\n                                        ,rf_reg,dt_default,lightgbm,xgboost]})\n\n# Horizontal bar chart of test mae\nmodel_comparison.sort_values('mae', ascending = False).plot(x = 'model', y = 'mae', kind = 'barh',\n                                                           color = 'red', edgecolor = 'black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss function to be optimized\nloss = ['ls', 'lad', 'huber']\n\n# Number of trees used in the boosting process\nn_estimators = [100, 500, 900, 1100, 1500]\n\n# Maximum depth of each tree\nmax_depth = [2, 3, 5, 10, 15]\n\n# Minimum number of samples per leaf\nmin_samples_leaf = [1, 2, 4, 6, 8]\n\n# Minimum number of samples to split a node\nmin_samples_split = [2, 4, 6, 10]\n\n# Maximum number of features to consider for making splits\nmax_features = ['auto', 'sqrt', 'log2', None]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {'loss': loss,\n                       'n_estimators': n_estimators,\n                       'max_depth': max_depth,\n                       'min_samples_leaf': min_samples_leaf,\n                       'min_samples_split': min_samples_split,\n                       'max_features': max_features}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model to use for hyperparameter tuning\nmodel = GradientBoostingRegressor(random_state = 42)\n\n# Set up the random search with 4-fold cross validation\nrandom_cv =  sklearn.model_selection.RandomizedSearchCV(estimator=model,\n                               param_distributions=hyperparameter_grid,\n                               cv=4, n_iter=25, \n                               scoring = 'neg_mean_absolute_error',\n                               n_jobs = -1, verbose = 1, \n                               return_train_score = True,\n                               random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit on the training data\nrandom_cv.fit(pcascaledXtrain, ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all of the cv results and sort by the test performance\nrandom_results = pd.DataFrame(random_cv.cv_results_).sort_values('mean_test_score', ascending = False)\n\nrandom_results.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model=random_cv.best_estimator_\nfinal_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit -n 1 -r 5\nfinal_model.fit(pcascaledXtrain,ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = final_model.predict(pcascaledXtest)\nprint('Final model performance on the test set:   MAE = %0.4f.' % mae(ytest, final_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\nr2_score for DecisionTree: ',r2_score(ytest,final_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}