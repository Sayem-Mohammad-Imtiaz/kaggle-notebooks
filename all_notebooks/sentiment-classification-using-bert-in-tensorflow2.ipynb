{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install bert-for-tf2\n!pip install sentencepiece","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport os\nimport bert\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"movie_reviews = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\nmovie_reviews.isnull().values.any()\nmovie_reviews.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_text(sen):\n    # Removing html tags\n    sentence = remove_tags(sen)\n    # Remove punctuations and numbers\n    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n    # Single character removal\n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n    # Removing multiple spaces\n    sentence = re.sub(r'\\s+', ' ', sentence)\n    return sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TAG_RE = re.compile(r'<[^>]+>')\n\ndef remove_tags(text):\n    return TAG_RE.sub('', text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews = []\nsentences = list(movie_reviews['review'])\nfor sen in sentences:\n    reviews.append(preprocess_text(sen))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(movie_reviews.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_reviews.sentiment.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = movie_reviews['sentiment']\n\ny = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reviews[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BertTokenizer = bert.bert_tokenization.FullTokenizer\nbert_layer = hub.KerasLayer(\n    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n    trainable=False\n)\nvocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\nto_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = BertTokenizer(vocabulary_file, to_lower_case)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.tokenize(\"don't be so judgmental\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"dont be so judgmental\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize_reviews(text_reviews):\n    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenized_reviews = [tokenize_reviews(review) for review in reviews]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_with_len = [[review, y[i], len(review)] for i, review in enumerate(tokenized_reviews)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(reviews_with_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_with_len.sort(key=lambda x: x[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\nprocessed_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nbatched_dataset = processed_dataset.padded_batch(\n    BATCH_SIZE, padded_shapes=((None, ), ())\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\nTEST_BATCHES = TOTAL_BATCHES // 10\nbatched_dataset.shuffle(TOTAL_BATCHES)\ntest_data = batched_dataset.take(TEST_BATCHES)\ntrain_data = batched_dataset.skip(TEST_BATCHES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TEXT_MODEL(tf.keras.Model):\n    \n    def __init__(self,\n                 vocabulary_size,\n                 embedding_dimensions=128,\n                 cnn_filters=50,\n                 dnn_units=512,\n                 model_output_classes=2,\n                 dropout_rate=0.1,\n                 training=False,\n                 name=\"text_model\"):\n        super(TEXT_MODEL, self).__init__(name=name)\n        \n        self.embedding = tf.keras.layers.Embedding(vocabulary_size,\n                                          embedding_dimensions)\n        self.cnn_layer1 = tf.keras.layers.Conv1D(filters=cnn_filters,\n                                        kernel_size=2,\n                                        padding=\"valid\",\n                                        activation=\"relu\")\n        self.cnn_layer2 = tf.keras.layers.Conv1D(filters=cnn_filters,\n                                        kernel_size=3,\n                                        padding=\"valid\",\n                                        activation=\"relu\")\n        self.cnn_layer3 = tf.keras.layers.Conv1D(filters=cnn_filters,\n                                        kernel_size=4,\n                                        padding=\"valid\",\n                                        activation=\"relu\")\n        self.pool = tf.keras.layers.GlobalMaxPool1D()\n        \n        self.dense_1 = tf.keras.layers.Dense(units=dnn_units, activation=\"relu\")\n        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n        if model_output_classes == 2:\n            self.last_dense = tf.keras.layers.Dense(units=1,\n                                           activation=\"sigmoid\")\n        else:\n            self.last_dense = tf.keras.layers.Dense(units=model_output_classes,\n                                           activation=\"softmax\")\n    \n    def call(self, inputs, training):\n        l = self.embedding(inputs)\n        l_1 = self.cnn_layer1(l) \n        l_1 = self.pool(l_1) \n        l_2 = self.cnn_layer2(l) \n        l_2 = self.pool(l_2)\n        l_3 = self.cnn_layer3(l)\n        l_3 = self.pool(l_3) \n        \n        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n        concatenated = self.dense_1(concatenated)\n        concatenated = self.dropout(concatenated, training)\n        model_output = self.last_dense(concatenated)\n        \n        return model_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VOCAB_LENGTH = len(tokenizer.vocab)\nEMB_DIM = 200\nCNN_FILTERS = 100\nDNN_UNITS = 256\nOUTPUT_CLASSES = 2\n\nDROPOUT_RATE = 0.2\n\nNB_EPOCHS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n                        embedding_dimensions=EMB_DIM,\n                        cnn_filters=CNN_FILTERS,\n                        dnn_units=DNN_UNITS,\n                        model_output_classes=OUTPUT_CLASSES,\n                        dropout_rate=DROPOUT_RATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if OUTPUT_CLASSES == 2:\n    text_model.compile(loss=\"binary_crossentropy\",\n                       optimizer=\"adam\",\n                       metrics=[\"accuracy\"])\nelse:\n    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n                       optimizer=\"adam\",\n                       metrics=[\"sparse_categorical_accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_model.fit(train_data, epochs=NB_EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = text_model.evaluate(test_data)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}