{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"49c5eef4-a0eb-5453-0f18-3649ee90c60e"},"source":"Since I am interested in working as a data scientist in the video game industry, I thought I would look at this StarCraft data set. I am looking to answer the questions posed with the set. \n\nHow do the replay attributes differ by level of player expertise?\nWhat are significant predictors of a player's league?\n\nIt seemed like a clustering problem to me. I enjoyed my data mining course and since we did not spend much time on a clustering project, I decided to use K-means as my clustering algorithm. There are 21 different attributes for this set. Of those 21, I removed attributes that were user reported (age, hours per week, and total hours) and the professionals players. \n\nThe user reported values are likely to contain \"errors\", like the person reporting a total hour play time of 1,000,000 hours.  The professionals were removed because the game itself ranges in rank from bronze to grand master. The researchers who created the data set added the professional rank but the professionals can only have a rank between bronze and grand master within the game. This makes their data points invalid based on improper labeling. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f1cf8a8-36ec-2e89-8887-36add3927cce"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import homogeneity_score\n\nkf = KFold(n_splits = 10) \nkmeans = KMeans(n_clusters = 7, random_state = 31133113)\n\nstarcraft = pd.read_csv('../input/starcraft.csv')\nstar = starcraft.loc[starcraft['TotalHours'].notnull()]\ny = pd.DataFrame(star, columns = ['LeagueIndex'])-1 # make zero-indexed\n\nbest_attr = [['UniqueHotkeys', 'ComplexUnitsMade', 'ComplexAbilityUsed', 'MaxTimeStamp'],\n             ['MinimapAttacks', 'ComplexUnitsMade', 'ComplexAbilityUsed', 'MaxTimeStamp'],\n             ['APM', 'UniqueHotkeys', 'TotalMapExplored', 'UniqueUnitsMade', 'ComplexUnitsMade',\n              'ComplexAbilityUsed', 'MaxTimeStamp'],\n             ['UniqueHotkeys', 'MinimapAttacks', 'ActionLatency', 'WorkersMade', \n              'ComplexUnitsMade']]"},{"cell_type":"markdown","metadata":{"_cell_guid":"d1f7a39b-47f0-8494-8edc-fd7e9281888c"},"source":"I selected the attributes in the best attributes list from a genetic algorithm I modified for this analysis. I did not establish a fitness score threshold for my algorithm. Instead, I allowed the algorithm to run for 5000 generations. The algorithm returned the attributes with the highest minimum silhouette score. \n\nSilhouette scores have a values between -1 and 1 inclusive. A larger positive value indicates a point's increased belonging to its assigned class. An increasing negative values indicates a point's increased belonging to a different class. Higher minimum silhouette scores correlates well with higher average silhouette scores. With no negative silhouette scores, I can assume that the poorest placement of a point in the cluster will more likely belong in the cluster to which it was assigned.\n\nThe genetic algorithm can be found on my GitHub page located [here][1].\n\nThe following loop evaluates the best attributes based on my GA results.\n\n\n  [1]: https://github.com/elleqelle/StarCraft-II-K-means"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d76fd38-e163-e1a6-5eae-f7390c9160ca"},"outputs":[],"source":"for attr in best_attr:\n    X = pd.DataFrame(star, columns = attr)\n    X += 0.0000001\n    X = X.apply(np.log)\n\n    X_sample, X_validation, y_sample, y_validation = train_test_split(\n        X, y, test_size=0.2, random_state = 13)\n    \n    sil_min = []\n    sil_mean = []\n    jaccard = []\n    purity = []\n\n    for train, test in kf.split(X_sample):        \n        labels = kmeans.fit_predict(X_sample.iloc[train,:])\n        sil_vals = silhouette_samples(X_sample.iloc[train,:], labels)\n        sil_min.append(min(sil_vals))\n        sil_mean.append(np.mean(sil_vals))\n        \n        jaccard.append(jaccard_similarity_score(y_sample.iloc[train,:], labels)) \n        purity.append(homogeneity_score(y_sample.iloc[train,:].values.flatten(), labels))\n        \n    print(attr)\n    print('Avg Silhouette min: ' + str(np.mean(np.asarray(sil_min))))\n    print('Avg Silhouette mean: ' + str(np.mean(np.asarray(sil_mean))))\n    print('Avg Jaccarad siilarity: ' + str(np.mean(np.asarray(jaccard))))\n    print('Avg Purity: ' + str(np.mean(np.asarray(purity))))\n    print()"},{"cell_type":"markdown","metadata":{"_cell_guid":"20d9cbc8-7859-8540-38b9-826b900c98a8"},"source":"We can see based on the above testing that UniqueHotkeys, ComplexUnitsMade, ComplexAbilityUsed, MaxTimeStamp has a high average silhouette minimum value and the highest average mean values. It also has the least number of attributes, so I will use those attributes for evaluation with the validation set. \n\nI included two additional metrics for comparison. I selected the Jaccard similiary and the purity score. Jaccard similarity and purity score are both external measures ranging from 0 to 1 inclusive. They require a priori class membership of the points classified in order to produce a score. Silhouette score, however, is an internal measure and only evaluates cluster membership based on a given point's distance to the cluster center the algorithm assigned it and its distance to other cluster centers. It does not require an knowledge of true class membership. I'll delve more into the external measures later.\n\nNow, let's look at the validation set classification."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95b30c9e-39bd-48a0-ff91-b20cccdc3b73"},"outputs":[],"source":"top_attr = ['UniqueHotkeys', 'ComplexUnitsMade', 'ComplexAbilityUsed', 'MaxTimeStamp']\nX = pd.DataFrame(star, columns = top_attr)\nX += 0.0000001\nX = X.apply(np.log)\n\nX_sample, X_validation, y_sample, y_validation = train_test_split(\n    X, y, test_size=0.2, random_state = 13)\n    \ncenters = kmeans.fit(X_sample)\nlabels = kmeans.predict(X_validation)\nsil_vals = silhouette_samples(X_validation, labels)\n\n\nprint(\"Validation Silhouette min: \" + str(min(sil_vals)))\nprint(\"Validation Silhouette mean: \" + str(np.mean(sil_vals)))\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"65d060fa-b024-5d47-f779-46d94558c514"},"source":"This looks pretty promising. An actual improvement in the validation set over the training set!?! A minimum silhouette well over 0 and a fairly high silhouette score mean seems like a great set of clusters! I want get a closer look at these cluster centers."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c823fd18-27a8-8a1e-53b7-c4afad97bdd2"},"outputs":[],"source":"star_centers = []\n\nfor i in range(7):\n    star_centers.append(np.exp(centers.cluster_centers_[i]))\n    \nlevel_centers = pd.DataFrame(star_centers, columns = top_attr)\nlevel_centers.index = range(1, len(level_centers)+1)\nlevel_centers[level_centers <= 0.0000001] = 0\n\nprint(level_centers)"},{"cell_type":"markdown","metadata":{"_cell_guid":"17c23f13-66b2-e738-be4f-70b584ff7fc0"},"source":"I based the the data frame's index on the ranks provided in the data. 1 is the bronze level and 7 is the grand master level. \n\nA quick glance at this data frame tells you almost nothing intuitive. The values for the centers appear randomly placed. My metrics tell me I have relatively good separation for all the data points, but these centers are meaningless as there is no trend along any of the columns. One can learn nothing tangible from these results outside of the ability to separate the points into reasonable clusters. \n\nI used the other high scoring list of attributes in the selection to see if this trend holds."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b10b93ef-5c58-00e9-a541-794560c81998"},"outputs":[],"source":"top_attr = ['APM', 'UniqueHotkeys', 'TotalMapExplored', 'UniqueUnitsMade', 'ComplexUnitsMade',\n              'ComplexAbilityUsed', 'MaxTimeStamp']\nX = pd.DataFrame(star, columns = top_attr)\nX += 0.0000001\nX = X.apply(np.log)\n\nX_sample, X_validation, y_sample, y_validation = train_test_split(\n    X, y, test_size=0.2, random_state = 13)\n    \ncenters = kmeans.fit(X_sample)\nlabels = kmeans.predict(X_validation)\nsil_vals = silhouette_samples(X_validation, labels)\nstar_centers = []\n\nfor i in range(7):\n    star_centers.append(np.exp(centers.cluster_centers_[i]))\n    \nlevel_centers = pd.DataFrame(star_centers, columns = top_attr)\nlevel_centers.index = range(1, len(level_centers)+1)\nlevel_centers[level_centers <= 0.0000001] = 0\n\nprint(\"Validation Silhouette min: \" + str(min(sil_vals)))\nprint(\"Validation Silhouette mean: \" + str(np.mean(sil_vals)))\nprint()\nprint(level_centers)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8768368c-5440-7039-b36b-b84410b8883b"},"source":"Sure enough, it does. \n\nPrior to running these algorithms, I did do some exploratory data analysis and one could be led to believe that a pattern existed of increase or decrease in certain attributes. For example, the box and whisker plots of APM, UniqueHotkeys, ComplexAbilityUsed, and MaxTimeStamp."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb139974-9d42-b884-be7d-300307e1dbe9"},"outputs":[],"source":"import seaborn as sns\n\nsns.boxplot(x = star['LeagueIndex'], y = star['APM'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2a43f35-8d92-5e2a-4c9a-3ff2ee16db10"},"outputs":[],"source":"sns.boxplot(x = star['LeagueIndex'], y = star['UniqueHotkeys'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3194192-36c8-9fae-90ae-645810560ec5"},"outputs":[],"source":"sns.boxplot(x = star['LeagueIndex'], y = star['ComplexUnitsMade'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"692a5716-0767-89ca-819e-bd9d39d93f57"},"outputs":[],"source":"sns.boxplot(x = star['LeagueIndex'], y = star['MaxTimeStamp'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"b2bc521a-d404-9688-8458-97625edbc042"},"source":"One can see that even with attributes showing the greatest separation of value, the whiskers and the IQRs overlap throughout. Values across the league index show great similarity and will not lead to any satisfying, or significant, separations. Sure, grand master players perform a lot of actions per minute (APM), but so do the rest of the players. "},{"cell_type":"markdown","metadata":{"_cell_guid":"1a29dd4e-dadd-b972-2a1c-8f1f97df7e28"},"source":"This brings back my earlier look at internal and external measures. The internal measures tell me that the clusters I produced are valid. The external measures disagree. The external measures disagree because the clusters the K-means algorithm places the points disregards the a priori classification. It has no clue about league index and places the points in clusters based on its algorithm. If the clustering placed the points into clusters based on the league index, we would see agreement between the internal and external measure values. But we don't. \n\nThe leads me to believe that the values provided in this data set are not enough to determine what rank a StarCraft player has. The final cluster centers do not provide a coherent pattern to easily assess a player's rank based on the cluster attributes with regards to external validation. I can easily, and fairly accurately, classify a new player based on the computed centers, but it has no relationship to the external rankings.  \n\nIn order to answer the question posed originally, I would either need additional data to improve agreement between internal and external measures, or I would conclude that K-means clustering is not sufficient to answer the question as stated.  (Or, I need to \"git gud\" at K-means :) ) "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}