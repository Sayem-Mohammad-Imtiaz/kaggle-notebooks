{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Welcome\n</div>"},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:Beige;\n           font-size:110%;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    \nHello Kagglers, <br>\n\nIn this notebook, I am going to predict whether an individual is healthy or diabetic. But, first I am going to do exploratory data analysis on our dataset and learn what is the common trait of people who has diabetes. Then, I am going to use multiple classification models on our dataset and select the best performing one. \n</p>\n</div>   "},{"metadata":{},"cell_type":"markdown","source":"### **Table of Contents:**\n1. [Importing Libraries](#1)<a href='1' ></a> <br>\n2. [Importing Dataset](#2)<a href='2' ></a> <br>\n3. [Expolatory Data Analysis](#3)<a href='3' ></a> <br>\n    3.1. [Heat Map Correlation](#3.1)<a href='3.1' ></a> <br>\n    3.2. [Pie Chart](#3.2)<a href='3.2' ></a> <br>\n    3.3. [Distribution Plot](#3.3)<a href='3.3' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; a. [Healthy vs Diabetic by Pregnancy](#3.3.1)<a href='3.3.1' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; b. [Healthy vs Diabetic by Glucose](#3.3.2)<a href='3.3.2' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; c. [Healthy vs Diabetic by Blood Pressure](#3.3.3)<a href='3.3.3' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; d. [Healthy vs Diabetic by Skin Thickness](#3.3.4)<a href='3.3.4' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; e. [Healthy vs Diabetic by Insulin](#3.3.5)<a href='3.3.5' ></a><br>\n    &nbsp;&nbsp;&nbsp;&nbsp; f. &nbsp;[Healthy vs Diabetic by BMI](#3.3.6)<a href='3.3.6' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; g. [Healthy vs Diabetic by Diabetes Pedigree Function](#3.3.7)<a href='3.3.7' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; h. [Healthy vs Diabetic by Age](#3.3.8)<a href='3.3.8' ></a> <br>\n    3.4. [Outliers - Detecting and Removing](#3.4)<a href='3.4' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; a. [Pregnancy](#3.4.1)<a href='3.4.1' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; b. [Glucose](#3.4.2)<a href='3.4.2' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; c. [Blood Pressure](#3.4.3)<a href='3.4.3' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; d. [Skin Thickness](#3.4.4)<a href='3.4.4' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; e. [Insulin](#3.4.5)<a href='3.4.5' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; f. &nbsp;[BMI](#3.4.6)<a href='3.4.6' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; g. [Diabetes Pedigree Function](#3.4.7)<a href='3.4.7' ></a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; h. [Age](#3.4.8)<a href='3.4.8' ></a> <br>\n    3.4. [Pair Plot](#3.5)<a href='3.5' ></a> <br>\n4. [Data Preprocessing](#4)<a href='4' ></a> <br> \n5. [Splitting Data into Train and Test Set](#5)<a href='5' ></a> <br>\n6. [Feature Scaling](#6)<a href='6' ></a> <br>\n7. [Model Selection](#7)<a href='7' ></a> <br>\n8. [Tuning the Models](#8)<a href='8' ></a> <br>\n9. [Models after Tuning Hyperparameters](#9)<a href='9' ></a> <br>\n    9.1. [Logistic Regression](#9.1)<a href='9.1' ></a> <br>\n    9.2. [Kneighbors](#9.2)<a href='9.2' ></a> <br>\n    9.3. [SVC](#9.3)<a href='9.3' ></a> <br> \n    9.4. [GaussianNB](#9.4)<a href='9.4' ></a> <br>\n    9.5. [BernoulliNB](#9.5)<a href='9.5' ></a> <br>\n    9.6. [Decision Tree](#9.6)<a href='9.6' ></a> <br>\n    9.7. [Random Forest](#9.7)<a href='9.7' ></a> <br>\n    9.8. [Extra Trees](#9.8)<a href='9.8' ></a> <br>\n    9.9. [AdaBoost](#9.9)<a href='9.9' ></a> <br>\n    9.10. [Gradient Boost](#9.10)<a href='9.10' ></a> <br>\n    9.11. [LightGBM](#9.11)<a href='9.11' ></a> <br>\n    9.12. [XGBoost](#9.12)<a href='9.12' ></a> <br>\n10. [Conclusion](#10)<a href='10' ></a> <br>    "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='1'></a>\n    \n    Importing Libraries \n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '2'></a>\n    \n    Importing Dataset \n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 Check if there are any NULL values."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '3'></a>\n\n    Exploratory Data Analysis \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## **Heat Map Correlation** <a id='3.1' ></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(dataset.corr(), cmap=\"YlGnBu\", annot= True,)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Pie Chart** <a id='3.2' ></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\")\nlabels = ['Healthy', 'Diabetic']\nsizes = dataset['Outcome'].value_counts(sort = True)\n\ncolors = [\"lightblue\",\"red\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.title('Number of diabetes in the dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 From above pie chart, we can say that around 65% of the people are Healthy and 35% are Diabetic "},{"metadata":{},"cell_type":"markdown","source":"## **Distribution Plot** <a id='3.3'></a>"},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by Pregnancy <a id='3.3.1'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"Pregnancies\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"Pregnancies\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by Pregnancy', fontsize=15)\nplt.xlim([-5,20])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 From above graph, we can say that the Pregnancy isn't likely cause for diabetes as the distribution between the Healthy and Diabetic is almost same. "},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by Glucose <a id='3.3.2'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"Glucose\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"Glucose\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by Glucose', fontsize=15)\nplt.xlim([-5,250])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 Diabetes is a disease that occurs when your blood glucose, also called blood sugar, is too high. Blood glucose is your main source of energy and comes from the food you eat. <br>\n\n📌 The Glucose level for a Normal Adult is around 120-130mg/dl anything above it means that the person is likely suffering from pre-diabetes and diabetes. <br>\n\n📌 From above graph, we can see the the Healthy person are more around 120mg/dl but it then gradually drops, and for diabetic person it is vice versa."},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by Blood Pressure <a id='3.3.3'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"BloodPressure\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"BloodPressure\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by Blood Pressure', fontsize=15)\nplt.xlim([-5,150])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 High blood pressure (also known as “hypertension”) is very common in people with diabetes. In fact, the two conditions often go hand-in-hand because they can both result from the same lifestyle factors. <br>\n\n📌 Diabetes damages arteries and makes them targets for hardening, called atherosclerosis. That can cause high blood pressure, which if not treated, can lead to trouble including blood vessel damage, heart attack, and kidney failure. <br>\n\n📌 For a Normal person BP should be at or below 120/80 mm Hg, the person with hypertension can be above 139/89 mm Hg. <br>\n\n📌 From above graph, we can say that, diabetic and healthy people are evenly distributed with low and normal BP but, there are less healthy people who have high BP. "},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by Skin Thickness <a id='3.3.4'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"SkinThickness\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"SkinThickness\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by Skin Thickness', fontsize=15)\nplt.xlim([-5,120])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 Changes to the blood vessels because of diabetes can cause a skin condition called diabetic dermopathy. Dermopathy appears as scaly patches that are light brown or red, often on the front of the legs. The patches do not hurt, blister, or itch, and treatment generally is not necessary. <br>\n\n📌 From above graph, the distribution between healthy and diabetic people are around same for skin thickness."},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by Insulin <a id='3.3.5'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"Insulin\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"Insulin\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by Insulin', fontsize=15)\nplt.xlim([-10,900])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 Insulin is a hormone that your pancreas makes to allow cells to use glucose. When your body isn't making or using insulin correctly, you can take man-made insulin to help control your blood sugar. Many types can be used to treat diabetes. <br>\n\n📌 Insulin helps control blood glucose levels by signaling the liver and muscle and fat cells to take in glucose from the blood. Insulin therefore helps cells to take in glucose to be used for energy. If the body has sufficient energy, insulin signals the liver to take up glucose and store it as glycogen. <br>\n\n📌 From above graph, we can see that there are diabetic people increase as the levels of insulin gradually increases. There are more healthy people around insulin levels 0-100."},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by BMI <a id='3.3.6'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"BMI\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"BMI\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by BMI', fontsize=15)\nplt.xlim([-10,75])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 Being overweight (BMI of 25-29.9), or affected by obesity (BMI of 30-39.9) or morbid obesity (BMI of 40 or greater), greatly increases your risk of developing type 2 diabetes. The more excess weight you have, the more resistant your muscle and tissue cells become to your own insulin hormone. <br>\n\n📌 From above graph we can determine that, as the BMI increases the person likely being healthy decreases and being diabetic increases. "},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by Diabetes Pedigree Function <a id='3.3.7'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"DiabetesPedigreeFunction\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"DiabetesPedigreeFunction\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by Diabetes Pedigree Function', fontsize=15)\nplt.xlim([-1,3])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 Diabetes Pedigree Function is a function which scores likelihood of diabetes based on family history. It provided some data on diabetes mellitus history in relatives and the genetic relationship of those relatives to the patient. <br>\n\n📌 From above graph, as thefunction increase the diabetic people increases, showing that the diabetes could be hereditary for that individual."},{"metadata":{},"cell_type":"markdown","source":"### Healthy vs Diabetic by Age <a id='3.3.8'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(dataset[dataset['Outcome'] == 0][\"Age\"], color='green') # Healthy - green\nsns.distplot(dataset[dataset['Outcome'] == 1][\"Age\"], color='red') # Diabetic - Red\n\nplt.title('Healthy vs Diabetic by Age', fontsize=15)\nplt.xlim([0,100])\nplt.grid(linewidth = 0.7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 As the person ages, they are at high risk for the development of type 2 diabetes due to the combined effects of increasing insulin resistance and impaired pancreatic islet function with aging. <br>\n\n📌 From above graph, we can see that there are more healthy people around 20-25 age but as the age gradually increases so does the people being diabetic, this shows that age and diabetes go hand in hand."},{"metadata":{},"cell_type":"markdown","source":"## **Outliers - Detecting and Removing** <a id='3.4'></a>"},{"metadata":{},"cell_type":"markdown","source":"📌 An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. <br>\n\n📌 In this notebook, we are using ***Box Plot*** to detect the outliers of each features in our dataset, where any point above or below the whiskers represent an outlier. This is also known as “***Univariate method***” as here we are using one variable outlier analysis. <br>\n\n📌 It is represented by the formula ***IQR = Q3 − Q1***. The lines of code below calculate and print the interquartile range for each of the variables in the dataset. The above output prints the IQR scores, which can be used to detect outliers. <br>\n\n📌 After detecting, we are using ***Median Imputation*** to take care of outliers. In this technique, we replace the extreme values with median values. It is advised to not use mean values as they are affected by outliers. "},{"metadata":{},"cell_type":"markdown","source":"### Pregnancy <a id='3.4.1'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.Pregnancies)\nplt.xlim([-1,20])\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.Pregnancies.quantile(0.25)\nq3 = dataset.Pregnancies.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.Pregnancies)\nfor i in dataset.Pregnancies:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.Pregnancies = dataset.Pregnancies.replace(i, med)\nsns.boxplot(x= dataset.Pregnancies)\nplt.xlim([-1,15])\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Glucose <a id='3.4.2'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.Glucose)\nplt.xlim([-2,210])\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.Glucose.quantile(0.25)\nq3 = dataset.Glucose.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.Glucose)\nfor i in dataset.Glucose:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.Glucose = dataset.Glucose.replace(i, med)\nsns.boxplot(x= dataset.Glucose)\nplt.xlim([-2,210])\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Blood Pressure <a id='3.4.3'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.BloodPressure)\nplt.xlim([-1,140])\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.BloodPressure.quantile(0.25)\nq3 = dataset.BloodPressure.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.BloodPressure)\nfor i in dataset.BloodPressure:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.BloodPressure = dataset.BloodPressure.replace(i, med)\nsns.boxplot(x= dataset.BloodPressure)\nplt.xlim([-1,140])\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Skin Thickness <a id='3.4.4'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.SkinThickness)\nplt.xlim([-3,105])\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.SkinThickness.quantile(0.25)\nq3 = dataset.SkinThickness.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.SkinThickness)\nfor i in dataset.SkinThickness:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.SkinThickness = dataset.SkinThickness.replace(i, med)\nsns.boxplot(x= dataset.SkinThickness)\nplt.xlim([-3,105])\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insulin <a id='3.4.5'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.Insulin)\nplt.xlim([-10,905])\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.Insulin.quantile(0.25)\nq3 = dataset.Insulin.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.Insulin)\nfor i in dataset.Insulin:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.Insulin = dataset.Insulin.replace(i, med)\nsns.boxplot(x= dataset.Insulin)\nplt.xlim([-10,905])\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### BMI <a id='3.4.6'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.BMI)\nplt.xlim([-3,75])\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.BMI.quantile(0.25)\nq3 = dataset.BMI.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.BMI)\nfor i in dataset.BMI:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.BMI = dataset.BMI.replace(i, med)\nsns.boxplot(x= dataset.BMI)\nplt.xlim([-3,75])\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Diabetes Pedigree Function <a id='3.4.7'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.DiabetesPedigreeFunction)\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.DiabetesPedigreeFunction.quantile(0.25)\nq3 = dataset.DiabetesPedigreeFunction.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.DiabetesPedigreeFunction)\nfor i in dataset.DiabetesPedigreeFunction:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.DiabetesPedigreeFunction = dataset.DiabetesPedigreeFunction.replace(i, med)\nsns.boxplot(x= dataset.DiabetesPedigreeFunction)\nplt.xlim([0,1.5])\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age <a id='3.4.8'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x= dataset.Age)\nplt.title(\"Box Plot before Median Imputation\")\nplt.show()\n\nq1 = dataset.Age.quantile(0.25)\nq3 = dataset.Age.quantile(0.75)\niqr = q3-q1\nLower_tail = q1 - 1.5 * iqr\nUpper_tail = q3 + 1.5 * iqr\nmed = np.median(dataset.Age)\nfor i in dataset.Age:\n    if i > Upper_tail or i < Lower_tail:\n            dataset.Age = dataset.Age.replace(i, med)\nsns.boxplot(x= dataset.Age)\nplt.title(\"Box Plot after Median Imputation\")\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 From above all the graphs, I took care of all the outliers present in the dataset. "},{"metadata":{},"cell_type":"markdown","source":"### **Pair Plot** <a id='3.5'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=dataset,hue='Outcome',diag_kind='kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 From the above graphs, we can see that the outliers in our dataset have been taken care of. "},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '4'></a>\n    \n    Data Preprocessing \n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '5'></a>\n    \n    Splitting Data into Train and Test Set \n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number transactions x_train dataset: \", x_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions x_test dataset: \", x_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '6'></a>\n    \n    Feature Scaling \n</div>"},{"metadata":{},"cell_type":"markdown","source":"📌 StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance. Unit variance means dividing all the values by the standard deviation. StandardScaler results in a distribution with a standard deviation equal to 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '7'></a>\n\n    Model Selection \n</div>"},{"metadata":{},"cell_type":"markdown","source":"📌 We are using different classification models to determine Accuracy, K-Fold Validation, ROC AUC, Precision, Recall and F1 score."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(['Logistic Regreesion', LogisticRegression(random_state=0)])\nmodels.append(['SVM', SVC(random_state=0)])\nmodels.append(['KNeighbors', KNeighborsClassifier()])\nmodels.append(['GaussianNB', GaussianNB()])\nmodels.append(['BernoulliNB', BernoulliNB()])\nmodels.append(['Decision Tree', DecisionTreeClassifier(random_state=0)])\nmodels.append(['Random Forest', RandomForestClassifier(random_state=0)])\nmodels.append(['Extra Tree', ExtraTreesClassifier(random_state=0)])\nmodels.append(['AdaBoost', AdaBoostClassifier(random_state=0)])\nmodels.append(['Gradiesnt Boost', GradientBoostingClassifier(random_state=0)])\nmodels.append(['Light GBM', LGBMClassifier(random_state=0)])\nmodels.append(['XGBoost', XGBClassifier(eval_metric= 'error')])\n\nlst_1= []\n\nfor m in range(len(models)):\n    lst_2= []\n    model = models[m][1]\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    cm = confusion_matrix(y_test, y_pred)  #Confusion Matrix\n    accuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10)   #K-Fold Validation\n    roc = roc_auc_score(y_test, y_pred)  #ROC AUC Score\n    precision = precision_score(y_test, y_pred)  #Precision Score\n    recall = recall_score(y_test, y_pred)  #Recall Score\n    f1 = f1_score(y_test, y_pred)  #F1 Score\n    print(models[m][0],':')\n    print(cm)\n    print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n    print('')\n    print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n    print('')\n    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n    print('')\n    print('ROC AUC Score: {:.2f}'.format(roc))\n    print('')\n    print('Precision: {:.2f}'.format(precision))\n    print('')\n    print('Recall: {:.2f}'.format(recall))\n    print('')\n    print('F1: {:.2f}'.format(f1))\n    print('-----------------------------------')\n    print('')\n    lst_2.append(models[m][0])\n    lst_2.append((accuracy_score(y_test, y_pred))*100) \n    lst_2.append(accuracies.mean()*100)\n    lst_2.append(accuracies.std()*100)\n    lst_2.append(roc)\n    lst_2.append(precision)\n    lst_2.append(recall)\n    lst_2.append(f1)\n    lst_1.append(lst_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(lst_1, columns= ['Model', 'Accuracy', 'K-Fold Mean Accuracy', 'Std. Deviation', 'ROC AUC', 'Precision', 'Recall', 'F1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by= ['Accuracy', 'K-Fold Mean Accuracy'], inplace= True, ascending= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 From above we can determine, RandomForest seems to have high accuracy but the standard deviation is high and its ROC AUC score also is high. <br>\n\n📌 But, we will also tune the model with Grid Search to determine best parameters for different models and to also increase its overall scores. "},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '8'></a>\n\n    Tuning the Models \n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"📌 The ***GridSearchCV*** is a library function that is a member of sklearn's model_selection package. It helps to loop through predefined hyperparameters and fit your estimator (model) on your training set. So, in the end, you can select the best parameters from the listed hyperparameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_models = [(LogisticRegression(),[{'C':[0.25,0.5,0.75,1],'random_state':[0]}]), \n               (KNeighborsClassifier(),[{'n_neighbors':[5,7,8,10], 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n               (SVC(),[{'C':[0.25,0.5,0.75,1],'kernel':['linear', 'rbf'],'random_state':[0]}]), \n               (GaussianNB(),[{'var_smoothing': [1e-09]}]), \n               (BernoulliNB(), [{'alpha': [0.25, 0.5, 1]}]), \n               (DecisionTreeClassifier(),[{'criterion':['gini','entropy'],'random_state':[0]}]), \n               (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}]),\n               (ExtraTreesClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}]),\n               (AdaBoostClassifier(),[{'n_estimators':[100,150,200],'learning_rate':[0.1, 0.5, 0.8, 1],'algorithm':['SAMME', 'SAMME.R'], 'random_state':[0]}]),\n               (GradientBoostingClassifier(),[{'n_estimators':[100,150,200],'criterion':['friedman_mse','mse'],'loss':['deviance','exponential'],'learning_rate':[0.1, 0.5, 0.8, 1],'random_state':[0]}]),\n               (LGBMClassifier(),[{'n_estimators':[100,150,200],'learning_rate':[0.1, 0.5, 0.8, 1],'random_state':[0]}]),\n               (XGBClassifier(), [{'learning_rate': [0.01, 0.05, 0.1], 'eval_metric': ['error']}])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in grid_models:\n    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'accuracy',cv = 10)\n    grid.fit(x_train, y_train)\n    best_accuracy = grid.best_score_\n    best_param = grid.best_params_\n    print('{}:\\nBest Accuracy : {:.2f}%'.format(i,best_accuracy*100))\n    print('Best Parameters : ',best_param)\n    print('')\n    print('----------------')\n    print('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '9'></a>\n\n    Models after Tuning Hyperparameters \n</div>"},{"metadata":{},"cell_type":"markdown","source":"📌 After Grid Search, we got best parameters for all the models. Now, we going to tune hyperparameters see how to it perform. <br>\n\n📌 ***True Positives (TP)*** - These are the correctly predicted positive values which means that the value of actual class is yes and the value of predicted class is also yes. <br>\n\n📌 ***True Negatives (TN)*** - These are the correctly predicted negative values which means that the value of actual class is no and value of predicted class is also no. <br>\n\n📌 ***False Positives (FP)*** – When actual class is no and predicted class is yes. <br>\n\n📌 ***False Negatives (FN)*** – When actual class is yes but predicted class in no. <br>\n\n📌 ***Accuracy*** - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Accuracy = TP+TN/TP+FP+FN+TN** <br>\n\n📌 ***Precision*** - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Precision = TP/TP+FP** <br>\n\n📌 ***Recall (Sensitivity)*** - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Recall = TP/TP+FN** <br>\n\n📌 ***F1 score*** - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**F1 Score = 2*(Recall * Precision) / (Recall + Precision)** <br>\n\n📌 ***Support*** - Support is the number of actual occurrences of the class in the specified dataset. Support doesn’t change between models but instead diagnoses the evaluation process. "},{"metadata":{},"cell_type":"markdown","source":"## **Logistic Regression** <a id='9.1'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting Logistic Regression Model\nclassifier = LogisticRegression(C= 1, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\nplt.figure(figsize = (6, 6))\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **KNeighbors** <a id='9.2'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting KNeighborsClassifier Model\nclassifier = KNeighborsClassifier(metric= 'manhattan', n_neighbors= 8)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **SVC** <a id='9.3'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting SVC Model\nclassifier = SVC(C= 0.5, kernel= 'linear', random_state= 0, probability=True)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **GaussianNB** <a id='9.4'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting GaussianNB Model\nclassifier = GaussianNB(var_smoothing= 1e-09)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **BernoulliNB** <a id='9.5'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting BernoulliNB Model\nclassifier = BernoulliNB(alpha= 0.25)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Decision Tree** <a id='9.6'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting DecisionTreeClassifier Model\nclassifier = DecisionTreeClassifier(criterion= 'gini', random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Random Forest** <a id='9.7'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting RandomForestClassifier Model\nclassifier = RandomForestClassifier(criterion= 'entropy', n_estimators= 200, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Extra Trees** <a id='9.8'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting ExtraTreesClassifier Model\nclassifier = ExtraTreesClassifier(criterion= 'gini', n_estimators= 100, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **AdaBoost** <a id='9.9'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting AdaBoostClassifier Model\nclassifier = AdaBoostClassifier(algorithm= 'SAMME', learning_rate= 0.1, n_estimators= 100, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Gradient Boost** <a id='9.10'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting GradientBoostingClassifier Model\nclassifier = GradientBoostingClassifier(criterion= 'mse', learning_rate= 0.1, loss= 'exponential', n_estimators= 100, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **LightGBM** <a id='9.11'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting LGBMClassifier Model\nclassifier = LGBMClassifier(learning_rate= 0.1, n_estimators= 100, random_state= 0)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **XGBoost** <a id='9.12'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting XGBClassifier Model\nclassifier = XGBClassifier(eval_metric= 'error', learning_rate= 0.1)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\n\n# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Healthy', 'Diabetic'], xticklabels = ['Predicted Healthy', 'Predicted Diabetic'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (6, 6))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC AUC Curve')\nplt.legend()\nplt.show()\n\n#Precision Recall Curve\naverage_precision = average_precision_score(y_test, y_prob)\ndisp = plot_precision_recall_curve(classifier, x_test, y_test)\nplt.title('Precision-Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '10'></a>\n\n    Conclusion\n</div>"},{"metadata":{},"cell_type":"markdown","source":"📌 After extensive data analysis and I tried different classification models to see how it performs on the dataset. I got pretty good results with accuracy, roc, precision and recall score. <br>\n\n📌 But, I didn't stop there, after that I tuned the hyperparamters with the help of Grid Search and saw the classification report with ROC AUC and Precision-Recall curve of different models. <br>\n\n📌 With that, I came to conclusion that ***RandomForest***, ***ExtraTrees*** and ***SVC*** are models which are best fit for our dataset. <br>"},{"metadata":{},"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           border:2px solid DodgerBlue;\n           background-color:white;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n    Thank You!\n</div>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}