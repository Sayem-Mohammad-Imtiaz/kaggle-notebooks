{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Single Image has 4 channels -> red, green, blue and near infra red\n################################################################################################\nBATCH_SIZE = 8\nLEARNING_RATE = 0.02\nEPOCHS = 5\nCROP = 256\nTEST_SIZE = 40668\nRESIZE = 256\nRMEAN = 0.6287\nGMEAN = 0.5494\nBMEAN = 0.3999\nNIRMEAN = 0.0808\n################################################################################################\n\nimport os \nimport pandas as pd  # for lookup in annotation file\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence  # pad batch\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image  # Load img\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport statistics\nimport torchvision.models as models\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torchvision.transforms.functional as TF\nimport torch.nn.functional as F\nimport random\n\nclass PlanetDataset(Dataset):\n    def __init__(self, csvfile, imgdir, transform=None, extension='jpg'):\n        self.csvfile = csvfile\n        self.imgdir = imgdir\n        self.extension = extension\n        \n        self.df = pd.read_csv(csvfile)[:4000]\n            \n        self.transform = transform\n        self.images = self.df['image_name']\n        self.tags = self.df['tags']\n        self.tags_to_index = {'agriculture' : 0, 'artisinal_mine': 1, 'bare_ground' : 2, 'blooming' : 3,\n                         'blow_down':4,'clear':5,'cloudy':6,'conventional_mine':7,'cultivation':8,\n                         'habitation':9,'haze':10,'partly_cloudy':11,'primary':12,'road':13,'selective_logging':14,\n                         'slash_burn':15,'water':16}\n        \n        self.index_to_tags = {}\n        for e in self.tags_to_index:\n            self.index_to_tags[self.tags_to_index[e]] = e\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def mytransforms(self, img):\n        #img = transforms.Resize((RESIZE, RESIZE))(img)\n        #if random.random() > 0.5:\n        #    img = TF.adjust_gamma(img, 1, gain=1)\n        #if random.random() > 0.5:\n        #    img = TF.adjust_saturation(img, 2)\n        img = transforms.RandomRotation(90)(img)\n        img = transforms.RandomRotation(180)(img)\n        img = transforms.RandomHorizontalFlip()(img)\n        img = transforms.RandomVerticalFlip()(img)\n        #img = transforms.RandomCrop(CROP)(img)\n        img = transforms.ColorJitter()(img)\n        #img = transforms.GaussianBlur(5)(img)\n        img = transforms.ToTensor()(img)\n        img = transforms.Normalize((RMEAN, GMEAN, BMEAN, NIRMEAN), (0.5, 0.5, 0.5, 0.5))(img)\n        \n        return img\n            \n        \n    def __getitem__(self, index):\n        image_name = self.images[index] + '.' + self.extension\n        alltags = self.tags[index]\n        img  = Image.open(os.path.join(self.imgdir, image_name))\n        \n        img = self.mytransforms(img)\n        img = self.addAuxiliaryLayers(img)\n        \n        one_hot_labels = [0 for _ in range(17)]\n        for tag in alltags.split(' '):\n            one_hot_labels[self.tags_to_index[tag]] = 1.0\n        \n        return img, torch.tensor(one_hot_labels)\n    \n    #ignore this function not used\n    def addAuxiliaryLayers(self, img):\n        red = img[0]\n        green = img[1]\n        blue = img[2]\n        nir = img[3]\n        #img = torch.vstack((img, ((nir - red) / (nir+red)).unsqueeze(0) ))\n        #img = torch.vstack(( img, ( 2.5 * ((nir-red)/(nir+6*red-7.5*blue+1)) ).unsqueeze(0) ))\n        #img = torch.vstack(( img, ( (nir-red)/(nir+red+0.5) * 1.5 ).unsqueeze(0) ))\n        #img = torch.vstack(( img, ( (2*nir+1-torch.sqrt((2*nir+1)**2 - 8*(nir-red)))/2 ).unsqueeze(0) ))\n        #img = torch.vstack(( img, ( (green-nir)/(green+nir) ).unsqueeze(0) ))\n        #img = torch.vstack(( img, ( nir/red ).unsqueeze(0) ))\n        #img = torch.vstack(( img, (  ).unsqueeze(0) ))\n        return img\n    \n    \n'''class GISModel(nn.Module):\n    def __init__(self):\n        super(GISModel, self).__init__()\n        self.pool = nn.MaxPool2d(2, 2)\n        self.drop = nn.Dropout(0.5)\n        \n        # 3 is input color channels for image\n        self.conv1 = nn.Conv2d(9, 100, 5)\n        self.conv2 = nn.Conv2d(100, 200, 5)\n        self.fc1 = nn.Linear(61*61*200, 100)\n        self.fc2 = nn.Linear(100, 200)\n        self.fc3 = nn.Linear(200, 17)\n        \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 61*61*200)\n        x = self.drop(F.relu(self.fc1(x)))\n        x = F.relu(self.fc2(x))\n        x = self.drop(F.relu(self.fc3(x)))\n        \n        return x'''\n        \n\ndef showSamples(dataset, loader):\n    count = 0\n    for idx, (imgs, labels) in enumerate(loader):\n        for i in range(imgs.shape[0]):\n            count+=1\n            plt.imshow(transforms.ToPILImage()(imgs[i]).convert('RGB'))\n            all_tags =[]\n            for j in range(17):\n                if labels[i][j] == 1.0:\n                    all_tags.append(dataset.index_to_tags[j])\n            print(all_tags)\n            plt.show()\n            \n            if count > 4:\n                return\n\nTHRESHOLD = 0.3\ndef getPredForAccuracy(originals, predicted, threshold=THRESHOLD):\n    predicted = torch.sigmoid(predicted)\n    predicted[predicted >= threshold] = 1\n    predicted[predicted < threshold] = 0\n    return (predicted == originals).sum(), originals.numel() \n\ndef getPredForFBeta(predicted, originals, threshold=THRESHOLD):\n    predicted = torch.sigmoid(predicted)\n    predicted[predicted >= threshold] = 1\n    predicted[predicted < threshold] = 0\n    \n    confusion_vector = predicted / originals\n    tp = torch.sum(confusion_vector == 1).item()\n    fp = torch.sum(confusion_vector == float('inf')).item()\n    #tn = torch.sum(torch.isnan(confusion_vector)).item()\n    fn = torch.sum(confusion_vector == 0).item()\n    p = tp/(tp+fp)\n    r = tp/(tp+fn)\n    return ( (5*p*r)/(4*p+r) )\n\ndef calculateMean(loader):\n    redSum = torch.zeros((CROP, CROP))\n    greenSum = torch.zeros((CROP, CROP))\n    blueSum = torch.zeros((CROP, CROP))\n    nirSum = torch.zeros((CROP, CROP))\n    count = 0\n    for idx, (imgs, tags) in tqdm(\n                enumerate(train_loader), total=len(train_loader), leave=False\n            ):\n        for img in imgs:\n            redSum += img[0]\n            greenSum += img[1]\n            blueSum += img[2]\n            nirSum += img[3]\n        count += imgs.shape[0]\n    \n    totalPixels = CROP * CROP * count\n    return redSum.sum()/(totalPixels), greenSum.sum()/(totalPixels), blueSum.sum()/(totalPixels), nirSum.sum()/(totalPixels)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = None\ndef train():\n\n    dataset = PlanetDataset('../input/planets-dataset/planet/planet/train_classes.csv',\n                           '../input/understanding-amazon-from-space-tar/train-tif-v2/train-tif-v2', transform,\n                           extension='tif')\n    \n    train_size = int(0.8 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n    \n    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=True, pin_memory=False)\n    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=True, pin_memory=False)\n    \n    torch.backends.cudnn.benchmark = True\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    model = models.resnet50(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    # tif images have 4 channels\n    model.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    model.fc = nn.Linear(model.fc.in_features, 17)\n    #model = GISModel()\n    model.to(device)\n\n    #criterion = nn.CrossEntropyLoss()\n    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n    #criterion = nn.BCELoss(reduction='mean')\n    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n\n    total_steps = len(train_loader)\n\n    for epoch in range(EPOCHS):\n        for idx, (imgs, tags) in tqdm(\n                enumerate(train_loader), total=len(train_loader), leave=False\n            ):\n            imgs = imgs.to(device)\n            tags = tags.to(device)\n\n            outputs = model(imgs)\n            loss = criterion(outputs, tags)\n\n            optimizer.zero_grad()\n            loss.backward(loss)\n            optimizer.step()\n\n        correct_pred = 1\n        total_pred = 1\n        all_outputs = None\n        all_tags = None\n        with torch.no_grad():\n            for idx, (imgs, tags) in tqdm(\n                    enumerate(val_loader), total=len(val_loader), leave=False\n                ):\n                imgs = imgs.to(device)\n                tags = tags.to(device)\n                outputs = model(imgs)\n                cpred, totpred = getPredForAccuracy(tags, outputs)\n                correct_pred += cpred\n                total_pred += totpred\n                \n                if all_outputs == None:\n                    all_outputs = outputs\n                    all_tags = tags\n                else:\n                    all_outputs = torch.vstack((all_outputs, outputs))\n                    all_tags = torch.vstack((all_tags, tags))\n                \n            print('Single batch shape: ', imgs.shape)\n            print('Predictions by model for single sample image: ', model(imgs[0].unsqueeze(0)))\n            print('Predictions after applying Sigmoid: (We will threshold the probabilities and assign 1/0)', torch.sigmoid(model(imgs[0].unsqueeze(0))))\n            print('Actual tags: ', tags[0])\n            \n        print(f'Epoch: [{epoch+1} / {EPOCHS}] \\t Loss: {loss.item():.4f} \\t Accuracy (Val): {correct_pred/total_pred:.4f} \\t F2 score (Val): {getPredForFBeta(all_outputs, all_tags):.4f}')  \n    \n    return model, dataset\n\nmodel, dataset = train()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}